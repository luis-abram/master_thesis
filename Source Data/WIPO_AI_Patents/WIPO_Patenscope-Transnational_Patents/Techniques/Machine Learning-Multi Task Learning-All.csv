Time:,20.04.2020 22:29:46,...3,...4,...5,...6,...7,...8,...9,...10,...11,...12,...13
Query:,AItechniqueMachineLearningMultiTaskLearning,,,,,,,,,,,
Offices:,"EP,WO",,,,,,,,,,,
SortBy:,Relevance,,,,,,,,,,,
,,,,,,,,,,,,
Application Id,Application Number,Application Date,Publication Number,Publication Date,Country,Title,Abstract,I P C,Applicants,Inventors,Priorities Data,National Phase Entries
WO2019090023,PCT/US2018/058855,02.11.2018,WO/2019/090023,09.05.2019,WO,SYSTEM AND METHOD FOR INTERACTIVE REPRESENTATION LEARNING TRANSFER THROUGH DEEP LEARNING OF FEATURE ONTOLOGIES,"A method for interactive representation learning transfer to a convolutional neural network (CNN) is presented. The method includes obtaining at least first and second input image datasets from first and second imaging modalities. Furthermore, the method includes performing at least one of jointly training a first supervised learning CNN based on labels associated with the first input image dataset and a second supervised learning CNN based on labels associated with the second input image dataset to generate one or more common feature primitives and corresponding mapping functions and jointly training a first unsupervised learning CNN and a second unsupervised learning CNN with the first and second input image dataset respectively to learn compressed representations of the input image datasets, including common feature primitives and corresponding mapping functions and storing the common feature primitives and the corresponding mapping functions in a feature primitive repository.",G06N 3/04; G06N 3/08; G06T 7/00; G06K 9/62,GENERAL ELECTRIC COMPANY,"VAIDYA, Vivek Prabhakar; MULLICK, Rakesh; SHRIRAM, Krishna Seetharam; RANJAN, Sohan Rashmi; ANNANGI, Pavan Kumar V; THIRUVENKADAM, Sheshadri; ALADAHALLI, Chandan Kumar Mallappa; SREEKUMARI, Arathi",201741039221 03.11.2017 IN,
WO2020013760,PCT/SG2019/050324,29.06.2019,WO/2020/013760,16.01.2020,WO,ANNOTATION SYSTEM FOR A NEURAL NETWORK,An annotation system for a neural network and a method thereof are disclosed in the present application. The annotation system comprises a memory and a processor operatively coupled to the memory. The memory is configured for storing instructions to cause the process to receive information comprising a first set of unlabeled instances from at least one source; set a learning target of the information; select a second set of unlabeled instances from the first set of unlabeled instances by executing a software algorithm; and annotate the second set of unlabeled instances for generating labeled data. The software algorithm increases an efficiency of annotation in training neural networks for deep-learning-based video analysis by combining semi-supervised learning and transfer learning via a data augmentation method. The software algorithm can increase the efficiency of annotation by reducing an amount of annotation by an order of one magnitude.,G06N 3/08; G06N 3/02; G06F 17/24,XJERA LABS PTE. LTD.,"DING, Lu; ZHANG, JunWu; CHU, XinQi",10201805864P 07.07.2018 SG,SG-11201908315V
WO2020009652,PCT/SE2019/050672,05.07.2019,WO/2020/009652,09.01.2020,WO,METHODS AND SYSTEMS FOR DYNAMIC SERVICE PERFORMANCE PREDICTION USING TRANSFER LEARNING,"Systems and methods are provided for generating a data driven target model associated with a service having a first configuration. The method including: determining if there is an existing data driven source model for the service having a second configuration which is different from the first configuration; wherein if there is an existing data driven source model, determining whether a level of differences between the first configuration and the second configuration enables the existing data driven source model to be used as a source model for the data driven target model being generated; wherein if there is no existing data driven source model or if the level of differences for the existing data driven source model does not enable the existing data driven source model for the first configuration to be used, then requesting a source domain, wherein the source domain is a scaled down version of the target domain and learning the source model using the source domain; obtaining a number of samples from the target domain which is associated with the service; and using transfer learning to learn the data driven target model in the target domain using the source model and the obtained number of samples.",G06F 11/34; G06F 9/50; G06N 3/04; G06N 20/00,TELEFONAKTIEBOLAGET LM ERICSSON (PUBL),"MORADI, Farnaz; JOHNSSON, Andreas; FLINTA, Christofer; AHMED, Jawwad; STADLER, Rolf","62/694,583 06.07.2018 US",
WO2016133699,PCT/US2016/016248,03.02.2016,WO/2016/133699,25.08.2016,WO,PRE-TRAINING AND/OR TRANSFER LEARNING FOR SEQUENCE TAGGERS,"Systems and methods for pre-training a sequence tagger with unlabeled data, such as a hidden layered conditional random field model are provided. Additionally, systems and methods for transfer learning are provided. Accordingly, the systems and methods build more accurate, more reliable, and/or more efficient sequence taggers than previously utilized sequence taggers that are not pre-trained with unlabeled data and/or that are not capable of transfer learning/training.",G06N 7/00; G06N 99/00,"MICROSOFT TECHNOLOGY LICENSING, LLC","KIM, Young-Bum; JEONG, Minwoo; SARIKAYA, Ruhi","14/625,828 19.02.2015 US",
WO2019143538,PCT/US2019/013414,14.01.2019,WO/2019/143538,25.07.2019,WO,QUESTION AND ANSWER PAIR GENERATION USING MACHINE LEARNING,"An interactive question and answer (Q&A) service provides pairs of questions and corresponding answers related to the content of a web page. The service includes pre-configured Q&A pairs derived from a deep learning framework that includes a series of neural networks trained through joint and transfer learning to generate questions for a given text passage. In addition, pre-configured Q&A pairs are generated from historical web access patterns and sources related to the content of the web page.",G06N 3/04; G06N 5/04; G06N 3/08,"MICROSOFT TECHNOLOGY LICENSING, LLC","BAJAJ, Payal; BOLAND, Gearard; GUPTA, Anshul; JIN, Matthew Glenn; NORIEGA DE ARMAS, Eduardo Enrique; SHAVER, Jason; SUNDARESAN, Neelakantan; ZILOUCHIAN MOGHADDAM, Roshanak","62/619,804 21.01.2018 US; 16/101,520 13.08.2018 US",
WO2019083559,PCT/US2018/018902,21.02.2018,WO/2019/083559,02.05.2019,WO,DEEP CONVOLUTIONAL NEURAL NETWORK WITH SELF-TRANSFER LEARNING,"Systems and techniques for facilitating a deep convolutional neural network with self-transfer learning are presented. In one example, a system includes a machine learning component, a medical imaging diagnosis component and a visualization component. The machine learning component generates learned medical imaging output regarding an anatomical region based on a convolutional neural network that receives medical imaging data. The machine learning component also performs a plurality of sequential downsampling and upsampling of the medical imaging data associated with convolutional layers of the convolutional neural network. The medical imaging diagnosis component determines a classification and an associated localization for a portion of the anatomical region based on the learned medical imaging output associated with the convolutional neural network. The visualization component generates a multi-dimensional visualization associated with the classification and the localization for the portion of the anatomical region.",G06K 9/62; G06T 7/00; G06N 3/04,GENERAL ELECTRIC COMPANY,"ZHANG, Min; AVINASH, Gopal Biligeri","15/792,698 24.10.2017 US",
WO2017052709,PCT/US2016/039661,27.06.2016,WO/2017/052709,30.03.2017,WO,TRANSFER LEARNING IN NEURAL NETWORKS,"A method of transfer learning includes receiving second data and generating, via a first network, second labels for the second data. In one configuration, the first network has been previously trained on first labels for first data. Additionally, the second labels are generated for training a second network.",G06N 3/04,QUALCOMM INCORPORATED,"WIERZYNSKI, Casimir Matthew","62/195,763 22.07.2015 US; 14/851,911 11.09.2015 US",EP-2016826207; JP-2018502806; KR-1020187001459
WO2017173489,PCT/AU2017/050291,05.04.2017,WO/2017/173489,12.10.2017,WO,SYSTEMS AND METHODS FOR MAKING A PRODUCT,"A method used in making a product, wherein a characteristic of the product is at least in part determined by values of parameters used in making the product, the method including the steps of: (a) applying a machine-based transfer learning process to prior result data, the application of the transfer learning process resulting in the generation of predictive data; (b) selecting one or more parameter values to be used in making the product based on the generated predictive data; (c) making the whole or a part of the product using the selected one or more parameter values.",G06F 9/455; G06Q 99/00; G06N 7/00,DEAKIN UNIVERSITY,"RANA, Santu; GUPTA, Sunil Kumar; VENKATESH, Svetha; SUTTI, Alessandra",2016901256 05.04.2016 AU,EP-2017778473; AU-2017247001; CA-3015025
WO2018196760,PCT/CN2018/084306,25.04.2018,WO/2018/196760,01.11.2018,WO,ENSEMBLE TRANSFER LEARNING,"An apparatus and method are provided for ensemble transfer learning. One or more first (machine learning) projects that are similar to a second (machine learning) project are identified by comparing metadata of the one or more first projects and the second project, where the metadata comprises a plurality of characteristics and the characteristics of the first projects are compared to the characteristic of the second project to identify the one or more first projects. One or more (machine learning) models associated with the one or more first projects are selected as a plurality of models that each share a common feature set with the second project. Each model in the plurality of models is applied to input data for the second project to generate a set of results. Output data corresponding to the input data is produced for the second project based on the set of results.",G06K 9/62,"HUAWEI TECHNOLOGIES CO., LTD.","ZANG, Hui; WU, Zonghuan; YU, Jiangsheng","15/499,660 27.04.2017 US",
WO2019099305,PCT/US2018/060158,09.11.2018,WO/2019/099305,23.05.2019,WO,META-LEARNING FOR MULTI-TASK LEARNING FOR NEURAL NETWORKS,"Methods and systems for meta-learning are described for automating learning of child tasks with a single neural network. The order in which tasks are learned by the neural network can affect performance of the network, and the meta-learning approach can use a task-level curriculum for multi-task training. The task-level curriculum can be learned by monitoring a trajectory of loss functions during training. The meta-learning approach can learn to adapt task loss balancing weights in the course of training to get improved performance on multiple tasks on real world datasets. Advantageously, learning to dynamically balance weights among different task losses can lead to superior performance over the use of static weights determined by expensive random searches or heuristics. Embodiments of the meta-learning approach can be used for computer vision tasks or natural language processing tasks, and the trained neural networks can be used by augmented or virtual reality devices.",G06N 3/02; G06N 20/00,"MAGIC LEAP, INC.","RABINOVICH, Andrew; BADRINARAYANAN, Vijay; RAJENDRAN, Srivignesh; LEE, Chen-Yu","62/586,154 14.11.2017 US",
WO2018065158,PCT/EP2017/072210,05.09.2017,WO/2018/065158,12.04.2018,WO,COMPUTER DEVICE FOR TRAINING A DEEP NEURAL NETWORK,"A computer device for training a deep neural network is suggested. The computer device comprises a receiving unit for receiving a two-dimensional input image frame, a deep neural network for examining the two-dimensional input image frame in view of objects being included in the two-dimensional in- put image frame, wherein the deep neural network comprises a plurality of hidden layers and an output layer representing a decision layer, a training unit for training the deep neural network using transfer learning based on synthetic images for generating a model comprising trained parameters, and an out- put unit for outputting a result of the deep neural network based on the model. The suggested computer device is capable of providing meaningful results also if there is lack of sufficient annotated training data, for example, in the scenario where the camera or system is under development is inaccessible.",G06N 3/08; G06N 3/04; G06K 9/00,SIEMENS AKTIENGESELLSCHAFT,"GHOSH, Sanjukta; AMON, Peter; HUTTER, Andreas",201611034299 06.10.2016 IN,EP-2017761521; CN-201780075981.8
WO2019075410,PCT/US2018/055723,12.10.2018,WO/2019/075410,18.04.2019,WO,DEEP LEARNING-BASED DIAGNOSIS AND REFERRAL OF OPHTHALMIC DISEASES AND DISORDERS,"Disclosed herein are systems, methods, devices, and media for carrying out medical diagnosis of ophthalmic diseases and conditions. Deep learning algorithms enable the automated analysis of ophthalmic images to generate predictions of comparable accuracy to clinical experts.",G16H 50/20; A61B 5/00,AI TECHNOLOGIES INC.; THE REGENTS OF THE UNIVERSITY OF CALIFORNIA,"ZHANG, Kang; HOU, Rui; ZHENG, Lianghong","62/572,384 13.10.2017 US; 62/668,698 08.05.2018 US; 62/694,939 06.07.2018 US",
WO2019157435,PCT/US2019/017476,11.02.2019,WO/2019/157435,15.08.2019,WO,"CT BIG DATA FROM SIMULATION, EMULATION AND TRANSFER LEARNING","In some embodiments, a method of machine learning includes identifying, by an auto encoder network, a simulator feature based, at least in part, on a received first simulator data set and an emulator feature based, at least in part, on a received first emulator data set. The method further includes determining, by a synthesis control circuitry, a synthesized feature based, at least in part, on the simulator feature and based, at least in part, on the emulator feature; and generating, by the auto encoder network, an intermediate data set based, at least in part, on a second simulator data set and including the synthesized feature. Some embodiments of the method further include determining, by a generative artificial neural network, a synthesized data set based, at least in part, on the intermediate data set and based, at least in part, on an objective function.",G06F 15/18; G06K 9/62; A61B 8/08,RENSSELAER POLYTECHNIC INSTITUTE,"WANG, Ge; HARRISON, Daniel, David; JIA, Xun; MUELLER, Klaus","62/629,464 12.02.2018 US",
WO2018203147,PCT/IB2018/000935,23.04.2018,WO/2018/203147,08.11.2018,WO,MULTI-LINGUAL SEMANTIC PARSER BASED ON TRANSFERRED LEARNING,"The disclosure relates to transferred learning from a first language (e.g., a source language for which a semantic parser has been defined) to a second language (e.g., a target language for which a semantic parser has not been defined). A system may use knowledge from a trained model in one language to model another language. For example, the system may transfer knowledge of a semantic parser from a first (e.g., source) language to a second (e.g., target) language. Such transfer of knowledge may occur and be useful when the first language has sufficient training data but the second language has insufficient training data. The foregoing transfer of knowledge may extend the semantic parser for multiple languages (e.g., the first language and the second language).",G06F 17/27; G10L 15/18; G10L 21/00,"NUANCE COMMUNICATIONS, INC.","DUONG, Long; AFSHAR, Hadi; ESTIVAL, Dominique; PINK, Glen; COHEN, Philip; JOHNSON, Mark, Edward","62/488,838 23.04.2017 US",EP-2018794176
WO2018212711,PCT/SG2018/050234,15.05.2018,WO/2018/212711,22.11.2018,WO,PREDICTIVE ANALYSIS METHODS AND SYSTEMS,"Methods and systems for predictive analysis are disclosed, A predictive analysis method comprises: receiving a set of predictor variables as an input feature vector comprising a plurality of features; projecting each feature of the feature vector onto a dense vector representation to obtain a set of embedding vectors representing the input feature vector in an embedding space; converting the set of embedding vectors into a bi-interaction pooling vector that encodes second-order interactions between features of the feature vector in the embedding space; inputting the bi-interaction pooling vector into a hidden layer stack, the hidden layer stack comprising at least one hidden layer of neural network nodes; and transforming an output vector of the hidden layer stack into a prediction score.",G06N 3/02; G06F 15/18; G06N 7/00,NATIONAL UNIVERSITY OF SINGAPORE,"HE, Xiangnan; CHUA, Tat-Seng",10201704120Q 19.05.2017 SG,
WO2018226492,PCT/US2018/035275,31.05.2018,WO/2018/226492,13.12.2018,WO,ASYNCHRONOUS AGENTS WITH LEARNING COACHES AND STRUCTURALLY MODIFYING DEEP NEURAL NETWORKS WITHOUT PERFORMANCE DEGRADATION,"Methods and computer systems improve a trained base deep neural network by structurally changing the base deep neural network to create an updated deep neural network, such that the updated deep neural network has no degradation in performance relative to the base deep neural network on the training data. The updated deep neural network is subsequently training. Also, an asynchronous agent for use in a machine learning system comprises a second machine learning system ML2 that is to be trained to perform some machine learning task. The asynchronous agent further comprises a learning coach LC and an optional data selector machine learning system DS. The purpose of the data selection machine learning system DS is to make the second stage machine learning system ML2 more efficient in its learning (by selecting a set of training data that is smaller but sufficient) and/or more effective (by selecting a set of training data that is focused on an important task). The learning coach LC is a machine learning system that assists the learning of the DS and ML2. Multiple asynchronous agents could also be in communication with each others, each trained and grown asynchronously under the guidance of their respective learning coaches to perform different tasks.",G06N 3/02; G06N 3/08; G06F 15/18; G06F 17/30,D5AI LLC,"BAKER, James K.","62/515,142 05.06.2017 US",EP-2018813951
EP231425267,15909311,27.11.2015,3382609,03.10.2018,EP,"RISK ASSESSMENT METHOD, RISK ASSESSMENT PROGRAM, AND INFORMATION PROCESSING DEVICE",A risk evaluation method is disclosed. A machine learning is conducted by using a neural network by inputting training data. A data distance corresponding to a permission level is calculated based on restoration data and the training data. The restoration data are generated by using at least one weight at the permission level among a plurality of weights of synapses at the plurality of layers. The plurality of weights are generated by the machine learning.,G06N 3/08; G06N 3/04,FUJITSU LTD,ENDOH TOSHIO,2015083425 27.11.2015 JP,
WO2019113122,PCT/US2018/063928,04.12.2018,WO/2019/113122,13.06.2019,WO,SYSTEMS AND METHODS FOR IMPROVED MACHINE LEARNING FOR CONVERSATIONS,"Systems and methods for improvements in AI model learning and updating are provided. The model updating may reuse existing business conversations as the training data set. Features within the dataset may be defined and extracted. Models may be selected and parameters for the models defined. Within a distributed computing setting the parameters may be optimized, and the models deployed. The training data may be augmented over time to improve the models. Deep learning models may be employed to improve system accuracy, as can active learning techniques. The models developed and updated may be employed by a response system generally, or may function to enable specific types of AI systems. One such a system may be an AI assistant that is designed to take use cases and objectives, and execute tasks until the objectives are met. Another system capable of leveraging the models includes an automated question answering system utilizing approved answers. Yet another system for utilizing these various classification models is an intent based classification system for action determination. Lastly, it should be noted that any of the above systems may be further enhanced by enabling multiple language analysis.",G06F 15/18,"CONVERSICA, INC.","TERRY, George, Alexis; KOEPF, Werner; JONNALAGADDA, Siddhartha, Reddy; HARRIGER, James, D.; WEBB-PURKIS, William, Dominic; GAINOR, Macgregor, S.; FERGUSON, Collin, C.; SHANKAR, Ravi; SHANKAR, Shashi; MCCANN, Ian; GODFREY, Keith; LONG, Christopher, Allan; KAMINSKI, Brian, Matthew; SANSONE, John; KIRKLAND, Jennifer; GINSTROM, Ryan, Francis; BREDLOW, Caleb, Andrew; SARGENT, Kyle; FORDYCE, Alexander Carmelo, Reid","16/208,478 03.12.2018 US; 16/208,488 03.12.2018 US; 16/208,484 03.12.2018 US; 62/594,415 04.12.2017 US",
WO2018236446,PCT/US2018/024168,23.03.2018,WO/2018/236446,27.12.2018,WO,TRANSFER LEARNING OF CONVOLUTIONAL NEURAL NETWORKS FROM VISIBLE COLOR (RBG)TO INFRARED (IR) DOMAIN,Described is a system for converting a convolutional neural network (CNN) designed and trained for color (RGB) images to one that works on infrared (IR) or grayscale images. The converted CNN comprises a series of convolution layers of neurons arranged in a set kernels having corresponding depth slices. The converted CNN is used for performing object detection. A mechanical component of an autonomous device is controlled based on the object detection.,G06T 3/40; G06T 5/20; G06N 3/08,"HRL LABORATORIES, LLC","UHLENBROCK, Ryan, M.; CHEN, Yang; KHOSLA, Deepak","62/510,741 24.05.2017 US",EP-2018819924; CN-201880023966.3
WO2017203262,PCT/GB2017/051481,25.05.2017,WO/2017/203262,30.11.2017,WO,METHOD AND SYSTEM FOR PREDICTING GARMENT ATTRIBUTES USING DEEP LEARNING,"There is provided a computer implemented method for predicting garment or accessory attributes using deep learning techniques, comprising the steps of: (i) receiving and storing one or more digital image datasets including images of garments or accessories; (ii) training a deep model for garment or accessory attribute identification, using the stored one or more digital image datasets, by configuring a deep neural network model to predict (a) multiple-class discrete attributes; (b) binary discrete attributes, and (c ) continuous attributes, (iii) receiving one or more digital images of a garment or an accessory, and (iv) extracting attributes of the garment or the accessory from the one or more received digital images using the trained deep model for garment or accessory attribute identification. A related system is also provided.",G06K 9/00; G06K 9/46; G06K 9/62,METAIL LIMITED,"CHEN, Yu; SHANKAR, Sukrit; DOWNING, Jim; TOWNSEND, Joe; ROBERTSON, Duncan; ADEYOOLA, Tom",1609245.4 25.05.2016 GB; 1620670.8 05.12.2016 GB; 1702930.7 23.02.2017 GB,EP-2017734807
WO2020048722,PCT/EP2019/071317,08.08.2019,WO/2020/048722,12.03.2020,WO,TRANSFER LEARNING OF A MACHINE-LEARNING MODEL USING A HYPERPARAMETER RESPONSE MODEL,"The invention relates to a method of building a machine- learning model (301-304) for operational monitoring of an ensemble (200) of field devices (201-204), the method comprising: performing a training (2001, 2012) of a first value of a hyperparameter (2053) of the machine-learning model (301-304) based on training data (603) of a first device of the ensemble (200); and, based on the training: obtaining a response model (2050) of the hyperparameter, the response model providing a mapping of a value of the hyperparameter to a performance indicator of the machine- learning model; and determining a second value of the hyperparameter for a second field device (201-204) of the ensemble (200) based on the response model (2050).",G06N 20/00; G06N 7/00,SIEMENS AKTIENGESELLSCHAFT,"GEIPEL, Markus Michael; MITTELSTÄDT, Sebastian; VON BEUNINGEN, Anja",18192498.6 04.09.2018 EP,
EP243363826,17206055,07.12.2017,3495992,12.06.2019,EP,DANGER RANKING USING END TO END DEEP NEURAL NETWORK,,G06K 9/00,IMRA EUROPE SAS,TSISHKOU DZMITRY; BENDAHAN RÉMY,17206055 07.12.2017 EP,
WO2019231448,PCT/US2018/035306,31.05.2018,WO/2019/231448,05.12.2019,WO,SOLAR IRRADIATION PREDICTION USING DEEP LEARNING WITH END-TO- END TRAINING,"Deep learning is used to train a neural network for end-to-end prediction of short term (e.g., 20 minutes or less) solar irradiation based on camera images and metadata. The architecture of the neural network includes a recurrent network for temporal considerations. The images and metadata are input at different locations in the neural network. The resulting machine-learned neural network predicts solar irradiation based on camera images and metadata so that a solar plant and back-up power source may be controlled to minimize output power variation.",G06N 3/04; G06N 3/08,SIEMENS AKTIENGESELLSCHAFT,"CHANG, Ti-Chiun; REEB, Patrick; BAMBERGER, Joachim; PENG, Kuan-Chuan; ERNST, Jan",,
EP210495663,16180143,19.07.2016,3273387,24.01.2018,EP,MEDICAL IMAGE SEGMENTATION WITH A MULTI-TASK NEURAL NETWORK SYSTEM,"The invention refers to a method and system for parsing a medical image, comprising the steps of: 
- Providing (61) a network, being a multi-task deep neural network 
- Providing (62) the image to be parsed 
- Pre-determining (63) image features derived from the image 
- Defining (64) 
- a main task for image parsing and 
- adjuvant tasks for reconstruction of the image features  
- Applying (65) a multi-task learning pipeline to train the network by simultaneously learning the deep neural multi-task network on main and adjuvant tasks in a supervised manner, and to perform multi-tasks prediction, wherein the adjuvant tasks act as regularization of the network during a training phase and are used for deriving an in-build, automatic confidence estimation during a prediction phase.",G06K 9/46; G06K 9/62,SIEMENS HEALTHCARE GMBH,KELM MICHAEL; PAULY OLIVIER,16180143 19.07.2016 EP,
WO2017117568,PCT/US2016/069580,30.12.2016,WO/2017/117568,06.07.2017,WO,ACCELERATED TRAINING OF A MACHINE LEARNING BASED MODEL FOR SEMICONDUCTOR APPLICATIONS,Methods and systems for accelerated training of a machine learning based model for semiconductor applications are provided. One method for training a machine learning based model includes acquiring information for non-nominal instances of specimen(s) on which a process is performed. The machine learning based model is configured for performing simulation(s) for the specimens. The machine learning based model is trained with only information for nominal instances of additional specimen(s). The method also includes re-training the machine learning based model with the information for the non-nominal instances of the specimen(s) thereby performing transfer learning of the information for the non-nominal instances of the specimen(s) to the machine learning based model.,G06N 99/00,KLA-TENCOR CORPORATION,"BHASKAR, Kris; KARSENTI, Laurent; YOUNG, Scott A.; MAHADEVAN, Mohan; ZHANG, Jing; DUFFY, Brian","62/273,985 31.12.2015 US; 15/394,792 29.12.2016 US",IL-259705; JP-2018534670; KR-1020187021817; EP-2016882778
WO2018222204,PCT/US2017/035637,02.06.2017,WO/2018/222204,06.12.2018,WO,SYSTEMS AND METHODS FOR BLACK-BOX OPTIMIZATION,"The present disclosure provides computing systems and associated methods for optimizing one or more adjustable parameters (e.g. operating parameters) of a system. In particular, the present disclosure provides a parameter optimization system that can perform one or more black-box optimization techniques to iteratively suggest new sets of parameter values for evaluation. The iterative suggestion and evaluation process can serve to optimize or otherwise improve the overall performance of the system, as evaluated by an objective function that evaluates one or more metrics. The present disclosure also provides a novel black-box optimization technique known as ""Gradientless Descent"" that is more clever and faster than random search yet retains most of random search's favorable qualities.",G06N 3/08; G06N 5/00; G06N 99/00; G06N 7/00,GOOGLE LLC,"GOLOVIN, Daniel Reuben; SOLNIK, Benjamin; MOITRA, Subhodeep; SCULLEY, II, David W.; KOCHANSKI, Gregory Peter",,CN-201780088583.X; EP-2017732650
EP289840122,19178450,05.06.2019,3620993,11.03.2020,EP,METHOD AND SYSTEM FOR SCALABLE MULTI-TASK LEARNING WITH CONVEX CLUSTERING,"A method for scalable multi-task learning with convex clustering includes: extracting features from a dataset of a plurality of tasks; generating a graph from the extracted features, nodes of the graph representing linear learning models, each of the linear learning models being for one of the tasks; constraining the graph using convex clustering to generate a convex cluster constrained graph; and obtaining a global solution by minimizing a graph variable loss function, the minimizing the graph variable loss function comprising: introducing auxiliary variables for each connection between nodes in the convex cluster constrained graph; iteratively performing the following operations until convergence: updating the linear learning models by solving a sparse linear system; and updating the auxiliary variables by solving an equation having the auxiliary variables each be proportional to a vector norm for their respective nodes.",G06N 5/00; G06N 20/20,NEC LABORATORIES EUROPE GMBH,HE XIAO; ALESIANI FRANCESCO; SHAKER AMMAR,201862724704 30.08.2018 US; 201916414812 17.05.2019 US,
WO2018126213,PCT/US2017/069102,29.12.2017,WO/2018/126213,05.07.2018,WO,MULTI-TASK LEARNING USING KNOWLEDGE DISTILLATION,"Methods, systems, and apparatus, including computer programs encoded on computer storage media for performing multi-task learning. In one method a system obtains a respective set of training data for each of multiple machine learning tasks. For each of the machine learning tasks, the system configures a respective teacher machine learning model to perform the machine learning task by training the teacher machine learning model on the training data. The system trains a single student machine learning model to perform the multiple machine learning tasks using (i) the configured teacher machine learning models, and (ii) the obtained training data.",G06N 3/04,GOOGLE LLC,"CHUNG, Junyoung; JOHNSON PREMKUMAR, Melvin, Jose; SCHUSTER, Michael; MACHEREY, Wolfgang","62/441,119 30.12.2016 US",
WO2020048728,PCT/EP2019/071412,09.08.2019,WO/2020/048728,12.03.2020,WO,BUILDING A MACHINE-LEARNING MODEL WITH IMPROVED FEATURE DISTRIBUTION,"The invention relates to a method of building a deep-learning classifier machine-learning model (300) for operational monitoring of an ensemble (200) of field devices (201-204), comprising: performing a training of one or more feature recognition algorithms (93) of the deep-learning classifier machine-learning model (300) using labeled training data (99) obtained from the ensemble (200) of field devices (201-204), the training being based on a prediction error signal (95) and a further error signal (7012); and determining the further error signal based on a difference between density estimations (7011) of features recognized by the one or more feature recognition algorithms (93) using the labeled training data (99) of different ones of the ensemble (200) of field devices (201-204).",G06K 9/00; G06K 9/62; G06K 9/46,SIEMENS AKTIENGESELLSCHAFT,"GEIPEL, Markus Michael; MITTELSTÄDT, Sebastian",18192496.0 04.09.2018 EP,
EP243363805,17836214,08.06.2017,3495973,12.06.2019,EP,METHOD AND DEVICE FOR PERFORMING TRANSFORMATION-BASED LEARNING ON MEDICAL IMAGE,"The present application discloses a method and device for performing transformation-based learning on a medical image. The method comprises: reading raw data of a medical image, performing transformation processing on the data by analyzing a data attribute, and integrating the same into a data format capable of being received by a model to be analyzed; selecting a transformation mode by comparing parameters of the model to be analyzed and a trained model, so as to perform parameter transformation and apply transformation-based learning to training of the model to be analyzed for the medical image; and upon finishing model training, applying a parameter of a trained model to image category analysis. The method can increase the accuracy of a model obtained by performing deep learning on a small quantity of medical images. The invention further comprises a device for performing transformation-based learning on a medical image, comprising: a data processing module; a transformation-based learning module; and an application module.",G16H 30/40; G06N 3/04; G06N 3/08; G16H 50/20,INFERVISION,CHEN KUAN; ZHANG RONGGUO,201610627265 03.08.2016 CN; 2017087587 08.06.2017 CN,
WO2018017319,PCT/US2017/040673,05.07.2017,WO/2018/017319,25.01.2018,WO,LIVENESS DETECTION FOR ANTISPOOF FACE RECOGNITION,A face recognition system and facility access control system are provided. The face recognition system includes a camera (110) configured to capture an input image of a subject purported to be a person. The face recognition system further includes a memory (122) storing a deep learning model configured to perform multi-task learning for a pair of tasks including a liveness detection task and a face recognition task. The face recognition task also includes a processor (121) configured to apply the deep learning model to the input image to recognize an identity of the subject in the input image and a liveness of the subject. The liveness detection task is configured to evaluate a plurality of different distractor modalities corresponding to different physical spoofing materials to prevent face spoofing for the face recognition task.,G06K 9/00; G06N 3/08,"NEC LABORATORIES AMERICA, INC.; NEC HONG KONG LIMITED","CHANDRAKER, Manmohan; LAU, Eric; WONG, Elsa; YU, Xiang","62/365,510 22.07.2016 US; 62/366,285 25.07.2016 US; 15/637,264 29.06.2017 US; 15/637,368 29.06.2017 US; 15/637,465 29.06.2017 US; 15/637,569 29.06.2017 US; 15/637,644 29.06.2017 US",JP-2018538215; SG-11201804580U; DE-112017000231
WO2016182659,PCT/US2016/026944,11.04.2016,WO/2016/182659,17.11.2016,WO,BIT WIDTH SELECTION FOR FIXED POINT NEURAL NETWORKS,"A method for selecting bit widths for a fixed point machine learning model includes evaluating a sensitivity of model accuracy to bit widths at each computational stage of the model. The method also includes selecting a bit width for parameters, and/or intermediate calculations in the computational stages of the mode. The bit width for the parameters and the bit width for the intermediate calculations may be different. The selected bit width may be determined based on the sensitivity evaluation.",G06N 3/063; G06N 3/10,QUALCOMM INCORPORATED,"LIN, Dexu; ANNAPUREDDY, Venkata Sreekanta Reddy; JULIAN, David Jonathan; WIERZYNSKI, Casimir Matthew","62/159,097 08.05.2015 US; 14/936,594 09.11.2015 US",EP-2016718942
WO2017007742,PCT/US2016/040925,05.07.2016,WO/2017/007742,12.01.2017,WO,TRANSFER LEARNING TECHNIQUES FOR DISPARATE LABEL SETS,"Examples of the present disclosure describe systems and methods of transfer learning techniques for disparate label sets. In aspects, a data set may be accessed on a server device. The data set may comprise labels and word sets associated with the labels. The server device may induce label embedding within the data set. The embedded labels may be represented by multi-dimensional vectors that correspond to particular labels. The vectors may be used to construct label mappings for the data set. The label mappings may be used to train a model to perform domain adaptation or transfer learning techniques. The model may be used to provide results to a statement/query or to train a different model.",G06N 99/00; G10L 15/18,"MICROSOFT TECHNOLOGY LICENSING, LLC","KIM, Young-Bum; SARIKAYA, Ruhi","14/792,269 06.07.2015 US",EP-2016742099
WO2017207138,PCT/EP2017/058100,05.04.2017,WO/2017/207138,07.12.2017,WO,METHOD OF TRAINING A DEEP NEURAL NETWORK,"The invention describes a method of training a deep neural network (N) to perform a specific image processing task, which method comprises the steps of extracting a plurality of pseudo-targets (101PS,..., 105PS) from a non-annotated set (DBna) of medical images; performing supervised pre-training on an initialized network (Ninit) to obtain a pre-trained network (Npre) with a pseudo-task specific top layer (LPTS); replacing the pseudo-task specific layer (LPTS) by a task- specific layer (LTS); and performing supervised training on the pre-trained network (Npre) using an annotated set (DB) of medical images.",G06K 9/46; G06K 9/62,SIEMENS HEALTHCARE GMBH,"KELM, Michael; PAULY, Olivier; JEREBKO, Anna",16172126.1 31.05.2016 EP,
EP204575604,16180230,19.07.2016,3226177,04.10.2017,EP,SYSTEM AND METHOD FOR OPTICAL CHARACTER RECOGNITION,"This disclosure relates to system and method for optical character recognition. In one embodiment, the method comprises providing an image data to a plurality of customized machine learning algorithms or various customized neural networks, configured to recognize a set of pre-defined characters. The method comprises presenting one or more suggestions for the character to the user in response to negative character recognition, and training a customized machine learning algorithm corresponding to the character if one of the suggestions is identified by the user. If the suggestions are rejected by the user, the method comprises prompting the user to identify the character and determining presence of the character in the set of pre-defined characters. The method further comprises training a customized machine learning algorithm corresponding to the character if the character is present, or dynamically creating a customized machine learning algorithm corresponding to the character if the character is not present.",G06K 9/62,WIPRO LTD,SINGH MADHUSUDAN; RAMANNA RAMPRASAD KANAKATTE; MANNOPANTAR RAGHOTTAM,201641010875 29.03.2016 IN,
WO2018015080,PCT/EP2017/064768,16.06.2017,WO/2018/015080,25.01.2018,WO,MEDICAL IMAGE SEGMENTATION WITH A MULTI-TASK NEURAL NETWORK SYSTEM,"Medical image segmentation with a multi-task neural network system The invention refers to a method and system for parsing a medical image, comprising the steps of: - Receiving a network, being a multi-task deep neural network - Receiving the image to be parsed - Pre-determining (63) image features derived from the image - Defining (64) - a main task for image parsing and - an adjuvant task for reconstruction of the image features - Applying (65) a multi-task learning pipeline to train the network by simultaneously learning the deep neural multi-task network on main and adjuvant tasks in a supervised manner, and to perform multi-tasks prediction, wherein the adjuvant task acts as regularization of the network during a training phase and is used for deriving an in-build, automatic confidence estimation during a prediction phase.",G06K 9/46; G06K 9/62,SIEMENS HEALTHCARE GMBH,"KELM, Michael; PAULY, Olivier",16180143.6 19.07.2016 EP,
WO2019191697,PCT/US2019/025020,29.03.2019,WO/2019/191697,03.10.2019,WO,METHOD AND SYSTEM FOR DIGITAL STAINING OF LABEL-FREE FLUORESCENCE IMAGES USING DEEP LEARNING,"A deep learning-based digital staining method and system are disclosed that enables the creation of digitally/virtually-stained microscopic images from label or stain-free samples based on autofluorescence images acquired using a fluorescent microscope. The system and method have particular applicability for the creation of digitally/virtually-stained whole slide images (WSIs) of unlabeled/unstained tissue samples that are analyzes by a histopathologist. The methods bypass the standard histochemical staining process, saving time and cost. This method is based on deep learning, and uses, in one embodiment, a convolutional neural network trained using a generative adversarial network model to transform fluorescence images of an unlabeled sample into an image that is equivalent to the brightfield image of the chemically stained-version of the same sample. This label-free digital staining method eliminates cumbersome and costly histochemical staining procedures and significantly simplifies tissue preparation in pathology and histology fields.",G06K 9/00; G06T 1/00; G06T 1/20; G06T 1/40; G06T 7/00; G06T 7/10; G06T 7/11,THE REGENTS OF THE UNIVERSITY OF CALIFORNIA,"OZCAN, Aydogan; RIVENSON, Yair; WANG, Hongda; WEI, Zhensong","62/651,005 30.03.2018 US",
WO2015143580,PCT/CN2014/000350,28.03.2014,WO/2015/143580,01.10.2015,WO,METHOD AND SYSTEM FOR VERIFYING FACIAL DATA,"Disclosed are a method for verifying facial data and a system thereof. The method comprises a step of retrieving a plurality of source-domain datasets from a first database and a target-domain dataset from a second database different from the first database; a step of determining a latent subspace matching with target-domain dataset best, and a posterior distribution for the determined latent subspace from the target-domain dataset and the source-domain datasets; a step of determining information shared between the target-domain data and the source-domain datasets; and a step of establishing a Multi-Task learning model from the posterior distribution P, and the shared information M on the target-domain dataset and the source-domain datasets.",G06K 9/00,"HUAWEI TECHNOLOGIES CO., LTD","TANG, Xiaoou; LU, Chaochao",,
EP206658720,16172126,31.05.2016,3252671,06.12.2017,EP,METHOD OF TRAINING A DEEP NEURAL NETWORK,"The invention describes a method of training a deep neural network (N) to perform a specific image processing task, which method comprises the steps of extracting a plurality of pseudo-targets (101 PS , ..., 105 PS ) from a non-annotated set (DB na ) of medical images; performing supervised pre-training on an initialized network (N init ) to obtain a pre-trained network (N pre ) with a pseudo-task specific top layer (L PTS ) ; replacing the pseudo-task specific layer (L PTS ) by a task-specific layer (L TS ); and performing supervised training on the pre-trained network (N pre ) using an annotated set (DB) of medical images.",G06K 9/46; G06K 9/62,SIEMENS HEALTHCARE GMBH,KELM MICHAEL; PAULY OLIVIER; JEREBKO ANNA,16172126 31.05.2016 EP,
WO2019150612,PCT/JP2018/029320,30.07.2018,WO/2019/150612,08.08.2019,WO,SYSTEM AND METHOD FOR CONTROLLING OPERATION,"Systems and methods for controlling an operation of devices for an occupant. A processor to iteratively train a personalized thermal comfort model (PTCM) during an initialization period. Receive a sequence of unlabeled real-time data. A transmitter requests the occupant to label an instance of unlabeled data, when there is a disagreement between the labels of stored historical labeled data (LD) similar to received unlabeled data and a predicted label on the new unlabeled data that exceeds a threshold. The processor, in response to receiving the labeled data, trains the PTCM using different weights of the personalized LD than to the historical LD. Retrains PTCM using the historical database and the updated personalized database. A controller controls the set of devices based on the retrained PTCM.",G05B 15/02; G05B 13/04,MITSUBISHI ELECTRIC CORPORATION,"LAFTCHIEV, Emil; NATARAJAN, Annamalai","15/888,172 05.02.2018 US",
WO2018081751,PCT/US2017/059119,30.10.2017,WO/2018/081751,03.05.2018,WO,VIDEO TAGGING SYSTEM AND METHOD,"An automatic video tagging system which learns from videos, their web context and comments shared on social networks is described. Massive multimedia collections are analyzed by Internet crawling and a knowledge base is maintained that updates in real time with no need of human supervision. As a result, each video is indexed with a rich set of labels and linked with other related contents. Practical applications of video recognition require a label scheme that is appealing to the end-user (i.e. obtained from social curation) and a training dataset that can be updated in real-time to be able to recognize new actions, scenes and people. To create this dataset that evolves in real-time and uses labels that are relevant to the users, a weakly-supervised deep learning approach is utilized combining both a machine-learning pre-processing stage together with a set of keywords obtained from the internet. The resulting tags combined with videos and summaries of videos are used with deep learning to train a neural network in an unsupervised manner that allows the tagging system to go from an image to a set of tags for the image and then to the visual representation of a tag.",G06E 1/00; G06F 17/30; G06N 5/02,"VILYNX, INC.","BOU BALUST, Elisenda; RIVEIRO INSUA, Juan Carlos; FERNANDEZ CAÑELLAS, Delia; ESPADALER RODÉS, Joan; ADURIZ BERASATEGI, Asier; VARAS GONZÁLEZ, David","62/414,308 28.10.2016 US; 62/552,369 30.08.2017 US",EP-2017866015
WO2019100032,PCT/US2018/061887,19.11.2018,WO/2019/100032,23.05.2019,WO,METHODS FOR USING MACHINE LEARNING AND MECHANISTIC MODELS FOR BIOLOGICAL FEATURE MAPPING WITH MULTIPARAMETRIC MRI,"Described here are systems and methods for generating and implementing a hybrid machine learning and mechanistic model to produce biological feature maps, or other measurements of biological features, based on an input of multiparametric magnetic resonance or other images. The hybrid model can include a combination of a machine learning model and a mechanistic model that takes as an input multiparametric MRI, or other imaging, data to generate biological feature maps (e.g., tumor cell density maps), or other measures or predictions of biological features (e.g., tumor cell density). The hybrid models have capabilities of learning individual-specific relationships between imaging features and biological features.",A61B 5/026,MAYO FOUNDATION FOR MEDICAL EDUCATION AND RESEARCH,"HU, Leland, S.; LI, Jing; SWANSON, Kristin, R.; WU, Teresa; GAW, Nathan; YOON, Hyunsoo; HAWKINS-DAARUD, Andrea","62/588,096 17.11.2017 US; 62/684,096 12.06.2018 US",
WO2019017990,PCT/US2017/062222,17.11.2017,WO/2019/017990,24.01.2019,WO,LEARNING UNIFIED EMBEDDING,"A computer-implemented method for generating a unified machine learning model using a neural network on a data processing apparatus is described. The method includes the data processing apparatus determining respective learning targets for each of a plurality of object verticals. The data processing apparatus determines the respective learning targets based on two or more embedding outputs of the neural network. The method also includes the data processing apparatus training the neural network to identify data associated with each of the plurality of object verticals. The data processing apparatus trains the neural network using the respective learning targets and based on a first loss function. The data processing apparatus uses the neural network trained to generate a unified machine learning model, where the model is configured to identify particular data items associated with each of the plurality of object verticals.",G06N 3/08; G06N 3/04; G06K 9/62,GOOGLE LLC,"SONG, Yang; LI, Yuan; WU, Bo; CHEN, Chao-Yeh; ZHANG, Xiao; ADAM, Hartwig","62/533,535 17.07.2017 US",EP-2017812137; CN-201780089483.9
WO2018213763,PCT/US2018/033487,18.05.2018,WO/2018/213763,22.11.2018,WO,NATURAL LANGUAGE PROCESSING USING CONTEXT-SPECIFIC WORD VECTORS,"A system is provided for natural language processing. In some embodiments, the system includes an encoder for generating context-specific word vectors for at least one input sequence of words. The encoder is pre-trained using training data for performing a first natural language processing task. A neural network performs a second natural language processing task on the at least one input sequence of words using the context-specific word vectors. The first natural language process task is different from the second natural language processing task and the neural network is separately trained from the encoder. In some embodiments, the first natural processing task can be machine translation, and the second natural processing task can be one of sentiment analysis, question classification, entailment classification, and question answering.",G06N 3/04; G06F 17/28,"SALESFORCE.COM, INC.","MCCANN, Bryan; XIONG, Caiming; SOCHER, Richard","62/508,977 19.05.2017 US; 62/536,959 25.07.2017 US; 15/982,841 17.05.2018 US",CN-201880033016.9; CA-3062891; DE-112018002601
WO2019051359,PCT/US2018/050177,10.09.2018,WO/2019/051359,14.03.2019,WO,A SYSTEM AND METHOD FOR AUTOMATED LABELING AND ANNOTATING UNSTRUCTURED MEDICAL DATASETS,"Supervised and unsupervised learning schemes may be used to automatically label medical images for use in deep learning applications. Large labeled datasets may be generated from a small initial training set using an iterative snowball sampling scheme. A machine learning powered automatic organ classifier for imaging datasets, such as CT datasets, with a deep convolutional neural network (CNN) followed by an organ dose calculation is also provided. This technique can be used for patient-specific organ dose estimation since the locations and sizes of organs for each patient can be calculated independently.",G06F 15/18,THE GENERAL HOSPITAL CORPORATION,"DO, Synho","62/555,799 08.09.2017 US; 62/555,767 08.09.2017 US",
WO2017161233,PCT/US2017/022902,17.03.2017,WO/2017/161233,21.09.2017,WO,DEEP MULTI-TASK REPRESENTATION LEARNING,"Technologies for analyzing multi-task multimodal data to detect multi-task multimodal events using a deep multi-task representation learning, are disclosed. A combined model with both generative and discriminative aspects is used to share information during both generative and discriminative processes. The technologies can be used to classify data and also to generate data from classification events. The data can then be used to morph data into a desired classification event.",G06N 5/04,SRI INTERNATIONAL,"AMER, Mohamed R.; SHIELDS, Timothy J.; TAMRAKAR, Amir; EHLRICH, Max; ALMAEV, Timur","62/309,804 17.03.2016 US",US-16085859
WO2017210690,PCT/US2017/035974,05.06.2017,WO/2017/210690,07.12.2017,WO,SPATIAL AGGREGATION OF HOLISTICALLY-NESTED CONVOLUTIONAL NEURAL NETWORKS FOR AUTOMATED ORGAN LOCALIZATION AND SEGMENTATION IN 3D MEDICAL SCANS,"Disclosed are systems and methods for localization and segmentation of organs (especially abnormally shaped, deformable, and/or smaller organs, such as the pancreas and lymph nodes) based on data from 3D medical imaging (e.g., CT and MRI scans) using holistically-nested convolutional neural networks (""HNNs""). Using as an example CT scan data and the pancreas, the methods can include localizing an organ from an entire 3D CT scan, providing a reliable bounding box for the more refined segmentation step. The methods can further comprise introducing a fully deep-learning approach, based on an efficient application of HNNs on the three orthogonal views. The resulting HNN per-pixel probability maps can then be fused using pooling to reliably produce a 3D bounding box of the pancreas that maximizes the recall. An introduced localizer compares favorably to both a conventional non-deep-learning method and a hybrid approach based on spatial aggregation of superpixels using random forest classification. The segmentation phase can operate within the computed bounding box and can integrate semantic mid-level cues of deeply-learned organ interior and boundary maps, obtained by two additional and separate realizations pf HNNs. By integrating these two mid-level cues, the disclosed methods are capable of generating boundary-preserving pixel-wise class label maps that result in exceptional final organ segmentations.",G06K 9/00; G06T 7/00,"THE UNITED STATES OF AMERICA, AS REPRESENTED BY THE SECRETARY, DEPARTMENT OF HEALTH AND HUMAN SERVICES","HARRISON, Adam P.; WANG, Xiaosong; SUMMERS, Ronald; NOGUES, Isabella-Emmanuella; ROTH, Holger; LU, Le","62/450,681 26.01.2017 US; 62/345,606 03.06.2016 US",
WO2020068848,PCT/US2019/052724,24.09.2019,WO/2020/068848,02.04.2020,WO,DEEP LEARNING LYME DISEASE DIAGNOSIS,"Techniques for diagnosing Lyme disease are presented. The techniques may include obtaining a digital photo of a skin lesion, providing the digital photo to a deep learning convolutional neural network, such that an output diagnosis is provided. The deep learning convolutional neural network may be trained using a training corpus including a plurality of digital training images annotated according to one of a plurality of training image diagnoses, where the plurality of training image diagnoses include at least one Lyme disease type, normal skin, and at least one non-Lyme skin lesion type, and where the plurality of digital training images include multiple digital photographs publicly available on the internet. The techniques can include outputting the output diagnosis.",A61B 5/00; G06T 1/40; G06N 20/00,THE JOHNS HOPKINS UNIVERSITY,"BILLINGS, Seth D.; BURLINA, Philippe M.; JOSHI, Neil J.; AUCOTT, John N.; NG, Elise","62/735,351 24.09.2018 US",
EP210494789,16782808,21.04.2016,3272611,24.01.2018,EP,"INFORMATION PROCESSING SYSTEM, INFORMATION PROCESSING METHOD, AND PROGRAM","An information processing system (1000) that appropriately estimates a driving conduct includes: a detector (1001) that detects a vehicle environment state, which is at least one of surroundings of a vehicle and a driving state of the vehicle; a behavior learning unit (1002) configured to cause a neural network to learn a relationship between the vehicle environment state detected by the detector (1001) and a behavior of the vehicle implemented after the vehicle environment state; and a behavior estimation unit (1003) configured to estimate a behavior of the vehicle by inputting, into the neural network that learned, the vehicle environment state detected at a current point in time by the detector.",B60W 50/14; B60K 31/00; B60K 35/00; B60R 16/02; B60W 30/00; B60W 40/09; B60W 50/00; B60W 50/10; G05D 1/00; G06K 9/00; G06K 9/62; G06N 3/04; G06N 3/08; G08G 1/01; G08G 1/0962; G08G 1/0967; G08G 1/16,PANASONIC IP MAN CO LTD,MOTOMURA HIDETO; KOURKOUSS MOHAMED SAHIM; SAWADA YOSHIHIDE; MORI TOSHIYA; TSUJI MASANAGA,2015087069 21.04.2015 JP; 2015099474 14.05.2015 JP; 2015119139 12.06.2015 JP; 2015215049 30.10.2015 JP; 2016002125 21.04.2016 JP; 2016038476 29.02.2016 JP,
WO2020069369,PCT/US2019/053536,27.09.2019,WO/2020/069369,02.04.2020,WO,SYSTEM AND METHOD FOR USING A DEEP LEARNING NETWORK OVER TIME,"The present approach relates to a system capable of life-long learning in a deep learning context. The system includes a deep learning network configured to process an input dataset and perform one or more tasks from among a first set of tasks. As an example, the deep learning network may be part of an imaging system, such as a medical imaging system, or may be used in industrial applications. The system further includes a learning unit communicatively coupled to the deep learning network 102 and configured to modify the deep learning network so as to enable it to perform one or more tasks in a second task list without losing the ability to perform the tasks from the first list.",G06N 3/04; G06N 3/08,GENERAL ELECTRIC COMPANY,"VENKATARAMANI, Rahul; ANAMANDRA, Sai; RAVISHANKAR, Hariharan; SUDHAKAR, Prasad","201841036423 27.09.2018 IN; 16/522,367 25.07.2019 US",
WO2017223560,PCT/US2017/039274,26.06.2017,WO/2017/223560,28.12.2017,WO,TOMOGRAPHIC IMAGE RECONSTRUCTION VIA MACHINE LEARNING,"Tomographic/tomosynthetic image reconstruction systems and methods in the framework of machine learning, such as deep learning, are provided. A machine learning algorithm can be used to obtain an improved tomographic image from raw data, processed data, or a preliminarily reconstructed intermediate image for biomedical imaging or any other imaging purpose. In certain cases, a single, conventional, non-deep-learning algorithm can be used on raw imaging data to obtain an initial image, and then a deep learning algorithm can be used on the initial image to obtain a final reconstructed image. All machine learning methods and systems for tomographic image reconstruction are covered, except for use of a single shallow network (three layers or less) for image reconstruction.",G06N 3/08; G06N 3/04; G06N 99/00; A61B 6/03; A61B 5/055; A61B 5/00,RENSSELAER POLYTECHNIC INSTITUTE,"WANG, Ge; CONG, Wenxiang; YANG, Qingsong","62/354,319 24.06.2016 US",
WO2019089578,PCT/US2018/058191,30.10.2018,WO/2019/089578,09.05.2019,WO,FONT IDENTIFICATION FROM IMAGERY,A system includes a computing device that includes a memory configured to store instructions. The system also includes a processor to execute the instructions to perform operations that include receiving an image that includes textual content in at least one font. Operations also include identifying the at least one font represented in the received image using a machine learning system. The machine learning system being trained using images representing a plurality of training fonts. A portion of the training images includes text located in the foreground and being positioned over captured background imagery.,G06K 9/46; G06K 9/62; G06K 9/66; G06K 9/68; G06N 3/02,MONOTYPE IMAGING INC.,"KAASILA, Sampo Juhani; BANSAL, Jitendra Kumar; VIJAY, Anand; NATANI, Vishal; GHAI, Chiranjeev; WARIALANI, Mayur G.; DHIMAN, Prince","62/578,939 30.10.2017 US",
WO2020030913,PCT/GB2019/052222,07.08.2019,WO/2020/030913,13.02.2020,WO,METHODS AND APPARATUS FOR MANAGEMENT OF A MACHINE-LEARNING MODEL TO ADAPT TO CHANGES IN LANDSCAPE OF POTENTIALLY MALICIOUS ARTIFACTS,"In some embodiments, an apparatus includes a memory and a processor. The processor can be configured to train a machine-learning(ML)model to output an identification of whether an artifact is malicious and (2) a confidence value associated with the identification of whether the artifact is malicious. The processor can further be configured to receive a set of artifacts during a set of time periods, and provide a representation of each artifact from the set of artifacts to obtain as an output of the MLmodel including an indication of whether that artifact is malicious and a confidence value associated with the indication. The processor can be further configured to calculate a confidence metric for each time period based on the confidence value associated with each artifact, and send an indication to retrain the MLmodel based on the confidence metric for at least one time period meeting a retraining criterion.",G06N 3/04; G06N 5/00; G06N 20/20; G06N 5/04,SOPHOS LIMITED,"HARANG, Richard; DUCAU, Felipe","62/715,762 07.08.2018 US",
WO2019070978,PCT/US2018/054371,04.10.2018,WO/2019/070978,11.04.2019,WO,ECG-BASED CARDIAC EJECTION-FRACTION SCREENING,"Systems, methods, devices, and techniques for estimating an ejection-fraction characteristic of a mammal. An electrocardiogram (ECG) procedure is performed on a mammal, and a computer system obtains ECG data that describes results of the ECG over a period of time. The system provides a predictive input that is based on the ECG data to an ejection-fraction predictive model, such as a neural network or other machine-learning model. In response, the ejection-fraction predictive model processes the input to generate an estimated ejection-fraction characteristic of the mammal. The system outputs the estimated ejection-fraction characteristic of the mammal for presentation to a user.",A61B 5/0402; A61B 5/0456; G06F 19/10; G06F 19/24,MAYO FOUNDATION FOR MEDICAL EDUCATION AND RESEARCH,"ATTIA, Itzhak Zachi; FRIEDMAN, Paul A.; LOPEZ-JIMENEZ, Francisco; KAPA, Suraj","62/569,268 06.10.2017 US; 62/599,163 15.12.2017 US",
WO2017210613,PCT/US2017/035767,02.06.2017,WO/2017/210613,07.12.2017,WO,NATURAL LANGUAGE GENERATION IN A SPOKEN DIALOGUE SYSTEM,"Described herein are systems and methods for providing a natural language generator in a spoken dialogue system that considers both lexicalized and delexicalized dialogue act slot-value pairs when translating one or more dialogue act slot-value pairs into a natural language output. Each slot and value associated with the slot in a dialogue act are represented as (dialogue act + slot, value), where the first term (dialogue act + slot) is delexicalized and the second term (value) is lexicalized. Each dialogue act slot-value representation is processed to produce to produce at least one delexicalized sentence as an output. A lexicalized sentence is produced by replacing each delexicalized slot with the value associated with the delexicalized slot.",G06F 17/28,MALUUBA INC.,"SHARMA, Shikhar; HE, Jing; SULEMAN, Kaheer; BACHMAN, Philip; SCHULZ, Hannes","62/345,456 03.06.2016 US",CN-201780033548.8; EP-2017730017
WO2019200410,PCT/US2019/027565,15.04.2019,WO/2019/200410,17.10.2019,WO,MACHINE LEARNING IMPLEMENTATION FOR MULTI-ANALYTE ASSAY OF BIOLOGICAL SAMPLES,"Systems and methods that analyze blood-based cancer diagnostic tests using multiple classes of molecules are described. The system uses machine learning (ML) to analyze multiple analytes, for example cell-free DNA, cell-free microRNA, and circulating proteins, from a biological sample. The system can use multiple assays, e.g., whole-genome sequencing, whole-genome bisulfite sequencing or EM-seq, small-RNA sequencing, and quantitative immunoassay. This can increase the sensitivity and specificity of diagnostics by exploiting independent information between signals. During operation, the system receives a biological sample, and separates a plurality of molecule classes from the sample. For a plurality of assays, the system identifies feature sets to input to a machine learning model. The system performs an assay on each molecule class and forms a feature vector from the measured values. The system inputs the feature vector into the machine learning model and obtains an output classification of whether the sample has a specified property.",G06N 5/04; G06N 20/10,"FREENOME HOLDINGS, INC.","DRAKE, Adam; DELUBAC, Daniel; NIEHAUS, Katherine; ARIAZI, Eric; HAQUE, Imran; LIU, Tzu-Yu; WAN, Nathan; KANNAN, Ajay; WHITE, Brandon","62/657,602 13.04.2018 US; 62/679,587 01.06.2018 US; 62/679,641 01.06.2018 US; 62/731,557 14.09.2018 US; 62/742,799 08.10.2018 US; 62/749,955 24.10.2018 US; 62/767,435 14.11.2018 US; 62/767,369 14.11.2018 US; 62/804,614 12.02.2019 US; 62/824,709 27.03.2019 US",
WO2018063460,PCT/US2017/038504,21.06.2017,WO/2018/063460,05.04.2018,WO,SYSTEM AND METHOD FOR OPTIMIZATION OF DEEP LEARNING ARCHITECTURE,"A method for determining optimized deep learning architecture includes receiving a plurality of training images and a plurality of real time images corresponding to a subject. The method further includes receiving, by a medical practitioner, a plurality of learning parameters comprising a plurality of filter classes and a plurality of architecture parameters. The method also includes determining a deep learning model based on the plurality of learning parameters and the plurality of training images, wherein the deep learning model comprises a plurality of reusable filters. The method further includes determining a health condition of the subject based on the plurality of real time images and the deep learning model. The method also includes providing the health condition of the subject to the medical practitioner.",G06N 3/04; G06K 9/46,GENERAL ELECTRIC COMPANY,"THIRUVENKADAM, Sheshadri; RANJAN, Sohan Rashmi; VAIDYA, Vivek Prabhakar; RAVISHANKAR, Hariharan; VENKATARAMANI, Rahul; SUDHAKAR, Prasad",201641033618 30.09.2016 IN,
WO2019055848,PCT/US2018/051175,14.09.2018,WO/2019/055848,21.03.2019,WO,MACHINE LEARNING METHODS AND APPARATUS FOR ROBOTIC MANIPULATION AND THAT UTILIZE MULTI-TASK DOMAIN ADAPTATION,"Training a machine learning model that, once trained, is used in performance of robotic grasping and/or other manipulation task(s) by a robot. The model can be trained using simulated training examples that are based on simulated data that is based on simulated robot(s) attempting simulated manipulations of various simulated objects. At least portions of the model can also be trained based on real training examples that are based on data from real-world physical robots attempting manipulations of various objects. The simulated training examples can be utilized to train the model to predict an output that can be utilized in a particular task – and the real training examples used to adapt at least a portion of the model to the real-world domain can be tailored to a distinct task. In some implementations, domain-adversarial similarity losses are determined during training, and utilized to regularize at least portion(s) of the model.",B25J 9/16,X DEVELOPMENT LLC,"BAI, Yunfei; FANG, Kuan; HINTERSTOISSER, Stefan; KALAKRISHNAN, Mrinal","62/559,279 15.09.2017 US; 15/913,212 06.03.2018 US",EP-2018779999
WO2018112137,PCT/US2017/066292,14.12.2017,WO/2018/112137,21.06.2018,WO,SYSTEM AND METHOD FOR IMAGE SEGMENTATION USING A JOINT DEEP LEARNING MODEL,"A method for image segmentation includes receiving an input image (102). The method further includes obtaining a deep learning model (104) having a triad of predictors (116, 118, 120). Furthermore, the method includes processing the input image by a shape model in the triad of predictors (116, 118, 120) to generate a segmented shape image (110). Moreover, the method includes presenting the segmented shape image via a display unit (128).",G06T 7/10; G06F 15/18,GENERAL ELECTRIC COMPANY,"RAVISHANKAR, Hariharan; VAIDYA, Vivek Prabhakar; THIRUVENKADAM, Sheshadri; VENKATARAMANI, Rahul; SUDHAKAR, Prasad",201641042796 15.12.2016 IN; 201641042796 14.12.2017 IN; 201741044976 14.12.2017 IN,EP-2017826368; CN-201780074980.1
WO2019226270,PCT/US2019/029006,24.04.2019,WO/2019/226270,28.11.2019,WO,MULTI-SAMPLE WHOLE SLIDE IMAGE PROCESSING VIA MULTI-RESOLUTION REGISTRATION,"When reviewing digital pathology tissue specimens, multiple slides may be created from thin, sequential slices of tissue. These slices may then be prepared with various stains and digitized to generate a Whole Slide Image (WSI). Review of multiple WSIs is challenging because of the lack of homogeneity across the images. In embodiments, to facilitate review, WSIs are aligned with a multi -resolution registration algorithm, normalized for improved processing, annotated by an expert user, and divided into image patches. The image patches may be used to train a Machine Learning model to identify features useful for detection and classification of regions of interest (ROIs) in images. The trained model may be applied to other images to detect and classify ROIs in the other images, which can aid in navigating the WSIs. When the resulting ROIs are presented to the user, the user may easily navigate and provide feedback through a display layer.",G06T 7/00; G06K 9/00,"CORISTA, LLC","WIRCH, Eric, W.; ANDRYUSHKIN, Alexander; WINGARD, Richard, Y.II; LEE, Nigel; SCOURTAS, Aristana, Olivia; WILBUR, David, C.","62/674,368 21.05.2018 US",
WO2018089289,PCT/US2017/060104,06.11.2017,WO/2018/089289,17.05.2018,WO,SIAMESE RECONSTRUCTION CONVOLUTIONAL NEURAL NETWORK FOR POSE-INVARIANT FACE RECOGNITION,"A computer-implemented method, system, and computer program product is provided for pose-invariant facial recognition. The method includes generating, by a processor using a recognition neural network (150), a rich feature embedding for identity information and non-identity information for each of one or more images. The method also includes generating, by the processor using a Siamese reconstruction network (160), one or more pose-invariant features (170) by employing the rich feature embedding for identity information and non-identity information. The method additionally includes identifying, by the processor, a user (180) by employing the one or more pose-invariant features. The method further includes controlling an operation of a processor-based machine to change a state of the processor-based machine, responsive to the identified user in the one or more images.",G06K 9/00; G06K 9/62; G06N 3/02,"NEC LABORATORIES AMERICA, INC","XU, Xiang; SOHN, Kihyuk; CHANDRAKER, Manmohan; PENG, Xi","62/418,892 08.11.2016 US; 62/421,430 14.11.2016 US; 15/803,292 03.11.2017 US; 15/803,318 03.11.2017 US",
WO2019165475,PCT/US2019/019687,26.02.2019,WO/2019/165475,29.08.2019,WO,SYSTEMS AND METHODS FOR QUANTIFYING MULTISCALE COMPETITIVE LANDSCAPES OF CLONAL DIVERSITY IN GLIOBLASTOMA,"Methods that implement image-guided tissue analysis, MRI-based computational modeling, and imaging informatics to analyze the diversity and dynamics of molecularly - distinct subpopulations and the evolving competitive landscapes in human glioblastoma multiforme (""GBM"") are provided. Machine learning models are constructed based on multiparametric MRI data and molecular data (e.g., CNV, exome, gene expression). Models can also be built based on specific biological factors, such as sex and age. Inputting MRI data into the trained predictive models generates maps that depict spatial patterns of molecular markers, which can be used to quantify and co-localize regions molecularly distinct subpopulations in tumors and other regions, such as the non-enhancing parenchyma, or brain around tumor (""BAT"") regions.",A61B 5/055; G06N 3/08; G06T 7/11; G06K 9/62,MAYO FOUNDATION FOR MEDICAL EDUCATION AND RESEARCH,"HU, Leland, S.; SWANSON, Kristin, R.; MITCHELL, J., Ross; TRAN, Nhan, L.","62/635,276 26.02.2018 US",
WO2017106645,PCT/US2016/067170,16.12.2016,WO/2017/106645,22.06.2017,WO,INTERPRETATION AND QUANTIFICATION OF EMERGENCY FEATURES ON HEAD COMPUTED TOMOGRAPHY,"A computer-based method for quantitative evaluation of computed tomography (CT) images of the head, particularly in circumstances of neurological emergency such as acute intracranial hemorrhage, evidence of intracranial mass effect, and acute stroke. The method comprises: calculation of volumes of abnormal areas such as locations of hemorrhage; quantification of severity of midline shift and basilar cistern effacement; and rapid identification of anatomical locations of abnormal findings. The methods comprise use of heuristics, convolutional neural networks, deep learning, edge detection, and Hough transform.",G06K 9/00,THE REGENTS OF THE UNIVERSITY OF CALIFORNIA,"YUH, Esther L.; MUKHERJEE, Pratik; MANLEY, Geoffrey T.","62/269,778 18.12.2015 US",US-15782005; EP-2016876771; JP-2018531110
WO2019147767,PCT/US2019/014895,24.01.2019,WO/2019/147767,01.08.2019,WO,3-D CONVOLUTIONAL AUTOENCODER FOR LOW-DOSE CT VIA TRANSFER LEARNING FROM A 2-D TRAINED NETWORK,"A 3-D convolutional autoencoder for low-dose CT via transfer learning from a 2-D trained network is described, A machine learning method for low dose computed tomography (LDCT) image correction is provided. The method includes training, by a training circuitry, a neural network (NN) based, at least in part, on two-dimensional (2-D) training data. The 2-D training data includes a plurality of 2-D training image pairs. Each 2-D image pair includes one training input image and one corresponding target output image. The training includes adjusting at least one of a plurality of 2-D weights based, at least in part, on an objective function. The method further includes refining, by the training circuitry, the NN based, at least in part, on three-dimensional (3-D) training data. The 3-D training data includes a plurality of 3-D training image pairs. Each 3-D training image pair includes a plurality of adjacent 2-D training input images and at least one corresponding target output image. The refining includes adjusting at least one of a plurality of 3-D weights based, at least in part, on the plurality of 2-D weights and based, at least in part, on the objective function. The plurality of 2-D weights includes the at least one adj usted 2-D weight.",A61B 6/00; A61B 6/03; G06K 9/66; G06T 3/40; G06T 5/00; G06T 5/50,RENSSELAER POLYTECHNIC INSTITUTE,"WANG, Ge; SHAN, Hongming; CONG, Wenxiang","62/621,114 24.01.2018 US; 62/795,829 23.01.2019 US",
WO2019245916,PCT/US2019/037294,14.06.2019,WO/2019/245916,26.12.2019,WO,METHOD AND SYSTEM FOR PARAMETRIC SPEECH SYNTHESIS,"Embodiments of the present systems and methods may provide techniques for synthesizing speech in any voice in any language in any accent. For example, in an embodiment, a text-to-speech conversion system may comprise a text converter adapted to convert input text to at least one phoneme selected from a plurality of phonemes stored in memory, a machine-learning model storing voice patterns for a plurality of individuals and adapted to receive the at least one phoneme and an identity of a speaker and to generate acoustic features for each phoneme, and a decoder adapted to receive the generated acoustic features and to generate a speech signal simulating a voice of the identified speaker in a language.",G10L 13/08; G10L 13/033; G10L 15/02; G10L 25/30,GEORGETOWN UNIVERSITY,"GARMAN, Joe; FRIEDER, Ophir","62/686,838 19.06.2018 US; 62/822,258 22.03.2019 US",
EP278936911,18823086,26.06.2018,3579227,11.12.2019,EP,VOICE WAKE-UP METHOD AND DEVICE AND ELECTRONIC DEVICE,"A voice wake-up method and device, and an electronic device are provided. The voice wake-up method comprises: using a voice wake-up model comprising a deep neural network and a connectionist time classifier to implement voice wake-up, wherein the voice wake-up model can be obtained by training with general voice data.",G10L 15/06; G10L 15/08; G10L 15/16,ALIBABA GROUP HOLDING LTD,WANG ZHIMING; ZHOU JUN; LI XIAOLONG,201710514348 29.06.2017 CN; 2018092899 26.06.2018 CN,
WO2018125014,PCT/TR2017/050699,26.12.2017,WO/2018/125014,05.07.2018,WO,A METHOD FOR FOREIGN OBJECT DEBRIS DETECTION,"This invention discloses a system and method for detection of foreign object debris (FOD) on the areas of including but not limited to the airport runways, taxiways, aprons and adjacent areas. The invention makes use of single or multiple passive optical sensors monitoring the areas for signal acquisition, a database and a processing unit to further analyze the captured optical signal in order to detect the presence; and in case of the detection of the foreign debris in various threat levels, creating an alert for the removal thereof; depending on variables such as the estimated area and foreign object size and visual characteristics.",G06T 7/00; G06K 9/00,ARGOSAI TEKNOLOJI ANONIM SIRKETI,"TASLI, Huseyin Emrah; KARADENIZ, Merih Alphan; KOSE, Aziz",16206900.9 26.12.2016 EP,EP-2017887681
WO2018034740,PCT/US2017/040680,05.07.2017,WO/2018/034740,22.02.2018,WO,BABY DETECTION FOR ELECTRONIC-GATE ENVIRONMENTS,A baby detection system and a mass transit surveillance system are provided. The baby detection system includes a camera (110) configured to capture an input image of a subject purported to be a baby and presented at an electronic-gate system. The baby detection system further includes a memory (122) storing a deep learning model configured to perform a baby detection task for an electronic-gate application corresponding to the electronic-gate system. The baby detection system also includes a processor (121) configured to apply the deep learning model to the input image to provide a baby detection result of either a presence or an absence of an actual baby in relation to the subject purported to be the baby. The baby detection task is configured to evaluate one or more different distractor modalities corresponding to one or more different physical spoofing materials to prevent baby spoofing for the baby detection task.,G06K 9/20; G06N 3/08,"NEC LABORATORIES AMERICA, INC.; NEC HONG KONG LIMITED","CHANDRAKER, Manmohan; CHOI, Wongun; LAU, Eric; WONG, Elsa; CHEN, Guobin","62/374,981 15.08.2016 US; 15/637,433 29.06.2017 US; 15/637,360 29.06.2017 US; 15/637,533 29.06.2017 US",JP-2019507790; DE-112017004095; SG-11201811187V
WO2019226686,PCT/US2019/033373,21.05.2019,WO/2019/226686,28.11.2019,WO,DEEP LEARNING SYSTEM,"A machine learning system is provided to enhance various aspects of machine learning models. In some aspects, a substantially photorealistic three-dimensional (3D) graphical model of an object is accessed and a set of training images of the 3D graphical mode are generated, the set of training images generated to add imperfections and degrade photorealistic quality of the training images. The set of training images are provided as training data to train an artificial neural network.",G06N 3/08; G06N 20/00; G06T 17/10; G06T 19/00,MOVIDIUS LTD.,"MOLONEY, David Macdara; BUCKLEY, Léonie Raideen; RODRIGUEZ MARTÍN DE LA SIERRA, Luis M.; MÁRQUEZ RODRÍGUEZ-PERAL, Carlos; BRICK, Cormac M.; BYRNE, Jonathan David; XU, Xiaofan; PEÑA CARRILLO, Dexmont Alejandro; PARK, Mi Sun; PALLA, Alessandro","62/675,601 23.05.2018 US",
WO2019009897,PCT/US2017/040798,06.07.2017,WO/2019/009897,10.01.2019,WO,SYSTEMS AND METHODS FOR COMPRESSION AND DISTRIBUTION OF MACHINE LEARNING MODELS,"The present disclosure provides systems and methods for compressing and/or distributing machine learning models. In one example, a computer-implemented method is provided to compress machine-learned models, which includes obtaining, by one or more computing devices, a machine-learned model. The method includes selecting, by the one or more computing devices, a weight to be quantized and quantizing, by the one or more computing devices, the weight. The method includes propagating, by the one or more computing devices, at least a part of a quantization error to one or more non-quantized weights and quantizing, by the one or more computing devices, one or more of the non-quantized weights. The method includes providing, by the one or more computing devices, a quantized machine-learned model.",G06N 3/063; G06F 7/483; G06N 3/04; G06N 3/08,GOOGLE LLC,"ALAKUIJALA, Jyrki; OBRYK, Robert",,CN-201780092778.1; EP-2017745218
WO2020008365,PCT/IB2019/055643,02.07.2019,WO/2020/008365,09.01.2020,WO,TRANSFERRING LEARNING IN CLASSIFIER-BASED SENSING SYSTEMS,"Systems and methods for transferring learning in sensor devices. Historical time-series measurement samples of one or more parameters associated with a biological function being monitored by the sensor device are received and assigned to clusters. Feature data extracted from the historical time-series measurement samples are used to generate cluster-specific source-domain classifiers for each cluster. Unlabeled time-series measurement samples of the one or more parameters associated with the biological function are received. A cluster-identifier is assigned to each unlabeled target-domain sample, the cluster-identifier including information identifying a cluster-specific source-domain classifier associated with the unlabeled target-domain sample. Labeled time-series measurement samples of the one or more parameters associated with the biological function are received, feature data is extracted from the labeled samples and cluster-specific target-domain classifiers are generated for each cluster based on the source-domain classifiers and the feature data extracted from the labeled samples.",G06F 15/18; G06N 5/04,3M INNOVATIVE PROPERTIES COMPANY,"KADKHODAIE ELYADERANI, Mojtaba; GOLNARI, Golshan; TAGHVAEEYAN, Saber; SHANNON, Robert W.; BARTON, Roger W.; PACHAURI, Deepti","62/693,374 02.07.2018 US",
EP224637559,18154195,30.01.2018,3361421,15.08.2018,EP,HIERARCHICAL LEARNING OF WEIGHTS OF A NEURAL NETWORK FOR PERFORMING MULTIPLE ANALYSES,Systems and methods are provided for performing medical imaging analysis. Input medical imaging data is received for performing a particular one of a plurality of medical imaging analyses. An output that provides a result of the particular medical imaging analysis on the input medical imaging data is generated using a neural network trained to perform the plurality of medical imaging analyses. The neural network is trained by learning one or more weights associated with the particular medical imaging analysis using one or more weights associated with a different one of the plurality of medical imaging analyses. The generated output is outputted for performing the particular medical imaging analysis.,G06N 3/04,SIEMENS HEALTHCARE GMBH,ZHOU SHAOHUA KEVIN; CHEN MINGQING; XU DAGUANG; XU ZHOUBING; MIAO SHUN; YANG DONG; ZHANG HE,201762456368 08.02.2017 US; 201815865581 09.01.2018 US,
WO2019152020,PCT/US2018/016238,31.01.2018,WO/2019/152020,08.08.2019,WO,QUANTUM COMPUTATION THROUGH REINFORCEMENT LEARNING,"Methods, systems, and apparatus for designing a quantum control trajectory for implementing a quantum gate using quantum hardware. In one aspect, a method includes the actions of representing the quantum gate as a sequence of control actions and applying a reinforcement learning model to iteratively adjust each control action in the sequence of control actions to determine a quantum control trajectory that implements the quantum gate and reduces leakage, infidelity and total runtime of the quantum gate to improve its robustness of performance against control noise during the iterative adjustments.",G06N 99/00; G06N 3/00; G06N 3/04; G06N 3/08,"GOOGLE, LLC","NIU, Yuezhen; NEVEN, Hartmut; SMELYANSKIY, Vadim; CASTRILLO, Sergio Boixo",,
WO2018232388,PCT/US2018/038040,18.06.2018,WO/2018/232388,20.12.2018,WO,SYSTEMS AND METHODS FOR INTEGRATING TOMOGRAPHIC IMAGE RECONSTRUCTION AND RADIOMICS USING NEURAL NETWORKS,"Computed tomography (CT) screening, diagnosis, or another image analysis tasks are performed using one or more networks and/or algorithms to either integrate complementary tomographic image reconstructions and radiomics or map tomographic raw data directly to diagnostic findings in the machine learning framework. One or more reconstruction networks are trained to reconstruct tomographic images from a training set of CT projection data. One or more radiomics networks are trained to extract features from the tomographic images and associated training diagnostic data. The networks/algorithms are integrated into an end-to-end network and trained. A set of tomographic data, e.g., CT projection data, and other relevant information from an individual is input to the end-to-end network, and a potential diagnosis for the individual based on the features extracted by the end-to-end network is produced. The systems and methods can be applied to CT projection data, MRI data, nuclear imaging data, ultrasound signals, optical data, other types of tomographic data, or combinations thereof.",A61B 5/055; A61B 6/02; A61B 6/03; A61B 8/13; G06K 9/46; G06T 7/11,RENSSELAER POLYTECHNIC INSTITUTE,"WANG, Ge; KALRA, Mannudeep; HAHN, Juergen; KRUGER, Uwe; CONG, Wenxiang; SHAN, Hongming","62/520,682 16.06.2017 US",KR-1020207001590; EP-2018817973
WO2018001702,PCT/EP2017/064174,09.06.2017,WO/2018/001702,04.01.2018,WO,MACHINE LEARNING-BASED QUANTITATIVE PHOTOACOUSTIC TOMOGRAPHY (PAT),"A method for estimating an optical property of a tissue (10) from a photoacoustic image (20) of the tissue (10) or parts thereof (12) using a machine learning algorithm, wherein the photoacoustic image (20) is obtained with a photoacoustic setup (30) and wherein the machine learning algorithm is configured to infer the optical property at least at one domain of the photoacoustic image (20) by means of a descriptor for said at least one domain, wherein at least part of the photoacoustic image (20) is partitioned in a plurality of domains (22) with respect to at least one parameter, wherein the at least one parameter corresponds to a physical property of the tissue (10), and wherein the variation of the at least one parameter within each domain is limited to a pre-determined value, such that each domain corresponds to a limited range of said physical property of the tissue (10), and a descriptor is determined for each of said at least one domain, wherein the descriptor for a given domain (V) comprises information related to the photoacoustic image (20) for each contributing domain (v11,...,v33) of a set of contributing domains (Cv), wherein the set of contributing domains (Cv) comprises one or more domains other than said given domain (V).",G06K 9/00,DEUTSCHES KREBSFORSCHUNGSZENTRUM STIFTUNG DES ÖFFENTLICHEN RECHTS,"MAIER-HEIN, Lena; KIRCHNER, Thomas; GRÖHL, Janek",16177204.1 30.06.2016 EP,EP-2017728230
WO2019126880,PCT/CA2018/051681,28.12.2018,WO/2019/126880,04.07.2019,WO,A LOW-POWER KEYWORD SPOTTING SYSTEM,A system and method of performing low-power keyword detection is provided. An acoustic signal is obtained comprising speech by an electronic device. The acoustic signal is preprocessed by transforming the acoustic signal to a frequency domain representation. The frequency domain representation is divided into a plurality of frequency bands. The plurality of frequency bands is provided to a neural network. At least one of a plurality of keywords or absence of any of the plurality of keywords is predicted. The acoustic signal can then be provided for additional processing by a higher power processing core.,G10L 15/02; G06N 3/02; G10L 15/05,FLUENT.AI INC.,"MYER, Sam; TOMAR, Vikrant","62/611,794 29.12.2017 US",
WO2017101036,PCT/CN2015/097534,16.12.2015,WO/2017/101036,22.06.2017,WO,FULLY CONVOLUTIONAL PYRAMID NETWORKS FOR PEDESTRIAN DETECTION,"A fully convolutional pyramid network and method for object (e.g., pedestrian) detection are disclosed. The object detection system is a pedestrian detection system that comprises: a multi-scale image generator (112) to generate a set of images from an input image, the set of images being versions of the input image at different scales; a pedestrian-specific fully convolutional network (FCN) model (113) operable to generate a set of detection results for each image in the set of images that is indicative of objects that are potentially pedestrians; and a post processor (114) to combine sets of detection results generated by the FCN model (113) for the set of images into an output image with each object location determined as potentially being a pedestrian being marked.",G06K 9/62,INTEL CORPORATION,"YAO, Anbang; WANG, Ruoyan; CHEN, Yurong",,US-15300490; EP-2015910509
WO2019175571,PCT/GB2019/050693,12.03.2019,WO/2019/175571,19.09.2019,WO,COMBINED METHODS AND SYSTEMS FOR ONLINE MEDIA CONTENT,"The present invention relates to a series of methods and systems in respect of online media content. More specifically, the present invention relates to aspects of fact checking of online media content.",G06F 16/35; G06Q 50/00; G06F 17/27; G06K 9/62; G06F 21/10; G06F 16/9535,FACTMATA LIMITED,"GHULATI, Dhruv; WASEEM, Zeerak; SHUKLA, Rishabh; PISAREVSKAYA, Dina; VINCENT, Emmanuel; ROBBINS, Martin","1803954.5 12.03.2018 GB; 1804295.2 16.03.2018 GB; 1804297.8 16.03.2018 GB; 1804532.8 21.03.2018 GB; 1804528.6 21.03.2018 GB; 1804529.4 21.03.2018 GB; 1804828.0 26.03.2018 GB; 62/654,699 09.04.2018 US; 62/654,908 09.04.2018 US; 62/654,968 09.04.2018 US; 62/654,700 09.04.2018 US; 62/655,053 09.04.2018 US; 62/654,901 09.04.2018 US; 62/654,947 09.04.2018 US; 1810079.2 19.06.2018 GB",
WO2020014477,PCT/US2019/041395,11.07.2019,WO/2020/014477,16.01.2020,WO,"METHODS, SYSTEMS, AND COMPUTER READABLE MEDIA FOR IMAGE ANALYSIS WITH DEEP LEARNING TO PREDICT BREAST CANCER CLASSES","A method for image analysis using deep learning to predict breast cancer classes, includes receiving a test image. The method further includes generating test image instances from the test image. The method further includes inputting the test image instances into a convolutional neural network (CNN), which extracts features from each of the test image instances. The method further includes applying an instance support vector machine (SVM) to the features to predict breast cancer classes for each of the instances. The method further includes aggregating outputs from the instance SVM to predict breast cancer classes for the test image.",G16H 50/70; G16H 50/20; G16H 30/40; A61B 5/00,THE UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL; CITY OF HOPE,"PEROU, Charles, Maurice; COUTURE, Heather Dunlop; WILLIAMS, Lindsay Almquist; NYANTE, Sarah; MARRON, James Stephen; TROESTER, Melissa; NIETHAMMER, Marc; GERADTS, Joseph; BUTLER, Ebonee","62/696,464 11.07.2018 US; 62/757,746 08.11.2018 US",
WO2019060208,PCT/US2018/050946,13.09.2018,WO/2019/060208,28.03.2019,WO,AUTOMATICALLY ANALYZING MEDIA USING MACHINE LEARNING ANALYSIS,"A stream of media eligible to be automatically shared is received. Using a machine learning model trained using engagement information regarding one or more previously shared media, a media included in the stream of media is analyzed to output an engagement analysis. Based on the engagement analysis, a determination is made on whether the media included in the stream of media is desirable to be automatically shared. The media is automatically shared in an event it is determined that the media included in the stream of media is desirable to be automatically shared. A media and a context information associated with the media are received. A first machine learning model and a second machine learning model are trained using different machine learning training data sets. Using the first machine learning model, the media is analyzed to determine a classification result. Using the second machine learning model, the classification result and the context information are analyzed to determine whether the media is likely not desirable to share. In an event the media is not identified as not desirable to share, the media is automatically shared.",G06F 15/18,"GET ATTACHED, INC.","AZOUT, Albert; IMBRUCE, Douglas; PAPE, Gregory, T.","15/714,741 25.09.2017 US; 15/714,737 25.09.2017 US",
WO2018085577,PCT/US2017/059776,02.11.2017,WO/2018/085577,11.05.2018,WO,IMPLICIT BRIDGING OF MACHINE LEARNING TASKS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media for performing machine learning tasks. One method includes receiving (i) a model input, and (ii) data identifying a first machine learning task to be performed on the model input to generate a first type of model output for the model input; augmenting the model input with an identifier for the first machine learning task to generate an augmented model input; and processing the augmented model input using a machine learning model. An exemplary system applying implicit bridging for machine learning tasks, as described in this specification, trains a machine learning model to perform certain types of machine learning tasks without requiring that explicit training data for the certain types of machine learning tasks to be used during training.",G06N 3/04; G06F 17/28; G06N 3/063,GOOGLE LLC,"CHEN, Zhifeng; SCHUSTER, Michael; JOHNSON PREMKUMAR, Melvin Jose; WU, Yonghui; LE, Quoc V.; KRIKUN, Maxim; BRANTS, Thorsten","62/418,098 04.11.2016 US; 15/394,708 29.12.2016 US",KR-1020197015572; EP-2017800671; JP-2019522923; CN-201780068195.5
WO2018142266,PCT/IB2018/050533,29.01.2018,WO/2018/142266,09.08.2018,WO,INFORMATION EXTRACTION FROM DOCUMENTS,"There is provided a method including sending a first document to a GUI, and receiving at a classification and extraction engine (CEE) from the GUI an input indicating first document data for the first document. The input forms a portion of a dataset. A prediction is generated at the CEE of second document data for a second document using a machine learning model (MLM) configured to receive an input and generate a predicted output. The MLM is trained using the dataset, the input includes one or more tokens corresponding to the second document. The output includes the prediction of the second document data. The prediction is sent to the GUI, and feedback on the prediction is received at the CEE from the GUI, to form a reviewed prediction. The reviewed prediction is added to the dataset to form an enlarged dataset, and the MLM is trained using the enlarged dataset.",G06F 17/00; G06F 15/18; G06F 17/20,MOCSY INC.,"LI, Jasper","62/452,736 31.01.2017 US",CA-3052113; EP-2018748692
WO2019178561,PCT/US2019/022611,15.03.2019,WO/2019/178561,19.09.2019,WO,"USING MACHINE LEARNING AND/OR NEURAL NETWORKS TO VALIDATE STEM CELLS AND THEIR DERIVATIVES FOR USE IN CELL THERAPY, DRUG DISCOVERY, AND DIAGNOSTICS","A method is provided for non-invasively predicting characteristics of one or more cells and cell derivatives. The method includes training a machine learning model using at least one of a plurality of training cell images representing a plurality of cells and data identifying characteristics for the plurality of cells. The method further includes receiving at least one test cell image representing at least one test cell being evaluated, the at least one test cell image being acquired non-invasively and based on absorbance as an absolute measure of light, and providing the at least one test cell image to the trained machine learning model. Using machine learning based on the trained machine learning model, characteristics of the at least one test cell are predicted. The method further includes generating, by the trained machine learning model, release criteria for clinical preparations of cells based on the predicted characteristics of the at least one test cell.",G06K 9/00,"THE UNITED STATES OF AMERICA, as represented by THE SECRETARY, DEPARTMENT OF HEALTH & HUMAN SERVICES","BHARTI, Kapil; HOTALING, Nathan, A.; SCHAUB, Nicholas, J.; SIMON, Carl, G.","62/644,175 16.03.2018 US",
WO2017200597,PCT/US2016/069589,30.12.2016,WO/2017/200597,23.11.2017,WO,PROGRESSIVE NEURAL NETWORKS,"Methods and systems for performing a sequence of machine learning tasks. One system includes a sequence of deep neural networks (DNNs), including: a first DNN corresponding to a first machine learning task, wherein the first DNN comprises a first plurality of indexed layers, and each layer in the first plurality of indexed layers is configured to receive a respective layer input and process the layer input to generate a respective layer output; and one or more subsequent DNNs corresponding to one or more respective machine learning tasks, wherein each subsequent DNN comprises a respective plurality of indexed layers, and each layer in a respective plurality of indexed layers with index greater than one receives input from a preceding layer of the respective subsequent DNN, and one or more preceding layers of respective preceding DNNs, wherein a preceding layer is a layer whose index is one less than the current index.",G06N 3/04,DEEPMIND TECHNOLOGIES LIMITED,"RABINOWITZ, Neil Charles; DESJARDINS, Guillaume; RUSU, Andrei-Alexandru; KAVUKCUOGLU, Koray; HADSELL, Raia Thais; PASCANU, Razvan; KIRKPATRICK, James; SOYER, Hubert Josef","62/339,719 20.05.2016 US",EP-2016826910; CN-201680085917.3
EP233540600,17171020,15.05.2017,3404497,21.11.2018,EP,A METHOD AND SYSTEM FOR PROVIDING AN OPTIMIZED CONTROL OF A COMPLEX DYNAMICAL SYSTEM,"A method for performing an optimized control of a complex dynamical system (sys) using machine learned, scenario based control heuristics, the method comprising the steps of: 
providing (S1) a simulation model (f) for predicting a system state vector (x) of said dynamical system (sys) in time based on a current scenario parameter vector (p) and a control vector (u); using (S2) a Model Predictive Control, MPC, algorithm to provide the control vector (u) at every time during a simulation of said dynamical system (sys) using said simulation model (f) for different scenario parameter vectors (p0, p1, p2, ..) and initial system state vectors (x00, x01, x02, ..); calculating (S3) for every simulated combination of a scenario parameter vector (p) and initial system state vector (x 0 ) a resulting optimal control value (u* (p, x 0 )) by the MPC algorithm and saving the resulting optimal control value; generating (S4) machine learned control heuristics (u a(p, x 0 )) approximating the relationship between the corresponding scenario parameter vector (p) and the initial system state vector (x 0 ) for the saved resulting optimal control value (u* (p, x 0 )) using a machine learning algorithm; and using the generated machine learned control heuristics to control (S5) the complex dynamical system (sys) modelled by said simulation model (f).",G05B 13/02; G05B 13/04,SIEMENS AG,HARTMANN DIRK; OBST BIRGIT; WANNERBERG ERIK OLOF JOHANNES,17171020 15.05.2017 EP,
WO2018141061,PCT/CA2018/050116,01.02.2018,WO/2018/141061,09.08.2018,WO,SYSTEM AND METHOD FOR MEASURING PERCEPTUAL EXPERIENCES,"There is provided a method for determining perceptual experiences. The method comprises obtaining a plurality of signals acquired by a measurement device comprising a plurality of sensors positioned to measure brain activity of users being measured by the measurement device; providing the plurality of signals, without pre-processing, to a processing system comprising at least one deep learning module, the at least one deep learning module being configured to process the signals to generate at least one capability, wherein combinations of one or more of the at least one capability form the perceptual experiences; and providing an output corresponding to a combination of one or more of the at least one capability to an application utilizing the corresponding perceptual experience.",A61B 5/16; A61B 5/0476; G06F 15/18; G06F 3/01; G06N 3/02; G06N 3/08; G16H 50/20,CEREBIAN INC.,"AYYAD, Karim","62/453,022 01.02.2017 US",EP-2018747760; CN-201880023688.1
WO2019236955,PCT/US2019/035975,07.06.2019,WO/2019/236955,12.12.2019,WO,A METHOD FOR GENERATING PREDICTED ULTRASONIC MEASUREMENTS FROM SONIC DATA,"A method, computer program product, and computing system are provided for receiving sonic data associated with an inner casing of a well. Predicted ultrasonic data associated with an outer casing of the well may be generated based upon, at least in part, a nonlinear regression model and the received sonic data associated with the inner casing of the well.",E21B 41/00; G01V 1/50,SCHLUMBERGER TECHNOLOGY CORPORATION; SCHLUMBERGER CANADA LIMITED; SERVICES PETROLIERS SCHLUMBERGER; GEOQUEST SYSTEMS B.V.,"ZHU, Lingchen; BOSE, Sandip; ZEROUG, Smaine","62/682,327 08.06.2018 US",
WO2019152929,PCT/US2019/016515,04.02.2019,WO/2019/152929,08.08.2019,WO,REGULARIZED NEURAL NETWORK ARCHITECTURE SEARCH,"A method for receiving training data for training a neural network (NN) to perform a machine learning (ML) task and for determining, using the training data, an optimized NN architecture for performing the ML task is described. Determining the optimized NN architecture includes: maintaining population data comprising, for each candidate architecture in a population of candidate architectures, (i) data defining the candidate architecture, and (ii) data specifying how recently a neural network having the candidate architecture has been trained while determining the optimized neural network architecture; and repeatedly performing multiple operations using each of a plurality of worker computing units to generate a new candidate architecture based on a selected candidate architecture having the best measure of fitness, adding the new candidate architecture to the population, and removing from the population the candidate architecture that was trained least recently.",G06N 3/08,GOOGLE LLC,"HUANG, Yanping; AGGARWAL, Alok; LE, Quoc V.; REAL, Esteban Alberto","62/625,923 02.02.2018 US",
WO2019222289,PCT/US2019/032313,14.05.2019,WO/2019/222289,21.11.2019,WO,A GENERALIZABLE AND INTERPRETABLE DEEP LEARNING FRAMEWORK FOR PREDICTING MSI FROM HISTOPATHOLOGY SLIDE IMAGES,"A generalizable and interpretable deep learning model for predicting microsatellite instability from histopathology slide images is provided. Microsatellite instability (MSI) is an important genomic phenotype that can direct clinical treatment decisions, especially in the context of cancer immunotherapies. A deep learning framework is provided to predict MSI from histopathology images, to improve the generalizability of the predictive model using adversarial training to new domains, such as on new data sources or tumor types, and to provide techniques to visually interpret the topological and morphological features that influence the MSI predictions.",G06T 7/00; G06N 3/08; G06N 20/10,"TEMPUS LABS, INC.","KHAN, Aly, Azeem","62/671,300 14.05.2018 US",
WO2019154944,PCT/EP2019/053066,07.02.2019,WO/2019/154944,15.08.2019,WO,DISTRIBUTED MACHINE LEARNING SYSTEM,"There is provided a computer-implemented method of determining policy parameters for multiple reinforcement learning tasks. The policy parameters for each task depend on a common set of parameters shared by the tasks and a task-specific set of parameters. The method includes each of a plurality of processors receiving trajectory data from a subset of the tasks, and determining a local version of the common set of parameters as well as the task-specific set of parameters for each task in the subset. Determining the local version includes iteratively determining partial input data and taking part in a distributed computation with the other processors to determine, using the partial input data, a first set of intermediate variables. The method then includes updating the local version of the common set of parameters using a subset of the first set of intermediate variables. The local versions of the common set of parameters converge.",G06N 3/00; G06N 7/00; G06N 99/00; G06N 20/00,PROWLER.IO LIMITED,"BOU-AMMAR, Haitham; TUTUNOV, Rasul; KIM, Dongho; TOMCZAK, Marcin",18275016.6 08.02.2018 EP,
EP241675045,17199028,27.10.2017,3477616,01.05.2019,EP,METHOD FOR CONTROLLING A VEHICLE USING A MACHINE LEARNING SYSTEM,"The present invention relates to a method for controlling a vehicle, particularly an autonomous vehicle. Particularly, the present invention relates to the use of a machine learning system, such as a deep neural network (DNN) to predict environmental parameters that are used to control and safely drive the ego vehicle. Also provided is a vehicle using the method of the invention to control the vehicle and a method for training a machine learning system.",G08G 1/16; G05D 1/02; G06K 9/00,SIGRA TECH GMBH,MANSOUR KARIM; GRABAR SIMON; CHOPRA SWAGAT,17199028 27.10.2017 EP,
WO2019216938,PCT/US2018/047249,21.08.2018,WO/2019/216938,14.11.2019,WO,APPLICATION DEVELOPMENT PLATFORM AND SOFTWARE DEVELOPMENT KITS THAT PROVIDE COMPREHENSIVE MACHINE LEARNING SERVICES,"The present disclosure provides an application development platform and associated software development kits (""SDKs"") that provide comprehensive services for generation, deployment, and management of machine-learned models used by computer applications such as, for example, mobile applications executed by a mobile computing device. In particular, the application development platform and SDKs can provide or otherwise leverage a unified, cross-platform application programming interface (""API"") that enables access to all of the different machine learning services needed for full machine learning functionality within the application. In such fashion, developers can have access to a single SDK for all machine learning services.",G06N 3/04; G06N 3/08; G06N 99/00; G06N 20/00,GOOGLE LLC,"CHAI, Wei; SANKETI, Pannag; ELBOUCHIKHI, Ibrahim","62/667,959 07.05.2018 US",
WO2018085728,PCT/US2017/060056,03.11.2017,WO/2018/085728,11.05.2018,WO,JOINT MANY-TASK NEURAL NETWORK MODEL FOR MULTIPLE NATURAL LANGUAGE PROCESSING (NLP) TASKS,"The technology disclosed provides a so-called ""joint many-task neural network model"" to solve a variety of increasingly complex natural language processing (NLP) tasks using growing depth of layers in a single end-to-end model. The model is successively trained by considering linguistic hierarchies, directly connecting word representations to all model layers, explicitly using predictions in lower tasks, and applying a so-called ""successive regularization"" technique to prevent catastrophic forgetting. Three examples of lower level model layers are part-of-speech (POS) tagging layer, chunking layer, and dependency parsing layer. Two examples of higher level model layers are semantic relatedness layer and textual entailment layer. The model achieves the state-of-the-art results on chunking, dependency parsing, semantic relatedness and textual entailment.",G06N 3/04; G10L 15/16; G10L 15/18; G10L 25/30; G06F 17/20,"SALESFORCE.COM, INC.","HASHIMOTO, Kazuma; XIONG, Caiming; SOCHER, Richard","62/417,269 03.11.2016 US; 62/418,070 04.11.2016 US; 15/421,407 31.01.2017 US; 15/421,424 31.01.2017 US; 15/421,431 31.01.2017 US",CN-201780068289.2; JP-2019523092; CA-3039517; EP-2017800683
WO2017158058,PCT/EP2017/056172,15.03.2017,WO/2017/158058,21.09.2017,WO,METHOD FOR CLASSIFICATION OF UNIQUE/RARE CASES BY REINFORCEMENT LEARNING IN NEURAL NETWORKS,"A method to reinforce deep neural network learning capacity to classify rare cases, which comprises the steps of training a first deep neural network (DNN-A) used to classify generic cases of original data (Data-A) into specified labels (Label-A); localizing discriminative class-specific features within the original data processed through DNN-A and mapping the discriminative class-specific features as spatial-probabilistic labels (Label-B); training a second deep neural network (DNN-C) used to classify rare cases of the original data into the spatial-probabilistic labels; and training a combined deep neural network (DNN-D) used to classify both generic and rare cases of the original data into primary combined specified and spatial-probabilistic labels (Label-A+B*).",G06N 3/04; G06N 3/08,IMRA EUROPE SAS,"TSISHKOU, Dzmitry; BENDAHAN, Rémy",10 2016 204 275.0 15.03.2016 DE,JP-2018549257; EP-2017710934; US-16085989
WO2017174982,PCT/GB2017/050951,05.04.2017,WO/2017/174982,12.10.2017,WO,METHOD OF MATCHING A SKETCH IMAGE TO A FACE IMAGE,"The performance of automated facial forensic sketch matching is improved by learning from examples of facial forgetting over time. Forensic facial sketch recognition is a key capability for law enforcement, but remains an unsolved problem. It is extremely challenging because there are three distinct contributors to the domain gap between forensic sketches and photos: The well-studied sketch-photo modality gap, and the less studied gaps due to (i) the forgetting process of the eye-witness and (ii) their inability to elucidate their memory. A database of forensic sketches created at different time-delaysis used train a model to reverse the forgetting process. Surprisingly, this enables a model to systematically ""un-forget"" facial details. This model is applied to dramatically improve forensic sketch recognition in practice.",G06K 9/00,QUEEN MARY UNIVERSITY OF LONDON,"SONG, Yi-Zhe; HOSPEDALES, Timothy",1605837.2 06.04.2016 GB,
WO2020048721,PCT/EP2019/071308,08.08.2019,WO/2020/048721,12.03.2020,WO,SYSTEM AND METHOD FOR NATURAL LANGUAGE PROCESSING,"A natural language processing system configured for receiving an input sequence of input tokens representing a first sequence of words in a natural language of a first text and generating an output sequence of output tokens representing a second sequence of words in a natural language of a second text. The natural language processing system has at least one sequence-to-sequence (seq2seq) model and a policy gradient generator. The seq2seq model comprises an encoder, an attention module and a decoder. The encoder and the decoder each comprise a forward recurrent neural network RNN and a backward RNN, and the attention module is configured for applying weights to the encoded representations.",G06F 17/27; G06F 16/34,SIEMENS AKTIENGESELLSCHAFT,"KUMAR KARN, Sanjeev; KROMPASS, Denis; WALTINGER, Ulli",18192464.8 04.09.2018 EP,
WO2019229117,PCT/EP2019/063943,29.05.2019,WO/2019/229117,05.12.2019,WO,METHOD FOR TRANSFERRING LEARNING FROM A FIRST CONVOLUTIONAL NEURAL NETWORK TO A SECOND CONVOLUTIONAL NEURAL NETWORK,"The invention relates to a method, implemented by a computer (ORD), for transferring learning from a first convolutional neural network to a second convolutional neural network, comprising the following steps: a) learning by the first convolutional neural network of a database of images labelled according to a plurality of categories of the most specific level of the database, each image being able to be represented by a characteristic vector; b) for each of the categories of the most specific level, constructing at least one subcategory; c) relabelling the database of images with the set of subcategories, in order to form a database of relabelled images; d) learning by the second convolutional neural network of the database of re-labelled images.",G06N 3/04; G06N 3/08; G06N 20/10,COMMISSARIAT A L'ENERGIE ATOMIQUE ET AUX ENERGIES ALTERNATIVES,"TAMAAZOUSTI, Youssef; GIRARD, Julien; LE BORGNE, Hervé; HUDELOT, Céline",1854785 01.06.2018 FR,
WO2019051356,PCT/US2018/050173,10.09.2018,WO/2019/051356,14.03.2019,WO,A SYSTEM AND METHOD FOR AUTOMATED LABELING AND ANNOTATING UNSTRUCTURED MEDICAL DATASETS,"Supervised and unsupervised learning schemes may be used to automatically label medical images for use in deep learning applications. Large labeled datasets may be generated from a small initial training set using an iterative snowball sampling scheme. A machine learning powered automatic organ classifier for imaging datasets, such as CT datasets, with a deep convolutional neural network (CNN) followed by an organ dose calculation is also provided. This technique can be used for patient-specific organ dose estimation since the locations and sizes of organs for each patient can be calculated independently.",G06K 9/34,THE GENERAL HOSPITAL CORPORATION,"DO, Synho; CHO, Jung, Hwan","62/555,799 08.09.2017 US; 62/555,767 08.09.2017 US",
WO2018222203,PCT/US2017/035635,02.06.2017,WO/2018/222203,06.12.2018,WO,SYSTEMS AND METHODS FOR BLACK-BOX OPTIMIZATION,"The present disclosure provides computing systems and associated methods for optimizing one or more adjustable parameters (e.g. operating parameters) of a system. In particular, the present disclosure provides a parameter optimization system that can perform one or more black-box optimization techniques to iteratively suggest new sets of parameter values for evaluation. The iterative suggestion and evaluation process can serve to optimize or otherwise improve the overall performance of the system, as evaluated by an objective function that evaluates one or more metrics. The present disclosure also provides a novel black-box optimization technique known as ""Gradientless Descent"" that is more clever and faster than random search yet retains most of random search's favorable qualities.",G06F 17/11; G06N 99/00,GOOGLE LLC,"GOLOVIN, Daniel Reuben; SOLNIK, Benjamin; MOITRA, Subhodeep; SCULLEY, David W., II",,
WO2018183650,PCT/US2018/025101,29.03.2018,WO/2018/183650,04.10.2018,WO,END-TO-END TEXT-TO-SPEECH CONVERSION,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating speech from text. One of the systems includes one or more computers and one or more storage devices storing instructions that when executed by one or more computers cause the one or more computers to implement: a sequence-to-sequence recurrent neural network configured to: receive a sequence of characters in a particular natural language, and process the sequence of characters to generate a spectrogram of a verbal utterance of the sequence of characters in the particular natural language; and a subsystem configured to: receive the sequence of characters in the particular natural language, and provide the sequence of characters as input to the sequence-to-sequence recurrent neural network to obtain as output the spectrogram of the verbal utterance of the sequence of characters in the particular natural language.",G10L 13/04; G10L 15/16; G06N 3/08,GOOGLE LLC,"BENGIO, Samuel; WANG, Yuxuan; YANG, Zongheng; CHEN, Zhifeng; WU, Yonghui; AGIOMYRGIANNAKIS, Ioannis; WEISS, Ron J.; JAITLY, Navdeep; RIFKIN, Ryan M.; CLARK, Robert Andrew James; LE, Quoc V.; RYAN, Russell J.; XIAO, Ying",20170100126 29.03.2017 GR,CA-3058433; AU-2018244917; KR-1020197032042; CN-201880021978.2; JP-2019553345; EP-2018718562
WO2018217635,PCT/US2018/033674,21.05.2018,WO/2018/217635,29.11.2018,WO,APPLICATION DEVELOPMENT PLATFORM AND SOFTWARE DEVELOPMENT KITS THAT PROVIDE COMPREHENSIVE MACHINE LEARNING SERVICES,"The present disclosure provides an application development platform and associated software development kits (""SDKs"") that provide comprehensive services for generation, deployment, and management of machine-learned models used by computer applications such as, for example, mobile applications executed by a mobile computing device. In particular, the application development platform and SDKs can provide or otherwise leverage a unified, cross-platform application programming interface (""API"") that enables access to all of the different machine learning services needed for full machine learning functionality within the application. In such fashion, developers can have access to a single SDK for all machine learning services.",G06N 3/04; G06N 3/08,GOOGLE LLC,"RAVI, Sujith; MENGHANI, Gaurav; KALIAMOORTHI, Prabhu; FAN, Yicheng","62/509,058 20.05.2017 US; 62/517,635 09.06.2017 US; 62/667,959 07.05.2018 US",EP-2018729531
WO2019221965,PCT/US2019/031006,07.05.2019,WO/2019/221965,21.11.2019,WO,UNSUPERVISED CROSS-DOMAIN DISTANCE METRIC ADAPTATION WITH FEATURE TRANSFER NETWORK,"A method for implementing an unsupervised cross-domain distance metric adaptation framework with a feature transfer network for enhancing facial recognition includes recursively training a feature transfer network and automatic labeling of target domain data using a clustering method, and implementing the feature transfer network and the automatic labeling to perform a facial recognition task.",G06K 9/00; G06N 3/08,"NEC LABORATORIES AMERICA, INC.","SOHN, Kihyuk; CHANDRAKER, Manmohan; YU, Xiang","62/672,567 16.05.2018 US; 16/400,429 01.05.2019 US",
WO2019068073,PCT/US2018/053710,01.10.2018,WO/2019/068073,04.04.2019,WO,AUTOMATED EVALUATION OF HUMAN EMBRYOS,"Systems and methods are provided for provided for automatic evaluation of a human embryo. An image of the embryo is obtained and provided to a neural network to generate a plurality of values representing the morphology of the embryo. The plurality of values representing the morphology of the embryo are evaluated at an expert system to provide an output class representing one of a current quality of the embryo, a future quality of the embryo, a likelihood that implantation of the embryo will be successful, and a likelihood that implantation of the embryo will result in a live birth.",G06F 19/26; G06T 7/00,"THE BRIGHAM AND WOMEN'S HOSPITAL, INC.","SHAFIEE, Hadi; BORMANN, Charles; KUMAR KANAKASABAPATHY, Manoj; THIRUMALARAJU, Prudhvi","62/565,237 29.09.2017 US; 62/651,658 02.04.2018 US",
WO2019200289,PCT/US2019/027275,12.04.2019,WO/2019/200289,17.10.2019,WO,DEVICES AND METHODS EMPLOYING OPTICAL-BASED MACHINE LEARNING USING DIFFRACTIVE DEEP NEURAL NETWORKS,"An all-optical Diffractive Deep Neural Network (D2NN) architecture learns to implement various functions or tasks after deep learning-based design of the passive diffractive or reflective substrate layers that work collectively to perform the desired function or task. This architecture was successfully confirmed experimentally by creating 3D-printed D2NNs that learned to implement handwritten classifications and lens function at the terahertz spectrum. This all-optical deep learning framework can perform, at the speed of light, various complex functions and tasks that computer-based neural networks can implement, and will find applications in all-optical image analysis, feature detection and object classification, also enabling new camera designs and optical components that can learn to perform unique tasks using D2NNs. In alternative embodiments, the all-optical D2NN is used as a front-end in conjunction with a trained, digital neural network back-end.",G02B 5/32; G02F 1/225; G03H 1/28; G06N 3/04; G06N 3/08; G11B 7/28,THE REGENTS OF THE UNIVERSITY OF CALIFORNIA,"OZCAN, Aydogan; RIVENSON, Yair; LIN, Xing; MENGU, Deniz; LUO, Yi","62/657,405 13.04.2018 US; 62/703,029 25.07.2018 US; 62/740,724 03.10.2018 US",
WO2020002210,PCT/EP2019/066636,24.06.2019,WO/2020/002210,02.01.2020,WO,PRIVACY ENHANCING DEEP LEARNING CLOUD SERVICE USING A TRUSTED EXECUTION ENVIRONMENT,"Mechanisms are provided to implement an enhanced privacy deep learning system framework (hereafter ""framework""). The framework receives, from a client computing device, an encrypted first subnet model of a neural network, where the first subnet model is one partition of multiple partitions of the neural network. The framework loads the encrypted first subnet model into a trusted execution environment (TEE) of the framework, decrypts the first subnet model, within the TEE, and executes the first subnet model within the TEE. The framework receives encrypted input data from the client computing device, loads the encrypted input data into the TEE, decrypts the input data, and processes the input data in the TEE using the first subnet model executing within the TEE.",G06N 3/04; G06N 3/063,INTERNATIONAL BUSINESS MACHINES CORPORATION; IBM UNITED KINGDOM LIMITED,"GU, Zhongshu; HUANG, Heqing; ZHANG, Jialong; SU, Dong; PENDARAKIS, Dimitrios; MOLLOY, Ian, Michael","16/016,752 25.06.2018 US",
WO2018217738,PCT/US2018/033874,22.05.2018,WO/2018/217738,29.11.2018,WO,SYSTEMS AND METHODS FOR IMAGE PROCESSING,"A computing-device implemented system and method for identifying an item in an x-ray image is described. The method includes training a machine learning algorithm with at least one training data set of x-ray images to generate at least one machine- learned model. The method further includes receiving at least one rendered x-ray image that includes an item, identifying the item using the at least one model, and generating an automated detection indication associated with the item.",G06K 9/00,"L3 SECURITY & DETECTION SYSTEMS, INC.","PERTICONE, David; FOLAND, Andrew D.","62/509,676 22.05.2017 US",CA-3064559; AU-2018272836; EP-2018769845
EP219398307,17199835,03.11.2017,3327726,30.05.2018,EP,ANONYMOUS AND SECURE CLASSIFICATION USING A DEEP LEARNING NETWORK,"A machine-learnt classifier is used for more anonymous data transfer. Deep learning, such as neural network machine learning, results in a classifier with multiple distinct layers. Each layer processes the output of a preceding layer. As compared to the input to the layer, the output is different. By applying a subset of layers locally, the resulting output may be provided to a cloud server for application to the remaining layers. Since the output of a layer of the deep-learnt classifier is different than the input, the information transmitted to and available at the cloud server is more anonymous or different than the original data, yet the cloud server may apply the latest machine learnt classifier as the remaining layers.",G16H 30/20; G06N 3/04,SIEMENS HEALTHCARE GMBH,KIRALY ATILLA PETER; GALL PETER,201615344321 04.11.2016 US,
WO2017209660,PCT/RU2017/050048,05.06.2017,WO/2017/209660,07.12.2017,WO,LEARNABLE VISUAL MARKERS AND METHOD OF THEIR PRODUCTION,"This technical solution refers to methods for production of a family of visual markers capable of encoding information in robotics, virtual and augmented reality domains. A synthesizing neural network that converts a sequence of bits into images of visual markers, a rendering neural network that converts input images of visual markers into images comprising visual markers, and a recognizing neural network that converts images containing visual markers into a bit sequence are created The synthesizing, rendering and recognizing neural networks are trained jointly via the minimization of the loss function, reflecting a probability of correct recognition of random bit sequences. A localizing neural network that translates images comprising a marker to various marker position parameters instead of or in addition to the recognizing neural network is created. The technical result is an increase in accuracy of recognition and localization of visual markers.",G06N 3/02; G05B 13/02; G06T 1/00,AUTONOMOUS NON-PROFIT ORGANIZATION FOR HIGHER EDUCATION «SKOLKOVO INSTITUTE OF SCIENCE AND TECHNOLOGY»,"LEMPITSKY, Victor Sergeevich",2016122082 03.06.2016 RU,
WO2020041237,PCT/US2019/047152,20.08.2019,WO/2020/041237,27.02.2020,WO,BRAIN OPERATING SYSTEM,"Embodiments may provide an intelligent adaptive system that combines input data types, processing history and objectives, research knowledge, and situational context to determine the most appropriate mathematical model, choose the computing infrastructure, and propose the best solution for a given problem. For example, a method implemented in a computer may comprise receiving, at the computer system, data relating to a problem to be solved, generating, at the computer system, a description of the problem, wherein the description conforms to defined format, obtaining, at the computer system, at least one machine learning model relevant to the problem, selecting, at the computer system, computing infrastructure upon which to execute the at least one machine learning model relevant to the problem, and executing, at the computer system, the at least one machine learning model relevant to the problem using the selected computing infrastructure to generate at least one recommendation relevant to the problem.",G06N 3/00; G06N 20/00; G06N 99/00,"HOWARD, Newton","HOWARD, Newton","16/545,205 20.08.2019 US; 62/719,849 20.08.2018 US; 62/726,699 04.09.2018 US; 62/783,050 20.12.2018 US",
WO2019222401,PCT/US2019/032486,15.05.2019,WO/2019/222401,21.11.2019,WO,GRADIENT ADVERSARIAL TRAINING OF NEURAL NETWORKS,"Systems and methods for gradient adversarial training of a neural network are disclosed. In one aspect of gradient adversarial training, an auxiliary neural network can be trained to classify a gradient tensor that is evaluated during backpropagation in a main neural network that provides a desired task output. The main neural network can serve as an adversary to the auxiliary network in addition to a standard task-based training procedure. The auxiliary neural network can pass an adversarial gradient signal back to the main neural network, which can use this signal to regularize the weight tensors in the main neural network. Gradient adversarial training of the neural network can provide improved gradient tensors in the main network. Gradient adversarial techniques can be used to train multitask networks, knowledge distillation networks, and adversarial defense networks.",G06N 3/08; G06N 3/04,"MAGIC LEAP, INC.","SINHA, Ayan Tuhinendu; RABINOVICH, Andrew; CHEN, Zhao; BADRINARAYANAN, Vijay","62/673,116 17.05.2018 US",
WO2019002465,PCT/EP2018/067414,28.06.2018,WO/2019/002465,03.01.2019,WO,TRAINING ACTION SELECTION NEURAL NETWORKS USING APPRENTICESHIP,"An off-policy reinforcement learning actor-critic neural network system configured to select actions from a continuous action space to be performed by an agent interacting with an environment to perform a task. An observation defines environment state data and reward data. The system has an actor neural network which learns a policy function mapping the state data to action data. A critic neural network learns an action-value (Q) function. A replay buffer stores tuples of the state data, the action data, the reward data and new state data. The replay buffer also includes demonstration transition data comprising a set of the tuples from a demonstration of the task within the environment. The neural network system is configured to train the actor neural network and the critic neural network off-policy using stored tuples from the replay buffer comprising tuples both from operation of the system and from the demonstration transition data.",G06N 3/04; G06N 3/08; G06N 3/00,DEEPMIND TECHNOLOGIES LIMITED,"PIETQUIN, Olivier; RIEDMILLER, Martin; FUMIN, Wang; PIOT, Bilal; VECERIK, Matej; HESTER, Todd Andrew; ROTHORL, Thomas; LAMPE, Thomas; HEESS, Nicolas Manfred Otto; SCHOLZ, Jonathan Karl","62/526,290 28.06.2017 US",CN-201880028844.3; EP-2018735278
WO2019161204,PCT/US2019/018221,15.02.2019,WO/2019/161204,22.08.2019,WO,"PLATFORM FOR PROTEIN STORAGE, ANALYSIS AND ENGINEERING","Disclosed here is a database for storage and analysis of protein engineering data, a deposition tool used to parse and store protein engineering data, and an artificial intelligence platform for designing proteins with specific functions. The database and related tools store a plurality of full length mutant protein sequences, and related characteristic data sets. The characteristic data includes data from assays done with the protein of the respective full length mutant protein sequence",G06N 3/08; G06F 19/18; G06F 19/24,PROTABIT LLC,"OLAFSON, Barry, D.; CHANG, Paul, M.; WANG, Connie, Y.; FIELD, Wesley, Aaron; OU, Shu-Ching; ARY, Mary, L.","62/632,169 19.02.2018 US",
WO2020074080,PCT/EP2018/077710,11.10.2018,WO/2020/074080,16.04.2020,WO,ENABLING PREDICTION OF FUTURE OPERATIONAL CONDITION FOR SITES,"It is provided a method for enabling prediction of a future operational condition for at least one site, each site comprising at least one radio network node of a radio access technology, RAT, of a cellular network. The method comprises the steps of: obtaining input properties of the at least one site; selecting a plurality of machine learning models based on the input properties; and activating the selected plurality of machine learning models in an inference engine, such that all of the selected plurality of machine learning models are collectively applicable to enable prediction of a future operational condition of the at least one site.",H04W 24/04; H04L 12/24; G05B 13/02; G06K 9/62,TELEFONAKTIEBOLAGET LM ERICSSON (PUBL),"VANDIKAS, Konstantinos; SUN, Bin; LINDEGREN, David; KARAPANTELAKIS, Athanasios",,
WO2018217501,PCT/US2018/032814,15.05.2018,WO/2018/217501,29.11.2018,WO,USING ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING TO AUTOMATICALLY SHARE DESIRED DIGITAL MEDIA,"Artificial intelligence is utilized to automatically share a digital media. The digital media is detected. The media is analyzed using machine learning to identify whether the digital media is likely not desirable to share. In an event the digital media is not identified as not desirable to share, the digital media is automatically shared.",G06F 15/16; G06F 7/00; G06F 17/00; G06F 17/30; G06K 9/62,"GET ATTACHED, INC.","AZOUT, Albert; IMBRUCE, Douglas","15/607,026 26.05.2017 US",
WO2018085730,PCT/US2017/060059,03.11.2017,WO/2018/085730,11.05.2018,WO,TRAINING A JOINT MANY-TASK NEURAL NETWORK MODEL USING SUCCESSIVE REGULARIZATION,"The technology disclosed provides a so-called ""joint many-task neural network model"" to solve a variety of increasingly complex natural language processing (NLP) tasks using growing depth of layers in a single end-to-end model. The model is successively trained by considering linguistic hierarchies, directly connecting word representations to all model layers, explicitly using predictions in lower tasks, and applying a so-called ""successive regularization"" technique to prevent catastrophic forgetting. Three examples of lower level model layers are part-of-speech (POS) tagging layer, chunking layer, and dependency parsing layer. Two examples of higher level model layers are semantic relatedness layer and textual entailment layer. The model achieves the state-of-the-art results on chunking, dependency parsing, semantic relatedness and textual entailment.",G06N 3/04; G10L 15/16; G10L 15/18; G10L 25/30; G06F 17/20,"SALESFORCE.COM, INC.","HASHIMOTO, Kazuma; XIONG, Caiming; SOCHER, Richard","62/417,269 03.11.2016 US; 62/418,070 04.11.2016 US; 15/421,431 31.01.2017 US; 15/421,407 31.01.2017 US; 15/421,424 31.01.2017 US",CA-3039551; CN-201780068346.7; JP-2019522896; EP-2017801556
WO2020001082,PCT/CN2019/078472,18.03.2019,WO/2020/001082,02.01.2020,WO,FACE ATTRIBUTE ANALYSIS METHOD BASED ON TRANSFER LEARNING,"A face attribute analysis method based on transfer learning, relating to the technical field of calculation and reckon, in particular to the technical field of computer vision for recognizing face attributes. The method comprises: jointly training sample sets on a multi-attribute prediction network to predict feature attributes, transferring the convergent multi-attribute prediction network to a main attribute prediction network, and continuing to train the main attribute prediction network and fine-tuning parameters until a loss function of the main attribute prediction network converges. The main attributes comprise but are not limited to face attributes based on logistic regression and the main attributes of face attributes based on linear regression, so that not only local minima are prevented, but also the precision decrease caused by excessive complexity of tasks is avoided, and the method is more accurate and flexible in practical application.",G06K 9/00,SOUTHEAST UNIVERSITY; 东南大学,"LU, Shengli; 陆生礼; PANG, Wei; 庞伟; XIANG, Jiaqi; 向家淇; ZHOU, Shihao; 周世豪; YANG, Wentao; 杨文韬; PAN, Wenwen; 泮雯雯",201810702472.X 30.06.2018 CN,
EP289050030,19192393,19.08.2019,3614337,26.02.2020,EP,METHOD AND SYSTEM OF ANALYZING MEDICAL IMAGES,"The present invention seeks to provide a method of analyzing medical image, the method comprises receiving a medical image; applying a model stored in a memory; analyzing the medical image based on the model; determining the medical image including a presence of fracture; and, transmitting an indication indicative of the determination.",G06T 7/00,CHANG GUNG MEMORIAL HOSPITAL LINKOU,LIAO CHIEN-HUNG; CHENG CHI-TUNG; HO TSUNG-YING; LEE TAO-YI; CHOU CHING-CHENG,201862719664 19.08.2018 US,
WO2018085729,PCT/US2017/060057,03.11.2017,WO/2018/085729,11.05.2018,WO,DEEP NEURAL NETWORK MODEL FOR PROCESSING DATA THROUGH MULTIPLE LINGUISTIC TASK HIERARCHIES,"The technology disclosed provides a so-called ""joint many-task neural network model"" to solve a variety of increasingly complex natural language processing (NLP) tasks using growing depth of layers in a single end-to-end model. The model is successively trained by considering linguistic hierarchies, directly connecting word representations to all model layers, explicitly using predictions in lower tasks, and applying a so-called ""successive regularization"" technique to prevent catastrophic forgetting. Three examples of lower level model layers are part-of-speech (POS) tagging layer, chunking layer, and dependency parsing layer. Two examples of higher level model layers are semantic relatedness layer and textual entailment layer. The model achieves the state-of-the-art results on chunking, dependency parsing, semantic relatedness and textual entailment.",G06N 3/04; G10L 15/16; G10L 15/18; G10L 25/30; G06F 17/20,"SALESFORCE.COM, INC.","HASHIMOTO, Kazuma; XIONG, Caiming; SOCHER, Richard","62/417,269 03.11.2016 US; 62/418,070 04.11.2016 US; 15/421,424 31.01.2017 US; 15/421,407 31.01.2017 US; 15/421,431 31.01.2017 US",EP-2017797845; JP-2019522984; CN-201780068577.8; CA-3039386
WO2019100784,PCT/CN2018/102161,24.08.2018,WO/2019/100784,31.05.2019,WO,FEATURE EXTRACTION USING MULTI-TASK LEARNING,"Systems and methods training a model are disclosed. In the method, training data is obtained by a deep neural network (DNN) first, the deep neural network comprising at least one hidden layer. Then features of the training data are obtained from a specified hidden layer of the at least one hidden layer, the specified hidden layer being connected respectively to a supervised classification network for classification tasks and an autoencoder based reconstruction network for reconstruction tasks. And at last the DNN, the supervised classification network and the reconstruction network are trained as a whole based on the obtained features, the training being guided by the classification tasks and the reconstruction tasks",G06N 3/04,"INTERNATIONAL BUSINESS MACHINES CORPORATION; IBM (CHINA) CO., LIMITED","DONG, Weishan; YUAN, Ting; YANG, Kai; LI, Changsheng; ZHU, Jun; YAO, Renjie; GAO, Peng; MA, Chunyang","15/818,877 21.11.2017 US",
WO2019060730,PCT/US2018/052226,21.09.2018,WO/2019/060730,28.03.2019,WO,DETERMINING CONTROL POLICIES FOR ROBOTS WITH NOISE-TOLERANT STRUCTURED EXPLORATION,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for optimizing the determination of control policies for robots through the performance of simulations of robots and real-world context to determine control policy parameters.",B25J 9/16,GOOGLE LLC,"SINDHWANI, Vikas; ISCEN, Atil; CHOROMANSKI, Krzysztof Marcin","62/562,286 22.09.2017 US; 62/599,552 15.12.2017 US",CN-201880038417.3; EP-2018783306
WO2017166137,PCT/CN2016/077910,30.03.2016,WO/2017/166137,05.10.2017,WO,METHOD FOR MULTI-TASK DEEP LEARNING-BASED AESTHETIC QUALITY ASSESSMENT ON NATURAL IMAGE,"A method for multi-task deep learning-based aesthetic quality assessment on a natural image. The method comprises: step 1, automatically learning about multi-task deep learning-based aesthetic and semantic features of a natural image (S101); and step 2, performing multi-task deep learning-based aesthetic classification and semantic identification on the automatic learning result to implement aesthetic quality assessment on the natural image (S102). The method more efficiently performs aesthetic quality assessment by assisting the expression and learning of aesthetic features using semantic information, and designs a plurality of multi-task deep learning network structures to more efficiently obtain a high-precision classification of an image using aesthetic and semantic information. The method can be applied to many fields related to aesthetic quality assessment of images, including image searching, photography, album management, and the like.",G06K 9/62,"INSTITUTE OF AUTOMATION, CHINESE ACADEMY OF SCIENCES; 中国科学院自动化研究所","HUANG, Kaiqi; 黄凯奇; TAN, Tieniu; 谭铁牛; HE, Ran; 赫然; KAO, Yueying; 考月英",,US-16068912
EP275493179,19168125,09.04.2019,3561735,30.10.2019,EP,INTEGRATING DEEP LEARNING INTO GENERALIZED ADDITIVE MIXED-EFFECT (GAME) FRAMEWORKS,,G06N 3/04; G06N 3/08; G06N 5/00; G06N 5/02; G06N 7/00; G06N 20/20; G06Q 10/06; G06Q 10/10,MICROSOFT TECHNOLOGY LICENSING LLC,MA YIMING; LU WEI; JIA JUN; CHEN BEE-CHUNG; LONG BO,201815964586 27.04.2018 US,
EP231869832,18161702,14.03.2018,3389005,17.10.2018,EP,ABSTRACTION LIBRARY TO ENABLE SCALABLE DISTRIBUTED MACHINE LEARNING,"One embodiment provides for a non-transitory machine readable medium storing instructions which, when executed by one or more processors, cause the one or more processors to perform operations comprising providing an interface to define a neural network using machine-learning domain specific terminology, wherein the interface enables selection of a neural network topology and abstracts low-level communication details of distributed training of the neural network.",G06T 1/20,INTEL CORP,KALAMKAR DHIRAJ D; VAIDYANATHAN KARTHIKEYAN; SRIDHARAN SRINIVAS; DAS DIPANKAR,201715482925 10.04.2017 US,
EP250371255,18275016,08.02.2018,3525136,14.08.2019,EP,DISTRIBUTED MACHINE LEARNING SYSTEM,,G06N 3/00; G06N 7/00; G06N 99/00,PROWLER IO LTD,BOU-AMMAR HAITHAM; TUTUNOV RASUL; KIM DONGHO; TOMCZAK MARCIN,18275016 08.02.2018 EP,
WO2020029585,PCT/CN2019/078522,18.03.2019,WO/2020/029585,13.02.2020,WO,"NEURAL NETWORK FEDERATION MODELING METHOD AND DEVICE EMPLOYING TRANSFER LEARNING, AND STORAGE MEDIUM","A neural network federation modeling method and device employing transfer learning, and a storage medium. The method comprises: a first terminal inputting a feature vector of first sample data to a first neural network so as to acquire a first neural network vector, determining a first gradient value and a first loss value according to the first neural network vector, and encrypting the first gradient value and the first loss value (S101); combining the encrypted first gradient value and the encrypted first loss value with a received encrypted second gradient value and encrypted second loss value sent by a second terminal so as to acquire an encrypted third loss value and encrypted third gradient value (S102); sending the encrypted third loss value and the encrypted third gradient value to a third terminal, and determining, according to the third loss value and a historical loss value decrypted and returned by the third terminal, whether a model to be trained converges (S103); and if the model converges, using a model parameter at the time of convergence to establish the model (S104).",G06N 3/04,"WEBANK CO., LTD; 深圳前海微众银行股份有限公司","LIU, Yang; 刘洋; YANG, Qiang; 杨强; CHENG, Kewei; 成柯葳; FAN, Tao; 范涛; CHEN, Tianjian; 陈天健",201810913188.7 10.08.2018 CN,
WO2018125347,PCT/US2017/053949,28.09.2017,WO/2018/125347,05.07.2018,WO,MULTI-TASK MACHINE LEARNING FOR PREDICTED TOUCH INTERPRETATIONS,"The present disclosure provides systems and methods that leverage machine learning to predict multiple touch interpretations. In particular, the systems and methods of the present disclosure can include and use a machine-learned touch interpretation prediction model that has been trained to receive touch sensor data indicative of one or more locations of one or more user input objects relative to a touch sensor at one or more times and, in response to receipt of the touch sensor data, provide one or more predicted touch interpretation outputs. Each predicted touch interpretation output corresponds to a different type of predicted touch interpretation based at least in part on the touch sensor data. Predicted touch interpretations can include a set of touch point interpretations, a gesture interpretation, and/or a touch prediction vector for one or more future times.",G06F 3/041; G06N 3/02; G06F 3/0488,GOOGLE LLC,"DESELAERS, Thomas; CARBUNE, Victor","15/393,611 29.12.2016 US",EP-2017784127; CN-201780087180.3
WO2020058800,PCT/IB2019/057562,09.09.2019,WO/2020/058800,26.03.2020,WO,ENCODER-DECODER MEMORY-AUGMENTED NEURAL NETWORK ARCHITECTURES,"Memory-augmented neural networks are provided. An encoder artificial neural network is adapted to receive an input and provide an encoded output based on the input. A plurality of decoder artificial neural networks is provided, each adapted to receive an encoded input and provide an output based on the encoded input. A memory is operatively coupled to the encoder artificial neural network and to the plurality of decoder artificial neural networks. The memory is adapted to store the encoded output of the encoder artificial neural network and provide the encoded input to the plurality of decoder artificial neural networks.",G06N 3/04,INTERNATIONAL BUSINESS MACHINES CORPORATION; IBM UNITED KINGDOM LIMITED; IBM (CHINA) INVESTMENT COMPANY LIMITED,"THATHACHAR, Jayram; KORNUTA, Tomasz; OZCAN, Ahmet, Serkan","16/135,990 19.09.2018 US",
WO2013184688,PCT/US2013/044124,04.06.2013,WO/2013/184688,12.12.2013,WO,STOCHASTIC APPARATUS AND METHODS FOR IMPLEMENTING GENERALIZED LEARNING RULES,"Generalized learning rules may be implemented. A framework may be used to enable adaptive signal processing system to flexibly combine different learning rules (supervised, unsupervised, reinforcement learning) with different methods (online or batch learning). The generalized learning framework may employ time-averaged performance function as the learning measure thereby enabling modular architecture where learning tasks are separated from control tasks, so that changes in one of the modules do not necessitate changes within the other. The generalized learning apparatus may be capable of implementing several learning rules concurrently based on the desired control application and without requiring users to explicitly identify the required learning rule composition for that application.",G06N 3/02,BRAIN CORPORATION,"SINYAVSKIY, Oleg; COENEN, Olivier","13/487,499 04.06.2012 US",
WO2019104003,PCT/US2018/061946,20.11.2018,WO/2019/104003,31.05.2019,WO,SYSTEMS AND METHODS FOR AUTOMATICALLY INTERPRETING IMAGES OF MICROBIOLOGICAL SAMPLES,"In accordance with some embodiments of the disclosed subject matter, provided herein are mechanisms (which can, for example, include systems, methods, and media) for automatically interpreting and classifying images of Gram-stained biological samples.",G06K 9/00; G06N 3/02; G06N 3/06,"BETH ISRAEL DEACONESS MEDICAL CENTER, INC","KIRBY, James E.; SMITH, Kenneth P.; KANG, Anthony","62/589,246 21.11.2017 US",
WO2019217281,PCT/US2019/030859,06.05.2019,WO/2019/217281,14.11.2019,WO,VIDEO OBJECT TRACKING,"A technique is disclosed for automating tracking of annotated objects and improves the throughput and efficiency of existing methods while maintaining a degree of accuracy comparable to a human annotator. In particular, the disclosed technique provides an automated annotated object tracking tool that allows machine-learning teams to annotate an object within a frame and have that annotation persist across frames as the annotated object is tracked within a series of frames, still ensuring that every frame is accurately reviewed by a human where high quality annotation is required. This technique incorporates human feedback via a user adjustment that allows the tool to adapt and improve its accuracy in tracking an annotated object across a sequence of frames.",G06T 7/20; G06T 7/70,"FIGURE EIGHT TECHNOLOGIES, INC.","VAJAPEY, Kiran; MUNRO, Robert; CLOUGHLEY, Joseph, Richard; GORDON, Matthew, Allen; IRSHAD, Humayun; CHEN, Monchu; MIRSHARIF, Seyyedeh, Qazale; XIAO, Caiqun","62/669,259 09.05.2018 US; 16/228,579 20.12.2018 US",
WO2020037055,PCT/US2019/046524,14.08.2019,WO/2020/037055,20.02.2020,WO,CONTROL METHODS AND SYSTEMS USING EXTERNAL 3D MODELING AND NEURAL NETWORKS,A system for controlling tinting of one or more zones of windows in a building based on predictions of future environmental conditions.,E06B 3/67; E06B 9/24; G02F 1/163; G05B 13/02; G05B 15/02,"VIEW, INC.","RASMUS-VORRATH, Jack; ZEDLITZ, Jason David; DUTTA, Ranojoy; YING, Yuyang; KLAWUHN, Erich R.; SHRIVASTAVA, Dhairya","62/764,821 15.08.2018 US; 62/745,920 15.10.2018 US; 62/805,841 14.02.2019 US",
WO2019224823,PCT/IL2019/050582,22.05.2019,WO/2019/224823,28.11.2019,WO,METHOD AND SYSTEM FOR IMAGING AND IMAGE PROCESSING,"A method of designing an element for the manipulation of waves, comprises: accessing a computer readable medium storing a machine learning procedure, having a plurality of learnable weight parameters. A first plurality of the weight parameters corresponds to the element, and a second plurality of the weight parameters correspond to an image processing. The method comprises accessing a computer readable medium storing training imaging data, and training the machine learning procedure on the training imaging data, so as to obtain values for at least the first plurality of the weight parameters.",G06N 3/02; G06K 9/46; G06T 5/00,RAMOT AT TEL-AVIV UNIVERSITY LTD.,"ELMALEM, Shay; GIRYES, Raja; HAIM, Harel; BRONSTEIN, Alexander; MAROM, Emanuel","62/674,724 22.05.2018 US",
WO2020046445,PCT/US2019/038443,21.06.2019,WO/2020/046445,05.03.2020,WO,A MULTISTAGE CURRICULUM TRAINING FRAMEWORK FOR ACOUSTIC-TO-WORD SPEECH RECOGNITION,"Methods and apparatuses are provided for performing acoustic to word (A2W) speech recognition training performed by at least one processor. The method includes initializing, by the at least one processor, one or more first layers of a neural network with phone based Connectionist Temporal Classification (CTC), initializing, by the at least one processor, one or more second layers of the neural network with grapheme based CTC, acquiring, by the at least one processor, training data and performing, by the at least one processor, A2W speech recognition training based the initialized one or more first layers and one or more second layers of the neural network using the training data.",G10L 15/02; G10L 15/04; G10L 15/08; G10L 15/16; G10L 15/187; G10L 15/20; G06N 3/02; G06N 3/04; G06N 3/08,"YU, Chengzhu; WENG, Chao; CUI, Jia; YU, Dong","YU, Chengzhu; WENG, Chao; CUI, Jia; YU, Dong","16/117,373 30.08.2018 US",
WO2019034328,PCT/EP2018/068345,06.07.2018,WO/2019/034328,21.02.2019,WO,IDENTIFYING THE QUALITY OF THE CELL IMAGES ACQUIRED WITH DIGITAL HOLOGRAPHIC MICROSCOPY USING CONVOLUTIONAL NEURAL NETWORKS,"A system for performing adaptive focusing of a microscopy device comprises a microscopy device configured to acquire microscopy images depicting cells and one or more processors executing instructions for performing a method that includes extracting pixels from the microscopy images. Each set of pixels corresponds to an independent cell. The method further includes using a trained classifier to assign one of a plurality of image quality labels to each set of pixels indicating the degree to which the independent cell is in focus. If the image quality labels corresponding to the sets of pixels indicate that the cells are out of focus, a focal length adjustment for adjusting focus of the microscopy device is determined using a trained machine learning model. Then, executable instructions are sent to the microscopy device to perform the focal length adjustment.",G02B 21/24; G03H 1/00; G06K 9/00,SIEMENS HEALTHCARE GMBH,"EL-ZEHIRY, Noha Youssry; KAMEN, Ali; RAPAKA, Saikiran","62/545,517 15.08.2017 US",EP-2018748860
WO2020006263,PCT/US2019/039554,27.06.2019,WO/2020/006263,02.01.2020,WO,SYSTEM AND METHODS FOR BRAIN HEALTH MONITORING AND SEIZURE DETECTION AND PREDICTION,"The present disclosure provides for monitoring brain health and predicting and detecting seizures via a wearable head apparatus. An exemplary method provides for receiving EEG data output by a plurality of sensors attached to a wearable head apparatus. For example, the wearable head apparatus is worn by a user. The method then provides for storing the EEG data in a memory device and processing the EEG data using a machine learning model to identify a time window of a subset of the EEG data representing a seizure. The method then provides for tagging the time window of the subset of the EEG data as seizure data. The method then provides for outputting a representation of the time window of the subset of the EEG data. The representation includes a tag of the time window as seizure data. The method then provides for training the machine learning model based on the subset of the EEG data and the tag as seizure data.",A61B 5/0478; A61B 5/04; A61B 5/0402; A61B 5/0408; A61B 5/0476,CORTEXXUS INC.,"ALVES, David; RAZAVI, Babak; DE JESUS ALVES, Ana Margarida","62/690,520 27.06.2018 US; 62/800,194 01.02.2019 US",
WO2019220393,PCT/IB2019/054072,16.05.2019,WO/2019/220393,21.11.2019,WO,METHOD FOR ESTIMATING MEASURABLE PROPERTIES IN A THREE-DIMENSIONAL VOLUME OF MATERIAL,"Method for estimating measurable properties in a three-dimensional volume of material, in particular, the present method providing for the estimation of physical, chemical, biological and/or statistical properties of a volume of material, be it solid, liquid or gaseous; wherein a two-dimensional digital image is obtained, representing a single projection of said volume, which is obtained from a single view position in transmissive or partially reflective mode and wherein said two-dimensional digital image is subjected to analysis by means of machine learning algorithms in supervised mode.",G06T 7/00,BIORETICS S.R.L.,"ROFFILLI, Matteo",102018000005488 18.05.2018 IT,
EP241674976,18198500,03.10.2018,3477555,01.05.2019,EP,MULTI-TASK FEATURE SELECTION NEURAL NETWORKS,"The present approach relates to feature ranking within deep neural networks 50, 116 in a multi-task and/or multi-label setting. Approaches are described to identify features that are task-specific as well as features that are shared across multiple tasks. In addition to facilitating interpretability, the selected subset of features can be used to make efficient models leading to better stability and regularization along with reduced computation and memory.",G06N 3/04; G06N 5/02,GEN ELECTRIC,RAVISHANKAR HARIHARAN; SUNDAR BHARATH RAM; SUDHAKAR PRASAD; VENKATARAMANI RAHUL; VAIDYA VIVEK,201715799698 31.10.2017 US,
WO2014205231,PCT/US2014/043206,19.06.2014,WO/2014/205231,24.12.2014,WO,DEEP LEARNING FRAMEWORK FOR GENERIC OBJECT DETECTION,"Object detection remains a fundamental problem and bottleneck to be addressed for making vision algorithms practical. Despite the promise, deep learning methods have not been extensively investigated on object detection problems. In this disclosure, deep learning approaches are developed for object detection problems. Specifically, learning algorithms are developed that learn hierarchical features (e.g., object parts) that can provide useful discriminative information for object detection tasks. In addition, algorithms are developed to improve invariance and discriminative power of the learned features.",G06T 7/20; G06K 9/00,THE REGENTS OF THE UNIVERSITY OF MICHIGAN,"LEE, Honglak; SOHN, Kihyuk","61/836,845 19.06.2013 US",
WO2020025932,PCT/GB2019/052080,25.07.2019,WO/2020/025932,06.02.2020,WO,"SYSTEM, METHOD AND APPARATUS FOR NEURAL NETWORKS","An system, apparatus and method for utilizing software and hardware portions of a neural network to fix, or hardwire,certain portions while modifying other portions. A first set of weights for layers of the first neural network are established, and selected weights are modified to generate a second set of weights, based on a second dataset. The second set of weights is then used to train a second neural network.",G06F 1/3234; G06N 3/08; G06N 3/04; G06N 3/063,ARM LIMITED,"WHATMOUGH, Paul Nicholas; MATTINA, Matthew; BEU, Jesse Garrett","16/054,358 03.08.2018 US",
WO2019234291,PCT/FI2019/050393,21.05.2019,WO/2019/234291,12.12.2019,WO,"AN APPARATUS, A METHOD AND A COMPUTER PROGRAM FOR SELECTING A NEURAL NETWORK","There is provided an apparatus comprising means for receiving data to be processed by one of a plurality of main neural networks (210). The apparatus comprises means for providing the data and signalling information associated with the data to a plurality of devices each comprising a main neural network and an auxiliary neural network, the auxiliary neural network comprising a subset of layers of the main neural network, wherein the signalling information comprises an identifier of an auxiliary task to be performed on the data by the auxiliary neural networks at the plurality of devices (220). The apparatus comprises means for receiving, from the plurality of devices, indications of performance of the auxiliary neural networks for performing the auxiliary task (230). The apparatus comprises means for selecting, based on the indications of performance of the auxiliary neural networks, one of the plurality of main neural networks for performing a main task on the data (240).",G06N 3/04; G06N 3/08; H04L 29/08; G06F 9/50; G06T 9/00; G06T 5/00,NOKIA TECHNOLOGIES OY,"CRICRI, Francesco; AYTEKIN, Caglar",20185527 08.06.2018 FI,
WO2019169042,PCT/US2019/019905,27.02.2019,WO/2019/169042,06.09.2019,WO,ULTRA-SENSITIVE DETECTION OF CIRCULATING TUMOR DNA THROUGH GENOME-WIDE INTEGRATION,"The disclosure relates to systems, software and methods for diagnosing tumor diseases in a patient.",C12Q 1/68; C12Q 1/6809; C12Q 1/6886; G06F 19/24,"CORNELL UNIVERSITY; NEW YORK GENOME CENTER; LANDAU, Dan Avi; ZVIRAN, Asaf; KOTHEN-HILL, Steven","LANDAU, Dan Avi; ZVIRAN, Asaf","62/636,135 27.02.2018 US",
WO2016070034,PCT/US2015/058300,30.10.2015,WO/2016/070034,06.05.2016,WO,TRANSFER LEARNING FOR BILINGUAL CONTENT CLASSIFICATION,"This disclosure provides systems and methods for determining a classification model for a secondary language different from a primary language. A social networking server is configured to obtain primary language content written in a first spoken language and secondary language content written in a second spoken language. The social networking server further obtains a machine translation of the primary language content. The social networking server then determines an initial language model from the machine translation. The social networking further determines a language model perturbation using the initial language model, where the language model perturbation accounts for a difference between the machine translation and the secondary language content. The social networking server also determines a classification model from the initial language model and the language model perturbation, which is then applied to a plurality of comments associated with an item of interest provided by a social networking service.",G06Q 50/00; G06F 17/27,LINKEDIN CORPORATION,"AMIN, Mohammad Shafkat; YAN, Baoshi; MARTELL, Craig; MARKMAN, Vita; BHASIN, Anmol","62/073,556 31.10.2014 US",
WO2019202073,PCT/EP2019/060070,18.04.2019,WO/2019/202073,24.10.2019,WO,NEURAL NETWORKS FOR SCALABLE CONTINUAL LEARNING IN DOMAINS WITH SEQUENTIALLY LEARNED TASKS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for scalable continual learning using neural networks. One of the methods includes receiving new training data for a new machine learning task; training an active subnetwork on the new training data to determine trained values of the active network parameters from initial values of the active network parameters while holding current values of the knowledge parameters fixed; and training a knowledge subnetwork on the new training data to determine updated values of the knowledge parameters from the current values of the knowledge parameters by training the knowledge subnetwork to generate knowledge outputs for the new training inputs that match active outputs generated by the trained active subnetwork for the new training inputs.",G06N 3/04; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"SCHWARZ, Jonathan; PASCANU, Razvan; HADSELL, Raia Thais; CZARNECKI, Wojciech; THE, Yee Whye; LUKETINA, Jelena","62/659,610 18.04.2018 US",
WO2018015414,PCT/EP2017/068181,19.07.2017,WO/2018/015414,25.01.2018,WO,METHOD AND SYSTEM FOR ARTIFICIAL INTELLIGENCE BASED MEDICAL IMAGE SEGMENTATION,"Methods and systems for artificial intelligence based medical image segmentation are disclosed. In a method for autonomous artificial intelligence based medical image segmentation, a medical image of a patient is received. A current segmentation context is automatically determined based on the medical image and at least one segmentation algorithm is automatically selected from a plurality of segmentation algorithms based on the current segmentation context. A target anatomical structure is segmented in the medical image using the selected at least one segmentation algorithm.",G06K 9/00; G06K 9/46,SIEMENS HEALTHCARE GMBH,"ZHOU, Shaohua Kevin; CHEN, Mingqing; DING, Hui; GEORGESCU, Bogdan; GULSUN, Mehmet Akif; KIM, Tae Soo; KIRALY, Atilla Peter; LU, Xiaoguang; PARK, Jin-hyeong; SHARMA, Puneet; SUN, Shanhui; XU, Daguang; XU, Zhoubing; ZHENG, Yefeng","62/365,032 21.07.2016 US; 62/414,913 31.10.2016 US",EP-2017751267; CN-201780045106.5
WO2019226051,PCT/NL2019/050301,24.05.2019,WO/2019/226051,28.11.2019,WO,"MONITORING AND ANALYZING BODY LANGUAGE WITH MACHINE LEARNING, USING ARTIFICIAL INTELLIGENCE SYSTEMS FOR IMPROVING INTERACTION BETWEEN HUMANS, AND HUMANS AND ROBOTS","There is provided a body language system for determining a body language message of a living being in a context, said system comprising an artificial intelligence (AI) system, said AI system running a computer program that: - retrieves at least one image of said living being showing body language; - labels said living being in said at least one image, resulting in a labeled living being; - determines said context from said at least one image using a trained machine learning model; - determines a baseline body language of said labeled living being from said at least one image using a trained machine learning model; - adapts a trained machine learning model of said AI system using said baseline body language and said context; - applies the adapted trained machine learning model of said AI system to at least one of said at least one image for categorizing said body language resulting in a category, and applying said category for determining said body language message.",G06K 9/00,KEPLER VISION TECHNOLOGIES B.V.,"STOKMAN, Henricus Meinardus Gerardus; VAN OLDENBORGH, Marc Jean Baptist; ALNAJAR, Fares",2020989 25.05.2018 NL; 2020996 28.05.2018 NL,EP-2019743015
WO2018071392,PCT/US2017/055894,10.10.2017,WO/2018/071392,19.04.2018,WO,NEURAL NETWORKS FOR SELECTING ACTIONS TO BE PERFORMED BY A ROBOTIC AGENT,"A system includes a neural network system implemented by one or more computers. The neural network system is configured to receive an observation characterizing a current state of a real-world environment being interacted with by a robotic agent to perform a robotic task and to process the observation to generate a policy output that defines an action to be performed by the robotic agent in response to the observation. The neural network system includes: (i) a sequence of deep neural networks (DNNs), in which the sequence of DNNs includes a simulation-trained DNN that has been trained on interactions of a simulated version of the robotic agent with a simulated version of the real-world environment to perform a simulated version of the robotic task, and (ii) a first robot-trained DNN that is configured to receive the observation and to process the observation to generate the policy output.",G06N 3/04; G06N 3/00; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"PASCANU, Razvan; HADSELL, Raia Thais; VECERIK, Mel; ROTHORL, Thomas; RUSU, Andrei-Alexandru; HEESS, Nicolas Manfred Otto","62/406,363 10.10.2016 US",CN-201780074261.X; EP-2017788409; JP-2019519210
WO2019194980,PCT/US2019/023381,21.03.2019,WO/2019/194980,10.10.2019,WO,SYSTEMS AND METHODS FOR RESPONDING TO HEALTHCARE INQUIRIES,"Techniques for responding to a healthcare inquiry from a user are disclosed. In one particular embodiment, the techniques may be realized as a method for responding to a healthcare inquiry from a user, according to a set of instructions stored on a memory of a computing device and executed by a processor of the computing device, the method comprising the steps of: classifying an intent of the user based on the healthcare inquiry; identifying the intent as a need to obtain a dermatological diagnosis or treatment; soliciting, from the user and via the computing device, an image of the user's skin area to be diagnosed or treated; instantiating an image classification system to identify a dermatological disease from the image; and presenting one or more medical recommendations to the user based on the identified dermatological disease.",G06F 16/20; G06F 17/27; G06Q 50/22; G06Q 50/24; G06T 7/00,"CURAI, INC.","KANNAN, Anitha; RAVURI, Murali; RODRIGUES, Vitor; VENKATARAMAN, Vignesh; TSO, Geoffrey; KHOSLA, Neal; HUNT, Neil; AMATRIAIN, Xavier; CHABLANI, Manish; SONTAG, David; UDAY, Viraj","16/265,799 01.02.2019 US; 16/266,784 04.02.2019 US; 62/654,111 06.04.2018 US",
WO2018208939,PCT/US2018/031833,09.05.2018,WO/2018/208939,15.11.2018,WO,"SYSTEMS AND METHODS TO ENABLE CONTINUAL, MEMORY-BOUNDED LEARNING IN ARTIFICIAL INTELLIGENCE AND DEEP LEARNING CONTINUOUSLY OPERATING APPLICATIONS ACROSS NETWORKED COMPUTE EDGES","Lifelong Deep Neural Network (L-DNN) technology revolutionizes Deep Learning by enabling fast, post-deployment learning without extensive training, heavy computing resources, or massive data storage. It uses a representation-rich, DNN-based subsystem (Module A) with a fast-learning subsystem (Module B) to learn new features quickly without forgetting previously learned features. Compared to a conventional DNN, L-DNN uses much less data to build robust networks, dramatically shorter training time, and learning on-device instead of on servers. It can add new knowledge without re-training or storing data. As a result, an edge device with L-DNN can learn continuously after deployment, eliminating massive costs in data collection and annotation, memory and data storage, and compute power. This fast, local, on-device learning can be used for security, supply chain monitoring, disaster and emergency response, and drone-based inspection of infrastructure and properties, among other applications.",G06K 9/46; G06K 9/62; G06K 9/00; G06K 9/36; G06K 9/48,"NEURALA, INC.","LUCIW, Matthew; OLIVERA, Santiago; GORSHECHNIKOV, Anatoly; WURBS, Jeremy; VERSACE, Heather Ames; VERSACE, Massimiliano","62/503,639 09.05.2017 US; 62/612,529 31.12.2017 US",CA-3061767; KR-1020197035963; EP-2018799281
WO2019153094,PCT/CA2019/050172,11.02.2019,WO/2019/153094,15.08.2019,WO,SYSTEM AND METHOD FOR INTERFACING WITH BIOLOGICAL TISSUE,"There is provided a system and method for interfacing with biological tissue. The system includes: a feature extraction module to implement an extraction approach to extract one or more features from the one or more physiological recording signals; a machine learning module to apply a machine learning model based on input data to detect a physiological event or condition for classification, the input data including the extracted features, the machine learning model trained using a training set including feature vectors of time-series data labelled with known occurrences of the physiological event or condition; and an output module to output the classification of the machine learning module.",A61B 5/04; A61B 5/00; A61B 5/0476; G06F 3/01; G06F 3/05; G06K 9/62; G06N 20/00; G06N 20/10,THE GOVERNING COUNCIL OF THE UNIVERSITY OF TORONTO,"GENOV, Roman; O'LEARY, Gerard","62/629,001 10.02.2018 US; 16/214,374 10.12.2018 US",
WO2018209608,PCT/CN2017/084755,17.05.2017,WO/2018/209608,22.11.2018,WO,METHOD AND SYSTEM FOR ROBUST LANGUAGE IDENTIFICATION,"A method and system for robust and efficient language identification. The method includes: receiving the speech signal (301); partitioning the speech signal into a plurality of audio frames (305); extracting features of the plurality of audio frames (307); determining, using a neural network, a variable associated with the language identity and one or more auxiliary attributes of the speech signal, for each of the plurality of audio frames (309); determining scores of the plurality of audio frames based on the extracted features (311); and determining the language identity of the speech signal based on the variables and scores determined for the plurality of audio frames (315).",G10L 15/00,"BEIJING DIDI INFINITY TECHNOLOGY AND DEVELOPMENT CO., LTD.","FU, Tianxiao",,CN-201780034751.7
WO2018165753,PCT/CA2018/050304,14.03.2018,WO/2018/165753,20.09.2018,WO,STRUCTURE DEFECT DETECTION USING MACHINE LEARNING ALGORITHMS,"Structure defect detection is performed using computer-implemented arrangements employing machine learning algorithms in the form of neural networks. In one arrangement, a convolutional neural network is trained using a database of images formed to optimize accuracy of the convolutional neural network to detect, for example, a crack in a concrete surface. A two-stage scanning process each performing a plurality of scans of a test image is incorporated in the foregoing arrangement of convolutional neural network, with the two-stages forming overlapping capture areas to reduce likelihood of a crack lying on a boundary of the individual scans going undetected. Also, region-based convolutional neural networks are trained to detect various types of defects.",G01N 21/88; G06N 3/02; G06N 3/08,UNIVERSITY OF MANITOBA,"CHA, Young Jin; CHOI, Wooram","62/471,090 14.03.2017 US; 62/551,510 29.08.2017 US",CA-3056498; EP-2018766855
WO2018076122,PCT/CA2017/051293,31.10.2017,WO/2018/076122,03.05.2018,WO,SYSTEM AND METHOD FOR IMPROVING THE PREDICTION ACCURACY OF A NEURAL NETWORK,"A system and method for improving the prediction accuracy of a neural network is proposed. Prediction tasks derived from labeled video data are used to regularize the feature space of the neural network so that it encodes constraints of the physical world while also learning to solve the original task at hand. The videos are generated by instructing humans to perform actions according to predefined labels or descriptions, so that a wide variety of physically relevant motion patterns are available to regularize the network.",G06N 3/08,TWENTY BILLION NEURONS GMBH,"MEMISEVIC, Roland; YIANILOS, Peter; SOBTI, Sumeet","62/414,949 31.10.2016 US; 15/608,059 30.05.2017 US",CN-201780081578.6; CA-3041726; EP-2017864131
EP177122858,15191549,27.10.2015,3059699,24.08.2016,EP,NEURAL NETWORK TRAINING METHOD AND RECOGNITION APPARATUS,"Disclosed is a neural network training method and apparatus, and recognition method and apparatus. The neural network training apparatus receives data and train a neural network based on remaining hidden nodes obtained by excluding a reference hidden node from hidden nodes included in the neural network, wherein the reference hidden node maintains a value in a previous time interval until a subsequent time interval.",G06N 3/04; G06N 3/08; G10L 15/16; G10L 25/30,SAMSUNG ELECTRONICS CO LTD,YOO SANG HYUN; MOON TAESUP,20150025077 23.02.2015 KR,
WO2020070519,PCT/GB2019/052819,07.10.2019,WO/2020/070519,09.04.2020,WO,METHOD FOR DETECTING ADVERSE CARDIAC EVENTS,"A method (1) is described for training a machine learning model (2) to receive as input a time-resolved three-dimensional model (4) of a heart or a portion of a heart, and to output (3) a predicted time-to-event or a measure of risk for an adverse cardiac event. The method includes receiving a training set (5). The training set (5) includes a number of time-resolved three-dimensional models (41,..., 4N) of a heart or a portion of a heart. The training set (5) also includes, for each time-resolved three-dimensional model (41,..., 4N), corresponding outcome data (71,..., 7N) associated with the time- resolved three-dimensional model (41,..., 4N). The method (1) of training a machine learning model (2) also includes, using the training set (5) as input, training the machine learning model (2) to recognise latent representations (12) of cardiac motion which are predictive of an adverse cardiac event. The method (1) of training a machine learning model (2) also includes storing the trained machine learning model (2).",G16H 50/20; G16H 30/40; G06N 3/04; G06N 3/08; G06N 20/00,"IMPERIAL COLLEGE OF SCIENCE, TECHNOLOGY AND MEDICINE","BELLO, Ghalib A.; BIFFI, Carlo; DUAN, Jinming; DAWES, Timothy J.W.; RUECKERT, Daniel; O'REGAN, Declan P.",1816281.8 05.10.2018 GB,
WO2019232435,PCT/US2019/034994,31.05.2019,WO/2019/232435,05.12.2019,WO,CONVOLUTIONAL NEURAL NETWORK SYSTEMS AND METHODS FOR DATA CLASSIFICATION,"Classification of cancer condition, in a plurality of different cancer conditions, for a species, is provided in which, for each training subject in a plurality of training subjects, there is obtained a cancer condition and a genotypic data construct including genotypic information for the respective training subject. Genotypic constructs are formatted into corresponding vector sets comprising one or more vectors. Vector sets are provided to a network architecture including a convolutional neural network path comprising at least a first convolutional layer associated with a first filter that comprise a first set of filter weights and a scorer. Scores, corresponding to the input of vector sets into the network architecture, are obtained from the scorer. Comparison of respective scores to the corresponding cancer condition of the corresponding training subjects is used to adjust the filter weights thereby training the network architecture to classify cancer condition.",A61K 45/00; A61P 35/00; C40B 30/04; C40B 60/12; G06N 3/12; G06N 7/00,"GRAIL, INC.","NICULA, Virgil; VALOUEV, Anton; FILIPPOVA, Darya; LARSON, Matthew, H.; MAHER, M., Cyrus; PORTELA DOS SANTOS PIMENTEL, Monica; CALEF, Robert Abe Paine; MELTON, Collin","62/679,746 01.06.2018 US",
WO2020027732,PCT/SG2019/050378,30.07.2019,WO/2020/027732,06.02.2020,WO,METHOD AND SYSTEM FOR ASSESSING FIBROSIS IN A TISSUE SAMPLE,"There is provided a method of assessing fibrosis in a tissue sample. The method includes: obtaining a stained image of a stained tissue sample, the stained tissue sample being stained in relation to collagen therein; producing a plurality of different types of collagen images based on the stained image, the plurality of different types of collagen images corresponding to a plurality of different types of collagen, respectively; determining a plurality of different types of collagen parameters based on the plurality of different types of collagen images using a deep neural network; and determining a degree of fibrosis in the stained tissue sample based on the plurality of different types of collagen parameters. The plurality of different types of collagen comprises portal collagen, fibrillary collagen and septal collagen. The different types of collagen images are produced by determining if the collagen satisfies a predetermined size condition or a predetermined distance condition with respect to a boundary of the portal tracts and central veins.",G16H 50/20; G06T 7/60,"AGENCY FOR SCIENCE, TECHNOLOGY AND RESEARCH","YU, Hanry; YU, Yang",10201806494Y 30.07.2018 SG,
WO2019191554,PCT/US2019/024777,29.03.2019,WO/2019/191554,03.10.2019,WO,ADAPTIVE PERMUTATION INVARIANT TRAINING WITH AUXILIARY INFORMATION FOR MONAURAL MULTI-TALKER SPEECH RECOGNITION,"Provided are a speech recognition training processing method and an apparatus including the same. The speech recognition training processing method includes acquiring a stream of speech data from one or more speakers, extracting an auxiliary feature corresponding to a speech characteristic of the one or more speaker and updating an acoustic model by performing permutation invariant training (PIT) model training based on the auxiliary feature.",G10L 15/00; G10L 15/06,TENCENT TECHNOLOGY (SHENZHEN) COMPANY LIMITED,"YU, Dong; QIAN, Yanmin","15/940,246 29.03.2018 US",
WO2018029028,PCT/EP2017/069365,01.08.2017,WO/2018/029028,15.02.2018,WO,ELECTRONIC CLINICAL DECISION SUPPORT DEVICE BASED ON HOSPITAL DEMOGRAPHICS,An electronic clinical decision support (CDS) device (10) employs a trained CDS algorithm (30) that operates on values of a set of covariates to output a prediction of a medical condition. The CDS algorithm was trained on a training data set (22). The CDS device includes a computer (12) that is programmed to provide a user interface (62) for completing clinical survey questions using the display and the one or more user input devices. Marginal probability distributions (42) for the covariates of the set of covariates are generated from the completed clinical survey questions. The trained CDS algorithm is adjusted for covariate shift using the marginal probability distributions. A prediction of the medical condition is generated for a medical subject using the trained CDS algorithm adjusted for covariate shift (50) operating on values for the medical subject of the covariates of the set of covariates.,G06F 19/00,KONINKLIJKE PHILIPS N.V.,"CONROY, Bryan; POTES BLANDON, Cristhian Mauricio; XU, Minnan",62/371886 08.08.2016 US,JP-2019506358; EP-2017748455; CN-201780048722.6
WO2018107128,PCT/US2017/065475,08.12.2017,WO/2018/107128,14.06.2018,WO,SYSTEMS AND METHODS FOR AUTOMATING DATA SCIENCE MACHINE LEARNING ANALYTICAL WORKFLOWS,Systems and methods for automating data science machine learning using analytical workflows are disclosed that provide for user interaction and iterative analysis including automated suggestions based on at least one analysis of a dataset.,G06F 15/18; G06Q 10/06; G06N 5/00,"U2 SCIENCE LABS, INC.","MINKIN, Andrew M.; MCNALLY, Mark; KNIGHT, William; MAJOR, Stephane; LAMOREAUX, Richard; HERNANDEZ, Leandro","62/432,558 09.12.2016 US",
WO2018200072,PCT/US2018/020101,28.02.2018,WO/2018/200072,01.11.2018,WO,CYCLIC GENERATIVE ADVERSARIAL NETWORK FOR UNSUPERVISED CROSS-DOMAIN IMAGE GENERATION,A system is provided for unsupervised cross-domain image generation relative to a first and second image domain that each include real images. A first generator generates synthetic images similar to real images in the second domain while including a semantic content of real images in the first domain. A second generator generates synthetic images similar to real images in the first domain while including a semantic content of real images in the second domain. A first discriminator discriminates real images in the first domain against synthetic images generated by the second generator. A second discriminator discriminates real images in the second domain against synthetic images generated by the first generator. The discriminators and generators are deep neural networks and respectively form a generative network and a discriminative network in a cyclic GAN framework configured to increase an error rate of the discriminative network to improve synthetic image quality.,G06K 9/62; G06N 3/02,"NEC LABORATORIES AMERICA, INC.","CHOI, Wongun; SCHULTER, Samuel; SOHN, Kihyuk; CHANDRAKER, Manmohan","62/489,529 25.04.2017 US; 15/906,710 27.02.2018 US",JP-2019546011; DE-112018002166
WO2018229490,PCT/GB2018/051631,14.06.2018,WO/2018/229490,20.12.2018,WO,A SYSTEM AND COMPUTER-IMPLEMENTED METHOD FOR SEGMENTING AN IMAGE,"A computer-implemented method for segmenting an input image, the method comprises: generating a first segmentation of the input image using a first machine learning system, the first segmentation comprising multiple segments; receiving, from a user, at least one indication, wherein each indication corresponds to a particular segment from the multiple segments, and indicates one or more locations of the input image as belonging to that particular segment; constructing, for each segment of the multiple segments having at least one corresponding indication, a respective geodesic distance map, based on the input image and the user indications received for that segment; and generating a second segmentation using a second machine learning system based on the input image and the constructed geodesic distance maps.",G06T 7/00; G06T 7/11,UCL BUSINESS LTD,"WANG, Guotai; VERCAUTEREN, Tom; OURSELIN, Sebastien; LI, Wenqi; FIDON, Lucas",1709672.8 16.06.2017 GB,EP-2018734897
WO2018212918,PCT/US2018/028743,21.04.2018,WO/2018/212918,22.11.2018,WO,HYBRID REWARD ARCHITECTURE FOR REINFORCEMENT LEARNING,"Aspects provided herein are relevant to machine learning techniques, including decomposing single-agent reinforcement learning problems into simpler problems addressed by multiple agents. Actions proposed by the multiple agents are then aggregated using an aggregator, which selects an action to take with respect to an environment. Aspects provided herein are also relevant to a hybrid reward model.",G06N 3/04; G06N 3/08; G06N 3/00,"MICROSOFT TECHNOLOGY LICENSING, LLC","VAN SEIJEN, Harm Hendrik; FATEMI BOOSHEHRI, Seyed Mehdi; LAROCHE, Romain Michel Henri; ROMOFF, Joshua Samuel","62/508,340 18.05.2017 US; 62/524,461 23.06.2017 US; 15/634,914 27.06.2017 US",EP-2018723249
WO2020018370,PCT/US2019/041590,12.07.2019,WO/2020/018370,23.01.2020,WO,MULTI-MODAL ELECTRONIC DOCUMENT CLASSIFICATION,"A method comprising operating at least one hardware processor for: receiving, as input, a plurality of electronic documents, training a machine learning classifier based, at least on part, on a training set comprising: (i) labels associated with the electronic documents, (ii) raw text from each of said plurality of electronic documents, and (iii) a rasterized version of each of said plurality of electronic documents, and applying said machine learning classifier to classify one or more new electronic documents.",G06K 9/00; G06K 9/46; G06K 9/62,"NETAPP, INC.","LEIBOVITZ, Guy; BALI, Adam","62/698,168 15.07.2018 US; 16/037,194 17.07.2018 US; 16/271,847 10.02.2019 US",
WO2019200748,PCT/CN2018/095497,12.07.2018,WO/2019/200748,24.10.2019,WO,"TRANSFER LEARNING METHOD, DEVICE, COMPUTER DEVICE, AND STORAGE MEDIUM","A transfer learning method: marked data of a specified task is inputted into a task training model for training to acquire a first parameter; the first parameter is locked, unmarked data and the marked data are mixed and inputted into a domain classification network to acquire a second parameter; the second parameter is locked, a domain classifier and the task training model jointly train a feature extraction layer to acquire a third parameter making no distinction between data of the feature extraction layer; and a recognition is performed with respect to the unmarked data on the basis of the third parameter.",G06K 9/62,"PING AN TECHNOLOGY (SHENZHEN) CO., LTD.; 平安科技（深圳）有限公司","HAN, Maokun; 韩茂琨; WANG, Jianzong; 王健宗; XIAO, Jing; 肖京",201810345254.5 17.04.2018 CN,
WO2020068141,PCT/US2018/062050,20.11.2018,WO/2020/068141,02.04.2020,WO,PREDICTED VARIABLES IN PROGRAMMING,"The present disclosure is directed to a new framework the enables the combination of symbolic programming with machine learning, where the programmer maintains control of the overall architecture of the functional mapping and the ability to inject domain knowledge while allowing their program to evolve by learning from examples. In some instances, the framework provided herein can be referred to as ""predictive programming.""",G06N 20/00; G06N 5/00,GOOGLE LLC,"YAGNIK, Jay; DARIN, Aleksandr; COPPEY, Thierry; DESELAERS, Thomas; CARBUNE, Victor","62/737,048 26.09.2018 US",
WO2020028382,PCT/US2019/044166,30.07.2019,WO/2020/028382,06.02.2020,WO,"MULTI-MODAL, MULTI-RESOLUTION DEEP LEARNING NEURAL NETWORKS FOR SEGMENTATION, OUTCOMES PREDICTION AND LONGITUDINAL RESPONSE MONITORING TO IMMUNOTHERAPY AND RADIOTHERAPY","Systems and methods for multi-modal, multi-resolution deep learning neural networks for segmentation, outcomes prediction and longitudinal response monitoring to immunotherapy and radiotherapy are detailed herein. A structure-specific Generational Adversarial Network (SSGAN) is used to synthesize realistic and structure-preserving images not produced using state-of-the art GANs and simultaneously incorporate constraints to produce synthetic images. A deeply supervised, Multi-modality, Multi-Resolution Residual Networks (DeepMMRRN) for tumor and organs-at-risk (OAR) segmentation may be used for tumor and OAR segmentation. The DeepMMRRN may combine multiple modalities for tumor and OAR segmentation. Accurate segmentation is may be realized by maximizing network capacity by simultaneously using features at multiple scales and resolutions and feature selection through deep supervision. DeepMMRRN Radiomics may be used for predicting and longitudinal monitoring response to immunotherapy. Auto-segmentations may be combined with radiomics analysis for predicting response prior to treatment initiation. Quantification of entire tumor burden may be used for automatic response assessment.",G06T 11/00; A61B 5/055; A61B 6/03; G06N 3/04; G06N 3/08; G06N 20/00; G06T 7/00,MEMORIAL SLOAN KETTERING CANCER CENTER,"DEASY, Joseph O.; VEERARAGHAVAN, Harini; HU, Yu-Chi; MAGERAS, Gig; JIANG, Jue","62/712,175 30.07.2018 US",
WO2019032622,PCT/US2018/045676,07.08.2018,WO/2019/032622,14.02.2019,WO,LONG-TERM AND CONTINUOUS ANIMAL BEHAVIORAL MONITORING,"Systems and methods for continuous monitoring of the behavior of animals, such as small rodents, are provided. Monitoring can include video, audio, and other sensor modalities. In one embodiment, the system can include cameras, arena design, environmental sensors, and ultrasonic sensors. The system uniquely provides a continuous long-term monitoring system suitable for mouse behavioral study. Further provided is a neural network based tracker configured for use with video data acquired by the monitoring system. 3 different neural network architectures have been tested to determine their performance on genetically diverse mice under varying environmental conditions. It has been observed that that an encoder- decoder segmentation neural network achieves high accuracy and speed with minimal training data. This general purpose neural network tracker can be easily extended to other experimental paradigms and even to other animals through transfer learning, thus forming a robust, generalizable solution for bio-behavioral research.",A01K 1/03; A01K 11/00; A01K 29/00; G06K 9/46; G06K 9/66,THE JACKSON LABORATORY,"KUMAR, Vivek; GEUTHER, Brian, Q.; PETERSON, Jim; CHURCHILL, Gary","62/661,610 23.04.2018 US; 62/542,180 07.08.2017 US",EP-2018843419
WO2018176035,PCT/US2018/024354,26.03.2018,WO/2018/176035,27.09.2018,WO,METHOD AND SYSTEM OF BUILDING HOSPITAL-SCALE CHEST X-RAY DATABASE FOR ENTITY EXTRACTION AND WEAKLY-SUPERVISED CLASSIFICATION AND LOCALIZATION OF COMMON THORAX DISEASES,"A new chest X-ray database, referred to as ""ChestX-ray8"", is disclosed herein, which comprises over 100,000 frontal view X-ray images of over 32,000 unique patients with the text-mined eight disease image labels (where each image can have multi-labels), from the associated radiological reports using natural language processing. We demonstrate that these commonly occurring thoracic diseases can be detected and spatially-located via a unified weakly supervised multi-label image classification and disease localization framework, which is validated using our disclosed dataset.",G06F 19/00; G06T 7/00; G06N 3/08; G06K 9/46; A61B 5/05,"THE UNITED OF AMERICA, AS REPRESENTED BY THE SECRETARY, DEPARTMENT OF HEALTH AND HUMAN SERVICES","WANG, Xiaosong; PENG, Yifan; LU, Le; LU, Zhiyong; SUMMERS, Ronald M.","62/476,029 24.03.2017 US",
EP250876582,18156676,14.02.2018,3528178,21.08.2019,EP,"METHOD FOR ADAPTING A FUNCTIONAL DESCRIPTION FOR A VEHICLE'S COMPONENT TO BE OBSERVED, COMPUTER PROGRAM AND COMPUTER READABLE MEDIUM",,G06N 3/04; G06N 3/08,SIEMENS AG,SIVALINGAM UDHAYARAJ; TAYLOR MICHAEL,18156676 14.02.2018 EP,
EP241674969,18203331,30.10.2018,3477549,01.05.2019,EP,COMPUTER VISION ARCHITECTURE WITH MACHINE LEARNED IMAGE RECOGNITION MODELS,"In an example, a first machine learning algorithm is used to train a smart contour model to identify contours of product shapes in input images and to identify backgrounds in the input images. A second machine learning algorithm is used to train a plurality of shape-specific classification models to output identifications of products in input images. A candidate image of one or more products is obtained. The candidate image is passed to the smart contour model, obtaining output of one or more tags identifying product contours in the candidate image. The candidate image and the one or more tags are passed to an ultra-large scale multi-hierarchy classification system to identify one or more classification models for one or more individual product shapes in the candidate image. The one or more classification models are used to distinguish between one or more products and one or more unknown products in the image.",G06K 9/46; G06K 9/00; G06K 9/32; G06K 9/34; G06K 9/62; G06N 3/04,SAP SE,N SIVAKUMAR; A K PRAVEENKUMAR; D RAGHAVENDRA; G VIJAY; SHENOY PRATIK; KEDIA KISHAN KUMAR,201715797117 30.10.2017 US,
WO2019125799,PCT/US2018/064688,10.12.2018,WO/2019/125799,27.06.2019,WO,LEVERAGING ENDPOINT AND NETWORK ENVIRONMENT INFERENCES FOR MALWARE TRAFFIC CLASSIFICATION,"In one embodiment, a device obtains simulation environment data regarding traffic generated within a simulation environment in which malware is executed. The device trains a malware detector using the simulation environment data. The device obtains deployment environment characteristics of a network to which the malware detector is to be deployed. The device configures the malware detector to ignore data in the simulation environment data that is associated with one or more environment characteristics that are not present in the deployment environment characteristics.",H04L 29/06; H04L 12/24,"CISCO TECHNOLOGY, INC.","ANDERSON, Blake, Harrell; REHAK, Martin; MCGREW, David; VEJMAN, Martin; PEVNY, Tomas; GRILL, Martin; KOHOUT, Jan","15/851,918 22.12.2017 US",
WO2019239153,PCT/GB2019/051666,14.06.2019,WO/2019/239153,19.12.2019,WO,IMMEDIATE WORKUP,"The present invention relates to deep learning implementations for medical imaging. More particularly, the present invention relates to a method and system for indicating whether additional medical tests are required after analysing an initial medical screening, in substantially real-time. Aspects and/or embodiments seek to provide a method and system for recommending additional medical tests, in substantially real-time, based on analysing an initial medical scan, with the use of deep learning.",A61B 6/00; G06T 7/10; G16H 30/20; G16H 40/63; G16H 40/60; G16H 50/00; G06T 7/00,KHEIRON MEDICAL TECHNOLOGIES LTD,"KECSKEMETHY, Peter; RIJKEN, Tobias; KARPATI, Edith; O'NEILL, Michael; HEINDL, Andreas; YEARSLEY, Joseph Elliot; KORKINOF, Dimitrios; KHARA, Galvin",1809796.4 14.06.2018 GB; 1819329.2 27.11.2018 GB; 1900212.0 07.01.2019 GB,
WO2019071754,PCT/CN2017/113068,27.11.2017,WO/2019/071754,18.04.2019,WO,METHOD FOR SENSING IMAGE PRIVACY ON THE BASIS OF DEEP LEARNING,"Provided in the present invention is a method for sensing image privacy on the basis of deep learning, comprising the following steps: S1, constructing a privacy classification data set labeled with classifications, and training a privacy sensing network by means of a transfer learning method; S2, completing identification of a private image using a deep convolutional neural network oriented toward privacy sensing; and S3, extracting an attention distribution graph according to deep convolutional features of the neural network, and locating an attention focusing region, so as to complete sensing of a private region of an image. The present invention completes end-to-end training and testing on the basis of a deep neural network, thereby achieving accurate classification of a private image and locating of a private region in the image and facilitating selective protection of private information in an image.",G06K 9/62; G06F 21/62,HARBIN INSTITUTE OF TECHNOLOGY SHENZHEN GRADUATE SCHOOL; 哈尔滨工业大学深圳研究生院,"WANG, Hongpeng; 王鸿鹏; ZHANG, Yang; 张阳; YOU, Lei; 尤磊; HE, Huamen; 何华门; HUANG, Xingsen; 黄兴森",201710928967.X 09.10.2017 CN,
WO2020028257,PCT/US2019/043927,29.07.2019,WO/2020/028257,06.02.2020,WO,DEEP LEARNING TECHNIQUES FOR MAGNETIC RESONANCE IMAGE RECONSTRUCTION,"A magnetic resonance imaging (MRI) system, comprising: a magnetics system comprising: a Bo magnet configured to provide a Bo field for the MRI system; gradient coils configured to provide gradient fields for the MRI system; and at least one RF coil configured to detect magnetic resonance (MR) signals; and a controller configured to: control the magnetics system to acquire MR spatial frequency data using non-Cartesian sampling; and generate an MR image from the acquired MR spatial frequency data using a neural network model comprising one or more neural network blocks including a first neural network block, wherein the first neural network block is configured to perform data consistency processing using a non-uniform Fourier transformation.",G01R 33/56; G01R 33/48; G06K 9/40; G06N 3/04; G06T 5/00; A61B 5/055; G06N 3/08; G01R 33/561,"HYPERFINE RESEARCH, INC.; WANG, Ziyi; KUNDU, Prantik; SACOLICK, Laura; SOFKA, Michal; ROTHBERG, Jonathan, M.; SCHLEMPER, Jo; MOSHEN SALEHI, Seyed, Sadegh; LAZARUS, Carole; DYVORNE, Hadrien, A.; O'HALLORAN, Rafael; 4CATALYZER CORPORATION","WANG, Ziyi; KUNDU, Prantik; SACOLICK, Laura; SOFKA, Michal; ROTHBERG, Jonathan, M.; SCHLEMPER, Jo; MOSHEN SALEHI, Seyed, Sadegh; LAZARUS, Carole; DYVORNE, Hadrien, A.; O'HALLORAN, Rafael","62/711,895 30.07.2018 US; 62/744,529 11.10.2018 US; 62/737,524 27.09.2018 US; 62/820,119 18.03.2019 US",
EP284291870,19191008,09.08.2019,3611672,19.02.2020,EP,MATERIAL SELECTION AND OPTIMIZATION PROCESS FOR COMPONENT MANUFACTURING,"A method for designing a material for an aircraft component includes training a neural network (10) to correlate microstructural features of an alloy with material properties of the alloy by at least providing a set of images of the alloy to the neural network. Each of the images in the set of images has varied constituent compositions. The method further includes providing the neural network (10) with a set of determined material properties corresponding to each image, associating the microstructural features of each image with the set of empirically determined data corresponding to the image, and determining non-linear relationships between the microstructural features and corresponding empirically determined material properties via a machine learning algorithm, receiving a set of desired material properties of the alloy for aircraft component, and determining a set of microstructural features capable of achieving the desired material properties of the alloy based on the determined non-linear relationships.",G06N 3/08; C22C 14/00; G06N 3/04,UNITED TECHNOLOGIES CORP,SOMANATH NAGENDRA; NORAAS RYAN B; GIERING MICHAEL J,201816104435 17.08.2018 US,
WO2020025696,PCT/EP2019/070669,31.07.2019,WO/2020/025696,06.02.2020,WO,METHOD AND SYSTEM FOR AUGMENTED IMAGING USING MULTISPECTRAL INFORMATION,"Disclosed herein is a method of generating augmented images of tissue of a patient, wherein each augmented image associates at least one tissue parameter with a region or pixel of the image of the tissue, said method comprising the following steps: obtaining one or more multispectral images of said tissue, and applying a machine learning based regressor or classifier, or an out of distribution (OoD) detection algorithm for determining information about the closeness of the multispectral image or parts of said multispectral image to a given training data set, or a change detection algorithm to at least a part of said one or more multispectral images, or an image derived from said multispectral image, or to a time sequence of multispectral images, parts of multiple images or images derived therefrom, to thereby derive one or more tissue parameters associated with image regions or pixels of the corresponding multispectral image.",G06T 7/00; G06T 7/254,DEUTSCHES KREBSFORSCHUNGSZENTRUM STIFTUNG DES ÖFFENTLICHEN RECHTS,"MAIER-HEIN, Lena; WIRKERT, Sebastian Josef; VEMURI, Anant Suraj; MENJIVAR, Leonardo Antonio Ayala; SEIDLITZ, Silvia; KIRCHNER, Thomas; ADLER, Tim",18186700.3 31.07.2018 EP,
WO2017223009,PCT/US2017/038209,20.06.2017,WO/2017/223009,28.12.2017,WO,MULTI-DOMAIN JOINT SEMANTIC FRAME PARSING,"A processing unit can train a model as a joint multi-domain recurrent neural network (JRNN), such as a bi-directional recurrent neural network (bRNN) and/or a recurrent neural network with long-short term memory (RNN-LSTM) for spoken language understanding (SLU). The processing unit can use the trained model to, e.g., jointly model slot filling, intent determination, and domain classification. The joint multi-domain model described herein can estimate a complete semantic frame per query, and the joint multi-domain model enables multi-task deep learning leveraging the data from multiple domains. The joint multi-domain recurrent neural network (JRNN) can leverage semantic intents (such as, finding or identifying, e.g., a domain specific goal) and slots (such as, dates, times, locations, subjects, etc.) across multiple domains.",G10L 15/22; G10L 15/18; G10L 15/16,"MICROSOFT TECHNOLOGY LICENSING, LLC","HAKKANI-TUR, Dilek, Z.; CELIKYILMAZ, Asli; CHEN, Yun-Nung; DENG, Li; GAO, Jianfeng; TUR, Gokhan; WANG, Ye-Yi","62/354,064 23.06.2016 US; 15/228,990 04.08.2016 US",
WO2020028036,PCT/US2019/041992,16.07.2019,WO/2020/028036,06.02.2020,WO,ROBUST VON NEUMANN ENSEMBLES FOR DEEP LEARNING,"Computer-implemented systems and methods build and train an ensemble of machine learning systems to be robust against adversarial attacks by employing a probabilistic mixed strategy with the property that, even if the adversary knows the architecture and parameters of the machine learning system, any adversarial attack has an arbitrarily low probability of success.",G06F 7/58; G06F 21/55; G06N 3/04; G06N 3/08,D5AI LLC,"BAKER, James K.","62/713,282 01.08.2018 US",
WO2020062911,PCT/CN2019/090092,05.06.2019,WO/2020/062911,02.04.2020,WO,ACTOR ENSEMBLE FOR CONTINUOUS CONTROL,"A method of training a reinforcement learning agent to output actions from a continuous action space, comprising: providing an actor ensemble that includes a plurality of actor neural networks that each output a respective action from the continuous action space in response to an observed state of an environment; providing a critic neural network that approximates a state-action value function indicating an impact of an action on the environment based on a reward from the environment and the observed state of the environment; training the actor ensemble and the critic neural network to maximize a state-action value from the state-action value function over successive time steps by, in each time step: selecting from the respective actions output by the plurality of actor neural networks the action that will provide a best state-action value from the state-action value function; applying the selected action to the environment; based on an observed state of the environment of in response to the selected action, determine a gradient ascent for the plurality of actor neural networks for updating the parameters of the plurality of actor neural networks and determine a gradient descent for the critic neural network for updating the parameters of the critic neural network.",G06N 3/08,"HUAWEI TECHNOLOGIES CO., LTD.","ZHANG, Shangtong; YAO, Hengshuai; CHEN, Hao","62/736,914 26.09.2018 US",
WO2019089339,PCT/US2018/057485,25.10.2018,WO/2019/089339,09.05.2019,WO,METHOD AND SYSTEM FOR NEURAL NETWORK SYNTHESIS,"According to various embodiments, a method for generating one or more optimal neural network architectures is disclosed. The method includes providing an initial seed neural network architecture and utilizing sequential phases to synthesize the neural network until a desired neural network architecture is reached. The phases include a gradient-based growth phase and a magnitude-based pruning phase.",G06N 3/02; G06F 15/18,THE TRUSTEES OF PRINCETON UNIVERSITY,"DAI, Xiaoliang; YIN, Hongxu; JHA, Niraj, K.","62/580,525 02.11.2017 US",
WO2019225837,PCT/KR2019/002406,28.02.2019,WO/2019/225837,28.11.2019,WO,METHOD FOR LEARNING CROSS DOMAIN PERSONALIZED VOCABULARY AND ELECTRONIC DEVICE THEREOF,"A method for operating an electronic device includes detecting a first natural language (NL) input, determining a skill from the first NL input, if the NL input includes at least one unique skill word, transmitting the first NL input to a custom skill parser for determination of a skill intent, wherein the custom skill parser is trained based on data including at least a custom training data set, and if the NL input does not includes the at least one unique skill word, transmitting the first NL input to a generic parser for determination of a general intent of the first NL input.",G06F 17/27; G10L 15/22,"SAMSUNG ELECTRONICS CO., LTD.","RAY, Avik; SHEN, Yilin; JIN, Hongxia","15/986,633 22.05.2018 US",
WO2020033966,PCT/US2019/046207,12.08.2019,WO/2020/033966,13.02.2020,WO,DEEP LEARNING AND INTELLIGENT SENSING SYSTEM INTEGRATION,"Disclosed herein are systems, methods, and apparatuses for deep learning and intelligent sensing system integrations. A processor may be configured to receive a plurality of images from the sensor system, identify objects in the images in an offline mode, classify the objects in the images in the offline mode, generate heat maps in the offline mode, and send instructions regarding operation of the maritime vessel based on the objects that are identified. The visual sensor may be a stereoscopic camera. The processor may be further configured to perform stereoscopy. The instructions may include a speed or a heading of, for example, a maritime vessel.",G05D 1/02; G01S 17/89; G05D 1/00; G06K 9/62,BUFFALO AUTOMATION GROUP INC.,"SURESH, Thiru Vikram; KHAKHARIA, Mohit Arvind","16/537,172 09.08.2019 US; 62/717,744 10.08.2018 US",
WO2020024646,PCT/CN2019/086387,10.05.2019,WO/2020/024646,06.02.2020,WO,MONAURAL MULTI-TALKER SPEECH RECOGNITION WITH ATTENTION MECHANISM AND GATED CONVOLUTIONAL NETWORKS,"Provided are a speech recognition training processing method and an apparatus including the same. The speech recognition training processing method includes acquiring multi-talker mixed speech sequence data corresponding to a plurality of speakers, encoding the multi-speaker mixed speech sequence data into an embedded sequence data, generating speaker specific context vectors at each frame based on the embedded sequence, generating senone posteriors for each of the speaker based on the speaker specific context vectors and updating an acoustic model by performing permutation invariant training (PIT) model training based on the senone posteriors.",G10L 17/18; G10L 21/0272,TENCENT TECHNOLOGY (SHENZHEN) COMPANY LIMITED,"QIAN, Yanmin; YU, Dong","16/050,825 31.07.2018 US",
EP236801784,18156212,12.02.2018,3435294,30.01.2019,EP,SYSTEMS AND METHODS FOR SOLVING INVERSE PROBLEMS USING A COUPLED AUTOENCODER,"Motion blur occur when acquiring images and videos with cameras fitted to the high speed motion devices, for example, drones. Distorted images intervene with the mapping of the visual points, hence the pose estimation and tracking may get corrupted. System and method for solving inverse problems using a coupled autoencoder is disclosed. In an embodiment, solving inverse problems, for example, generating a clean sample from an unknown corrupted sample is disclosed. The coupled autoencoder learns the autoencoder weights and coupling map (between source and target) simultaneously. The technique is applicable to any transfer learning problem. The embodiments of the present disclosure implements/proposes a new formulation that recasts deblurring as a transfer learning problem which is solved using the proposed coupled autoencoder.",G06N 3/04; G06T 5/00,TATA CONSULTANCY SERVICES LTD,GUPTA KAVYA; BHOWMICK BROJESHWAR; MAJUMDAR ANGSHUL,201721026251 24.07.2017 IN,
WO2018128653,PCT/US2017/053230,25.09.2017,WO/2018/128653,12.07.2018,WO,SYSTEM AND METHOD FOR DESIGNING SYSTEM ON CHIP (SOC) CIRCUITS THROUGH ARTIFICIAL INTELLIGENCE AND REINFORCEMENT LEARNING,"The embodiments herein discloses a system and method for designing SoC using AI and Reinforcement Learning (RL) techniques. Reinforcement Learning is done either hierarchically in Several steps or in a single-step comprising environment, tasks, agents and experiments, to have access to SoC (System on a Chip) related information. The AI agent is configured to learn from the interaction and plan the implementation of a SoC circuit design, Q values generated for each domain and sub domain are stored in a hierarchical SMDP structure in a form of SMDP Q table in a big data database. An optimal chip architecture corresponding to a maximum Q value of a top level in the SMDP Q table is acquired and stored in a database for learning and inference. Desired SoC configuration is optimized and generated based on the optimal chip architecture and the generated chip specific graph library.",G06F 15/18,ALPHAICS CORPORATION,"NAGARAJA, Nagendra","62/443,803 08.01.2017 US; 15/499,832 27.04.2017 US",JP-2019558330; EP-2017889850
WO2016145379,PCT/US2016/022127,11.03.2016,WO/2016/145379,15.09.2016,WO,Automated Compilation of Probabilistic Task Description into Executable Neural Network Specification,"A mechanism for compiling a generative description of an inference task into a neural network. First, an arbitrary generative probabilistic model from the exponential family is specified (or received). The model characterizes a conditional probability distribution for measurement data given a set of latent variables. A factor graph is generated for the generative probabilistic model. Each factor node of the factor graph is expanded into a corresponding sequence of arithmetic operations, based on a specified inference task and a kind of message passing algorithm. The factor graph and the sequences of arithmetic operations specify the structure of a neural network for performance of the inference task. A learning algorithm is executed, to determine values of parameters of the neural network. The neural network is then ready for performing inference on operational measurements.",G06F 19/00; G06N 3/02; G10L 15/14,WILLIAM MARSH RICE UNIVERSITY,"PATEL, Ankit B.; BARANIUK, Richard G.","62/131,872 12.03.2015 US; 62/137,656 24.03.2015 US",
WO2018211138,PCT/EP2018/063275,22.05.2018,WO/2018/211138,22.11.2018,WO,MULTITASK NEURAL NETWORK SYSTEMS WITH TASK-SPECIFIC POLICIES AND A SHARED POLICY,"A method is proposed for training a multitask computer system, such as a multitask neural network system. The system comprises a set of trainable workers and a shared module. The trainable workers and shared module are trained on a plurality of different tasks, such that each worker learns to perform a corresponding one of the tasks according to a respective task policy, and said shared policy network learns a multitask policy which represents common behavior for the tasks. The coordinated training is performed by optimizing an objective function comprising, for each task: a reward term indicative of an expected reward earned by a worker in performing the corresponding task according to the task policy; and at least one entropy term which regularizes the distribution of the task policy towards the distribution of the multitask policy.",G06N 3/04; G06N 3/00; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"PASCANU, Razvan; HADSELL, Raia Thais; BAPST, Victor Constant; CZARNECKI, Wojciech; KIRKPATRICK, James; TEH, Yee Whye; HEESS, Nicolas Manfred Otto","62/508,991 19.05.2017 US",EP-2018726143
WO2015031576,PCT/US2014/053086,28.08.2014,WO/2015/031576,05.03.2015,WO,SYSTEMS AND METHODS FOR ESTIMATING PHYSIOLOGICAL HEART MEASUREMENTS FROM MEDICAL IMAGES AND CLINICAL DATA,"A method and system for estimating physiological heart measurements from medical images and clinical data disclosed. A patient-specific anatomical model of the heart is generated from medical image data of the patient. A patient-specific multi-physics computational heart model is generated based on the patient-specific anatomical model by personalizing parameters of a cardiac electrophysiology model, a cardiac biomechanics model, and a cardiac hemodynamics model based on medical image data and clinical measurements of the patient. Cardiac function of the patient is simulated using the patient-specific multi-physics computational heart model. The parameters can be personalized by inverse problem algorithms based on forward model simulations or the parameters can be personalized using a machine-learning based statistical model.",G06F 19/00; A61B 8/08; A61B 5/00; A61B 5/02; A61B 5/04; A61B 5/055; G06T 17/00; G09B 23/30,SIEMENS HEALTHCARE GMBH,"NEUMANN, Dominik; MANSI, Tommaso; GRBIC, Sasa; GEORGESCU, Bogdan; KAMEN, Ali; COMANICIU, Dorin; VOIGT, Ingmar","61/870,849 28.08.2013 US; 61/882,764 26.09.2013 US",US-14915478; CN-201480047428.X; KR-1020167008156
WO2019155065,PCT/EP2019/053327,11.02.2019,WO/2019/155065,15.08.2019,WO,NEURAL NETWORK SYSTEMS IMPLEMENTING CONDITIONAL NEURAL PROCESSES FOR EFFICIENT LEARNING,"According to a first aspect a network system to generate output data values from input data values according to one or more learned data distributions comprises an input to receive a set of observations, each comprising a respective first data value for a first variable and a respective second data value for a second variable dependent upon the first variable. The system may comprise an encoder neural network system configured to encode each observation of the set of observations to provide an encoded output for each observation. The system may further comprise an aggregator configured to aggregate the encoded outputs for the set of observations and provide an aggregated output. The system may further comprise a decoder neural network system configured to receive a combination of the aggregated output and a target input value and to provide a decoder output. The target input value may comprise a value for the first variable and the decoder output may predict a corresponding value for the second variable.",G06N 3/04; G06N 3/08; G06N 7/00,DEEPMIND TECHNOLOGIES LIMITED,"RAMALHO, Tiago Miguel Sargento Pires; ROSENBAUM, Dan; GARNELO, Marta; MADDISON, Christopher; ESLAMI, Seyed Mohammadali; TEH, Yee Whye; REZENDE, Danilo Jimenez","62/628,899 09.02.2018 US",
WO2018071389,PCT/US2017/055891,10.10.2017,WO/2018/071389,19.04.2018,WO,VERY DEEP CONVOLUTIONAL NEURAL NETWORKS FOR END-TO-END SPEECH RECOGNITION,"A speech recognition neural network system includes an encoder neural network and a decoder neural network. The encoder neural network generates an encoded sequence from an input acoustic sequence that represents an utterance. The input acoustic sequence includes a respective acoustic feature representation at each of a plurality of input time steps, the encoded sequence includes a respective encoded representation at each of a plurality of time reduced time steps, and the number of time reduced time steps is less than the number of input time steps. The encoder neural network includes a time reduction subnetwork, a convolutional LSTM subnetwork, and a network in network subnetwork. The decoder neural network receives the encoded sequence and processes the encoded sequence to generate, for each position in an output sequence order, a set of substring scores that includes a respective substring score for each substring in a set of substrings.",G10L 15/16; G06N 3/04,GOOGLE LLC,"JAITLY, Navdeep; ZHANG, Yu; CHAN, William","62/406,345 10.10.2016 US",CN-201780069463.5; EP-2017788050; JP-2019518455
WO2019185981,PCT/FI2019/050214,13.03.2019,WO/2019/185981,03.10.2019,WO,GENERATING OR OBTAINING AN UPDATED NEURAL NETWORK,"Generating or Obtaining an Updated Neural Network A method and apparatus is described comprising: obtaining or generating an updated multi- unit neural network from a base neural network, wherein the updated neural network is generated by updating weights within a plurality of units of the base neural network, wherein each of the plurality of units is any of a neural network layer, a neural network filter or a neural network node; obtaining an order of unit updates for converting the base neural network into the updated neural network unit-by-unit, wherein the order of layer updates is based on a metric; and providing neural network updating information, wherein the neural network updating information includes data relating to said order.",G06N 3/08; H04L 29/08; H04L 12/24; G06F 8/658; H04W 8/24; G06F 11/07,NOKIA TECHNOLOGIES OY,"CRICRI, Francesco; FAN, Lixin; AYTEKIN, Caglar",1804866.0 27.03.2018 GB,
WO2018013495,PCT/US2017/041408,10.07.2017,WO/2018/013495,18.01.2018,WO,AUGMENTED REALITY METHODS AND DEVICES,"Augmented reality methods and systems are described. According to one aspect, an augmented reality computer system includes processing circuitry configured to access an image of the real world, wherein the image includes a real world object, and evaluate the image using a neural network to determine a plurality of augmented reality estimands which are indicative of a pose of the real world object and which are useable to generate augmented content regarding the real world object. Other methods and systems are disclosed including additional aspects directed towards training and using neural networks.",G06F 17/00; G06K 9/00; G06K 9/62,"GRAVITY JACK, INC.","RICHEY, Aaron, Luke; RIDGWAY, Randall, Sewell; POINDEXTER, Shawn, David; ROLLINS, Marc, Andrew; ABEL, Joshua, Adam","62/360,889 11.07.2016 US",
WO2019201726,PCT/EP2019/059208,11.04.2019,WO/2019/201726,24.10.2019,WO,ADAPTIVE ULTRASOUND SCANNING,"The present disclosure describes imaging systems configured to generate adaptive scanning protocols based on anatomical features and conditions identified during a prenatal scan of an object. Systems may include an ultrasound transducer configured to acquire echo signals responsive to ultrasound pulses transmitted toward a target region. Processors coupled with the transducer can generate an image frame from the echoes and provide the image frame to a first neural network. The first neural network may be configured to identify an anatomical feature in the image frame. An indication of the anatomical feature may be provided a second neural network. The second neural network may then determine an anatomical measurement to be obtained based, in part, on the feature identified. The processors may be further configured to cause an indicator of the anatomical measurement to be obtained to be displayed on a user interface.",A61B 8/08; A61B 5/107; G06T 7/00,KONINKLIJKE PHILIPS N.V.,"CANFIELD, Earl, M.; NGUYEN, Man; XIE, Hua",62/660332 20.04.2018 US,
EP289344306,19194538,30.08.2019,3617943,04.03.2020,EP,MULTIVARIATE AND MULTI-RESOLUTION RETINAL IMAGE ANOMALY DETECTION SYSTEM,"Machine learning technologies are used to identify and separating abnormal and normal subjects and identifying possible disease types with images (e.g., optical coherence tomography (OCT) images of the eye), where the machine learning technologies are trained with only normative data. In one example, a feature or a physiological structure of an image is extracted, and the image is classified based on the extracted feature. In another example, a region of the image is masked and then reconstructed, and a similarity is determined between the reconstructed region and the original region of the image. A label (indicating an abnormality) and a score (indicating a severity) can be determined based on the classification and/or the similarity.",G06K 9/00,TOPCON CORP,YANG QI; ZERIHUN BISRAT; REISMAN CHARLES A,201862724864 30.08.2018 US; 201916552467 27.08.2019 US,
WO2017015390,PCT/US2016/043172,20.07.2016,WO/2017/015390,26.01.2017,WO,"DEEP MULTI-TASK LEARNING FRAMEWORK FOR FACE DETECTION, LANDMARK LOCALIZATION, POSE ESTIMATION, AND GENDER RECOGNITION","Various image processing may benefit from the application deep convolutional neural networks. For example, a deep multi-task learning framework may assist face detection, for example when combined with landmark localization, pose estimation, and gender recognition. An apparatus can include a first module of at least three modules configured to generate class independent region proposals to provide a region. The apparatus can also include a second module of the at least three modules configured to classify the region as face or non-face using a multi-task analysis. The apparatus can further include a third module configured to perform post- processing on the classified region.",G06K 9/00; G06K 9/46; G06K 9/66; G06K 9/68,"UNIVERSITY OF MARYLAND, COLLEGE PARK","RANJAN, Rajeev; PATEL, Vishal M.; CHELLAPPA, Ramalingam; CASTILLO, Carlos D.","62/194,598 20.07.2015 US; 62/258,788 23.11.2015 US",US-15746237
WO2020006259,PCT/US2019/039547,27.06.2019,WO/2020/006259,02.01.2020,WO,WEARABLE SYSTEM FOR BRAIN HEALTH MONITORING AND SEIZURE DETECTION AND PREDICTION,"The present disclosure provides for monitoring brain health and predicting and detecting seizures via a wearable head apparatus. An exemplary system includes a wearable head apparatus with a plurality of sensors. The system includes a memory device with instructions for performing a method. The method provides for first receiving electroencephalography (EEG) data and/or other data types output by the plurality of sensors. The EEG data includes electrical signals representing brain activity of a user. The method provides for processing the EEG data and/or other data types using a machine learning model to identify a time window of a subset of the EEG data and/or other data types, which represents a seizure. The method provides for tagging the time window as seizure data. A representation of the time window of the EEG data and/or other data types is then output.",A61B 5/0476,CORTEXXUS INC.,"ALVES, David; RAZAVI, Babak; DE JESUS ALVES, Ana Margarida","62/690,520 27.06.2018 US; 62/800,194 01.02.2019 US",
WO2017213398,PCT/KR2017/005862,05.06.2017,WO/2017/213398,14.12.2017,WO,LEARNING MODEL FOR SALIENT FACIAL REGION DETECTION,"One embodiment provides a method comprising receiving a first input image and a second input image. Each input image comprises a facial image of an individual. For each input image, a first set of facial regions of the facial image is distinguished from a second set of facial regions of the facial image based on a learning based model. The first set of facial regions comprises age-invariant facial features, and the second set of facial regions comprises age-sensitive facial features. The method further comprises determining whether the first input image and the second input images comprise facial images of the same individual by performing face verification based on the first set of facial regions of each input image.",G06K 9/00; G06K 9/62; G06K 9/48; G06N 3/08,"SAMSUNG ELECTRONICS CO., LTD.","WANG, Xiaolong; ZHOU, Yin; LI, Bo; CURREY, Jonathan J.","62/346,208 06.06.2016 US; 15/449,266 03.03.2017 US",CN-201780042954.0; EP-2017810521
WO2020037127,PCT/US2019/046659,15.08.2019,WO/2020/037127,20.02.2020,WO,SYSTEMS AND METHODS FOR MODELING AND CONTROLLING PHYSICAL DYNAMICAL SYSTEMS USING ARTIFICIAL INTELLIGENCE,"The present disclosure provides systems, methods, and computer program products for controlling an object. An example method can comprise (a) obtaining video data of the object and (b) performing motion analysis on the video data to generate modified video data. The method can further comprise (c) using artificial intelligence (AI) to identify a set of features in the modified video data. The set of features may be indicative of a predicted state of the object. The AI may be been trained offline on historical training data. The method can further comprise (d) using the predicted state to determine a control signal and (e) transmitting, in real-time, the control signal to the object to adjust or maintain a state of the object in relation to the predicted state. Operations (a) to (d) can be performed without contacting the object.",G06T 7/20; G06K 9/00; G06T 7/00,"DAUNTLESS.IO, INC.","VAUGHAN, Adam","62/719,296 17.08.2018 US",
WO2020008339,PCT/IB2019/055608,01.07.2019,WO/2020/008339,09.01.2020,WO,SENSING SYSTEM AND METHOD FOR MONITORING TIME-DEPENDENT PROCESSES,"Systems and methods for detecting the quality of signals captured by a sensor device monitoring a biological function. Sensor data associated with the sensor device is received, the sensor data representing time -series measurement samples of one or more parameters associated with the biological function, the sensor data including usable and unusable samples of the time- series measurements. Data representing two or more features of samples of the time-series measurements is extracted and filtered to reduce outliers in the extracted data based on an expected outlier ratio. A machine learning algorithm is then trained to identify events based on the filtered extracted data.",A61B 5/00; A61B 5/08; G06F 19/10; G06F 19/24; G16H 50/20; G16H 50/70,3M INNOVATIVE PROPERTIES COMPANY,"TAGHVAEEYAN, Saber; GOLNARI, Golshan; KADKHODAIE ELYADERANI, Mojtaba; SHANNON, Robert W.; BARTON, Roger W.; PACHAURI, Deepti","62/693,364 02.07.2018 US",
WO2017019555,PCT/US2016/043716,22.07.2016,WO/2017/019555,02.02.2017,WO,CONTINUOUS CONTROL WITH DEEP REINFORCEMENT LEARNING,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training an actor neural network used to select actions to be performed by an agent interacting with an environment. One of the methods includes obtaining a minibatch of experience tuples; and updating current values of the parameters of the actor neural network, comprising: for each experience tuple in the minibatch: processing the training observation and the training action in the experience tuple using a critic neural network to determine a neural network output for the experience tuple, and determining a target neural network output for the experience tuple; updating current values of the parameters of the critic neural network using errors between the target neural network outputs and the neural network outputs; and updating the current values of the parameters of the actor neural network using the critic neural network.",G06N 3/04,DEEPMIND TECHNOLOGIES LIMITED,"LILLICRAP, Timothy Paul; HUNT, Jonathan James; PRITZEL, Alexander; HEESS, Nicolas Manfred Otto; EREZ, Tom; TASSA, Yuval; SILVER, David; WIERSTRA, Daniel Pieter","62/196,854 24.07.2015 US",MX-MX/a/2018/000942; CA-2993551; JP-2018523386; KR-1020187005435; DE-112016003350; RU-2018106248; SG-11201800544U; EP-2016745383; IL-257103; AU-2016297852; GB-1802748.2
EP241923954,18203324,30.10.2018,3480786,08.05.2019,EP,MEDICAL IMAGE OBJECT DETECTION WITH DENSE FEATURE PYRAMID NETWORK ARCHITECTURE IN MACHINE LEARNING,"For object detection (56), deep learning (44) is applied with an architecture designed for low contrast objects, such as lymph nodes. The architecture uses a combination of dense deep learning or features, which employs feed-forward connections between convolutions layers (22), and a pyramidal arrangement of the dense deep learning using different resolutions.",G06T 7/00; G06T 7/11,SIEMENS HEALTHCARE GMBH,GEORGESCU BOGDAN; LIU SIQI; XU DAGUANG; COMANICIU DORIN; ZHOU SHAOHUA KEVIN; WENGROWSKI ERIC,201715802893 03.11.2017 US,
WO2020039121,PCT/FI2019/050589,19.08.2019,WO/2020/039121,27.02.2020,WO,METHOD AND SYSTEM FOR GENERATING ANNOTATED TRAINING DATA,"Disclosed is a method of generating an annotated synthetic training data for training a machine learning module for processing an operational data set. The method comprises creating a first procedural model for the object,the first procedural model having a first set of parameters relating to the object, creating a second procedural model for the background, the second procedural model having a second set of parameters relating to the background, creating the task environment model pertaining to the machine learning task using the first and the second procedural models; creating a synthetic data set using the task environment model; and allocating at least one parameter of the first set of parameters as an annotation for the simulation data to generate the annotated synthetic training data.",G06K 9/00; G06K 9/62; G06N 3/08; G06N 7/00; G06N 20/00; G06T 7/11; G06T 7/143; G06T 7/194,AALTO UNIVERSITY FOUNDATION SR.,"GILLBERG, Jussi; JUNTUNEN, Harri; WAGNER, Paul; LINTUSAARI, Jarno; NGUYEN, Linh",20185687 20.08.2018 FI,
EP240631210,18165197,29.03.2018,3467718,10.04.2019,EP,MACHINE LEARNING SYSTEM,"There is described a reinforcement learning system comprising an environment, and agent, and a learning routine. The environment has multiple possible states. The agent is arranged to receive state information indicative of a current state of the environment and to generate an action signal dependent on the state information and a policy associated with the agent, where the action signal is operable to cause a change in a state of the environment. The agent is further arranged to generate experience data dependent on the state information and information conveyed by the action signal. The learning routine is configured to process the experience data in order to update the policy associated with the agent. The reinforcement learning system further comprises a probabilistic model operable to generate, dependent on the current state of the environment, probabilistic data relating to future states of the environment, and the agent is further arranged to generate the action signal in dependence on the probabilistic data.",G06N 3/00; G06N 3/04; G06N 3/08; G06N 7/00,PROWLER IO LTD,ELEFTHERIADIS STEFANOS; HENSMAN JAMES; JOHN SEBASTIAN; SALIMBENI HUGH,17275185 21.11.2017 EP; 20170100448 04.10.2017 GR; 20180100074 20.02.2018 GR,
WO2019238976,PCT/EP2019/065876,17.06.2019,WO/2019/238976,19.12.2019,WO,IMAGE CLASSIFICATION USING NEURAL NETWORKS,"A computer-implemented method for training a neural network for classifying image data and a related computer program product are disclosed. A labelled input data set comprising a plurality of labelled image data samples is provided together with a neural network. The neural network comprises an input layer, at least one intermediate layer, and an output layer having one channel per label class. Each channel comprises a plurality of neurons of the output layer and is generating a multidimensional feature vector in response to an image data sample presented to the input layer of the neural network. Furthermore, the input layer of a decoder network for reconstructing image data samples at its output is connected to the output layer of the neural network. A classifier predicts class labels as the labels of those channels for which a normed distance of its corresponding feature vector relative to a pre-determined reference point is smallest. A loss function for the neural network is suitable for steering, for each channel, the feature vectors onto which image data samples of the associated class are mapped, into a convex region around the pre-determined reference point.",G06K 9/46; G06K 9/62,UNIVERSITÉ DE LIÈGE,"VAN DROOGENBROECK, Marc; DELIÈGE, Adrien; CIOPPA, Anthony",18178146.9 15.06.2018 EP,
WO2018081607,PCT/US2017/058825,27.10.2017,WO/2018/081607,03.05.2018,WO,METHODS OF SYSTEMS OF GENERATING VIRTUAL MULTI-DIMENSIONAL MODELS USING IMAGE ANALYSIS,"The present approach relates to the use of trained artificial neural networks, such as convolutional neural networks, to classify vascular structures, such as using a hierarchical classification scheme. In certain approaches, the artificial neural network is trained using training data that is all or partly derived from synthetic vascular representations.",G06T 17/20; G06T 7/00,"GENERAL ELECTRIC COMPANY; SANTAMARIA-PANG, Alberto; MEYER, Danial Eugene; MARINO, Michael Ernest; LI, Qing; DYLOV, Dmitry V.; CHOWDHURY, Aritra","SANTAMARIA-PANG, Alberto; MEYER, Danial Eugene; MARINO, Michael Ernest; LI, Qing; DYLOV, Dmitry V.; CHOWDHURY, Aritra","62/413,684 27.10.2016 US",
WO2019169455,PCT/AU2019/050212,08.03.2019,WO/2019/169455,12.09.2019,WO,METHOD AND SYSTEM FOR GUIDED RADIATION THERAPY,The present invention is concerned with a method and system for guiding a radiation therapy system. The method comprises: capturing an image of a target area to which radiation is to be delivered; analysing the image with a trained convolutional neural network to determine the position of one or more objects of interest present in the target area; and outputting the determined position/s to the radiation therapy system.,G06N 3/02; G06T 7/73; A61N 5/00; A61B 6/00,"NGUYEN, Doan Trang; KEALL, Paul; MYLONAS, Adam","NGUYEN, Doan Trang; KEALL, Paul; MYLONAS, Adam",2018900755 08.03.2018 AU,
EP283377999,17901932,21.03.2017,3605405,05.02.2020,EP,"SERVER DEVICE, TRAINED MODEL PROVIDING PROGRAM, TRAINED MODEL PROVIDING METHOD, AND TRAINED MODEL PROVIDING SYSTEM","A server device configured to communicate, via a communication network, with at least one device including a learner configured to perform processing by using a learned model, the server device including: a storage unit configured to store a plurality of shared models pre-learned in accordance with environments and conditions of various devices; a device data acquisition unit configured to acquire device data including information on an environment and conditions from the at least one device; a target shared model selection unit configured to select an optimum shared model for the at least one device based on acquired device data; and a transmitter configured to transmit a selected shared model to the at least one device.",G06N 99/00,PREFERRED NETWORKS INC,KAWAAI KEIGO; HIDO SHOHEI; KUBOTA NOBUYUKI; TANAKA DAISUKE,2017011216 21.03.2017 JP,
WO2019191306,PCT/US2019/024400,27.03.2019,WO/2019/191306,03.10.2019,WO,"TRAINING, TESTING, AND VERIFYING AUTONOMOUS MACHINES USING SIMULATED ENVIRONMENTS","In various examples, physical sensor data may be generated by a vehicle in a real-world environment. The physical sensor data may be used to train deep neural networks (DNNs). The DNNs may then be tested in a simulated environment - in some examples using hardware configured for installation in a vehicle to execute an autonomous driving software stack - to control a virtual vehicle in the simulated environment or to otherwise test, verify, or validate the outputs of the DNNs. Prior to use by the DNNs, virtual sensor data generated by virtual sensors within the simulated environment may be encoded to a format consistent with the format of the physical sensor data generated by the vehicle.",G06N 3/02; B62D 15/02; G05D 1/00; G06K 9/00; G06N 3/063; G06N 3/04,NVIDIA CORPORATION,"FARABET, Clement; ZEDLEWSKI, John; TAYLOR, Zachary; HEINRICH, Greg; DELAUNEY, Claire; DALY, Mark; CAMPBELL, Matthew; BEESON, Curtis; HICOK, Gary; COX, Michael; LEBAREDIAN, Rev; TAMASI, Tony; AULD, David","62/648,399 27.03.2018 US; 16/366,875 27.03.2019 US",
WO2019110583,PCT/EP2018/083473,04.12.2018,WO/2019/110583,13.06.2019,WO,DEEP-LEARNING SYSTEMS AND METHODS FOR JOINT CELL AND REGION CLASSIFICATION IN BIOLOGICAL IMAGES,The present disclosure relates to automated systems and methods for training a multilayer neural network to jointly and simultaneously classify cells and regions from a set of training images. The present disclosure also relates to automated systems and methods for using a trained multilayer neural network to classify cells within an unlabeled image.,G06K 9/00; G06K 9/62,"VENTANA MEDICAL SYSTEMS, INC.; F. HOFFMANN-LA ROCHE AG","CHUKKA, Srinivas; SARKAR, Anindya; TAGELDIN, Mohamed, Amgad","62/596,036 07.12.2017 US",
WO2020021261,PCT/GB2019/052074,24.07.2019,WO/2020/021261,30.01.2020,WO,COMPUTER CLASSIFICATION OF BIOLOGICAL TISSUE,A biological tissue is classified using a computing system. Image data comprising a plurality of images of an examination area of a biological tissue is received at the computing system. Each of the plurality of images is captured at different times during a period in which topical application of a pathology differentiating agent to the examination area of the tissue causes transient optical effects. The received image data is provided as an input to a machine learning algorithm operative on the computing system. The machine learning algorithm is configured to allocate one of a plurality of classifications to each of a plurality of segments of the tissue.,G06T 7/00,DYSIS MEDICAL LIMITED,"PAPAGIANNAKIS, Emmanouil; ATKINSON, Alastair",1812050.1 24.07.2018 GB,
WO2019094562,PCT/US2018/059785,08.11.2018,WO/2019/094562,16.05.2019,WO,NEURAL NETWORK BASED BLIND SOURCE SEPARATION,"A device includes a sound acquisition manager configured to receive a mixed audio signal including a first plurality of audio signals, an independent component analysis manager configured to determine a set of parameters configured to generate a second plurality of audio signals based on the first plurality of audio signals, and to minimize a correlation between pairs of signals of the converted second plurality of audio signals, and a memory configured to store the second plurality of audio signals as multi-channel audio data.",G10L 21/0272; G10L 25/30,GOOGLE LLC,"YAN, Longfei; KLEIJN, Willem Bastiaan","62/583,141 08.11.2017 US",
WO2019074545,PCT/US2018/032697,15.05.2018,WO/2019/074545,18.04.2019,WO,IMAGE BASED SCREENING SYSTEM FOR PREDICTION OF INDIVIDUAL AT RISK OF LATE AGE-RELATED MACULAR DEGENERATION (AMD),An automated screening system using retinal imaging to identify individuals with early-stage Age-related Macular Degeneration (AMD) and identify individuals at risk for developing late AMD.,A61B 3/12; G06T 7/60; G06T 7/00,IHEALTHSCREEN INC.,"BHUIYAN, Mohammed, Alauddin; HUSAIN, Md., Akter; GOVINDAIAH, Arun","62/572,292 13.10.2017 US",
WO2019005722,PCT/US2018/039391,26.06.2018,WO/2019/005722,03.01.2019,WO,"SYSTEM, METHOD, AND COMPUTER-ACCESSIBLE MEDIUM FOR VIRTUAL PANCREATOGRAPHY","A system, method, and computer-accessible medium for using medical imaging data to screen for a cystic lesion(s) can include, for example, receiving first imaging information for an organ(s) of a one patient(s), generating second imaging information by performing a segmentation operation on the first imaging information to identify a plurality of tissue types, including a tissue type(s) indicative of the cystic lesion(s), identifying the cystic lesion(s) in the second imaging information, and applying a first classifier and a second classifier to the cystic lesion(s) to classify the cystic lesion(s) into one or more of a plurality of cystic lesion types. The first classifier can be a Random Forest classifier and the second classifier can be a convolutional neural network classifier. The convolutional neural network can include at least 6 convolutional layers, where the at least 6 convolutional layers can include a max-pooling layer(s), a dropout layer(s), and fully-connected layer(s).",G06K 9/00,THE RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK,"KAUFMAN, Arie; DMITRIEV, Konstantin","62/524,819 26.06.2017 US",EP-2018824396
WO2020069533,PCT/US2019/053914,30.09.2019,WO/2020/069533,02.04.2020,WO,"METHOD, MACHINE-READABLE MEDIUM AND SYSTEM TO PARAMETERIZE SEMANTIC CONCEPTS IN A MULTI-DIMENSIONAL VECTOR SPACE AND TO PERFORM CLASSIFICATION, PREDICTIVE, AND OTHER MACHINE LEARNING AND AI ALGORITHMS THEREON","A computer-implemented method, computer system and machine readable medium. The method is to implement a training model to be used by a neural network-based computing system to perform distributed computation regarding semantic concepts. A training model corresponding to a data structure to be used by the neural network-based computing system corresponds to a Distributed Knowledge Graph (DKG) defined by a plurality of nodes each representing a respective one of a plurality of semantic concepts that are based at least in part on existing data, each of the nodes represented by a characteristic distributed pattern of activity levels for respective meta-semantic nodes (MSNs), the MSNs for said each of the nodes defining a standard basis vector to designate a semantic concept, wherein standard basis vectors for respective ones of the nodes together define a continuous vector space of the DKG.",G06F 7/00; G06F 17/00; G06N 3/02; G10L 13/08,"ALVELDA, Philip; BRAINWORKS","ALVELDA, Philip","62/739,207 29.09.2018 US; 62/739,208 29.09.2018 US; 62/739,210 29.09.2018 US; 62/739,287 30.09.2018 US; 62/739,297 30.09.2018 US; 62/739,301 30.09.2018 US; 62/739,364 01.10.2018 US; 62/739,864 02.10.2018 US; 62/739,895 02.10.2018 US",
WO2019049141,PCT/IL2018/050999,06.09.2018,WO/2019/049141,14.03.2019,WO,A SYSTEM AND METHOD FOR USING KNOWLEDGE GATHERED BY A VEHICLE,"A system, method and computer program product for using knowledge gathered by a vehicle, the method comprising: receiving information from a first vehicle by a server, the information related to a context the first vehicle has experienced; storing the information on a storage device associated with the sever; determining a second vehicle to which the context is relevant; training a network of networks by a processor associated with the server, the network of networks including the information and additional information previously available to the second vehicle; and transmitting the information to the second vehicle.",G05D 1/02; B60W 40/02; G08G 1/09,OSR ENTERPRISES AG,"BEN-EZRA, Yosef; BEN-HAIM, Yaniv; SHIFMAN, Orit; HAZAK, Samuel; NISSIM, Shai; SCHIFF, Yoni","62/554,778 06.09.2017 US",
WO2018200840,PCT/US2018/029605,26.04.2018,WO/2018/200840,01.11.2018,WO,SYSTEM AND METHOD FOR AUTOMATED FUNDUSCOPIC IMAGE ANALYSIS,"A system and method of classifying images of pathology. An image is received, normalized, and segmented normalizing the image; into a plurality of regions; A disease vector is automatically determining for the plurality of regions with at least one classifier comprising a neural network. Each of the respective plurality of regions is automatically annotated, based on the determined disease vectors. The received image is automatically graded based on at least the annotations. The neural network is trained based on at least an expert annotation of respective regions of images, according to at least one objective classification criterion. The images may be eye images, vascular images, or funduscopic images. The disease may be a vascular disease, vasculopathy, or diabetic retinopathy, for example.",G06K 9/00; G06K 9/46; A61B 3/14,"PASCHALAKIS, Stavros; BOBER, Miroslaw; RETINOPATHY ANSWER LIMITED; RETINOPATHY ANSWER LIMITED (UK)","PASCHALAKIS, Stavros; BOBER, Miroslaw","62/490,977 27.04.2017 US",JP-2019559095; EP-2018725363
WO2019126881,PCT/CA2018/051682,28.12.2018,WO/2019/126881,04.07.2019,WO,SYSTEM AND METHOD FOR TONE RECOGNITION IN SPOKEN LANGUAGES,There is provided a system and method for recognizing tone patterns in spoken languages using sequence-to-sequence neural networks in an electronic device. The recognized tone patterns can be used to improve the accuracy for a speech recognition system on tonal languages.,G10L 25/90; G10L 15/02; G10L 15/22; G10L 17/26,FLUENT.AI INC.,"LUGOSCH, Loren; TOMAR, Vikrant","62/611,848 29.12.2017 US",
WO2018203470,PCT/JP2018/015636,16.04.2018,WO/2018/203470,08.11.2018,WO,"LEARNING APPARATUS, LEARNING METHOD, AND LEARNING PROGRAM","A learning apparatus according to an aspect of the present invention includes: a learning data acquisition unit configured to acquire a first learning data group for enabling a learning device to learn a predetermined ability through machine learning, the first learning data group including a plurality of pieces of learning data; a learning processing unit configured to construct a first learning device that has learned the predetermined ability, by carrying out machine learning of the learning device using the first learning data group; and an evaluation unit configured to evaluate quantity of insufficient learning data in machine learning of the first learning device, based on a result of the first learning device carrying out processing using the predetermined ability with respect to sample data.",G06N 99/00; G06N 3/04,OMRON CORPORATION,"ANDO, Tanichi",2017-091295 01.05.2017 JP,
WO2020041881,PCT/CA2019/051192,28.08.2019,WO/2020/041881,05.03.2020,WO,ULTRASONIC IMAGE ANALYSIS,"A computer-implemented method of facilitating ultrasonic image analysis of a subject is disclosed. The method involves receiving signals representing a set of ultrasound images of the subject, deriving one or more extracted feature representations from the set of ultrasound images, determining, based on the derived one or more extracted feature representations, a quality assessment value representing a quality assessment of the set of ultrasound images, determining, based on the derived one or more extracted feature representations, an image property associated with the set of ultrasound images, and producing signals representing the quality assessment value and the image property for causing the quality assessment value and the image property to be associated with the set of ultrasound images. A computer-implemented method of training one or more neural networks to facilitate ultrasonic image analysis is also disclosed. Other apparatuses, methods, systems, and computer-readable media are also disclosed.",G06T 7/00; A61B 8/13; G06N 3/08; G06T 1/40,THE UNIVERSITY OF BRITISH COLUMBIA,"ABOLMAESUMI, Purang; ROHLING, Robert; TSANG, Teresa; LIAO, Zhibin; ABDI, Amir","62/725,913 31.08.2018 US",
WO2020028890,PCT/US2019/045023,03.08.2019,WO/2020/028890,06.02.2020,WO,PREDICTION OF HEALTHCARE OUTCOMES AND RECOMMENDATION OF INTERVENTIONS USING DEEP LEARNING,"A system includes first, second and third input data sets. The first input data set includes demographic information characterizing a patient. The second and third input data sets characterize a healthcare treatment history of the patient. A neural network includes first, second and third neural subnetworks. The first neural subnetwork is configured to process the first input data set to produce a first output data set. The second neural subnetwork is configured to process the second input data set to produce a second output data set. The third neural subnetwork is configured to process the third input data set to produce a third output data set. An autoencoder layer has an input layer comprising the first, second and third output data sets and is configured to process the first, second and third output data sets to produce a secondary output data set.",G06N 3/02; G06N 3/04; G06N 3/08; G06F 19/00,"EDIFECS, INC.; SARIPALLI, Kanaka Prasad; WOLCOTT, Frank Lucas; DAUSMAN, Paul Raymond; SAXENA, Shailly; CLEMENTS, William Lee","SARIPALLI, Kanaka Prasad; WOLCOTT, Frank Lucas; DAUSMAN, Paul Raymond; SAXENA, Shailly; CLEMENTS, William Lee","62/714,483 03.08.2018 US",
WO2019202203,PCT/FI2019/050278,08.04.2019,WO/2019/202203,24.10.2019,WO,ENABLING IN-EAR VOICE CAPTURE USING DEEP LEARNING,"A method includes accessing, by at least one processing device, an audible signal including at least one in-ear microphone audible signal and at least one external microphone audible signal and at least one noise signal; training a generative network to generate an enhanced external microphone signal from an in-ear microphone signal based on the at least one in-ear microphone audible signal and the at least one external microphone audible signal; and outputting the generative network.",G06N 3/04; G10L 21/02; H04R 1/10; G10K 11/178,NOKIA TECHNOLOGIES OY,"KÄRKKÄINEN, Asta; KÄRKKÄINEN, Leo; HONKALA, Mikko; VESA, Sampo","15/956,457 18.04.2018 US",
EP252257046,19163921,19.03.2019,3543917,25.09.2019,EP,DYNAMIC ADAPTATION OF DEEP NEURAL NETWORKS,,G06N 3/04; G06N 3/063; G06N 3/08,SRI INT INC,CHAI SEK MENG; RAGHAVAN ASWIN NADAMUNI; PARAJULI SAMYAK,201816133446 17.09.2018 US; 201862644715 19.03.2018 US; 201862645358 20.03.2018 US,
EP160060121,15181884,20.08.2015,2993618,09.03.2016,EP,DOMAIN ADAPTATION FOR IMAGE CLASSIFICATION WITH CLASS PRIORS,"In camera-based object labeling, boost classifier      f  T    x   =      ˆ‘   r  =  1   M      ²  r     h  r    x       is trained to classify an image represented by feature vector x using a target domain training set  D T   of labeled feature vectors representing images acquired by the same camera and a plurality of source domain training sets  D S 1  ,...,D S N    acquired by other cameras. The training applies an adaptive boosting (AdaBoost) algorithm to generate base classifiers  h r  (x) and weights  ²  r . The  r th   iteration of the AdaBoost algorithm trains candidate base classifiers      h  r  k    x       each trained on a training set  D T UD S k  ,  and selects  h r  (x) from previously trained candidate base classifiers. The target domain training set  D T   may be expanded based on a prior estimate of the labels distribution for the target domain. The object labeling system may be a vehicle identification system, a machine vision article inspection system, or so forth.",G06K 9/00; G06K 9/62,XEROX CORP,CHIDLOVSKII BORIS; CSURKA GABRIELA,201414477215 04.09.2014 US,
WO2015073162,PCT/US2014/061433,20.10.2014,WO/2015/073162,21.05.2015,WO,METHOD AND SYSTEM FOR TRAINING A NEURAL NETWORK,A method and system (20) for training a neural network (95) is disclosed herein. A processor (41) is configured to train a neural network to learn to generate a plurality of sub-concept outputs from a first plurality of inputs (80) of the plurality of digital input signals. The processor (41) is also configured to use the plurality of sub- concept outputs as a plurality of target outputs for a plurality of top-level inputs of the plurality of digital input signals.,A61B 5/0476; G06N 3/08; G06Q 40/02,PERSYST DEVELOPMENT CORPORATION,"WILSON, Scott, B.","14/078,497 12.11.2013 US",
WO2019084189,PCT/US2018/057382,24.10.2018,WO/2019/084189,02.05.2019,WO,GRADIENT NORMALIZATION SYSTEMS AND METHODS FOR ADAPTIVE LOSS BALANCING IN DEEP MULTITASK NETWORKS,"Systems and methods for training a multitask network is disclosed. In one aspect, training the multitask network includes determining a gradient norm of a single-task loss adjusted by a task weight for each task, with respect to network weights of the multitask network, and a relative training rate for the task based on the single-task loss for the task. Subsequently, a gradient loss function, comprising a difference between (1) the determined gradient norm for each task and (2) a corresponding target gradient norm, can be determined. An updated task weight for the task can be determined and used in the next iteration of training the multitask network, using a gradient of the gradient loss function with respect to the task weight for the task.",G06F 15/18,"MAGIC LEAP, INC.","CHEN, Zhao; BADRINARAYANAN, Vijay; RABINOVICH, Andrew","62/577,705 26.10.2017 US; 62/599,693 16.12.2017 US; 62/628,266 08.02.2018 US; 62/695,356 09.07.2018 US",
WO2019237191,PCT/CA2019/050820,11.06.2019,WO/2019/237191,19.12.2019,WO,SYSTEM AND METHOD FOR DETERMINING CORONAL ARTERY TISSUE TYPE BASED ON AN OCT IMAGE AND USING TRAINED ENGINES,"There is described a system for determining a coronal artery tissue type. The system generally has an optical coherence tomography (OCT) imaging system being configured for acquiring an OCT image of coronal artery tissue; and a controller configured to perform the steps of: using trained feature extraction engines, extracting corresponding feature vectors comprising a plurality of features in at least a region of interest of the OCT image; using trained classification engines, determining corresponding preliminary coronal artery tissue types associated to the region of interest of the OCT image based on corresponding ones of the plurality of feature vectors; and using a majority voting engine, majority voting an output coronal artery tissue type associated to the region of interest of the OCT image based on the previously determined preliminary coronal artery tissue types.",A61B 5/00; G06K 9/46; G06K 9/78; G06N 3/02,"SOCOVAR, SOCIÉTÉ EN COMMANDITE; DAHDAH, Nagib; CHERIET, Farida","DAHDAH, Nagib; CHERIET, Farida; ABDOLMANAFI, Atefeh; DUONG, Luc","62/683,176 11.06.2018 US; 62/821,590 21.03.2019 US",
WO2018018038,PCT/US2017/043502,24.07.2017,WO/2018/018038,25.01.2018,WO,"SYSTEM AND METHOD FOR SMALL MOLECULE ACCURATE RECOGNITION TECHNOLOGY (""SMART"")","Systems and methods are provided that leverage the advantages of Non-Uniform Sampling (NUS) 2D NMR techniques and Deep Convolutional Neural Networks (DCNN) to create the ""SMART"" tool that can assist in high-throughput natural product discovery. The methodological development of SMART is accomplished in two steps: (1) the NUS heteronuclear single quantum coherence (HSQC) NMR program was adapted to a state-of-the-art nuclear magnetic resonance (NMR) instrument equipped with a cryoprobe, and the data reconstruction methods were optimized, (2) a DCNN with modified contrastive loss was trained on a database containing over 2000 HSQC spectra as the initial training set. To demonstrate the utility of SMART, several newly isolated compounds were automatically located with their known analogues in the test embedding map (TEM), thereby streamlining the discovery pipeline for new biologically active natural products.",A61B 5/05; A61K 49/00; G01R 33/465; G01R 33/58; G06F 17/14; G06F 19/00,THE REGENTS OF THE UNIVERSITY OF CALIFORNIA,"ZHANG, Chen; IDELBAYEV, Yerlan; COTTRELL, Garrison, W.; GERWICK, William, H.; LANDON, Preston, B.","62/365,548 22.07.2016 US",
WO2019068141,PCT/AU2018/051071,02.10.2018,WO/2019/068141,11.04.2019,WO,SYSTEM AND METHOD FOR MACHINE LEARNING-DRIVEN OBJECT DETECTION,"Embodiments relate to systems and methods for gaming monitoring. In particular, embodiments relate to systems and methods for gaming monitoring based on machine learning processes configured to analyse captured images to identify or detect game objects and game events to monitor games.",G06K 9/62; G06T 7/10,SENSEN NETWORKS GROUP PTY LTD,"VO, Nhat; CHALLA, Subhash; QUINN, Louis",2017903975 02.10.2017 AU,
WO2018108741,PCT/EP2017/082052,08.12.2017,WO/2018/108741,21.06.2018,WO,DEVICE FOR CLASSIFYING DATA,"The present invention relates to a device configured to classify data. It is described to provide (210) to a processing unit a plurality of data samples comprising one or more of: image data, radar data; acoustic data; and lidar data, wherein the plurality of data samples comprises at least one test sample and comprises a plurality of positive samples and comprises a plurality of negative samples, and wherein, each of the positive samples has been determined to contain data relating to at least one object to be detected comprising one or more of: pedestrian; car; vehicle; truck or bicycle,and wherein each of the negative samples has been determined not to contain data relating to the at least one object to be detected, wherein the determination that the positive samples contain data relating to an object to be detected and the determination that the negative samples do not contain data relating to an object are provided as input data, validated by a human operative, and/or provided by the device itself through utilization of a learning algorithm. A first plurality of groups is generated (220) by the processing unit implementing an artificial neural network, wherein at least some of the first plurality of groups are assigned a weighting factor. Each group of the first plurality of groups is populated (230) by the processing unit implementing the artificial neural with a different at least one of the plurality of negative samples on the basis of a different feature of sample data similarity for each group comprising processing the negative samples to determine a number of different features of sample similarity in order to populate different groups with negative samples that share or substantially share that or a similar feature,wherein at least one of the group of the first plurality of groups contains at least two negative samples. It is determined (240) by the processing unit implementing the artificial neural network if the at least one test sample contains data relating to the at least one object on the basis of the plurality of the positive samples and the first plurality of groups. The artificial neural network comprises the learning algorithm.",G06K 9/62,CONTI TEMIC MICROELECTRONIC GMBH,"KARG, Michelle; SCHARFENBERGER, Christian; THIEL, Robert",16204089.3 14.12.2016 EP,DE-112017005651
WO2015056024,PCT/GB2014/053116,17.10.2014,WO/2015/056024,23.04.2015,WO,VISUAL DATA MINING,"Method and system for finding targets within visual data, comprising receiving target object information. Generating a set of target object semantic attributes from the target object information. Identifying a plurality of candidate objects within visual data. Generating a set of low-level feature descriptors from the visual data for each candidate object. Generating from the set of low-level feature descriptors a set of candidate semantic attributes for each candidate object within the visual data. Identifying one or more portions of the visual data containing a candidate object, from the plurality of candidate objects, having a set of candidate object semantic attributes that match the set of target object semantic attributes. Providing an output indicating the identified one or more portions of the visual data.",G06K 9/00,VISION SEMANTICS LIMITED,"GONG, Shaogang Sean; HOSPEDALES, Timothy Miguel",1318472.6 18.10.2013 GB,EP-2014787045; US-15028082
WO2019099074,PCT/US2018/046022,09.08.2018,WO/2019/099074,23.05.2019,WO,HIGHLY EFFICIENT CONVOLUTIONAL NEURAL NETWORKS,"The present disclosure provides directed to new, more efficient neural network architectures. As one example, in some implementations, the neural network architectures of the present disclosure can include a linear bottleneck layer positioned structurally prior to and/or after one or more convolutional layers, such as, for example, one or more depthwise separable convolutional layers. As another example, in some implementations, the neural network architectures of the present disclosure can include one or more inverted residual blocks where the input and output of the inverted residual block are thin bottleneck layers, while an intermediate layer is an expanded representation. For example, the expanded representation can include one or more convolutional layers, such as, for example, one or more depthwise separable convolutional layers. A residual shortcut connection can exist between the thin bottleneck layers that play a role of an input and output of the inverted residual block.",G06N 3/04; G06T 7/10,GOOGLE LLC,"HOWARD, Andrew Gerald; SANDLER, Mark; CHEN, Liang-Chieh; ZHMOGINOV, Andrey; ZHU, Menglong","62/586,007 14.11.2017 US; 15/898,566 17.02.2018 US",EP-2018759827
WO2018175098,PCT/US2018/020887,05.03.2018,WO/2018/175098,27.09.2018,WO,LEARNING COACH FOR MACHINE LEARNING SYSTEM,"A machine learning (ML) system includes a student ML system, a learning coach ML system, and a reference system that generates training data for the student ML system. The learning coach ML system learns to make an enhancement to the student ML system or to its learning process, such as updated hyperparameter or a network structural change, based on training of the student ML system with the training data generated by the reference system. The system may also comprise a learning experimentation system that communicates with the reference system to conduct experiments on the learning of the student learning system. Also, the learning experimentation system can determine a cost function for the learning coach ML system.",G06F 15/18,D5AI LLC,"BAKER, James, K.","62/476,280 24.03.2017 US",EP-2018772282
WO2018067962,PCT/US2017/055581,06.10.2017,WO/2018/067962,12.04.2018,WO,IMAGE PROCESSING NEURAL NETWORKS WITH SEPARABLE CONVOLUTIONAL LAYERS,"A neural network system is configured to receive an input image and to generate a classification output for the input image. The neural network system includes: a separable convolution subnetwork comprising a plurality of separable convolutional neural network layers arranged in a stack one after the other, in which each separable convolutional neural network layer is configured to: separately apply both a depthwise convolution and a pointwise convolution during processing of an input to the separable convolutional neural network layer to generate a layer output.",G06N 3/04,GOOGLE LLC,"CHOLLET, Francois; HOWARD, Andrew Gerald","62/405,181 06.10.2016 US",KR-1020197012961; JP-2019518553; CN-201780061438.2; EP-2017790905
WO2018172971,PCT/IB2018/051933,22.03.2018,WO/2018/172971,27.09.2018,WO,HEALTHCARE ANALYTICS MANAGEMENT,"A healthcare analytics development sub-system of a healthcare analytics management system develops an analytics pipeline of a set of analytics assets for a selected healthcare based on a set of business needs for a healthcare analytics client and a healthcare analytics model based on the set of analytics assets and the set of business needs. The healthcare analytics model links to the analytics pipeline. A model deployment module of a healthcare analytics operation sub-system of the healthcare analytics management system deploys the healthcare analytics model on a set of computing devices of the selected healthcare consumer. Responsive to a model monitoring module of the healthcare analytics operation sub-system detecting a performance deviation of the deployed healthcare analytics motel for performance deviation from the set of business needs for the healthcare analytics client, a model feedback module of the healthcare analytics operation sub-system determines improvement needs for the healthcare analytics model. The model feedback module feeds the improvement needs back to the healthcare analytics development sub-system. The healthcare analytics development sub-system customizes the healthcare analytics model based on the improvement needs.",G06F 19/00,INTERNATIONAL BUSINESS MACHINES CORPORATION; IBM UNITED KINGDOM LIMITED; IBM (CHINA) INVESTMENT COMPANY LIMITED,"WANG, Yajuan; CURBERA, Francisco, Phelan; YUEN-REED, Gigi; WILLIAMS, Rose, Marie; MAHATMA, Shilpa","15/467,211 23.03.2017 US",CN-201880020298.9; GB-1914873.3; DE-112018001524; JP-2019551442
WO2019160975,PCT/US2019/017876,13.02.2019,WO/2019/160975,22.08.2019,WO,CONDITIONAL LOSS FUNCTION MODIFICATION IN A NEURAL NETWORK,"Method, electronic device, and computer readable medium embodiments are disclosed. In one embodiment, a method includes training a neural network using a first image dataset and a first truth dataset (720, 820), then using the trained neural network to analyze a second image dataset (722, 822). The training includes modifying a loss function of the neural network (708, 810) to forego penalizing the neural network when a feature is predicted with higher than a first confidence level by the neural network, and the first truth dataset has no feature corresponding to the predicted feature.",G06N 3/08; G06N 3/04,"SLINGSHOT AEROSPACE, INC.","GODWIN IV, David Stuart; ROMO, Spencer Ryan; HERNANDEZ, Carrie Inez; ASHMAN, Thomas Scott; STRICKLAN, Melanie","62/630,097 13.02.2018 US; 62/640,404 08.03.2018 US",
WO2017151757,PCT/US2017/020183,01.03.2017,WO/2017/151757,08.09.2017,WO,RECURRENT NEURAL FEEDBACK MODEL FOR AUTOMATED IMAGE ANNOTATION,"A deep learning model is provided to efficiently detect disease from an image (e.g., an x-ray image) and annotate its contexts. In one example of the disclosed technology, a method of generating an annotation sequence describing an input image includes training a convolutional neural network (CNN) with a series of reference images and associated annotation sequences, training a recurrent neural network (RNN) by initializing the RNN with the trained CNN embedding of the reference image and a first word of an annotation sequence, sampling the CNN and RNN with a reference image, and producing a sequence of annotation describing the image, disease(s) in the image, one or more attributes or contexts. In one examples of the disclosed technology, mean pooling is applied to the state vectors of RNN to obtain a joint image/text context vector summarizing the contexts of image and text annotation.",G06N 3/04,"THE UNITED STATES OF AMERICA, AS REPRESENTED BY THE SECRETARY, DEPARTMENT OF HEALTH AND HUMAN SERVICES","SHIN, Hoo-Chang; LU, Le; SUMMERS, Ronald, M.","62/302,084 01.03.2016 US",
EP282270336,19184180,03.07.2019,3598339,22.01.2020,EP,SYSTEMS AND METHODS FOR END-TO-END HANDWRITTEN TEXT RECOGNITION USING NEURAL NETWORKS,,G06K 9/00; G06K 9/62,TATA CONSULTANCY SERVICES LTD,CHOWDHURY ARINDAM; VIG LOVEKESH,201821026934 19.07.2018 IN,
WO2016193824,PCT/IB2016/000926,03.06.2016,WO/2016/193824,08.12.2016,WO,SYSTEM AND METHOD FOR MULTIMODAL HUMAN STATE RECOGNITION,"An adaptive system and method are provided for modelling the behavioral and non-behavioral state of individual human subjects according to a set of past observations through sensed signals via a multi-modal pattern recognition algorithm. The system may take into consideration both subjective parameters that are learnt from the user over time, and contextual factors that are provided to the system, to achieve the model development.",G06F 19/00; G06F 15/18; G06K 9/62,SENSAURA INC.,"KHOMAMI ABADI, Mojtaba; RANCOURT POULIN, Jean-philip","62/171,359 05.06.2015 US",
WO2020014280,PCT/US2019/041078,09.07.2019,WO/2020/014280,16.01.2020,WO,DEEP LEARNING-BASED FRAMEWORK FOR IDENTIFYING SEQUENCE PATTERNS THAT CAUSE SEQUENCE-SPECIFIC ERRORS (SSEs),"The technology disclosed presents a deep learning-based framework, which identifies sequence patterns that cause sequence-specific errors (SSEs). Systems and methods train a variant filter on large-scale variant data to learn causal dependencies between sequence patterns and false variant calls. The variant filter has a hierarchical structure built on deep neural networks such as convolutional neural networks and fully-connected neural networks. Systems and methods implement a simulation that uses the variant filter to test known sequence patterns for their effect on variant filtering. The premise of the simulation is as follows: when a pair of a repeat pattern under test and a called variant is fed to the variant filter as part of a simulated input sequence and the variant filter classifies the called variant as a false variant call, then the repeat pattern is considered to have caused the false variant call and identified as SSE-causing.",G16B 40/20; G16B 20/20; G06N 3/04,"ILLUMINA, INC.","KASHEFHAGHIGHI, Dorna; KIA, Amirali; FARH, Kai-How","62/696,699 11.07.2018 US; 2021473 16.08.2018 NL; 16/505,100 08.07.2019 US",SG-11201912766V; IL-271213; KR-KR1020197036426; EP-2019742664; KR-1020197036426
WO2016063795,PCT/JP2015/079242,08.10.2015,WO/2016/063795,28.04.2016,WO,METHOD FOR TRANSFORMING A NOISY SPEECH SIGNAL TO AN ENHANCED SPEECH SIGNAL,"A method transforms a noisy speech signal to an enhanced speech signal, by first acquiring the noisy speech signal from an environment. The noisy speech signal is processed by an automatic speech recognition system (ASR) to produce ASR features. The the ASR features and noisy speech spectral features are processed using an enhancement network having network parameters to produce a mask. Then, the mask is applied to the noisy speech signal to obtain the enhanced speech signal.",G10L 25/30; G10L 21/0208; G10L 25/03; G10L 21/0324; G06N 3/02,MITSUBISHI ELECTRIC CORPORATION,"ERDOGAN, Hakan; HERSHEY, John; WATANABE, Shinji; LE ROUX, Jonathan",62/066451 21.10.2014 US; 14/620514 12.02.2015 US,
WO2018218034,PCT/US2018/034411,24.05.2018,WO/2018/218034,29.11.2018,WO,SHEET MUSIC SEARCH AND DISCOVERY SYSTEM,"A sheet music search and discovery system is disclosed that uses specific mathematical rules to analyze and characterize sheet music and provides functionality for users to identify sheet music based on those characterizations. The system stores sheet music data and metadata characterizing each composition, provides a graphical user interface that provides functionality for users to search the sheet music data for compositions, and generates search results based at least in part on the metadata characterizing each composition. In one embodiment, metadata describing structured sheet music data is generated using a global vector space that includes semantic representations of elements extracted from a large corpus. In another embodiment, metadata describing unstructured sheet music data is generated using machine learning-based pattern recognition. In another embodiment, the interface provides functionality for users to identify instruments and a range for each of the instruments and identify compositions with similar instruments and ranges.",G06F 17/00,"J. W. PEPPER & SON, INC.","SAWRUK, Jeremy; DONNELLY, Bruce; HAMILTON, Michael","62/511,025 25.05.2017 US",CA-3062700
WO2015193032,PCT/EP2015/060298,11.05.2015,WO/2015/193032,23.12.2015,WO,CONTROLLING A TARGET SYSTEM,"For controlling a target system, e.g. a gas or wind turbine or another technical system, a pool of control policies is used. The pool of control policies comprising a plurality of control policies and weights for weighting each of the plurality of control policies are received. The plurality of control policies is weighted by the weights to provide a weighted aggregated control policy. With that, the target system is controlled using the weighted aggregated control policy, and performance data relating to a performance of the controlled target system are received. Furthermore, the weights are adjusted on the basis of the received performance data to improve the performance of the controlled target system. With that, the plurality of control policies is reweighted by the adjusted weights to adjust the weighted aggregated control policy.",G05B 13/02,SIEMENS AKTIENGESELLSCHAFT,"DÜLL, Siegmund; MÜLLER, Michael; OTTE, Clemens; UDLUFT, Steffen; BASSILY, Hany F.","14/309,641 19.06.2014 US",EP-2015725521; CN-201580032397.5; KR-1020177001589
EP96431806,13186465,27.09.2013,2713293,02.04.2014,EP,Rapid community learning for predictive models of medical knowledge,"A predictive model of medical knowledge is trained (42, 48) from patient data of multiple different medical centers (14). The predictive model is machine learnt from routine patient data from multiple medical centers (14). Distributed learning avoids transfer of the patient data from any of the medical centers (14). Each medical center (14) trains (42) the predictive model from the local patient data. The learned statistics, and not patient data, are transmitted (44) to a central server (12). The central server (12) reconciles (48) the statistics and proposes (52) new statistics to each of the local medical centers. In an iterative approach, the predictive model is developed without transfer of patient data but with statistics responsive to patient data available from multiple medical centers (14). To assure comfort with the process, the transmitted statistics may be in a human readable format.",G06F 19/00,SIEMENS MEDICAL SOLUTIONS,ANAND VIKRAM; FAROOQ FAISAL; KRISHNAPURAM BALAJI; YU SHIPENG,201261706293 27.09.2012 US; 201261715447 18.10.2012 US; 201314027494 16.09.2013 US,
WO2020055910,PCT/US2019/050469,10.09.2019,WO/2020/055910,19.03.2020,WO,SYSTEMS AND METHODS FOR GRAPH-BASED AI TRAINING,"Graphs are powerful structures made of nodes and edges. Information can be encoded in the nodes and edges themselves, as well as the connections between them. Graphs can be used to create manifolds which in turn can be used to efficiently train more robust Al systems. Systems and methods for graph-based Al training in accordance with embodiments of the invention are illustrated. In one embodiment, a graph interface system including a processor, and a memory configured to store a graph interface application, where the graph interface application directs the processor to obtain a set of training data, where the set of training data describes a plurality of scenarios, encode the set of training data into a first knowledge graph, generate a manifold based on the first knowledge graph, and train an Al model by traversing the manifold.",G06K 9/62; G06N 3/04; G06K 9/46,"DRISK, INC.","STETSON, Robert, Chess; CHAISANGUANTHUM, Kris; FERGUSON, Robert; REVECHKIS, Boris","62/789,955 08.01.2019 US; 62/729,368 10.09.2018 US",
EP209989505,16705880,03.02.2016,3259713,27.12.2017,EP,PRE-TRAINING AND/OR TRANSFER LEARNING FOR SEQUENCE TAGGERS,,G06N 7/00; G06N 99/00,MICROSOFT TECHNOLOGY LICENSING LLC,KIM YOUNG-BUM; JEONG MINWOO; SARIKAYA RUHI,201514625828 19.02.2015 US; 2016016248 03.02.2016 US,
WO2019155471,PCT/IL2019/050155,07.02.2019,WO/2019/155471,15.08.2019,WO,METHOD OF DEEP LEARNING-BASED EXAMINATION OF A SEMICONDUCTOR SPECIMEN AND SYSTEM THEREOF,"There is provided a method of examination of a semiconductor specimen and a system thereof. The method comprises: using a trained Deep Neural Network (DNN) to process a fabrication process (FP) sample, wherein the FP sample comprises first FP image(s) received from first examination modality(s) and second FP image(s) received from second examination modality(s) which differs from the first examination modality(s), and wherein the trained DNN processes the first FP image(s) separately from the second FP image(s); and further processing by the trained DNN the results of such separate processing to obtain examination-related data specific for the given application and characterizing at least one of the processed FP images. When the FP sample further comprises numeric data associated with the FP image(s), the method further comprises processing by the trained DNN at least part of the numeric data separately from processing the first and the second FP images.",G06N 3/04; G06N 3/08; G06K 9/03; G06K 9/46; G06K 9/62; G06T 7/00; G01N 21/95,APPLIED MATERIALS ISRAEL LTD.,"SHAUBI, Ohad; SUHANOV, Denis; ASBAG, Assaf; COHEN, Boaz","62/627,692 07.02.2018 US",
WO2017142397,PCT/NL2017/050084,10.02.2017,WO/2017/142397,24.08.2017,WO,DEVICE AND METHOD FOR GENERATING A GROUP EQUIVARIANT CONVOLUTIONAL NEURAL NETWORK,"The invention provides a device for generating a convolutional neural network, said device comprising a computer device comprising a computer program which, when running on said computer device, defines said convolutional neural network, said convolutional neural network comprising at least one non-translational group convolution layer, said non-translational group convolution layer taking as input a set of learnable filters and an input stack of feature maps, both inputs being a vector- valued function on a discrete set of sampling points having a set of symmetry transformations that form a mathematical group of symmetry transformations, with the exclusion of mathematical groups of symmetry transformations that are pure translation groups, and said non-translational group convolution layer producing as output an output stack of feature maps being a vector-valued function on said mathematical group of symmetry transformations.",G06N 3/02; G06F 17/15; G06N 3/10,SCYFER B.V.,"COHEN, Taco Sebastiaan; WELLING, Max",2016285 19.02.2016 NL,
WO2019084697,PCT/CA2018/051400,06.11.2018,WO/2019/084697,09.05.2019,WO,"PLATFORM, DEVICE AND PROCESS FOR ANNOTATION AND CLASSIFICATION OF TISSUE SPECIMENS USING CONVOLUTIONAL NEURAL NETWORK","Embodiments described herein provide a platform, device and process for digital pathology that enable multi-level annotation and visualization of histopathologic slides using a modular arrangement of deep convolutional neural networks (CNNs). The CNNs can be trained using pathology images (e.g., in some cases increasing the base of data by breaking larger fields of view into smaller ones) to learn features consistent with certain pathologies. The platform can use the CNNs to visually annotate pathology slides at an interface tool of a display device. The platform can automate the process of selection, as well as provide an opportunity for the pathologist to see a depiction of predicted results. The platform can use the CNNs to identify regions of interest on pathology slides. The interface tool can enable a predicted region of interest (ROI) type to be visually presented on a surface map showing the basis of the prediction. If the ROI primarily lands in part of the hyperdimensional space not occupied by any training set, then the interface tool is capable of marking it as an ROI of unknown type.",G06K 9/62; A61B 90/00; G06N 3/02,UNIVERSITY HEALTH NETWORK,"FAUST, Kevin; VOLYNSKAYA, Zoya; DJURIC, Ugljesa; DIAMANDIS, Phedias","62/582,068 06.11.2017 US",
EP12360523,92480080,10.06.1992,0520925,30.12.1992,EP,CONVOLUTIONAL EXPERT NEURAL SYSTEM,"Based on the recognition that transfer functions of Boolean completeness can be expressed as a domain within a periodic function, an architecture of a artificial neuron which is fully generalized in application and capable of rapid learning with minimal memory requirements while maintaining content addressability of memory, is provided. Full functionality of this architecture is demonstrated for an input vector containing two values. Extension to three variables shows the potential for generality of this architecture to N-valued input vectors. <IMAGE>",G06F 15/18; G06F 17/10; G06G 7/60; G06N 3/04; G06N 3/08; G06N 99/00,IBM,APARICIO IV MANUEL; OTTO SAMUEL E,72027891 24.06.1991 US,
WO2019106061,PCT/EP2018/082925,29.11.2018,WO/2019/106061,06.06.2019,WO,THREE-DIMENSIONAL MEDICAL IMAGE ANALYSIS METHOD AND SYSTEM FOR IDENTIFICATION OF VERTEBRAL FRACTURES,"The present invention provides a machine-based learning method to estimate a probability of bone fractures in a 3D image, more specifically vertebral fractures. The method and system utilizing such method utilize a data-driven computational model to learn 3D image features for classifying vertebra fractures.",G06T 7/00,UCB BIOPHARMA SRL,"NICOLAES, Joeri",1720059.3 01.12.2017 GB,
WO2018192662,PCT/EP2017/059428,20.04.2017,WO/2018/192662,25.10.2018,WO,DEFECT CLASSIFICATION IN AN IMAGE OR PRINTED OUTPUT,A monitoring device includes circuitry to compare a printed output with a reference representing a target output and to determine potential defects in the printed output based on the comparison. The monitoring device further includes and circuitry to implement a convolutional neural network to classify each potential defect as a true defect or a false alarm.,G06K 9/03; G06K 9/46; G06K 9/62; G06T 7/00,HP INDIGO B.V.,"HAIK, Oren; PERRY, Oded; CHEN, Eli",,
WO2018057714,PCT/US2017/052679,21.09.2017,WO/2018/057714,29.03.2018,WO,"SYSTEMS, METHODS AND MEDIA FOR AUTOMATICALLY GENERATING A BONE AGE ASSESSMENT FROM A RADIOGRAPH","In accordance with some embodiments, systems, methods and media for generating a bone age assessment. In some embodiments, a method comprises: receiving an x-ray image of a subject's left hand and wrist; converting the image to a predetermined size; identifying, without user intervention, a first portion of the image corresponding to the hand and wrist; processing the first portion of the image to increase contrast between bones and non-bones to generate a processed image; causing a trained convolution neural network to determine a bone age based on the processed image; receiving an indication of the bone age; causing the bone age to be presented to a user as the result of a bone age assessment; and causing the bone age and the image to be stored in an electronic medical record associated with the subject.",A61B 5/00; A61B 5/107; A61B 6/00; A61B 8/00; A61B 8/08; G06K 9/00; G06T 7/00,THE GENERAL HOSPITAL CORPORATION,"DO, Synho; LEE, Hyunkwang; GEE, Michael; TAJMIR, Shahein; ALKASAB, Tarik","62/397,667 21.09.2016 US",
WO2019191810,PCT/AU2019/050298,04.04.2019,WO/2019/191810,10.10.2019,WO,"METHODS AND SYSTEMS FOR RESOLVING USER INTERFACE FEATURES, AND RELATED APPLICATIONS","A method including the following steps: receiving user input; resolving a feature of the input using a trainable algorithm, the trainable algorithm being trainable to resolve a feature by application of the algorithm to a dataset including a plurality of labelled dataset entries, the label of each labelled dataset entry describing a feature; wherein the trainable algorithm resolves the features in user input by identifying in the user input a dataset entry labelled with said feature; forming a UI that incorporates the resolved feature; presenting the formed UI; obtaining feedback in relation to the presented UI or a feature thereof; applying the feedback to train the trainable algorithm to resolve features of a UI, wherein feedback for training the trainable algorithm derives from any one or more of, or a combination of: user selection/validation/customisation of features presented to the user and/or user observation.",G06F 8/38; G06F 17/50; G06F 3/01; G06F 17/20; G06N 20/00; G06N 3/00,"BASYROV, Marat","BASYROV, Marat",2018202382 04.04.2018 AU,
WO2018102748,PCT/US2017/064309,01.12.2017,WO/2018/102748,07.06.2018,WO,AUTOMATED DETECTION AND REPOSITIONING OF MICRO-OBJECTS IN MICROFLUIDIC DEVICES,"Methods are provided for the automated detection and/or counting of micro-objects in a microfluidic device. In addition, methods are provided for repositioning micro-objects in a microfluidic device. In addition, methods are provided for separating micro-objects in a spatial region of the microfluidic device.",G06T 7/10; G06T 1/20; G06T 1/40; G06T 7/00,"BERKELEY LIGHTS, INC.","KIM, Hansohl E.; TENNEY, John A.; SLOCUM, Joshua F.","62/429,071 01.12.2016 US; 62/579,897 01.11.2017 US",AU-2017368268; CN-201780085461.5; KR-1020197018732; CA-3045333; SG-11201904870T; EP-2017876009; IL-267009
EP240631209,17275185,21.11.2017,3467717,10.04.2019,EP,MACHINE LEARNING SYSTEM,"There is described a machine learning system comprising a first subsystem and a second subsystem remote from the first subsystem. The first subsystem comprises an environment having multiple possible states, the environment being arranged to output a state signal comprising data indicative of the state of the environment at a discrete time and to receive an action signal operable to cause a change of state, and a decision making subsystem comprising one or more agents, each agent being configured to generate an action signal dependent on the data conveyed by the received state signal and a policy associated with that agent, the decision making subsystem being further arranged to generate experience data dependent on data conveyed by the state signal and the action signal. The first subsystem also includes a first network interface configured to send said experience data to the second subsystem and to receive policy data from the second subsystem. The second subsystem comprises: a second network interface configured to receive experience data from the first subsystem and send policy data to the first subsystem; and a learning routine configured to process said received experience data to generate said policy data, dependent on the experience data, for updating one or more policies associated with the one or more agents. The decision making subsystem is operable to update the one or more policies associated with the one or more agents in accordance with policy data received from the second subsystem.",G06N 3/00; G06N 3/04; G06N 3/08; G06N 7/00,PROWLER IO LTD,TUKIAINEN ALEKSI; KIM DONGHO; NICHOLSON THOMAS; TOMCZAK MARCIN; MUNOZ DE COTE FLORES LUNA JOSE ENRIQUE; FERGUSON NEIL; ELEFTHERIADIS STEFANOS; SEPPA JUHA; BEATTIE DAVID; JENNINGS JOEL; HENSMAN JAMES; LEIBFRIED FELIX; GRAU-MOYA JORDI; JOHN SEBASTIAN; BOU-AMMAR HAITHAM; VRANCX PETER,20170100448 04.10.2017 GR,
WO2018195198,PCT/US2018/028168,18.04.2018,WO/2018/195198,25.10.2018,WO,ARTIFICIALLY INTELLIGENT SYSTEM EMPLOYING MODULARIZED AND TAXONOMY-BASE CLASSIFICATIONS TO GENERATED AND PREDICT COMPLIANCE-RELATED CONTENT,"A system employing new and improved artificially intelligent system for employing modularized and taxonomy-based classifications to generate compliance-related content. In one embodiment, the system comprises monitoring circuitry that receives regulatory compliance data from one or more regulatory institutions, as well as a taxonomy engine that processes the regulatory compliance data to generate taxonomy -based classifications of the regulatory compliance data comprising a plurality of modules and compliance requirements within each module. In certain embodiments, the system also includes a database storing the taxonomy-based classifications of the regulatory compliance data, and a plurality of processors in operative communication with the database that receive at least two of the plurality of modules from the taxonomy -based classifications and process the compliance requirements within each received module using natural language processing to generate a mapping of semantic relationship pairs between each received module. In certain embodiments, the system also includes scoring circuitry that processes the mapping of semantic relationship pairs between each received module to produce a similarity score for each relationship pair, as well as interface circuitry that uses the similarity scores to generate a set of compliance steps that covers all compliance requirements from each of the received modules.",G06F 17/00; G06F 17/22; G06Q 30/00; G06Q 50/18; G06Q 50/26,"ASCENT TECHNOLOGIES, INC.","CLARK, Brian, T.; DOYLE, Chris","62/487,181 19.04.2017 US",AU-2018255335; GB-1916813.7
WO2018193241,PCT/GB2018/051008,17.04.2018,WO/2018/193241,25.10.2018,WO,SYSTEM AND METHOD FOR AUTOMATIC SPEECH ANALYSIS,"A computer implemented method for automatic speech analysis comprising setting a target phrase, the target phrase comprising a target phoneme, the target phoneme having corresponding target values of a set of phonological features associated therewith, wherein each target value is one of: an indication that the phonological feature should be present, an indication that the phonological feature should be absent, or an indication that the presence of the phonological feature is not specified, receiving a speech signal, wherein the speech signal comprises a user' s attempt to say the target phrase, analysing the speech signal to determine the phonological features present within a portion of the speech signal corresponding to the target phoneme and assigning a probability to each of the set of phonological features, comparing the probability assigned to each phonological feature based on the speech signal to the expected target value of that phonological feature within the phrase, determining a deviation from the comparison; and outputting the deviation to provide feedback on the closeness of the speech signal to the phrase.",G10L 25/60; G10L 15/02; G10L 25/30; G10L 15/16,OXFORD UNIVERSITY INNOVATION LIMITED,"ARORA, Vipul; LAHIRI, Aditi; REETZ, Henning",1706078.1 18.04.2017 GB,EP-2018721102
WO2019235821,PCT/KR2019/006746,04.06.2019,WO/2019/235821,12.12.2019,WO,OPTIMIZATION TECHNIQUE FOR FORMING DNN CAPABLE OF PERFORMING REAL-TIME INFERENCES IN MOBILE ENVIRONMENT,"Provided is a system comprising at least one processor implemented so as to execute a computer-readable command, wherein the at least one processor comprises a learning part for learning a deep neural network (DNN)-based style transfer model by using an image of a specific style to be learned, and the style transfer model is a DNN model having a structure in which the number of deep layers is reduced through transfer learning using a previously learned result.",G06N 3/08; G06N 3/04,NAVER CORPORATION; 네이버 주식회사,"CHO, Sungtak; 조성택; LEE, Young Soo; 이영수; LEE, Dongju; 이동주; KIM, SungHo; 김성호; CHANG, Joon-kee; 장준기",10-2018-0064897 05.06.2018 KR,
WO2020055615,PCT/US2019/049185,30.08.2019,WO/2020/055615,19.03.2020,WO,AI SOFTWARE TESTING SYSTEM AND METHOD,"A system for performing software testing uses machine learning to extract features from a user interface of an app, classify screen types and screen elements of the user interface, and implement flows of test sequences to test the app. Training is performed to train the system to learn common application states of an application graph and to navigate through an application. In some implementations, the training includes Q-leaming to learn how to navigate to a selected screen state. In some implementations, there is reuse of classifiers cross-application and cross platform.",G06F 11/36; G06N 3/08,"APPDIFF, INC.","ARBON, Jason, Joseph; LIU, Justin, Mingjay; NAVRIDES, Christopher, Randall","16/400,861 01.05.2019 US; 62/731,717 14.09.2018 US",
WO2018125585,PCT/US2017/066237,14.12.2017,WO/2018/125585,05.07.2018,WO,GRAPH LONG SHORT TERM MEMORY FOR SYNTACTIC RELATIONSHIP DISCOVERY,"Long short term memory units that accept a non-predefined number of inputs are used to provide natural language relation extraction over a user-specified range on content. Content written for human consumption is parsed with distant supervision in segments (e.g., sentences, paragraphs, chapters) to determine relationships between various words within and between those segments.",G06F 17/30; G06F 17/20; G06N 3/04; G06N 5/02,"MICROSOFT TECHNOLOGY LICENSING, LLC","QUIRK, Christopher Brian; TOUTANOVA, Kristina Nikolova; YIH, Wen-Tau; POON, Hoifung; PENG, Nanyun","15/395,961 30.12.2016 US",
WO2012000649,PCT/EP2011/003176,28.06.2011,WO/2012/000649,05.01.2012,WO,METHOD FOR CONTROLLING A LASER PROCESSING OPERATION BY MEANS OF A REINFORCEMENT LEARNING AGENT AND LASER MATERIAL PROCESSING HEAD USING THE SAME,"The present invention relates to a method for controlling a processing operation of a workpiece by means of a Reinforcement Learning (RL) agent unit, comprising the steps of: (a) observing an interaction zone in the workpiece by means of at least one radiation sensor to generate at least one sensor signal st, wherein the workpiece is processed using an actuator having an initial actuator value at; (b) determining a basis function Φ(st) from the set of sensor signals st; (c) determining a reward function rt giving the probability of good results of the processing operation; (d) choosing a next actuator value at+1 on the basis of a policy π depending on the reward function rt and the basis function Φ(st); and (e) repeating the steps (a) to (d) for further time points to perform a RL controlled processing operation.",B23K 26/00; G06T 7/00; G05B 13/00; G05B 19/408,"PRECITEC KG; PRECITEC ITM GMBH; STORK GENANNT WERSBORG, Ingo; GARCEA, Adrian","STORK GENANNT WERSBORG, Ingo; GARCEA, Adrian",10006692.7 28.06.2010 EP; 10012614.3 30.09.2010 EP; 10015914.4 21.12.2010 EP; 11000995.8 08.02.2011 EP; 11001371.1 18.02.2011 EP; 11004209.0 20.05.2011 EP,EP-2011741515; US-13807290
WO2019169400,PCT/US2019/020585,04.03.2019,WO/2019/169400,06.09.2019,WO,LEARNING COMMUNICATION SYSTEMS USING CHANNEL APPROXIMATION,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training and deploying machine-learned communication over RF channels. In some implementations, information is obtained. An encoder network is used to process the information and generate a first RF signal. The first RF signal is transmitted through a first channel. A second RF signal is determined that represents the first RF signal having been altered by transmission through the first channel. Transmission of the first RF signal is simulated over a second channel implementing a machine-learning network, the second channel representing a model of the first channel. A simulated RF signal that represents the first RF signal having been altered by simulated transmission through the second channel is determined. A measure of distance between the second RF signal and the simulated RF signal is calculated. The machine-learning network is updated using the measure of distance.",G06N 3/08; G06N 3/10; H04W 72/06; H04W 72/08; H04W 72/10,DEEPSIG INC,"O'SHEA, Tim; HILBURN, Ben; TAMOGHNA, Roy; WEST, Nathan","62/637,770 02.03.2018 US; 62/664,306 30.04.2018 US",
WO2017091751,PCT/US2016/063641,23.11.2016,WO/2017/091751,01.06.2017,WO,DEPLOYED END-TO-END SPEECH RECOGNITION,"Embodiments of end-to-end deep learning systems and methods are disclosed to recognize speech of vastly different languages, such as English or Mandarin Chinese. In embodiments, the entire pipelines of hand-engineered components are replaced with neural networks, and the end-to-end learning allows handling a diverse variety of speech including noisy environments, accents, and different languages. Using a trained embodiment and an embodiment of a batch dispatch technique with GPUs in a data center, an end-to-end deep learning system can be inexpensively deployed in an online setting, delivering low latency when serving users at scale.",G10L 15/16; G10L 15/06; G10L 15/08; G10L 15/183,BAIDU USA LLC,"CATANZARO, Bryan; CHEN, Jingdong; CHRZANOWSKI, Mike; ELSEN, Erich; ENGEL, Jesse; FOUGNER, Christopher; HAN, Xu; HANNUN, Awni; PRENGER, Ryan; SATHEESH, Sanjeev; SENGUPTA, Shubhabrata; YOGATAMA, Dani; WANG, Chong; ZHAN, Jun; ZHU, Zhenyao; AMODEI, Dario","62/260,206 25.11.2015 US; 15/358,102 21.11.2016 US; 15/358,083 21.11.2016 US",JP-2017544340; KR-1020177023173
WO2019116252,PCT/IB2018/059928,12.12.2018,WO/2019/116252,20.06.2019,WO,GUIDING MACHINE LEARNING MODELS AND RELATED COMPONENTS,"Techniques facilitating guiding machine learning models and related components are provided. In one example, a computer-implemented method comprises identifying, by a device operatively coupled to a processor, a set of models, wherein the set of models includes respective model components; determining, by the device, one or more model relations among the respective model components, wherein the one or more model relations respectively comprise a vector of component relations between respective pairwise ones of the model components; and suggesting, by the device, a subset of the set of models based on a mapping of the component relations.",G06F 17/00,INTERNATIONAL BUSINESS MACHINES CORPORATION; IBM UNITED KINGDOM LIMITED; IBM (CHINA) INVESTMENT COMPANY LIMITED,"WESTERINK, Peter; MUMMERT, Todd, William; BOBROFF, Norman; BRAZ, Alan; HIRZEL, Martin","15/840,315 13.12.2017 US",
WO2016090044,PCT/US2015/063527,02.12.2015,WO/2016/090044,09.06.2016,WO,AUTOMATIC DEFECT CLASSIFICATION WITHOUT SAMPLING AND FEATURE SELECTION,"Systems and methods for defection classification in a semiconductor process are provided. The system includes a communication line configured to receive a defect image of a wafer from the semiconductor process and a deep-architecture neural network in electronic communication with the communication line. The neural network has a first convolution layer of neurons configured to convolve pixels from the defect image with a filter to generate a first feature map. The neural network also includes a first subsampling layer configured to reduce the size and variation of the first feature map. A classifier is provided for determining a defect classification based on the feature map. The system may include more than one convolution layers and/or subsampling layers. A method includes extracting one or more features from a defect image using a deep-architecture neural network, for example a convolutional neural network.",H01L 21/66; G06F 19/00,KLA-TENCOR CORPORATION,"CHANG, Wei; OLAVARRIA, Ramon; RAO, Krishna","62/087,180 03.12.2014 US; 62/174,288 11.06.2015 US; 14/956,326 01.12.2015 US",SG-11201704384T; IL-252147; KR-1020177018319; JP-2017529635
WO2018053340,PCT/US2017/051891,15.09.2017,WO/2018/053340,22.03.2018,WO,SUPER RESOLUTION USING A GENERATIVE ADVERSARIAL NETWORK,"A neural network is trained to process received visual data to estimate a high-resolution version of the visual data using a training dataset and reference dataset. A set of training data is generated and a generator convolutional neural network parameterized by first weights and biases is trained by comparing characteristics of the training data to characteristics of the reference dataset. The first network is trained to generate super-resolved image data from low-resolution image data and the training includes modifying first weights and biases to optimize processed visual data based on the comparison between the characteristics of the training data and the characteristics of the reference dataset. A discriminator convolutional neural network parameterized by second weights and biases is trained by comparing characteristics of the generated super-resolved image data to characteristics of the reference dataset, and where the second network is trained to discriminate super-resolved image data from real image data.",G06T 3/40; G06N 3/04; G06N 3/08,"TWITTER, INC.","SHI, Wenzhe; LEDIG, Christian; WANG, Zehan; THEIS, Lucas; HUSZAR, Ferenc","62/395,186 15.09.2016 US; 62/422,012 14.11.2016 US",
WO2010105988,PCT/EP2010/053204,12.03.2010,WO/2010/105988,23.09.2010,WO,NATURAL COMPUTATIONAL MACHINE,"Natural computational machine comprising : a system including a plurality of artificial neural networks and in which each of the neural networks is composed of a plurality of processing nodes, which are interconnected for receiving and transmitting communication signals from and to one or more of the other nodes, some input nodes having an input for signals received from outside the network, and some output nodes having outputs for signals transmitted outside the network; a database of known case data organized in records, each of which belongs to a quality class of a predetermined number of classes. According to the invention, said system comprises an artificial neural network for each different class among those provided and each of the neural networks is a self-organizing neural network designed to determine the class to which a data record belongs. Each neural network is trained using the known records belonging to the same class with which the neural network is associated, and the class for a record of unknown class is selected as the class associated with the neural network that obtained, upon record processing, the lowest value for the difference between the network performance parameters determined during training and during processing of said record.",G06N 3/04; G06N 3/08,"SEMEION CENTRO RICERCHE; BRACCO IMAGING SPA; BUSCEMA, Paolo, Massimo","BUSCEMA, Paolo, Massimo",09425114.7 20.03.2009 EP,
WO2019180255,PCT/EP2019/057336,22.03.2019,WO/2019/180255,26.09.2019,WO,WARE IDENTIFICATION AND HANDLING APPARATUS,"A warewasher system for identifying and handling wares is disclosed. The system comprises a first apparatus for identifying and locating a ware to be transported from a first location to a second location in the warewasher system, and a second apparatus for transporting the ware. The first apparatus comprises means for identifying a region of an image that contains an image part corresponding to at least a part of the ware. The identified region has a perimeter that does not coincide with the perimeter of the image part. The first apparatus also comprises means for determining a location of the region, within the image, and for generating information representing a corresponding spatial location in a receiving area. The second apparatus comprises means for receiving the generated information, and a resilient handling tool for transporting the ware, even when the estimated spatial location is not coincident with the actual spatial location.",B25J 9/16; A47L 15/24; B25J 11/00; G06K 9/00,ELIOR GROUP,"YOUNG, Douglas, Geoffrey; BUCKLEY, James, Edward; FLETCHER, Henry, Matthew, Lawrence; ROBERTS, Christopher, John",1804637.5 22.03.2018 GB,
WO2019057987,PCT/EP2018/075953,25.09.2018,WO/2019/057987,28.03.2019,WO,MACHINE VISION SYSTEM,"A machine vision system comprising receiving means configured to receive image data indicative of an object to be classified where there is provided processing means with an initial neural network, the processing means configured to determine a differential equation describing the initial neural network algorithm based on the neural network parameters, and to determine a solution to the differential equation in the form of a series expansion; and to convert the series expansion to a finite series expansion by limiting the number of terms in the series expansion to a finite number; and to determine the output classification in dependence on the finite series expansion.",G06K 9/46; G06K 9/62; G06N 3/04; G06N 3/08; G06K 9/00,"NISSAN MOTOR CO., LTD.","BATCHELOR, Andrew; JONES, Garry; SATO, Yoshinori",1715456.8 25.09.2017 GB,
WO2019231844,PCT/US2019/033930,24.05.2019,WO/2019/231844,05.12.2019,WO,METHODS AND SYSTEMS FOR UTILIZING QUANTITATIVE IMAGING,"Systems and methods for analyzing pathologies utilizing quantitative imaging are presented herein. Advantageously, the systems and methods of the present disclosure utilize a hierarchical analytics framework that identifies and quantify biological properties/analytes from imaging data and then identifies and characterizes one or more pathologies based on the quantified biological properties/analytes. This hierarchical approach of using imaging to examine underlying biology as an intermediary to assessing pathology provides many analytic and processing advantages over systems and methods that are configured to directly determine and characterize pathology from underlying imaging data.",G06K 9/00,ELUCID BIOIMAGING INC.,"BUCKLER, Mark A.; PAIK, David S.; VALTCHINOV, Vladimir; BUCKLER, Andrew J.","62/676,975 27.05.2018 US; 62/771,448 26.11.2018 US",
WO2018128654,PCT/US2017/053238,25.09.2017,WO/2018/128654,12.07.2018,WO,SYSTEM AND METHOD FOR DESIGNING SYSTEM ON CHIP (SOC) CIRCUITS BY SYNCHRONIZING A HIERARCHY OF SMDPS,"The embodiments herein discloses a system and method for designing SoC by synchronizing a hierarchy of SMDPs. Reinforcement Learning is done either hierarchically in several steps or in a single-step comprising environment, tasks, agents and experiments, to have access to SoC (System on a Chip) related information. The ΑI agent is configured to learn from tire interaction and plan the implementation of a SoC circuit design. Q values generated for each domain and sub domain are stored in a hierarchical SMDP structure in a form of SMDP Q table in a big date database. An optimal chip architecture corresponding to a maximum Q value of a top level in the SMDP Q table is acquired and stored in a database for learning and inference. Desired SoC configuration is optimized and generated based on the optimal chip architecture and the generated chip specific graph library.",G06F 17/50,ALPHAICS CORPORATION,"NAGARAJA, Nagendra","15/499,832 27.04.2017 US; 62/443,803 08.01.2017 US; 15/697,803 07.09.2017 US",JP-2019558331; EP-2017890156
WO2020065326,PCT/GB2019/052721,26.09.2019,WO/2020/065326,02.04.2020,WO,HIERARCHICAL RELATIONSHIP EXTRACTION,"Methods, apparatus, system and computer-implemented method are provided for embedding a portion of text describing one or more entities of interest and a relationship. The portion of text describes a relationship for the one or more entity(ies) of interest, where the portion of text includes multiple separable entities describing the relationship and the entity(ies). The multiple separable entities including the one or more entity(ies) of interest and one or more relationship entity(ies). A set of embeddings for each of the separable entities is generated, where the set of embeddings for a separable entity includes an embedding for the separable entity and an embedding for at least one entity associated with the separable entity. One or more composite embeddings may be formed based on at least one embedding from each of the sets of embeddings. The composite embedding(s) may be sent for input to a machine learning model or classifier.",G06N 20/00; G06N 3/04,BENEVOLENTAI TECHNOLOGY LIMITED,"CREED, Paidi; SIM, Aaron Jefferson Khey Jin",1815664.6 26.09.2018 GB,
WO2019104217,PCT/US2018/062314,21.11.2018,WO/2019/104217,31.05.2019,WO,SYSTEM METHOD AND COMPUTER-ACCESSIBLE MEDIUM FOR CLASSIFYING BREAST TISSUE USING A CONVOLUTIONAL NEURAL NETWORK,"An exemplary system, method and computer-accessible medium for classifying a breast tissue(s) a patient(s) can include, for example, receiving an image(s) of an internal portion(s) of a breast of the patient(s), and automatically classifying the breast tissue(s) of the breast by applying a neural network(s) to the image(s). The automatic classification can include a classification as to whether the breast tissue(s) is atypical ductal hyperplasia or ductal carcinoma. The automatic classification can include a classification as to whether the breast tissue(s) is a cancerous tissue or a non-cancerous tissue. The image(s) can be a mammographic image or an optical coherence tomography image.",G06T 7/00,THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK,"HA, Richard","62/589,924 22.11.2017 US",
EP13156892,97402030,29.08.1997,0911741,28.04.1999,EP,System adapted to develop conditioned reflexes,"An architecture, which may be embodied in hardware, software or a combination of the two, is adapted to develop reflexes conditioned based on influences external to the architecture (such as user activity) in order to optimise the fulfilment of operational requirements of application modules (10) in the architecture. The architecture includes, in addition to one or more application modules (10), modulation modules (20) involved in the regulation of the functions performed by the application modules, a central regulator (5) for registering the existence of an unsatisfied operational requirement in an application module (10) and for controlling the modulation modules (20) to seek a solution by a strategy including the manifestation (a) of the ""need"" condition externally to the architecture via output modules (30) and this manifestation is detected by the architecture itself via input modules (40), which also detect external phenomena indicating the activity of a user or external agent. An external event or input (c) leads to satisfaction of the operational requirement. A conditioning system (8) receiving inputs from the application modules (10), modulation modules (20), central regulator (5), input and output modules (30,40) generates, on the basis of conditioning received through past experience, a signal ( epsilon ) indicating the expectation of satisfaction of the operational requirement. The operation of the architecture responds to the value of this expectation signal. <IMAGE>",G06F 15/18; G05B 13/02; G06F 9/44; G06N 3/00; G06N 5/04; G06N 99/00,SONY FRANCE SA,NUMAOKA CHISATO,97402030 29.08.1997 EP,
WO2018200316,PCT/US2018/028458,20.04.2018,WO/2018/200316,01.11.2018,WO,OCTREE-BASED CONVOLUTIONAL NEURAL NETWORK,"The implementations of the subject matter described herein relate to an octree-based convolutional neural network. In some implementations, there is provided a computer-implemented method for processing a three-dimensional shape. The method comprises obtaining an octree for representing the three-dimensional shape. Nodes of the octree include empty nodes and non-empty nodes. The empty nodes exclude the three-dimensional shape and are leaf nodes of the octree, and the non-empty nodes include at least a part of the three-dimensional shape. The method further comprises for nodes in the octree with a depth associated with a convolutional layer of a convolutional neural network, performing a convolutional operation of the convolutional layer to obtain an output of the convolutional layer.",G06T 17/00; G06N 3/04,"MICROSOFT TECHNOLOGY LICENSING, LLC","WANG, Pengshuai; LIU, Yang; TONG, Xin",201710297300.4 28.04.2017 CN,RU-2019138328; CA-3056959; KR-1020197031714; EP-2018725346; SG-11201909561R; JP-2019549375; AU-2018258094; IL-270192; MX-MX/a/2019/012673
WO2019092439,PCT/GB2018/053259,12.11.2018,WO/2019/092439,16.05.2019,WO,DETECTING STATIC PARTS OF A SCENE,"A method of distinguishing between static and ephemeral parts of an experienced environment in representations of the experienced environment, the method comprising automatically generating training data comprising a set of training representations and corresponding ephemerality masks segmenting each of the training representations into static and ephemeral parts, wherein the training representations are representations of a training environment, and wherein the ephemerality masks are generated by comparing each training representation to a corresponding portion of a 3D static model of the static parts of the training environment, computing a discrepancy between the training representation and the corresponding portion of the 3D static model; and calculating an ephemerality mask for the training representation based on the discrepancy, the ephemerality mask segmenting the training representation into static and ephemeral parts, training a neural network with the training data, providing experienced representations of the environment to the trained neural network; and predicting, using the trained neural network, which parts of the experienced representation relate to static parts of the experienced environment and which to ephemeral parts of the experienced environment.",G06K 9/62; G06K 9/00; G06N 3/08,OXFORD UNIVERSITY INNOVATION LIMITED,"POSNER, Ingmar; BARNES, Daniel; MADDERN, Will; PASCOE, Geoffrey",1718692.5 13.11.2017 GB,
WO2009100417,PCT/US2009/033532,09.02.2009,WO/2009/100417,13.08.2009,WO,METHOD FOR TRAINING A LEARNING MACHINE HAVING A DEEP MULTI-LAYERED NETWORK WITH LABELED AND UNLABELED TRAINING DATA,"A method for training a learning machine having a deep network with a plurality of layers, includes applying a regularizer to one or more of the layers of the deep network; training the regularizer with unlabeled data; and training the deep network with labeled data. Also, an apparatus for use in discriminative classification and regression, including an input device for inputting unlabeled and labeled data associated with a phenomenon of interest; a processor; and a memory communicating with the processor. The memory includes instructions executable by the processor for implementing a learning machine having a deep network structure and training the learning machine by applying a regularizer to one or more of the layers of the deep network; training the regularizer with unlabeled data; and training the deep network with labeled data.",G06F 15/18; G06F 9/44,"NEC LABORATORIES AMERICA, INC.","WESTON, Jason; COLLOBERT, Ronan","61/026,860 07.02.2008 US; 12/367,278 06.02.2009 US",EP-2009708540
WO2018071424,PCT/US2017/055948,10.10.2017,WO/2018/071424,19.04.2018,WO,ALL-IN-ONE CONVOLUTIONAL NEURAL NETWORK FOR FACE ANALYSIS,"Various facial recognition systems may benefit from appropriate use of computer systems. For example, certain face analysis systems may benefit from an all-in-one convolutional neural network that has been appropriately configured. A method can include obtaining an image of a face. The method can also include processing the image of the face using a first set of convolutional network layers configured to perform subject-independent tasks. The method can further include subsequently processing the image of the face using a second set of convolutional network layers configured to perform subject-dependent tasks. The second set of convolutional network layers can be integrated with the first set of convolutional network layers to form a single convolutional neural network. The method can additionally include outputting facial image detection results based on the processing and subsequent processing.",G06K 9/46; G06K 9/62; G06K 9/66,"UNIVERSITY OF MARYLAND, COLLEGE PARK","RANJAN, Rajeev; SANKARANARAYANAN, Swaminathan; CASTILLO, Carlos; CHELLAPPA, Ramalingam","62/406,260 10.10.2016 US",
WO2018094360,PCT/US2017/062626,20.11.2017,WO/2018/094360,24.05.2018,WO,METHODS AND SYSTEMS FOR PREDICTING DNA ACCESSIBILITY IN THE PAN-CANCER GENOME,"Techniques are provided for predicting DNA accessibility. DNase-seq data files and RNA-seq data files for a plurality of cell types are paired by assigning DNase-seq data files to RNA-seq data files that are at least within a same biotype. A neural network is configured to be trained using batches of the paired data files, where configuring the neural network comprises configuring convolutional layers to process a first input comprising DNA sequence data from a paired data file to generate a convolved output, and fully connected layers following the convolutional layers to concatenate the convolved output with a second input comprising gene expression levels derived from RNA-seq data from the paired data file and process the concatenation to generate a DNA accessibility prediction output. The trained neural network is used to predict DNA accessibility in a genomic sample input comprising RNA-seq data and whole genome sequencing for a new cell type.",G06F 19/24; G06F 19/12; G06F 19/26; C12Q 1/68,"NANTOMICS, LLC; NANT HOLDINGS IP, LLC","WNUK, Kamil; SUDOL, Jeremi; RABIZADEH, Shahrooz; SOON-SHIONG, Patrick; SZETO, Christopher; VASKE, Charles","62/540,523 02.08.2017 US; 62/481,574 04.04.2017 US; 62/424,370 18.11.2016 US",AU-2017362569; IL-266692; EP-2017870742; CA-3044254; KR-1020197016912
WO2018165103,PCT/US2018/021060,06.03.2018,WO/2018/165103,13.09.2018,WO,MACHINE LEARNING FOR DIGITAL PATHOLOGY,A method assessing tissue morphology using machine learning includes a step of training a machine learnable device to predict the status of a diagnostic feature in stained tissue samples. The machine learnable device is trained with a characterized set of digital images of stained tissue samples. Each digital image of the characterized set has a known status for the diagnostic feature and an extracted feature map provides values for a extracted feature over an associated 2-dimensional grid of spatial locations. A step of inputting the set of extracted feature maps is inputted into the machine learnable device to form associations therein between the set of extracted feature maps to and the known status for the diagnostic feature to form a trained machine learnable device. The status for the diagnostic feature of a stained tissue sample of unknown status for the diagnostic feature is predicted from the trained machine learnable device.,G16H 50/20; G16H 50/30; G06T 7/00; G01N 33/574,UNIVERSITY OF SOUTHERN CALIFORNIA,"AGUS, David B.; MACKLIN, Paul Thomas; RAWAT, Rishi Raghav; RUDERMAN, Daniel Lee","62/467,579 06.03.2017 US",EP-2018763650
EP174230847,15198654,09.12.2015,3035246,22.06.2016,EP,"IMAGE RECOGNITION METHOD AND APPARATUS, IMAGE VERIFICATION METHOD AND APPARATUS, LEARNING METHOD AND APPARATUS TO RECOGNIZE IMAGE, AND LEARNING METHOD AND APPARATUS TO VERIFY IMAGE","A method of recognizing a feature of an image may include receiving an input image including an object; extracting first feature information using a first layer of a neural network, the first feature information indicating a first feature corresponding to the input image among a plurality of first features; extracting second feature information using a second layer of the neural network, the second feature information indicating a second feature among a plurality of second features, the indicated second feature corresponding to the first feature information; and recognizing an element corresponding to the object based on the first feature information and the second feature information.",G06K 9/46; G06K 9/00; G06K 9/62; G06N 3/04,SAMSUNG ELECTRONICS CO LTD,HAN HANSEUNGJU; SUH SUHSUNGJOO; HAN HANJAEJOON; CHOI CHOICHANG KYU,20140180213 15.12.2014 KR; 20150138491 01.10.2015 KR,
WO2018048507,PCT/US2017/042136,14.07.2017,WO/2018/048507,15.03.2018,WO,NEURAL NETWORK FOR GENERATING SYNTHETIC MEDICAL IMAGES,"Systems, computer-implemented methods, and computer readable media for generating a synthetic image of an anatomical portion based on an origin image of the anatomical portion acquired by an imaging device using a first imaging modality are disclosed. These systems may be configured to receive the origin image of the anatomical portion acquired by the imaging device using the first imaging modality, receive a convolutional neural network model trained for predicting the synthetic image based on the origin image, and convert the origin image to the synthetic image through the convolutional neural network model. The synthetic image may resemble an imaging of the anatomical portion using a second imaging modality differing from the first imaging modality.",A61N 5/10; A61B 5/00; G01R 33/56; G06T 11/00,"ELEKTA, INC.","HAN, Xiao","62/384,171 06.09.2016 US; 62/408,676 14.10.2016 US",AU-2017324069; EP-2017751509; CN-201780065652.5; JP-2019534634; RU-2019109966
WO2019104221,PCT/US2018/062319,21.11.2018,WO/2019/104221,31.05.2019,WO,SYSTEM METHOD AND COMPUTER-ACCESSIBLE MEDIUM FOR DETERMINING BREAST CANCER RESPONSE USING A CONVOLUTIONAL NEURAL NETWORK,"An exemplary system, method and computer-accessible medium for determining a breast cancer response(s) for a patient(s) can include, for example, receiving an image(s) of an internal portion(s) of a breast of the patient(s), and determining the breast cancer response(s) by applying a neural network(s) to the image(s). The breast cancer response(s) can be a response to at least one chemotherapy treatment. The breast cancer response(s) can include an Oncotype DX recurrence score. The breast cancer response(s) can be a neoadjuvant axillary response. The image(s) can be a magnetic resonance image(s) (MRI). The MRI(s) can include a dynamic contrast enhanced MRI(s).",G06T 7/00,THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK,"HA, Richard","62/589,924 22.11.2017 US",
WO2019051271,PCT/US2018/050020,07.09.2018,WO/2019/051271,14.03.2019,WO,SYSTEMS AND METHODS FOR BRAIN HEMORRHAGE CLASSIFICATION IN MEDICAL IMAGES USING AN ARTIFICIAL INTELLIGENCE NETWORK,"Systems and methods for rapid, accurate, fully-automated, brain hemorrhage deep learning (DL) based assessment tools are provided, to assist clinicians in the detection & characterization of hemorrhages or bleeds. Images may be acquired from a subject using an imaging source, and preprocessed to cleanup, reformat, and perform any needed interpolation prior to being analyzed by an artificial intelligence network, such as a convolutional neural network (CNN). The artificial intelligence network identifies and labels regions of interest in the image, such as identifying any hemorrhages or bleeds. An output for a user may also include a confidence value associated with the identification.",A61B 5/00,THE GENERAL HOSPITAL CORPORATION,"DO, Synho; LEV, Michael; GONZALEZ, Gilberto","62/555,783 08.09.2017 US",
WO2020025684,PCT/EP2019/070649,31.07.2019,WO/2020/025684,06.02.2020,WO,METHOD AND SYSTEM FOR AUGMENTED IMAGING IN OPEN TREATMENT USING MULTISPECTRAL INFORMATION,"Disclosed herein is a method of generating augmented images of tissue of a patient undergoing open treatment, in particular open surgery, wherein each augmented image associates at least one tissue parameter with a region or pixel of the image of the tissue, said method comprising the following steps: estimating a spectral composition of light illuminating a region of interest of the tissue, obtaining one or more multispectral images of the region of interest, applying a machine learning based regressor or classifier to the one or more multispectral images, or an image derived from said multispectral image, to thereby derive one or more tissue parameters associated with image regions or pixels of the corresponding multispectral image, wherein said regressor or classifier has been trained to predict the one or more tissue parameters from a multispectral image under a given spectral composition of illumination, wherein the regressor or classifier employed is made to match the estimated spectral composition of light illuminating said region of interest of the tissue.",A61B 5/00; A61B 5/1455; A61B 5/1495; G06T 7/00,DEUTSCHES KREBSFORSCHUNGSZENTRUM STIFTUNG DES ÖFFENTLICHEN RECHTS,"MAIER-HEIN, Lena; WIRKERT, Sebastian Josef; VEMURI, Anant Suraj; MENJIVAR, Leonardo Antonio Ayala; SEIDLITZ, Silvia; KIRCHNER, Thomas; ADLER, Tim",18186670.8 31.07.2018 EP,
EP251296618,17865943,18.08.2017,3534303,04.09.2019,EP,INFORMATION PROCESSOR AND INFORMATION-PROCESSING METHOD,"[Problem] To predict, in advance, learning performance that corresponds to the labeled state of learning data. [Solution] Provided is an information processor provided with a data distribution presentation unit for performing dimensionality reduction on inputted learning data and generating a data distribution diagram pertaining to the learning data, a learning performance prediction unit for predicting learning performance on the basis of the data distribution diagram and a labeled state pertaining to the learning data, and a display control unit for controlling display pertaining to the data distribution diagram and the learning performance, the data distribution diagram including information about overlapping of clusters constituted from the learning data and information about the number of learning data that belong to each cluster.",G06N 99/00; G06N 3/04; G06N 3/08; G06N 20/10,SONY CORP,IDE NAOKI,2016209332 26.10.2016 JP; 2017029691 18.08.2017 JP,
WO2018084942,PCT/US2017/052252,19.09.2017,WO/2018/084942,11.05.2018,WO,DEEP CROSS-CORRELATION LEARNING FOR OBJECT TRACKING,An artificial neural network for learning to track a target across a sequence of frames includes a representation network configured to extract a target region representation from a first frame and a search region representation from a subsequent frame. The artificial neural network also includes a cross-correlation layer configured to convolve the extracted target region representation with the extracted search region representation to determine a cross-correlation map. The artificial neural network further includes a loss layer configured to compare the cross-correlation map with a ground truth cross-correlation map to determine a loss value and to back propagate the loss value into the artificial neural network to update filter weights of the artificial neural network.,G06N 3/04; G06N 3/08; G06K 9/32,QUALCOMM INCORPORATED,"HABIBIAN, Amirhossein; SNOEK, Cornelis, Gerardus, Maria","62/418,707 07.11.2016 US; 15/708,014 18.09.2017 US",
WO2018089783,PCT/US2017/061090,10.11.2017,WO/2018/089783,17.05.2018,WO,AUTOMATED STEREOLOGY FOR DETERMINING TISSUE CHARACTERISTICS,"Systems and methods for automated stereology are provided. A method can include providing an imager for capturing a Z-stack of images of a three-dimensional (3D) object,; constructing extended depth of field (EDF) images from the Z-stack of images; performing a segmentation method on the EDF images including estimating a Gaussian Mixture Model (GMM), performing morphological operations, performing watershed segmentation, constructing Voronoi diagrams and perfomiing boundary smoothing; and determining one or more stereology parameters such as number of cells in a region.",H04N 13/02; G06K 9/00,"UNIVERSITY OF SOUTH FLORIDA; STEREOLOGY RESOURCE CENTER, INC.","MOUTON, Peter, Randolph; PHOULADY, Hady, Ahmady; GOLDGOF, Dmitry; HALL, Lawrence, O.","62/420,771 11.11.2016 US",EP-2017870047
WO2019036845,PCT/CN2017/098317,21.08.2017,WO/2019/036845,28.02.2019,WO,"METHOD, SYSTEM AND APPARATUS FOR PATTERN RECOGNITION","A method for pattern recognition may be provided, comprising: receiving data； processing the data with a trained convolutional neural network so as to recognize a pattern in the data, wherein the convolutional neural network comprises at least: an input layer, at least one convolutional layer, at least one batch normalization layer, at least one activation function layer, and an output layer； and wherein processing the data with a trained convolutional neural network so as to recognize a pattern in the data comprises: processing values outputted by a batch normalization layer so that the histogram of the processed values is flatter than the histogram of the values, and outputting the processed values to an activation function layer. A corresponding apparatus and system for pattern recognition, as well as a computer readable medium, a method for implementing a convolutional neural network and a convolutional neural network are also provided.",G06K 9/62,"NOKIA TECHNOLOGIES OY; NOKIA TECHNOLOGIES (BEIJING) CO., LTD.","CAO, Jiale",,
WO2016089313,PCT/SG2015/050488,07.12.2015,WO/2016/089313,09.06.2016,WO,SLEEP PROFILING SYSTEM WITH FEATURE GENERATION AND AUTO-MAPPING,"A method for profiling sleep of an individual is provided. The method includes defining a sleep feature space for the individual, measuring a brain wave for the individual during the individual's sleep, and mapping the sleep feature space in response to a comparison of the brain wave and a previous brain wave measurement used to define the sleep feature space. The brain wave may comprise a brain wave spectrum. The sleep feature space may comprise, or be composed of, spectral power and envelope measures. The method also includes modelling the mapped sleep feature space in response to recognized neural network patterns corresponding to each of a plurality of sleep stages derived from recognizing the neural network patterns from the sleep feature space and deriving a sleep profile for the individual from sleep stages determined in response to the modelled mapped sleep feature space and the brain wave of the individual.",A61B 5/00; A61B 5/0476; A61B 5/048,"AGENCY FOR SCIENCE, TECHNOLOGY AND RESEARCH","ZHANG, Zhuo; GUAN, Cuntai; ZHANG, Hai Hong; YANG, Huijuan",10201408145X 05.12.2014 SG,US-15533372; SG-11201704534W
WO2019213459,PCT/US2019/030496,02.05.2019,WO/2019/213459,07.11.2019,WO,SYSTEM AND METHOD FOR GENERATING IMAGE LANDMARKS,"A system, neural network, and corresponding method generate 3D landmarks associated with an object in a 2D image. An embodiment is a system comprising a neural network detector configured to produce planar coordinates of landmarks at points of the object in the 2D image and a depth coordinate estimator. The planar coordinates include planar coordinate pairs. The depth coordinate estimator is configured to receive the 2D image and the planar coordinates and to estimate a depth coordinate for each planar coordinate pair of each landmark to generate the 3D landmarks. The system reduces network parameters from MB to KB and has better performance relative to state-of-the-art methods. The system may be configured to apply the 3D landmarks for face alignment, virtual face makeup, face recognition, eye gaze tracking, face synthesis, or other face related application.",G06K 9/00; G06K 9/46,NORTHEASTERN UNIVERSITY,"FU, Yun; SUN, Bin","62/666,849 04.05.2018 US",
WO2020073114,PCT/CA2019/051401,01.10.2019,WO/2020/073114,16.04.2020,WO,IMAGE PROCESSING OF STREPTOCOCCAL INFECTION IN PHARYNGITIS SUBJECTS,"A method for determining a disease state prediction, relating to a potential disease or medical condition of a subject, includes accessing a set of subject images, the subject images capturing a part of a subject's body, anlaawad accessing a set of clinical factors from the subject. The clinical factors are collected by a device or a medical practitioner substantially contemporaneously with the capture of the subject images. The subject images are inputted into an image model to generate disease metrics for disease prediction for the subject. The disease metrics generated by the image model and the clinical factors are inputted into a classifier to determine the disease state prediction, and the disease state prediction is returned.",G16H 50/20; A61B 5/00; G06N 20/00; G06N 3/02; G16H 30/40,LIGHT AI INC.,"SARKARIA, Sarbjit; REBIFFE, Steven; GUPTA, Udit; MALIAPEN, Mahendran; WHITEHEAD, Peter","62/743,245 09.10.2018 US; 62/855,875 31.05.2019 US; 16/589,077 30.09.2019 US",
EP133202536,14189068,15.10.2014,2863340,22.04.2015,EP,Distributed machine learning intelligence development systems,,G06N 5/04; G06N 3/12,LOCKHEED CORP,HARRISON GREGORY ANHONY; WORDEN ERIC W; BRANT JONATHAN CHARLES; SMITH DAVID A,201314053811 15.10.2013 US,
WO2019107177,PCT/JP2018/042398,16.11.2018,WO/2019/107177,06.06.2019,WO,"INFORMATION PROCESSING APPARATUS, INFORMATION PROCESSING SYSTEM, INFORMATION PROCESSING METHOD, AND PROGRAM","An information processing method includes deducing a diagnosis name derived from a medical image on the basis of an image feature amount corresponding to a value indicating a feature of a medical image, deducing an image finding representing a feature of the medical image on the basis of the image feature amount, and presenting the image finding deduced in the deducing the image finding which is affected by an image feature amount common to the image feature amount that has affected the deduction of the diagnosis name in the deducing the diagnosis name and the diagnosis name to a user.",A61B 6/03; A61B 5/00; G16H 30/00,CANON KABUSHIKI KAISHA,KIKUCHI Toru,2017-230994 30.11.2017 JP,
WO2017091763,PCT/US2016/063661,23.11.2016,WO/2017/091763,01.06.2017,WO,END-TO-END SPEECH RECOGNITION,"Embodiments of end-to-end deep learning systems and methods are disclosed to recognize speech of vastly different languages, such as English or Mandarin Chinese. In embodiments, the entire pipelines of hand-engineered components are replaced with neural networks, and the end-to-end learning allows handling a diverse variety of speech including noisy environments, accents, and different languages. Using a trained embodiment and an embodiment of a batch dispatch technique with GPUs in a data center, an end-to-end deep learning system can be inexpensively deployed in an online setting, delivering low latency when serving users at scale.",G06F 17/28; G10L 15/04; G10L 15/06; G10L 15/08; G10L 15/183; G10L 15/28,BAIDU USA LLC,"CATANZARO, Bryan; CHEN, Jingdong; CHRZANOWSKI, Mike; ELSEN, Erich; ENGEL, Jesse; FOUGNER, Christopher; HAN, Xu; HANNUN, Awni; PRENGER, Ryan; SATHEESH, Sanjeev; SENGUPTA, Shubhabrata; YOGATAMA, Dani; WANG, Chong; ZHAN, Jun; ZHU, Zhenyao; AMODEI, Dario","62/260,206 25.11.2015 US; 15/358,102 21.11.2016 US; 15/358,083 21.11.2016 US",JP-2017544352; KR-1020177023177
WO2019222591,PCT/US2019/032815,17.05.2019,WO/2019/222591,21.11.2019,WO,SYNTHESIS OF SPEECH FROM TEXT IN A VOICE OF A TARGET SPEAKER USING NEURAL NETWORKS,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for speech synthesis. The methods, systems, and apparatus include actions of obtaining an audio representation of speech of a target speaker, obtaining input text for which speech is to be synthesized in a voice of the target speaker, generating a speaker vector by providing the audio representation to a speaker encoder engine that is trained to distinguish speakers from one another, generating an audio representation of the input text spoken in the voice of the target speaker by providing the input text and the speaker vector to a spectrogram generation engine that is trained using voices of reference speakers to generate audio representations, and providing the audio representation of the input text spoken in the voice of the target speaker for output.",G10L 13/033; G10L 13/04; G10L 25/30,GOOGLE LLC,"JIA, Ye; CHEN, Zhifeng; WU, Yonghui; SHEN, Jonathan; PANG, Ruoming; WEISS, Ron J.; MORENO, Ignacio Lopez; REN, Fei; ZHANG, Yu; WANG, Quan; NGUYEN, Patrick An Phu","62/672,835 17.05.2018 US",
WO2018093796,PCT/US2017/061618,14.11.2017,WO/2018/093796,24.05.2018,WO,DEEP LEARNING SYSTEM FOR CUBOID DETECTION,"Systems and methods for cuboid detection and keypoint localization in images are disclosed. In one aspect, a deep cuboid detector can be used for simultaneous cuboid detection and keypoint localization in monocular images. The deep cuboid detector can include a plurality of convolutional layers and non-convolutional layers of a trained convolution neural network for determining a convolutional feature map from an input image. A region proposal network of the deep cuboid detector can determine a bounding box surrounding a cuboid in the image using the convolutional feature map. The pooling layer and regressor layers of the deep cuboid detector can implement iterative feature pooling for determining a refined bounding box and a parameterized representation of the cuboid.",G06F 3/01; G06F 3/0346; G06K 9/66; G06N 3/04; G06T 7/215,"MAGIC LEAP, INC.","MALISIEWICZ, Tomasz; RABINOVICH, Andrew; BADRINARAYANAN, Vijay; DWIBEDI, Debidatta","62/422,547 15.11.2016 US",EP-2017870853; CA-3043352; JP-2019524982; KR-1020197015993; IL-266482; CN-201780082830.5; AU-2017361061
WO2019175870,PCT/IL2019/050274,12.03.2019,WO/2019/175870,19.09.2019,WO,AUTOMATED BONE SEGMENTATION IN IMAGES,"A method for automated segmentation of a bone in an image dataset of a region of a human body, wherein said region comprises at least two adjacent bones, and wherein one of the bones comprises a shaft region and a head region, the method comprising identifying in the image dataset voxels belonging to a contiguous volume comprising both bones based on a density threshold; extracting a subset comprising the head region of the first bone, based on a boundary image slice; and applying a trained machine learning classifier to said subset, to generate a classification of each of voxel as belonging to one of the bones or a none-bone tissue.",G06T 7/136; G06T 7/174; G06T 7/00,PERSIMIO LTD.,"BOOK, Gilad; YOSIBASH, Zohar; TRABELSI, Nir","62/641,483 12.03.2018 US",
WO2018213108,PCT/US2018/032197,11.05.2018,WO/2018/213108,22.11.2018,WO,DOMAIN ADAPTATION AND FUSION USING WEAKLY SUPERVISED TARGET IRRELEVANT DATA,Aspects include receiving a request to perform an image classification task in a target domain. The image classification task includes identifying a feature in images in the target domain. Classification information related to the feature is transferred from a source domain to the target domain. The transferring includes receiving a plurality of pairs of task-irrelevant images that each includes a task-irrelevant image in the source domain and in the target domain. The task-irrelevant image in the source domain has a fixed correspondence to the task-irrelevant image in the target domain. A target neural network is trained to perform the image classification task in the target domain. The training is based on the plurality of pairs of task-irrelevant images. The image classification task is performed in the target domain and includes applying the target neural network to an image in the target domain and outputting an identified feature.,G06K 9/62; G06K 9/46,SIEMENS MOBILITY GMBH,"WU, Ziyan; PENG, Kuan-Chuan; ERNST, Jan","62/506,128 15.05.2017 US; 62/528,690 05.07.2017 US; 15/720,424 29.09.2017 US",EP-2018732984
WO2019232099,PCT/US2019/034467,29.05.2019,WO/2019/232099,05.12.2019,WO,NEURAL ARCHITECTURE SEARCH FOR DENSE IMAGE PREDICTION TASKS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for determining neural network architectures. One of the methods includes obtaining training data for a dense image prediction task; and determining an architecture for a neural network configured to perform the dense image prediction task, comprising: searching a space of candidate architectures to identify one or more best performing architectures using the training data, wherein each candidate architecture in the space of candidate architectures comprises (i) the same first neural network backbone that is configured to receive an input image and to process the input image to generate a plurality of feature maps and (ii) a different dense prediction cell configured to process the plurality of feature maps and to generate an output for the dense image prediction task; and determining the architecture for the neural network based on the best performing candidate architectures.",G06N 3/08; G06N 3/04,GOOGLE LLC,"ZOPH, Barret; SHLENS, Jonathon; ZHU, Yukun; COLLINS, Maxwell Donald Emmet; CHEN, Liang-Chieh; HARTWIG, Adam; PAPANDREOU, Georgios",20180100232 29.05.2018 GR,
WO2001078003,PCT/NZ2001/000059,10.04.2001,WO/2001/078003,18.10.2001,WO,ADAPTIVE LEARNING SYSTEM AND METHOD,"The invention provides a neural network module comprising an input layer comprising one or more input nodes arranged to receive input data, a rule base layer comprising one or more rule nodes, an output layer comprising one or more output nodes, and an adaptive component arranged to aggregate selected two or more rule nodes in the rule base layer based on the input data. The invention also provides an adaptive learning system comprising one or more of the neural network modules of the invention. The invention further provides related methods of implementing a neural network module an adaptive learning system, and a neural network computer program.",G06N 3/04,"UNIVERSITY OF OTAGO; KASABOV, Nikola, Kirilov","KASABOV, Nikola, Kirilov",503882 10.04.2000 NZ,AU-2001252793; EP-2001926261; US-10257214
WO2019157078,PCT/US2019/016886,06.02.2019,WO/2019/157078,15.08.2019,WO,SYSTEMS AND METHODS FOR ANALYSIS AND REMOTE INTERPRETATION OF OPTICAL HISTOLOGIC IMAGES,"A system is presented for analyzing and interpreting histologic images. The system includes an imaging device and a diagnostic module. The imaging device captures an image of a tissue sample at an optical section of the tissue sample, where the tissue sample has a thickness larger than the optical section. The system may further include an image interpretation subsystem located remotely from the imaging device and configured to receive the images from the imaging device. The diagnostic module is configured to receive the images for the tissue sample from the imaging device and generates a diagnosis for the tissue sample by applying a machine learning algorithm to the images. The diagnostic module may be interface directly with the imaging device or located remotely at the image interpretation subsystem.",G01N 21/65; G01N 33/574; G01N 35/00; G01N 35/02; G06F 19/00,"THE REGENTS OF THE UNIVERSITY OF MICHIGAN; INVENIO IMAGING, INC.","ORRINGER, Daniel; PANDIAN, Balaji; FREUDIGER, Christian; HOLLON, Todd","62/627,033 06.02.2018 US",
WO2019088930,PCT/SG2018/050557,02.11.2018,WO/2019/088930,09.05.2019,WO,METHOD AND SYSTEM FOR DETERMINING A MAGNETIC RESONANCE SCAN COVERAGE OF AN INTERNAL ANATOMICAL STRUCTURE,"There is provided a method for determining a magnetic resonance (MR) scan coverage of an internal anatomical structure, e.g. brain. The method includes: receiving a MR scan image of the internal anatomical structure; determining a first parameter and a second parameter associated with one or more anatomical features relating to the internal anatomical structure from the MR scan image using a deep neural network; determining a reference based on the first parameter and the second parameter; and determining the MR scan coverage of the internal anatomical structure based on the reference. In particular, the first parameter comprises position information, and the second parameter comprises angulation information. There is also provided a corresponding system for determining a MR scan coverage of an internal anatomical structure.",G06T 7/73; A61B 5/055,"AGENCY FOR SCIENCE, TECHNOLOGY AND RESEARCH","YANG, Xulei; TANG, Wai Teng; YEO, Si Yong; TJIO, Gabriel; SU, Yi",10201709069V 03.11.2017 SG,
WO2019234103,PCT/EP2019/064666,05.06.2019,WO/2019/234103,12.12.2019,WO,METHOD AND VEHICLE MANAGER FOR MANAGING REMOTE-CONTROLLED VEHICLE,A method performed by a vehicle manager (150) for managing a remote- controlled vehicle (160). The vehicle manager (150) obtains an original route to the destination passing a sequence of radio access points in a wireless network that a wireless device in the vehicle (160) will connect to in a communication with the vehicle manager (150) when the vehicle (160) travels along the original route. The vehicle manager (150) detects at least one deficient radio access point of the original route. The vehicle manager (150) then instructs the vehicle (160) to adapt its behaviour based on said detecting.,G05D 1/02,TELEFONAKTIEBOLAGET LM ERICSSON (PUBL),"AHMED, Jawwad; JOHNSSON, Andreas",62/681885 07.06.2018 US,
WO2019147687,PCT/US2019/014775,23.01.2019,WO/2019/147687,01.08.2019,WO,COMPUTER VISION SYSTEMS AND METHODS FOR UNSUPERVISED REPRESENTATION LEARNING BY SORTING SEQUENCES,"Systems and methods for unsupervised representation learning by sorting sequences are provided. An unsupervised representation learning approach is provided which uses videos without semantic labels. The temporal coherence as a supervisory signal can be leveraged by formulating representation learning as a sequence sorting task. A plurality of temporally shuffled frames (i.e., in non-chronological order) can be used as inputs and a convolutional neural network can be trained to sort the shuffled sequences and to facilitate machine learning of features by the convolutional neural network. Features are extracted from all frame pairs and aggregated to predict the correct sequence order. As sorting shuffled image sequence requires an understanding of the statistical temporal structure of images, training with such a proxy task can allow a computer to learn rich and generalizable visual representations from digital images.",G06T 7/246; G06K 9/32; G06K 9/46; G06T 7/215,"INSURANCE SERVICES OFFICE, INC.","LEE, Hsin-ying; HUANG, Jia-bin; SINGH, Maneesh, Kumar; YANG, Ming-Hsuan","62/620,700 23.01.2018 US",
WO2018187632,PCT/US2018/026341,05.04.2018,WO/2018/187632,11.10.2018,WO,"DEEP LEARNING METHODS FOR ESTIMATING DENSITY AND/OR FLOW OF OBJECTS, AND RELATED METHODS AND SOFTWARE","Methods and software utilizing artificial neural networks (ANNs) to estimate density and/or flow (speed) of objects in one or more scenes each captured in one or more images. In some embodiments, the ANNs and their training configured to provide reliable estimates despite one or more challenges that include but are not limited to, low-resolution images, low framerate image acquisition, high rates of object occlusions, large camera perspective, widely varying lighting conditions, and widely varying weather conditions. In some embodiments, fully convolutional networks (FCNs) are used in the ANNs. In some embodiments, a long short-term memory network (LSTM) is used with an FCN. In such embodiments, the LSTM can be connected to the FCN in a residual learning manner or in a direct connected manner. Also disclosed are methods of generating training images for training an ANN-based estimating algorithm that make training of the estimating algorithm less costly.",G08G 1/01; G06N 3/08; G06K 9/46,CARNEGIE MELLON UNIVERSITY; INSTITUTO SUPERIOR TECNICO,"MOURA, José, M. F.; COSTEIRA, João, Paulo; ZHANG, Shanghang; TOROPOV, Evgeny","62/601,953 05.04.2017 US",CN-201880033667.8
WO2016026063,PCT/CN2014/000769,21.08.2014,WO/2016/026063,25.02.2016,WO,A METHOD AND A SYSTEM FOR FACIAL LANDMARK DETECTION BASED ON MULTI-TASK,"The present application disclosed a method and system for detecting facial landmarks of a face image. The method may comprise extracting multiple feature maps from at least one facial region of the face image and/or the whole face image; generating a shared facial feature vector from the extracted multiple feature maps; and predicting facial landmark locations of the face image from the generated shared facial feature vector. With the present method and system, the facial landmark detection can be optimized together with heterogeneous but subtly related task, so that the detection robustness can be improved through multi-task learning.",G06K 9/78,"BEIJING SENSETIME TECHNOLOGY DEVELOPMENT CO., LTD","ZHANG, Zhanpeng; LUO, Ping; LOY, Chen Change; TANG, Xiaoou",,
WO2019140402,PCT/US2019/013534,14.01.2019,WO/2019/140402,18.07.2019,WO,DEEP LEARNING-BASED VARIANT CLASSIFIER,"The technology disclosed directly operates on sequencing data and derives its own feature filters. It processes a plurality of aligned reads that span a target base position. It combines elegant encoding of the reads with a lightweight analysis to produce good recall and precision using lightweight hardware. For instance, one million training examples of target base variant sites with 50 to 100 reads each can be trained on a single GPU card in less than 10 hours with good recall and precision. A single GPU card is desirable because it a computer with a single GPU is inexpensive, almost universally within reach for users looking at genetic data. It is readily available on could-based platforms.",G06N 3/04; G16B 40/00; G16B 20/20,"ILLUMINA, INC.; ILLUMINA CAMBRIDGE LIMITED","SCHULZ-TRIEGLAFF, Ole Benjamin; COX, Anthony James; FARH, Kai-How","62/617,552 15.01.2018 US",KR-1020197038077; AU-2019206709; CN-201980003259.2; IL-271093; SG-11201911805V; EP-2019703482
EP290833378,18194791,17.09.2018,3624021,18.03.2020,EP,DEVICE AND METHOD FOR TRAINING AN AUGMENTED DISCRIMINATOR,"A computer-implemented method for training an augmented discriminator (AD) and a generator (G), including the steps of- providing a training set comprising real training samples (x<sub>d</sub>) and artificial training samples (x<sub>g</sub>) for training of the augmented discriminator (AD), wherein the artificial training samples (x<sub>g</sub>) are generated by the generator (G);- assigning a data sequence (s) to at least one data sample (x) of the training set;- wherein each pair (x, s) of data sample (x) and assigned data sequence (s) is assigned to one of a plurality of classes such that, given the assigned one class of the plurality of classes and the assigned data sequence (s) taken together characterize whether the data sample (x) is a real training sample (x<sub>d</sub>) or an artificial training sample (x<sub>g</sub>);and- training the augmented discriminator (AD) to being able to compute from pairs (x, s) of data sample (x) and assigned data sequence (s) the respective one class (r<sub>d</sub>) to which the corresponding pair (s) is assigned- training the generator (G) to being able to generate artificial training samples (x<sub>d</sub>) such that the augmented discriminator (AD) is not able to correctly compute the aforementioned one class (r<sub>d</sub>).",G06N 3/08; G06N 3/04,BOSCH GMBH ROBERT,ZHANG DAN; KHOREVA ANNA,18194791 17.09.2018 EP,
WO2020057867,PCT/EP2019/071694,13.08.2019,WO/2020/057867,26.03.2020,WO,DEVICE AND METHOD FOR TRAINING AN AUGMENTED DISCRIMINATOR,"A computer-implemented method for training an augmented discriminator (AD) and a generator (G), including the steps of - providing a training set comprising real training samples (ϰd) and artificial training samples (ϰg) for training of the augmented discriminator (AD), wherein the artificial training samples (ϰg) are generated by the generator (G); - assigning a data sequence (s) to at least one data sample (x) of the training set; - wherein each pair (x, s) of data sample (x) and assigned data sequence (s) is assigned to one of a plurality of classes such that, given the assigned one class of the plurality of classes and the assigned data sequence (s) taken together characterize whether the data sample (x) is a real training sample(ϰd) or an artificial training sample (ϰg); and - training the augmented discriminator (AD) to being able to compute from pairs (x, s) of data sample (x) and assigned data sequence (s) the respective one class (rd) to which the corresponding pair (s) is assigned - training the generator (G) to being able to generate artificial training samples (ϰd) such that the augmented discriminator (AD) is not able to correctly compute the aforementioned one class (rd).",G06N 3/08; G06N 3/04,ROBERT BOSCH GMBH,"ZHANG, Dan; KHOREVA, Anna",18194791.2 17.09.2018 EP,
EP279633438,18178146,15.06.2018,3582142,18.12.2019,EP,IMAGE CLASSIFICATION USING NEURAL NETWORKS,,G06K 9/46; G06K 9/62,UNIV DE LIEGE,VAN DROOGENBROECK MARC; DELIEGE ADRIEN; CIOPPA ANTHONY,18178146 15.06.2018 EP,
WO2019013711,PCT/SG2018/050347,12.07.2018,WO/2019/013711,17.01.2019,WO,MOBILE DEVICE PLATFORM FOR AUTOMATED VISUAL RETAIL PRODUCT RECOGNITION,"Disclosed is a mobile electronic device platform for automated visual product recognition. As part of the platform, a mobile electronic device comprising a processing element and computer-readable media performs automated product-recognition processes based on input image frames received from a photographic element. The non-transitory computer-readable media may include computer-readable instructions stored thereon, the instructions instructing the processing element of the mobile electronic device to complete the following data processing steps without sending or receiving the processed data over an active data connection to any other computing device: (1) pass an input image frame of the input image frames depicting a product through a convolutional neural network stored on the computer-readable media; (2) generate a product classification for the product based at least in part on passage of the image frame through the convolutional neural network; and (3) record product metadata corresponding to the product to a record of the automated product-recognition process. The convolutional neural network may be trained through adjustment of model parameters according to the output of multiple classification arms sharing upstream convolutional features and utilize network compression and/or quantization techniques described herein, resulting in significant performance gains.",G06F 17/30; G07G 1/00; G06Q 20/20,MASTERCARD ASIA/PACIFIC PTE. LTD.,"VOSS, Catalin","62/531,843 12.07.2017 US",
WO2009149236,PCT/US2009/046213,04.06.2009,WO/2009/149236,10.12.2009,WO,SYSTEM AND METHOD FOR PARALLELIZING AND ACCELERATING LEARNING MACHINE TRAINING AND CLASSIFICATION USING A MASSIVELY PARALLEL ACCELERATOR,A method system for training an apparatus to recognize a pattern includes providing the apparatus with a host processor executing steps of a machine learning process; providing the apparatus with an accelerator including at least two processors; inputting training pattern data into the host processor; determining coefficient changes in the machine learning process with the host processor using the training pattern data; transferring the training data to the accelerator; determining kernel dot-products with the at least two processors of the accelerator using the training data; and transferring the dot-products back to the host processor.,G06F 15/16; G06F 9/46; G06F 13/00,"NEC LABORATORIES AMERICA, INC.","CADAMBI, Srihari","61/058,887 04.06.2008 US; 61/146,498 22.01.2009 US",EP-2009759395; JP-2011512636
EP254729081,19168004,08.04.2019,3553742,16.10.2019,EP,METHOD AND DEVICE FOR IDENTIFYING PATHOLOGICAL PICTURE,,G06T 7/00,SUN YAT SEN UNIV CANCER CENTER,YUN JING-PING; WANG ZHI,201810315279 10.04.2018 CN,
WO2020047288,PCT/US2019/048862,29.08.2019,WO/2020/047288,05.03.2020,WO,IMAGE DRIVEN QUALITY CONTROL FOR ARRAY BASED PCR,"A system and methods are provided for image driven quality control for array based PCR. The system comprises a PCR unit, a reaction array plate, a convolutional neural network (CNN) configured to receive a sequence of images of the reaction array plate in the PCR system, and an output of the CNN coupled to a control for the reaction array plate. The method comprises applying a sequence of images from a plurality of subarrays of the reaction array plate to a plurality of CNNs during operation of the PCR system on the reaction plate array, operating the CNNs to generate failure mode predictions for the reaction plate based on the sequence of images, and coupling an output of the CNNs to one or more of a setting for manufacture of the reaction array plate or to control the PCR system.",G06N 3/04; G06N 3/08; G01N 35/00; G01N 35/02; G06T 7/00,LIFE TECHNOLOGIES CORPORATION,"CHU, Yong; MAJUMBAR, Nivedita; ALIMINATI, Manjula; CHEN, Yongzhi; PAPENFUSS, Kevin","62/725,894 31.08.2018 US",
WO2019094857,PCT/US2018/060271,12.11.2018,WO/2019/094857,16.05.2019,WO,"SYSTEM, METHOD AND COMPUTER-ACCESSIBLE MEDIUM FOR DETERMINING BREAST CANCER RISK","An exemplary system, method and computer-accessible medium for determining a risk of developing breast cancer for a patient(s) can include, for example receiving an image(s) of an internal portion(s) of a breast of the patient(s), and determining the risk by applying a neural network(s) to the image(s). The neural network can be a convolutional neural network (CNN). The CNN can include a plurality of layers. Each of the layers can have a different number of feature channels. The CNN can include at least four layers. A first layer of the at least four layers can have 256x256x16 feature channels, a second layer of the at least four layers can have 128x128x32 feature channels, a third layer of the at least four layers can have 64x64x64 feature channels, and a fourth layer of the at least four layers can have 32x32x128 feature channels.",G06N 3/00; G06N 3/02; G06N 3/04; G06N 3/06; G06N 3/08,THE TRUSTEES OF COLUMBIA UNIVERISTY IN THE CITY OF NEW YORK; UNIVERSITY OF CALIFORNIA SAN FRANCISCO,"HA, Richard; CHANG, Peter","62/585,452 13.11.2017 US",
WO2013186216,PCT/EP2013/062040,11.06.2013,WO/2013/186216,19.12.2013,WO,"A METHOD, COMPUTER PROGRAM AND SYSTEM FOR INFERRING AND STRUCTURING RELATIONS BETWEEN CULTURAL SPECIFIC CONCEPTS IN TWO CULTURES","The present invention relates to a method, computer program and system for inferring relations between cultural specific concepts (CSC) in two cultures at least comprising the steps of - extracting and listing said cultural specific concepts (CSCs) and features of said CSCs from at least a first corpora belonging to a first culture and a second corpora belonging to a second culture, - applying a algorithm to infer relations between said CSCs in the first and the second corpora.",G06F 17/28; G06F 17/30; G06F 9/44,IBC - DEPARTMENT OF INTERNATIONAL BUSINESS COMMUNICATION; TECHNICAL UNIVERSITY OF DENMARK,"GLÜCKSTAD, Fumiko Kano; MØRUP, Morten; HERLAU, Tue; SCHMIDT, Mikkei, N.","12171535.3 11.06.2012 EP; 61/658,003 11.06.2012 US",
EP254729045,17877417,24.11.2017,3553711,16.10.2019,EP,"INFORMATION PROCESSING DEVICE AND METHOD, AND PROGRAM","The present disclosure relates to an information processing device and method, and program, whereby it is possible to cause a system to efficiently learn a method of controlling a person. A control learning system computes a reward on the basis of an inputted control subject target state and a state of the control subject based on a sensing result of the control subject. By reinforcement learning using the computed reward and the state of the control subject, the control learning system selects a more suitable action for bringing the control subject closer to the target state. The control learning system executes the selected action upon the control subject. The present disclosure may be applied to a control learning system which is formed from a terminal and a cloud system, as an example.",G06N 99/00; G06N 20/00,SONY CORP,KOBAYASHI YOSHIYUKI; TANAKA YASUFUMI; TAKAMATSU SHINGO; NODA ATSUSHI,2016237602 07.12.2016 JP; 2017042153 24.11.2017 JP,
WO2018148526,PCT/US2018/017597,09.02.2018,WO/2018/148526,16.08.2018,WO,BATCH RENORMALIZATION LAYERS,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for implementing a neural network. In one aspect, the neural network includes a batch renormalization layer between a first neural network layer and a second neural network layer. The first neural network layer generates first layer outputs having multiple components. The batch renormalization layer is configured to, during training of the neural network on a current batch of training examples, obtain respective current moving normalization statistics for each of the multiple components and determine respective affine transform parameters for each of the multiple components from the current moving normalization statistics. The batch renormalization layer receives a respective first layer output for each training example in the current batch and applies the affine transform to each component of a normalized layer output to generate a renormalized layer output for the training example.",G06N 3/08; G06N 3/04,GOOGLE LLC,"IOFFE, Sergey","62/457,649 10.02.2017 US",KR-1020197026511; CN-201880011378.8; EP-2018707480; JP-2019543328
WO2020028352,PCT/US2019/044118,30.07.2019,WO/2020/028352,06.02.2020,WO,METHODS AND SYSTEMS FOR SEGMENTING ORGANS IN IMAGES USING A CNN-BASED CORRECTION NETWORK,"Among the various aspects of the present disclosure is the provision of methods and systems for segmenting images and expediting a contouring process for MRI-guided adaptive radiotherapy (MR-IGART) comprising applying a convolutional neural network (CNN), wherein the CNN accurately segments organs (e.g., the liver, kidneys, stomach, bowel, or duodenum) in 3D MR images.",G06T 7/00; A61B 5/00; A61B 5/055; A61B 6/00; A61B 6/03,WASHINGTON UNIVERSITY,"YANG, Deshan; FU, Yabo","62/712,619 31.07.2018 US; 62/850,225 20.05.2019 US",
WO2019199967,PCT/US2019/026783,10.04.2019,WO/2019/199967,17.10.2019,WO,SYSTEMS AND METHODS FOR GAMIFICATION OF DRONE BEHAVIOR USING ARTIFICIAL INTELLIGENCE,"A conventional drone with an image sensor can track an object identified by a user in its image sensor's field of view. The user draws a bounding box around the object, and as long as the drone keeps the object in the bounding box, the drone can track the object. Unfortunately, this tracking scheme isn't robust; if the object changes shape or aspect ratio or is occluded by another object, the drone will lose the object. Using a neural network to identify the object in the image stream from the image sensor increases the robustness of the tracking; a trained neural network can recognize the object from a variety of angles without any user input (no user-drawn bounding box necessary). Moreover, if the neural network is a lifelong deep neural network (L-DNN), it can learn new objects on the fly. The drone can respond by moving in a predetermined fashion with respect to the object.",B64C 39/02; G05D 1/00,"NEURALA, INC.; VERSACE, Massimiliano","VERSACE, Massimiliano","62/655,490 10.04.2018 US",
WO2018141429,PCT/EP2017/078429,07.11.2017,WO/2018/141429,09.08.2018,WO,A METHOD AND APPARATUS FOR DETECTING OBJECTS OF INTEREST IN IMAGES,"A method and apparatus for detecting objects of interest in images, the method comprising the steps of supplying (S1) at least one input image to a trained deep neural network, DNN, which comprises a stack of layers; and using at least one deconvolved output of at least one learned filter or combining (S2) deconvolved outputs of learned filters of at least one layer of the trained deep neural network, DNN, to detect the objects of interest in the supplied images.",G06K 9/32; G06K 9/46; G06K 9/38,SIEMENS AKTIENGESELLSCHAFT,"GHOSH, Sanjukta; AMON, Peter; HUTTER, Andreas",201711004037 03.02.2017 IN,CN-201780085505.4; EP-2017805111
WO2019162241,PCT/EP2019/054016,19.02.2019,WO/2019/162241,29.08.2019,WO,REAL-TIME OBJECT DETECTION USING DEPTH SENSORS,"A depth-based object-detection convolutional neural network is disclosed. The depth-based object-detection convolutional neural network described herein incorporates a base network and additional structure. The base network is configured to receive a depth image formatted as RGB image data as input, and compute output data indicative of at least one feature of an object in the RGB image data. The additional structure is configured to receive the output data of the base network as input, and compute predictions of the location of a region in the received depth image that includes the object and of a class of the object as output. An object detection device incorporating the depth-based object-detection convolutional neural network is operable in real time using an embedded GPU.",G06K 9/00; G06K 9/46; G06K 9/62,ROBERT BOSCH GMBH,"MITHUN, Niluthpol Chowdhury; MUNIR, Sirajum; SHELTON, Charles","62/633,202 21.02.2018 US",
WO2020047302,PCT/US2019/048885,29.08.2019,WO/2020/047302,05.03.2020,WO,LANE AND OBJECT DETECTION SYSTEMS AND METHODS,"Embodiments disclosed herein include systems and methods for lane and object detection. A system may comprise a plurality of cameras and a processor in electronic communication with the cameras. The cameras may be disposed on a vehicle. The cameras may be configured to collect one or more images. The cameras may be configured to generate an image data feed using the one or more images. A method may comprise collecting one or more images; generating, from the one or more images, an image data feed; receiving, at a processor, the image data feed; and performing lane detection and object detection, and may employ a deep learning network.",B60W 50/14; G06K 9/66,BUFFALO AUTOMATION GROUP INC.,"KHAKHARIA, Mohit, Arvind; SURESH, Thiru, Vikram; MCDONOUGH, Trevor, R.; CHANG LEE, Miguel, Ojielong","62/724,311 29.08.2018 US",
WO2020033391,PCT/US2019/045283,06.08.2019,WO/2020/033391,13.02.2020,WO,SYSTEM AND METHOD FOR SELECTING ARTIFICIALLY FERTILIZED EMBRYOS,A method for classifying human blastocysts includes obtaining images of a set of artificially fertilized (AF) embryos incubating in an incubator. A morphological quality of the AF embryos is determined based on a classification of the images by a convolutional neural network trained using images of pre-classified embryos. Each of the AF embryos is graded based on the morphological quality. A probability that a given graded AF embryo will result in a successful pregnancy after the given AF embryo is implanted in a gestating female is computed for each of the AF embryos from the set based on a grade of the given AF embryo and clinical parameters associated with the gestating female. One or more graded AF embryos to be recommended to be implanted in the gestating female from the set are selected based on the probability of successful pregnancy. An identity of each of the selected graded AF embryos and a number of the selected graded AF embryos to be potentially implanted in the gestating female is then output based on an outcome desired by the gestating female following implantation.,G06K 9/00; G06K 9/46; G16H 50/30; G16H 30/40,CORNELL UNIVERSITY; YALE UNIVERSITY,"ZANINOVIC, Nikica; ELEMENTO, Olivier; HAJIRASOULIHA, Iman; KHOSRAVI, Pegah; MALMSTEN, Jonah; ROSENWAKS, Zev; ZHAN, Qiansheng; KAZEMI, Ehsan","62/715,518 07.08.2018 US",
EP238117534,17187764,24.08.2017,3447721,27.02.2019,EP,A METHOD OF GENERATING AN ENHANCED TOMOGRAPHIC IMAGE OF AN OBJECT,"A neural network is trained by feeding it with a first set of tomographic images of an object and a second set of tomographic images of that object having a lower quality in at least one image quality aspect.  The lower quality tomographic images are acquired by applying a reconstruction algorithm to projection image data of lower quality for that aspect.  At inference phase, tomographic images of lower quality are enhanced by using the trained neural network.",G06T 3/40; G06T 11/00,AGFA NV,SOONS JORIS; DANUDIBROTO ADRIYANA; CANT JEROEN,17187764 24.08.2017 EP,
WO2020033453,PCT/US2019/045368,06.08.2019,WO/2020/033453,13.02.2020,WO,A MULTI-MODAL APPROACH TO PREDICTING IMMUNE INFILTRATION BASED ON INTEGRATED RNA EXPRESSION AND IMAGING FEATURES,"Multi-modal approaches to predict tumor immune infiltration are based on integrating gene expression data and imaging features in a neural network-based framework. This framework is configured to estimate percent composition, and thus immune infiltration score, of a patient tumor biopsy sample. Multi-modal approaches may also be used to predict cell composition beyond immune cells via integrated multi-layer neural network frameworks.",C12Q 1/68; G06T 7/00; G16B 40/00,"TEMPUS LABS, INC.","LAU, Denise; KHAN, Aly, Azeem","62/715,079 06.08.2018 US",
WO2019204186,PCT/US2019/027437,15.04.2019,WO/2019/204186,24.10.2019,WO,INTEGRATED UNDERSTANDING OF USER CHARACTERISTICS BY MULTIMODAL PROCESSING,"A system and method for multimodal classification of user characteristics is described. The method comprises receiving audio and other inputs, extracting fundamental frequency information from the audio input, extracting other feature information from the video input, classifying the fundamental frequency information, textual information and video feature information using the multimodal neural network.",G06N 3/02; G06N 3/04; G06N 20/00,"SONY INTERACTIVE ENTERTAINMENT INC.; CHEN, Ruxin","CHEN, Ruxin; OMOTE, Masanori; MENENDEZ-PIDAL, Xavier; YOO, Jaekwon; TASHIRO, Koji; KRISHNAMURTHY, Sudha; KUMAR, Komath Naveen","62/659,657 18.04.2018 US",
EP198313194,15827812,23.07.2015,3176563,07.06.2017,EP,IDENTIFICATION DEVICE AND IDENTIFICATION METHOD,"The identification apparatus 1 includes a quantitative phase image acquisition unit 11, a feature quantity extraction unit 12, a learning unit 13, a storage unit 14, and an identification unit 15. The feature quantity extraction unit 12 extracts a feature quantity of a quantitative phase image of a cell acquired by the quantitative phase image acquisition unit 11. The learning unit 13 performs machine learning for a quantitative phase image of a known cell of which a type is known based on the feature quantity extracted by the feature quantity extraction unit 12. The storage unit 14 stores a result of the machine learning by the learning unit 13. The identification unit 15 determines, based on the feature quantity extracted by the feature quantity extraction unit 12 for the quantitative phase image of an unknown cell of which a type is unknown, the type of the unknown cell using the learning result stored by the storage unit 14. Thus, an apparatus and a method capable of identifying an object, even when the object has a three-dimensional shape, has a size and a shape with no distinctive feature, and is colorless and transparent, are realized.",G01N 15/14; G01N 15/00; G01N 15/02; G01N 15/10; G01N 21/41; G06K 9/00; G06T 7/00,NATIONAL UNIV CORPORATION HAMAMATSU UNIV SCHOOL OF MEDICINE; HAMAMATSU PHOTONICS KK,OZAKI YUSUKE; IWAI HIDENAO; KONNO HIROYUKI; KIKUCHI HIROTOSHI; YAMAUCHI TOYOHIKO,2014153651 29.07.2014 JP; 2015071023 23.07.2015 JP,
WO2019145951,PCT/IL2019/050098,23.01.2019,WO/2019/145951,01.08.2019,WO,AUTOMATED MONITORING OF MEDICAL IMAGING PROCEDURES,"A method for automated image capture of a body tissue in situ, comprising: providing an imaging device configured to transmit an image stream of a body tissue; and using at least one hardware processor for: receiving the image stream, identifying a medical accessory appearing in the image stream, and capturing multiple images of the body tissue, wherein (i) at least one of the images is captured before said identifying, and (ii) at least one of the images is captured at one or more specified times upon said identifying.",G06T 7/10; G06K 9/00; A61B 5/00,MOBILEODT LTD.,"BERNAT, Amir Shlomo; LEVITZ, David; BOLTON, Frank John; FERNANDES, Kelwin","62/620,579 23.01.2018 US; 62/689,991 26.06.2018 US",
WO2019025298,PCT/EP2018/070365,26.07.2018,WO/2019/025298,07.02.2019,WO,"METHOD, DEVICE, AND COMPUTER PROGRAM FOR IMPROVING THE RECONSTRUCTION OF DENSE SUPER-RESOLUTION IMAGES FROM DIFFRACTION-LIMITED IMAGES ACQUIRED BY SINGLE MOLECULE LOCALIZATION MICROSCOPY","The invention relates to reconstructing a synthetic dense super-resolution image from at least one low-information-content image, for example from a sequence of diffraction-limited images acquired by single molecule localization microscopy. After having obtained such a sequence of diffraction-limited images, a sparse localization image is reconstructed from the obtained sequence of diffraction-limited images according to single molecule localization microscopy image processing. The reconstructed sparse localization image and/or a corresponding low-resolution wide-field image are input to an artificial neural network and a synthetic dense super-resolution image is obtained from the artificial neural network, the latter being trained with training data comprising triplets of sparse localization images, at least partially corresponding low-resolution wide-field images, and corresponding dense super-resolution images, as a function of a training objective function comparing dense super-resolution images and corresponding outputs of the artificial neural network.",G06T 3/40,INSTITUT PASTEUR,"ZIMMER, Christophe; OUYANG, Wei",17306022.9 31.07.2017 EP; 18305225.7 01.03.2018 EP,EP-2018742837
EP212499869,17183949,31.07.2017,3282446,14.02.2018,EP,"DIALOGUE ACT ESTIMATION METHOD, DIALOGUE ACT ESTIMATION APPARATUS, AND MEDIUM","A dialogue act estimation method includes acquiring learning data including a first sentence to be estimated in the form of text data of a first uttered sentence uttered at a first time point, a second sentence which is text data of a second uttered sentence uttered, at a time point before the first time point, successively after the first uttered sentence, act information indicating an act associated to the first sentence, property information indicating a property information associated to the first sentence, and dialogue act information indicating a dialogue act in the form of a combination of an act and a property associated to the first sentence, making a particular model learn three or more tasks at the same time using the learning data, and storing a result of the learning as learning result information in a memory.",G10L 15/18; G06F 17/27; G06N 3/02; G10L 17/04,PANASONIC IP MAN CO LTD,USHIO TAKASHI; SHI HONGJIE; ENDO MITSURU; YAMAGAMI KATSUYOSHI,2017071334 31.03.2017 JP; 201662372443 09.08.2016 US,
WO2019028075,PCT/US2018/044697,31.07.2018,WO/2019/028075,07.02.2019,WO,INTELLIGENT ROBOTS,"One embodiment can provide an intelligent robotic system. The intelligent robotic system can include at least one multi-axis robotic arm, at least one gripper attached to the multi-axis robotic arm for picking up a component, a machine vision system comprising at least a three-dimensional (3D) surfacing-imaging module for detecting 3D pose information associated with the component, and a control module configured to control movements of the multi-axis robotic arm and the gripper based on the detected 3D pose of the component.",B25J 9/16; G05B 19/00,"ENOVA TECHNOLOGY, INC.","YUNG, Kai C.; XU, Zheng; FU, Jianming","62/539,926 01.08.2017 US; 16/051,251 31.07.2018 US",
WO2019168765,PCT/US2019/019285,22.02.2019,WO/2019/168765,06.09.2019,WO,CONTEXT-AWARE SYNTHESIS FOR VIDEO FRAME INTERPOLATION,"Systems, methods, and computer-readable media for context-aware synthesis for video frame interpolation are provided. Bidirectional flow may be used in combination with flexible frame synthesis neural network to handle occlusions and the like, and to accommodate inaccuracies in motion estimation. Contextual information may be used to enable frame synthesis neural network to perform informative interpolation. Optical flow may be used to provide initialization for interpolation. Other embodiments may be described and/or claimed.",H04N 7/01; H04N 5/14; G06T 3/40; G06N 3/08,PORTLAND STATE UNIVERSITY,"LIU, Feng; NIKLAUS, Simon","62/635,675 27.02.2018 US",
WO2018170393,PCT/US2018/022858,16.03.2018,WO/2018/170393,20.09.2018,WO,FRAME INTERPOLATION VIA ADAPTIVE CONVOLUTION AND ADAPTIVE SEPARABLE CONVOLUTION,"Systems, methods, and computer-readable media for context-aware synthesis for video frame interpolation are provided. A convolutional neural network (ConvNet) may, given two input video or image frames, interpolate a frame temporarily in the middle of the two input frames by combining motion estimation and pixel synthesis into a single step and formulating pixel interpolation as a local convolution over patches in the input images. The ConvNet may estimate a convolution kernel based on a first receptive field patch of a first input image frame and a second receptive field patch of a second input image frame. The ConvNet may then convolve the convolutional kernel over a first pixel patch of the first input image frame and a second pixel patch of the second input image frame to obtain color data of an output pixel of the interpolation frame. Other embodiments may be described and/or claimed.",G06T 1/40,PORTLAND STATE UNIVERSITY,"LIU, Feng; NIKLAUS, Simon; MAI, Long","62/473,234 17.03.2017 US; 62/485,794 14.04.2017 US",KR-1020197030137
WO2019038246,PCT/EP2018/072475,21.08.2018,WO/2019/038246,28.02.2019,WO,A METHOD OF GENERATING AN ENHANCED TOMOGRAPHIC IMAGE OF AN OBJECT,"Tomographic images, acquired by iterative reconstruction of lower quality images, are enhanced by a trained neural network. Next, the enhanced tomographic images are input to the next step of the iterative reconstruction. For this purpose, one or several neural networks are trained with a first set of tomographic images and a second set of tomographic images at lower quality. The second set of tomographic images at lower quality are acquired by applying an iterative reconstruction algorithm to lower quality projection images. The iterative reconstruction can use a normal quality tomographic image as input.",G06T 3/40; G06T 11/00,AGFA NV,"SOONS, Joris; DANUDIBROTO, Adriyana; CANT, Jeroen",17187772.3 24.08.2017 EP,
EP224031935,17152333,20.01.2017,3352112,25.07.2018,EP,ARCHITECTURE ADAPTED FOR RECOGNISING A CATEGORY OF AN ELEMENT FROM AT LEAST ONE IMAGE OF SAID ELEMENT,"Architecture for recognising a category (CA, CA') of an element (E1, E2) from an image (I, 11, 12), comprising: a DCNN network (N, N1, N2) with k convolution layers (C k , C 1 -C 5 ) to detect a feature (f k ) in an image (I, 11, 12), comprising each n k  kernels adapted to filter said feature (f k ), the first layer (C 1 ) filtering an input image (I, 11, 12) for producing n 1  feature maps (F 1 ) representing spatial locations of its feature (f 1 ), the following layers (C 2 -C k ) filtering output feature maps (F 1 -Fk- 1 ) of the preceding layer (C 1 -C k-1 ) for producing n2-nk feature maps (F 2 -F k ); and a fully-connected layer (FC) for predicting a possible category (CA, CA'), the architecture further comprising a SVM machine (V) for classifying and furnishing the last feature maps (F 5 , F k ) to the layer (FC) to improve the prediction accuracy with a lower computational complexity; means for establishing a confusion matrix to evaluate the pairs of categories (CA, CA') most often confused.",G06K 9/46; G06K 9/62,NOKIA TECHNOLOGIES OY,MILIORIS DIMITRIOS,17152333 20.01.2017 EP,
EP248884888,18215628,21.12.2018,3511872,17.07.2019,EP,ARTIFICIAL NEURAL NETWORK,,G06N 3/08,SONY CORP,ALONSO GARCIA JAVIER; CARDINAUX FABIEN; YOSHIYAMA KAZUKI; KEMP THOMAS; TIEDEMANN STEPHEN; UHLICH STEFAN,18151416 12.01.2018 EP,
WO2019186198,PCT/GB2019/050927,29.03.2019,WO/2019/186198,03.10.2019,WO,ATTENTION FILTERING FOR MULTIPLE INSTANCE LEARNING,"Method(s), apparatus, and system(s) are provided for filtering a set of data, the set of data comprising multiple data instances by: receiving a set of scores for the set of data; determining attention filtering information based on prior knowledge of one or more relationships between the data instances in said set of data and calculating attention relevancy weights corresponding to the data instances and the set of scores; and providing the attention filtering information to a machine learning, ML, technique or ML model.",G06N 5/02; G06N 20/00,BENEVOLENTAI TECHNOLOGY LIMITED,"CREED, Paidi; SIM, Aaron Jefferson Khey Jin; SPENCER, Stephen Thomas; VILENIUS, Mikko Juhani",1805293.6 29.03.2018 GB,
WO2017062453,PCT/US2016/055495,05.10.2016,WO/2017/062453,13.04.2017,WO,IMAGE SEGMENTATION OF ORGANS DEPICTED IN COMPUTED TOMOGRAPHY IMAGES,"Methods, systems, and non-transitory computer storage media for image segmentation are disclosed. In some examples, the method includes performing both displacement regression and organ classification on a computed tomography (CT) image of a CT scan of a patient using a shared random forest, resulting in a displacement field for the CT image and an organ classification map for the CT image. The method includes iteratively repeating the displacement regression and organ classification using, at each iteration, one or more extracted context features from the displacement field and the organ classification map of a prior iteration to refine the displacement field and the organ classification map of a current iteration. The method includes segmenting the CT image to identify a target organ depicted in the CT image.",A61B 5/055; G06T 7/149; G06T 7/33,THE UNIVERSITY OF NORTH CAROLINA AT CHAPEL HILL,"SHEN, Dinggang; GAO, Yaozong","62/237,506 05.10.2015 US",
WO2019198265,PCT/JP2018/040422,24.10.2018,WO/2019/198265,17.10.2019,WO,SPEECH RECOGNITION SYSTEM AND METHOD USING SPEECH RECOGNITION SYSTEM,"Systems and methods for a speech recognition system for recognizing speech including overlapping speech by multiple speakers. The system including a hardware processor. A computer storage memory to store data along with having computer-executable instructions stored thereon that, when executed by the processor is to implement a stored speech recognition network. An input interface to receive an acoustic signal, the received acoustic signal including a mixture of speech signals by multiple speakers, wherein the multiple speakers include target speakers. An encoder network and a decoder network of the stored speech recognition network are trained to transform the received acoustic signal into a text for each target speaker. Such that the encoder network outputs a set of recognition encodings, and the decoder network uses the set of recognition encodings to output the text for each target speaker. An output interface to transmit the text for each target speaker.",G10L 25/30,MITSUBISHI ELECTRIC CORPORATION,"LE ROUX, Jonathan; HORI, Takaaki; SETTLE, Shane; SEKI, Hiroshi; WATANABE, Shinji; HERSHEY, John","15/952,330 13.04.2018 US",EP-2018808527
WO2018208947,PCT/US2018/031845,09.05.2018,WO/2018/208947,15.11.2018,WO,AUTOMATED PLANT DETECTION USING IMAGE DATA,"A plant treatment platform uses a plant detection model to detect plants as the plant treatment platform travels through a field. The plant treatment platform receives image data from a camera that captures images of plants (e.g., crops or weeds) growing in the field. The plant treatment platform applies pre-processing functions to the image data to prepare the image data for processing by the plant detection model. For example, the plant treatment platform may reformat the image data, adjust the resolution or aspect ratio, or crop the image data. The plant treatment platform applies the plant detection model to the pre-processed image data to generate bounding boxes for the plants. The plant treatment platform then can apply treatment to the plants based on the output of the machine-learned model.",A01G 1/00; A01M 21/04; G01N 33/00; G06K 9/00; G06K 9/20; G06K 9/62; H04N 7/18,BLUE RIVER TECHNOLOGY INC.,"REDDEN, Lee Kamp; PADWICK, Christopher Grant; RADHAKRISHNAN, Rajesh; OSTROWSKI, James Patrick","62/503,770 09.05.2017 US; 62/580,290 01.11.2017 US",EP-2018799189
WO2018045269,PCT/US2017/049822,01.09.2017,WO/2018/045269,08.03.2018,WO,SYSTEM AND METHOD OF OTOSCOPY IMAGE ANALYSIS TO DIAGNOSE EAR PATHOLOGY,"Disclosed herein are systems and methods to detect a wide range of eardrum abnormalities by using high-resolution otoscope images and report the condition of the eardrum as ""normal"" or ""abnormal.""",G06K 9/00,OHIO STATE INNOVATION FOUNDATION,"SENARAS, Caglar; MOBERLY, Aaron Christopher; TEKNOS, Theodoros; ESSIG, Garth Fredric, Jr.; ELMARAGHY, Charles Albert; TAJ-SCHAAL, Nazhat Fatima; YU, Lianbo; GURCAN, Metin Nafi","62/382,914 02.09.2016 US",EP-2017847614; AU-2017318691; CA-3035763; JP-2019512207; CN-201780067908.6
WO2017164954,PCT/US2016/068800,28.12.2016,WO/2017/164954,28.09.2017,WO,ADAPTIVE AUDIO ENHANCEMENT FOR MULTICHANNEL SPEECH RECOGNITION,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for neural network adaptive beamforming for multichannel speech recognition are disclosed. In one aspect, a method includes the actions of receiving a first channel of audio data corresponding to an utterance and a second channel of audio data corresponding to the utterance. The actions further include generating a first set of filter parameters for a first filter based on the first channel of audio data and the second channel of audio data and a second set of filter parameters for a second filter based on the first channel of audio data and the second channel of audio data. The actions further include generating a single combined channel of audio data. The actions further include inputting the audio data to a neural network. The actions further include providing a transcription for the utterance.",G10L 15/20; G10L 21/0216; G10L 15/16,GOOGLE LLC,"LI, Bo; WEISS, Ron J.; BACCHIANI, Michiel A.U.; SAINATH, Tara N.; WILSON, Kevin William","62/312,053 23.03.2016 US",EP-2016826635; KR-1020187020390; CN-201680079040.7; RU-2018125957; JP-2018536452
WO2019246239,PCT/US2019/037953,19.06.2019,WO/2019/246239,26.12.2019,WO,SYSTEMS AND METHODS FOR MENTAL HEALTH ASSESSMENT,"The present disclosure provides systems and methods for assessing a mental state of a subject in a single session or over multiple different sessions, using for example an automated module to present and/or formulate at least one query based in part on one or more target mental states to be assessed. The query may be configured to elicit at least one response from the subject. The query may be transmitted in an audio, visual, and/or textual format to the subject to elicit the response. Data comprising the response from the subject can be received. The data can be processed using one or more individual, joint, or fused models. One or more assessments of the mental state associated with the subject can be generated for the single session, for each of the multiple different sessions, or upon completion of one or more sessions of the multiple different sessions.",G06F 17/27,"ELLIPSIS HEALTH, INC.; RUTOWSKI, Tomasz","RUTOWSKI, Tomasz; SHRIBERG, Elizabeth, E.; ARATOW, Michael; ISLAM, Mainul; HARATI, Amir; LIN, David; LU, Yang; HAQUE, Farshid; ROGERS, Robert, D.","62/687,176 19.06.2018 US; 62/733,568 19.09.2018 US; 62/733,552 19.09.2018 US; 62/749,113 22.10.2018 US; 62/749,669 23.10.2018 US; 62/749,654 23.10.2018 US; 62/749,663 23.10.2018 US; 62/749,672 24.10.2018 US; 62/754,547 01.11.2018 US; 62/754,534 01.11.2018 US; 62/754,541 01.11.2018 US; 62/755,356 02.11.2018 US; 62/755,361 02.11.2018 US",
WO2013071149,PCT/US2012/064506,09.11.2012,WO/2013/071149,16.05.2013,WO,"METHODS AND APPARATUS FOR UNSUPERVISED NEURAL REPLAY, LEARNING REFINEMENT, ASSOCIATION AND MEMORY TRANSFER: STRUCTURAL PLASTICITY AND STRUCTURAL CONSTRAINT MODELING","Certain aspects of the present disclosure support techniques for unsupervised neural replay, learning refinement, association and memory transfer.",G06N 3/04; G06N 3/08,QUALCOMM INCORPORATED,"HUNZINGER, Jason Frank; CHAN, Victor Hokkiu","13/292,191 09.11.2011 US",KR-1020147015331; JP-2014541339; EP-2012788700
WO2018115570,PCT/FI2017/050813,23.11.2017,WO/2018/115570,28.06.2018,WO,AN APPARATUS AND ASSOCIATED METHOD FOR IMAGING,"An apparatus configured to generate an output quality error estimate using a machine- learning error estimation model to compare an output meeting a predetermined quality threshold with an output image reconstructed from a plurality of images, and provide the output quality error estimate for use in estimating if a second subsequent image is required, in addition to a first subsequent image to obtain a cumulative output having an output quality error meeting a predetermined error threshold. Also an apparatus configured, using a received output quality error estimate generated using a machine-learning error estimation model as above, to estimate if a second subsequent image is required, in addition to a first subsequent image, to obtain a cumulative output having an output quality error meeting a predetermined error threshold.",A61B 6/03; A61B 6/00; G06K 9/66; G06T 11/00,NOKIA TECHNOLOGIES OY,"HONKALA, Mikko; VETEK, Akos; TAIPALUS, Tapio; LINDHOLM, Harri",16206200.4 22.12.2016 EP,
WO2019060125,PCT/US2018/049129,31.08.2018,WO/2019/060125,28.03.2019,WO,THREE-DIMENSIONAL BOUNDING BOX FROM TWO-DIMENSIONAL IMAGE AND POINT CLOUD DATA,A three-dimensional bounding box is determined from a two-dimensional image and a point cloud. A feature vector associated with the image and a feature vector associated with the point cloud may be passed through a neural network to determine parameters of the three- dimensional bounding box. Feature vectors associated with each of the points in the point cloud may also be determined and considered to produce estimates of the three-dimensional bounding box on a per-point basis.,G06K 9/00; G06K 9/46,"ZOOX, INC.","XU, Danfei; ANGUELOV, Dragomir Dimitrov; JAIN, Ashesh","15/797,573 30.10.2017 US; 62/562,193 22.09.2017 US",
WO2008157811,PCT/US2008/067779,20.06.2008,WO/2008/157811,24.12.2008,WO,SELECTIVE SAMPLING OF USER STATE BASED ON EXPECTED UTILITY,"Model enhancement architecture that provides selective sampling of data to enhance model performance where model testing is deemed to be poor. Sampling can include direct interaction with the user while the user is logged-in to the computing system. The system can be used to infer a computer user's current interruptability based on computer activity and relevant contextual information. Personalized models can then be created that are utilized to determine a cost of interruption and an expected utility. A modeling component is provided that builds and runs models based on data. The data can be any type of data such as application data, user profile data, tracking data, user state data, user situation data, and so on. A sampling component samples the data based on failure analysis of the model. The architecture is a utility-centric approach to gathering data to maximally enhance the current model.",G06F 17/00,MICROSOFT CORPORATION,"HORVITZ, Eric J.; KAPOOR, Ashish","11/766,547 21.06.2007 US",
WO2019045802,PCT/US2018/032538,14.05.2018,WO/2019/045802,07.03.2019,WO,DISTANCE METRIC LEARNING USING PROXIES,"The present disclosure provides systems and methods that enable distance metric learning using proxies. A machine-learned distance model can be trained in a proxy space in which a loss function compares an embedding provided for an anchor data point of a training dataset to a positive proxy and one or more negative proxies, where each of the positive proxy and the one or more negative proxies serve as a proxy for two or more data points included in the training dataset. Thus, each proxy can approximate a number of data points, enabling faster convergence. According to another aspect, the proxies of the proxy space can themselves be learned parameters, such that the proxies and the model are trained jointly. Thus, the present disclosure enables faster convergence (e.g., reduced training time). The present disclosure provides example experiments which demonstrate a new state of the art on several popular training datasets.",G06K 9/46; G06K 9/66; G06K 9/62,GOOGLE LLC,"MOYSHOVITZ-ATTIAS, Yair; LEUNG, King Hong; SINGH, Saurabh; TOSHEV, Alexander; IOFFE, Sergey","15/690,426 30.08.2017 US; 15/710,377 20.09.2017 US",
WO2018102240,PCT/US2017/063217,27.11.2017,WO/2018/102240,07.06.2018,WO,JOINT LANGUAGE UNDERSTANDING AND DIALOGUE MANAGEMENT,"A processing unit can operate an end-to-end recurrent neural network (RNN) with limited contextual dialogue memory that can be jointly trained by supervised signals-user slot tagging, intent prediction and/or system action prediction. The end-to-end RNN, or joint model has shown advantages over separate models for natural language understanding (NLU) and dialogue management and can capture expressive feature representations beyond conventional aggregation of slot tags and intents, to mitigate effects of noisy output from NLU. The joint model can apply a supervised signal from system actions to refine the NLU model. By back-propagating errors associated with system action prediction to the NLU model, the joint model can use machine learning to predict user intent, and perform slot tagging, and make system action predictions based on user input, e.g., utterances across a number of domains.",G10L 15/06; G10L 15/22,"MICROSOFT TECHNOLOGY LICENSING, LLC","LI, Xiujun; CROOK, Paul Anthony; DENG, Li; GAO, Jianfeng; CHEN, Yun-Nung; YANG, Xuesong","15/368,380 02.12.2016 US",
WO2008038994,PCT/KR2007/004699,27.09.2007,WO/2008/038994,03.04.2008,WO,METHOD FOR CONVERTING PRONUNCIATION USING BOUNDARY PAUSE INTENSITY AND TEXT-TO-SPEECH SYNTHESIS SYSTEM BASED ON THE SAME,"Provided are a method for converting pronunciation using boundary pause intensity and a text-to-speech synthesis system based on the same. The synthesis database is processed to reflect a pronunciation variation phenomenon at a word boundary depending on reading with breath, a speaker-dependent pronunciation conversion module is created based on the processed synthesis database, and the feature parameters for pronunciation conversion are extracted based on the language analysis result for an input sentence upon speech synthesis and inter-word boundary strength information and applied to the pronunciation conversion model in order to automatically generate a pronunciation string. Thus, a sophisticated pronunciation string can be generated particularly upon inter-word pronunciation conversion, thereby improving quality of a synthesized sound in the text-to-speech synthesis system.",G10L 13/02,"ELECTRONICS AND TELECOMMUNICATIONS RESEARCH INSTITUTE; KIM, Jong Jin; PARK, Moon Hwan","KIM, Jong Jin; PARK, Moon Hwan",10-2006-0096296 29.09.2006 KR,
EP279871219,18181012,29.06.2018,3588441,01.01.2020,EP,IMAGIFICATION OF MULTIVARIATE DATA SEQUENCES,,G06T 11/20; G06K 9/00; G06K 9/46; G06K 9/62,FUJITSU LTD,CHATON THOMAS,18181012 29.06.2018 EP,
WO2007090033,PCT/US2007/061061,25.01.2007,WO/2007/090033,09.08.2007,WO,META LEARNING FOR QUESTION CLASSIFICATION,"A system and a method are disclosed for automatic question classification and answering. A multipart artificial neural network (ANN) comprising a main ANN and an auxiliary ANN classifies a received question according to one of a plurality of defined categories. Once the auxiliary ANN has trained, the weights are frozen and transferred to the main ANN. The main ANN can then be trained using labeled questions. The invention makes efficient use of available information, and improves training time and error rate relative to use of single part ANNs.",G05B 13/02,"HONDA MOTOR CO., LTD.; GUPTA, Rakesh; SWARUP, Samarth","GUPTA, Rakesh; SWARUP, Samarth","60/764,412 01.02.2006 US; 11/410,443 24.04.2006 US",DE-null; JP-2008553450
WO2018152248,PCT/US2018/018240,14.02.2018,WO/2018/152248,23.08.2018,WO,"SYSTEMS, METHODS, AND MEDIA FOR SELECTIVELY PRESENTING IMAGES CAPTURED BY CONFOCAL LASER ENDOMICROSCOPY","In accordance with some embodiments of the disclosed subject matter, systems, methods, and media for selectively presenting images captured by confocal laser endomicroscopy (CLE) are provided. In some embodiments, a method comprises: receiving images captured by a CLE device during brain surgery; providing the images to a convolution neural network (CNN) trained using at least a plurality of images of brain tissue captured by a CLE device and labeled diagnostic or non-diagnostic; receiving an indication, from the CNN, likelihoods that the images are diagnostic images; determining, based on the likelihoods, which of the images are diagnostic images; and in response to determining that an image is a diagnostic image, causing the image to be presented during the brain surgery.",A61B 5/00; G06K 9/46; G06K 7/00; G06T 7/33,DIGNITY HEALTH,"IZADYYAZDANABADI, Mohammadhassan; PREUL, Mark, C.; BELYKH, Evgenii","62/458,886 14.02.2017 US",CA-3053368
WO2019104252,PCT/US2018/062395,23.11.2018,WO/2019/104252,31.05.2019,WO,SYSTEM METHOD AND COMPUTER-ACCESSIBLE MEDIUM FOR CLASSIFYING TISSUE USING AT LEAST ONE CONVOLUTIONAL NEURAL NETWORK,"An exemplary system, method and computer-accessible medium for classifying a tissue(s) of a patient(s) can include, for example, receiving an image(s) of an internal portion(s) of a breast of the patient(s), and automatically classifying the tissue(s) of the breast by applying a neural(s) network to the image(s). The tissue(s) can include a lymph node(s). The lymph node(s) can be classified as a cancerous tissue or a non-cancerous tissue. The tissue(s) can be classified as a fibroglandular tissue or a background parenchymal enhancement tissue. The tissue(s) can be classified as a cancer molecular subtype. The image(s) can be is a magnetic resonance image.",G06T 7/00,THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK,"HA, Richard","62/589,924 22.11.2017 US",
WO2018213012,PCT/US2018/030841,03.05.2018,WO/2018/213012,22.11.2018,WO,ESTIMATION OF DAMAGE PREVENTION WITH BUILDING RETROFIT,"Methods, systems, and computer programs are presented for estimating the differences, due to building retrofitting, in damage caused to a building by an earthquake. One method includes operations for accessing a database to retrieve current fragility functions for predicting structural damage to a building, and for identifying features of the building. The method further includes operations for identifying a retrofit measure having a cost to improve the building structure, and for estimating a first building damage after a simulated earthquake utilizing a machine- learning program and the current fragility functions. The method further includes operations for determining new fragility functions for the building based on the retrofit measure and the current fragility functions, for estimating a second building damage after the simulated earthquake utilizing the new fragility functions, and for determining the difference in damage resulting from the retrofit measure based on the first and the second building damage.",G06F 17/50; G06Q 40/08; G06Q 50/16; G06Q 50/26; G01V 1/28,"ONE CONCERN, INC.","WANI, Ahmad; HU, Nicole; FRANK, Timothy","62/506,755 16.05.2017 US",
WO2018106805,PCT/US2017/064910,06.12.2017,WO/2018/106805,14.06.2018,WO,SIGNAL RECOVERY VIA DEEP CONVOLUTIONAL NETWORKS,"Real-world data may not be sparse in a fixed basis, and current high-performance recovery algorithms are slow to converge, which limits compressive sensing (CS) to either non-real-time applications or scenarios where massive back-end computing is available. Presented herein are embodiments for improving CS by developing a new signal recovery framework that uses a deep convolutional neural network (CNN) to learn the inverse transformation from measurement signals. When trained on a set of representative images, the network learns both a representation for the signals and an inverse map approximating a greedy or convex recovery algorithm. Implementations on real data indicate that some embodiments closely approximate the solution produced by state-of-the-art CS recovery algorithms, yet are hundreds of times faster in run time.",H03M 7/30; G06K 9/62; G06N 3/00; G06N 3/04,WILLIAM MARSH RICE UNIVERSITY,"BARANIUK, Richard, G.; MOUSAVI, Ali","62/432,230 09.12.2016 US",
WO2018171533,PCT/CN2018/079362,16.03.2018,WO/2018/171533,27.09.2018,WO,REVIEW MACHINE LEARNING SYSTEM,"An apparatus and method are provided for review-based machine learning. Included are a non-transitory memory storing instructions and one or more processors in communication with the non-transitory memory. The one or more processors execute the instructions to receive first data, generate a plurality of first features based on the first data, and identify a first set of labels for the first data. A first model is trained using the first features and the first set of labels. The first model is reviewed to generate a second model, by receiving a second set of labels for the first data, and reusing the first features with the second set of labels in connection with training the second model.",G06F 17/30,"HUAWEI TECHNOLOGIES CO., LTD.","HU, Luhui; ZANG, Hui; HU, Ziang","15/467,847 23.03.2017 US",
WO2017213780,PCT/US2017/031616,08.05.2017,WO/2017/213780,14.12.2017,WO,MOBILE AND WEARABLE VIDEO CAPTURE AND FEEDBACK PLAT-FORMS FOR THERAPY OF MENTAL DISORDERS,"Behavioral and mental health therapy systems in accordance with several embodiments of the invention include a wearable camera and/or a variety of sensors (accelerometer, microphone, among various other) connected to a computing system including a display, audio output, holographic output, and/or vibrotactile output to automatically recognize social cues from images captured by at least one camera and provide this information to the wearer via one or more outputs such as (but not limited to) displaying an image, displaying a holographic overlay, generating an audible signal, and/or generating a vibration.",G06F 19/00; G06T 7/20; G06Q 50/22,"THE BOARD OF TRUSTEES OF THE LELAND STANFORD JUNIOR UNIVERSITY; VOSS, Catalin","VOSS, Catalin; HABER, Nicholas, Joseph; WALL, Dennis, Paul; KLINE, Aaron, Scott; WINOGRAD, Terry, Allen","62/333,108 06.05.2016 US",CA-3023241; EP-2017810680; CN-201780036661.1; JP-2019510585; KR-1020187035497
EP12315712,92400175,22.01.1992,0496677,29.07.1992,EP,Adaptive equalizers,"The present inventions relate to adaptive equalizers for detecting characteristics of a transmission line in radio and cable communications and for equalizing received signals by using the detected results. An object of the present inventions is to provide a function for equalizing not only linear distortion but also nonlinear distortion in accordance with variation of characteristics of the transmission line. An adaptive equalizer comprises a characteristic detection means 11 for detecting real part and imaginary parts of a transfer function by using an output signal corresponding to an input signal of an object to be equalized to compensate for deterioration, for example a transmission line; and an equalizing means 12 for equalizing an output signal of the object to be equalized 10 in accordance with an unknown input signal by using the detected result of the characteristic detection means 11. <IMAGE>",H04L 25/03; H04L 25/03,FUJITSU LTD,KIMOTO TAKASHI; YAGINUMA YOSHINORI; ASAKAWA KAZUO; NAGATA SHIGEMI,2100591 14.02.1991 JP; 627291 23.01.1991 JP,
WO2019220128,PCT/GB2019/051352,16.05.2019,WO/2019/220128,21.11.2019,WO,GRAPH NEUTRAL NETWORKS WITH ATTENTION,"Methods and apparatus are provided for generating a graph neural network (GNN) model based on an entity-entity graph. The entity-entity graph comprising a plurality of entity nodes in which each entity node is connected to one or more entity nodes of the plurality of entity nodes by one or more corresponding relationship edges. The method comprising: generating an embedding based on data representative of the entity-entity graph for the GNN model, wherein the embedding comprises an attention weight assigned to each relationship edge of the entity-entity graph; and updating weights of the GNN model including the attention weights by minimising a loss function associated with at least the embedding; wherein the attention weights indicate the relevancy of each relationship edge between entity nodes of the entity-entity graph. The entity-entity graph may be filtered based on the attention weights of a trained GNN model. The filtered entity-entity graph may be used to update the GNN model or train another GNN model. The trained GNN model may be used to predict link relationship between a first entity and a second entity associated with the entity-entity graph.",G06N 3/04; G06N 3/08; G06N 5/02; G16B 40/00,BENEVOLENTAI TECHNOLOGY LIMITED,"CREED, Paidi; SIM, Aaron; ALAMDARI, Amir; BRIODY, Joss; NEIL, Daniel; LACOSTE, Alix","62/673,554 18.05.2018 US",
WO2015195609,PCT/US2015/035945,16.06.2015,WO/2015/195609,23.12.2015,WO,ANALYZING DIGITAL HOLOGRAPHIC MICROSCOPY DATA FOR HEMATOLOGY APPLICATIONS,"A method for analyzing digital holographic microscopy (DHM) data for hematology applications includes receiving a plurality of DHM images acquired using a digital holographic microscopy system. One or more connected components are identified in each of the plurality of DHM images and one or more training white blood cell images are generated from the one or more connected components. A classifier is trained to identify a plurality of white blood cell types using the one or more training white blood cell images. The classifier may be applied to a new white blood cell image to determine a plurality of probability values, each respective probability value corresponding to one of the plurality of white blood cell types. The new white blood cell image and the plurality of probability values may then be presented in a graphical user interface.",G06K 9/00; G01N 15/14,SIEMENS HEALTHCARE DIAGNOSTICS INC.,"EL-ZEHIRY, Noha; SUN, Shanhui; GEORGESCU, Bogdan; LADIC, Lance; KAMEN, Ali","62/012,636 16.06.2014 US",US-15318831; EP-2015741628; JP-2016572573
WO2018236852,PCT/US2018/038255,19.06.2018,WO/2018/236852,27.12.2018,WO,INTERPRETATION OF GENETIC AND GENOMIC VARIANTS VIA AN INTEGRATED COMPUTATIONAL AND EXPERIMENTAL DEEP MUTATIONAL LEARNING FRAMEWORK,"Disclosed herein are system, method, and computer program product embodiments for determining phenotypic impacts of molecular variants identified within a biological sample. Embodiments include receiving molecular variants associated with functional elements within a model system. The embodiments then determine molecular scores associated with the model system. The embodiments then determine molecular signals and population signals associated with the molecular variants based on the molecular scores. The embodiments then determine functional scores for the molecular variants based on statistical learning. The embodiments then derive evidence scores of the molecular variants based on the functional scores. The embodiments then determine phenotypic impacts of the molecular variants based on the functional scores or evidence scores.",G06F 19/22; C12Q 1/68,JUNGLA INC.,"ARAYA, Carlos, L.; REUTER, Jason, A.; PADIGEPATI, Samskruthi, Reddy; COLAVIN, Alexandre","62/521,759 19.06.2017 US; 62/640,432 08.03.2018 US",IL-271498; MX-MX/a/2019/015420; AU-2018289410; EP-2018819937
WO2020031851,PCT/JP2019/030255,01.08.2019,WO/2020/031851,13.02.2020,WO,IMAGE PROCESSING METHOD AND IMAGE PROCESSING DEVICE,"The purpose of the present invention is to provide an image processing method and an image processing device capable of efficiently learning images with different backgrounds. In learning and recognition using a hierarchical network, it is experientially known that a layer close to an input functions as a feature extractor for extracting a feature which is necessary for recognition, and a layer close to an output performs recognition by combining extracted features. Therefore, as in an embodiment of the present invention, learning by setting a learning rate on the layer close to the input side of the hierarchical network to be larger relative to a learning rate on the layer close to the output side in a second learning process corresponds to relearning (adjusting) a feature extraction part principally with respect to data sets with different backgrounds. As a result, it is possible to absorb a difference between the data sets, and it is possible to achieve efficient learning as compared to simply performing transfer learning.",G06T 7/00; G06N 3/08,FUJIFILM CORPORATION; 富士フイルム株式会社,"KAMON, Shumpei; 加門　駿平",2018-149388 08.08.2018 JP,
WO2015038358,PCT/US2014/053387,29.08.2014,WO/2015/038358,19.03.2015,WO,CLASSIFICATION OF LAND BASED ON ANALYSIS OF REMOTELY-SENSED EARTH IMAGES,"Land classification based on analysis of image data. Feature extraction techniques may be used to generate a feature stack corresponding to the image data to be classified. A user may identify training data from the image data from which a classification model may be generated using one or more machine learning techniques applied to one or more features of the image. In this regard, the classification module may in turn be used to classify pixels from the image data other than the training data. Additionally, quantifiable metrics regarding the accuracy and/or precision of the models may be provided for model evaluation and/or comparison. Additionally, the generation of models may be performed in a distributed system such that model creation and/or application may be distributed in a multi-user environment for collaborative and/or iterative approaches.",G06F 19/00; G06T 7/00,"DIGITALGLOBE, INC.","MARCHISIO, Giovanni B.; TUSK, Carsten; KOPERSKI, Krzysztof; TABB, Mark D.; SHAFER, Jeffrey D.","14/024,418 11.09.2013 US",
WO2019222675,PCT/US2019/032946,17.05.2019,WO/2019/222675,21.11.2019,WO,"SYSTEM, METHOD AND COMPUTER-ACCESSIBLE MEDIUM FOR A PATIENT SELECTION FOR A DUCTAL CARCINOMA IN SITU OBSERVATION AND DETERMINATIONS OF ACTIONS BASED ON THE SAME","An exemplary system, method and computer-accessible medium for determining ductal carcinoma in situ(DCIS) information regarding a patient (s) can include for example, receiving image (s) of internal portion (s) of a breast of the patient (s), and automatically determining the DCIS information by applying a neural network(s) to the image(s). The DCIS information can include predicting (i) pure DCIS or (ii) DCIS with invasion. Input information of the patient(s) can be selected for a DCIS observation for determining the DCIS informiation. The image (s) can be a mammographic image (s). The image (s) can be one of a magnetic resonance image or a computer tomography image.",A61B 5/055; A61B 6/03,"THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK; HA, Richard","HA, Richard","62/672,945 17.05.2018 US",
EP211348935,17183786,28.07.2017,3279820,07.02.2018,EP,MEDICAL SCANNER TEACHES ITSELF TO OPTIMIZE CLINICAL PROTOCOLS AND IMAGE ACQUISITION,"A computer-implemented method for identifying an optimal set of parameters for medical image acquisition includes receiving a set of input parameters corresponding to a medical imaging scan of a patient and using a model of operator parameter selection to determine a set of optimal target parameter values for a medical image scanner based on the set of input parameters. The medical imaging scan of the patient is performed using the set of optimal target parameter values to acquire one or more images and feedback is collected from one or more users in response to acquisition of the one or more images. This feedback is used to update the model of operator parameter selection, thereby yielding an updated model of operator parameter selection.",G06F 19/00,SIEMENS HEALTHCARE GMBH,KLUCKNER STEFAN; COMANICIU DORIN,201615224710 01.08.2016 US,
WO2003079286,PCT/NZ2003/000045,17.03.2003,WO/2003/079286,25.09.2003,WO,MEDICAL APPLICATIONS OF ADAPTIVE LEARNING SYSTEMS USING GENE EXPRESSION DATA,A neural network module is provided. It comprises an input layer comprising one or more input nodes configured to receive gene expression data. It also has a rule base layer comprising one or more rule nodes and an output layer comprising one or more output nodes configured to output one or more conditions. It also comprises an adaptive component configured to extract one or more rules from the rule base layer representing relationships between the gene expression data and the one or more conditions. Methods and systems using the module are disclosed as well as specific profiles utilising the system.,G06N 3/00; G06N 3/04,"PACIFIC EDGE BIOTECHNOLOGY LIMITED; REEVE, Anthony, Edmund,; FUTSCHIK, Mathias, Erwin,; SULLIVAN, Michael, James,; KASABOV, Nikola, Kirilov; GUILFORD, Parry, John,","REEVE, Anthony, Edmund,; FUTSCHIK, Mathias, Erwin,; SULLIVAN, Michael, James,; KASABOV, Nikola, Kirilov; GUILFORD, Parry, John,",517817 15.03.2002 NZ,US-10507737; JP-2003577211; AU-2003214724
WO2020069534,PCT/US2019/053915,30.09.2019,WO/2020/069534,02.04.2020,WO,"DATA REPRESENTATIONS AND ARCHITECTURES, SYSTEMS, AND METHODS FOR MULTI-SENSORY FUSION, COMPUTING, AND CROSS-DOMAIN GENERALIZATION","A computer-implemented method, computer system and machine readable medium. The method includes performing a set of parameterizations of a plurality of semantic concepts, each parameterization of the set including: receiving existing data at a computer system on the plurality of semantic concepts, the existing data including processed output data from a plurality of neural network-based computing systems (NNBCSs), the processed output data corresponding to a plurality of distinct data domains associated with respective ones of the NNBCSs; generating a data structure to define a continuous vector space of a digital knowledge graph (DKG) based on the existing data; and storing the data structure in the memory circuitry; and in response to a determination that error rates from a processing of data sets by the plurality of NNBCSs are below respective predetermined thresholds, generating a training model.",G06N 3/02; G06N 3/08; G06F 16/901,"BRAINWORKS; ALVELDA, Philip","ALVELDA, Philip","62/739,207 29.09.2018 US; 62/739,208 29.09.2018 US; 62/739,210 29.09.2018 US; 62/739,287 30.09.2018 US; 62/739,297 30.09.2018 US; 62/739,301 30.09.2018 US; 62/739,364 01.10.2018 US; 62/739,864 02.10.2018 US; 62/739,895 02.10.2018 US",
WO2019040866,PCT/US2018/047947,24.08.2018,WO/2019/040866,28.02.2019,WO,APPARATUS AND METHOD FOR AGRICULTURAL DATA COLLECTION AND AGRICULTURAL OPERATIONS,"Aspects of the subject disclosure may include, for example, obtaining video data from a single monocular camera, wherein the video data comprises a plurality of frames, wherein the camera is attached to a mobile robot that is travelling along a lane defined by a row of crops, wherein the row of crops comprises a first plant stem, and wherein the plurality of frames include a depiction of the first plant stem; obtaining robot velocity data from encoder(s), wherein the encoder(s) are attached to the robot; performing foreground extraction on each of the plurality of frames of the video data, wherein the foreground extraction results in a plurality of foreground images; and determining, based upon the plurality of foreground images and based upon the robot velocity data, an estimated width of the first plant stem. Additional embodiments are disclosed.",G06T 7/00; G06T 7/20; G05D 1/02,THE BOARD OF TRUSTEES OF THE UNIVERSITY OF ILLINOIS,"CHOWDHARY, Girish; SOMAN, Chinmay; KAYACAN, Erkan; THOMPSON, Benjamin; ZHANG, Zhongzhong; CHOUDHURI, Anwesa","62/550,271 25.08.2017 US; 62/596,506 08.12.2017 US; 62/688,885 22.06.2018 US",AU-2018320964
WO2018204371,PCT/US2018/030465,01.05.2018,WO/2018/204371,08.11.2018,WO,SYSTEM AND METHOD FOR BATCH-NORMALIZED RECURRENT HIGHWAY NETWORKS,"Embodiments of the present disclosure relate to a recurrent framework based on Recurrent Highway Networks (RHNs) for sequence modeling using batch normalization. In certain embodiments, constraints within the RHNs are relaxed to reduce or avoid gradient vanishing or exploding by normalizing the current transition units in highway layers",G06N 3/04; G06N 3/08; G06K 9/00,KODAK ALARIS INC.,"ZHANG, Chi; PTUCHA, Raymond; LOUI, Alexander; SALVAGGIO, Carl","62/500,347 02.05.2017 US",CN-201880028894.1; EP-2018725729
WO2018208791,PCT/US2018/031620,08.05.2018,WO/2018/208791,15.11.2018,WO,SYSTEMS AND METHODS FOR INSPECTION AND DEFECT DETECTION USING 3-D SCANNING,"A method for detecting defects in objects includes: controlling, by a processor, one or more depth cameras to capture a plurality of depth images of a target object; computing, by the processor, a three-dimensional (3-D) model of the target object using the depth images; rendering, by the processor, one or more views of the 3-D model; computing, by the processor, a descriptor by supplying the one or more views of the 3-D model to a convolutional stage of a convolutional neural network; supplying, by the processor, the descriptor to a defect detector to compute one or more defect classifications of the target object; and outputting the one or more defect classifications of the target object.",G06K 9/66; G06K 9/46; G06K 9/52; G06K 9/62; G03F 1/72; G11C 29/02; B23K 31/02; B23K 9/127,"AQUIFI, INC.","MEMO, Alvise; DEMIRDJIAN, David; MARIN, Giulio; TIEU, Kinh; PERUCH, Francesco; SALVAGNINI, Pietro; MURALI, Giridhar; DAL MUTTO, Carlo; CESARE, Guido","62/503,115 08.05.2017 US",
WO2019156877,PCT/US2019/015927,30.01.2019,WO/2019/156877,15.08.2019,WO,DOMAIN ADAPTION LEARNING SYSTEM,"Described is a system for adapting a deep convolutional neural network (CNN). A deep CNN is first trained on an annotated source image domain. The deep CNN is adapted to a new target image domain without requiring new annotations by determining domain agnostic features that map from the annotated source image domain and a target image domain to a joint latent space, and using the domain agnostic features to map the joint latent space to annotations for the target image domain.",G06F 16/55; G06F 16/51; G06N 3/08,"HRL LABORATORIES, LLC","MUREZ, Zachary; KIM, Kyungnam; KOLOURI, Soheil; ROSTAMI, Mohammad","62/627,179 06.02.2018 US",
WO2020023590,PCT/US2019/043168,24.07.2019,WO/2020/023590,30.01.2020,WO,INTELLIGENT REASONING FRAMEWORK FOR USER INTENT EXTRACTION,"Embodiments of the present systems and methods may provide an intelligent systems framework for analysis of user-generated content from various capture points to determine user intent. For example, a method may be implemented in a computer system comprising a processor, memory accessible by the processor, and computer program instructions stored in the memory and executable by the processor, the method may comprise receiving, at the computer system, data relating to a plurality of aspects of at least one person, including data from at least one of physical or physiological sensors and communicatively connected devices, extracting, at the computer system, from the received data, features relevant to events relating to at least one person, extracting, at the computer system, at least one intent of at least one event relating to at least one person, and performing, at the computer system, an action based on the extracted at least one intent.",G06F 15/18,"HOWARD, Newton","HOWARD, Newton","62/702,815 24.07.2018 US; 16/520,673 24.07.2019 US",
WO2019222759,PCT/US2019/033178,20.05.2019,WO/2019/222759,21.11.2019,WO,RECURRENT MULTIMODAL ATTENTION SYSTEM BASED ON EXPERT GATED NETWORKS,"Systems and methods for multimodal classification include a plurality of expert modules, each expert module configured to receive data corresponding to one of a plurality of input modalities and extract associated features, a plurality of class prediction modules, each class prediction module configured to receive extracted features from a corresponding one of the expert modules and predict an associated class, a gate expert configured to receive the extracted features from the plurality of expert modules and output a set of weights for the input modalities, and a fusion module configured to generate a weighted prediction based on the class predictions and the set of weights. Various embodiments include one or more of an image expert, a video expert, an audio expert, class prediction modules, a gate expert, and a co-learning framework.",G06K 9/62; G06N 3/02,SYNAPTICS INCORPORATED; TRUSTEES OF INDIANA UNIVERSITY,"NESTA, Francesco; GUO, Lijiang; KIM, Minje","62/673,801 18.05.2018 US",
WO2013071155,PCT/US2012/064512,09.11.2012,WO/2013/071155,16.05.2013,WO,"METHODS AND APPARATUS FOR UNSUPERVISED NEURAL REPLAY, LEARNING REFINEMENT, ASSOCIATION AND MEMORY TRANSFER: NEURAL ASSOCIATIVE LEARNING, PATTERN COMPLETION, SEPARATION, GENERALIZATION AND HIERARCHICAL REPLAY","Certain aspects of the present disclosure support techniques for unsupervised neural replay, learning refinement, association and memory transfer.",G06N 3/04,QUALCOMM INCORPORATED,"HUNZINGER, Jason Frank; CHAN, Victor Hokkiu","13/292,184 09.11.2011 US",EP-2012805809; KR-1020147015330; JP-2014541342
WO2020051192,PCT/US2019/049471,04.09.2019,WO/2020/051192,12.03.2020,WO,DIALOGUE SYSTEMS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media for dialogue systems. A transcription of a user utterance is obtained. The transcription of the utterance is tokenized to identify multiple tokens for the utterance. Token-level utterance encodings corresponding to different tokens of the transcription are generated. A system action encoding from data indicating system actions previously performed by the dialogue system are generated. A dialogue context vector based on the utterance encoding and the system action encoding are generated. The token-level utterance encodings, the system action encoding, and the dialogue context vector are processed using a slot tagger to produce token-level output vectors. A limited set of candidate token classifications for the tokens of the user utterance are determined based on the token-level utterance encodings. A response for output is provided in response to the user utterance.",G10L 21/00; G10L 19/16; G10L 15/22; G06F 17/21; G06F 17/27,GOOGLE LLC,"HAKKANI-TUR, Dilek; RASTOGI, Abhinav Kumar; GUPTA, Raghav","62/727,833 06.09.2018 US",
WO2009141631,PCT/GB2009/001303,26.05.2009,WO/2009/141631,26.11.2009,WO,AN IMPROVED NEURO TYPE-2 FUZZY BASED METHOD FOR DECISION MAKING,"According to a first aspect of the invention there is provided a method of decision- making comprising: a data input step to input data from a plurality of first data sources into a first data bank, analysing said input data by means of a first adaptive artificial neural network (ANN), the neural network including a plurality of layers having at least an input layer, one or more hidden layers and an output layer, each layer comprising a plurality of interconnected neurons, the number of hidden neurons utilised being adaptive, the ANN determining the most important input data and defining therefrom a second ANN, deriving from the second ANN a plurality of Type-1 fuzzy sets for each first data source representing the data source, combining the Type-1 fuzzy sets to create Footprint of Uncertainty (FOU) for type-2 fuzzy sets, modelling the group decision of the combined first data sources; inputting data from a second data source, and assigning an aggregate score thereto, comparing the assigned aggregate score with a fuzzy set representing the group decision, and producing a decision therefrom. A method employing a developed ANN as defined in Claim 1 and extracting data from said ANN, the data used to learn the parameters of a normal Fuzzy Logic System (FLS).",G06N 3/04,"SANCTUARY PERSONNEL LIMITED; DOCTOR, Faiyaz; HAGRAS, Hani","DOCTOR, Faiyaz; HAGRAS, Hani",0809443.5 23.05.2008 GB,US-12993958; EP-2009750109
WO2018161723,PCT/CN2018/072372,12.01.2018,WO/2018/161723,13.09.2018,WO,POWER LOAD FORECASTING SYSTEM BASED ON LONG SHORT-TERM MEMORY NEURAL NETWORK,"A power load forecasting system (10) based on a long short-term memory neural (LSTM) network, wherein the LSTM network comprises an input layer, an LSTM network layer, and an output layer. The system comprises: an information receiving module (101) used for transmitting input power load data and region feature factor at a historical moment to the input layer; a modeling module (102) used for training and modeling the power load data and the region feature factor at the historical moment by means of the LSTM network layer, in order to generate a deep neural network load forecasting model; a power forecasting module (103) used for forecasting the power load in a region by means of the deep neural network load forecasting model, and generating a forecasting result of the power load in the region by means of a regressor connected to the LSTM network layer; and a result output module (104) used for outputting the forecasting result of the power load in the region by means of the output layer. By constructing a load forecasting model for multi-task learning on the basis of an LSTM network, power consumption loads in multiple regions can be precisely forecasted, and the forecasting effect is improved.",G06Q 50/06; G06Q 10/04; G06N 3/02,"X-TRIP INFORMATION TECHNOLOGIES CO., LTD; 深圳市景程信息科技有限公司","YANG, Yandong; 杨延东; DENG, Li; 邓力; LI, Shufang; 李书芳; ZHANG, Guanjing; 张贯京; GE, Xinke; 葛新科",201710136478.0 08.03.2017 CN,
WO2013071164,PCT/US2012/064521,09.11.2012,WO/2013/071164,16.05.2013,WO,"METHODS AND APPARATUS FOR UNSUPERVISED NEURAL REPLAY, LEARNING REFINEMENT, ASSOCIATION AND MEMORY TRANSFER: NEURAL COMPONENT REPLAY","Certain aspects of the present disclosure support techniques for unsupervised neural replay, learning refinement, association and memory transfer.",G06N 3/04; G06N 3/08,QUALCOMM INCORPORATED,"HUNZINGER, Jason Frank; CHAN, Victor Hokkiu","13/292,167 09.11.2011 US",KR-1020147015333; EP-2012805810; JP-2014541347
WO2020033967,PCT/US2019/046208,12.08.2019,WO/2020/033967,13.02.2020,WO,TRAINING A DEEP LEARNING SYSTEM FOR MARITIME APPLICATIONS,"An object detection network can be trained with training images to identify and classify objects in images from a sensor system disposed on a maritime vessel. The objects in the images can be identified, classified, and heat maps can be generated. Instructions can be sent regarding operation of the maritime vessel. For some training images, water conditions, sky conditions, and/or light conditions in the image can be changed to generate a second image.",G05D 1/02; G01S 17/89; G05D 1/00; G06K 9/62,BUFFALO AUTOMATION GROUP INC.,"SURESH, Thiru, Vikram; KHAKHARIA, Mohit, Arvind","62/724,349 29.08.2018 US; 62/717,746 10.08.2018 US",
EP279871154,19182560,26.06.2019,3588382,01.01.2020,EP,A DEEP LEARNING METHOD FOR TUMOR CELL SCORING ON CANCER BIOPSIES,,G06K 9/62,DEFINIENS GMBH,KAPIL ANSH; BRIEU NICOLAS,201862690329 26.06.2018 US,
WO2018081036,PCT/US2017/057958,24.10.2017,WO/2018/081036,03.05.2018,WO,DYNAMIC SCENE PREDICTION WITH MULTIPLE INTERACTING AGENTS,Methods and systems for predicting a trajectory include determining prediction samples for agents in a scene based on a past trajectory. The prediction samples are ranked according to a likelihood score that incorporates interactions between agents and semantic scene context. The prediction samples are iteratively refined using a regression function that accumulates scene context and agent interactions across iterations. A response activity is triggered when the prediction samples satisfy a predetermined condition.,G06K 9/00; G06N 3/08; G06K 9/62,"NEC LABORATORIES AMERICA, INC","CHOI, Wongun; VERNAZA, Paul; CHANDRAKER, Manmohan; LEE, Namhoon","62/414,288 28.10.2016 US; 62/418,442 07.11.2016 US; 62/422,086 15.11.2016 US; 15/789,098 20.10.2017 US",
WO2019171398,PCT/IN2019/050188,05.03.2019,WO/2019/171398,12.09.2019,WO,A FUNDUS IMAGE ANALYSIS SYSTEM,"A computer implemented system for analyzing a fundus image of a patient is disclosed. The system (100) comprises at least one processor coupled to a non-transitory computer readable storage medium configured to store a fundus image analysis application (103), comprising: a graphical user interface (103k) comprising interactive elements (103j) configured to enable capture and analysis of the fundus image; a reception means (103a) adapted to receive an input from an image capturing device based on a plurality of parameters of the image capturing device; an interactive fundus image rendering means (103b) adapted to dynamically render the input; a fundus image capture means (103c) adapted to capture the fundus image based on the dynamically rendered input; a first analysis means (103h) configured to generate a first label for the fundus image; a second analysis means (103i) configured to generate a second label for the fundus image.",G06K 9/00; A61B 3/00; G16H 50/00,ARTIFICIAL LEARNING SYSTEMS INDIA PRIVATE LIMITED,"WALIA, Pradeep; KODHANDAPANI, Rajarajeshwari; RAJA, Raja Lakshmi; HALOI, Mrinal",201841008545 08.03.2018 IN,
EP275493078,18203236,30.10.2018,3561645,30.10.2019,EP,DEEP NEURAL NETWORK TRAINING FOR APPLICATION PROGRAM GENERATION,,G06F 3/01; G06F 3/03; G06F 3/033; G06F 3/0346; G06F 3/0482; G06F 3/0488; G06F 3/16; G06N 3/04; G06N 3/063; G06N 3/08; H04L 9/32,FUJITSU LTD,MONTANTES JAMES,201815963011 25.04.2018 US,
WO2019232346,PCT/US2019/034870,31.05.2019,WO/2019/232346,05.12.2019,WO,SYSTEMS AND MEDIA FOR AUTOMATICALLY DIAGNOSING THYROID NODULES,"In accordance with some embodiments, systems, methods, and media for automatically localizing and diagnosing thyroid nodules are provided. In some embodiments, a system for automatically diagnosing thyroid nodules comprises: an ultrasound machine; and a processor programmed to: receive a B-mode ultrasound of a thyroid from the ultrasound machine; provide the B-mode ultrasound to a classification model trained to automatically segment B-mode ultrasound; receive an output indicating which portions of the B-mode ultrasound correspond to a nodule; provide at least a portion of the B-mode ultrasound corresponding to the nodule to a second classification model trained to automatically classify thyroid nodules based B-mode, color Doppler, and shear wave elastography ultrasound; and receive, from the second trained classification model, an output indicative of the likelihood that the nodule is malignant.",A61B 8/08; G06N 3/02,MAYO FOUNDATION FOR MEDICAL EDUCATION AND RESEARCH,"AKKUS, Zeynettin; ERICKSON, Bradley, J.; CALLSTROM, Matthew, R.","62/678,736 31.05.2018 US",
EP21408395,10151057,19.01.2010,2345984,20.07.2011,EP,Online learning of grounded categories using adaptive feature spaces,"The invention therefore provides a method for categorizing input patterns, comprising receiving from an accepting of means at least one input pattern including sensorial information representing observations, generating at least one feature pattern by transforming the input pattern by application of at least one feature extraction module which learns from the performed generating process, categorizing the feature pattern into a category by application of at least one learnable categorization module which learns from the performed categorization process. The learning of the feature extraction module uses input from at least one categorization module based on which the feature extraction module extracts a feature pattern discriminating the categories obtained by the categorization module, and the generating and categorization process are performed on a processing means. The method further comprises storing a category derived from the categorization process with features of the input pattern, and returning category information for the input pattern by an output means.",G06N 3/04; G06N 3/08,HONDA RES INST EUROPE GMBH,GLAESER CLAUDIUS,10151057 19.01.2010 EP,
WO2016187711,PCT/CA2016/050586,24.05.2016,WO/2016/187711,01.12.2016,WO,BIOMARKER-DRIVEN MOLECULARLY TARGETED COMBINATION THERAPIES BASED ON KNOWLEDGE REPRESENTATION PATHWAY ANALYSIS,"A method for therapeutic application involves accessing information associated with a patient and a reference biological network database, generating, using the information associated with the patient and the reference biological network database, a disease model, identifying, from the disease model, a molecular target, identifying, from the molecular target, a drug for the patient, generating, based on the drug for the patient, a treatment plan for the patient, and repetitively generating, based on repetitively inputting a patient outcome from the treatment plan into a feedback loop mechanism, a different treatment plan for the patient based on either the molecular target or a different molecular target.",A61B 90/00; A61B 5/00; G06F 19/00; G06F 19/10; G06N 5/02; C12Q 1/68,CSTS HEALTH CARE INC.,"KLEMENT, Giannoula Lakka; HASHEMI, Ali; GETGOOD, Thomas; KLEMENT, Christos; RIETMAN, Edward A.","62/165,879 22.05.2015 US; 62/194,090 17.07.2015 US; PCT/CA2016/050581 20.05.2016 CA",US-15576543; CA-2986773; EP-2016798993
WO2020041517,PCT/US2019/047570,21.08.2019,WO/2020/041517,27.02.2020,WO,SYSTEMS AND METHODS FOR ENHANCED IMAGING AND ANALYSIS,"A method to, is provided for collecting an image from a sample. The method includes selecting a radiation level for a first probe to meet a desired radiation dosage, and providing, with the first probe, a radiation at a selected point within a region of the sample. The method includes identifying a second selected point within the region of the sample based on a down sampling scheme, and providing a second radiation amount at the second selected point within the region of the sample. The method also includes interpolating a first datum and a second datum based on an up sampling scheme to obtain a plurality of data, and forming an image of the region of the sample with the plurality of data. A system to perform the above method and including the first probe is also provided.",A61B 5/00; G16H 30/40,THE SALK INSTITUTE FOR BIOLOGICAL STUDIES,"MANOR, Uri; FANG, Linjing","62/720,762 21.08.2018 US",
WO2020023959,PCT/US2019/043913,29.07.2019,WO/2020/023959,30.01.2020,WO,SYSTEM AND METHOD FOR AI-BASED EYE CONDITION DETERMINATIONS,"In some embodiments, a set of eye images related to a subject may be provided to a prediction model. A first prediction may be obtained via the prediction model, where the first prediction is derived from a first eye image and indicates whether an eye condition is present in the subject. A second prediction may be obtained via the prediction model, where the second prediction is derived from a second eye image and indicates that the eye condition is present in the subject. An aspect associated with the first prediction may be adjusted via the prediction model based on the second prediction's indication that the eye condition is present in the subject. One or more predictions related to at least one eye condition for the subject may be obtained from the prediction model, where the prediction model generates the predictions based on the adjustment of the first prediction.",G16H 50/20; A61B 3/14; A61B 5/00; G06N 3/02,UNIVERSITY OF MIAMI,"ABOU SHOUSHA, Mohamed; ELSAWY, Amr Saad Mohamed","16/047,944 27.07.2018 US",
WO2011094757,PCT/US2011/023398,01.02.2011,WO/2011/094757,04.08.2011,WO,JOINT EMBEDDING FOR ITEM ASSOCIATION,"Methods and systems to associate semantically-related items of a plurality of item types using a joint embedding space are disclosed. The disclosed methods and systems are scalable to large, web-scale training data sets. According to an embodiment, a method for associating semantically-related items of a plurality of item types includes embedding training items of a plurality of item types in a joint embedding space configured in a memory coupled to at least one processor, learning one or more mappings into the joint embedding space for each of the item types to create a trained joint embedding space and one or more learned mappings, and associating one or more embedded training items with a first item based upon a distance in the trained joint embedding space from the first item to each said associated embedded training items. Exemplary item types that may be embedded in the joint embedding space include images, annotations, audio and video.",G06F 17/30,"GOOGLE INC.; BENGIO, Samy; WESTON, Jason","BENGIO, Samy; WESTON, Jason","61/300,356 01.02.2010 US",CA-2786727; CN-201180007972.8; JP-2012551391; EP-2011703984; AU-2011210535
WO2019232473,PCT/US2019/035046,31.05.2019,WO/2019/232473,05.12.2019,WO,AUTOMATED DETECTION AND CHARACTERIZATION OF MICRO-OBJECTS IN MICROFLUIDIC DEVICES,"Methods are provided for the automated detection, characterization, and selection of micro-objects in a microfluidic device. In addition, methods are provided for grouping detected micro-objects into subgroups that share the same characteristics and, optionally, repositioning micro-objects in a selected sub-population within the microfluidic device. For example, microobjects in a selected sub-population can be moved into sequestration pens. The methods also provide for visual displays of the micro-object characteristics, such as two- or three-dimensional graphs, and for user-based definition and/or selection of sub-populations of the detected microobjects. In addition, non-transitory computer-readable medium in which a program is stored and systems for carrying out any of the disclosed methods are provided.",G01N 21/31; G01N 15/14; G06F 19/00,"BERKELEY LIGHTS, INC.","TENNEY, John A.; VETTERLI, Thomas M.; KIM, Hansohl E.","62/678,791 31.05.2018 US",
WO2019157257,PCT/US2019/017175,08.02.2019,WO/2019/157257,15.08.2019,WO,SYSTEM AND METHOD FOR PSEUDO-TASK AUGMENTATION IN DEEP MULTITASK LEARNING,"A multi-task (MTL) process is adapted to the single-task learning (STL) case, i.e., when only a single task is available for training. The process is formalized as pseudo-task augmentation (PTA), in which a single task has multiple distinct decoders projecting the output of the shared structure to task predictions. By training the shared structure to solve the same problem in multiple ways, PTA simulates the effect of training towards distinct but closely-related tasks drawn from the same universe. Training dynamics with multiple pseudo-tasks strictly subsumes training with just one, and a class of algorithms is introduced for controlling pseudo-tasks in practice.",G06N 3/00; G06N 3/02; G06N 3/04; G06N 3/06; G06N 3/063; G06N 3/067; G06N 3/08,COGNIZANT TECHNOLOGY SOLUTIONS U.S. CORPORATION,"MEYERSON, Elliot; MIIKKULAINEN, Risto","62/628,248 08.02.2018 US; 62/684,125 12.06.2018 US",
WO2020072700,PCT/US2019/054365,02.10.2019,WO/2020/072700,09.04.2020,WO,HLA SINGLE ALLELE LINES,"Adaptive immune responses rely on the ability of cytotoxic T cells to identify and eliminate cells displaying disease-specific antigens on human leukocyte antigen (HLA) class I molecules. Investigations into antigen processing and display have immense implications in human health, disease and therapy. To extend understanding of the rules governing antigen processing and presentation, immunopurified peptides from B cells, each expressing a single HLA class I allele, were profiled. A resource dataset containing thousands of peptides bound to distinct class I HLA- A, -B, and -C alleles was generated by implementing a novel allele-specific database search strategy. Applicants discovered new binding motifs, established the role of gene expression in peptide presentation and improved prediction of HLA-peptide binding by using these data to train machine-learning models. These streamlined experimental and analytic workflows enable direct identification and analysis of endogenously processed and presented antigens.",A61K 35/15; A61K 39/00; G01N 33/569,"DANA-FARBER CANCER INSTITUTE, INC.; THE GENERAL HOSPITAL CORPORATION; THE BROAD INSTITUTE, INC.; KESKIN, Derin; SARKIZOVA, Siranush; CARR, Steven; WU, Catherine J.; CLAUSER, Karl","KESKIN, Derin; SARKIZOVA, Siranush; CARR, Steven; WU, Catherine J.; CLAUSER, Karl; KLAEGER, Susan; HACOHEN, Nir","62/740,324 02.10.2018 US; 62/852,924 24.05.2019 US",
EP203841214,15794785,06.11.2015,3218901,20.09.2017,EP,PREDICTION-BASED SEQUENCE RECOGNITION,,G10L 15/16; G06N 3/04,MICROSOFT TECHNOLOGY LICENSING LLC,YU DONG; ZHANG YU; SELTZER MICHAEL L; DROPPO JAMES G,201414578938 22.12.2014 US; 201462079164 13.11.2014 US; 2015059361 06.11.2015 US,
EP14326827,03788512,15.08.2003,1534122,01.06.2005,EP,MEDICAL DECISION SUPPORT SYSTEMS UTILIZING GENE EXPRESSION AND CLINICAL INFORMATION AND METHOD FOR USE,"Embodiments of this invention provide improved medical decision support systems and methods for using such systems to simultaneously consider two or more different types of information along with estimates of accuracies of the information to produce a combined predictor (Figure 1). Such predictors have greater accuracy compared to use of the individual types of information alone. Increased accuracy can increase the likelihood of correct diagnosis and/or evaluation of clinical condition or outcome, and can decrease the frequency of false negative results, including misdiagnosis. Embodiments of medical decision support systems can include EFuNN, Bayesian or other statistical estimators to produce a combined predictor. The systems can be used to extract relationship rules between sets of genes and clinical variables common for patients of a group, thus making a personalized gene-based treatment possible. Such systems are incorporated into computer-based devices and are run using suitable computer programs.",G06F 19/20; A61B 5/00; A61K; G06F 19/00; G06F 19/18; G06F 19/24,PACIFIC EDGE LTD,KASABOV NIKOLA KIRILOV; FUTSCHIK MATTHIAS ERWIN; SULLIVAN MICHAEL JAMES; REEVE ANTHONY EDMUND,0325563 15.08.2003 US; 40375602 15.08.2002 US,
WO2018029696,PCT/IN2016/050268,10.08.2016,WO/2018/029696,15.02.2018,WO,METHODS AND APPARATUS FOR SEMANTIC KNOWLEDGE TRANSFER,"A method (100) for transferring semantic knowledge between domains of a network is disclosed, the network comprising a first domain and a second domain. The method comprises establishing a semantic knowledge base for the first domain (110), the semantic knowledge base comprising concepts of the first domain, properties of the first domain concepts, relationships between the first domain concepts, and constraints governing the first domain concepts (110a). The method further comprises establishing a semantic information base for the second domain (120), the semantic information base comprising concepts of the second domain (120a). The method further comprises, for a concept of the second domain (130), determining measures of similarity between the second domain concept and concepts of the first domain (140) and identifying, on the basis of the determined measures of similarity, a first domain concept which is equivalent to the second domain concept (150). The method further comprises, for the concept of the second domain, mapping properties, relationships and constraints from the semantic knowledge base of the first domain which apply to the identified first domain concept to the second domain concept (160), and populating a semantic knowledge base for the second domain with the second domain concept and the mapped properties, relationships and constraints (170). Also disclosed are an apparatus (300, 400) and a computer program configured to carry out a method for transferring semantic knowledge between domains of a network.",G06F 17/00; G06N 5/00,"TELEFONAKTIEBOLAGET LM ERICSSON (PUBL); MOHAN, Saravanan","MOHAN, Saravanan; BANERJEE, Arindam",,EP-2016912604; CN-201680089964.5
EP283496596,19189781,02.08.2019,3608845,12.02.2020,EP,SYSTEM AND METHOD FOR USING A USER-ACTION LOG TO LEARN TO CLASSIFY ENCRYPTED TRAFFIC,A system and method for the monitoring of encrypted communication over communication networks and the application of machine-learning techniques to facilitate such monitoring. The system comprises a communication interface and a processor which are configured to obtain a user-action log. The user-action log specifies a series of actions performed using an application and the respective times at which the actions were performed. The system uses the communication interface to obtain a network-traffic report that specifies properties of a plurality of packets that were exchanged between the application and a server for the application during performance of the actions. The properties including respective receipt times for the packets while the packets were en route between the application and the server. The system defines multiple non-overlapping blocks of consecutive ones of the packets based on the receipt times. It identifies a correspondence between the actions and respective corresponding ones of the blocks by correlating between the action times and the receipt times. The system uses the identified correspondence to train a classifier to associate other blocks of packets with respective ones of the action types based on the properties of the other blocks.,G06N 3/08; H04L 12/26; H04L 29/08,VERINT SYSTEMS LTD,GIL OFFRI; ZIV OMER; FRIEDMAN GAL,26098618 05.08.2018 IL,
WO2017163230,PCT/IL2017/050230,23.02.2017,WO/2017/163230,28.09.2017,WO,METHOD AND SYSTEM FOR CONVERTING AN IMAGE TO TEXT,"In a method of converting an input image patch to a text output, a convolutional neural network (CNN) is applied to the input image patch to estimate an n-gram frequency profile of the input image patch. A computer-readable database containing a lexicon of textual entries and associated n-gram frequency profiles is accessed and searched for an entry matching the estimated frequency profile. A text output is generated responsively to the matched entries.",G06K 9/46; G06K 9/62,RAMOT AT TEL-AVIV UNIVERSITY LTD.,"WOLF, Lior; POZNANSKI, Arik","62/312,560 24.03.2016 US",US-16086646; EP-2017769556
WO2020006271,PCT/US2019/039564,27.06.2019,WO/2020/006271,02.01.2020,WO,WEARABLE SYSTEM FOR BRAIN HEALTH MONITORING AND SEIZURE DETECTION AND PREDICTION,"The present disclosure provides for monitoring brain health and predicting and detecting seizures via a wearable device. An exemplary device includes a plurality of sensors, at least one camera, a wireless communication element, and a frame. The at least one camera records image data of a user's face. The wireless communication element transmits sensor data from the plurality of sensors to an external computing device. The frame houses the at least one camera, the wireless communication element, and the plurality of sensors. The frame is configured to be worn on the head of the user.",A61B 5/0476,CORTEXXUS INC.,"ALVES, David; RAZAVI, Babak; DE JESUS ALVES, Ana Margarida","62/690,520 27.06.2018 US; 62/800,194 01.02.2019 US",
WO2020037217,PCT/US2019/046841,16.08.2019,WO/2020/037217,20.02.2020,WO,TECHNIQUES FOR BUILDING A KNOWLEDGE GRAPH IN LIMITED KNOWLEDGE DOMAINS,"Techniques disclosed herein relate generally to constructing a customized knowledge graph. In one embodiment, entities and relations among entities are extracted from a user dataset based on certain rules to generate a seed graph. Large-scale knowledge graphs are then traversed using a finite state machine to identify candidate entities and/or relations to add to the seed graph. A priority function is used to select entities and/or relations from the candidate entities and/or relations. The selected entities and/or relations are then added to the seed graph to generate the customized knowledge graph.",G06N 5/02; G06N 5/04; G06N 20/00; G06N 3/00; G06N 3/08,ORACLE INTERNATIONAL CORPORATION,"SINGARAJU, Gautam; AMMANABROLU, Prithviraj Venkata","62/765,005 16.08.2018 US; 16/542,017 15.08.2019 US",
WO2016077157,PCT/US2015/059361,06.11.2015,WO/2016/077157,19.05.2016,WO,PREDICTION-BASED SEQUENCE RECOGNITION,A sequence recognition system comprises a prediction component configured to receive a set of observed features from a signal to be recognized and to output a prediction output indicative of a predicted recognition based on the set of observed features. The sequence recognition system also comprises a classification component configured to receive the prediction output and to output a label indicative of recognition of the signal based on the prediction output.,G10L 15/16; G06N 3/04,"MICROSOFT TECHNOLOGY LICENSING, LLC","YU, Dong; ZHANG, Yu; SELTZER, Michael L.; DROPPO, James G.","62/079,164 13.11.2014 US; 14/578,938 22.12.2014 US",
EP238739202,17188832,31.08.2017,3451231,06.03.2019,EP,IMAGIFICATION OF MULTIVARIATE DATA,"A method for creating and storing images representing data in a multivariate data set having at least N variables comprises: partitioning an N-1 dimensional image attribute region into M sub-regions corresponding respectively to different values of one of the variables associated with N-1 continuous variables of the N variables, the N-1 dimensional image attribute region having N-1 axes respectively representing the N-1 variables; for each data sub-set in the data set, mapping the values of the N-1 variables to a corresponding position in one of the sub-regions of the image attribute region which corresponds to the value of the associated one variable, and assigning to the data sub-set an image attribute corresponding to the position of the data sub-set in the image attribute region; creating an image representing the data in the multivariate data set using the image attributes assigned to the data sub-sets; and storing the created image in computer storage for use in an automated image processing system.",G06K 9/62,FUJITSU LTD,TOWNSEND JOSEPH,17188832 31.08.2017 EP,
WO2019169044,PCT/US2019/019907,27.02.2019,WO/2019/169044,06.09.2019,WO,SYSTEMS AND METHODS FOR DETECTION OF RESIDUAL DISEASE,"The disclosure relates to systems, software, and methods for the detection of residual disease, e.g., residual tumor disease, in subjects, e.g., human cancer patients.",C12Q 1/68; C12Q 1/6886; G01N 33/574,"CORNELL UNIVERSITY; NEW YORK GENOME CENTER; THE BROAD INSTITUTE, INC.; LANDAU, Dan Avi; ZVIRAN, Asaf; ADALSTEINSSON, Viktor A.","LANDAU, Dan Avi; ZVIRAN, Asaf; ADALSTEINSSON, Viktor A.","62/636,150 27.02.2018 US",
EP275493166,19170842,24.04.2019,3561723,30.10.2019,EP,AIRPORT NOISE CLASSIFICATION METHOD AND SYSTEM,,G06K 9/00; G08G 5/00; G10L 21/10; G10L 25/27; G10L 25/51,METROPOLITAN AIRPORTS COMMISSION,ANDERSON DEREK; BAKER MATTHEW; HELLER NICHOLAS; JUFFER BRADLEY,201862662590 25.04.2018 US; 201916386603 17.04.2019 US,
WO2020041399,PCT/US2019/047389,21.08.2019,WO/2020/041399,27.02.2020,WO,IMAGE PROCESSING METHOD AND APPARATUS,"An image processing method and apparatus are disclosed in embodiments of this specification. The method is performed at a mobile device that comprises a camera. The method comprises: acquiring a video stream of an accident vehicle by the camera according to a user instruction; obtaining an image of a current frame in the video stream; determining whether the image meets a predetermined criterion by inputting the image into a predetermined classification model; adding a target box and/or target segmentation information to the image by inputting the image into a target detection and segmentation model when the image meets the predetermined criterion, wherein the target box and the target segmentation information both correspond to at least one of vehicle parts and vehicle damage of the vehicle; and displaying the target box and/or the target segmentation information to the user.",H04N 5/232; G06N 3/02; G06Q 40/08; G06K 9/00,ALIBABA GROUP HOLDING LIMITED,"GUO, Xin; CHENG, Yuan; JIANG, Chen; LU, Zhihong",201810961701.X 22.08.2018 CN,
WO2020036082,PCT/JP2019/030574,02.08.2019,WO/2020/036082,20.02.2020,WO,"INSPECTION DEVICE, INSPECTION METHOD, AND INSPECTION PROGRAM","The present invention addresses the problem of providing an inspection device, an inspection method, and an inspection program that make it possible to achieve highly accurate foodstuff inspections. According to the present embodiment, a foodstuff inspection server 12: (1) performs object recognition that involves recognizing an inspection target (an ingredient for a foodstuff, a foodstuff, or a container and a foodstuff that is in the container) from an image that has been captured of the inspection target by a foodstuff imaging device 11 and extracting the region of the recognized inspection target from the image; and (2) adapts the extracted region to a model that has been generated by the foodstuff inspection server 12 (a model that is for classifying inspection targets as quality or not quality and that has been generated by unsupervised transfer learning that uses images of quality inspection targets as learning data and is based on feature data that has been extracted using a trained model that has been adjusted by Bayesian optimization) and thereby classifies the recognized inspection target as quality or not quality.",G01N 21/88; G06T 7/00,"AJINOMOTO CO., INC.; 味の素株式会社","SHIMODAIRA, Yoshiki; 下平　祥貴; MORI, Kazuyuki; 森　和之",2018-152830 15.08.2018 JP,
WO2016026135,PCT/CN2014/085007,22.08.2014,WO/2016/026135,25.02.2016,WO,FACE ALIGNMENT WITH SHAPE REGRESSION,"The subject matter described herein relates to face alignment via shape regression. A method, computer storage medium, and system are provided. The method comprises receiving an image including a face; and performing shape regression to estimate a facial shape in the image. For each stage in the shape regression, a local feature is extracted from a local region around each facial landmark in the image independently; and a joint projection is performed based on local features of multiple facial landmarks to predict a facial shape increment. Then, a facial shape of a current stage is generated based on the predicted facial shape increment and a facial shape of a previous stage.",G06K 9/66; G06K 9/00,"MICROSOFT TECHNOLOGY LICENSING, LLC; CAO, Xudong","CAO, Xudong; WEI, Yichen; SUN, Jian; REN, Shaoqing",,EP-2014900073
WO2019068200,PCT/CA2018/051260,05.10.2018,WO/2019/068200,11.04.2019,WO,BRAIN-COMPUTER INTERFACE PLATFORM AND PROCESS FOR CLASSIFICATION OF COVERT SPEECH,"A device and method are provided for real-time classification of covert speech. The device comprises a plurality of sensors for capturing real-time bio-signal data for brain monitoring in response to mental tasks delivered to a user, and a brain computer interface with memory storing instructions to configure a processor to perform a method of real-time classification of covert speech. The method comprises capturing real-time bio-signal data for brain monitoring in response to mental tasks delivered to a user, pre-processing the raw bio-signal data, extracting a vector of features from the raw bio-signal data, selecting features from the vector of features, building classification model to generate classified covert speech data using the selected features, and controlling a display device with visual elements based on the classified covert speech data.",G06K 9/62; A61B 5/04; A61B 5/0476; G06F 3/01; G06F 3/14,HOLLAND BLOORVIEW KIDS REHABILITATION HOSPITAL,"SERESHKEH, Alborz Rezazadeh; CHAU, Thomas Tak Kin","62/569,184 06.10.2017 US; 62/642,180 13.03.2018 US",
WO2016063794,PCT/JP2015/079241,08.10.2015,WO/2016/063794,28.04.2016,WO,METHOD FOR TRANSFORMING A NOISY AUDIO SIGNAL TO AN ENHANCED AUDIO SIGNAL,"A method transforms a noisy audio signal to an enhanced audio signal, by first acquiring the noisy audio signal from an environment. The noisy audio signal is processed by an enhancement network having network parameters to jointly produce a magnitude mask and a phase estimate. Then, the magnitude mask and the phase estimate are used to obtain the enhanced audio signal.",G10L 25/30; G10L 21/0208; G10L 21/0324; G06N 3/02,MITSUBISHI ELECTRIC CORPORATION,"ERDOGAN, Hakan; HERSHEY, John; WATANABE, Shinji; LE ROUX, Jonathan",62/066451 21.10.2014 US; 14/620526 12.02.2015 US,DE-112015004785; JP-2017515359
WO2017124116,PCT/US2017/013829,17.01.2017,WO/2017/124116,20.07.2017,WO,"SEARCHING, SUPPLEMENTING AND NAVIGATING MEDIA","One or more computing devices, systems, and/or methods for searching, supplementing and/or navigating media are provided. For example, a query for media may be used to identify results and provide the results based upon temporal properties of the results. In another example, media may be segmented into portions based upon time-associated text information of the media, and each portion of the media may be supplemented with content selected based upon a context of the portion. In another example, an area of a video may be selected based upon image analysis of the video, and the video may be supplemented with content at the area. In another example, a video may be supplemented with content, and properties of the content may be adjusted based upon image analysis of the video. In another example, media may be navigated through at different rates of advancement.",G06F 17/30,"BAO, Sheng; LIU, Yang","BAO, Sheng; LIU, Yang","62/279,616 15.01.2016 US; 62/446,650 16.01.2017 US",
EP14242020,03291359,06.06.2003,1484716,08.12.2004,EP,An architecture for self-developing devices,"A self-developing device (1) capable of open-ended development makes use of a special motivational system for selecting which action should be taken on the environment by an associated sensory-motor apparatus (2). For a given candidate action, a motivational module (11) calculates a reward associated with the corresponding values that would be taken by one or more motivational variables that are independent of the nature of the associated sensory-motor apparatus. Preferred motivational variables are dependent on the developmental history of the device (1), and include variables quantifying the predictability, familiarity and stability of sensory-motor variables serving as the inputs to the device (1). The sensory-motor variables represent the status of the external environment and/or the internal resources (3) of the sensory-motor apparatus (2) whose behaviour is controlled by the self-developing device (1). Open-ended development is enabled by attributing a reward which is proportional to the rate of change of the history-dependent motivational variables. <IMAGE>",G06N 3/00; B25J 13/00; G06N 3/00,SONY FRANCE SA,KAPLAN FREDERIC; OUDEYER PIERRE-YVES,03291359 06.06.2003 EP,
WO2019113308,PCT/US2018/064240,06.12.2018,WO/2019/113308,13.06.2019,WO,ACTIVE ADAPTATION OF NETWORKED COMPUTE DEVICES USING VETTED REUSABLE SOFTWARE COMPONENTS,"A method includes receiving a text description of a system capability request, and converting the text description into a normalized description of the system capability request. A repository is then queried, based on the normalized description and using a search algorithm, to identify multiple candidate application software units (ASUs). The candidate ASUs are displayed to a user for selection. The user-selected ASU is then deployed, either locally or to at least one remote compute device, in response to receiving the user selection. Deployment can include the user-selected candidate ASU being integrated into a local or remote software package, thus defining a modified software package that is configured to provide the system capability.",G06F 9/06; G06F 9/44; G06F 9/45; G06F 15/16; G06F 17/30; G06F 17/50,"FRANCHITTI, Jean-Claude","FRANCHITTI, Jean-Claude","62/594,922 05.12.2017 US",
EP206520225,16869294,23.11.2016,3245652,22.11.2017,EP,DEPLOYED END-TO-END SPEECH RECOGNITION,,G10L 15/16; G10L 15/06; G10L 15/08; G10L 15/183,BAIDU USA LLC,CATANZARO BRYAN; CHEN JINGDONG; CHRZANOWSKI MIKE; ELSEN ERICH; ENGEL JESSE; FOUGNER CHRISTOPHER; HAN XU; HANNUN AWNI; PRENGER RYAN; SATHEESH SANJEEV; SENGUPTA SHUBHABRATA; YOGATAMA DANI; WANG CHONG; ZHAN JUN; ZHU ZHENYAO; AMODEI DARIO,201562260206 25.11.2015 US; 2016063641 23.11.2016 US; 201615358083 21.11.2016 US; 201615358102 21.11.2016 US,
EP253959221,18204942,07.11.2018,3547161,02.10.2019,EP,POSITION-DEPENDENT WORD SALIENCE ESTIMATION,,G06F 17/27; G06N 3/02; G06Q 50/00,SAP SE,ZHENG XIN,201815940041 29.03.2018 US,
WO2014040175,PCT/CA2013/000785,16.09.2013,WO/2014/040175,20.03.2014,WO,"SYSTEMS AND METHODS FOR COLLECTING, ANALYZING, AND SHARING BIO-SIGNAL AND NON-BIO-SIGNAL DATA","A computer network implemented system for improving the operation of one or more biofeedback computer systems is provided. The system includes an intelligent bio-signal processing system that is operable to: capture bio-sigrial data and in addition optionally non-bio-signal data; and analyze the bio-signal data and non-bio-signal data, if any, so as to: extract one or more features related to at least one individual interacting with the biofeedback computer system; classify the individual based on the features by establishing one or more brain wave interaction profiles for the individual for improving the interaction of the individual with the one or more biofeedback computer systems, and initiate the storage of the brain waive interaction profiles to a database; and access one or more machine learning components or processes for further improving the interaction of the individual with the one or more biofeedback computer systems by updating automatically the brain wave interaction profiles based on detecting one or more defined interactions between the individual and the one or more of the biofeedback computer systems. A number of additional system and computer implemented method features are also provided.",G06F 17/30; A61B 5/00; A61B 5/0476; G06F 15/18; H04L 12/16,INTERAXON INC.,"COLEMAN, Trevor CE; AIMONE, Christopher Allen; GARTEN, Ariel Stephanie; PINO, Locillo (Lou) Giuseppe; BARANOWSKI, Paul Harrison; RUPSINGH, Raul Rajiv; VIDYARTHI, Kapil Jay Mishra","61/701,176 14.09.2012 US; 61/701,002 14.09.2012 US",CA-2923979; EP-2013836691; US-14115781
WO2020052169,PCT/CN2018/124841,28.12.2018,WO/2020/052169,19.03.2020,WO,CLOTHING ATTRIBUTE RECOGNITION DETECTION METHOD AND APPARATUS,"A clothing attribute recognition detection method and apparatus. The method comprises: obtaining a picture to be detected, the picture to be detected being a clothing picture; labeling the picture to be detected by using a key point model, and generating the picture to be detected in which a key point is labeled, wherein the key point model is obtained by training a multilayer network structure by using a data set, the multilayer network structure comprises a primary network and a secondary network, and the data set is a set of data obtained by performing data pre-processing after capturing a large number of clothing picture data; according to the picture to be detected in which the key point is labeled, performing clothing attribute recognition of a key point region by using a clothing attribute model, and obtaining clothing attribute information of the picture to be detected, wherein the clothing attribute model is obtained by training a pre-training model on the basis of the idea of transfer learning.",G06K 9/62,"SHENZHEN INTELLIFUSION TECHNOLOGIES CO., LTD.; 深圳云天励飞技术有限公司","DONG, Er Xi; 董尔希; HUANG, Xuan; 黄轩; WANG, Xiao Yu; 王孝宇; FU, Ling Zhi; 付凌志; YU, Yong Bo; 虞勇波",201811059627.9 12.09.2018 CN,
WO2020047440,PCT/US2019/049111,30.08.2019,WO/2020/047440,05.03.2020,WO,SYSTEM AND METHOD FOR PERFORMING IMAGE PROCESSING BASED ON A DAMAGE ASSESSMENT IMAGE JUDGEMENT MODEL,"A system is provided for performing image processing. During operation, the system can obtain a video stream of a target object, and obtain, from the video stream, a plurality of images ranked according to a first sequence. The target object can be, e.g., a damage vehicle. The system can then extract a set of feature vectors corresponding to the plurality of images. The system may sequentially provide the set of feature vectors to a trained damage assessment image judgment model. Next, the system can apply the trained damage assessment image judgment model to determine whether each image in the plurality of images corresponds to a damage assessment image.",G06K 9/00; G06K 9/62,ALIBABA GROUP HOLDING LIMITED,"GUO, Xin; CHENG, Yuan; HUANG, Jun","201811014364.X 31.08.2018 CN; 16/555,425 29.08.2019 US",
EP281666234,19162981,14.03.2019,3594861,15.01.2020,EP,SYSTEMS AND METHODS FOR CLASSIFICATION OF MULTI-DIMENSIONAL TIME SERIES OF PARAMETERS,,G06N 3/04; G06N 3/08,TATA CONSULTANCY SERVICES LTD,UKIL ARIJIT; BANDYOPADHYAY SOMA; MALHOTRA PANKAJ; PAL ARPAN,201821025603 09.07.2018 IN,
WO2019190312,PCT/NL2019/050182,25.03.2019,WO/2019/190312,03.10.2019,WO,ADAPTIVE ARTIFICIAL INTELLIGENCE SYSTEM FOR EVENT CATEGORIZING BY SWITCHING BETWEEN DIFFERENT STATES,"The invention provides an artificial intelligence (AI) system for categorizing events, said AI system comprising a first state and a second state, wherein: - said AI system is in a first state for categorizing events in a first category type; - upon categorizing of a first event in a predefined category of said first category type, said AI system is set to said second state, in said second state said AI system is set for categorizing subsequent events in a second category type.",G06N 3/04,KEPLER VISION TECHNOLOGIES BV,"STOKMAN, Henricus Meinardus Gerardus; VAN OLDENBORGH, Marc Jean Baptist",2020685 29.03.2018 NL,
EP276895893,19169386,16.04.2019,3570219,20.11.2019,EP,"CONTROL SYSTEM, LEARNING DATA CREATION APPARATUS, LEARNING APPARATUS, AND JUDGMENT APPARATUS",,G06N 3/00; G06N 3/04; G06N 3/08,OMRON TATEISI ELECTRONICS CO,ANDO TANICHI,2018092840 14.05.2018 JP,
WO2017157555,PCT/EP2017/051656,26.01.2017,WO/2017/157555,21.09.2017,WO,HIGH ACCURACY 5-PART DIFFERENTIAL WITH DIGITAL HOLOGRAPHIC MICROSCOPY AND UNTOUCHED LEUKOCYTES FROM PERIPHERAL BLOOD,"The present invention relates to an improved method for marker-free detection of a cell type of at least one cell in a medium using microfluidics and digital holographic microscopy, as well as a device, particular for carrying out the method.",G01N 15/14; G03H 1/04; G06K 9/00,SIEMENS HEALTHCARE GMBH,"EL-ZEHIRY, Noha Youssry; HAYDEN, Oliver; KAMEN, Ali; RICHTER, Lukas; STANZEL, Manfred; UGELE, Matthias; SEIDEL, Daniela; MARQUARDT, Gaby; SCHMIDT, Oliver",16160664.5 16.03.2016 EP; 16182979.1 05.08.2016 EP,JP-2018548662
WO1999058479,PCT/US1999/010611,13.05.1999,WO/1999/058479,18.11.1999,WO,"LEARNING-BASED CONTROLLER FOR BIOTECHNOLOGY PROCESSING, AND METHOD OF USING","The present invention relates to process control where some of the controllable parameters are difficult or impossible to characterize. The present invention relates to process control in biotechnology of such systems, but not limited to. Additionally, the present invention relates to process control in biotechnology minerals processing. In the inventive method, an application of the present invention manipulates a minerals bioprocess to find local exterma (maxima or minima) for selected output variables/process goals by using a learning-based controller for bioprocess oxidation of minerals during hydrometallurgical processing. The learning-based controller operates with or without human supervision and works to find processor optima without previously defined optima due to the non-characterized nature of the process being manipulated.",C12M 1/36; E21B 41/00; E21B 43/28; G05B 13/02,"BECHTEL BWXT IDAHO, LLC; JOHNSON, John, A.; STONER, Daphne, L.; LARSEN, Eric, D.; MILLER, Karen, S.; TOLLE, Charles, R.","JOHNSON, John, A.; STONER, Daphne, L.; LARSEN, Eric, D.; MILLER, Karen, S.; TOLLE, Charles, R.","60/085,420 13.05.1998 US",US-09647134
WO2020035453,PCT/EP2019/071604,12.08.2019,WO/2020/035453,20.02.2020,WO,MAPPING IMAGES TO THE SYNTHETIC DOMAIN,"Mapping Images to the Synthetic Domain The invention relates to a method for training a generative network which is designed for converting cluttered images into a representation of the synthetic domain. In addition, the invention provides a method for recovering an object from a cluttered image.",G06K 9/62,SIEMENS AKTIENGESELLSCHAFT,"PLANCHE, Benjamin; ZAKHAROV, Sergey; HUTTER, Andreas; ILIC, Slobodan; WU, Ziyan","62/719,210 17.08.2018 US; 18208941.7 28.11.2018 EP",
EP96170896,12178238,27.07.2012,2690582,29.01.2014,EP,System for controlling an automated device,"The present invention uses context information, in order to control an incremental learning process of a system 1 for controlling an automated device even in an unexpected environment. The system 1 is able to correct errors, which are produced by a pre-trained mapping unit 4 that maps an input obtained by primary sensors 2 onto a first control signal 4a for controlling the automated device. The context information obtained by context sensors 3 helps to constrain the learning process of a learning unit 8 to situations, which can be uniquely identified and cannot be covered by the mapping unit 4. A control signal 9a of the combined control signals 4a and 8a of the mapping unit 4 and the learning unit 8, respectively, is computed in a fusion unit 9 by evaluating the confidence values of the two control signals 4a, 8a, and by either choosing one of the two control signals or interpolating between the two control signals. The confidence value evaluation can be done by quantizing the input space according to the incremental learning data, and using the quantized regions for evaluating the performance of both the learned and pre-trained unit within each region.",G06K 9/62; G05D 1/02,HONDA RES INST EUROPE GMBH,WERSING HEIKO; QUEISSER JEFFREY FREDERIC,12178238 27.07.2012 EP,
WO2015192655,PCT/CN2015/071382,23.01.2015,WO/2015/192655,23.12.2015,WO,METHOD AND DEVICE FOR ESTABLISHING AND USING USER RECOMMENDATION MODEL IN SOCIAL NETWORK,"A method and device for establishing and using a user recommendation model in a social network, for recommending a user in the social network based on heterogeneous data so as to solve the technical problem in the prior art that current user recommendation requirements cannot be satisfied. In some feasible embodiments of the present invention, the method for establishing a user recommendation model in the social network comprises: acquiring training data from the social network, the training data comprising text data, image data and user-related data; performing heterogeneous data transfer learning with respect to the training data, and learning a semanteme of the training data; establishing a relationship between a user and the image data using the text data as a medium, and establishing a semanteme association relationship between the image data and the user according to the semanteme of the training data and the relationship between the user and the image data; and establishing a user recommendation model according to the semanteme association relationship, the user recommendation model comprising the semanteme association relationship between the image data and the user.",G06F 17/30,"HUAWEI TECHNOLOGIES CO., LTD.; 华为技术有限公司","YANG, Qiang; 杨强; ZHEN, Yi; 甄毅; DAI, Wenyuan; 戴文渊",201410281345.9 20.06.2014 CN,
WO2019202886,PCT/JP2019/010433,07.03.2019,WO/2019/202886,24.10.2019,WO,AUDIO SIGNAL PROCESSING SYSTEM AND METHOD FOR TRANSFORMING INPUT AUDIO SIGNALS,"Systems and methods for an audio signal processing system for transforming an input audio signal. A processor implements steps of a module by inputting an input audio signal into a spectrogram estimator to extract an audio feature sequence, and process the audio feature sequence to output a set of estimated spectrograms. Processing the set of estimated spectrograms and the audio feature sequence using a spectrogram refinement module, to output a set of refined spectrograms. Wherein the processing of the spectrogram refinement module is based on an iterative reconstruction algorithm. Processing the set of refined spectrograms for the one or more target audio signals using a signal refinement module, to obtain the target audio signal estimates. An output interface to output the optimized target audio signal estimates. Wherein the module is optimized by minimizing an error using an optimizer stored in the memory.",G10L 21/0272; G10L 25/30,MITSUBISHI ELECTRIC CORPORATION,"LE ROUX, Jonathan; HERSHEY, John, R.; WANG, Zhongqiu; WICHERN, Gordon, P.","62/658,567 16.04.2018 US; 15/983,256 18.05.2018 US",
WO2019209276,PCT/US2018/029263,25.04.2018,WO/2019/209276,31.10.2019,WO,IDENTIFYING DIFFERENCES BETWEEN IMAGES,A method is disclosed. The method may comprise obtaining first image data representing a reference image to be printed on a substrate. The method may comprise obtaining second image data representing a scanned image of a substrate on which the reference image has been printed. The method may comprise combining the first image data and the second image data to generate combined image data. The method may comprise providing the combined image data as an input to a classifier component to identify a difference between the first image data and the second image data. An apparatus and a machine-readable medium are also disclosed.,G06K 9/68,"HEWLETT-PACKARD DEVELOPMENT COMPANY, L.P.","HAIK, Oren; PERRY, Oded; CHEN, Eli",,
WO2019234175,PCT/EP2019/064826,06.06.2019,WO/2019/234175,12.12.2019,WO,IMAGE SEGMENTATION,"In one aspect, hierarchical image segmentation is applied to an image formed of a plurality of pixels, by classifying the pixels according to a hierarchical classification scheme, in which at least some of those pixels are classified by a parent level classifier in relation to a set of parent classes, each of which is associated with a subset of child classes, and each of those pixels is also classified by at least one child level classifier in relation to one of the subsets of child classes, wherein each of the parent classes corresponds to a category of visible structure, and each of the subset of child classes associated with it corresponds to a different type of visible structure within that category.",G06K 9/00; G06K 9/62; G06K 9/46; G06N 3/04; G06N 3/08,FIVE AI LIMITED,"REDFORD, John; SAMANGOOEI, Sina",1809345.0 07.06.2018 GB,
WO2008085857,PCT/US2008/000071,04.01.2008,WO/2008/085857,17.07.2008,WO,PROCESSING TEXT WITH DOMAIN-SPECIFIC SPREADING ACTIVATION METHODS,"A method for performing natural language processing of free text using domain- specific spreading activation. Embodiments of the present invention ontologize free text using an algorithm based on neurocognitive theory by simulating human recognition, semantic, and episodic memory approaches. Embodiments of the invention may be used to process clinical text for assignment of billing codes, analyze suicide notes or legal discovery materials, and for processing other collections of text. Further, embodiments of the invention may be used to more effectively search large databases, such as a database containing a large number of medical publications.",G06F 17/27,"CHILDREN'S HOSPITAL MEDICAL CENTER; PESTIAN, John","PESTIAN, John","60/878,718 04.01.2007 US",
WO2020006275,PCT/US2019/039570,27.06.2019,WO/2020/006275,02.01.2020,WO,WEARABLE SYSTEM FOR BRAIN HEALTH MONITORING AND SEIZURE DETECTION AND PREDICTION,"The present disclosure provides for monitoring brain health and predicting and detecting seizures via a wearable device. An exemplary device includes a plurality of electrodes, a wireless communication element, and an eyeglass frame. The electrodes measure (electroencephalogram) EEG data from a human brain. The eyeglass frame houses the wireless communication element and the plurality of electrodes.",A61B 5/0478; A61B 5/0482,CORTEXXUS INC.,"ALVES, David; RAZAVI, Babak; DE JESUS ALVES, Ana Margarida","62/690,520 27.06.2018 US; 62/800,194 01.02.2019 US",
WO2019075276,PCT/US2018/055520,11.10.2018,WO/2019/075276,18.04.2019,WO,SYSTEMS AND METHODS FOR OBJECT IDENTIFICATION,"A method for identifying and tracking objects includes: capturing one or more 3-D models of one or more objects in a scene using a three-dimensional (3-D) scanning system, the one or more 3-D models including color and geometry information of the one or more objects; and computing, by an analysis agent, one or more descriptors of the one or more 3-D models, each descriptor corresponding to a fixed-length feature vector; and retrieving metadata identifying the one or more objects based on the one or more descriptors.",G06F 17/30; G06K 9/46; G06K 9/62; G06K 9/78,"AQUIFI, INC.","DAL MUTTO, Carlo; TIEU, Kinh; ZUCCARINO, Tony; TRACHEWSKY, Jason; RAFII, Abbas","62/571,209 11.10.2017 US",
WO2019032128,PCT/US2017/051968,18.09.2017,WO/2019/032128,14.02.2019,WO,METHODS AND APPARATUS TO ENHANCE EMOTIONAL INTELLIGENCE USING DIGITAL TECHNOLOGY,"Methods, systems, and apparatuses are disclosed herein that output suggestions to users based on current or upcoming inter-personal interactions. Digital technology can be used to understand situations, relationships, and context to help improve the emotional intelligence of users as they engage in such inter-personal interactions. The system can receive inputs about the current situation, environment, users, and other factors. These inputs can be used to determine emotional states of the user and other participants. Based on determined emotional states, the system can suggest one or more outputs to a user to help improve the inter-personal interaction.",G16H 50/20; G06F 17/30; G06Q 50/00,GENERAL ELECTRIC COMPANY,"DIVINE, Lucas Jason; RUSSO, Lauren A.; SHANNON, Brian; BERGMAN, Ophira; WIMMER, Megan","15/671,789 08.08.2017 US",
WO2017168125,PCT/GB2017/050825,23.03.2017,WO/2017/168125,05.10.2017,WO,SKETCH BASED SEARCH METHODS,"The overall system 1of an embodiment of the invention has three main parts: a fine-grained retrieval engine 2, a selective sketch interactive module 3 and an augmenting sketch interactive module 4. An interface 5handles communication with a user. The fine-grained retrieval engine 1 is a model trained from a database of sketches and photos. It can then be used non-interactively to retrieve photos similar to an input sketch, or interactively via one of the two interactive modules 3, 4. The interactive interface which can be of a selective type or an augmenting type.",G06F 17/30,QUEEN MARY UNIVERSITY OF LONDON,"SONG, Yi-Zhe; XIANG, Tao; HOSPEDALES, Timothy",1605481.9 31.03.2016 GB; 1613525.3 05.08.2016 GB,
WO2012000648,PCT/EP2011/003175,28.06.2011,WO/2012/000648,05.01.2012,WO,METHOD FOR CLOSED-LOOP CONTROLLING A LASER PROCESSING OPERATION AND LASER MATERIAL PROCESSING HEAD USING THE SAME,"The present invention relates to a method for closed-loop controlling a processing operation of a workpiece, comprising the steps of: (a) recording a pixel image at an initial time point of an interaction zone by means of a camera, wherein the workpiece is processed using an actuator having an initial actuator value; (b) converting the pixel image into a pixel vector; (c) representing the pixel vector by a sum of predetermined pixel mappings each multiplied by a corresponding feature value; (d) classifying the set of feature values on the basis of learned feature values into at least two classes of a group of classes comprising a first class of a too high actuator value, a second class of a sufficient actuator value and a third class of a too low actuator value at the initial time point; (e) performing a control step for adapting the actuator value by minimizing the error et between a quality indicator ye and a desired value; and (f) repeating the steps (a) to (e) for further time points to perform a closed-loop controlled processing operation.",B23K 26/00; G06T 7/00; G05B 13/00; G05B 19/408,"PRECITEC KG; PRECITEC ITM GMBH; STORK GENANNT WERSBORG, Ingo; BAUTZE, Thibault","STORK GENANNT WERSBORG, Ingo; BAUTZE, Thibault",10006692.7 28.06.2010 EP; 10012614.3 30.09.2010 EP; 10015914.4 21.12.2010 EP; 11000995.8 08.02.2011 EP; 11001371.1 18.02.2011 EP; 11004209.0 20.05.2011 EP,US-13807289; EP-2011745481
WO2019220009,PCT/FI2019/050368,10.05.2019,WO/2019/220009,21.11.2019,WO,METHODS AND APPARATUSES FOR IMPLEMENTING A HEAD TRACKING HEADSET,"Methods, apparatuses, and computer program products are provided in order to provide 3D audio playback using audio head-mounted devices. The apparatuses may be configured to receive at least one of position and orientation of a first head-mounted device in relation to a first user device, wherein the at least one of the position and orientation received is used to train a model using machine learning (602). A change in at least one of the position and orientation is detected based on input data (604). At least one signal quality parameter may be determined (606) based on the input data and a filter pair may be determined corresponding with a direction to which a spatial audio signal is rendered based at least in part on the at least one signal quality parameter and the model so as to control spatial audio signal reproduction to take effect a change in the at least one of the position and orientation of the first head-mounted device during rendering of the spatial audio signal (608).",H04S 7/00; G06F 3/01; G02B 27/00; G06N 3/02; G01S 5/02; G06N 20/00,NOKIA TECHNOLOGIES OY,"KÄRKKÄINEN, Asta; KÄRKKÄINEN, Leo; LAITINEN, Mikko-Ville","15/983,685 18.05.2018 US",
EP225510986,17785408,17.04.2017,3370188,05.09.2018,EP,"FACIAL VERIFICATION METHOD, DEVICE, AND COMPUTER STORAGE MEDIUM","Embodiments of the application provide a face verification method and device, and a computer storage medium. In the method, a moire fringe face image to be verified and an initial face image are acquired; a moire fringe removal operation is performed on the moire fringe face image by using a preset moire fringe removal model to acquire a moire fringe removed face image; characteristic extraction is performed on the moire fringe removed face image by using a preset moire fringe removed face verification model to acquire a moire fringe removed face characteristic, and characteristic extraction is performed on the initial face image by using the preset moire fringe removed face verification model to acquire an initial face characteristic; and face verification is performed on the moire fringe removed face image and the initial face image based on the moire fringe removed face characteristic and the initial face characteristic.",G06K 9/00; G06K 9/46; G06K 9/62,TENCENT TECH SHENZHEN CO LTD,WANG CHENGJIE; LI JILIN; LIANG YICONG,201610250901 21.04.2016 CN; 2017080745 17.04.2017 CN,
WO2012000650,PCT/EP2011/003177,28.06.2011,WO/2012/000650,05.01.2012,WO,A METHOD FOR CLASSIFYING A MULTITUDE OF IMAGES RECORDED BY A CAMERA OBSERVING A PROCESSING AREA AND LASER MATERIAL PROCESSING HEAD USING THE SAME,"The present invention relates to a method for classifying a multitude of images recorded by a camera observing a processing area of a workpiece processed by a processing beam, comprising the steps of: recording a first pixel image and a multitude of subsequent pixel images by the camera during a processing operation; detecting mismatches of a position and orientation of a keyhole generated by the processing beam in the workpiece within an image plane of the subsequent pixel images in comparison to the first pixel image; compensating the mismatches of the position and orientation of the respective keyholes in the subsequent pixel images with regard to the first pixel image, to produce a set of pixel images having each a normalized keyhole position and orientation; classifying the set of normalized pixel images into at least two classes by means of a classifier.",G06K 9/00; G06T 7/00; B23K 26/00; G05B 19/408,PRECITEC KG; PRECITEC ITM GMBH; INGO STORK GENANNT WERSBORG; MÜLLER-MEERKATZ Stefan,INGO STORK GENANNT WERSBORG; MÜLLER-MEERKATZ Stefan,10006692.7 28.06.2010 EP; 10012614.3 30.09.2010 EP; 10015914.4 21.12.2010 EP; 11000995.8 08.02.2011 EP; 11001371.1 18.02.2011 EP; 11004209.0 20.05.2011 EP,US-13807286; EP-2011728189
WO2019241619,PCT/US2019/037166,14.06.2019,WO/2019/241619,19.12.2019,WO,DEEP ACTIONABLE BEHAVIORAL PROFILING AND SHAPING,"Behavioral profiling and shaping is used in a ""closed-loop"" in that an interaction with at least one human is monitored and based on inferred characteristics of the interaction with that human (e.g., their behavioral profile) the interaction is guided. In one exemplary embodiment, the interaction is between two humans, for example, a ""customer"" and an ""agent"" and the interaction is monitored and the agent is guided according to the inferred behavioral profile of the customer (or optionally of the agent themselves).",G06Q 30/00; G06Q 30/02; G06F 17/27,"BEHAVIORAL SIGNAL TECHNOLOGIES, INC.","KATSAMANIS, Athanasios; NARAYANAN, Shrikanth; POTAMIANOS, Alexandros","62/684,934 14.06.2018 US",
EP241923891,18203241,30.10.2018,3480730,08.05.2019,EP,3D ANISOTROPIC HYBRID NETWORK: TRANSFERRING CONVOLUTIONAL FEATURES FROM 2D IMAGES TO 3D ANISOTROPIC VOLUMES,"A computer-implemented method for identifying features in 3D image volumes includes dividing a 3D volume into a plurality of 2D slices and applying a pre-trained 2D multi-channel global convolutional network (MC-GCN) to the plurality of 2D slices until convergence. Following convergence of the 2D MC-GCN, a plurality of parameters are extracted from a first feature encoder network in the 2D MC-GCN. The plurality of parameters are transferred to a second feature encoder network in a 3D Anisotropic Hybrid Network (AH-Net). The 3D AH-Net is applied to the 3D volume to yield a probability map;. Then, using the probability map, one or more of (a) coordinates of the objects with non-maximum suppression or (b) a label map of objects of interest in the 3D volume are generated.",G06K 9/00; G06K 9/46; G06K 9/62,SIEMENS HEALTHCARE GMBH,LIU SIQI; XU DAGUANG; ZHOU SHAOHUA KEVIN; MERTELMEIER THOMAS; WICKLEIN JULIA; JEREBKO ANNA; GRBIC SASA; PAULY OLIVIER; COMANICIU DORIN,201762580477 02.11.2017 US; 201815996719 04.06.2018 US,
EP196486982,15827413,02.03.2015,3163471,03.05.2017,EP,DATA INFORMATION TRANSACTION METHOD AND SYSTEM,"The present invention provides a data information transaction method and system. The method includes: receiving, by a server, a query request that is sent by a terminal of a data requester and carries a query condition and a user characteristic identifier of a digital human that needs to meet the query condition, where the user characteristic identifier is a characteristic category identifier obtained by classifying user characteristic information included in the digital human; determining user characteristic information that is of a digital human and corresponding to the query condition and the user characteristic identifier, obtaining a query result, and sending the query result to the terminal of the data requester; and receiving a purchase request sent by the terminal of the data requester, and completing a transaction according to the purchase request. User characteristic information is queried in a digital human according to a query condition and a user characteristic identifier, so that a query result is more accurate and query efficiency is improved; moreover, obtaining user characteristic information by means of a purchase transaction is beneficial to ensuring legal interests and information security of an actual terminal user.",G06F 17/30; G06F 21/62; G06Q 30/06,HUAWEI TECH CO LTD,LI YINGTAO; QIAN LI,201410378087 01.08.2014 CN; 2015073494 02.03.2015 CN,
WO2017180661,PCT/US2017/027065,11.04.2017,WO/2017/180661,19.10.2017,WO,URINATION PREDICTION AND MONITORING,"A system for predicting and detecting urination events of users is disclosed. The system can include any number of wearable devices, mobile devices, hubs, computing devices, and servers to collect, share, process, and interpret data, as well as to provide stimuli to users and caregivers. Biometric and/or environmental data associated with a user can be collected and applied to a urination model to determine a predicted urination time. The user or a caregiver can be provided with direct or environmental stimuli conveying information about predicted urination times. Ongoing biometric and/or environmental data collection can be used to identify, and provide stimuli warning of, imminent urination events. Voluntary and involuntary feedback of actual urination events, as well as continued biometric and/or environmental data collection, can be used to train individual and collective urination models.",A61B 5/20,"GOGO BAND, INC.","FRANCO, Israel; ZYGLOWICZ, Steven; BAKER, Tim; COBLE, Jon","62/321,690 12.04.2016 US; 62/365,714 22.07.2016 US",CN-201780036246.6; JP-2018554491; CA-3020748; AU-2017249318; EP-2017783007
WO2017070126,PCT/US2016/057560,18.10.2016,WO/2017/070126,27.04.2017,WO,OPTIMIZED ROUTING OF INTERACTIONS TO CONTACT CENTER AGENTS BASED ON MACHINE LEARNING,"A system that is adapted to route interactions to contact center agents. More specifically, the system is adapted to identify an interaction to be routed, and identify a group of agents based on one or more constraints for generating one or more candidate agents. The system is also adapted to gather context data surrounding the candidate agents. For each agent of the candidate agents, the system is adapted to estimate an expected value to be obtained by routing the interaction to the agent. The system is further adapted to select a particular agent of the candidate agents based on the estimates, and signal a routing device for routing the interaction to the particular agent.",H04L 29/08; G06N 99/00,"GREENEDEN U.S. HOLDINGS II, LLC","MCGANN, Conor; ARAVAMUDHAN, Bharath; MAKAGON, Petr; RISTOCK, Herbert Willi Artur; KONIG, Yochai; DUCLOS, Gregory; ZHAKOV, Vyacheslav; PELEMIS, Damjan","14/887,297 19.10.2015 US; 14/887,276 19.10.2015 US; 14/887,318 19.10.2015 US; 14/887,310 19.10.2015 US",KR-1020187013906; EP-2016858080; CA-3009944; AU-2016341201
WO2019070588,PCT/US2018/053766,01.10.2018,WO/2019/070588,11.04.2019,WO,IDENTIFYING THE MUSIC AS A PARTICULAR SONG,"In general, the subject matter described in this disclosure can be embodied in methods, systems, and program products for indicating a reference song. A computing device stores reference song characterization data that identifies a plurality of audio characteristics for each reference song in a plurality of reference songs. The computing device receives digital audio data that represents audio recorded by a microphone, converts the digital audio data from time-domain format into frequency-domain format, and uses the digital audio data in the frequency-domain format in a music-characterization process. In response to determining that characterization values for the digital audio data are most relevant to characterization values for a particular reference song, the computing device outputs an indication of the particular reference song.",G06F 17/30; G06F 16/683,GOOGLE LLC,"ROBLEK, Dominik; AGUERA-ARCAS, Blaise; HUME, Tom; RITTER, Marvin; BARBELLO, Brandon; KILGOUR, Kevin; VELIMIROVIC, Mihajlo; THORNTON, Christopher Walter George; TAUBMAN, Gabriel; LYON, James David; ALTHAUS, Jan; NALIUKA, Katsiaryna; ODELL, Julian; SHARIFI, Matthew; GFELLER, Beat","62/567,755 03.10.2017 US",CN-201880031926.3
WO2019229768,PCT/IN2019/050414,28.05.2019,WO/2019/229768,05.12.2019,WO,A BOT ENGINE FOR AUTOMATIC DYNAMIC INTENT COMPUTATION,"A method for communicating with a bot engine with automatic dynamic intent computation, said method comprising: parsing (301) input text / data; identifying word embeddings (302) and character embeddings (303); obtaining a concatenated embeddings' matrix; obtaining a focus-weighted embeddings' matrix, attribute-weighted embeddings' matrix, named-entity-relationship-weighted embeddings' matrix, common-sense weighted embeddings' matrix; feeding a Bidirectional Long-Short Term Memory (310) to provide a first set of intents being a matrix of intents comprising weight-assigned intent vectors; determining an attention vector; multiplying (312) said intent vectors, with attention vector to obtain a second intent vector; outputting (316) an intent-based network of nodes, comprising channel paths to correspond with bot engine, said intent-based network of nodes being dynamically computed pertinent output per every parsed (301) input text / data for facilitating full-duplex, intent-based, communication channel between a natural user and a bot engine based on said second intent.",G06F 9/44,"THOTTAPILLY, Sanjeev; SAMUEL, Animesh","THOTTAPILLY, Sanjeev; SAMUEL, Animesh",201821019826 28.05.2018 IN,
WO2015149696,PCT/CN2015/075639,01.04.2015,WO/2015/149696,08.10.2015,WO,METHOD AND SYSTEM FOR EXTRACTING CHARACTERISTIC OF THREE-DIMENSIONAL FACE IMAGE,"A method for extracting a characteristic of a three-dimensional face image includes: performing face area division, to obtain a group of face areas; projecting each face area onto a corresponding regional bounding sphere; obtaining an indication of the corresponding face area according to the regional bounding sphere, and recording the indication as a regional bounding spherical descriptor of the face area; calculating a weight of the regional bounding spherical descriptor of the face area for each face area; and obtaining a characteristic of a three-dimensional face image according to the indication of the face area and the corresponding weight.",G06K 9/00,TENCENT TECHNOLOGY (SHENZHEN) COMPANY LIMITED,"MING, Yue; JIANG, Jie; LIU, Tingting; WANG, Juhong",201410133560.4 03.04.2014 CN,
WO2018211927,PCT/JP2018/016703,25.04.2018,WO/2018/211927,22.11.2018,WO,"CONTROL APPARATUS, CONTROL PROGRAM, LEARNING DATA CREATION METHOD, AND LEARNING METHOD","Provided is a technology for ensuring that, even when conflict arises between a plurality of controls, control target apparatuses do not become inoperative. A control apparatus according to one aspect of the present invention includes a first control processing unit configured to control operation of a first control target apparatus, based on a control value output from a trained first learning machine that has performed learning for controlling operation of the first control target apparatus, a second control processing unit configured to control operation of a second control target apparatus, based on a control value output from a trained second learning machine that has performed learning for controlling operation of the second control target apparatus, and a conflict resolution unit configured to, when control of the first control target apparatus based on the control value output from the first learning machine conflicts with control of the second control target apparatus based on the control value output from the second learning machine, resolve the conflict by correcting control of the first and second control target apparatuses.",G06N 3/04,OMRON CORPORATION,"ANDO, Tanichi",2017-096165 15.05.2017 JP,
EP275492905,17884719,22.12.2017,3561490,30.10.2019,EP,DATA CREATION METHOD AND DATA USE METHOD,"Provided is a data creation method which includes: an autofluorescence data generation step for generating autofluorescence data that includes intensity data and/or spectrum data of autofluorescence light, by disposing the focal point of light of a prescribed wavelength at a single set of coordinates on a prescribed focal plane, irradiating a sample positioned at the coordinates with excitation light comprising light, and thereby acquiring autofluorescence light originating from the sample; a reflected light data generation step for generating intensity data of reflected light by acquiring reflected light dispersed by the sample by irradiating the single set of coordinates on the prescribed focal plane with irradiation light; and a correspondence data generation step for creating correspondence data in which the autofluorescence data at the single set of coordinates on the prescribed focal plane and the reflected light data are associated.",G01N 21/64; C12Q 1/68; G01N 33/50,UNIV TSUKUBA,NOMURA NOBUHIKO; YAWATA YUTAKA; KIYOKAWA TATSUNORI,2016249896 22.12.2016 JP; 2017047414 22.12.2017 JP,
WO2016096743,PCT/EP2015/079619,14.12.2015,WO/2016/096743,23.06.2016,WO,BRAIN ACTIVITY PREDICTION,"A method for estimating a brain activity response following a stimulus of a person comprises the steps: providing a usage data set of the person from a personal device used by said person, wherein at least one usage attribute is associated to said usage data set, wherein attribute data is associated to each of the at least one usage attribute, providing a computational inference model, generated from a plurality of brain activity data sets and a plurality of usage data sets, wherein each brain activity data set comprises data derived from a brain activity response following a sensory stimulus, submitting the attribute data of each of the at least one usage attributes to said computational inference model, estimating a brain activity response following a sensory stimulus of said person by evaluating said computational inference model for the submitted attribute data. The method is useful to determine, for example the influence of intensive touch pad usage (of a smartphone) on somatosensory evoked potentials.",A61B 5/0484; A61B 5/00,UNIVERSITÄT ZÜRICH; UNIVERSITY OF FRIBOURG,"GHOSH, Arko; ROUILLIER, Eric; CHYTIRIS, Magali; BALERNA, Myriam; GINDRAT, Anne-Dominique",14197841.1 14.12.2014 EP,US-15535535
WO2019067641,PCT/US2018/052988,26.09.2018,WO/2019/067641,04.04.2019,WO,SYSTEMS AND METHODS FOR VISUAL INSPECTION BASED ON AUGMENTED REALITY,"A system for visual inspection includes: a scanning system configured to capture images of an object and to compute a three-dimensional (3-D) model of the object based on the captured images; an inspection system configured to: compute a descriptor of the object based on the 3-D model of the object; retrieve metadata corresponding to the object based on the descriptor; and compute a plurality of inspection results based on the retrieved metadata and the 3-D model of the object; and a display device system including: a display; a processor; and a memory storing instructions that, when executed by the processor, cause the processor to: generate overlay data from the inspection results; and show the overlay data on the display, the overlay data being aligned with a view of the object through the display.",G06F 3/01; G06F 17/30; G06F 17/50; H04N 13/117; G01N 21/95; G01N 23/02; G01N 27/90,"AQUIFI, INC.","DAL MUTTO, Carlo; TRACHEWSKY, Jason; ZUCCARINO, Tony","62/563,560 26.09.2017 US",
WO2018107181,PCT/US2017/065654,11.12.2017,WO/2018/107181,14.06.2018,WO,METHODS AND SYSTEMS FOR DIAGNOSIS OF POST-TRAUMATIC STRESS DISORDER,"The present invention relates to a method of detecting PTSD in a subject comprising measurement and analysis of brain wave patterns from a subject and determination of a value for one or more neuromarkers from the brain wave pattern. The present invention additionally relates to a system that can be used to diagnose the presence or severity of PTSD in a subject, and to a computer program product for detecting PTSD in a subject by determining if the value of the one or more neuromarkers is above a designated threshold, or is increased or decreased relative to a control value. The invention can also be used to track recovery during and following PTSD therapy, and also as a means for predicting response to therapy and the potential for relapse.",A61B 5/00; A61B 5/08; A61B 5/16; A61B 5/0478; A61N 2/00,THE UNITED STATES OF AMERICA AS REPRESENTED BY THE DEPARTMENT OF VETERANS AFFAIRS,"MODARRES, Mo","62/432,526 09.12.2016 US",
