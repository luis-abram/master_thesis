Time:,21.04.2020 00:05:26,...3,...4,...5,...6,...7,...8,...9,...10,...11,...12,...13
Query:,AIfunctionalapplicationsComputerVisionSceneUnderstandingAndVisionForRobotics,,,,,,,,,,,
Offices:,"EP,WO",,,,,,,,,,,
SortBy:,Relevance,,,,,,,,,,,
,,,,,,,,,,,,
Application Id,Application Number,Application Date,Publication Number,Publication Date,Country,Title,Abstract,I P C,Applicants,Inventors,Priorities Data,National Phase Entries
WO2019126323,PCT/US2018/066501,19.12.2018,WO/2019/126323,27.06.2019,WO,ROBOT INTERACTION WITH OBJECTS BASED ON SEMANTIC INFORMATION ASSOCIATED WITH EMBEDDING SPACES,"Techniques described herein relate to using reduced-dimensionality embeddings generated from robot sensor data to identify predetermined semantic labels that guide robot interaction with objects. In various implementations, obtaining, from one or more sensors of a robot, sensor data that includes data indicative of an object observed in an environment in which the robot operates. The sensor data may be processed utilizing a first trained machine learning model to generate a first embedded feature vector that maps the data indicative of the object to an embedding space. Nearest neighbor(s) of the first embedded feature vector may be identified in the embedding space. Semantic label(s) may be identified based on the nearest neighbor(s). A given grasp option may be selected from enumerated grasp options previously associated with the semantic label(s). The robot may be operated to interact with the object based on the pose and using the given grasp option.",B25J 9/16,X DEVELOPMENT LLC,"NAGARAJAN, Umashankar","15/851,622 21.12.2017 US",
WO2020069379,PCT/US2019/053554,27.09.2019,WO/2020/069379,02.04.2020,WO,TRAINING A DEEP NEURAL NETWORK MODEL TO GENERATE RICH OBJECT-CENTRIC EMBEDDINGS OF ROBOTIC VISION DATA,"Training a machine learning model (e.g., a neural network model such as a convolutional neural network (CNN) model) so that, when trained, the model can be utilized in processing vision data (e.g., from a vision component of a robot), that captures an object, to generate a rich object-centric embedding for the vision data. The generated embedding can enable differentiation of even subtle variations of attributes of the object captured by the vision data.",G06K 9/00; G06K 9/62; G06K 9/72,GOOGLE LLC,"PIRK, Soeren; BAI, Yunfei; SERMANET, Pierre; KHANSARI ZADEH, Seyed Mohammad; LYNCH, Harrison","62/737,794 27.09.2018 US",
WO2019113074,PCT/US2018/063851,04.12.2018,WO/2019/113074,13.06.2019,WO,LEARNING AND APPLYING EMPIRICAL KNOWLEDGE OF ENVIRONMENTS BY ROBOTS,"Techniques described herein relate to generating a posteriori knowledge about where objects are typically located within environments to improve object location. In various implementations, output from vision sensor(s) of a robot may include visual frame(s) that capture at least a portion of an environment in which a robot operates/will operate. The visual frame(s) may be applied as input across a machine learning model to generate output that identifies potential location(s) of an object of interest. The robot's position/pose may be altered based on the output to relocate one or more of the vision sensors. One or more subsequent visual frames that capture at least a not-previously-captured portion of the environment may be applied as input across the machine learning model to generate subsequent output identifying the object of interest. The robot may perform task(s) that relate to the object of interest.",B25J 9/16; G05B 13/02; G06N 3/02; G06N 3/08,X DEVELOPMENT LLC,"GREENBERG, Alexa","15/832,705 05.12.2017 US",
WO2019241680,PCT/US2019/037264,14.06.2019,WO/2019/241680,19.12.2019,WO,DEEP REINFORCEMENT LEARNING FOR ROBOTIC MANIPULATION,"Using large-scale reinforcement learning to train a policy model that can be utilized by a robot in performing a robotic task in which the robot interacts with one or more environmental objects. In various implementations, off-policy deep reinforcement learning is used to train the policy model, and the off-policy deep reinforcement learning is based on self-supervised data collection. The policy model can be a neural network model. Implementations of the reinforcement learning utilized in training the neural network model utilize a continuous-action variant of Q-learning. Through techniques disclosed herein, implementations can learn policies that generalize effectively to previously unseen objects, previously unseen environments, etc.",B25J 9/16,GOOGLE LLC,"KALASHNIKOV, Dmitry; IRPAN, Alexander; PASTOR SAMPEDRO, Peter; IBARZ, Julian; HERZOG, Alexander; JANG, Eric; QUILLEN, Deirdre; HOLLY, Ethan; LEVINE, Sergey","62/685,838 15.06.2018 US",
WO2019055848,PCT/US2018/051175,14.09.2018,WO/2019/055848,21.03.2019,WO,MACHINE LEARNING METHODS AND APPARATUS FOR ROBOTIC MANIPULATION AND THAT UTILIZE MULTI-TASK DOMAIN ADAPTATION,"Training a machine learning model that, once trained, is used in performance of robotic grasping and/or other manipulation task(s) by a robot. The model can be trained using simulated training examples that are based on simulated data that is based on simulated robot(s) attempting simulated manipulations of various simulated objects. At least portions of the model can also be trained based on real training examples that are based on data from real-world physical robots attempting manipulations of various objects. The simulated training examples can be utilized to train the model to predict an output that can be utilized in a particular task – and the real training examples used to adapt at least a portion of the model to the real-world domain can be tailored to a distinct task. In some implementations, domain-adversarial similarity losses are determined during training, and utilized to regularize at least portion(s) of the model.",B25J 9/16,X DEVELOPMENT LLC,"BAI, Yunfei; FANG, Kuan; HINTERSTOISSER, Stefan; KALAKRISHNAN, Mrinal","62/559,279 15.09.2017 US; 15/913,212 06.03.2018 US",EP-2018779999
WO2019183568,PCT/US2019/023714,22.03.2019,WO/2019/183568,26.09.2019,WO,CONTROLLING A ROBOT BASED ON FREE-FORM NATURAL LANGUAGE INPUT,"Implementations relate to using deep reinforcement learning to train a model that can be utilized, at each of a plurality of time steps, to determine a corresponding robotic action for completing a robotic task. Implementations additionally or alternatively relate to utilization of such a model in controlling a robot. The robotic action determined at a given time step utilizing such a model can be based on: current sensor data associated with the robot for the given time step, and free-form natural language input provided by a user. The free-form natural language input can direct the robot to accomplish a particular task, optionally with reference to one or more intermediary steps for accomplishing the particular task. For example, the free-form natural language input can direct the robot to navigate to a particular landmark, with reference to one or more intermediary landmarks to be encountered in navigating to the particular landmark.",G06N 3/00; G06F 17/27; G06N 3/04,GOOGLE LLC,"SHAH, Pararth; HAKKANI-TUR, Dilek; KEW, Juliana; FISER, Marek; FAUST, Aleksandra","62/647,425 23.03.2018 US",
WO2020069517,PCT/US2019/053857,30.09.2019,WO/2020/069517,02.04.2020,WO,INTELLIGENT TRANSPORTATION SYSTEMS,"Transportation systems have artificial intelligence including neural networks for recognition and classification of objects and behavior including natural language processing and computer vision systems. The transportation systems involve sets of complex chemical processes, mechanical systems, and interactions with behaviors of operators. System-level interactions and behaviors are classified, predicted and optimized using neural networks and other artificial intelligence systems through selective deployment, as well as hybrids and combinations of the artificial intelligence systems, neural networks, expert systems, cognitive systems, genetic algorithms and deep learning.",B60W 30/14,"STRONG FORCE INTELLECTUAL CAPITAL, LLC","CELLA, Charles","62/739,335 30.09.2018 US",
WO2019133081,PCT/US2018/050868,13.09.2018,WO/2019/133081,04.07.2019,WO,SHARING LEARNED INFORMATION AMONG ROBOTS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for sharing learned information among robots. In some implementations, a robot obtains sensor data indicating characteristics of an object. The robot determines a classification for the object and generates an embedding for the object using a machine learning model stored by the robot. The robot stores the generated embedding and data indicating the classification for the object. The robot sends the generated embedding and the data indicating the classification to a server system. The robot receives, from the server system, an embedding generated by a second robot and a corresponding classification. The robot stores the received embedding and the corresponding classification in the local cache of the robot. The robot may then use the information in the cache to identify objects.",B25J 9/00; B25J 9/16,X DEVELOPMENT LLC,"RAJKUMAR, Nareshkumar; LEGER, Patrick; HUDSON, Nicolas; SHANKAR, Krishna; HESSMER, Rainer","15/855,329 27.12.2017 US",
WO2020023518,PCT/US2019/043051,23.07.2019,WO/2020/023518,30.01.2020,WO,A METHOD OF REAL TIME VEHICLE RECOGNITION WITH NEUROMORPHIC COMPUTING NETWORK FOR AUTONOMOUS DRIVING,"Described is a system for online vehicle recognition in an autonomous driving environment. Using a learning network comprising an unsupervised learning component and a supervised learning component, images of moving vehicles extracted from videos captured in the autonomous driving environment are learned and classified. Vehicle feature data is extracted from input moving vehicle images. The extracted vehicle feature data is clustered into different vehicle classes using the unsupervised learning component. Vehicle class labels for the different vehicle classes are generated using the supervised learning component. Based on a vehicle class label for a moving vehicle in the autonomous driving environment, the system selects an action to be performed by the autonomous vehicle, and causes the selected action to be performed by the autonomous vehicle in the autonomous driving environment.",B60W 30/14; B60W 40/02; G06N 3/08,"HRL LABORATORIES, LLC","JIANG, Qin; CHO, Youngkwan; STEPP, Nigel D.; SKORHEIM, Steven W.; DE SAPIO, Vincent; PILLY, Praveen K.; RUGGERO, Scorcioni","62/702,042 23.07.2018 US",
WO2019006091,PCT/US2018/039947,28.06.2018,WO/2019/006091,03.01.2019,WO,MACHINE LEARNING METHODS AND APPARATUS FOR SEMANTIC ROBOTIC GRASPING,"Deep machine learning methods and apparatus related to semantic robotic grasping are provided. Some implementations relate to training a training a grasp neural network, a semantic neural network, and a joint neural network of a semantic grasping model. In some of those implementations, the joint network is a deep neural network and can be trained based on both: grasp losses generated based on grasp predictions generated over a grasp neural network, and semantic losses generated based on semantic predictions generated over the semantic neural network. Some implementations are directed to utilization of the trained semantic grasping model to servo, or control, a grasping end effector of a robot to achieve a successful grasp of an object having desired semantic feature(s).",B25J 9/16; G06N 3/04; G06N 3/08,GOOGLE LLC,"JANG, Eric; VIJAYANARASIMHAN, Sudheendra; PASTOR SAMPEDRO, Peter; IBARZ, Julian; LEVINE, Sergey","62/526,211 28.06.2017 US",EP-2018743264; CN-201880039073.8
WO2019099305,PCT/US2018/060158,09.11.2018,WO/2019/099305,23.05.2019,WO,META-LEARNING FOR MULTI-TASK LEARNING FOR NEURAL NETWORKS,"Methods and systems for meta-learning are described for automating learning of child tasks with a single neural network. The order in which tasks are learned by the neural network can affect performance of the network, and the meta-learning approach can use a task-level curriculum for multi-task training. The task-level curriculum can be learned by monitoring a trajectory of loss functions during training. The meta-learning approach can learn to adapt task loss balancing weights in the course of training to get improved performance on multiple tasks on real world datasets. Advantageously, learning to dynamically balance weights among different task losses can lead to superior performance over the use of static weights determined by expensive random searches or heuristics. Embodiments of the meta-learning approach can be used for computer vision tasks or natural language processing tasks, and the trained neural networks can be used by augmented or virtual reality devices.",G06N 3/02; G06N 20/00,"MAGIC LEAP, INC.","RABINOVICH, Andrew; BADRINARAYANAN, Vijay; RAJENDRAN, Srivignesh; LEE, Chen-Yu","62/586,154 14.11.2017 US",
WO2019060632,PCT/US2018/052078,20.09.2018,WO/2019/060632,28.03.2019,WO,OPTIMIZING POLICY CONTROLLERS FOR ROBOTIC AGENTS USING IMAGE EMBEDDINGS,"There are provided systems, methods, and apparatus, for optimizing a policy controller to control a robotic agent that interacts with an environment to perform a robotic task. One of the methods includes optimizing the policy controller using a neural network that generates numeric embeddings of images of the environment and a demonstration sequence of demonstration images of another agent performing a version of the robotic task.",G06N 3/00; G06N 3/04; G06N 3/08,GOOGLE LLC,"CHEBOTAR, Yevgen; SERMANET, Pierre; LYNCH, Harrison","62/561,133 20.09.2017 US",EP-2018783292; CN-201880038469.0
EP232545771,18382345,21.05.2018,3396598,31.10.2018,EP,METHOD AND USER INTERFACE FOR MANAGING AND CONTROLLING POWER IN MODULAR ROBOTS AND APPARATUS THEREFOR,"A method for managing the power consumption of a modular robot is disclosed, being the overall power consumption of the robot the result of the individual power consumption of all its components following from certain power routines and inference techniques; a method that allows for an automatic inference and instant determination of the overall power consumption required by a modular robot is provided, such method also extended to the determination of the power consumption of a modular robot over a period of time; a method for training the behavior of a modular robot in a power-conscious manner according to a power inference source and a desired power consumption or a desired energy profile, using for that purpose Reinforcement and Imitation Learning techniques, is also disclosed; a method for monitoring and controlling the power consumption of the modular robot through a user interface conceived to that end is likewise disclosed; lastly, the robot apparatus therefor, a modular robot whose components own the electronics needed for the deployment of the disclosed method, is provided.",G06N 3/00; B25J 9/08; B25J 9/16; G05B 19/00; G06F 17/50; G06N 99/00,ERLE ROBOTICS S L,MAYORAL VILCHES VÍCTOR; MUÑIZ ROSAS ADAY; BILBAO CALVO ASIER; MUGURUZA GOENAGA IÑIGO; ZAMALLOA UGARTE IRATI,18382345 21.05.2018 EP,
WO2019113067,PCT/US2018/063843,04.12.2018,WO/2019/113067,13.06.2019,WO,VIEWPOINT INVARIANT VISUAL SERVOING OF ROBOT END EFFECTOR USING RECURRENT NEURAL NETWORK,"Training and/or using a recurrent neural network model for visual servoing of an end effector of a robot. In visual servoing, the model can be utilized to generate, at each of a plurality of time steps, an action prediction that represents a prediction of how the end effector should be moved to cause the end effector to move toward a target object. The model can be viewpoint invariant in that it can be utilized across a variety of robots having vision components at a variety of viewpoints and/or can be utilized for a single robot even when a viewpoint, of a vision component of the robot, is drastically altered. Moreover, the model can be trained based on a large quantity of simulated data that is based on simulator(s) performing simulated episode(s) in view of the model. One or more portions of the model can be further trained based on a relatively smaller quantity of real training data.",B25J 9/16; G05B 13/02; G06N 3/08,GOOGLE LLC,"TOSHEV, Alexander; SADEGHI, Fereshteh; LEVINE, Sergey","62/595,037 05.12.2017 US",EP-2018821946; CN-201880040068.9
WO2016097758,PCT/GB2015/054076,18.12.2015,WO/2016/097758,23.06.2016,WO,SENSOR NOISE PROFILE,"The invention relates to feature extraction technique based on edge extraction. It can be used in computer vision systems, including image/facial/object recognition systems, scene interpretation, classification and captioning systems. A model or profile of the noise in the sensor is used to improve feature extraction or object detection on an image from a sensor.",G06K 9/00; G06K 9/40; G06T 5/00,APICAL LIMITED,"ROMANENKO, Ilya",1422787.0 19.12.2014 GB,
WO2017151926,PCT/US2017/020455,02.03.2017,WO/2017/151926,08.09.2017,WO,DEEP MACHINE LEARNING METHODS AND APPARATUS FOR ROBOTIC GRASPING,Deep machine learning methods and apparatus related to manipulation of an object by an end effector of a robot. Some implementations relate to training a semantic grasping model to predict a measure that indicates whether motion data for an end effector of a robot will result in a successful grasp of an object; and to predict an additional measure that indicates whether the object has desired semantic feature(s). Some implementations are directed to utilization of the trained semantic grasping model to servo a grasping end effector of a robot to achieve a successful grasp of an object having desired semantic feature(s).,G06N 3/04; G05B 13/00; G05B 13/02; G06N 3/08,GOOGLE LLC,"VIJAYANARASIMHAN, Sudheendra; JANG, Eric; PASTOR SAMPEDRO, Peter; LEVINE, Sergey","62/303,139 03.03.2016 US; 62/422,549 15.11.2016 US; 15/448,013 02.03.2017 US",KR-1020187027695; EP-2017711906; JP-2018545896
WO2017151206,PCT/US2016/066393,13.12.2016,WO/2017/151206,08.09.2017,WO,DEEP MACHINE LEARNING METHODS AND APPARATUS FOR ROBOTIC GRASPING,"Deep machine learning methods and apparatus related to manipulation of an object by an end effector of a robot. Some implementations relate to training a deep neural network to predict a measure that candidate motion data for an end effector of a robot will result in a successful grasp of one or more objects by the end effector. Some implementations are directed to utilization of the trained deep neural network to servo a grasping end effector of a robot to achieve a successful grasp of an object by the grasping end effector. For example, the trained deep neural network may be utilized in the iterative updating of motion control commands for one or more actuators of a robot that control the pose of a grasping end effector of the robot, and to determine when to generate grasping control commands to effectuate an attempted grasp by the grasping end effector.",G06N 3/04; G05B 13/00; G05B 13/02; G06N 3/08,GOOGLE LLC,"LEVINE, Sergey; PASTOR SAMPEDRO, Peter; KRIZHEVSKY, Alex","62/303,139 03.03.2016 US; 15/377,280 13.12.2016 US",CN-201680083745.6; MX-MX/a/2018/010589; KR-1020197026856; CA-3016418; KR-1020187028530; JP-2018545901; EP-2016822854
WO2020033898,PCT/US2019/046011,09.08.2019,WO/2020/033898,13.02.2020,WO,"SYSTEMS AND METHODS FOR PROVIDING FLEXIBLE, MULTI-CAPACITY MODELS FOR USE OF DEEP NEURAL NETWORKS IN MOBILE DEVICES","Systems and methods are disclosed which allow mobile devices, and other resource constrained applications, to more efficiently and effectively utilize deep learning neural networks using only (or primarily) local resources. These systems and methods take the dynamics of runtime resources into account to enable resource-aware, multi-tenant on-device deep learning for artificial intelligence functions for use in tasks like mobile vision systems. The multi-capacity framework enables deep learning models to offer flexible resource-accuracy trade-offs and other similar balancing of performance and resources consumed. At runtime, various systems disclosed herein may dynamically select the optimal resource-accuracy trade-off for each deep learning model to fit the model's resource demand to the system's available runtime resources and the needs of the task being performed by the model. In doing so, systems and methods disclosed herein can efficiently utilize the limited resources in mobile systems to maximize performance of multiple concurrently running neural network-based applications.",G06F 13/28; G06N 3/04; G06N 3/08; G06N 7/02; G16H 50/20; G16H 50/50; G16H 50/70,BOARD OF TRUSTEES OF MICHIGAN STATE UNIVERSITY,"ZHANG, Mi; FANG, Biyi; ZENG, Xiao","62/716,812 09.08.2018 US",
WO2019182974,PCT/US2019/022753,18.03.2019,WO/2019/182974,26.09.2019,WO,STEREO DEPTH ESTIMATION USING DEEP NEURAL NETWORKS,"Various examples of the present disclosure include a stereoscopic deep neural network (DNN) that produces accurate and reliable results in real-time. Both LIDAR data (supervised training) and photometric error (unsupervised training) may be used to train the DNN in a semi-supervised manner. The stereoscopic DNN may use an exponential linear unit (ELU) activation function to increase processing speeds, as well as a machine learned argmax function that may include a plurality of convolutional layers having trainable parameters to account for context. The stereoscopic DNN may further include layers having an encoder/decoder architecture, where the encoder portion of the layers may include a combination of three-dimensional convolutional layers followed by two-dimensional convolutional layers.",G06N 3/04; G06N 3/063; G06N 3/08; G01S 17/02; G06T 7/593,NVIDIA CORPORATION,"SMOLYANSKIY, Nikolai; KAMENEV, Alexey; BIRCHFIELD, Stan","62/646,148 21.03.2018 US; 16/356,439 18.03.2019 US",
EP242162263,17200577,08.11.2017,3483794,15.05.2019,EP,CLOUD-BASED STORAGE FOR HETEROGENEOUS CLOUD ROBOTICS,"Methods and apparatus, including computer program products, are provided for cloud-based storage for heterogeneous robots. In some example embodiments, there may be provided a method that includes receiving, by a cloud server including a machine learning model in a training phase, training data; storing, by the cloud server, a configuration of the machine learning model; receiving, by the cloud server including the trained machine learning model in an operations phase, a request, from at least one apparatus, for the model training data; creating, by the trained machine learning model in the operations phase, the model training data; and providing, by the cloud server including the trained machine learning model in the operations phase, the response including the model training data to the at least one apparatus. Related systems, methods, and articles of manufacture are also described.",G06N 3/08; G06N 99/00,NOKIA TECHNOLOGIES OY,JORDAN SANDOR; NEMES CSABA,17200577 08.11.2017 EP,
WO2019010137,PCT/US2018/040644,02.07.2018,WO/2019/010137,10.01.2019,WO,UPDATE OF LOCAL FEATURES MODEL BASED ON CORRECTION TO ROBOT ACTION,"Methods, apparatus, and computer-readable media for determining and utilizing corrections to robot actions. Some implementations are directed to updating a local features model of a robot in response to determining a human correction of an action performed by the robot. The local features model is used to determine, based on an embedding generated over a corresponding neural network model, one or more features that are most similar to the generated embedding. Updating the local features model in response to a human correction can include updating a feature embedding, of the local features model, that corresponds to the human correction. Adjustment(s) to the features model can immediately improve robot performance without necessitating retraining of the corresponding neural network model.",G06N 3/00; G06K 9/62; G06N 3/08,X DEVELOPMENT LLC,"SHANKAR, Krishna; HUDSON, Nicolas; TOSHEV, Alexander","15/640,936 03.07.2017 US",EP-2018743369; KR-1020197038773
WO2020056299,PCT/US2019/051065,13.09.2019,WO/2020/056299,19.03.2020,WO,DEEP REINFORCEMENT LEARNING-BASED TECHNIQUES FOR END TO END ROBOT NAVIGATION,"Using reinforcement learning to train a policy network that can be utilized, for example, by a robot in performing robot navigation and/or other robotic tasks. Various implementations relate to techniques for automatically learning a reward function for training of a policy network through reinforcement learning, and automatically learning a neural network architecture for the policy network.",G06N 3/04; G06N 3/00; G06N 3/08,GOOGLE LLC,"FAUST, Aleksandra; CHIANG, Hao-tien; FRANCIS, Anthony; FISER, Marek","62/731,788 14.09.2018 US",
WO2018112514,PCT/AU2017/051388,14.12.2017,WO/2018/112514,28.06.2018,WO,DEEP LEARNING SYSTEMS AND METHODS FOR USE IN COMPUTER VISION,"A method and system for generating a compressed machine learning model is provided. The method includes providing a first set of training images to a first machine learning model to generate a first set of outputs; providing a second set of training images to a second machine learning model to generate a second set of outputs, wherein the second set of training images corresponds to the first set of training images at a lower resolution; and updating the second machine learning model according to a difference between the first and second sets of outputs to generate the compressed machine learning model.",G06N 3/08; G06T 1/20,QUEENSLAND UNIVERSITY OF TECHNOLOGY,"MCCOOL, Chris",2016905352 23.12.2016 AU,
WO2017201023,PCT/US2017/032865,16.05.2017,WO/2017/201023,23.11.2017,WO,MACHINE LEARNING METHODS AND APPARATUS RELATED TO PREDICTING MOTION(S) OF OBJECT(S) IN A ROBOT'S ENVIRONMENT BASED ON IMAGE(S) CAPTURING THE OBJECT(S) AND BASED ON PARAMETER(S) FOR FUTURE ROBOT MOVEMENT IN THE ENVIRONMENT,"Some implementations of this specification are directed generally to deep machine learning methods and apparatus related to predicting motion(s) (if any) that will occur to object(s) in an environment of a robot in response to particular movement of the robot in the environment. Some implementations are directed to training a deep neural network model to predict at least one transformation (if any), of an image of a robot's environment, that will occur as a result of implementing at least a portion of a particular movement of the robot in the environment. The trained deep neural network model may predict the transformation based on input that includes the image and a group of robot movement parameters that define the portion of the particular movement.",B25J 9/16; G05B 13/02,GOOGLE LLC,"LEVINE, Sergey; FINN, Chelsea; GOODFELLOW, Ian","62/339,734 20.05.2016 US; 15/596,103 16.05.2017 US",CN-201780031172.7; JP-2018559945; KR-1020197013816; EP-2017727043; KR-1020187035430
WO2018053187,PCT/US2017/051646,14.09.2017,WO/2018/053187,22.03.2018,WO,DEEP REINFORCEMENT LEARNING FOR ROBOTIC MANIPULATION,"Implementations utilize deep reinforcement learning to train a policy neural network that parameterizes a policy for determining a robotic action based on a current state. Some of those implementations collect experience data from multiple robots that operate simultaneously. Each robot generates instances of experience data during iterative performance of episodes that are each explorations of performing a task, and that are each guided based on the policy network and the current policy parameters for the policy network during the episode. The collected experience data is generated during the episodes and is used to train the policy network by iteratively updating policy parameters of the policy network based on a batch of collected experience data. Further, prior to performance of each of a plurality of episodes performed by the robots, the current updated policy parameters can be provided (or retrieved) for utilization in performance of the episode.",B25J 9/16; G05B 13/02; G06N 3/08; G06N 3/00; G06N 3/04,GOOGLE LLC,"LEVINE, Sergey; HOLLY, Ethan; GU, Shixiang; LILLICRAP, Timothy","62/395,340 15.09.2016 US",CN-201780067067.9; KR-1020197009013; JP-2019514301; EP-2017772579
WO2020056060,PCT/US2019/050697,11.09.2019,WO/2020/056060,19.03.2020,WO,MULTI-STAGE MACHINE-LEARNING MODELS TO CONTROL PATH-DEPENDENT PROCESSES,"Provided is a process, including: obtaining a first training dataset of subject-entity records; training a first machine-learning model on the first training dataset; forming virtual subject-entity records by appending members of a set of candidate action sequences to time-series of at least some of the subject-entity records; forming a second training dataset by labeling the virtual subject-entity records with predictions of the first machine-learning model; and training a second machine-learning model on the second training dataset.",G06N 3/08; G06N 3/04,CEREBRI AI INC.,"SILBERMAN, Gabriel M.; BRIANÇON, Alain; KLOSE, Gregory; WEGAN, Michael; HARPER, Lee; KRAEMER, Andrew; PRAKASH, Arun","16/127,933 11.09.2018 US",
WO2019057356,PCT/EP2018/066429,20.06.2018,WO/2019/057356,28.03.2019,WO,ANOMALY DETECTION IN AN INDUSTRIAL ROBOT,"A method for anomaly detection in an industrial robot, comprising the steps of a) while executing a predetermined movement, recording (S11) a time series of at least one first operating parameter of the robot; b) applying a machine learning model to the time series obtained in step a), and c) use the machine learning model to score the time series obtained in step a), deciding whether it is an anomaly or not.",B25J 9/16; G05B 23/02,ABB SCHWEIZ AG,"DAI, Fan; CLEVER, Debora; FIEDLER, Boris; KLÖPPER, Benjamin; SCHLAKE, Jan-Christoph; DIX, Marcel; SUBBIAH, Subanatarajan",17192265.1 21.09.2017 EP,
WO2019241798,PCT/US2019/037548,17.06.2019,WO/2019/241798,19.12.2019,WO,SELF-SUPERVISED ROBOTIC OBJECT INTERACTION,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training an object representation neural network. One of the methods includes obtaining training sets of images, each training set comprising: (i) a before image of a before scene of the environment, (ii) an after image of an after scene of the environment after the robot has removed a particular object, and (iii) an object image of the particular object, and training the object representation neural network on the batch of training data, comprising determining an update to the object representation parameters that encourages the vector embedding of the particular object in each training set to be closer to a difference between (i) the vector embedding of the after scene in the training set and (ii) the vector embedding of the before scene in the training set.",B25J 9/16,GOOGLE LLC,"JANG, Eric Victor; LEVINE, Sergey Vladimir; DEVIN, Coline Manon","62/685,885 15.06.2018 US",
WO2019105543,PCT/EP2017/080806,29.11.2017,WO/2019/105543,06.06.2019,WO,BYZANTINE TOLERANT GRADIENT DESCENT FOR DISTRIBUTED MACHINE LEARNING WITH ADVERSARIES,"The present application concerns a computer-implemented method for training a machine learning model in a distributed fashion, using Stochastic Gradient Descent, SGD, wherein the method is performed by a first computer in a distributed computing environment and comprises performing a learning round, comprising broadcasting a parameter vector to a plurality of worker computers in the distributed computing environment, receiving an estimate update vector (gradient) from all or a subset of the worker computers, wherein each received estimate vector is either an estimate of a gradient of a cost function, or an erroneous vector, and determining an updated parameter vector for use in a next learning round based only on a subset of the received estimate vectors. The method aggregates the gradients while guaranteeing resilience to up to half workers being compromised (malfunctioning, erroneous or modified by attackers).",G06N 3/08; G06N 3/04,ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE (EPFL),"BLANCHARD, Peva; EL MHAMDI, El Mahdi; GUERRAOUI, Rachid; STAINER, Julien",,
WO2019136124,PCT/US2019/012147,03.01.2019,WO/2019/136124,11.07.2019,WO,GRASPING OF AN OBJECT BY A ROBOT BASED ON GRASP STRATEGY DETERMINED USING MACHINE LEARNING MODEL(S),"Grasping of an object, by an end effector of a robot, based on a grasp strategy that is selected using one or more machine learning models. The grasp strategy utilized for a given grasp is one of a plurality of candidate grasp strategies. Each candidate grasp strategy defines a different group of one or more values that influence performance of a grasp attempt in a manner that is unique relative to the other grasp strategies. For example, value(s) of a grasp strategy can define a grasp direction for grasping the object (e.g., ""top"", ""side""), a grasp type for grasping the object (e.g., ""pinch"", ""power""), grasp force applied in grasping the object, pre-grasp manipulations to be performed on the object, and/or post-grasp manipulations to be performed on the object.",B25J 9/16; G05B 19/418,X DEVELOPMENT LLC,"NAGARAJAN, Umashankar; HOMBERG, Bianca","15/862,514 04.01.2018 US",
WO2018226492,PCT/US2018/035275,31.05.2018,WO/2018/226492,13.12.2018,WO,ASYNCHRONOUS AGENTS WITH LEARNING COACHES AND STRUCTURALLY MODIFYING DEEP NEURAL NETWORKS WITHOUT PERFORMANCE DEGRADATION,"Methods and computer systems improve a trained base deep neural network by structurally changing the base deep neural network to create an updated deep neural network, such that the updated deep neural network has no degradation in performance relative to the base deep neural network on the training data. The updated deep neural network is subsequently training. Also, an asynchronous agent for use in a machine learning system comprises a second machine learning system ML2 that is to be trained to perform some machine learning task. The asynchronous agent further comprises a learning coach LC and an optional data selector machine learning system DS. The purpose of the data selection machine learning system DS is to make the second stage machine learning system ML2 more efficient in its learning (by selecting a set of training data that is smaller but sufficient) and/or more effective (by selecting a set of training data that is focused on an important task). The learning coach LC is a machine learning system that assists the learning of the DS and ML2. Multiple asynchronous agents could also be in communication with each others, each trained and grown asynchronously under the guidance of their respective learning coaches to perform different tasks.",G06N 3/02; G06N 3/08; G06F 15/18; G06F 17/30,D5AI LLC,"BAKER, James K.","62/515,142 05.06.2017 US",EP-2018813951
WO2018081569,PCT/US2017/058774,27.10.2017,WO/2018/081569,03.05.2018,WO,SYSTEMS AND METHODS FOR A HYBRID BRAIN INTERFACE FOR ROBOTIC SWARMS USING EEG SIGNALS AND AN INPUT DEVICE,"A system and a method for hybrid brain computer interface for controlling a robotic swarm are disclosed. The system comprises: a control interface for defining a plurality of electrodes configured for accessing a plurality of brain signals associated with a plurality of channels located over a sensorimotor cortex; a processor, in operative communication with the control interface, configured to: train a machine learning model to associate a brain state with data defining a brain signal, decode a control signal of the plurality of brain signals to generate control data, apply the control data to the machine learning model to identify the brain state, and transmit instructions to a plurality of robotic devices to modify a density of the plurality of robotic devices based on the brain state; and an input device, in operable communication with the processor, for generating input data, the input data utilized by the processor to modify a position of the plurality of robotic devices.",G06F 3/01; B25J 13/06; G06N 99/00,"ARTEMIADIS, Panagiotis; KARAVAS, Georgios Konstantinos","ARTEMIADIS, Panagiotis; KARAVAS, Georgios Konstantinos","62/413,756 27.10.2016 US",
WO2017191648,PCT/IN2017/000096,28.04.2017,WO/2017/191648,09.11.2017,WO,AN UNIVERSAL CLASSIFIER FOR LEARNING AND CLASSIFICATION OF DATA WITH USES IN MACHINE LEARNING,"The present invention discloses a new methododlogy which can be used to classify specific problems and describes a product such as the ""classification engine"" which is implementable in hardware for specific problems. The specific problem could be such as face Recognition Systems, Disease diagnostic systems, Robotic inspection systems for use in the factory shop floor etc. The system and method given in this invention examines any form of data for the purposes of learning and classification so that any Machine such as a robot or machine will be able to handle the data and classify the data for automatic decision making. While analyzing the data it performs, basically THREE main steps (I) The Partition Process and (II) The Reduction of Dimension (of data ) Process, (III) The Cluster Discovery Process and (IV) The classification Process.",G06N 3/00; G06N 99/00; G06F 15/18; G06F 17/30,"ESWARAN, Kumar","ESWARAN, Kumar",201641015775 05.05.2016 IN,
WO2011156001,PCT/US2011/001051,07.06.2011,WO/2011/156001,15.12.2011,WO,"VERSATILE VIDEO INTERPRETATION,VISUALIZATION, AND MANAGEMENT SYSTEM","A process and device for detecting colon cancer by classifying and annotating clinical features in video data containing colonoscopic features by applying a probabilistic analysis to intra-frame and inter-frame relationships between colonoscopic features in spatially and temporally neighboring portions of video frames, and classifying and annotating as clinical features any of the colonoscopic features that satisfy the probabilistic analysis as clinical features. Preferably the probabilistic analysis is Hidden Markove Model analysis, and the process is carried out by a computer trained using semi supervised learning from labeled and unlabeled examples of clinical features in video containing colonoscopic features.",G06K 9/00; A61B 1/06,"STI MEDICAL SYSTEMS, LLC; PARK, Sun, Young; SARGENT, Dustin; GUSTAFSSON, Ulf, Peter; LI, Wenjing; WOLTERS, Rolf; FLEISCHER, Stephen","PARK, Sun, Young; SARGENT, Dustin; GUSTAFSSON, Ulf, Peter; LI, Wenjing; WOLTERS, Rolf; FLEISCHER, Stephen","61/397,169 07.06.2010 US",
WO2018170510,PCT/US2018/023150,19.03.2018,WO/2018/170510,20.09.2018,WO,MIRROR LOSS NEURAL NETWORKS,"This description relates to a neural network that has multiple network parameters and is configured to receive an input observation characterizing a state of an environment and to process the input observation to generate a numeric embedding of the state of the environment. The neural network can be used to control a robotic agent. The network can be trained using a method comprising: obtaining a first observation captured by a first modality; obtaining a second observation that is co-occurring with the first observation and that is captured by a second, different modality; obtaining a third observation captured by the first modality that is not co-occurring with the first observation; determining a gradient of a triplet loss that uses the first observation, the second observation, and the third observation; and updating current values of the network parameters using the gradient of the triplet loss.",G06N 3/04; G06N 3/08; G06K 9/00; G06F 17/30,GOOGLE LLC,"SERMANET, Pierre","62/473,264 17.03.2017 US",CN-201880006613.2; EP-2018715190
WO2018212710,PCT/SG2018/050233,15.05.2018,WO/2018/212710,22.11.2018,WO,PREDICTIVE ANALYSIS METHODS AND SYSTEMS,"Methods and systems for predictive analysis are disclosed, A predictive analysis method comprises: receiving a set of predictor variables as an input feature vector comprising a plurality of features; projecting each feature of the input feature vector onto a dense vector representation to obtain a set of embedding vectors presenting the input feature vector in an embedding space; calculating a set of interacted vectors, each interacted vector being an element-wise product of two embedding vectors of the set of embedding vectors; performing a weight sum over the interacted vectors, the weighted sum being weighted by a plurality of attention scores each corresponding to an interaction between a pair of features of the feature vector; and projecting the weighed sum to obtain a prediction score.",G06F 15/18; G06N 7/00; G06N 3/02,NATIONAL UNIVERSITY OF SINGAPORE,"HE, Xiangnan; ZHANG, Hanwang; CHUA, Tat-Seng",10201704115T 19.05.2017 SG,
WO2018026836,PCT/US2017/044933,01.08.2017,WO/2018/026836,08.02.2018,WO,GENERATING A MODEL FOR AN OBJECT ENCOUNTERED BY A ROBOT,"Methods and apparatus related to generating a model for an object encountered by a robot in its environment, where the object is one that the robot is unable to recognize utilizing existing models associated with the robot. The model is generated based on vision sensor data that captures the object from multiple vantages and that is captured by a vision sensor associated with the robot, such as a vision sensor coupled to the robot. The model may be provided for use by the robot in detecting the object and/or for use in estimating the pose of the object.",B25J 9/16,X DEVELOPMENT LLC,"KONOLIGE, Kurt; RAJKUMAR, Nareshkumar; HINTERSTOISSER, Stefan","15/227,612 03.08.2016 US",EP-2017751921
WO2019226686,PCT/US2019/033373,21.05.2019,WO/2019/226686,28.11.2019,WO,DEEP LEARNING SYSTEM,"A machine learning system is provided to enhance various aspects of machine learning models. In some aspects, a substantially photorealistic three-dimensional (3D) graphical model of an object is accessed and a set of training images of the 3D graphical mode are generated, the set of training images generated to add imperfections and degrade photorealistic quality of the training images. The set of training images are provided as training data to train an artificial neural network.",G06N 3/08; G06N 20/00; G06T 17/10; G06T 19/00,MOVIDIUS LTD.,"MOLONEY, David Macdara; BUCKLEY, Léonie Raideen; RODRIGUEZ MARTÍN DE LA SIERRA, Luis M.; MÁRQUEZ RODRÍGUEZ-PERAL, Carlos; BRICK, Cormac M.; BYRNE, Jonathan David; XU, Xiaofan; PEÑA CARRILLO, Dexmont Alejandro; PARK, Mi Sun; PALLA, Alessandro","62/675,601 23.05.2018 US",
WO2019028075,PCT/US2018/044697,31.07.2018,WO/2019/028075,07.02.2019,WO,INTELLIGENT ROBOTS,"One embodiment can provide an intelligent robotic system. The intelligent robotic system can include at least one multi-axis robotic arm, at least one gripper attached to the multi-axis robotic arm for picking up a component, a machine vision system comprising at least a three-dimensional (3D) surfacing-imaging module for detecting 3D pose information associated with the component, and a control module configured to control movements of the multi-axis robotic arm and the gripper based on the detected 3D pose of the component.",B25J 9/16; G05B 19/00,"ENOVA TECHNOLOGY, INC.","YUNG, Kai C.; XU, Zheng; FU, Jianming","62/539,926 01.08.2017 US; 16/051,251 31.07.2018 US",
WO2018236753,PCT/US2018/038082,18.06.2018,WO/2018/236753,27.12.2018,WO,ROBOTIC GRASPING PREDICTION USING NEURAL NETWORKS AND GEOMETRY AWARE OBJECT REPRESENTATION,"Deep machine learning methods and apparatus, some of which are related to determining a grasp outcome prediction for a candidate grasp pose of an end effector of a robot. Some implementations are directed to training and utilization of both a geometry network and a grasp outcome prediction network. The trained geometry network can be utilized to generate, based on two-dimensional or two-and-a-half-dimensional image(s), geometry output(s) that are: geometry-aware, and that represent (e.g., high-dimensionally) three-dimensional features captured by the image(s). In some implementations, the geometry output(s) include at least an encoding that is generated based on a trained encoding neural network trained to generate encodings that represent three-dimensional features (e.g., shape). The trained grasp outcome prediction network can be utilized to generate, based on applying the geometry output(s) and additional data as input(s) to the network, a grasp outcome prediction for a candidate grasp pose.",B25J 9/16,GOOGLE LLC,"DAVIDSON, James; YAN, Xinchen; BAI, Yunfei; LEE, Honglak; GUPTA, Abhinav; KHANSARI ZADEH, Seyed Mohammad; PATHAK, Arkanath; HSU, Jasmine","62/522,059 19.06.2017 US",EP-2018740382; CN-201880035890.6
WO2018170671,PCT/CN2017/077280,20.03.2017,WO/2018/170671,27.09.2018,WO,TOPIC-GUIDED MODEL FOR IMAGE CAPTIONING SYSTEM,"Techniques are provided for training and operation of a topic-guided image captioning system. A methodology implementing the techniques includes generating image feature vectors, for an image to be captioned, based on application of a convolutional neural network (CNN) to the image. The method further includes generating the caption based on application of a recurrent neural network (RNN) to the image feature vectors. The RNN is configured as a long short-term memory (LSTM) RNN. The method further includes training the LSTM RNN with training images and associated training captions. The training is based on a combination of: feature vectors of the training image; ature vectors of the associated training caption; and a multimodal compact bilinear (MCB) pooling of the training caption feature vectors and an estimated topic of the training image. The estimated topic is generated by an application of the CNN to the training image.",G06F 17/30,"INTEL CORPORATION; SU, Zhou; LI, Jianguo; YAO, Anbang; CHEN, Yurong","SU, Zhou; LI, Jianguo; YAO, Anbang; CHEN, Yurong",,
WO2004018158,PCT/US2003/026764,21.08.2003,WO/2004/018158,04.03.2004,WO,ORGANIZING GROUPS OF SELF-CONFIGURABLE MOBILE ROBOTIC AGENTS,"A system of self-organizing mobile robotic agents (MRAs) (6) in a multi robotic system (MRS) (2). MRAs cooperate, learn and interact with the environment. The system uses various AI technologies including genetic algorithms, genetic programming and evolving artificial neural networks to develop emergent dynamic behaviors. The collective behaviors of autonomous intelligent robotic agents are applied to numerous applications. The system uses hybrid control architectures. The system also develops dynamic coalitions of groups of autonomous MRAs (2) for formation and reformation in order to perform complex tasks.",B64C 39/02; F41H 13/00; G05D 1/02; G05D 1/10,"SOLOMON, Neal","SOLOMON, Neal","60/404,945 21.08.2002 US; 60/404,946 21.08.2002 US",JP-2004531235; EP-2003793423
WO2019018434,PCT/US2018/042546,17.07.2018,WO/2019/018434,24.01.2019,WO,ACTOR/PERSON CENTRIC AUTO THUMBNAIL,"Approaches, techniques, and mechanisms are disclosed for generating thumbnails. According to one embodiment, a subset of images each depicting character face(s) is identified from a collection of images. An unsupervised learning method is applied to automatically cluster the subset of images into image clusters. Top image clusters are selected from the image clusters based at least in part on weighted scores of images clustered within the image clusters. Thumbnail(s) are generated from images in the top image clusters.",G06K 9/00; G06N 20/00,PCCW VUCLIP (SINGAPORE) PTE. LTD.,"PACHAURI, Kulbhushan","15/656,417 21.07.2017 US",SG-11202000564S
WO2019094843,PCT/US2018/060205,09.11.2018,WO/2019/094843,16.05.2019,WO,SYSTEMS AND METHODS FOR SAFE AND RELIABLE AUTONOMOUS VEHICLES,"Autonomous driving is one of the world's most challenging computational problems. Very large amounts of data from cameras, RADARs, LIDARs, and HD-Maps must be processed to generate commands to control the car safely and comfortably in real-time. This challenging task requires a dedicated supercomputer that is energy-efficient and low-power, complex high-performance software, and breakthroughs in deep learning Al algorithms. To meet this task, the present technology provides advanced systems and methods that facilitate autonomous driving functionality, including a platform for autonomous driving Levels 3, 4, and/or 5. In preferred embodiments, the technology provides an end-to-end platform with a flexible architecture, including an architecture for autonomous vehicles that leverages computer vision and known ADAS techniques, providing diversity and redundancy, and meeting functional safety standards. The technology provides for a faster, more reliable, safer, energy-efficient and space- efficient System-on-a-Chip, which may be integrated into a flexible, expandable platform that enables a wide-range of autonomous vehicles, including cars, taxis, trucks, and buses, as well as watercraft and aircraft.",G05D 1/02; G06N 3/00; G06N 3/04; G06F 15/16; G05D 1/00; B60W 30/00,NVIDIA CORPORATION,"DITTY, Mike; HICOK, Gary; SWEEDLER, Jonathan; FARABET, Clement; YOUSUF, Mohammed, Abdulla; CHAN, T.Y.; GANAPATHI, Ram; SRINIVASAN, Ashok; TRUOG, Mike; GREB, Karl; MATHIESON, John; NISTER, David; FLORY, Kevin; PERRIN, Daniel; HETTENA, Dan","62/584,549 10.11.2017 US",
WO2018157873,PCT/CN2018/078019,05.03.2018,WO/2018/157873,07.09.2018,WO,FINE-GRAINED OBJECT RECOGNITION IN ROBOTIC SYSTEMS,"A method for fine-grained object recognition in a robotic system is disclosed that includes obtaining an image of an object from an imaging device. Based on the image, a deep category-level detection neural network is used to detect pre-defined categories of objects. A feature map is generated for each pre-defined category of object detected by the deep category-level detection neural network. Embedded features are generated, based on the feature map, using a deep instance-level detection neural network corresponding to the pre-defined category of the object, wherein each pre-defined category of an object comprises a corresponding different instance-level detection neural network. An instance-level of the object is determined based on classification of the embedded features.",G06T 7/00; G06K 9/00,"HUAWEI TECHNOLOGIES CO., LTD.","JIANG, Wei; WANG, Wei","15/449,541 03.03.2017 US",CN-201880003293.5; EP-2018760373
WO2017176356,PCT/US2017/016715,06.02.2017,WO/2017/176356,12.10.2017,WO,PARTITIONED MACHINE LEARNING ARCHITECTURE,"A system may include a processor and a memory. The memory may include program code that provides operations when executed by the processor. The operations may include: partitioning, based at least on a resource constraint of a platform, a global machine learning model into a plurality of local machine learning models; transforming training data to at least conform to the resource constraint of the platform; and training the global machine learning model by at least processing, at the platform, the transformed training data with a first of the plurality of local machine learning models.",G06N 99/00; G06N 3/08,WILLIAM MARSH RICE UNIVERSITY,"ROUHANI, Bita Darvish; MIRHOSEINI, Azalia; KOUSHANFAR, Farinaz","62/294,215 11.02.2016 US",
EP189898350,16173968,10.06.2016,3109009,28.12.2016,EP,"ROBOT, INFORMATION PROCESSING SYSTEM, CARRIER MEDIUM AND METHOD","A robot (100, 100a) includes a three-dimensional shape detecting sensor (12) to detect a three dimensional shape of a travel surface existing in a forward travelling direction of the robot (100, 100a), a posture stabilizer (18) to stabilize a posture of a body (10) of the robot (100, 100a), a feature data generator (102) to generate feature data of the detected three dimensional shape, an inclination angle prediction generator (106) to generate a prediction value of an inclination angle of the body (10) when the robot (100, 100a) is to reach a position on the travel surface in the forward travelling direction at a future time point based on the feature data and a prediction model, and an overturn prevention controller (108) to control the posture stabilizer (18) to prevent an overturn of the robot (100, 100a) based on the prediction value.",B25J 5/00; G05D 1/02; G05D 1/08,RICOH CO LTD,INABA DAIKI; HATANAKA WATARU; SHIMURA HIROSHI; KAWAGUCHI ATSUO,2015124516 22.06.2015 JP; 2016083341 19.04.2016 JP,
WO2017203262,PCT/GB2017/051481,25.05.2017,WO/2017/203262,30.11.2017,WO,METHOD AND SYSTEM FOR PREDICTING GARMENT ATTRIBUTES USING DEEP LEARNING,"There is provided a computer implemented method for predicting garment or accessory attributes using deep learning techniques, comprising the steps of: (i) receiving and storing one or more digital image datasets including images of garments or accessories; (ii) training a deep model for garment or accessory attribute identification, using the stored one or more digital image datasets, by configuring a deep neural network model to predict (a) multiple-class discrete attributes; (b) binary discrete attributes, and (c ) continuous attributes, (iii) receiving one or more digital images of a garment or an accessory, and (iv) extracting attributes of the garment or the accessory from the one or more received digital images using the trained deep model for garment or accessory attribute identification. A related system is also provided.",G06K 9/00; G06K 9/46; G06K 9/62,METAIL LIMITED,"CHEN, Yu; SHANKAR, Sukrit; DOWNING, Jim; TOWNSEND, Joe; ROBERTSON, Duncan; ADEYOOLA, Tom",1609245.4 25.05.2016 GB; 1620670.8 05.12.2016 GB; 1702930.7 23.02.2017 GB,EP-2017734807
WO2015154216,PCT/CN2014/074885,08.04.2014,WO/2015/154216,15.10.2015,WO,DEEP LEARNING USING ALTERNATING DIRECTION METHOD OF MULTIPLIERS,"The use of the alternating direction method of multipliers (ADMM) algorithm to train a classifier may reduce the amount of classifier training time with little degradation in classifier accuracy. The training involves partitioning the training data for training the classifier into multiple data blocks. The partitions may preserve the joint distribution of input features and an output class of the training data. The training may further include performing an ADMM iteration on the multiple data blocks in an initial order using multiple worker nodes. Subsequently, the training of the classifier is determined to be completed if a stop criterion is satisfied following the ADMM iteration. Otherwise, if the stop criterion is determined to be unsatisfied following the ADMM iteration, one or more additional ADMM iterations may be performed on different orders of the multiple data blocks until the stop criterion is satisfied.",G06N 3/08,"MICROSOFT TECHNOLOGY LICENSING, LLC; HUO, Qiang; YAN, Zhijie; CHEN, Kai","HUO, Qiang; YAN, Zhijie; CHEN, Kai",,US-15129813; EP-2014889068
WO2018213841,PCT/US2018/033734,21.05.2018,WO/2018/213841,22.11.2018,WO,MULTI-TASK MULTI-MODAL MACHINE LEARNING MODEL,"Methods, systems, and apparatus, including computer programs encoded on computer storage media for training a machine learning model to perform multiple machine learning tasks from multiple machine learning domains. One system includes a machine learning model that includes multiple input modality neural networks corresponding to respective different modalities and being configured to map received data inputs of the corresponding modality to mapped data inputs from a unified representation space; an encoder neural network configured to process mapped data inputs from the unified representation space to generate respective encoder data outputs; a decoder neural network configured to process encoder data outputs to generate respective decoder data outputs from the unified representation space; and multiple output modality neural networks corresponding to respective different modalities and being configured to map decoder data outputs to data outputs of the corresponding modality.",G06N 3/04; G06N 3/08,GOOGLE LLC,"SHAZEER, Noam M.; GOMEZ, Aidan Nicholas; KAISER, Lukasz Mieczyslaw; USZKOREIT, Jakob D.; JONES, Llion Owen; PARMAR, Niki J.; VASWANI, Ashish Teku","62/509,016 19.05.2017 US",CN-201880028587.3; EP-2018737050
WO2007066842,PCT/KR2005/004319,15.12.2005,WO/2007/066842,14.06.2007,WO,APPARATUS AND METHOD FOR VISION PROCESSING ON NETWORK BASED INTELLIGENT SERVICE ROBOT SYSTEM AND THE SYSTEM USING THE SAME,"There are provided an apparatus and method for vision processing on a network based intelligent service robot system and a system using the same. A robot can move to a target object, avoiding obstacles without helps of a robot server interfaced with a robot terminal over network, by extracting/processing three-dimensional distance information of external objects, using a stereo camera, a low price image processing dedicated chip and an embedded processor. Therefore, the intelligent robot can travel and move using only a stereo camera image processing without other sensors, and further provides users with various functional services with low expense.",B25J 9/16,"ELECTRONICS AND TELECOMMUNICATIONS RESEARCH INSTITUTE; CHO, Jae Il; CHOI, Seung Min; HWANG, Dae Hwan","CHO, Jae Il; CHOI, Seung Min; HWANG, Dae Hwan",10-2005-0119019 07.12.2005 KR,US-12088111; DE-null; JP-2008535430
WO2019209681,PCT/US2019/028454,22.04.2019,WO/2019/209681,31.10.2019,WO,SYSTEMS AND METHODS FOR LEARNING AGILE LOCOMOTION FOR MULTIPED ROBOTS,"Training and/or using a machine learning model for locomotion control of a robot, where the model is decoupled. In many implementations, the model is decoupled into an open loop component and a feedback component, where a user can provide a desired reference trajectory (e.g., a symmetric sine curve) as input for the open loop component. In additional and/or alternative implementations, the model is decoupled into a pattern generator component and a feedback component, where a user can provide controlled parameter(s) as input for the pattern generator component to generate pattern generator phase data (e.g., an asymmetric sine curve). The neural network model can be used to generate robot control parameters.",B25J 9/16; B62D 57/02,GOOGLE LLC,"TAN, Jie; ZHANG, Tingnan; ISCEN, Atil; COUMANS, Erwin; BAI, Yunfei","62/661,055 22.04.2018 US",
WO2019010136,PCT/US2018/040641,02.07.2018,WO/2019/010136,10.01.2019,WO,DETERMINING AND UTILIZING CORRECTIONS TO ROBOT ACTIONS,"Methods, apparatus, and computer-readable media for determining and utilizing human corrections to robot actions. In some implementations, in response to determining a human correction of a robot action, a correction instance is generated that includes sensor data, captured by one or more sensors of the robot, that is relevant to the corrected action. The correction instance can further include determined incorrect parameter(s) utilized in performing the robot action and/or correction information that is based on the human correction. The correction instance can be utilized to generate training example(s) for training one or model(s), such as neural network model(s), corresponding to those used in determining the incorrect parameter(s). In various implementations, the training is based on correction instances from multiple robots. After a revised version of a model is generated, the revised version can thereafter be utilized by one or more of the multiple robots.",B25J 9/16; G05B 13/02; G06N 3/08; G06N 3/04; G06N 20/00,X DEVELOPMENT LLC,"HUDSON, Nicolas; YAMPARALA, Devesh","15/640,914 03.07.2017 US",KR-1020197038754; EP-2018749662
WO2019204945,PCT/CA2019/050547,26.04.2019,WO/2019/204945,31.10.2019,WO,SYSTEM AND METHOD FOR SCALABLE CLOUD-ROBOTICS BASED FACE RECOGNITION AND FACE ANALYSIS,"A system and method for performing distributed facial recognition divides processing steps between a user engagement device/robot, having lower processing power, and a remotely located server, having significantly more processing power. Images captured by the user engagement device/robot are processed at the device/robot by applying a first set of image processing steps that includes applying a first face detection. First processed images having at least one detected face is transmitted to the server, whereat a second set of image processing steps are applied to determine a stored user facial image matching the detected face of the first processed image. At least one user property associated to the given matching user facial image is then transmitted to the user engagement device/robot. An interactive action personalized to the user can further be performed at the user engagement device/robot.",G06K 9/78; G06F 15/16; G06K 9/36; G06K 9/62; G06N 20/00; B25J 9/18,C2RO CLOUD ROBOTICS INC.,"FAROKHI, Soodeh; ABOLHASSANI, Amir Abbas Haji; DUGUAY, Felix-olivier; VARGAS MORENO, Aldo Enrique","62/662,990 26.04.2018 US",
WO2018071392,PCT/US2017/055894,10.10.2017,WO/2018/071392,19.04.2018,WO,NEURAL NETWORKS FOR SELECTING ACTIONS TO BE PERFORMED BY A ROBOTIC AGENT,"A system includes a neural network system implemented by one or more computers. The neural network system is configured to receive an observation characterizing a current state of a real-world environment being interacted with by a robotic agent to perform a robotic task and to process the observation to generate a policy output that defines an action to be performed by the robotic agent in response to the observation. The neural network system includes: (i) a sequence of deep neural networks (DNNs), in which the sequence of DNNs includes a simulation-trained DNN that has been trained on interactions of a simulated version of the robotic agent with a simulated version of the real-world environment to perform a simulated version of the robotic task, and (ii) a first robot-trained DNN that is configured to receive the observation and to process the observation to generate the policy output.",G06N 3/04; G06N 3/00; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"PASCANU, Razvan; HADSELL, Raia Thais; VECERIK, Mel; ROTHORL, Thomas; RUSU, Andrei-Alexandru; HEESS, Nicolas Manfred Otto","62/406,363 10.10.2016 US",CN-201780074261.X; EP-2017788409; JP-2019519210
WO2020075147,PCT/IB2019/058721,13.10.2019,WO/2020/075147,16.04.2020,WO,INTELLIGENT VISION SYSTEM AND METHODS,"Intelligent vision systems and methods which are capable of focusing on subtle visual cues at high resolution using principles of a foveal view coupled with an attention mechanism, that functions like the human eye are described. Intelligent vision systems and methods are based on artificial intelligence-deep learning neural network models that rely on a hierarchy of visual streams towards achieving humanand greater levels of sharp vision. Intelligent visions systems and methods processmultiple high-resolution field of view visual streams to create a foveal view representation of the environment which is fed forward to the neural network, which controls the pan/tilt positioning of the cameras based on an attention mechanism to achieve focus on a Subject of Interest (SOI).",G06N 3/08; H04N 7/18; H04N 5/225; H04N 13/239,FOVEA TECHNOLOGY,"SOMER, Mohamed; ABDUL GHANI, Abdul Rahman","62/745,346 13.10.2018 US",
WO2019222634,PCT/US2019/032880,17.05.2019,WO/2019/222634,21.11.2019,WO,DATA-EFFICIENT HIERARCHICAL REINFORCEMENT LEARNING,"Training and/or utilizing a hierarchical reinforcement learning (HRL) model for robotic control. The HRL model can include at least a higher-level policy model and a lower-level policy model. Some implementations relate to technique(s) that enable more efficient off-policy training to be utilized in training of the higher-level policy model and/or the lower-level policy model. Some of those implementations utilize off-policy correction, which re-labels higher-level actions of experience data, generated in the past utilizing a previously trained version of the HRL model, with modified higher-level actions. The modified higher-level actions are then utilized to off-policy train the higher-level policy model. This can enable effective off-policy training despite the lower-level policy model being a different version at training time (relative to the version when the experience data was collected).",B25J 9/16; G05D 1/00,GOOGLE LLC,"LEE, Honglak; GU, Shixiang; LEVINE, Sergey","62/673,746 18.05.2018 US",
WO2018029267,PCT/EP2017/070229,09.08.2017,WO/2018/029267,15.02.2018,WO,ROBOTIC DEVICE,"According to one aspect of the present invention there is provided a robotic device comprising: a plurality of sensors distributed over at least a portion of a surface of the robotic device, wherein the sensors are operable to visually detect an object in the vicinity of the robotic device based on a relative movement of the object with respect to the sensors.",B25J 13/08; B25J 9/16; B25J 19/06; F16P 3/14; F16P 3/16,JOANNEUM RESEARCH FORSCHUNGSGESELLSCHAFT MBH,"HOFBAUR, Michael; JAKOPIC, Georg; STADLOBER, Barbara; SCHMIDT, Volker",10 2016 114 835.0 10.08.2016 DE,
WO2020055435,PCT/US2018/051567,18.09.2018,WO/2020/055435,19.03.2020,WO,MACHINE-LEARNING-BASED VISUAL-HAPTIC FEEDBACK SYSTEM FOR ROBOTIC SURGICAL PLATFORMS,"Embodiments described herein provide various examples of a visual-haptic feedback system for generating a haptic feedback signal based on captured endoscopy images. In one aspect, the process for generating the haptic feedback signal includes the steps of: receiving an endoscopic video captured for a surgical procedure performed on a robotic surgical system; detecting a surgical task in the endoscopic video involving a given type of surgical tool-tissue interaction; selecting a machine learning model constructed for analyzing the given type of surgical tool-tissue interaction; for a video image associated with the detected surgical task depicting the given type of surgical tool-tissue interaction, applying the selected machine learning model to the video image to predict a strength level of the depicted surgical tool-tissue interaction; and then providing the predicted strength level to a surgeon performing the surgical task as a haptic feedback signal for the given type of surgical tool-tissue interaction.",A61B 34/00; A61B 34/10; A61B 90/00; A61B 34/35; G16H 20/40; G06N 99/00; A61B 17/00; A61B 18/00,VERB SURGICAL INC.,"VENKATARAMAN, Jagadish; MILLER, Denise Ann","16/129,593 12.09.2018 US",
WO2018236446,PCT/US2018/024168,23.03.2018,WO/2018/236446,27.12.2018,WO,TRANSFER LEARNING OF CONVOLUTIONAL NEURAL NETWORKS FROM VISIBLE COLOR (RBG)TO INFRARED (IR) DOMAIN,Described is a system for converting a convolutional neural network (CNN) designed and trained for color (RGB) images to one that works on infrared (IR) or grayscale images. The converted CNN comprises a series of convolution layers of neurons arranged in a set kernels having corresponding depth slices. The converted CNN is used for performing object detection. A mechanical component of an autonomous device is controlled based on the object detection.,G06T 3/40; G06T 5/20; G06N 3/08,"HRL LABORATORIES, LLC","UHLENBROCK, Ryan, M.; CHEN, Yang; KHOSLA, Deepak","62/510,741 24.05.2017 US",EP-2018819924; CN-201880023966.3
WO2006122030,PCT/US2006/017731,08.05.2006,WO/2006/122030,16.11.2006,WO,DEVICE FOR THE AUTONOMOUS BOOTSTRAPPING OF USEFUL INFORMATION,"A discovery system employing a neural network, training within this system, that is stimulated to generate novel output patterns through various forms of perturbation applied to it, a critic neural network likewise capable of training in situ within this system, that learns to associate such novel patterns with their utility or value while triggering reinforcement learning of the more useful or valuable of these patterns within the former net. The device is capable of bootstrapping itself to progressively higher levels of adaptive or creative competence, starting from no learning whatsoever, through cumulative cycles of experimentation and learning. Optional feedback mechanisms between the latter and former self-learning artificial neural networks are used to accelerate the convergence of this system toward useful concepts or plans of action.",G06N 3/04,"THALER, Stephen, L.","THALER, Stephen, L.","60/678,856 07.05.2005 US",JP-2008511241; IN-8923/DELNP/2007; RU-null; EP-2011002179; DE-null; EP-2006752398
WO2018164716,PCT/US2017/053243,25.09.2017,WO/2018/164716,13.09.2018,WO,PROCESSOR FOR IMPLEMENTING REINFORCEMENT LEARNING OPERATIONS,"A reinforcement learning processor specifically configured to execute reinforcement learning operations by the way of implementing an application-specific instruction set is envisaged. The application-specific instruction set incorporates 'Single Instruction Multiple Agents (SiMA)' instructions. SiMA type instructions are specifically designed to be implemented simultaneously on a plurality of reinforcement learning agents which interact with corresponding reinforcement learning environments. The SiMA type instructions are specifically configured to receive either a reinforcement learning agent ID or a reinforcement learning environment ID as the operand. The reinforcement learning processor uses neural network data paths to communicate with a neural network, which in turn uses the actions, state-value functions, Q-values and reward values generated by the reinforcement learning processor to approximate an optimal state-value function as well as an optimal reward function.",G06N 99/00,ALPHAICS CORPORATION,"NAGARAJA, Nagendra","15/455,126 09.03.2017 US",
WO2018217903,PCT/US2018/034147,23.05.2018,WO/2018/217903,29.11.2018,WO,REAL-TIME ADAPTIVE CONTROL OF ADDITIVE MANUFACTURING PROCESSES USING MACHINE LEARNING,"Disclosed herein are machine learning-based methods and systems for automated object defect classification and adaptive, real-time control of additive manufacturing and/or welding processes.",G06N 99/00; B23K 9/095; B23K 31/12; B29C 67/00,"RELATIVITY SPACE, INC.","MEHR, Edward; ELLIS, Tim; NOONE, Jordan","15/604,473 24.05.2017 US",EP-2018806932; CA-3064593; RU-2019141479
WO2019099684,PCT/US2018/061300,15.11.2018,WO/2019/099684,23.05.2019,WO,UNSUPERVISED LEARNING OF IMAGE DEPTH AND EGO-MOTION PREDICTION NEURAL NETWORKS,"A system includes a neural network implemented by one or more computers, in which the neural network includes an image depth prediction neural network and a camera motion estimation neural network. The neural network is configured to receive a sequence of images. The neural network is configured to process each image in the sequence of images using the image depth prediction neural network to generate, for each image, a respective depth output that characterizes a depth of the image, and to process a subset of images in the sequence of images using the camera motion estimation neural network to generate a camera motion output that characterizes the motion of a camera between the images in the subset. The image depth prediction neural network and the camera motion estimation neural network have been jointly trained using an unsupervised learning technique.",G06T 7/20; G06T 7/579,GOOGLE LLC,"ANGELOVA, Anelia; WICKE, Martin; MAHJOURIAN, Reza","62/586,611 15.11.2017 US",
WO2019098573,PCT/KR2018/013061,31.10.2018,WO/2019/098573,23.05.2019,WO,ELECTRONIC DEVICE AND METHOD FOR CHANGING CHATBOT,"An artificial intelligence (AI) system which utilizes machine learning algorithm such as deep learning and application is provided. The artificial intelligence (AI) system includes a controlling method of an electronic device for determining a chatbot using an artificial intelligence learning model includes receiving a voice uttered by a user, processing the voice and acquiring text information corresponding to the voice, and displaying the text information on a chat screen, determining a chatbot for providing a response message regarding the voice by inputting the acquired text information and chat history information regarding the chat screen to a model which is trained to determine the chatbot by inputting text information and chat history information, transmitting the acquired text information and the chat history information regarding the chat screen to a server for providing the determined chatbot, and receiving a response message from the server and displaying the response message on the chat screen.",G06Q 50/30; G06N 99/00,"SAMSUNG ELECTRONICS CO., LTD.","YUN, Ji Hwan; RYU, Won Ho; CHOI, Won Jong",10-2017-0154939 20.11.2017 KR,EP-2018879732
WO2009006735,PCT/CA2008/001256,08.07.2008,WO/2009/006735,15.01.2009,WO,GESTURE RECOGNITION SYSTEM INCLUDING KEYBOARD AND MOUSE EMULATION,"Universal Video Computer Vision Input Virtual Space Mouse-Keyboard Control Panel Robot has computer system use video vision camera sensors, logical vision sensor programming as trainable computer vision seeing objects movements X, Y, Z dimensions' definitions to recognize users commands by their Hands gestures and/or enhance symbols, colors objects combination actions to virtually input data, and commands to operate computer, and machines. The robot has automatically calibrated working space into Space Mouse Zone, Space Keyboard zone, and Hand-Sign Languages Zone between user and itself. The robot automatically translate the receiving coordination users' hand gesture actions combinations on the customizable puzzle-cell positions of working space and mapping to its software mapping lists for each of the puzzle-cell position definition and calibrate these user hand and/or body gestures' virtual space actions into entering data and commands to computer meaningful computer, machine, home appliances operations.",G06F 3/00; B25J 9/00; B25J 9/18; G05B 15/02; G06F 15/18; G06F 3/03; G09B 21/00; H04N 7/18,"CHIU, Hsien-Hsiang","CHIU, Hsien-Hsiang","2,591,808 11.07.2007 CA",US-12311239
WO2018218155,PCT/US2018/034663,25.05.2018,WO/2018/218155,29.11.2018,WO,MACHINE-LEARNED MODEL SYSTEM,"Provided are methods, systems, devices, and tangible non-transitory computer readable media for providing data associated with a machine-learned model library. The disclosed technology can perform operations including providing a machine-learned model library that includes a plurality of machine-learned models trained to generate semantic observations based on sensor data associated with a vehicle. Each machine-learned model of the plurality of machine-learned models can be associated with one or more configurations supported by each machine-learned model. A request for a machine-learned model from the machine-learned model library can be received a remote computing device. Furthermore, based on the request, the machine-learned model can be provided to the remote computing device.",H04W 4/44; G05D 1/02; G06N 3/02,GOOGLE LLC,"MCGAVRAN, Christine; BUKOWSKI, Richard William; YACOBIAN, Abraham Jack; ASGHARBEYGI, Nima; SIMMONS, Matthew","62/511,526 26.05.2017 US",EP-2018734669
WO2018022718,PCT/US2017/043889,26.07.2017,WO/2018/022718,01.02.2018,WO,SKILL TRANSFER FROM A PERSON TO A ROBOT,"A computer-implemented method includes recording one or more demonstrations of a task performed by a user. Movements of one or more joints of the user are determined from the one or more demonstrations. By a computer processor, a neural network or Gaussian mixture model incorporating one or more contraction analysis constraints is learned, based on the movements of the one or more joints of the user, the one or more contraction analysis constraints representing motion characteristics of the task. A first initial position of a robot is determined. A first trajectory of the robot is determined to perform the task, based at least in part on the neural network or Gaussian mixture model and the first initial position.",G06N 3/02; G05B 15/00; B25J 9/16,UNIVERSITY OF CONNECTICUT,"DANI, Ashwin; RAVICHANDAR, Harish","62/366,659 26.07.2016 US",
WO2010141369,PCT/US2010/036656,28.05.2010,WO/2010/141369,09.12.2010,WO,SEMANTIC SCENE SEGMENTATION USING RANDOM MULTINOMIAL LOGIT (RML),"A system and method are disclosed for learning a random multinomial logit (RML) classifier and applying the RML classifier for scene segmentation. The system includes an image textonization module, a feature selection module and a RML classifier. The image textonization module is configured to receive an image training set with the objects of the images being pre-labeled. The image textonization module is further configured to generate corresponding texton images from the image training set. The feature selection module is configured to randomly select one or more texture-layout features from the texton images. The RML classifier comprises multiple multinomial logistic regression models. The RML classifier is configured to learn each multinomial logistic regression model using the selected texture-layout features. The RML classifier is further configured to apply the learned regression models to an input image for scene segmentation.",G06K 9/40,"HONDA MOTOR CO., LTD.; RANGANATHAN, Ananth","RANGANATHAN, Ananth","61/217,930 04.06.2009 US; 12/789,292 27.05.2010 US",DE-1120100022321; DE-112010002232; JP-2012514018
WO2008136737,PCT/SE2008/000319,08.05.2008,WO/2008/136737,13.11.2008,WO,SELF LEARNING ROBOT,"The present invention relates to a robot using a learning control architecture comprising three layers: a reasoning layer, a reactive layer, and a modelling layer. The reasoning layer develops strategies from given commands and measured sensor/actuators signals, the reactive layer develop control commands from strategies and from sensor/actuator signals, and the modelling layer is used by both the reactive and reasoning layer to build a physical model of the world around the robot.",B25J 9/00; G05D 1/02,"INSTITUTE OF ROBOTICS IN SCANDINAVIA AB; TOFELT, Johan; NORDIN, Peter; BUSCHKA, Pär","TOFELT, Johan; NORDIN, Peter; BUSCHKA, Pär","60/928,250 08.05.2007 US; 0701114-1 08.05.2007 SE",
WO2016140701,PCT/US2015/043828,05.08.2015,WO/2016/140701,09.09.2016,WO,DIGITAL OBJECT LIBRARY MANAGEMENT SYSTEM FOR MACHINE LEARNING APPLICATIONS,"Digital object library management systems and methods for machine learning applications are taught herein. Such a method includes populating a digital object library with a number of machine readable digital objects, modifying the digital objects to include additional machine readable data about the digital objects or other digital objects and the relationships among existing digital objects, generating lists of objects for use in construction and verification of machine learning models used to classify unknown objects into one or more categories, building queries to generate object lists, initiating model generation, in which a machine learning model used to classify unknown objects into one or more categories is generated, initiating model evaluation, storing models, object lists, evaluation results, and associations among these objects, generating a visual display of object metadata, lists, relational information, and evaluation results and running distributable algorithms across the library of digital objects.",G06F 15/18; G06F 17/30,"BLUVECTOR, INC.","MISERENDINO, Scott, B.; STEINER, Donald, D.; PETERS, Ryan, V.; FAIRBANKS, Guy, B.","14/635,711 02.03.2015 US",JP-2017546095; EP-2015884155
EP11176955,09001710,06.02.2009,2216145,11.08.2010,EP,Learning and use of schemata in robotic devices,"The invention related to robots, especially to a robotic controller using schemata, the schemata being a set of parameterized sequences of motor commands in order to make a robot achieve a set goal, 
the parameters for the sequences being gained from the state variables of the robotic controller. The robotic controller comprises 
- an interface for supplying sensory input to the robotic controller, 
- a schemata state memory (1) structure supplied with either input from a schemata recognition module (4) or input from an inverse model module (2) or combinations of them, 
- an inverse model module (2) for generating motor commands based on state variables and stored schemata, 
- a forward model module (3) for predicting state variables based on state variables and stored schemata, and 
- a schemata recognition module (4) for selecting a schemata based on supplied state variables of the robot controlled by the robotic controller.",B25J 9/16,HONDA RES INST EUROPE GMBH,GLAESER CLAUDIUS; JOUBLIN FRANK DR,09001710 06.02.2009 EP,
WO2018152741,PCT/CN2017/074576,23.02.2017,WO/2018/152741,30.08.2018,WO,COLLABORATIVE ACTIVATION FOR DEEP LEARNING FIELD,"Methods and apparatus, including computer program products, are provided for machine learning including deep convolutional neural networks. In some example embodiments, there may be provided a method that includes receiving, at a trained machine learning model, a portion of a test image; activating, at the machine learning model, a convolutional result formed based on the portion of the test image, the activation based on neighboring regions in the test image; and providing, by the machine learning model, an activated output. Related systems, methods, and articles of manufacture are also described.",G06K 9/66,"NOKIA TECHNOLOGIES OY; NOKIA TECHNOLOGIES (BEIJING) CO., LTD.","LI, Hongyang",,CN-201780087233.1
EP235780378,18178751,20.06.2018,3418952,26.12.2018,EP,MACHINE LEARNING FOR WELDMENT CLASSIFICATION AND CORRELATION,"Embodiments of systems and methods for characterizing weldments are disclosed. One embodiment includes a method of generating an algorithm for classifying weldments as meeting or not meeting a specification. Training data is read by a machine learning system. The training data includes cross-sectional images of training weldments, truth data indicating whether the training weldments meet the specification or not, and training weld data associated with creating the training weldments. The machine learning system trains up an algorithm using the training data such that the resultant algorithm can classify a subsequent test weldment as meeting the specification or not meeting the specification when a cross-sectional image of the test weldment and test weld data used to create the test weldment are read and processed by the classification algorithm as trained.",G06N 99/00,LINCOLN GLOBAL INC,NARAYANAN BADRI K; PROCARIO JOHN R; KOTTMAN MICHAEL A,201715627867 20.06.2017 US,
EP251296534,19160316,01.03.2019,3534230,04.09.2019,EP,ROBOT WORK SYSTEM AND METHOD OF CONTROLLING ROBOT WORK SYSTEM,"An information processing apparatus obtains a plurality of combinations of a position of a work target candidate and a transport machine optimum control parameter which is a control parameter of the transport machine that maximizes performance of the work on a work target when the work target candidate is set as the work target, based on a captured image obtained by capturing an area including a plurality of the work target candidates transported by the transport machine, determines the work target from among the work target candidates based on the combinations, controls the transport machine based on the transport machine optimum control parameter of the determined work target, generates a control plan of the robot based on a position of the determined work target and the transport machine optimum control parameter of the work target and controls the robot according to the generated control plan.",B25J 9/16; G05B 19/418; G06N 3/04; G06N 3/08,HITACHI LTD,SAKAI RYO; KIMURA NOBUTAKA,2018037340 02.03.2018 JP,
EP11198639,09159753,08.05.2009,2249286,10.11.2010,EP,Robot with vision-based 3D shape recognition,"The invention relates to a method for processing video signals from a video sensor, in order to extract 3d shape information about objects represented in the video signals, 
the method comprising the following steps: 
- providing a memory in which objects are stored in a 3d shape space, the shape space being an abstract feature space encoding the objects' 3d shape properties, and 
- mapping a 2d video signal representation of an object in the shape space, the coordinates of the object in the shape space indicating the object's 3d shape.",G06K 9/00; G06K 9/62,HONDA RES INST EUROPE GMBH,FRANZIUS DR MATHIAS; WERSING DR HEIKO,09159753 08.05.2009 EP,
WO2019099206,PCT/US2018/058672,01.11.2018,WO/2019/099206,23.05.2019,WO,COMPONENT FEATURE DETECTOR FOR ROBOTIC SYSTEMS,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for an object feature identification system employed by a robotic are disclosed. In one aspect, a method includes the actions of generating a data reading of a work area by scanning the work area with a sensor device of the robot; identifying, by processing the data reading through a learning engine, a particular component of a plurality of components associated with the work area based on a task to be performed; identifying, with the machine learning engine, a particular feature of the particular component used in a completion of the task; determining, with the machine learning engine, a particular tool of a plurality of tools of the robot that is configured to perform the task; and performing the task with the particular tool and the particular feature of the particular component.",B25J 9/16; G06N 3/04,GOOGLE LLC,"NEMALLAN, Umakaran","15/815,381 16.11.2017 US",EP-2018804824; CN-201880034832.1
WO2019033381,PCT/CN2017/097979,18.08.2017,WO/2019/033381,21.02.2019,WO,EFFICIENT NEURAL NETWORKS WITH ELABORATE MATRIX STRUCTURES IN MACHINE LEARNING ENVIRONMENTS,"A mechanism is described for facilitating efficient neural networks with elaborate matrix structures in machine learning environments. A method of embodiments, as described herein, includes facilitating selection of one or more paths associated with one or more matrix structures for a neural network associated with deep learning processes performed by a processor of a computing device. The method further includes training the neural network based on the one or more paths and the corresponding one or more matrix structure to facilitate customization of the deep learning processes.",G06N 3/02; G06N 3/08,"INTEL CORPORATION; CHEN, Yurong; LI, Jianguo; NI, Renkun","CHEN, Yurong; LI, Jianguo; NI, Renkun",,
WO2019018533,PCT/US2018/042701,18.07.2018,WO/2019/018533,24.01.2019,WO,NEURO-BAYESIAN ARCHITECTURE FOR IMPLEMENTING ARTIFICIAL GENERAL INTELLIGENCE,"The present disclosure envisages a processor architecture designed tor artificial general intelligence operations. The engine for Neuro-Bayesian teaming (eN-BLe) further includes a hierarchical Neuro Bayesian Network module, a reinforcement learning module, a supervised learning, module, and a planning, imagination, and simulation module, for planning, imagination, and decision making under uncertainty. The engine for Neuro-Bayesian learning is communicably coupled to a user application and receives input data from the user application. The hierarchical Neuro-Bayesian Network (H-NBN) acts as a probabilistic internal model of an application or unknown environment. The H-NBN is capable of probabilistic and Bayesian inference, prediction, and unsupervised learning. Thereafter, the outputs of the H-NBN are provided to supervised NBNs for classification or regression of input states. Additionally, the output of the H-NBN is provided to the reinforcement learning module, which in turn comprises Value-NBNs (V-NBNs) and Policy-NBNs (P-NBNs), to compute expected reward and select optimal actions under uncertainty.",G06E 1/00,NEUBAY INC,"RAO, Rajesh Perampalli Nekkar; KATHIRISETTI, Satish; DURAIRAJ, Ramesh","62/534,040 18.07.2017 US",
WO2019060208,PCT/US2018/050946,13.09.2018,WO/2019/060208,28.03.2019,WO,AUTOMATICALLY ANALYZING MEDIA USING MACHINE LEARNING ANALYSIS,"A stream of media eligible to be automatically shared is received. Using a machine learning model trained using engagement information regarding one or more previously shared media, a media included in the stream of media is analyzed to output an engagement analysis. Based on the engagement analysis, a determination is made on whether the media included in the stream of media is desirable to be automatically shared. The media is automatically shared in an event it is determined that the media included in the stream of media is desirable to be automatically shared. A media and a context information associated with the media are received. A first machine learning model and a second machine learning model are trained using different machine learning training data sets. Using the first machine learning model, the media is analyzed to determine a classification result. Using the second machine learning model, the classification result and the context information are analyzed to determine whether the media is likely not desirable to share. In an event the media is not identified as not desirable to share, the media is automatically shared.",G06F 15/18,"GET ATTACHED, INC.","AZOUT, Albert; IMBRUCE, Douglas; PAPE, Gregory, T.","15/714,741 25.09.2017 US; 15/714,737 25.09.2017 US",
EP215642798,17200012,03.11.2017,3319016,09.05.2018,EP,CONTROL SYSTEMS USING DEEP REINFORCEMENT LEARNING,Data indicative of a plurality of observations of an environment are received at a control system. Machine learning using deep reinforcement learning is applied to determine an action based on the observations. The deep reinforcement learning applies a convolutional neural network or a deep auto encoder to the observations and applies a training set to locate one or more regions having a higher reward. The action is applied to the environment. A reward token indicative of alignment between the action and a desired result is received. A policy parameter of the control system is updated based on the reward token. The updated policy parameter is applied to determine a subsequent action responsive to a subsequent observation.,G06N 3/04; G05B 13/02; G06N 3/08,UNITED TECH CORPORATION,GIERING MICHAEL J; REDDY KISHORE K; VENUGOPALAN VIVEK; SURANA AMIT; SARKAR SOUMALYA,201662417804 04.11.2016 US,
WO2019113063,PCT/US2018/063839,04.12.2018,WO/2019/113063,13.06.2019,WO,MULTIPLE STAGE IMAGE BASED OBJECT DETECTION AND RECOGNITION,"Systems, methods, tangible non-transitory computer-readable media, and devices for autonomous vehicle operation are provided. For example, a computing system can receive object data that includes portions of sensor data. The computing system can determine, in a first stage of a multiple stage classification using hardware components, one or more first stage characteristics of the portions of sensor data based on a first machine-learned model. In a second stage of the multiple stage classification, the computing system can determine second stage characteristics of the portions of sensor data based on a second machine-learned model. The computing system can generate an object output based on the first stage characteristics and the second stage characteristics. The object output can include indications associated with detection of objects in the portions of sensor data.",G06K 9/00; G06K 9/38; G06K 9/46; G06K 9/62,"UATC, LLC","VALLESPI-GONZALEZ, Carlos; AMATO, Joseph Lawrence; TOTOLOS, JR., George","62/594,631 05.12.2017 US; 15/972,566 07.05.2018 US",
WO2019212860,PCT/US2019/029169,25.04.2019,WO/2019/212860,07.11.2019,WO,POSITIONING A ROBOT SENSOR FOR OBJECT CLASSIFICATION,"In one embodiment, a method includes receiving, from a first sensor on a robot, first sensor data indicative of an environment of the robot. The method also includes identifying, based on the first sensor data, an object of an object type m the environment of the robot, where the object type is associated with a classifier that takes sensor data from a predetermined pose relative to the object as input. The method further includes causing the robot to position a second sensor on the robot at the predetermined pose relative to the object. The method additionally includes receiving, from the second sensor, second sensor data indicative of the object while the second sensor is positioned at the predetermined pose relative to the object. The method further includes determining, by inputting the second sensor data into the classifier, a property of the object.",B25J 9/16; G06K 9/00; G06K 9/20,X DEVELOPMENT LLC,"HOMBERG, Bianca; BINGHAM, Jeefrey","15/968,922 02.05.2018 US",
WO2019137464,PCT/CN2019/071318,11.01.2019,WO/2019/137464,18.07.2019,WO,ROBOT NAVIGATION AND OBJECT TRACKING,"A system and method of tracking an object and navigating an object tracking robot includes receiving tracking sensor input representing the object and an environment at multiple times, responsive to the tracking sensor input, calculating positions of the robot and the object at the multiple times, and using a computer implemented deep reinforcement learning (DRL) network trained as a function of tracking quality rewards and robot navigation path quality rewards, the DRL network being responsive to the calculated positions of the robot and the object at the multiple times to determine possible actions specifying movement of the object tracking robot from a current position of the robot and target, determine quality values (Q-values) for the possible actions, and select an action as a function of the Q-values. A method of training the DRL network is also included.",G05D 1/02,"HUAWEI TECHNOLOGIES CO., LTD.","JIANG, Wei; WANG, Wei","15/870,626 12.01.2018 US",
EP14502209,05019965,14.09.2005,1638042,22.03.2006,EP,Mobile hybrid software router,"A hybrid router for dynamical control systems is described. The mobile hybrid software router (MHSR) combines distinctive computational and mathematical techniques, including evolutionary computation (EC), probabilistic simulations (PS), machine learning and artificial neural networks (A-NNs), in order to solve unique problems encountered in an unknown environment in real time. Embodied in intelligent mobile software agents (IMSAs), the MHSR operates within a multi-agent system (MAS) to continually optimize system operation. The MHSR is applied to several major complex system categories. In one embodiment of the system, the MHSR is implemented in hardware, including continuously programmable field programmable gate arrays (CP-FPGAs), for perpetually reconfigurable evolvable hardware operation. Whether in application-specific or multi-functional mode, the MHSR is useful to groups of agents in intelligent systems for adaptation to uncertain environments in order to perform self-organization capabilities.",G06N 3/08; G06N 5/00,SOLOMON NEAL E,SOLOMON NEAL E,05019965 14.09.2005 EP,
WO2017223560,PCT/US2017/039274,26.06.2017,WO/2017/223560,28.12.2017,WO,TOMOGRAPHIC IMAGE RECONSTRUCTION VIA MACHINE LEARNING,"Tomographic/tomosynthetic image reconstruction systems and methods in the framework of machine learning, such as deep learning, are provided. A machine learning algorithm can be used to obtain an improved tomographic image from raw data, processed data, or a preliminarily reconstructed intermediate image for biomedical imaging or any other imaging purpose. In certain cases, a single, conventional, non-deep-learning algorithm can be used on raw imaging data to obtain an initial image, and then a deep learning algorithm can be used on the initial image to obtain a final reconstructed image. All machine learning methods and systems for tomographic image reconstruction are covered, except for use of a single shallow network (three layers or less) for image reconstruction.",G06N 3/08; G06N 3/04; G06N 99/00; A61B 6/03; A61B 5/055; A61B 5/00,RENSSELAER POLYTECHNIC INSTITUTE,"WANG, Ge; CONG, Wenxiang; YANG, Qingsong","62/354,319 24.06.2016 US",
WO2017009396,PCT/EP2016/066698,13.07.2016,WO/2017/009396,19.01.2017,WO,HYBRID MACHINE LEARNING SYSTEMS,"A hybrid machine learning system (100, 200, 300, 400, 500, 600, 700, 800) is for processing image data (110, 210, 310, 410, 510, 610, 710, 810) obtained from an image sensor (105, 205, 305, 405, 505, 605, 705, 805). The system comprises a front end (115, 215, 315, 415, 515, 615, 715, 815) comprising one or more hard-coded filters (120, 220, 320, 420, 520, 620, 720, 820). Each of the one or more hard-coded filters is arranged to perform a set task. The system also comprises a neural network (125, 225, 325, 425, 525, 625, 725, 825) arranged to receive and process output from the front end. The one or more hard-coded filters include one or more hard-coded noise compensation filters that are hard-coded to compensate for a noise profile of the image sensor from which the image data is obtained.",G06K 9/46; G06K 9/40; G06K 9/34,APICAL LIMITED,"ROMANENKO, Ilya",1512278.1 14.07.2015 GB,GB-1802349.9
WO2018160267,PCT/US2018/000013,16.02.2018,WO/2018/160267,07.09.2018,WO,CLOUD BASED ROBOTIC CONTROL SYSTEMS AND METHODS,"A method of controlling an operation of a robot (102) is provided using a cluster of nodes (104) in a network (106). The method includes receiving, using a gateway cloud driver (108), robot state information from the robot (102) via the network (106), and converting, using the gateway cloud driver (108), the robot state information into at least one message. The method further includes transmitting, using a message broker (110), the at least one message to the cluster of nodes (104) via the network (106). The method further includes processing, using the cluster of nodes (104) in the network ( 106), the at least one message by parallel computing, and generating, using the cluster of nodes (104) in the network (106), a robot command to control the operation of the robot (102).",G06F 19/00,INDIANA UNIVERSITY RESEARCH AND TECHNOLOGY CORPORATION,"FOX, Geoffrey, C.; KAMBURUGAMUVE LOKU ACHARIGE, Supun, M.","62/459,967 16.02.2017 US",
EP74228501,10824490,08.10.2010,2492850,29.08.2012,EP,SOCIAL ROBOT,"Social robot formed by an artificial vision system composed of webcam cameras (3), a voice recognition system formed by three microphones (4) arranged in a triangular configuration, an expression system composed of an LED matrix, formed by a plurality of LEDs and a status LED, and eyelids (6) formed by half-moons connected to gearwheels which engage with respective servomotors via transmission wheels, a speech synthesis system composed of loudspeakers (7), a system for detecting obstacles which is formed by ultrasound sensors (8), and a movement system formed by two driving wheels (9).",G06N 3/00; B25J 5/00; B25J 11/00; B25J 13/00; B25J 19/02,THECORPORA S L,PAZ RODRIGUEZ FRANCISCO JAVIER,200902021 21.10.2009 ES; 2010000409 08.10.2010 ES,
WO2019081660,PCT/EP2018/079323,25.10.2018,WO/2019/081660,02.05.2019,WO,"HARDWARE MODULE, ROBOTIC SYSTEM, AND METHOD FOR OPERATING THE ROBOTIC SYSTEM","A robotic system comprises at least two Hardware Modules (3), each comprising at least one sensor (38) for measuring an internal property, a communication unit (37), a data storage unit (36) and an embedded controller (35). The embedded controller (35) is configured to collect collected data comprising: - status data representing the current status of the Hardware Module (3); and - operating data representing usage of the Hardware Module (3). At least part of the collected data is determined from sensor data, and the embedded controller (35) is configured to store or transmit the collected data. The robotic system comprises a central computation and command unit (10) configured to receive the collected data; and to control operation of the robotic system by controlling operation of at least one actuator (39) of the at least two Hardware Modules (3).",B25J 9/08; B25J 9/16,FESTO SE & CO. KG,"RIEK, Alfons; STOLL, Kurt; KLINGEL, Hans; AESCHLIMANN, Marcel; MALZACH, Samuel; SIGRIST, Martin; SCHMID, Christian; BERGER, Christoph; CHAPELAT, Carole; IANNUCCI, Kilian; KRAUSE, Alexandra",17198996.5 27.10.2017 EP,
WO2019216578,PCT/KR2019/004887,23.04.2019,WO/2019/216578,14.11.2019,WO,METHOD AND APPARATUS FOR EXECUTING CLEANING OPERATION,"A robotic cleaning apparatus for performing a cleaning operation and a method of cleaning a cleaning space therefor are provided. The method includes acquiring contamination data indicating a contamination level of the cleaning space, acquiring contamination map data based on the contamination data, determining at least one cleaning target area in the cleaning space, based on a current time and the contamination map data, and cleaning the determined at least one cleaning target area. The method and apparatus may relate to artificial intelligence (AI) systems for mimicking functions of human brains, e.g., cognition and decision, by using a machine learning algorithm such as deep learning, and applications thereof.",A47L 9/28; G05D 1/02; G06N 3/08; B25J 11/00; B25J 9/16,"SAMSUNG ELECTRONICS CO., LTD.","HAN, Seungbeom; KUK, Junggap; KIM, Hyunsuk; JANG, Kyunghun","62/670,149 11.05.2018 US; 10-2018-0143896 20.11.2018 KR",
WO2018175698,PCT/US2018/023726,22.03.2018,WO/2018/175698,27.09.2018,WO,CONTINUOUSLY LEARNING AND OPTIMIZING ARTIFICIAL INTELLIGENCE (AI) ADAPTIVE NEURAL NETWORK (ANN) COMPUTER MODELING METHODS AND SYSTEMS,"Continuously learning and optimizing artificial intelligence (AI) adaptive neural network (ANN) computer modeling methods and systems, designated human affect computer modeling (HACM) or affective neuron (AN), and, more particularly, to AI methods, systems and devices that can recognize, interpret, process and simulate human reactions and affects such as emotional responses to internal and external sensory stimuli, that provides real-time reinforcement learning modeling that reproduces human affects and/or reactions, wherein the human affect modeling (HACM) can be used singularly or collectively to modeling and predict complex human reactions and affects.",B25J 9/16; G06E 1/00; G06E 3/00; G06F 15/18,LARSX,"WOOD, Laurence F.; WOOD, Lisa S.","62/474,888 22.03.2017 US",
WO2019202487,PCT/IB2019/053109,16.04.2019,WO/2019/202487,24.10.2019,WO,ROBOTIC CAMERA SOFTWARE AND CONTROLLER,"A robotic camera system comprising: a robot head (45), for carrying and orienting a camera (48), a video capture unit (30), operatively arranged to capture video and/audio recording from the camera and storing in a frame buffer area (260), a processor unit (40), having access to the frame buffer area (260) and operatively arranged for generating a reference camera trajectory (130) based on directives from a director, optimizing (140) said camera trajectory based on a real-time projection of objects of interest in the video recording in the frame buffer area (260), driving the robot head (45) to follow the optimized trajectory.",B25J 9/16,ETH ZURICH,"KARIOTOGLOU, Nikolaos; HOFMANN, Reto",0490/18 17.04.2018 CH,
EP45086871,11180042,05.09.2011,2428335,14.03.2012,EP,Robot and control method thereof,"A robot, which performs natural walking similar to a human with high energy efficiency through optimization of actuated dynamic walking, and a control method thereof. The robot includes an input unit to which a walking command of the robot is input, and a control unit to control walking of the robot by calculating torque input values through control variables, obtaining a resultant motion of the robot through calculation of forward dynamics using the torque input values, and minimizing a value of an objective function set to consist of the sum total of a plurality of performance indices through adjustment of the control variables.",B25J 9/16; B62D 57/032,SAMSUNG ELECTRONICS CO LTD,LIM BOK MAN; ROH KYUNG SHIK; KWON WOONG; LEE JU SUK,20100088337 09.09.2010 KR,
WO2019242846,PCT/EP2018/066280,19.06.2018,WO/2019/242846,26.12.2019,WO,METHODS AND ARRANGEMENTS FOR CONTROLLING A ROBOT DEVICE OVER A WIRELESS NETWORK,"Methods and arrangements for controlling a robot device(202)by a control device (206) over a radio communication network using a video session are disclosed. Control commands from the control device are embedded (S226) into a down-stream video stream and delivered over the communication network (210) after which the control commands are extracted (S212) from down-stream video stream and provided to the robot device. Sensor data from the robot device, based on the control commands, are embedded (S218) in an up-stream video stream and delivered over the communication network, after which the sensor data is extracted (S220) from the up-stream video stream and provided to the control device. The control device may then determine updated control commands based on the provided sensor data. The quality of service used in the video session over thecommunication network is herein suitable for controlling the robot deviceby the control device.",H04W 72/04; B25J 9/16; H04L 29/08; B25J 13/00; G05D 1/00,TELEFONAKTIEBOLAGET LM ERICSSON (PUBL),"SZABO, Geza; BÁDER, Attila; FORMANEK, Bence; RÁCZ, Sándor",,
WO2017220966,PCT/GB2017/051679,09.06.2017,WO/2017/220966,28.12.2017,WO,DETECTING OBJECTS IN VIDEO DATA,"Certain examples described herein enable semantically-labelled representations of a three-dimensional (3D) space to be generated from video data. In described examples, a 3D representation is a surface element or 'surfel' representation, where the geometry of the space is modelled using a plurality of surfaces that are defined within a 3D co- ordinate system. Object-label probability values for spatial elements of frames of video data may be determined (605) using a two-dimensional image classifier. Surface elements that correspond to the spatial elements are identified (610) based on a projection of the surface element representation using an estimated pose for a frame. Object-label probability values for the surface elements are then updated (615) based on the object-label probability values for corresponding spatial elements. This results in a semantically-labelled 3D surface element representation of objects present in the video data. This data enables computer vision and/or robotic applications to make better use of the 3D representation.",G06K 9/00; G06F 17/00; G06K 9/62,"IMPERIAL COLLEGE OF SCIENCE, TECHNOLOGY AND MEDICINE","MCCORMAC, John Brendan; HANDA, Ankur; DAVISON, Andrew; LEUTENEGGER, Stefan",1611033.0 24.06.2016 GB,CN-201780051781.9; SG-11201811330W; AU-2017281822; EP-2017740064; RU-2019101759; KR-1020197002338; JP-2018567057
WO2016142351,PCT/EP2016/054824,07.03.2016,WO/2016/142351,15.09.2016,WO,ROBOTIC COMPANION SENSITIVE TO PHYSIOLOGICAL DATA GATHERED BY WEARABLE DEVICES,"A system enabling one or more of a robotic companion's actions to be determined as a function of a user's wearable device sensor readings such that the robotic companion may provide the user with visual, aural, and/or other types of feedback when a sensor reading meets or breaks one or more rules. At a high level, aspects of the present disclosure are directed to systems, methods, and software for enabling a robotic companion to perform an action as a function of a user's wearable device sensor readings. In an embodiment, a user may specify one or more rules that determine how a robotic companion will respond as a function of one or more sensor readings received from a wearable device.",G06N 5/00; G06F 19/00; G06N 99/00,KONINKLIJKE PHILIPS N.V.,"CRONIN, John; BODKIN, Joseph","62/130,201 09.03.2015 US; 15176440.4 13.07.2015 EP",
EP248178114,18206656,16.11.2018,3508937,10.07.2019,EP,MOBILE CLEANING ROBOT ARTIFICIAL INTELLIGENCE FOR SITUATIONAL AWARENESS,"A mobile cleaning robot includes a cleaning head configured to clean a floor surface in an environment, and at least one camera having a field of view that extends above the floor surface. The at least one camera is configured to capture images that include portions of the environment above the floor surface. The robot includes a recognition module is configured to recognize objects in the environment based on the images captured by the at least one camera, in which the recognition module is trained at least in part using the images captured by the at least one camera. The robot includes a storage device is configured to store a map of the environment. The robot includes a control module configured to control the mobile cleaning robot to navigate in the environment using the map and operate the cleaning head to perform cleaning tasks taking into account of the objects recognized by the recognition module.",G05D 1/02; G06K 9/00,IROBOT CORP,JONES CHRISTOPHER V; HALL GARY ELLIS; BARON STEVEN J; HILD BRENT; ZICKLER STEFAN; SINNIGEN JOHN,201815863591 05.01.2018 US,
WO2015058297,PCT/CA2014/051016,21.10.2014,WO/2015/058297,30.04.2015,WO,IMAGE-BASED TRAJECTORY ROBOT PROGRAMMING PLANNING APPROACH,"A method of programming at least one robot by demonstration comprising : performing at least one demonstration of at least one task in the Held of view of at least one fixed camera to obtain at least one observed task trajectory of at least one manipulated object, preferably at least one set of observed task trajectories; generating a generalized task trajectory from said at least one observed task trajectory, preferably from said at least one set of observed task trajectories; and executing said at least one task by said at least one robot in the field of view of said at least one fixed camera, preferably using image-based visual servoing to minimize the difference between the executed trajectory during said execution and the generalized task trajectory.",B25J 9/22; B25J 13/08; B25J 19/02; B25J 19/04; G05B 17/02; H04N 5/341,"VAKANSKI, Aleksandar; JANABI-SHARIFI, Farrokh","VAKANSKI, Aleksandar; JANABI-SHARIFI, Farrokh","61/895,721 25.10.2013 US",US-15031779; CA-2928645
EP14359518,02775338,11.10.2002,1552908,13.07.2005,EP,"ROBOT CONTROL ALGORITHM CONSTRUCTION DEVICE, ROBOT CONTROL ALGORITHM CONSTRUCTION PROGRAM, ROBOT CONTROL DEVICE, ROBOT CONTROL PROGRAM, AND ROBOT","The present invention relates to a control algorithm constructing device that constructs a control algorithm controlling the motion of a robot, and a controller that controls the motion of the robot in accordance with the constructed control algorithm, with the purpose of reducing the cost and time taken to create the control algorithm as compared with the conventional method such as an MZP method to solve a mechanical equation, in which the control algorithm is constructed by a recurrent neural network (RNN) including a neuron generating an output with an analogue lag with respect to an input, the coefficients of the RNN are determined in succession from the term of lower degree to the term of higher degree. <IMAGE>",B25J 9/16; G06F 19/00; G06N 3/00; G06N 3/02; G06N 3/04,FUJITSU LTD,NAGASHIMA FUMIO,0210622 11.10.2002 JP,
WO2019157633,PCT/CN2018/076659,13.02.2018,WO/2019/157633,22.08.2019,WO,INTELLIGENT SERVICE TERMINAL AND PLATFORM SYSTEM AND METHODS THEREOF,"An intelligence service platform comprises an input module, a deep learning engine based on a human mind deep learning model and an output module. The input module is configured to receive user related information collected by an intelligence service terminal. The deep learning model describes a manner that the brain encodes information, and the human mind deep learning model is trained based on individual related history data and further adjusted by individual's daily responses collected by the intelligence service terminal in use. The deep learning engine is further configured to identify the user' intention or emotion from the received user related information and generate a corresponding response or command output. The output module can be configured to provide the corresponding response or command output to the intelligence service terminal. With embodiments of the present disclosure, the deep learning model could be trained based on individual related history data and further adjusted by individual's daily responses collected by the intelligence service terminal in use, and thus the robot can learn from the user day by day and output appropriate commands or response for respective users accordingly without requiring pre-defined instructions and messages.",G06Q 50/00; A61B 5/16,NEC HONG KONG LIMITED; HUMAN CENTRED INNOVATIONS PTY. LTD .,"WONG, Yukkuen; KHOSLA, Rajiv",,CN-201880009316.3
WO2020016717,PCT/IB2019/055961,12.07.2019,WO/2020/016717,23.01.2020,WO,PERFORM PEG-IN-HOLE TASK WITH UNKNOWN TILT,"A computer-implemented method executed by a robotic system for performing a positional search process in an assembly task is presented. The method includes applying forces to a first component to be inserted into a second component, detecting the forces applied to the first component by employing a plurality of force sensors attached to a robotic arm of the robotic system, extracting training samples corresponding to the forces applied to the first component, normalizing time-series data for each of the training samples by applying a variable transformation about a right tilt direction, creating a time-series prediction model of transformed training data, applying the variable transformation with different directions for a test sample, and calculating a matching ratio between the created time- series prediction model and the transformed test sample.",G05B 13/02,INTERNATIONAL BUSINESS MACHINES CORPORATION; IBM UNITED KINGDOM LIMITED; IBM (CHINA) INVESTMENT COMPANY LIMITED,"YOSHIZUMI, Takayuki","16/039,879 19.07.2018 US",
WO2020041237,PCT/US2019/047152,20.08.2019,WO/2020/041237,27.02.2020,WO,BRAIN OPERATING SYSTEM,"Embodiments may provide an intelligent adaptive system that combines input data types, processing history and objectives, research knowledge, and situational context to determine the most appropriate mathematical model, choose the computing infrastructure, and propose the best solution for a given problem. For example, a method implemented in a computer may comprise receiving, at the computer system, data relating to a problem to be solved, generating, at the computer system, a description of the problem, wherein the description conforms to defined format, obtaining, at the computer system, at least one machine learning model relevant to the problem, selecting, at the computer system, computing infrastructure upon which to execute the at least one machine learning model relevant to the problem, and executing, at the computer system, the at least one machine learning model relevant to the problem using the selected computing infrastructure to generate at least one recommendation relevant to the problem.",G06N 3/00; G06N 20/00; G06N 99/00,"HOWARD, Newton","HOWARD, Newton","16/545,205 20.08.2019 US; 62/719,849 20.08.2018 US; 62/726,699 04.09.2018 US; 62/783,050 20.12.2018 US",
WO2013085799,PCT/US2012/067108,29.11.2012,WO/2013/085799,13.06.2013,WO,APPARATUS AND METHODS FOR IMPLEMENTING LEARNING FOR ANALOG AND SPIKING SIGNALS IN ARTIFICIAL NEURAL NETWORKS,"Apparatus and methods for universal node design implementing a universal learning rule in a mixed signal spiking neural network. In one implementation, at one instance, the node apparatus, operable according to a parameterized universal learning model, receives a mixture of analog and spiking inputs, and generates a spiking output based on the model parameter for that node that is selected by the parameterized model for that specific mix of inputs. At another instance, the same node receives a different mix of inputs, that also may comprise only analog or only spiking inputs and generates an analog output based on a different value of the node parameter that is selected by the model for the second mix of inputs. In another implementation, the node apparatus may change its output from analog to spiking responsive to a training input for the same inputs.",G06N 3/00,BRAIN CORPORATION,"PONULAK, Filip","13/313,826 07.12.2011 US",
WO2020058669,PCT/GB2019/052520,10.09.2019,WO/2020/058669,26.03.2020,WO,TASK EMBEDDING FOR DEVICE CONTROL,"A control system for a robotic device comprising a task embedding network to receive one or more demonstrations of a task and to generate a task embedding. The task embedding comprises a representation of the task, and each demonstration comprises one or more observations of a performance of the task. The control system includes a control network to receive the task embedding from the task embedding network and to apply a policy to map a plurality of successive observations of the robotic device to respective control instructions for the robotic device. The policy applied by the control network is modulated across the plurality of successive observations of the robotic device using the task embedding from the task embedding network.",G06N 3/04; G06N 3/08; B25J 9/16,"IMPERIAL COLLEGE OF SCIENCE, TECHNOLOGY AND MEDICINE","JAMES, Stephen Lloyd; BLOESCH, Michael; DAVISON, Andrew",1815431.0 21.09.2018 GB,
WO2019082165,PCT/IB2018/058410,26.10.2018,WO/2019/082165,02.05.2019,WO,GENERATING COMPRESSED REPRESENTATION NEURAL NETWORKS HAVING HIGH DEGREE OF ACCURACY,"Machine learning based models, for example, neural network models employ large numbers of parameters, from a few million to hundreds of millions or more. A machine learning based model is trained using fewer parameters than specified. An initial parameter vector is initialized, for example, using random number generation based on a seed. During training phase, the parameter vectors are modified in a subspace around the initial vector. The trained model can be stored or transmitted using seed values and the trained parameter vector in the subspace. The neural network model can be uncompressed using the seed values and the trained parameter vector in the subspace. The compressed representation of neural networks may be used for various applications such as generating maps, object recognition in images, processing of sensor data, natural language processing, and others.",G06N 3/08; G06N 99/00,"UBER TECHNOLOGIES, INC.","YOSINSKI, Jason; LI, Chunyuan; LIU, Rosanne","62/577,662 26.10.2017 US",
EP232832040,18167866,17.04.2018,3399471,07.11.2018,EP,EFFICIENT LEARNING AND USING OF TOPOLOGIES OF NEURAL NETWORKS IN MACHINE LEARNING,"A mechanism is described for facilitating learning and application of neural network topologies in machine learning at autonomous machines. A method of embodiments, as described herein, includes monitoring and detecting structure learning of neural networks relating to machine learning operations at a computing device having a processor, and generating a recursive generative model based on one or more topologies of one or more of the neural networks. The method may further include converting the generative model into a discriminative model.",G06N 7/00; G06N 3/04,INTEL CORP,YEHEZKEL ROHEKAR RAANAN YONATAN; KOREN GUY; NISIMOV SHAMI; NOVIK GAL,201715659853 26.07.2017 US; 201762501794 05.05.2017 US,
WO2020056301,PCT/US2019/051067,13.09.2019,WO/2020/056301,19.03.2020,WO,ROBOT INTERACTION WITH HUMAN CO-WORKERS,"Embodiments provide functionality to prevent collisions between robots and objects. An example embodiment detects a type and a location of an object based on a camera image of the object, where the image has a reference frame. Motion of the object is then predicted based on at least one of: the detected type of the object, the detected location of the object, and a model of object motion. To continue, a motion plan for the robot is generated that avoids having the robot collide with the object based on the predicted motion of the object and a transformation between the reference frame of the image and a reference frame of the robot. The robot can be controlled to move in accordance with the motion plan or a signal can be generated that controls the robot to operate in accordance with the motion plan.",B25J 9/16,"THE CHARLES STARK DRAPER LABORATORY, INC.","JOHNSON, David, M.S.; WAGNER, Syler; LINES, Steven","62/731,398 14.09.2018 US; 62/730,947 13.09.2018 US; 62/730,703 13.09.2018 US; 62/730,933 13.09.2018 US; 62/730,918 13.09.2018 US; 62/730,934 13.09.2018 US",
WO2019190627,PCT/US2019/015931,30.01.2019,WO/2019/190627,03.10.2019,WO,SYSTEM AND METHOD FOR ESTIMATING UNCERTAINTY OF THE DECISIONS MADE BY A SUPERVISED MACHINE LEARNER,"Described is a system for controlling autonomous platform. Based on an input image, the system generates a motor control command decision for the autonomous platform. A probability of the input image belonging to a set of training images is determined, and a reliability measure for the motor control command decision is generated using the determined probability. An exploratory action is performed when the reliability measure is above a predetermined threshold. Otherwise, an exploitation action corresponding with the motor control command decision is performed when the reliability measure is below a predetermined threshold.",G05D 1/00; G05B 15/02; G06N 3/08,"HRL LABORATORIES, LLC","KOLOURI, Soheil; HOFFMANN, Heiko","62/648,304 26.03.2018 US",
WO2020064994,PCT/EP2019/076154,27.09.2019,WO/2020/064994,02.04.2020,WO,REINFORCEMENT LEARNING NEURAL NETWORKS GROUNDED IN LEARNED VISUAL ENTITIES,A reinforcement learning neural network system in which internal representations and policies are grounded in visual entities derived from image pixels comprises a visual entity identifying neural network subsystem configured to process image data to determine a set of spatial maps representing respective discrete visual entities. A reinforcement learning neural network subsystem processes data from the set of spatial maps and environmental reward data to provide action data for selecting actions to perform a task.,G06N 3/04; G06N 3/08; G06N 3/00,DEEPMIND TECHNOLOGIES LIMITED,"IONESCU, Catalin-Dumitru; KULKARNI, Tejas Dattatraya","62/737,850 27.09.2018 US",
WO2017151466,PCT/US2017/019599,27.02.2017,WO/2017/151466,08.09.2017,WO,MODULAR DEEP LEARNING MODEL,"The technology described herein uses a modular model to process speech. A deep learning based acoustic model comprises a stack of different types of neural network layers. The sub-modules of a deep learning based acoustic model can be used to represent distinct non-phonetic acoustic factors, such as accent origins (e.g. native, non-native), speech channels (e.g. mobile, bluetooth, desktop etc.), speech application scenario (e.g. voice search, short message dictation etc.), and speaker variation (e.g. individual speakers or clustered speakers), etc. The technology described herein uses certain sub-modules in a first context and a second group of sub-modules in a second context.",G10L 15/065; G06N 3/04; G10L 15/16,"MICROSOFT TECHNOLOGY LICENSING, LLC","HUANG, Yan; LIU, Chaojun; KUMAR, Kshitiz; KALGAONKAR, Kaustubh Prakash; GONG, Yifan","62/304,133 04.03.2016 US; 15/199,346 30.06.2016 US",EP-2017711396
WO2019099633,PCT/US2018/061231,15.11.2018,WO/2019/099633,23.05.2019,WO,SYSTEMS AND METHODS FOR GENERATING SPARSE GEOGRAPHIC DATA FOR AUTONOMOUS VEHICLES,"Systems and methods for generating sparse geographic data for autonomous vehicles are provided. In one example embodiment, a computing system can obtain sensor data associated with at least a portion of a surrounding environment of an autonomous vehicle. The computing system can identify a plurality of lane boundaries within the portion of the surrounding environment of the autonomous vehicle based at least in part on the sensor data and a first machine-learned model. The computing system can generate a plurality of polylines indicative of the plurality of lane boundaries based at least in part on a second machine-learned model. Each polyline of the plurality of polylines can be indicative of a lane boundary of the plurality of lane boundaries. The computing system can output a lane graph including the plurality of polylines.",G01C 21/36; G01S 17/89; G06N 3/04; G06K 9/00,"UATC, LLC","HOMAYOUNFAR, Namdar; MA, Wei-Chiu; LAKSHMIKANTH, Shrinidhi Kowshika; URTASUN, Raquel","62/586,770 15.11.2017 US; 16/123,343 06.09.2018 US",
WO2019222401,PCT/US2019/032486,15.05.2019,WO/2019/222401,21.11.2019,WO,GRADIENT ADVERSARIAL TRAINING OF NEURAL NETWORKS,"Systems and methods for gradient adversarial training of a neural network are disclosed. In one aspect of gradient adversarial training, an auxiliary neural network can be trained to classify a gradient tensor that is evaluated during backpropagation in a main neural network that provides a desired task output. The main neural network can serve as an adversary to the auxiliary network in addition to a standard task-based training procedure. The auxiliary neural network can pass an adversarial gradient signal back to the main neural network, which can use this signal to regularize the weight tensors in the main neural network. Gradient adversarial training of the neural network can provide improved gradient tensors in the main network. Gradient adversarial techniques can be used to train multitask networks, knowledge distillation networks, and adversarial defense networks.",G06N 3/08; G06N 3/04,"MAGIC LEAP, INC.","SINHA, Ayan Tuhinendu; RABINOVICH, Andrew; CHEN, Zhao; BADRINARAYANAN, Vijay","62/673,116 17.05.2018 US",
WO2020016871,PCT/IB2019/057342,30.08.2019,WO/2020/016871,23.01.2020,WO,ROBOTIC SYSTEMS WITH SEPARATE PHOTOACOUSTIC RECEIVERS,"A surgical robotic visualization system (5900) comprises a first robotic arm (5912), a second robotic arm (5914), a photoacoustic receiver (5902) coupled to the first robotic arm (5912), an emitter assembly (5904) coupled to the second robotic arm (5914), and a control circuit. The control circuit is configured to cause the emitter assembly (5904) to emit electromagnetic radiation (5905) toward an anatomical structure (103) at a plurality of wavelengths capable of penetrating the anatomical structure (103) and reaching an embedded structure (101) located below a surface (105) of the anatomical structure (103), receive an input of the photoacoustic receiver (5902) indicative of an acoustic response signal of the embedded structure (101), and detect the embedded structure (101) based on the input from the photoacoustic receiver (5902).",A61B 5/00; A61B 5/107; A61B 17/04; A61B 17/062; A61B 34/30; A61B 90/30; A61B 90/00; G01B 11/25; G01N 21/25; G01N 21/31; G01S 17/89; A61B 1/00; A61B 1/04; A61B 1/06,ETHICON LLC,"SCHEIB, Charles J.; RITCHIE, Paul G.; MOORE, Sarah A.; SWAYZE, Jeffrey S.; TALBERT, Joshua D.; YOUNG, Joshua D.; MORENO, Victor C.","62/698,625 16.07.2018 US; 16/128,172 11.09.2018 US",
WO2016014137,PCT/US2015/029438,06.05.2015,WO/2016/014137,28.01.2016,WO,"APPARATUSES, METHODS, AND SYSTEMS FOR DEFINING HARDWARE-AGNOSTIC BRAINS FOR AUTONOMOUS ROBOTS","Conventionally, robots are typically either programmed to complete tasks using a programming language (either text or graphical), shown what to do for repetitive tasks, or operated remotely by a user. The present technology replaces or augments conventional robot programming and control by enabling a user to define a hardware-agnostic brain that uses Artificial Intelligence (AI) systems, machine vision systems, and neural networks to control a robot based on sensory input acquired by the robot's sensors. The interface for defining the brain allows the user to create behaviors from combinations of sensor stimuli and robot actions, or responses, and to group these behaviors to form brains. An Application Program Interface (API) underneath the interface translates the behaviors' inputs and outputs into API calls and commands specific to particular robots. This allows the user to port brains among different types of robot to robot without knowing specifics of the robot commands.",G06N 3/08,"NEURALA, INC.; GORCHETCHNIKOV, Anatoli; AMES, Heather Marie","GORCHETCHNIKOV, Anatoli; AMES, Heather Marie; VERSACE, Massimiliano; MATUS, Roger; DEFREITAS, Alexandrea; AMADEO, Mike; SEEMANN, Tim; MARSH, Ethan","61/989,332 06.05.2014 US",
EP133853566,13752693,11.07.2013,2874037,20.05.2015,EP,AUTONOMOUS ALL TERRAIN ROBOTICS VEHICLE,"The present invention is a multi-purpose service robot for robust operation in all-terrain outdoor environments, is aimed to fulfill the requirements of a robotic platform that is able to support the development of real world applications in surveillance, agriculture, environmental monitoring, and other related domains. This demanding scenario motivated a design mainly focused around the reliability of the mechanical platform, the scalability of the control system, and the flexibility of its self-diagnosis and error recovery mechanisms. These are key features for actual service robots, however usually disregarded in robotics. The present invention is made of durable materials, and with no-slip quasi-omnidirectional kinematic characteristics shown to be adequate for rough terrain. Supported by a control system fully compliant with the widespread Robot Operating System (ROS), scalability is guaranteed. The integration of active self-diagnosis and error recovery mechanisms extends system functionality for long duration tasks.",G05D 1/02,INTROSYS INTEGRATION FOR ROBOTIC SYSTEMS INTEGRACAO DE SIST ROBOTICOS S A,FIGUEIREDO SANTANA PEDRO; BENTES MOITA FLORES LUÍS MIGUEL; BENTES MOITA FLORES NUNO MANUEL; DA SILVA GUEDES MAGNO EDGAR; MARTINS DEUSDADO PEDRO MIGUEL; DA CRUZ HENRIQUES NUNO ANDRADE; PARREIRA E CORREIA LUÍS MIGUEL,10643912 11.07.2012 PT; 2013000041 11.07.2013 PT,
WO2019207577,PCT/IL2019/050449,18.04.2019,WO/2019/207577,31.10.2019,WO,SYSTEM AND METHOD FOR TRAINING A MACHINE-LEARNING MODEL TO IDENTIFY REAL-WORLD ELEMENTS,"A method and a system for training a machine-learning model to identify real-world elements using a simulated environment (SE) may include (a) receiving at least one set of appearance parameters, corresponding to appearance of real-world element; (b) generating one or more realistic elements, each corresponding to a variant of at least one real-world element; (c) generating one or more abstract-elements; (d) placing the elements within the SE; (e) producing at least one synthetic image from the SE; (f) providing the at least one synthetic image to a machine-learning model; and (g) training the machine-learning model to identify at least one real-world element from the at least one synthetic image, that corresponds to at least one realistic element in the SE.",G06K 9/00; G06F 15/18; G06N 3/08,IMAGRY (ISRAEL) LTD.,"TEN, Sergey; KESELMAN, Jose Ariel; HABIB, Suhail; ABU DBAI, Abed; GHAZALI, Adham; JUBEH, Majed; ORR, Itai","15/961,892 25.04.2018 US",
WO2018035473,PCT/US2017/047639,18.08.2017,WO/2018/035473,22.02.2018,WO,PROCESSING FUNDUS IMAGES USING MACHINE LEARNING MODELS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for processing fundus images using fundus image processing machine learning models. One of the methods includes obtaining a model input comprising one or more fundus images, each fundus image being an image of a fundus of an eye of a patient; processing the model input using a fundus image processing machine learning model, wherein the fundus image processing machine learning model is configured to process the model input comprising the one or more fundus image to generate a model output; and processing the model output to generate health analysis data.",G06F 19/00,GOOGLE LLC,"PENG, Lily Hao Yi; WEBSTER, Dale R.; NELSON, Philip Charles; GULSHAN, Varun; CORAM, Marc Adlai; STUMPE, Martin Christian; WU, Derek Janme; NARAYANASWAMY, Arunachalam; VARADARAJAN, Avinash Vaidyanathan; BLUMER, Katharine; LIU, Yun; POPLIN, Ryan","62/376,860 18.08.2016 US",JP-2019508910; CN-201780055989.8; KR-1020197007602; EP-2017784047
WO2017209660,PCT/RU2017/050048,05.06.2017,WO/2017/209660,07.12.2017,WO,LEARNABLE VISUAL MARKERS AND METHOD OF THEIR PRODUCTION,"This technical solution refers to methods for production of a family of visual markers capable of encoding information in robotics, virtual and augmented reality domains. A synthesizing neural network that converts a sequence of bits into images of visual markers, a rendering neural network that converts input images of visual markers into images comprising visual markers, and a recognizing neural network that converts images containing visual markers into a bit sequence are created The synthesizing, rendering and recognizing neural networks are trained jointly via the minimization of the loss function, reflecting a probability of correct recognition of random bit sequences. A localizing neural network that translates images comprising a marker to various marker position parameters instead of or in addition to the recognizing neural network is created. The technical result is an increase in accuracy of recognition and localization of visual markers.",G06N 3/02; G05B 13/02; G06T 1/00,AUTONOMOUS NON-PROFIT ORGANIZATION FOR HIGHER EDUCATION «SKOLKOVO INSTITUTE OF SCIENCE AND TECHNOLOGY»,"LEMPITSKY, Victor Sergeevich",2016122082 03.06.2016 RU,
WO2020072785,PCT/US2019/054519,03.10.2019,WO/2020/072785,09.04.2020,WO,ROBOTIC DRAWING,"A method includes providing a robot, providing an image of drawn handwritten characters to the robot, enabling the robot to capture a bitmapped image of the image of drawn handwritten characters, enabling the robot to infer a plan to replicate the image with a writing utensil, and enabling the robot to reproduce the image.",G06K 9/00; A61F 2/72; B25J 9/02; G06K 9/18; G06K 9/62,BROWN UNIVERSITY,"TELLEX, Stefanie; KOTANI, Atsunobu","62/741,323 04.10.2018 US",
WO2015103520,PCT/US2015/010114,05.01.2015,WO/2015/103520,09.07.2015,WO,DISTRIBUTED TRAINING OF A MACHINE LEARNING MODEL TO DETECT NETWORK ATTACKS IN A COMPUTER NETWORK,"Training method to train machine learning model (e.g., neural network) used to identify attacks in a network (e.g., denial of service). A first data set is received by a network device that is indicative of the statuses of a plurality of network devices when a type of network attack is not present. A second data set is also received that is indicative of the statuses of the plurality of network devices when the type of network attack is present. At least one of the plurality simulates the type of network attack by operating as an attacking node. A machine learning model is trained using the first and second data set to identify the type of network attack. A real network attack is then identified using the trained machine learning model. Application in Low Power and Lossy Networks.",H04L 12/24; H04L 29/06,"CISCO TECHNOLGY, INC.","VASSEUR, Jean-Philippe; CRUZ MOTA, Javier; DI PIETRO, Andrea","61/923,847 06.01.2014 US; 14/164,446 27.01.2014 US",EP-2015700405
EP248178111,18206641,16.11.2018,3508935,10.07.2019,EP,SYSTEM FOR SPOT CLEANING BY A MOBILE ROBOT,"A system for enabling spot cleaning includes a mobile computing device and a mobile cleaning robot. The mobile computing device includes at least one camera configured to capture images of an environment, and at least one data processor configured to (a) establish, based at least in part on first information provided by the at least one image sensor, a coordinate system in the environment, (b) determine, based at least in part on second information provided by the at least one camera, a first set of coordinates of a region at a first location, (c) determine, based at least in part on third information provided by the at least one camera, a second set of coordinates of a mobile cleaning robot at a second location, (d) send the first set of coordinates and second set of coordinates, or coordinates of the first location relative to the second location, to the mobile cleaning robot, and (e) send an instruction to the mobile cleaning robot to request the mobile cleaning robot to travel to the first location.",G05D 1/00; G05B 15/00; G05D 1/02,IROBOT CORP,BASSA ANGELA; AL-MOHSSEN HUSAIN,201815863705 05.01.2018 US,
WO2015066386,PCT/US2014/063265,30.10.2014,WO/2015/066386,07.05.2015,WO,PREDICTING RECOGNITION QUALITY OF A PHRASE IN AUTOMATIC SPEECH RECOGNITION SYSTEMS,"A method for predicting a speech recognition quality of a phrase comprising at least one word includes: receiving, on a computer system including a processor and memory storing instructions, the phrase; computing, on the computer system, a set of features comprising one or more features corresponding to the phrase; providing the phrase to a prediction model on the computer system and receiving a predicted recognition quality value based on the set of features; and returning the predicted recognition quality value.",G10L 15/01; G10L 15/02; G10L 15/183,"GREENEDEN U.S. HOLDINGS II, LLC","LEV-TOV, Amir; FAIZAKOF, Avraham; KONIG, Yochai","14/067,732 30.10.2013 US",CN-201480071972.8; EP-2014858418
WO2014137767,PCT/US2014/019178,28.02.2014,WO/2014/137767,12.09.2014,WO,ADAPTING ROBOT BEHAVIOR BASED UPON HUMAN-ROBOT INTERACTION,"A robot for human-robot interaction includes a computer-readable memory that comprises a model that, with respect to successful completions of a task, eg distributing flyers, is fit to observed data, where at least some of such observed data pertains to a condition that is controllable by the robot, such as position of the robot or distance between the robot and a human. The task that is desirably performed by the robot is to cause the human to engage with the robot. The model is updated while the robot is online, such that behavior of the robot adapts over time to increase the likelihood that the robot will successfully complete the task.",G06N 3/00; G06Q 30/02,"MICROSOFT TECHNOLOGY LICENSING, LLC","FLORENCIO, Dinei A.; MACHARET, Douglas Guimaraes; BOHUS, Dan","13/783,405 04.03.2013 US",CN-201480012191.1; EP-2014712825
WO2017091883,PCT/CA2015/051257,01.12.2015,WO/2017/091883,08.06.2017,WO,SYSTEM AND METHOD FOR IMPLEMENTING A VOCAL USER INTERFACE BY COMBINING A SPEECH TO TEXT SYSTEM AND A SPEECH TO INTENT SYSTEM,"The present disclosure relates to speech recognition systems and methods that enable personalized vocal user interfaces. More specifically, the present disclosure relates to combining a self-learning speech recognition system based on semantics with a speech-to- text system optionally integrated with a natural language processing system. The combined system has the advantage of automatically and continually training the semantics-based speech recognition system and increasing recognition accuracy.",G10L 15/02; G10L 15/197,FLUENT.AI INC.,"TOMAR, Vikrant; DESRUISSEAUX, Mathieu; SEETZEN, Helge",,US-15780576; EP-2015909433
WO2018063460,PCT/US2017/038504,21.06.2017,WO/2018/063460,05.04.2018,WO,SYSTEM AND METHOD FOR OPTIMIZATION OF DEEP LEARNING ARCHITECTURE,"A method for determining optimized deep learning architecture includes receiving a plurality of training images and a plurality of real time images corresponding to a subject. The method further includes receiving, by a medical practitioner, a plurality of learning parameters comprising a plurality of filter classes and a plurality of architecture parameters. The method also includes determining a deep learning model based on the plurality of learning parameters and the plurality of training images, wherein the deep learning model comprises a plurality of reusable filters. The method further includes determining a health condition of the subject based on the plurality of real time images and the deep learning model. The method also includes providing the health condition of the subject to the medical practitioner.",G06N 3/04; G06K 9/46,GENERAL ELECTRIC COMPANY,"THIRUVENKADAM, Sheshadri; RANJAN, Sohan Rashmi; VAIDYA, Vivek Prabhakar; RAVISHANKAR, Hariharan; VENKATARAMANI, Rahul; SUDHAKAR, Prasad",201641033618 30.09.2016 IN,
WO2018053246,PCT/US2017/051751,15.09.2017,WO/2018/053246,22.03.2018,WO,CONTROL POLICIES FOR ROBOTIC AGENTS,"A method includes: receiving data identifying, for each of one or more objects, a respective target location to which a robotic agent interacting with a real-world environment should move the object; causing the robotic agent to move the one or more objects to the one or more target locations by repeatedly performing the following: receiving a current image of a current state of the real-world environment; determining, from the current image, a next sequence of actions to be performed by the robotic agent using a next image prediction neural network that predicts future images based on a current action and an action to be performed by the robotic agent; and directing the robotic agent to perform the next sequence of actions.",G06N 3/04; G06N 3/00,GOOGLE LLC,"FINN, Chelsea, Breanna; LEVINE, Sergey, Vladimir","62/395,329 15.09.2016 US",JP-2019514296; CN-201780063614.6; EP-2017777714; KR-1020197010314
WO2017189859,PCT/US2017/029866,27.04.2017,WO/2017/189859,02.11.2017,WO,METHODS AND APPARATUS FOR PRUNING EXPERIENCE MEMORIES FOR DEEP NEURAL NETWORK-BASED Q-LEARNING,"The present technology involves collecting a new experience by an agent, comparing the new experience to experiences stored in the agent's memory, and either discarding the new experience or overwriting an experience in the memory with the new experience based on the comparison. For instance, the agent or an associated processor may determine how similar the new experience is to the stored experiences. If the new experience is too similar, the agent discards it; otherwise, the agent stores it in the memory and discards a previously stored experience instead. Collecting and selectively storing experiences based on the experiences' similarity to previously stored experiences addresses technological problems and yields a number of technological improvements. For instance, relieves memory size constraints, reduces or eliminates the chances of catastrophic forgetting by a neural network, and improves neural network performance.",B25J 9/16; G05B 15/00; G05B 19/18; G06N 3/00; G06N 3/02; G06N 3/04; G06N 3/08,"NEURALA, INC.","LUCIW, Matthew","62/328,344 27.04.2016 US",KR-1020187034384; EP-2017790438; JP-2018556879; CN-201780036126.6
WO2012140655,PCT/IL2012/050045,13.02.2012,WO/2012/140655,18.10.2012,WO,"ROBOTIC SYSTEM CONTROLLED BY MULTI PARTICIPANTS, CONSIDERING ADMINISTRATOR'S CRITERIA","Mobile robotic system allows multiple users to visit authentic places without physically being there. The users are able to take part in controlling the robot's movement according to their interest. A system administrator selects and defines criteria for robot's movement. The mobile robot with video and audio devices on it is remote controlled by a server which selects the robot's movement according to the users and system administrator criteria. The server provides information to users; the robot's location influences the content of the information. Such robotic system may be used for shopping, visiting museums and public touristic attractions over the internet.",G05B 19/04; G06F 19/00; G06N 3/00,"BARYAKAR, Dan; BARYAKAR, Andreea","BARYAKAR, Dan; BARYAKAR, Andreea","61/474,368 12.04.2011 US; 61/530,180 01.09.2011 US",
EP289049998,18200732,16.10.2018,3614308,26.02.2020,EP,JOINT DEEP LEARNING FOR LAND COVER AND LAND USE CLASSIFICATION,"Land cover (LC) and land use (LU) have commonly been classified separately from remotely sensed imagery, without considering the intrinsically hierarchical and nested relationships between them. A novel joint deep learning framework is proposed and demonstrated for LC and LU classification. The proposed Joint Deep Learning (JDL) model incorporates a multilayer perceptron (MLP) and convolutional neutral network (CNN), and is implemented via a Markov process involving iterative updating. In the JDL, LU classification conducted by the CNN is made conditional upon the LC probabilities predicted by the MLP. In turn, those LU probabilities together with the original imagery are re-used as inputs to the MLP to strengthen the spatial and spectral feature representation. This process of updating the MLP and CNN forms a joint distribution, where both LC and LU are classified simultaneously through iteration.",G06K 9/62,ORDNANCE SURVEY LTD,SARGENT ISABEL; ZHANG CE; ATKINSON PETER M,18190861 24.08.2018 EP,
WO2020068360,PCT/US2019/048924,29.08.2019,WO/2020/068360,02.04.2020,WO,DISTRIBUTED LABELING FOR SUPERVISED LEARNING,Embodiments described herein provide a technique to crowdsource labeling of training data for a machine learning model while maintaining the privacy of the data provided by crowdsourcing participants. Client devices can be used to generate proposed labels for a unit of data to be used in a training dataset. One or more privacy mechanisms are used to protect user data when transmitting the data to a server. The server can aggregate the proposed labels and use the most frequently proposed labels for an element as the label for the element when generating training data for the machine learning model. The machine learning model is then trained using the crowdsourced labels to improve the accuracy of the model.,G06N 3/04,APPLE INC.,"BHOWMICK, Abhishek; ROGERS, Ryan M.; VAISHAMPAYAN, Umesh S.; VYRROS, Andrew H.","62/738,990 28.09.2018 US; 16/556,066 29.08.2019 US",
WO2018093055,PCT/KR2017/011655,20.10.2017,WO/2018/093055,24.05.2018,WO,MOBILE ROBOT SYSTEM AND MOBILE ROBOT,"Disclosed herein are a mobile robot system including a server of creating and storing traveling information about moving space and a mobile robot of travelling on the moving space, wherein the mobile robot comprises a driving portion configured to move the mobile robot, a communication device configured to receive the traveling information from the server and a controller configured to control the driving portion based on the traveling information received from the communication device and wherein the server receives information about the moving space from at least one external robot, and creates the traveling information based on the information about the moving space. Disclosed herein are a mobile robot system and a mobile robot capable of receiving information about moving space received from another mobile robot from an external server, and then performing deep learning based on the information about the moving space so as to travel safely and flexibly in various environments.",B25J 9/16; B25J 19/02; B25J 11/00; B25J 9/00; A47L 9/28,"SAMSUNG ELECTRONICS CO., LTD.","KWAK, No San; SONG, Mi Jeong; ROH, Kyung Shik; PARK, Soon Yong; KIM, Bo Kyung; SEO, Ji Ho; JANG, Si Ho",10-2016-0153535 17.11.2016 KR,EP-2017871692
WO2019118613,PCT/US2018/065226,12.12.2018,WO/2019/118613,20.06.2019,WO,MACHINE LEARNING TO EXTRACT QUANTITATIVE BIOMARKERS FROM ULTRASOUND RF SPECTRUMS,The present disclosure provides for ultrasound systems and methods to pre-process ultrasound data to distinguish abnormal tissue from normal tissue. An exemplary method can include receiving a set of ultrasound data and partitioning the set into a set of windows. The method can then provide for processing the set of windows to determine a power spectrum for each window. The power spectrum for each window can be processed to determine a normalized power spectrum for each window. This normalized power spectrum can be processed for each window with a machine learning model. The method can then provide for displaying an image where each window of the set of windows is displayed using a unique identifier based on the output of the machine learning model.,G06K 9/36; G06K 9/42; G06N 3/04,"ONCOUSTICS INC.; EL KAFFAS, Ahmed","EL KAFFAS, Ahmed","62/597,537 12.12.2017 US",
WO2012091814,PCT/US2011/060935,16.11.2011,WO/2012/091814,05.07.2012,WO,MOBILE ROBOT SYSTEM,"A robot system (1600) includes a mobile robot (100) having a controller (500) executing a control system (510) for controlling operation of the robot, a cloud computing service (1620) in communication with the controller of the robot, and a remote computing device (310) in communication with the cloud computing service. The remote computing device communicates with the robot through the cloud computing service.",G05D 1/02,"IROBOT CORPORATION; PACK, Robert, Todd; FARLOW, Timothy, S.; ROSENSTEIN, Michael, T.; HALLORAN, Michael; WON, Chikyung; SHAMLIAN, Steven, V.; CHIAPPETTA, Mark","PACK, Robert, Todd; FARLOW, Timothy, S.; ROSENSTEIN, Michael, T.; HALLORAN, Michael; WON, Chikyung; SHAMLIAN, Steven, V.; CHIAPPETTA, Mark","61/429,863 05.01.2011 US; 61/428,734 30.12.2010 US; 61/428,717 30.12.2010 US; 61/428,759 30.12.2010 US",EP-2011802188; DE-1120111046448; DE-112011104644; JP-2013547475; EP-2014164631; GB-1313403.6; CA-2822980; AU-2011353004
WO2016100221,PCT/US2015/065589,14.12.2015,WO/2016/100221,23.06.2016,WO,SYSTEMS AND METHODS FOR CAPTURING IMAGES AND ANNOTATING THE CAPTURED IMAGES WITH INFORMATION,The present teachings provide an autonomous mobile robot that includes a drive configured to maneuver the robot over a ground surface within an operating environment; a camera mounted on the robot having a field of view including the floor adjacent the mobile robot in the drive direction of the mobile robot; a frame buffer that stores image frames obtained by the camera while the mobile robot is driving; and a memory device configured to store a learned data set of a plurality of descriptors corresponding to pixel patches in image frames corresponding to portions of the operating environment and determined by mobile robot sensor events.,G06F 19/00,IROBOT CORPORATION,"SCHNITTMAN, Mark, S.","14/572,712 16.12.2014 US",EP-2015870809
WO2008083489,PCT/CA2008/000041,11.01.2008,WO/2008/083489,17.07.2008,WO,METHOD AND SYSTEM FOR ROBOT GENERATION,"A method is provided for the automatic generation of a robotic devices, where the method comprises the steps of receiving user input to determine a task specification for one or more tasks for the robotic device, determining a task list comprising one or more tasks based on the provided task specification, determining based on the task list provided, one or more mechanical components, one or more processing components, and logic components required to execute one or more tasks; and generating the logic components required to execute one or more tasks, and embedding the logic components onto a recordable medium associated with the robotic device.",B25J 9/16; B25J 9/18,"BALTES, Hansjorg; PETERSON, Jack, Elmin; SCHAERER, Shawn, Samuel; LIU, Xiao-Wen, Terry; MCKINNON, Brian, P.; EPP, Sara; KANNE, Vergil; YANKE, Shane","BALTES, Hansjorg; PETERSON, Jack, Elmin; SCHAERER, Shawn, Samuel; LIU, Xiao-Wen, Terry; MCKINNON, Brian, P.; EPP, Sara; KANNE, Vergil; YANKE, Shane","60/880,059 12.01.2007 US",EP-2008700508; CN-200880008371.7
WO2019040866,PCT/US2018/047947,24.08.2018,WO/2019/040866,28.02.2019,WO,APPARATUS AND METHOD FOR AGRICULTURAL DATA COLLECTION AND AGRICULTURAL OPERATIONS,"Aspects of the subject disclosure may include, for example, obtaining video data from a single monocular camera, wherein the video data comprises a plurality of frames, wherein the camera is attached to a mobile robot that is travelling along a lane defined by a row of crops, wherein the row of crops comprises a first plant stem, and wherein the plurality of frames include a depiction of the first plant stem; obtaining robot velocity data from encoder(s), wherein the encoder(s) are attached to the robot; performing foreground extraction on each of the plurality of frames of the video data, wherein the foreground extraction results in a plurality of foreground images; and determining, based upon the plurality of foreground images and based upon the robot velocity data, an estimated width of the first plant stem. Additional embodiments are disclosed.",G06T 7/00; G06T 7/20; G05D 1/02,THE BOARD OF TRUSTEES OF THE UNIVERSITY OF ILLINOIS,"CHOWDHARY, Girish; SOMAN, Chinmay; KAYACAN, Erkan; THOMPSON, Benjamin; ZHANG, Zhongzhong; CHOUDHURI, Anwesa","62/550,271 25.08.2017 US; 62/596,506 08.12.2017 US; 62/688,885 22.06.2018 US",AU-2018320964
WO2018073832,PCT/IN2017/050210,30.05.2017,WO/2018/073832,26.04.2018,WO,EMOTIONALLY INTELLIGENT COMPANION DEVICE,"A robotic companion device (10) configured for capturing and analysing affective information and semantic information and elicit response accordingly is disclosed herein. It comprises a processor (20) for managing emotional processing and responses configured for capturing and analysing semantic and affective information from sensory devices and communicating with users as well as external world using multitude of actuators and communication devices; a facial arrangement (11) configured for capturing visual information and displaying emotions; a locomotor arrangement (13) enabling movement of the robotic companion device; and microphone/speaker arrangement (15) configured for receiving auditory signal and emitting vocal response. The facial arrangement (11), the locomotor arrangement (13) and the microphone/speaker arrangement (15) are all in communication with the processor (20).",G06F 15/18; G06N 3/00; G06N 99/00; G06F 19/00,RN CHIDAKASHI TECHNOLOGIES PVT. LTD.,"IYENGAR, Prashant; VASWANI, Sneh Rajkumar; RAIKAR, Chintan",201621035955 20.10.2016 IN,CN-201780065001.6; EP-2017862742
WO2019045779,PCT/US2018/026122,04.04.2018,WO/2019/045779,07.03.2019,WO,ROBOTIC SYSTEMS AND METHODS FOR ROBUSTLY GRASPING AND TARGETING OBJECTS,"Embodiments are generally directed to generating a training dataset of labelled examples of sensor images and grasp configurations using a set of three-dimensional (3D) models of objects, one or more analytic mechanical representations of either or both of grasp forces and grasp torques, and statistical sampling to model uncertainty in either or both sensing and control. Embodiments can also include using the training dataset to train a function approximator that takes as input a sensor image and returns data that is used to select grasp configurations for a robot grasping or targeting mechanism.",G06F 15/18,THE REGENTS OF THE UNIVERSITY OF CALIFORNIA,"GOLDBERG, Kenneth, Yigael; MAHLER, Jeffrey, Brian; MATL, Matthew","62/553,589 01.09.2017 US",
WO2019127063,PCT/CN2017/118813,27.12.2017,WO/2019/127063,04.07.2019,WO,REINFORCEMENT LEARNING FOR HUMAN ROBOT INTERACTION,A system and method of teaching a neural network through reinforcement learning methodology. The system includes a machine-readable medium having one or more processors that perform a motion task to produce a first result corresponding to navigating a device during a first episode and performing an interaction task during that same episode. After completion of the first episode a processor calculates a Q value change based on the first task result and the second task result. The processor then modifies parameters based on the Q value change such that during subsequent episode iterations the motion task and interactive task are improved and a smooth and continuous transition occurs between these two tasks.,G06N 3/02,"INTEL CORPORATION; CHEN, Hu Tiger; LIU, Zhongxuan; ZHANG, Yimin; REN, Haibing; HU, Jiankun","CHEN, Hu Tiger; LIU, Zhongxuan; ZHANG, Yimin; REN, Haibing; HU, Jiankun",,
WO2018093967,PCT/US2017/061894,16.11.2017,WO/2018/093967,24.05.2018,WO,METHOD AND DEVICE FOR EVALUATION OF EYELASHES,"A device for automating the process of installing eyelash extensions (261) onto the natural eyelashes (260) of a subject (301 ). In some embodiments, the placing of extensions (261) is carried out by a robotic mechanism (219) utilizing computer vision.",G06K 9/00,WINK ROBOTICS,"HARDING, Nathan; AMUNDSON, Kurt; NISHIHARA, H., Keith; MULLER, Michael","62/423,000 16.11.2016 US",JP-2019547237; EP-2017871279; CN-201780083665.5; KR-1020197016671
WO2019084028,PCT/US2018/057137,23.10.2018,WO/2019/084028,02.05.2019,WO,SYSTEM AND METHOD FOR QUANTIFYING UNCERTAINTY IN REASONING ABOUT 2D AND 3D SPATIAL FEATURES WITH A COMPUTER MACHINE LEARNING ARCHITECTURE,"This invention provides a system and method to propagate uncertainty information in a deep learning pipeline. It allows for the propagation of uncertainty information from one deep learning model to the next by fusing model uncertainty with the original imagery dataset. This approach results in a deep learning architecture where the output of the system contains not only the prediction, but also the model uncertainty information associated with that prediction. The embodiments herein improve upon existing deep learning-based models (CADe models) by providing the model with uncertainty/confidence information associated with (e.g. CADe) decisions. This uncertainty information can be employed in various ways, including (a) transmitting uncertainty from a first stage (or subsystem) of the machine learning system into a next (second) stage (or the next subsystem), and (b) providing uncertainty information to the end user in a manner that characterizes the uncertainty of the overall machine learning model.",G06T 7/00,"THE CHARLES STARK DRAPER LABORATORY, INC.","OZDEMIR, Omur; WOODWARD, Benjamin; BERLIN, Andrew, A.","15/790,332 23.10.2017 US",
WO2017076929,PCT/EP2016/076467,02.11.2016,WO/2017/076929,11.05.2017,WO,DEVICE AND METHOD FOR AUTONOMOUS LOCALISATION,Disclosed is a mobile robot comprising at least one memory component comprising at least map data; at least two cameras adapted to take visual images; and at least one processing component adapted to at least extract straight lines from the visual images taken by the at least two cameras and compare them to the map data to at least localise the robot. Further disclosed is a localisation method comprising taking visual images with at least two cameras; extracting straight lines from the individual visual images with at least one processing component; comparing the extracted features with existing map data; and outputting a location hypothesis based on said comparison.,G05D 1/02,STARSHIP TECHNOLOGIES OÜ,"HEINLA, Ahti; VOLKOV, Kalle-Rasmus; ROBERTS, Lindsay; MANDRE, Indrek",15192649.0 02.11.2015 EP,EP-2016798097; JP-2018519923; AU-2016348568; CA-3002308; KR-1020187015842
WO2018076122,PCT/CA2017/051293,31.10.2017,WO/2018/076122,03.05.2018,WO,SYSTEM AND METHOD FOR IMPROVING THE PREDICTION ACCURACY OF A NEURAL NETWORK,"A system and method for improving the prediction accuracy of a neural network is proposed. Prediction tasks derived from labeled video data are used to regularize the feature space of the neural network so that it encodes constraints of the physical world while also learning to solve the original task at hand. The videos are generated by instructing humans to perform actions according to predefined labels or descriptions, so that a wide variety of physically relevant motion patterns are available to regularize the network.",G06N 3/08,TWENTY BILLION NEURONS GMBH,"MEMISEVIC, Roland; YIANILOS, Peter; SOBTI, Sumeet","62/414,949 31.10.2016 US; 15/608,059 30.05.2017 US",CN-201780081578.6; CA-3041726; EP-2017864131
WO2017152067,PCT/US2017/020683,03.03.2017,WO/2017/152067,08.09.2017,WO,DRONE AND ROBOT CONTROL SYSTEMS AND METHODS,"A system may be configured to manage at least one robotic device. The system may comprise one or more databases and one or more processors in communication with the one or more databases. The one or more processors may be configured to provide an operating system for the at least one robotic device, control motion of the at least one robotic device, configure at least one sensor removably coupled to the at least one robotic device, process data collected by the at least one sensor, and/or perform localization and/or area mapping for the at least one robotic device by comparing data collected by the at least one sensor with data in the one or more databases to generate localization and/or area mapping data.",G05D 1/00,ANIMUSOFT LLC,"RODRIGUEZ, Daniel","62/303,828 04.03.2016 US",
EP243305208,17841038,15.08.2017,3493032,05.06.2019,EP,ROBOT CONTROL METHOD AND COMPANION ROBOT,"A robot control method, said method comprising: collecting interaction information of a companion target, and acquiring digital person information of a companion person (101); said interaction information containing voice or movement interaction information of said companion target toward said robot, and said digital person information containing digitized sets of various companion person information; determining a manner of interaction with said companion target according to said interaction information and said digital person information (103); adopting a machine learning algorithm according to the digital person information of said companion person, and generating an interaction content corresponding to said manner of interaction (105); generating a response action toward said companion target according to said manner of interaction and said interaction content (107). The present robot control method, robot and control information generating method and apparatus may control the robot to accompany a companion target while integrating the characteristics of a companion person.",G06F 3/01; B25J 11/00; G06K 9/00; G06N 3/00,HUAWEI TECH CO LTD,YANG SIXIAO; LIAO HENG; HUANG MAOSHENG; WEI JIANSHENG; HUO DAWEI; SUN WENHUA,201610681117 17.08.2016 CN; 2017097517 15.08.2017 CN; 201710306154 04.05.2017 CN,
WO1998013782,PCT/US1997/017419,26.09.1997,WO/1998/013782,02.04.1998,WO,AFFECT-BASED ROBOT COMMUNICATION METHODS AND SYSTEMS,"An affect-based method of communication between robots is provided by displaying a visual facial expression (52) indicative of a simulated emotional state on a display device of a first robot, and viewing the visual facial expression using a camera on a second robot (54). The simulated emotional state may be one of happiness, anger, or sadness, for example. The second robot determines the simulated emotional state to redefine its own simulated emotional state (56), and to display a visual facial expression indicative thereof. The visual facial expression allows a human observer to discern the simulated emotional state of the robot. Optionally, the robots further communicate affect using audio tones (53).",A63F 9/24; G06N 3/00,"INTERVAL RESEARCH CORPORATION; TOW, Robert, F.","TOW, Robert, F.","08/721,006 26.09.1996 US",
WO2015103514,PCT/US2015/010106,05.01.2015,WO/2015/103514,09.07.2015,WO,DISTRIBUTED TRAINING OF A MACHINE LEARNING MODEL USED TO DETECT NETWORK ATTACKS,"A machine learning model is to be trained by a plurality of devices in a network. A set of training devices are identified, with each of the training devices having a local set of training data. An instruction is then sent to each of the training devices that is configured to cause a training device to receive model parameters from a first training device in the set, use the parameters with at least a portion of the local set of training data to generate new model parameters, and forward the new model parameters to a second training device in the set. Model parameters from the training devices are also received that have been trained using a global set of training data that includes the local sets of training data on the training devices. Machine learning (e.g., artificial neural networks) is used to detect attacks on networks (e.g., DoS, Denial of service in Low Power and Lossy Network, LLN).",H04L 29/06; H04L 12/24,"CISCO TECHNOLOGY, INC.","CRUZ MOTA, Javier; VASSEUR, Jean-Philippe; DI PIETRO, Andrea","61/923,847 06.01.2014 US; 14/164,456 27.01.2014 US",EP-2015701265
WO2018020275,PCT/GB2017/052231,31.07.2017,WO/2018/020275,01.02.2018,WO,COMPUTER VISION SYSTEMS,"A computer-vision system or engine that (a) generates from a pixel stream a digital representation of a person and (b) determines attributes or characteristics of the person from that digital representation and (c) based on those attributes or characteristics, outputs data to a cloud-based analytics system that enables that analytics system to identify and also to authenticate the person. The attributes or characteristics of the person include their pose, and the system or engine analyses that pose to extract a facial image from a video stream that is the best facial image for use by the cloud-based analytics system to identify and authenticate the person. The computer-vision system or engine outputs the facial image to the cloud-based analytics system, but does not output the full-frame real-time video to the cloud-based analytics system.",G06K 9/00; G06F 17/30; H04N 21/234; H04L 29/08; G06Q 30/02; H04L 29/06; G06K 9/32,UNIFAI HOLDINGS LIMITED,"TUSH, Michael; JACKSON, Andrew; DUNE, John",1613138.5 29.07.2016 GB,
EP291472780,18207992,23.11.2018,3627398,25.03.2020,EP,"METHOD, SYSTEM, AND COMPUTER PROGRAM FOR ARTIFICIAL INTELLIGENCE ANSWER",Provided is an artificial intelligence (Al) answering system including a user question receiver configured to receive a user question from a user terminal; a first question extender configured to generate a question template by analyzing the user question and determine whether the user question and the generated question template match; a second question extender configured to generate a similar question template by using a natural language processing and a deep learning model when the user question and the generated question template do not match; a training data builder configured to generate training data for training the second question extender by using an neural machine translation (NMT) engine; and a question answering unit configured to transmit a user question result derived through the first question extender or the second question extender to the user terminal.,G06N 3/04; G06N 3/08; G06N 5/04,42 MARU INC,KIM DONG HWAN,20180112488 19.09.2018 KR,
WO2019229125,PCT/EP2019/063970,29.05.2019,WO/2019/229125,05.12.2019,WO,DEEP REINFORCEMENT LEARNING WITH FAST UPDATING RECURRENT NEURAL NETWORKS AND SLOW UPDATING RECURRENT NEURAL NETWORKS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for reinforcement learning. One of the methods includes selecting an action to be performed by the agent using both a slow updating recurrent neural network and a fast updating recurrent neural network that receives a fast updating input that includes the hidden state of the slow updating recurrent neural network.",G06N 3/00; G06N 3/04; G06N 3/08; G06N 3/12,DEEPMIND TECHNOLOGIES LIMITED,"DUNNING, Iain Robert; CZARNECKI, Wojciech; JADERBERG, Maxwell Elliot","62/677,632 29.05.2018 US",
WO2020060267,PCT/KR2019/012206,20.09.2019,WO/2020/060267,26.03.2020,WO,CLEANING ROBOT AND METHOD FOR PERFORMING TASK THEREOF,"A method for performing a task of a cleaning robot is provided. The method according to an embodiment includes generating a navigation map for driving the cleaning robot using a result of at least one sensor detecting a task area in which an object is arranged, obtaining recognition information of the object by applying an image of the object captured by at least one camera to a trained artificial intelligence model, generating a semantic map indicating environment of the task area by mapping an area of the object included in the navigation map with the recognition information of the object, and performing a task of the cleaning robot based on a control command of a user using the semantic map. An example of the trained artificial intelligence model may be a deep-learning neural network model in which a plurality of network nodes having weighted values are disposed in different layers and exchange data according to a convolution relationship, but the disclosure is not limited thereto.",B25J 9/16; B25J 19/02; B25J 11/00,"SAMSUNG ELECTRONICS CO., LTD.","HONG, Soonhyuk; GARG, Shivam; KIM, Eunseo",10-2018-0113305 20.09.2018 KR; 10-2018-0136769 08.11.2018 KR,
WO2019241667,PCT/US2019/037244,14.06.2019,WO/2019/241667,19.12.2019,WO,AUGMENTED REALITY DEEP GESTURE NETWORK,"A computer implemented method for recognizing a hand gesture using a random forest model includes training the random forest model. The method also includes obtaining image data. The method further includes clustering a plurality of pixels from the image data to generate a plurality of clusters. Moreover, the method includes analyzing the plurality of clusters using a rejection cascade to generate a plurality of selected candidates. In addition, the method includes analyzing the plurality of selected candidates using a classification decision tree from the random forest model. The method also includes skeletonizing the plurality of selected candidates to generate a one dimension plus branches hand model. The method further includes analyzing the one dimension plus branches hand model using a regression decision tree from the random forest model.",G06K 9/52; G06K 9/62; G06F 16/35; G06F 16/55; H04N 19/88; H04N 19/182,"MAGIC LEAP, INC.","LEE, Douglas, Bertram","62/685,262 14.06.2018 US",
WO2019222597,PCT/US2019/032823,17.05.2019,WO/2019/222597,21.11.2019,WO,SYSTEM AND METHODS FOR PIXEL BASED MODEL PREDICTIVE CONTROL,"Techniques are disclosed that enable model predictive control of a robot based on a latent dynamics model and a reward function. In many implementations, the latent space can be divided into a deterministic portion and stochastic portion, allowing the model to be utilized in generating more likely robot trajectories. Additional or alternative implementations include many reward functions, where each reward function corresponds to a different robot task.",B25J 9/16; G05B 13/04,GOOGLE LLC,"HAFNER, Danijar","62/673,744 18.05.2018 US",
WO2019046719,PCT/US2018/049095,31.08.2018,WO/2019/046719,07.03.2019,WO,ROBOT ATTENTION DETECTION,"A robot that uses sensor inputs for attention activation and corresponding methods, systems, and computer programs encoded on computer storage media. The robot can be configured to compute a plurality of attention signals from sensor inputs and provide the plurality of attention signals as input to the attention level classifier to generate an attention level. If a user is paying attention to the robot based on the generated attention level, the robot selects a behavior to execute based on the current attention level, wherein a behavior comprises one or more coordinated actions to be performed by the robot.",G06K 9/00; G06N 3/00,"ANKI, INC.","TAPPEINER, Hanns W.; NEUMAN, Bradford; STEIN, Andrew Neil; CRIPPEN, Lee","15/694,710 01.09.2017 US",
WO2018183852,PCT/US2018/025411,30.03.2018,WO/2018/183852,04.10.2018,WO,USER-ASSISTED ROBOTIC CONTROL SYSTEMS,"Exemplary embodiments relate to user-assisted robotic control systems, user interfaces for remote control of robotic systems, vision systems in robotic control systems, and modular grippers for use by robotic systems. Systems, methods, apparatuses and computer-readable media instructions are disclosed for interactions with and control of robotic systems, in particular, pick and place systems using soft robotic actuators to grasp, move and release target objects.",B25J 9/16; B25J 9/14; B25J 15/12,"SOFT ROBOTICS, INC.","ROSENSTEIN, Michael; CURHAN, Jeffrey; LESSING, Joshua, Aaron; KNOPF, Ryan; HARBURG, Daniel; CHIAPPETTA, Mark","62/478,775 30.03.2017 US",JP-2019553079; EP-2018720455
EP11172889,10151739,27.01.2010,2224371,01.09.2010,EP,Artificial vision system and method for knowledge-based selective visual analysis,"Generally the background of the present invention is the field of artificial vision systems, i.e. systems having a visual sensing means (e.g. a video camera) and a following processing stage implemented using a computing unit. The processing stage outputs a representation of the visually analysed scene, which output can then be fed to control different actors, such as e.g. parts of a vehicle (automobile, plane,...) or a robot, preferably an autonomous robot such as e.g. a humanoid robot.",G06K 9/00; G06K 9/68,HONDA RES INST EUROPE GMBH,EGGERT JULIAN; REBHAN SVEN,09153896 27.02.2009 EP; 10151739 27.01.2010 EP,
EP130756447,13714786,15.03.2013,2834047,11.02.2015,EP,SYSTEMS AND METHODS FOR PROVIDING FLEXIBLE ROBOTIC ACTUATORS,"Systems and methods for providing flexible robotic actuators are disclosed. Thanks to the concentrical positioning of a plurality of inflatable channels, the claimed soft robot is capable of providing a radial deflection motion. A method for operating the disclosed robotic systems is also disclosed.",B25J 9/16; A47L 9/28; B25J 9/10; B25J 9/14,HARVARD COLLEGE,MORIN STEPHEN A; SHEPHERD ROBERT F; STOKES ADAM; ILIEVSKI FILIP; MARTINEZ RAMSES V; BRANCH JAMIE L; FISH CARINA R; JIN LIHUA; NUNES RUI M D; SUO ZHIGANG; WHITESIDES GEORGE M,201261615665 26.03.2012 US; 201261673003 18.07.2012 US; 201261698436 07.09.2012 US; 2013032297 15.03.2013 US,
EP225889572,18157120,16.02.2018,3373141,12.09.2018,EP,SYSTEMS AND METHODS FOR PROVIDING AUTOMATED NATURAL LANGUAGE DIALOGUE WITH CUSTOMERS,"A system includes one or more memory devices storing instructions, and one or more processors configured to execute the instructions to perform steps of a providing automated natural dialogue with a customer. The system may generate one or more events and commands temporarily stored in queues to be processed by one or more of a dialogue management device, an API server, and an NLP device. The dialogue management device may create adaptive responses to customer communications using a customer context, a rules-based platform, and a trained-machine learning model.",G06F 9/54; G10L 15/22,CAPITAL ONE SERVICES LLC,ZOLLER GREGORY W; KARP SCOTT; JACOB SUJAY ELIPHAZ; MUELLER ERIK; HAY STEPHANIE; PAYNTER ADAM ROY,201715665960 01.08.2017 US; 201762469193 09.03.2017 US,
WO2018002863,PCT/IB2017/053903,29.06.2017,WO/2018/002863,04.01.2018,WO,BLOOD VESSEL EXTRACTION IN TWO-DIMENSIONAL THERMOGRAPHY,"What is disclosed is a system and method for isolating blood vessels in a thermographic image of a patient's breast or any other muscular region of the body. A thermographic image of a patient is received. A temperature-based analysis is performed on the image to detect vessel pixels. An intensity-based method analysis is performed on the image. A shape-based analysis is also performed to detect pixels of vessel-like structures. Candidate pixels which satisfy one or more of intensity-based or temperature-based or shaped-based criterion are identified. A constraint of local maximallity is thereafter imposed on each candidate pixel that satisfies both criterion to eliminate spurious non-vessel pixels. Candidate pixels which satisfy both criterion are then marked with a different color such that the vessel structures in the breast tissue can be visually differentiated. The vessel structures are provided to a classifier system which classifies the tissue in the thermal image as malignant and non-malignant otherwise, based on a tortuosity of the vessel structures.",A61B 5/01; A61B 5/026; G06K 9/54; G06T 7/00,NIRAMAI HEALTH ANALYTIX PVT. LTD.,"TEJA KAKILETI, Siva","62/356,238 29.06.2016 US",EP-2017819464; JP-2018567044
WO2019017990,PCT/US2017/062222,17.11.2017,WO/2019/017990,24.01.2019,WO,LEARNING UNIFIED EMBEDDING,"A computer-implemented method for generating a unified machine learning model using a neural network on a data processing apparatus is described. The method includes the data processing apparatus determining respective learning targets for each of a plurality of object verticals. The data processing apparatus determines the respective learning targets based on two or more embedding outputs of the neural network. The method also includes the data processing apparatus training the neural network to identify data associated with each of the plurality of object verticals. The data processing apparatus trains the neural network using the respective learning targets and based on a first loss function. The data processing apparatus uses the neural network trained to generate a unified machine learning model, where the model is configured to identify particular data items associated with each of the plurality of object verticals.",G06N 3/08; G06N 3/04; G06K 9/62,GOOGLE LLC,"SONG, Yang; LI, Yuan; WU, Bo; CHEN, Chao-Yeh; ZHANG, Xiao; ADAM, Hartwig","62/533,535 17.07.2017 US",EP-2017812137; CN-201780089483.9
WO2019049082,PCT/IB2018/056851,07.09.2018,WO/2019/049082,14.03.2019,WO,"COLLISION DETECTION, ESTIMATION, AND AVOIDANCE","An example method involves obtaining a log of sensor data indicative of an environment during a prior time period, with the log of sensor data including a sequence of image frames, and determining that the log of sensor data relates to a collision involving a physical object in the environment at a particular time within the prior time period. The method also involves, responsive to determining that the log of sensor data relates to the collision, generating a training data set for the collision from the log of sensor data. The training data set for the collision may include multiple image frames of the sequence of image frames that are prior to an image frame in the sequence of image frames that corresponds to the particular time.",G05D 1/02; G06T 7/20,"NIANTIC, INC.","HICKMAN, Ryan Michael; BAE, Soohyun","15/699,444 08.09.2017 US",
EP30783260,11153813,09.02.2011,2388778,23.11.2011,EP,Speech recognition,"An apparatus to improve robustness to environmental changes of a context dependent speech recognizer for an application, that includes a training database to store sounds for speech recognition training, a dictionary to store words supported by the speech recognizer, and a speech recognizer training module to train a set of one or more multiple state Hidden Markov Models (HMMs) with use of the training database and the dictionary. The speech recognizer training module performs a non-uniform state clustering process on each of the states of each HMM, which includes using a different non-uniform cluster threshold for at least some of the states of each HMM to more heavily cluster and correspondingly reduce a number of observation distributions for those of the states of each HMM that are less empirically affected by one or more contextual dependencies.",G10L 15/14; G10L 15/06; G10L 15/18,SONY COMPUTER ENTERTAINMENT INC,MENENDEZ-PIDAL XAVIER; CHEN RUXIN,78537510 21.05.2010 US,
EP225274480,18158792,27.02.2018,3367061,29.08.2018,EP,NAVIGATION SYSTEM BASED ON SLOW FEATURE GRADIENTS,"The invention relates to the field of navigation for mobile systems. The invention proposes a method for navigating a mobile system and corresponding mobile system, in particular for autonomous mobile systems such as robots, for example lawn mowers or even smartphones. The mobile device comprises at least one sensor, an electronic control unit and an output unit. The method comprises a step of acquiring sensor data on an environment of the mobile device, a step of calculating a gradient of a difference of a target environmental representation and a current environmental representation, a step of determining a movement direction to reach a target position corresponding to the target environmental representation based on the estimated gradient. In an output step, the determined movement direction for navigating the mobile device is output, for example to a steering system of the mobile device or to a display. Advantageously, the method comprises a step of generating an environmental representation by performing unsupervised learning from the acquired sensor data.",G01C 21/20; G05D 1/00,HONDA RES INSTITUTE EUROPE GMBH,FRANZIUS MATHIAS; METKA BENJAMIN; BAUER-WERSING UTE,17158504 28.02.2017 EP,
WO2019060679,PCT/US2018/052165,21.09.2018,WO/2019/060679,28.03.2019,WO,DYNAMIC WINDOW APPROACH USING OPTIMAL RECIPROCAL COLLISION AVOIDANCE COST-CRITIC,"A method and system for navigation of a robot along a goal path and avoiding obstacles. The method includes receiving goal pose for one or more robots and determining a goal path for a first robot while avoiding moving and fixed obstacles of a received obstacle map. A first objective function is evaluated to select a preferred velocity from a generated set of candidate velocities, the selecting based on one or more weighted cost functions. A set of velocity obstacles created based on the poses of the one or more robots and the preferred velocity is used in evaluating a second objective function to determine the motion of the robot in the next time cycle. Creating the set of velocity objects includes converting the preferred velocity from a non-holonomic to a holonomic velocity.",B60W 30/08; G01C 21/34; G06Q 10/04; G08G 1/16; G08G 1/00; G05D 1/02; G01D 21/00; G01C 21/00,LOCUS ROBOTICS CORP.,"MOORE, Thomas; POWERS, Bradley","15/712,256 22.09.2017 US",
EP131694636,13185089,19.09.2013,2851760,25.03.2015,EP,Multi-robot system,"A multi-agent system, comprising a server and at least two robots controllably wirelessly connected with the server, where the server contains at least one software agent allocated to each robot, which software agent provides abstraction from the robot being implemented in the hardware and enables to calculate, analyze, optimize and control the implementation of different scenarios of robots operation. The robots with marker sensors, odometers and collision sensors send their location and a (part of a) global map of a to a server with a global map, robots' positions and marker positions, the server updates the global map, plans work of the robots in optimal way, divides the environment in areas allocated to the robots.",G05D 1/02,UNIV RIGAS TEHNISKA,NIKITENKO AGRIS; LAVENDELIS EGONS; LIEKNA ALEKSIS; EKMANIS MARTINS; ANDERSONE ILZE; KULIKOVSKIS GUNTIS; PRIEDNIECE KINTIJA,13185089 19.09.2013 EP,
WO2019171123,PCT/IB2018/051395,05.03.2018,WO/2019/171123,12.09.2019,WO,"METHOD, APPARATUS, SYSTEM AND PROGRAM FOR CONTROLLING A ROBOT, AND STORAGE MEDIUM","The present disclosure relates to a method, an apparatus, a system and a program for controlling a robot, and a storage medium. The method uses a neural network connected to an external memory to conduct the controlling of the robot, and comprises: inputting input data into the learned neural network to obtain output data, wherein said input data comprises an image about an object, said output data comprises control data about said robot; and establishing an association between part or all of the information generated by said neural network during the calculation and said input data and/or said output data, wherein said part or all of the information represents a feature of said object related to said control data. Thus, the user can grasp the calculation process of the neural network.",B25J 9/16,OMRON CORPORATION,"IJIRI, Yoshihisa",,
WO2013009510,PCT/US2012/045202,02.07.2012,WO/2013/009510,17.01.2013,WO,CALIBRATION AND TRANSFORMATION OF A CAMERA SYSTEM'S COORDINATE SYSTEM,"Systems and methods are disclosed that determine a mapping between a first camera system's coordinate system and a second camera system's coordinate system; or determine a transformation between a robot's coordinate system and a camera system's coordinate system, and/or locate, in a robot's coordinate system, a tool extending from an arm of the robot based on the tool location in the camera's coordinate system. The disclosed systems and methods may use transformations derived from coordinates of features found in one or more images. The transformations may be used to interrelate various coordinate systems, facilitating calibration of camera systems, including in robotic systems, such as an image- guided robotic systems for hair harvesting and/or implantation.",A61B 5/00; A61F 2/10,"RESTORATION ROBOTICS, INC.; TENNEY, John, A.; BURD, Erik, R.; ZHANG, Hui; BIRO, Robert, F.","TENNEY, John, A.; BURD, Erik, R.; ZHANG, Hui; BIRO, Robert, F.","13/178,867 08.07.2011 US",EP-2012811280; JP-2014519220; KR-1020147000496
WO2015158887,PCT/EP2015/058373,17.04.2015,WO/2015/158887,22.10.2015,WO,"METHOD OF PERFORMING MULTI-MODAL DIALOGUE BETWEEN A HUMANOID ROBOT AND USER, COMPUTER PROGRAM PRODUCT AND HUMANOID ROBOT FOR IMPLEMENTING SAID METHOD","A method of performing a dialogue between a humanoid robot (R) and at least one user (U) comprising the following steps, carried out iteratively by said humanoid robot: i) acquiring a plurality of input signals (s1, s2) from respective sensors (c1, c2), at least one said sensor being a sound sensor and at least one other sensor being a motion or image sensor; ii) interpreting the acquired signals to recognize a plurality of events (EVI) generated by said user, selected from a group comprising: the utterance of at least a word or sentence, an intonation of voice, a gesture, a body posture, a facial expression; iii) determining a response of said humanoid robot, comprising at least one event (EVO) selected from a group comprising: the utterance of at least a word or sentence, an intonation of voice, a gesture, a body posture, a facial expression; iv ) generating, by said humanoid robot, said or each said event; characterized in that said step iii) comprises determining said response as a function of at least two events jointly generated by said user and recognized at said step ii), of which at least one is not a word or sentence uttered by said user. A computer program product and a humanoid robot for carrying out such a method.",B25J 9/16; B25J 11/00; G06N 3/00; G10L 15/32,SOFTBANK ROBOTICS EUROPE,"MONCEAUX, Jérôme; GATE, Gwennael; HOUSSIN, David; BARBIERI, Gabriele; MARTIN, Jocelyn; TESTARD, Jean; GOURDIN, Ilmo",14305583.8 17.04.2014 EP,RU-2016144006; CN-201580020117.9; AU-2015248713; US-15300226; JP-2016562886; SG-11201608205U; CA-2946056; KR-1020167032132; MX-MX/a/2016/013019
WO2018211141,PCT/EP2018/063283,22.05.2018,WO/2018/211141,22.11.2018,WO,IMAGINATION-BASED AGENT NEURAL NETWORKS,"A neural network system is proposed. The network can be trained by model-based reinforcement learning to select actions to be performed by an agent interacting with an environment, to perform a task in an attempt to achieve a specified result. The system may comprise at least one imagination core which has an input to receive a current observation characterizing a current state of the environment, and optionally historical observations, and which includes a model of the environment. The imagination core may be configured to output trajectory data in response to the current observation, and/or historical observations. The trajectory data comprising a sequence of future features of the environment imagined by the imagination core. The system may also include at least one rollout encoder to encode the sequence of features, and a reinforcement learning output stage to receive data derived from the rollout embedding and to output action policy data for defining an action policy identifying an action based on the current observation.",G06N 3/04; G06N 3/08; G06N 3/00,DEEPMIND TECHNOLOGIES LIMITED,"WIERSTRA, Daniel Pieter; LI, Yujia; PASCANU, Razvan; BATTAGLIA, Peter William; WEBER, Theophane Guillaume; BUESING, Lars; REICHERT, David Paul; GUEZ, Arthur Clement; REZENDE, Danilo Jiminez; BADIA, Adria Puigdomenech; VINYALS, Oriol; HEESS, Nicolas Manfred Otto; RACANIERE, Sebastien Henri","62/509,023 19.05.2017 US",EP-2018734078
WO2014151926,PCT/US2014/026685,13.03.2014,WO/2014/151926,25.09.2014,WO,ROBOTIC TRAINING APPARATUS AND METHODS,"Adaptive controller apparatus of a robot may be implemented. The controller may be operated in accordance with a reinforcement learning process. A trainer may observe movements of the robot and provide reinforcement signals to the controller via a remote clicker. The reinforcement may comprise one or more degrees of positive and/or negative reinforcement. Based on the reinforcement signal, the controller may adjust instantaneous cost and to modify controller implementation accordingly. Training via reinforcement combined with particular cost evaluations may enable the robot to move more like an animal.",G05D 1/00,BRAIN CORPORATION,"COENEN, Olivier","13/841,980 15.03.2013 US",
WO2020036490,PCT/NL2019/050533,15.08.2019,WO/2020/036490,20.02.2020,WO,A METHOD AND SYSTEM FOR AUTOMATICALLY ANNOTATING AND IDENTIFYING A LIVING BEING OR AN OBJECT WITH AN IDENTIFIER PROVIDING A SUBJECT IDENTIFICATION,"The invention relates to a method for training a machine learning model to identify a subject having at least one machine readable identifier providing a subject ID, said method comprising: providing a computer vision system with an image capturing system comprising at least one image capturing device, and a reader system comprising at least one reader for reading said at least one machine readable identifier; defining said machine learning model in said computer vision system; capturing a first image using said image capturing system, said first image showing said subject; reading said subject ID using said reader system when capturing said first image, and linking said subject ID with said first image, said linking providing said first image with a linked subject ID, providing a first annotated image; capturing at least one further image showing said subject, linking said linked subject ID to said at least one further image providing at least one further annotated image, and subjecting said first annotated image and said at least one further annotated image to said machine learning model for training said machine learning model.",G06K 9/00,KEPLER VISION TECHNOLOGIES BV,"VAN OLDENBORGH, Marc Jean Baptist; SNOEK, Cornelis Gerardus Maria",2021481 17.08.2018 NL; 2021498 24.08.2018 NL,
WO2015179108,PCT/US2015/028886,01.05.2015,WO/2015/179108,26.11.2015,WO,FAST SOLVING FOR LOOP CLOSURE,"The subject disclosure is generally directed towards a relatively fast and accurate technology that corrects mobile device (e.g., mobile robot) mapping data into corrected map data based upon detection of loop closure. A variation of stochastic gradient descent (with constraints in a deterministic order) may be used in a first correction phase to provide an updated graph in a relatively fast manner by operating in a relative state space. A graph-based variant of Gauss-Seidel that operates in a global state space may be used in a later phase to refine the updated graph into a more exact graph.",G06T 7/00,"MICROSOFT TECHNOLOGY LICENSING, LLC","BIRCHFIELD, Stanley; PEASLEY, Brian Kai","14/281,668 19.05.2014 US",
EP12287727,91118922,06.11.1991,0484911,13.05.1992,EP,Signal processing method,"A signal processing method for efficiently searching an optimum solution in a neural network by including a term of a nonlinear resistance in an equation of motion and changing such nonlinear resistance periodically. According to the method, the range of absolute values of connection weigths between units in the neural network is limited by the equation of motion, hence preventing a prolonged search time that may otherwise be caused by excessive extension of the search scope beyond the requisite. A plurality of patterns are previously embedded or stored in the neural network and, upon input of a predetermined key pattern, the nonlinear resistance is changed periodically to recall a pattern similar to the key pattern, whereby any desired pattern can be searched or retrieved with rapidity and facility out of the complicated patterns. A process of calculating the next position of an articulated robot (12) corresponding to an optimum solution is repeated while periodically changing a nonlinear resistance included in another equation of the positional energy of the robot (12), thereby acquiring the data of the robot path up to a desired goal. <IMAGE>",B25J 9/16; B25J 9/18,SONY CORP,TANI JUN,14968891 25.05.1991 JP; 29898490 06.11.1990 JP; 41490790 27.12.1990 JP,
WO2014130404,PCT/US2014/016749,18.02.2014,WO/2014/130404,28.08.2014,WO,METHOD AND DEVICE FOR CALCULATING A CAMERA OR OBJECT POSE,"Camera or object pose calculation is described, for example, to relocalize a mobile camera (such as on a smart phone) in a known environment or to compute the pose of an object moving relative to a fixed camera. The pose information is useful for robotics, augmented reality, navigation and other applications. In various embodiments where camera pose is calculated, a trained machine learning system associates image elements from an image of a scene, with points in the scene's 3D world coordinate frame. In examples where the camera is fixed and the pose of an object is to be calculated, the trained machine learning system associates image elements from an image of the object with points in an object coordinate frame. In examples, the image elements may be noisy and incomplete and a pose inference engine calculates an accurate estimate of the pose.",G06K 9/00; G06K 9/62,"MICROSOFT TECHNOLOGY LICENSING, LLC","SHOTTON, Jamie Daniel Joseph; ZACH, Christopher; IZADI, Shahram; FITZGIBBON, Andrew William; GLOCKER, Benjamin Michael; CRIMINISI, Antonio","13/774,145 22.02.2013 US",CN-201480010236.1; EP-2014709030
WO2010120302,PCT/US2009/040800,16.04.2009,WO/2010/120302,21.10.2010,WO,STORAGE DEVICE TESTING,A storage device testing system (100) includes at least one robotic arm (200) defining a first axis (205) substantially normal to a floor surface (10). The robotic arm is operable to rotate through a predetermined arc about and extend radially from the first axis. Multiple racks (300) are arranged around the robotic arm for servicing by the robotic arm. Each rack houses multiple test slots (310) that are each configured to receive a storage device transporter (550) configured to carry a storage device (500) for testing. A transfer station (400) is arranged for servicing by the robotic arm. The transfer station includes multiple tote receptacles (420) that are each configured to receive a storage device tote (450).,G01R 31/02; G01R 31/28; G11B 20/18; G02B 27/00,"TERADYNE, INC.; GARCIA, Edward; MERROW, Brian, S.; POLYAKOV, Evgeny; VAHEY, Walter; TRUEBENBACH, Eric, L.","GARCIA, Edward; MERROW, Brian, S.; POLYAKOV, Evgeny; VAHEY, Walter; TRUEBENBACH, Eric, L.",,JP-2011550106; MY-PI 2010002419; KR-1020107013047; CN-200980102323.9
WO2017168252,PCT/IB2017/000457,31.03.2017,WO/2017/168252,05.10.2017,WO,METHOD AND SYSTEM FOR PROCESSING AN INPUT QUERY,"Disclosed embodiments include systems and methods relevant to improvements to natural language processing used to determine an intent and one or more associated parameters from a given input string. In an example, an input string is received and first and second different n-grams are applied to the input string. Recurrent neural network models are then used to generate output data based in part on the first and second different n-grams. Intent detection and semantic labeling are applied to the output of the recurrent neural network models.",G06F 17/30; G06F 17/27; G06N 3/02,MALUUBA INC.,"HE, Jing; MERHEB-HARB, Jean; YE, Zheng; SULEMAN, Kaheer","62/316,208 31.03.2016 US",EP-2017773375
WO2018211139,PCT/EP2018/063279,22.05.2018,WO/2018/211139,22.11.2018,WO,TRAINING ACTION SELECTION NEURAL NETWORKS USING A DIFFERENTIABLE CREDIT FUNCTION,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for reinforcement learning. A reinforcement learning neural network selects actions to be performed by an agent interacting with an environment to perform a task in an attempt to achieve a specified result. The reinforcement learning neural network has at least one input to receive an input observation characterizing a state of the environment and at least one output for determining an action to be performed by the agent in response to the input observation. The system includes a reward function network coupled to the reinforcement learning neural network. The reward function network has an input to receive reward data characterizing a reward provided by one or more states of the environment and is configured to determine a reward function to provide one or more target values for training the reinforcement learning neural network.",G06N 3/04; G06N 3/08; G06N 3/00,DEEPMIND TECHNOLOGIES LIMITED,"XU, Zhongwen; HASSELT, Hado Philip Van; MODAYIL, Joseph Varughese; DA MOTTA BARRETO, Andre; SILVER, David","62/509,024 19.05.2017 US",EP-2018726144
WO2019219969,PCT/EP2019/062943,20.05.2019,WO/2019/219969,21.11.2019,WO,GRAPH NEURAL NETWORK SYSTEMS FOR BEHAVIOR PREDICTION AND REINFORCEMENT LEARNING IN MULTPLE AGENT ENVIRONMENTS,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for predicting the actions of, or influences on, agents in environments with multiple agents, in particular for reinforcement learning. In one aspect, a relational forward model (RFM) system receives agent data representing agent actions for each of multiple agents and implements: an encoder graph neural network subsystem to process the agent data as graph data to provide encoded graph data, a recurrent graph neural network subsystem to process the encoded graph data to provide processed graph data, a decoder graph neural network subsystem to decode the processed graph data to provide decoded graph data and an output to provide representation data for node and/or edge attributes of the decoded graph data relating to a predicted action of one or more of the agents. A reinforcement learning system includes the RFM system.",G06N 3/04; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"SONG, Hasuk; TACCHETTI, Andrea; BATTAGLIA, Peter William; ZAMBALDI, Vinicius","62/673,812 18.05.2018 US",
WO2020055909,PCT/US2019/050468,10.09.2019,WO/2020/055909,19.03.2020,WO,ZERO TEACH FOR ROBOTIC CONTINUOUS PATH,"A method and system for programming a path-following robot to perform an operation along a continuous path while accounting for process equipment characteristics. The method eliminates the use of manual teaching cycles. In one example, a dispensing robot is programmed to apply a consistent bead of material, such as adhesive or sealant, along the continuous path. A CAD-generated definition of the path, along with a model of dispensing equipment characteristics, are provided to an optimization routine. The optimization routine iteratively calculates robot tool center point path and velocity, and material flow, until an optimum solution is found. The optimized robot motion and dispensing equipment commands are then provided to an augmented reality (AR) system which allows a user to visualize and adjust the operation while viewing an AR simulation of dispensing system actions and a simulated material bead. Other examples include robotic welding or cutting along a continuous path.",B25J 9/16; G09B 19/04,FANUC AMERICA CORPORATION,"SUN, Yi; CHENG, Sai-Kai; TSAI, Jason","62/729,179 10.09.2018 US; 16/566,608 10.09.2019 US",
WO2018213763,PCT/US2018/033487,18.05.2018,WO/2018/213763,22.11.2018,WO,NATURAL LANGUAGE PROCESSING USING CONTEXT-SPECIFIC WORD VECTORS,"A system is provided for natural language processing. In some embodiments, the system includes an encoder for generating context-specific word vectors for at least one input sequence of words. The encoder is pre-trained using training data for performing a first natural language processing task. A neural network performs a second natural language processing task on the at least one input sequence of words using the context-specific word vectors. The first natural language process task is different from the second natural language processing task and the neural network is separately trained from the encoder. In some embodiments, the first natural processing task can be machine translation, and the second natural processing task can be one of sentiment analysis, question classification, entailment classification, and question answering.",G06N 3/04; G06F 17/28,"SALESFORCE.COM, INC.","MCCANN, Bryan; XIONG, Caiming; SOCHER, Richard","62/508,977 19.05.2017 US; 62/536,959 25.07.2017 US; 15/982,841 17.05.2018 US",CN-201880033016.9; CA-3062891; DE-112018002601
WO2017042789,PCT/IB2016/056450,27.10.2016,WO/2017/042789,16.03.2017,WO,HARVESTING AND LAWN CARE ROBOT,"This invention discloses a robot with the form of a wasp which has the function of harvesting fruit, vegetables and also helps with the care of the garden cutting the lawn. This robot has a set of sensors to determine the obstacles, distance sensors, infrared sensors, sound sensors; an internal navigation system which indicates to it the route that should be followed. It is divided into 4 parts: the lower part of the robot with the form of a wasp that is a solar panel which is an energy system for the different motors, the joining part of the lower part and the upper part which gives the robot mobility, and the upper part containing a set of pincers which serve as scissors to cut the fruit, the vegetable or the lawn and a set of limbs for its ground mobility, and a head wherein are housed the sensors and the set of antennas which serve as wireless device.",A01D 46/30; A01D 34/68; A01D 34/685; A01D 46/00; G05B 13/02; G05D 1/02; G05D 3/12,UNIVERSIDAD TECNOLÓGICA DE PANAMÁ,"ODENS, Marcos; GONZÁLEZ GILL, José Ángel; GUEVARA PÉREZ, Juan Bosco; GAMALIER MADERO, Ulises; SEGURA MARTINEZ, Yino Xavier",91250 20.07.2016 PA,
WO2018017399,PCT/US2017/042041,14.07.2017,WO/2018/017399,25.01.2018,WO,METHOD AND SYSTEM FOR 3D HAND SKELETON TRACKING,"A tracking system is disclosed. The system may comprise a processor and a non-transitory computer-readable storage medium coupled to the processor and storing instructions that, when executed by the processor, cause the system to perform a method. The method may comprise training a detection model and an extraction model, capturing one or more images of at least a portion of an object, detecting the portion of the object in each of the one or more images through the trained detection model, tracking the detected portion of the object in real-time, obtaining 2D positions of one or more locations on the tracked portion of the object through the trained extraction model, and obtaining 3D positions of the one or more locations on the tracked portion of the object based at least in part on the obtained 2D positions.",G06F 3/01; G06F 3/03; G06K 9/00; G06K 9/62; G06T 7/00; G06T 7/20,"USENS, INC.","MAO, Wentao; ZHANG, Xu; MA, Gengyu; FEI, Yue","62/364,783 20.07.2016 US",EP-2017831592
EP232832028,17305486,02.05.2017,3399460,07.11.2018,EP,CAPTIONING A REGION OF AN IMAGE,"The invention notably relates to a computer implemented method for learning a function configured for captioning a region of an image, the method comprising providing a dataset of triplets each including a respective image, a respective region of the respective image, and a respective caption of the respective region; and learning, with the dataset of triplets, a function that is configured to generate an output caption based on an input image and on an input region of the input image.  Such a method constitutes an improved solution for captioning a region of an image.",G06K 9/62; G06K 9/00,DASSAULT SYSTEMES,LUBBERS NIELS; BOULKENAFED MALIKA,17305486 02.05.2017 EP,
WO2018153375,PCT/CN2018/077354,27.02.2018,WO/2018/153375,30.08.2018,WO,PLANNING SYSTEM AND METHOD FOR CONTROLLING OPERATION OF AUTONOMOUS VEHICLE TO NAVIGATE PLANNED PATH,"A multi layer learning based control system and method for an autonomous vehicle or mobile robot. A mission planning layer, behavior planning layer and motion planning layer each having one or more neural networks are used to develop an optimal route for the autonomous vehicle or mobile robot, provide a series of functional tasks associated with at least one or more of the neural networks to follow the planned optimal route and develop commands to implement the functional tasks.",G05D 1/02,"HUAWEI TECHNOLOGIES CO., LTD.","ROHANI, Mohsen; LUO, Jun; ZHANG, Song","62/464,196 27.02.2017 US; 15/905,705 26.02.2018 US",CN-201880014416.5
WO2015116270,PCT/US2014/063540,31.10.2014,WO/2015/116270,06.08.2015,WO,REDUCED DEGREE OF FREEDOM ROBOTIC CONTROLLER APPARATUS AND METHODS,"Apparatus and methods for training and controlling of, for instance, robotic devices. In one implementation, a robot may be trained by a user using supervised learning. The user may be unable to control all degrees of freedom of the robot simultaneously. The user may interface to the robot via a control apparatus configured to select and operate a subset of the robot's complement of actuators. The robot may comprise an adaptive controller comprising a neuron network. The adaptive controller may be configured to generate actuator control commands based on the user input and output of the learning process. Training of the adaptive controller may comprise partial set training. The user may train the adaptive controller to operate first actuator subset. Subsequent to learning to operate the first subset, the adaptive controller may be trained to operate another subset of degrees of freedom based on user input via the control apparatus.",B25J 9/16,BRAIN CORPORATION,"PASSOT, Jean-Baptiste; SINYAVSKIY, Oleg; IZHIKEVICH, Eugene","14/070,239 01.11.2013 US",
EP20835551,10170133,20.07.2010,2287694,23.02.2011,EP,Distributed visual guidance for a mobile robotic device,"An apparatus includes a computer system (302), a number of structured light generators (304), and a number of mobile robotic devices (346). The computer system (302) is configured to generate a path plan. The number of structured light generators (304) is configured to project the path plan. The number of mobile robotic devices (346) is configured to detect and follow the path plan.",G05D 1/02,DEERE & CO,ANDERSON NOEL W,54312709 18.08.2009 US; 54315209 18.08.2009 US; 54317609 18.08.2009 US,
EP289344439,19191406,13.08.2019,3618063,04.03.2020,EP,"VOICE INTERACTION SYSTEM, VOICE INTERACTION METHOD, PROGRAM, LEARNING MODEL GENERATION APPARATUS, AND LEARNING MODEL GENERATION METHOD",A voice interaction system capable of appropriately handling a situation so as to effectively prevent a response error from occurring is provided. A speech acquisition unit 102 acquires user speech. A feature extraction unit 104 extracts a feature of the user speech. A response determination unit 120 determines a response corresponding to the extracted feature vector using any one of a plurality of learning models. A response execution unit 130 executes the determined response. A user state detection unit 140 detects a user state. A learning model selection unit 150 selects a learning model from a plurality of learning models in accordance with the detected user state. The response determination unit 120 determines a response using the selected learning model.,G10L 15/22; G06F 3/16; G06K 9/00; G10L 15/06; G10L 17/00; G10L 17/26; G10L 25/51; G10L 25/63; G10L 25/66; H04M 3/493,UNIV KYOTO; TOYOTA MOTOR CO LTD,KAWAHARA TATSUYA; HORI TATSURO; WATANABE NARIMASA,2018162774 31.08.2018 JP,
WO2015158884,PCT/EP2015/058367,17.04.2015,WO/2015/158884,22.10.2015,WO,OMNIDIRECTIONAL WHEELED HUMANOID ROBOT BASED ON A LINEAR PREDICTIVE POSITION AND VELOCITY CONTROLLER,"The object of the invention is a humanoid robot (100) with a body (190) joined to an omnidirectional mobile ground base (140), and equipped with: - a body position sensor and a base position sensor to provide measures, - actuators (212) comprising at least 3 wheels (141) located in the omnidirectional mobile base, - extractors (211) for converting the measures into useful data, - a controller to calculate position, velocity and acceleration commands from the useful data using a robot model and pre-ordered position and velocity references, - means for converting the commands into instructions for the actuators, characterized in that the robot model is a double point-mass model, and in that the commands are based on a linear model predictive control law with a discretized time according to a sampling time period and a number of predicted samples, and expressed as a quadratic optimization formulation with: - a weighted sum of objectives, - a set of predefined linear constraints.",B25J 9/16; B25J 5/00,SOFTBANK ROBOTICS EUROPE; INSTITUT NATIONAL DE RECHERCHE EN INFORMATIQUE ET EN AUTOMATIQUE,"LAFAYE, Jory; GOUAILLIER, David; WIEBER, Pierre-Brice",14305584.6 17.04.2014 EP,AU-2015248710; JP-2017505721; SG-11201608202Y; CA-2946047; US-15300218; CN-201580020099.4; MX-MX/a/2016/013020; RU-2016144026
WO2019215269,PCT/EP2019/061890,09.05.2019,WO/2019/215269,14.11.2019,WO,PERFORMING NAVIGATION TASKS USING GRID CODES,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for selecting actions to be performed by an agent interacting with an environment. In one aspect, a system comprises a grid cell neural network and an action selection neural network. The grid cell network is configured to: receive an input comprising data characterizing a velocity of the agent; process the input to generate a grid cell representation; and process the grid cell representation to generate an estimate of a position of the agent in the environment; the action selection neural network is configured to: receive an input comprising a grid cell representation and an observation characterizing a state of the environment; and process the input to generate an action selection network output.",G06N 3/00; G06N 3/04; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"BANINO, Andrea; KUMARAN, Sudarshan; HADSELL, Raia Thais; URIA-MARTINEZ, Benigno","62/669,355 09.05.2018 US",
WO2019055883,PCT/US2018/051255,15.09.2018,WO/2019/055883,21.03.2019,WO,IMPROVEMENTS RELATED TO GENERATING A ROBOT CONTROL POLICY FROM DEMONSTRATIONS COLLECTED VIA KINESTHETIC TEACHING OF A ROBOT,"Techniques are described herein for generating a dynamical systems control policy. A non-parametric family of smooth maps is defined on which vector-field learning problems can be formulated and solved using convex optimization. In some implementations, techniques described herein address the problem of generating contracting vector fields for certifying stability of the dynamical systems arising in robotics applications, e.g., designing stable movement primitives. These learning problems may utilize a set of demonstration trajectories, one or more desired equilibria (e.g., a target point), and once or more statistics including at least an average velocity and average duration of the set of demonstration trajectories. The learned contracting vector fields may induce a contraction tube around a targeted trajectory for an end effector of the robot. In some implementations, the disclosed framework may use curl-free vector-valued Reproducing Kernel Hilbert Spaces.",G06K 9/62; B25J 9/16; G06N 3/00; G06N 20/10,GOOGLE LLC,"SINDHWANI, Vikas","62/559,285 15.09.2017 US; 62/641,535 12.03.2018 US",EP-2018842594
WO2017159126,PCT/JP2017/004463,07.02.2017,WO/2017/159126,21.09.2017,WO,DIRECT INVERSE REINFORCEMENT LEARNING WITH DENSITY RATIO ESTIMATION,"A method of inverse reinforcement learning for estimating reward and value functions of behaviors of a subject includes: acquiring data representing changes in state variables that define the behaviors of the subject; applying a modified Bellman equation given by Eq. (1) to the acquired data: where r(x) and V(x) denote a reward function and a value function, respectively, at state x, and γ represents a discount factor, and b(y | x) and π(y | x) denote state transition probabilities before and after learning, respectively; estimating a logarithm of the density ratio π(x)/b(x) in Eq. (2); estimating r(x) and V(x) in Eq. (2) from the result of estimating a log of the density ratio π(x, y)/b(x, y); and outputting the estimated r(x) and V(x).",G06N 99/00,OKINAWA INSTITUTE OF SCIENCE AND TECHNOLOGY SCHOOL CORPORATION,"UCHIBE, Eiji; DOYA, Kenji","62/308,722 15.03.2016 US",EP-2017766134; JP-2018546050; KR-1020187026764
WO2006080820,PCT/KR2006/000322,27.01.2006,WO/2006/080820,03.08.2006,WO,METHOD AND SYSTEM FOR RECOMMENDING PREFERRED SERVICE USING MOBILE ROBOT,"Disclosed is a method and a system for recommending a preferred service by using a mobile robot wherein, when a user is provided with various services or information via the mobile robot, time of provision, position of the user, reaction of the user, etc. are stored as a log, the stored log is analyzed and the user's preferred service and information are predicted, based on utilization time and position, and the predicted service and information are recommended to the user when he is in the corresponding time period or position. The mobile robot recommends suitable information or service to a user in conformity with his current position and time and efficiently copes with the user's ever-changing environments. As a result, the user is satisfied with the service from the mobile robot. This substantially improves the user convenience.",G06F 17/00,"SK TELECOM CO., LTD.; WON, Seongho; HAN, Kyounghee; PARK, Shinyoung; LEE, Changsu; KIM, Kyungjin; JOO, Sanghyun","WON, Seongho; HAN, Kyounghee; PARK, Shinyoung; LEE, Changsu; KIM, Kyungjin; JOO, Sanghyun",10-2005-0007987 28.01.2005 KR,EP-06715775; EP-6715775
WO2019035766,PCT/SG2018/050412,14.08.2018,WO/2019/035766,21.02.2019,WO,A LABEL-FREE METHOD AND SYSTEM FOR MEASURING DRUG RESPONSE KINETICS OF THREE-DIMENSIONAL CELLULAR STRUCTURES,"Disclosed herein are methods of providing a computational model for predicting an activity of a test agent with respect to a 3D cell structure, such as spheroid, organoid and tumorsphere. Specifically, machine learning algorithm is employed to generate a quantitative model of drug response in the 3D cell structure using zone-specific image features, wherein the zones comprise a necrotic zone, a quiescent zone, and a proliferating zone. Also disclosed herein are label-free prediction methods using such computational model and a device configured to perform the methods as disclosed herein.",G01N 33/48; G06T 7/11; G06T 7/136,"AGENCY FOR SCIENCE, TECHNOLOGY AND RESEARCH","KOH, Lie Yong Judice; DASGUPTA, Ramanuj; PERIYASAMY, Giridharan",10201706639T 14.08.2017 SG,
WO2015089233,PCT/US2014/069619,10.12.2014,WO/2015/089233,18.06.2015,WO,APPARATUS AND METHODS FOR HAPTIC TRAINING OF ROBOTS,"Robotic devices may be trained by a trainer guiding the robot along a target trajectory using physical contact with the robot. The robot may comprise an adaptive controller configured to generate control commands based on the trainer input, sensory input, and/or performance measure. The trainer may observe task execution by the robot. Responsive to observing a discrepancy between the target behavior and the actual behavior, the trainer may provide a teaching input via a haptic action. The robot may execute the action based on a combination of the internal control signal produced by a learning process of the robot and the training input. The robot may infer the teaching input based on a comparison of a predicted state and actual state of the robot. The robot's learning process may be adjusted in accordance with the teaching input so as to reduce the discrepancy during a subsequent trial.",B25J 9/16; G05B 19/042,BRAIN CORPORATION,"PONULAK, Filip; KAZEMI, Moslem; LAURENT, Patryk; SINYAVSKIY, Oleg; IZHIKEVICH, Eugene M.","14/102,410 10.12.2013 US",
WO2015054264,PCT/US2014/059511,07.10.2014,WO/2015/054264,16.04.2015,WO,METHODS AND APPARATUS FOR REINFORCEMENT LEARNING,We describe a method of reinforcement learning for a subject system having multiple states and actions to move from one state to the next. Training data is generated by operating on the system with a succession of actions and used to train a second neural network. Target values for training the second neural network are derived from a first neural network which is generated by copying weights of the second neural network at intervals.,G06N 3/04; G06N 99/00,GOOGLE INC.,"MNIH, Volodymyr; KAVUKCUOGLU, Koray","61/888,247 08.10.2013 US; 14/097,862 05.12.2013 US",EP-2014819108
WO2020035156,PCT/EP2018/073415,31.08.2018,WO/2020/035156,20.02.2020,WO,METHOD OF PROGRAMMING AN INDUSTRIAL ROBOT,"A method of programming an industrial robot (1 ), said robot (1 ) having a robot arm (2) with an end-effector (4) mounted thereto which is controlled by a robot control unit (6) to manipulate a workpiece (8) which is arranged in a workplace (10) of said robot (1 ), wherein a target coordinate (1 1 ) system is associated to said workplace (10) and an image (12) of said workplace (10) and said workpiece (8) is taken by an image capturing device (14) and transmitted to a computing device (16) having a human- machine-interface (HMI) to generate control code for controlling said robot (1 ) which is transmitted to said robot control unit (6), wherein an image (12) of said workplace (10) and said workpiece (8) to be manipulated by said robot (1) is captured, said captured image (12) is transferred to said computing device (16) and displayed on a display (18) associated to said computing device (16), said workpiece (8) displayed on said display (18) is marked with a marker-object (17) on said display (18), said marker-object (17) is manipulated in a sequence of at least two subsequent manipulating steps which are associated to robot commands on said display (18) by means of said human-machine- interface (HMI), wherein said sequence of manipulating steps includes positions (P1 to P5) of the marker-object (17) in a coordinate system (19) for displaying said marker- object on said display (18), said positions (P1 to P5) of the marker-object (17) in the sequence of manipulating steps are transformed to positions (P1' to P5') of said workpiece (8) in said target coordinate system (11) and control code for controlling said robot (1) is generated from said transformed positions (P1' to P5') and associated robot commands is characterized by the following steps: Measuring a first distance value (D1) between a reference point (RP) which is located above said workpiece and a first measuring location (L1 ) on said workpiece (8), measuring a second distance value (D2) between said reference point (RP) and a second measuring location (L2) on said workplace (10), determining a workpiece height value (WH) associated to said workpiece (8) as the difference between the measured first distance value (D1) and said measured second distance value (D2) and generating said control code and associated robot commands for controlling said robot (1) on basis of said workpiece height value (WH).",B25J 9/16; G05B 19/401,ABB SCHWEIZ AG,"CLEVER, Debora; DAI, Fan",PCT/EP2018/071870 13.08.2018 EP,
WO2018083668,PCT/IB2017/056903,04.11.2017,WO/2018/083668,11.05.2018,WO,SCENE UNDERSTANDING AND GENERATION USING NEURAL NETWORKS,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for image rendering. In one aspect, a method comprises receiving a plurality of observations characterizing a particular scene, each observation comprising an image of the particular scene and data identifying a location of a camera that captured the image. In another aspect, the method comprises receiving a plurality of observations characterizing a particular video, each observation comprising a video frame from the particular video and data identifying a time stamp of the video frame in the particular video. In yet another aspect, the method comprises receiving a plurality of observations characterizing a particular image, each observation comprising a crop of the particular image and data characterizing the crop of the particular image. The method processes each of the plurality of observations using an observation neural network to determine a numeric representation as output.",G06K 9/00; G06T 15/20; G06T 17/00; G06N 3/04,DEEPMIND TECHNOLOGIES LIMITED,"REZENDE, Danilo Jimenez; ESLAMI, Seyed Mohammadali; GREGOR, Karol; BESSE, Frederic Olivier","62/418,144 04.11.2016 US; 62/540,817 03.08.2017 US",JP-2019523597; KR-1020197015932; EP-2017808162; CN-201780077072.8
WO2019033380,PCT/CN2017/097977,18.08.2017,WO/2019/033380,21.02.2019,WO,SLIMMING OF NEURAL NETWORKS IN MACHINE LEARNING ENVIRONMENTS,"A mechanism is described for facilitating slimming of neural networks in machine learning environments. A method of embodiments, as described herein, includes learning a first neural network associated with machine learning processes to be performed by a processor of a computing device, where learning includes analyzing a plurality of channels associated with one or more layers of the first neural network. The method may further include computing a plurality of scaling factors to be associated with the plurality of channels such that each channel is assigned a scaling factor, wherein each scaling factor to indicate relevance of a corresponding channel within the first neural network. The method may further include pruning the first neural network into a second neural network by removing one or more channels of the plurality of channels having low relevance as indicated by one or more scaling factors of the plurality of scaling factors assigned to the one or more channels.",G06N 3/08,"INTEL CORPORATION; YAN, Shoumeng; LI, Jianguo; LIU, Zhuang","YAN, Shoumeng; LI, Jianguo; LIU, Zhuang",,
WO2019021058,PCT/IB2018/000949,25.07.2018,WO/2019/021058,31.01.2019,WO,SYSTEMS AND METHODS FOR OPERATIONS A ROBOTIC SYSTEM AND EXECUTING ROBOTIC INTERACTIONS,"Systems and methods are provided for managing a robotic assistant. Environment data corresponding to a current environment is collected to determine a type of the current environment based on the collected environment data. One or more objects in the current environment are detected. The one or more objects are associated with the type of the current environment. For each of the one or more objects, one or more interactions are identified based on a type of the respective object and the type of the current environment. Object libraries corresponding to the one or more objects are downloaded. The object libraries include interaction data corresponding to the respective identified one or more interactions. At least a portion of the one or more interactions are executed upon the respective one or more objects.",B25J 9/16,MBL LIMITED,"OLEYNIK, Mark","62/678,456 31.05.2018 US; 62/648,711 27.03.2018 US; 62/536,625 25.07.2017 US; 62/546,022 16.08.2017 US; 62/597,449 12.12.2017 US",EP-2018782503; AU-2018306475; SG-11202000652S
WO2019215109,PCT/EP2019/061602,07.05.2019,WO/2019/215109,14.11.2019,WO,CONVOLUTIONAL LOCALIZATION NETWORKS FOR INTELLIGENT CAPTIONING OF MEDICAL IMAGES,"A method (100) for generating a textual description of a medical image, comprising: receiving (130) a medical image of an anatomical region, the image comprising one or more abnormalities; segmenting (140) the anatomical region in the received medical image from a remainder of the image; identifying (150) at least one of the one or more abnormalities in the segmented anatomical region; extracting (160) one or more features from the identified abnormality; generating (170), using the extracted features and a trained text generation model, a textual description of the identified abnormality; and reporting (180), via a user interface of the system, the generated textual description of the identified abnormality.",G06K 9/00; G06K 9/46,KONINKLIJKE PHILIPS N.V.,"SWISHER, Christine, Menking; AL HASAN, Sheikh, Sadid; RUBIN, Jonathan; POTES BLANDON, Cristhian, Mauricio; LING, Yuan; FARRI, Oladimeji, Feyisetan; SREENIVASAN, Rithesh",62/668317 08.05.2018 US,
WO2019012121,PCT/EP2018/069113,13.07.2018,WO/2019/012121,17.01.2019,WO,A METHOD AND APPARATUS FOR PROVIDING AN ADAPTIVE SELF-LEARNING CONTROL PROGRAM FOR DEPLOYMENT ON A TARGET FIELD DEVICE,"A method for deploying and executing self-optimizing functions on a target field device (TFD), the method comprising the steps of providing (S1) a set of functions, f, having at least one tuneable parameter, θ; deriving (S2) automatically from the provided set of functions, f, an additional set of functions used to optimize the tuneable parameters, θ; converting (S3) both sets of functions into a machine executable code specific to said target field device (TFD); and deploying (S4) and executing the converted machine executable code on said target field device (TFD).",G05B 13/04,SIEMENS AKTIENGESELLSCHAFT,"THON, Ingo; SOLER GARRIDO, Josep",17181431.2 14.07.2017 EP,
WO2004095421,PCT/US2004/006028,26.02.2004,WO/2004/095421,04.11.2004,WO,A COUPLED HIDDEN MARKOV MODEL (CHMM) FOR CONTINUOUS AUDIOVISUAL SPEECH RECOGNITION,"Method and apparatus for an audiovisual continuous speech recognition (AVCSR) system using a coupled hidden Markov model (CHMM) are described herein. In one aspect, an exemplary process includes receiving an audio data stream and a video data stream, and performing continuous speech recognition based on the audio and video data streams using a plurality of hidden Markov models (HMMs), a node of each of the HMMs at a time slot being subject to one or more nodes of related HMMs at a preceding time slot. Other methods and apparatuses are also described.",G06K 9/62; G06K 9/68; G10L 15/14; G10L 15/24,INTEL CORPORATION,"NEFIAN, Ara; LIU, Xiaoxing; PI, Xiaobo; LIANG, Luhong; ZHAO, Yibao","10/392,709 19.03.2003 US",GB-GB0513410.1; GB-0513410.1; CN-200480007461.6
WO2020069049,PCT/US2019/053040,25.09.2019,WO/2020/069049,02.04.2020,WO,EMPLOYING THREE-DIMENSIONAL DATA PREDICTED FROM TWO-DIMENSIONAL IMAGES USING NEURAL NETWORKS FOR 3D MODELING APPLICATIONS,"The disclosed subject matter is directed to employing machine learning models configured to predict 3D data from 2D images using deep learning techniques to derive 3D data for the 2D images. In some embodiments, a system is described comprising a memory that stores computer executable components, and a processor that executes the computer executable components stored in the memory. The computer executable components comprise a reception component configured to receive two-dimensional images, and a three-dimensional data derivation component configured to employ one or more three-dimensional data from two-dimensional data (3D-from-2D) neural network models to derive three-dimensional data for the two-dimensional images.",G06N 3/02; G06T 17/00,"MATTERPORT, INC.","GAUSEBECK, David Alan; BELL, Matthew Tschudy; ABDULLA, Waleed K.; HAHN, Peter Kyuhee","16/141,558 25.09.2018 US",
WO2020056373,PCT/US2019/051175,13.09.2019,WO/2020/056373,19.03.2020,WO,STOPPING ROBOT MOTION BASED ON SOUND CUES,"Embodiments provide methods and systems to modify motion of a robot based on sound and context. An embodiment detects a sound in an environment and processes the sound. The processing includes comparing the detected sound to a library of sound characteristics associated with sound cues and/or extracting features or characteristics from the detected sound using a model. Motion of a robot is modified based on a context of the robot and at least one of: (i) the comparison, (ii) the features extracted from the detected sound, and (iii) the characteristics extracted from the detected sound.",B25J 9/16,"THE CHARLES STARK DRAPER LABORATORY, INC.","JOHNSON, David, M.S.; WAGNER, Syler; TAYOUN, Anthony; LINES, Steven","62/730,703 13.09.2018 US; 62/730,947 13.09.2018 US; 62/730,918 13.09.2018 US; 62/731,398 14.09.2018 US; 62/730,933 13.09.2018 US; 62/730,934 13.09.2018 US",
WO2017143063,PCT/US2017/018167,16.02.2017,WO/2017/143063,24.08.2017,WO,"METHODS, MATERIALS AND APPARATUS FOR MOBILE ADDITIVE MANUFACTURING OF ADVANCED STRUCTURES AND ROADWAYS","The present disclosure provides various aspects for mobile and automated processing utilizing additive manufacturing and the methods for their utilization. In some examples, discrete material formats for use in an Additive Manufacturing Array are disclosed. Methods of using the additive manufacturing robot, discrete materials, and the roadways produced with the additive manufacturing robot are provided. A combined function Addibot, with Additive Manufacturing capabilities, cleaning capabilities, line painting capabilities and seal coating capabilities which may be used in concert with a camera equipped aerial drone for design and characterization function is described.",G06F 19/00,"FLITSCH, Robert; FLITSCH, Frederick","FLITSCH, Robert; FLITSCH, Frederick","62/296,504 17.02.2016 US; 62/299,405 24.02.2016 US; 62/322,169 13.04.2016 US; 62/334,783 11.05.2016 US",EP-2017753835
EP278935530,18748623,23.01.2018,3578322,11.12.2019,EP,ROBOT PATH-GENERATING DEVICE AND ROBOT SYSTEM,"[Problem] To generate more appropriate paths. [Solution] The present invention comprises: a database 34 for holding a path-planning unit learning data set that associates multiple path data, which are generated on the basis of movement restriction conditions for a robot 5, with assessment value data, which respectively correspond to the path data and are a measure of a specified assessment criterion; and a path-planning unit 32 for generating a path T1 for the robot 5 between a set start point Ps and a set endpoint Pe, which are set at will, on the basis of a machine learning process result based on the path-planning unit learning data set.",B25J 9/22,YASKAWA ELECTRIC CORP,SOKABE KOJI; ADACHI MASARU,2017015408 31.01.2017 JP; 2018001917 23.01.2018 JP,
WO2018048575,PCT/US2017/046608,11.08.2017,WO/2018/048575,15.03.2018,WO,SYSTEM AND METHOD FOR LEARNING MODELS OF RADIOTHERAPY TREATMENT PLANS TO PREDICT RADIOTHERAPY DOSE DISTRIBUTIONS,"The present disclosure relates to systems and methods for developing radiotherapy treatment plans though the use of machine learning approaches and neural network components. A neural network is trained using one or more three-dimensional medical images, one or more three-dimensional anatomy maps, and one or more dose distributions to predict a fluence map or a dose map. During training the neural network receives a predicted dose distribution determined by the neural network that is compared to an expected dose distribution. Iteratively the comparison is performed until a predetermined threshold is achieved. The trained neural network is then utilized to provide a three-dimensional dose distribution.",A61N 5/10; G06N 3/04; G06N 3/08; G06N 3/02; G06F 19/00,"ELEKTA, INC.","HIBBARD, Lyndon S.","62/384,192 07.09.2016 US",AU-2017324627; JP-2019513074; EP-2017755011; RU-2019110153; CN-201780062011.4
EP13810361,01126516,13.11.2001,1246166,02.10.2002,EP,Speech recognition based captioning system,A system and associated method of converting audio data from a television signal into textual data for display as a closed caption on an display device is provided. The audio data is decoded and audio speech signals are filtered from the audio data. The audio speech signals are parsed into phonemes in accordance by a speech recognition module. The parsed phonemes are grouped into words and sentences responsive to a database of words corresponding to the grouped phonemes. The words are converted into text data which is formatted for presentation on the display device as closed captioned textual data. <IMAGE>,G10L 15/26; H04N 5/278; G10L 15/00; G10L 15/02; G10L 15/14; H04N 5/445; H04N 5/60,MATSUSHITA ELECTRIC IND CO LTD,KAHN MICHAEL,82040101 29.03.2001 US,
WO2012130251,PCT/EG2011/000005,28.03.2011,WO/2012/130251,04.10.2012,WO,IMAGE UNDERSTANDING BASED ON FUZZY PULSE - COUPLED NEURAL NETWORKS,"A computational intelligent system for image understanding. It constitutes of an image segmentation system based on fuzzy-pulse- couple neural networks, and a classification system based on an integer-CHC genetic algorithm feature selection is performed with the ICHCGA and fuzzy artmap neural networks. The system is applied on mammogram images.",G06K 9/00,"AL-ROMIMAH, Abdalslam, Ahmed, Abdalgaleel; BADR, Amr Ahmed; ABDEL RAHMAN , Ibrahim, Farag","AL-ROMIMAH, Abdalslam, Ahmed, Abdalgaleel; BADR, Amr Ahmed; ABDEL RAHMAN , Ibrahim, Farag",,
WO2018187496,PCT/US2018/026119,04.04.2018,WO/2018/187496,11.10.2018,WO,PLASMA BASED PROTEIN PROFILING FOR EARLY STAGE LUNG CANCER PROGNOSIS,"The invention provides biomarkers and combinations of biomarkers useful in diagnosing non-small cell lung cancer. Measurements of these biomarkers are inputted into a classification system such as Random Forest to assist in determining the likelihood that an individual has non-small cell lung cancer. Kits comprising agents for detecting the biomarkers and combination of biomarkers, as well as systems that assist in diagnosing non-small cell lung cancer are also provided.",C12Q 1/68; G01N 33/574; G06F 19/00; G06F 19/12,"LUNG CANCER PROTEOMICS, LLC","GOEBEL, Cherylle; LOUDEN, Christopher; LONG, Thomas C.","62/481,474 04.04.2017 US",CN-201880036985.X; JP-2019555107; CA-3058481; AU-2018248293; EP-2018780542
WO2019186146,PCT/GB2019/050865,27.03.2019,WO/2019/186146,03.10.2019,WO,COLLABORATIVE ROBOT SYSTEM,"A system for robot and human collaboration. The system comprises: a multi- axis robot (102);one or more torque sensors (141-146), each torque sensor (141-146) being configured to measure a torque about a respective axis (121- 26) of the multi-axis robot (102); and a controller (108) configured to:receive one or more torque measurements taken by the one or more torque sensors (141-146); compare the one or more torque measurements or a function of the one or more torque measurements to a threshold value; and control the multi- axis robot (102) based on the comparison.",B25J 9/16; G05B 19/416,BAE SYSTEMS plc,"KNOTT, Martin; MIDDLETON, Daniel, James",1805054.2 28.03.2018 GB; 18164756.1 28.03.2018 EP; 1805056.7 28.03.2018 GB; 18164760.3 28.03.2018 EP,
EP209681334,16167611,29.04.2016,3239792,01.11.2017,EP,SERVER BASED ROBOTIC SYSTEM AND A METHOD FOR OPERATING THE ROBOTIC SYSTEM,"The invention concerns a server based robotic system providing online robot control functions comprising a robot unit having at least one actuator and / or one sensor and an I/O-interface for receiving and transmitting signals, a server unit providing executable programs for controlling the robot unit, executing actuator and/or sensor signal processing and am I/O-interface for receiving and transmitting signals and a communication network for exchanging the signals between the robot unit and the server unit.  Further a method is described for operating a robotic system using the system as mentioned before. The method comprises the following steps: a) providing executable programs for controlling the robot unit and executing actuator and/or sensor signal processing on the server unit, b) activating at least one executable program at the server and generating an output, c) transmitting the at least one output by the communication network to the robot unit and d) performing an action by the robot unit based on said output.",G05B 19/18; B25J 9/16; H04L 29/08,ROBOTICS CLUB LTD,HELMS EVERT,16167611 29.04.2016 EP,
EP252255986,18214015,19.12.2018,3542971,25.09.2019,EP,GENERATING LEARNED KNOWLEDGE FROM AN EXECUTABLE DOMAIN MODEL,"A computer-implemented method for performing autonomous operations in an operating environment includes simulating the operating environment to generate a plurality of examples. Each example comprises (a) signal data describing a scene, (b) one or more objects present in the scene, and (c) a description of characteristics associated with the objects. A machine learning model is trained using the examples to generate a data structure comprising (i) objects associated with a signal and (ii) characteristics corresponding to the objects associated with the signal. A signal sensor of an autonomous device collects an input signal describing a new scene. The machine learning model is used to generate an output data structure based on the input signal. One or more objects are identified using the output data structure. One or more actions are generated for operating the autonomous device based on the characteristics associated with the identified objects.",B25J 9/16,SIEMENS AG,MCDANIEL RICHARD GARY; QUIROS ARAYA GUSTAVO ARTURO; FRADKIN DMITRIY,201862645361 20.03.2018 US,
WO2013184688,PCT/US2013/044124,04.06.2013,WO/2013/184688,12.12.2013,WO,STOCHASTIC APPARATUS AND METHODS FOR IMPLEMENTING GENERALIZED LEARNING RULES,"Generalized learning rules may be implemented. A framework may be used to enable adaptive signal processing system to flexibly combine different learning rules (supervised, unsupervised, reinforcement learning) with different methods (online or batch learning). The generalized learning framework may employ time-averaged performance function as the learning measure thereby enabling modular architecture where learning tasks are separated from control tasks, so that changes in one of the modules do not necessitate changes within the other. The generalized learning apparatus may be capable of implementing several learning rules concurrently based on the desired control application and without requiring users to explicitly identify the required learning rule composition for that application.",G06N 3/02,BRAIN CORPORATION,"SINYAVSKIY, Oleg; COENEN, Olivier","13/487,499 04.06.2012 US",
WO2019226051,PCT/NL2019/050301,24.05.2019,WO/2019/226051,28.11.2019,WO,"MONITORING AND ANALYZING BODY LANGUAGE WITH MACHINE LEARNING, USING ARTIFICIAL INTELLIGENCE SYSTEMS FOR IMPROVING INTERACTION BETWEEN HUMANS, AND HUMANS AND ROBOTS","There is provided a body language system for determining a body language message of a living being in a context, said system comprising an artificial intelligence (AI) system, said AI system running a computer program that: - retrieves at least one image of said living being showing body language; - labels said living being in said at least one image, resulting in a labeled living being; - determines said context from said at least one image using a trained machine learning model; - determines a baseline body language of said labeled living being from said at least one image using a trained machine learning model; - adapts a trained machine learning model of said AI system using said baseline body language and said context; - applies the adapted trained machine learning model of said AI system to at least one of said at least one image for categorizing said body language resulting in a category, and applying said category for determining said body language message.",G06K 9/00,KEPLER VISION TECHNOLOGIES B.V.,"STOKMAN, Henricus Meinardus Gerardus; VAN OLDENBORGH, Marc Jean Baptist; ALNAJAR, Fares",2020989 25.05.2018 NL; 2020996 28.05.2018 NL,EP-2019743015
WO2018094295,PCT/US2017/062434,18.11.2017,WO/2018/094295,24.05.2018,WO,ADAPTIVE ATTENTION MODEL FOR IMAGE CAPTIONING,"The technology disclosed presents a novel spatial attention model that uses current hidden state information of a decoder long short-term memory (LSTM) to guide attention and to extract spatial image features for use in image captioning. The technology disclosed also presents a novel adaptive attention model for image captioning that mixes visual information from a convolutional neural network (CNN) and linguistic information from an LSTM. At each timestep, the adaptive attention model automatically decides how heavily to rely on the image, as opposed to the linguistic model, to emit the next caption word. The technology disclosed further adds a new auxiliary sentinel gate to an LSTM architecture and produces a sentinel LSTM (Sn-LSTM). The sentinel gate produces a visual sentinel at each timestep, which is an additional representation, derived from the LSTM's memory, of long and short term visual and linguistic information.",G06N 3/04,"SALESFORCE.COM, INC.","LU, Jiasen; XIONG, Caiming; SOCHER, Richard","62/424,353 18.11.2016 US; 15/817,153 17.11.2017 US; 15/817,161 17.11.2017 US; 15/817,165 18.11.2017 US",
WO2018107343,PCT/CN2016/109547,12.12.2016,WO/2018/107343,21.06.2018,WO,ROBOT GESTURE GENERATION,"A method and apparatus for robot gesture generation is described. Generally speaking, a concept corresponding to a utterance to be spoken by a robot is determined (204). After a concept is determined or selected, a symbolic representation of a gesture that corresponds to the determined concept is retrieved from a predetermined gesture library (206). Subsequently, the symbolic representation is provided to cause the robot to perform the gesture (208). In such way, a more natural, comprehensive and effective communication between human and robots may be achieved.",B25J 9/16,"MICROSOFT TECHNOLOGY LICENSING, LLC.","IKEUCHI, Katsushi; HABIB, Mona Soliman",,EP-2016923912; CN-201680091517.3
WO2006113755,PCT/US2006/014634,18.04.2006,WO/2006/113755,26.10.2006,WO,CONTROLLING A ROBOT USING POSE,Systems and methods are presented that enable robot commands to be determined based on the pose of an object. A method is described for determining the orientation and pose of an object using indistinguishable points. The resolution of the pose detection is based on the robot's command vocabulary. A system is described for controlling a robot by pose detection using unlabelled points.,G06F 19/00,"HONDA MOTOR CO., LTD.; GONZALEZ-BANOS, Hector; NG-THOW-HING, Victor","GONZALEZ-BANOS, Hector; NG-THOW-HING, Victor","60/672,916 18.04.2005 US; 11/406,483 17.04.2006 US",JP-2008507820; EP-6750629; RU-null
WO2019127231,PCT/CN2017/119453,28.12.2017,WO/2019/127231,04.07.2019,WO,TRAINING DATA GENERATORS AND METHODS FOR MACHINE LEARNING,"Training data generators and methods for machine learning are disclosed. An example method to generate training data for machine learning by generating simulated training data for a target neural network, transforming, with a training data transformer, the simulated training data form transformed training data, the training data transformer trained to increase a conformance of the transformed training data and the simulated training data, and training the target neural network with the transformed training data.",G06K 9/62,"INTEL CORPORATION; SHI, Xuesong; WANG, Zhigang","SHI, Xuesong; WANG, Zhigang",,
EP178063629,15162447,02.04.2015,3075496,05.10.2016,EP,METHOD FOR IMPROVING OPERATION OF A ROBOT,"The invention relates to a method for improving operation of at least one robot. The robot is being operated on the basis of a set of predefined actions. A method comprises:  Generating combined actions (51, 53) by combining at least two actions out of a set of original actions stored in an action library. Storing the combined actions in the actions library in addition to the original actions. Applying a reinforcement learning algorithm (S4) to the set of actions stored now in the action library to learn a control policy making use of the original actions and the combined actions. And finally, operating the robot on the basis of the resulting action library.",B25J 9/16,HONDA RES INST EUROPE GMBH,MÜHLIG MANUEL; GIENGER MICHAEL; HAYASHI AKINOBU,15162447 02.04.2015 EP,
WO2018217828,PCT/US2018/033986,22.05.2018,WO/2018/217828,29.11.2018,WO,METHODS AND APPARATUS FOR DISCRIMINATIVE SEMANTIC TRANSFER AND PHYSICS-INSPIRED OPTIMIZATION OF FEATURES IN DEEP LEARNING,"Methods and apparatus for discrimitive semantic transfer and physics-inspired optimization in deep learning are disclosed. A computation training method for a convolutional neural network (CNN) includes receiving a sequence of training images in the CNN of a first stage to describe objects of a cluttered scene as a semantic segmentation mask. The semantic segmentation mask is received in a semantic segmentation network of a second stage to produce semantic features. Using weights from the first stage as feature extractors and weights from the second stage as classifiers, edges of the cluttered scene are identified using the semantic features.",G06N 3/08; G06N 3/04,INTEL CORPORATION,"YAO, Anbang; ZHAO, Hao; LU, Ming; GUO, Yiwen; CHEN, Yurong","62/509,960 23.05.2017 US; 62/509,990 23.05.2017 US",EP-2018805872
WO2019232466,PCT/US2019/035037,31.05.2019,WO/2019/232466,05.12.2019,WO,MACHINE LEARNING MODEL RE-TRAINING BASED ON DISTRIBUTED FEEDBACK,"Machine learning model re-training based on distributed feedback received from a plurality of edge computing devices is provided. A trained instance of a machine learning model is transmitted, via one or more communications networks, to the plurality of edge computing devices. Feedback data is collected, via the one or more communications networks, from the plurality of edge computing devices. The feedback data includes labeled observations generated by the execution of the trained instance of the machine learning model at the plurality of edge computing devices on unlabeled observations captured by the plurality of edge computing devices. A re-trained instance of the machine learning model is generated from the trained instance using the collected feedback data. The re-trained instance of the machine learning model is transmitted, via the one or more communications networks, to the plurality of edge computing devices.",G06N 20/10; G06N 3/02; G06N 3/08,NAMI ML INC.,"PEZZILLO, Joseph D.; BURCAW, Daniel","62/679,256 01.06.2018 US; 62/681,200 06.06.2018 US; 16/428,540 31.05.2019 US",
WO2019095038,PCT/CA2018/000223,14.11.2018,WO/2019/095038,23.05.2019,WO,SECURITY ROBOT WITH LOW SCANNING CAPABILITIES,"A mobile robot with one or more deployable scanning wands that advantageously mounts each scanning wand for movement from a storage position in or adjacent to a wall of the mobile base unit to a deployed position extending outwardly from the robot adjacent ground level. Preferably, the robot includes two or more deployable scanning wands and a holonomic drive function is provided in the mobile base unit. This drive allows controlled linear and rotational movement of the robot to provide an effective scan area. Sensors can be provided in the sides of the mobile base for assistance in control of the drive and/or further scanning of a vehicle, trailer or object of interest.",G01N 37/00; B25J 19/02; B25J 5/00; B25J 9/18,CROSSWING INC.,"SUTHERLAND, Stephen; GUILLAUMONT, Philippe; SUTHERLAND, Daniel","2,985,566 15.11.2017 CA",
WO2007047514,PCT/US2006/040217,16.10.2006,WO/2007/047514,26.04.2007,WO,ROBOTIC RETRIEVAL AND DELIVERY SYSTEM,"Systems, methods and devices for the automated retrieval/delivery of goods from one location to another using a robotic device such as a tug and accompanying cart. A computer within the tug/cart stores a map of the building floor plan and intended paths for the tug to take when traversing from one location to the next. During the delivery, a variety of different sensors and scanners gather data that is used to avoid obstacles and/or continuously adjust the movement of the tug in order to more closely follow the intended path. The system preferably includes wireless networks that allow one or more tugs to communicate with a tug base station, a primary network located at the site of the delivery and a remote host center that monitors the status and data collected by the tugs.",G06F 19/00,"AETHON, INC.","ZINI, Aldo; ALLEN Spencer Wayne; SKIRBLE, Barry Mark; THORNE Henry f.","60/727,280 14.10.2005 US",CA-2625895; EP-6825962
EP11901364,88112175,27.07.1988,0301527,01.02.1989,EP,DEVICE AND METHOD FOR CORRECTION OF ROBOT INACCURACY,"A method and device for improving orientation and/or location accuracy of a programmable robot with respect to a target object. The method consists of calibrating the position of a terminal control frame associated with a robot end-effector which is coupled to a robot distal link. Separated reference positions external from the robot are identified, as to geometry and spatial data. This identification data is stored for later recall and comparison for use in determining a localized relative frame of reference. The robot end-effector is moved to a first reference position and a rigid body error correction is determined. This correction is stored in computer memory for application to later computer movement.",B25J 9/10; B25J 9/16; B25J 9/18; G05B 19/18; G05B 19/19; G05B 19/404; G05B 19/418,BRIGHAM YOUNG UNIVERSITY,"RED, WALTER E.; DAVIES, BRADY R.; WANG, XUGUANG; TURNER, EDGAR R.",7916887 28.07.1987 US,
EP222931970,17847785,18.01.2017,3345086,11.07.2018,EP,A PHYSICAL MODEL AND MACHINE LEARNING COMBINED METHOD TO SIMULATE AUTONOMOUS VEHICLE MOVEMENT,"In one embodiment, a driving scenario is identified for a next movement for an autonomous vehicle, where the driving scenario is represented by a set of one or more predetermined parameters. A first next movement is calculated for the autonomous vehicle using a physical model corresponding to the driving scenario. A sideslip predictive model is applied to the set of predetermined parameters to predict a sideslip of the autonomous vehicle under the driving scenario. A second next movement of the autonomous vehicle is determined based on the first next movement and the predicted sideslip of the autonomous vehicle. The predicted sideslip is utilized to modify the first next movement to compensate the sideslip. Planning and control data is generated for the second next movement and the autonomous vehicle is controlled and driven based on the planning and control data.",G08G 1/16; B60W 30/045; B60W 30/18; B60W 50/00; G05D 1/02,BAIDU USA LLC,ZHU FAN; KONG QI; YANG GUANG; WANG JINGAO,201615278719 28.09.2016 US; 2017013930 18.01.2017 US,
EP13715068,01917788,02.04.2001,1195231,10.04.2002,EP,"ROBOT DEVICE, ROBOT DEVICE ACTION CONTROL METHOD, EXTERNAL FORCE DETECTING DEVICE AND EXTERNAL FORCE DETECTING METHOD","A robot (1) is proposed which includes a speech recognition unit (101) to detect information supplied simultaneously with or just before or after detection of a touch by a touch sensor, an associative memory/recall memory (104) to store action made correspondingly to the touch and input information (speech signal) detected by the speech recognition unit (101) in association with each other, and an action generator (105) to control the robot (1) to make action recalled by the associative memory/recall memory (104) based on a newly acquired input information (speech signal). The robot (1) includes also a sensor data processor (102) to allow the robot (1) to act correspondingly to the touch detection by the touch sensor. Thus, the robot (1) can learn action in association with an input signal such as speech signal. <IMAGE>",B25J 9/22; B25J 13/00; B25J 13/08; G06K 9/62; G06N 3/00; G10L 15/26,SONY CORP,FUJITA MASAHIRO; TAKAGI TSUYOSHI; HASEGAWA RIKA; HANAGATA OSAMU; YOKONO JUN; COSTA GABRIEL; SHIMOMURA HIDEKI,0102867 02.04.2001 JP; 2000101364 31.03.2000 JP; 2000280871 14.09.2000 JP,
WO2018165753,PCT/CA2018/050304,14.03.2018,WO/2018/165753,20.09.2018,WO,STRUCTURE DEFECT DETECTION USING MACHINE LEARNING ALGORITHMS,"Structure defect detection is performed using computer-implemented arrangements employing machine learning algorithms in the form of neural networks. In one arrangement, a convolutional neural network is trained using a database of images formed to optimize accuracy of the convolutional neural network to detect, for example, a crack in a concrete surface. A two-stage scanning process each performing a plurality of scans of a test image is incorporated in the foregoing arrangement of convolutional neural network, with the two-stages forming overlapping capture areas to reduce likelihood of a crack lying on a boundary of the individual scans going undetected. Also, region-based convolutional neural networks are trained to detect various types of defects.",G01N 21/88; G06N 3/02; G06N 3/08,UNIVERSITY OF MANITOBA,"CHA, Young Jin; CHOI, Wooram","62/471,090 14.03.2017 US; 62/551,510 29.08.2017 US",CA-3056498; EP-2018766855
WO2019139659,PCT/US2018/056827,22.10.2018,WO/2019/139659,18.07.2019,WO,SYSTEM AND METHODS FOR ROBOTIC AUTONOMOUS MOTION PLANNING AND NAVIGATION,"The present approach relates to navigation (e.g., route planning and movement) of robots in an indoor environment shared with humans. The present approach includes detecting human activity over time, including but not limited to human motion; modeling human activities using the historical human activity, and using the modeled human activity to plan robotic motion or movement.",G05D 1/02; G05D 1/00,GENERAL ELECTRIC COMPANY,"TAN, Huan; DEROSE, Lynn Ann; XU, Yi; ZHAO, Yang","15/870,534 12.01.2018 US",
WO2013192500,PCT/US2013/046996,21.06.2013,WO/2013/192500,27.12.2013,WO,USER INTERFACES FOR ROBOT TRAINING,"In accordance with various embodiments, a user interface embedded into a robot facilitates robot training via direct and intuitive physical interactions. In some embodiments, the user interface includes a wrist cuff that, when grasped by the user, switches the robot into zero-force gravity-compensated mode.",B25J 9/16; G05B 19/42; B25J 13/02; B25J 11/00,"RETHINK ROBOTICS, INC.; CHEN, Elaine, Y.; BROOKS, Rodney; BLUMBERG, Bruce; DYE, Noelle; CAINE, Michael; SUSSMAN, Michael; LINDER, Natan; LONG, Paula; BUEHLER, Christopher, J.; WILLIAMSON, Matthew, M.; ROMANO, Joseph, M.; GOODWIN, William, A.","CHEN, Elaine, Y.; BROOKS, Rodney; BLUMBERG, Bruce; DYE, Noelle; CAINE, Michael; SUSSMAN, Michael; LINDER, Natan; LONG, Paula; BUEHLER, Christopher, J.; WILLIAMSON, Matthew, M.; ROMANO, Joseph, M.; GOODWIN, William, A.","13/621,657 17.09.2012 US; 13/621,561 17.09.2012 US; 13/621,519 17.09.2012 US; 61/676,586 27.07.2012 US; 13/621,687 17.09.2012 US; 61/662,646 21.06.2012 US; 13/621,658 17.09.2012 US; 13/621,708 17.09.2012 US; 13/621,517 17.09.2012 US; 13/621,648 17.09.2012 US; 13/621,706 17.09.2012 US",EP-2013740399; JP-2015518601
WO2018002861,PCT/IB2017/053901,29.06.2017,WO/2018/002861,04.01.2018,WO,THERMOGRAPHY-BASED BREAST CANCER SCREENING USING A MEASURE OF SYMMETRY,"What is disclosed is a system and method for breast cancer screening which determines whether hot spots, as seen in a thermal image of both breasts, can be classified as possibly malignant based on a measure of symmetry. A thermographic image of both breasts of a patient is received and analyzed to determine whether there exists, in each of a left breast and a right breast, a hot spot comprising a patch of pixels with an elevated temperature with respect to surrounding tissue. If a hot spot has been identified in each breast then a measure of symmetry comprising a ratio of an area of a smaller hot spot to an area of a larger hot spot is extracted from the thermographic image. The measure of symmetry is provided to a classifier system trained to classify an unclassified hot spot as malignant or non-malignant based on a measure of symmetry.",A61B 5/01; A61B 8/08; G06T 7/00; G01N 33/574,NIRAMAI HEALTH ANALYTIX PVT. LTD.,"VENKATARAMANI, Krithika; JABBIREDDY, Susmija; J. MADHU, Himanshu; TEJA KAKILETI, Siva; V. RAMPRAKASH, Hadonahalli","62/356,176 29.06.2016 US",
WO2018137807,PCT/EP2017/079266,15.11.2017,WO/2018/137807,02.08.2018,WO,METHOD AND APPARATUS FOR COLLECTING OPERATING DATA OF AN INDUSTRIAL ROBOT APPLICATION,"A method of collecting operating data (2) of an industrial robot (4), said robot (4) having a robot control unit (6) for controlling said robot (4) and a first communication interface (8) for receiving and/or transmitting said operating data (2) from/to a central processing unit (10), said central processing unit (10) having a second communication interface (12) for receiving and/or transmitting said operating data (2) and a data mining unit (14) for analyzing said received operating data (2), is characterized by the method steps of collecting the operating data (2) of said robot (4) with a collecting frequency (15) and transmitting said collected operating data (2) to said central processing unit (10) when operating said robot (4), analyzing said collected operating data (2) and computing an indicator value (16) from said collected operating data (2) by means of said data mining unit (14), comparing said indicator value (16) with a predetermined probability threshold value (18), setting said collecting frequency (15) to a lower collecting frequency (20) if said indicator value (16) is below said predetermined probability threshold value (18), and setting said collecting frequency (15) to a higher collecting frequency (22) if said indicator value (16) is above said predetermined probability threshold value (18). The invention is further related to an apparatus for carrying out the method.",B25J 9/16,ABB SCHWEIZ AG,"KLÖPPER, Benjamin; SCHMIDT, Benedikt; QUERTANI, Mohamed-Zied",17153758.2 30.01.2017 EP,CN-201780085141.X; JP-2019534785
WO2018094294,PCT/US2017/062433,18.11.2017,WO/2018/094294,24.05.2018,WO,SPATIAL ATTENTION MODEL FOR IMAGE CAPTIONING,"The technology disclosed presents a novel spatial attention model that uses current hidden state information of a decoder long short-term memory (LSTM) to guide attention and to extract spatial image features for use in image captioning. The technology disclosed also presents a novel adaptive attention model for image captioning that mixes visual information from a convolutional neural network (CNN) and linguistic information from an LSTM. At each timestep, the adaptive attention model automatically decides how heavily to rely on the image, as opposed to the linguistic model, to emit the next caption word. The technology disclosed further adds a new auxiliary sentinel gate to an LSTM architecture and produces a sentinel LSTM (Sn-LSTM). The sentinel gate produces a visual sentinel at each timestep, which is an additional representation, derived from the LSTM's memory, of long and short term visual and linguistic information.",G06N 3/04,"SALESFORCE.COM, INC.","LU, Jiasen; XIONG, Caiming; SOCHER, Richard","62/424,353 18.11.2016 US; 15/817,153 17.11.2017 US; 15/817,161 17.11.2017 US; 15/817,165 18.11.2017 US",CA-3040165; CN-201780071579.2; EP-2017821750
WO2017151759,PCT/US2017/020185,01.03.2017,WO/2017/151759,08.09.2017,WO,CATEGORY DISCOVERY AND IMAGE AUTO-ANNOTATION VIA LOOPED PSEUDO-TASK OPTIMIZATION,"Methods and apparatus are disclosed for providing a looped deep pseudo-task automation approach for automatic category discovery as can be applied to a collection of images. In one example of the disclosed technology, a method of analyzing a collection of images includes extracting at least a portion of the activation values and weights associated with internal nodes of the neural network responsive to a respective input image of the collection of images being applied to the neural network, encoding the extracted activation values and weights, producing encoded vectors, clustering at least a portion of the collection of images based on similarities of the encoded vectors, to produce a plurality of clusters, and evaluating the clusters with a convergence criteria.",G06N 3/04; G06N 3/08,"THE UNITED STATES OF AMERICA, AS REPRESENTED BY THE SECRETARY, DEPARTMENT OF HEALTH AND HUMAN SERVICES","LU, Le; WANG, Xiaosong; SUMMERS, Ronald, M.","62/302,096 01.03.2016 US",
EP246633927,17843971,24.08.2017,3505310,03.07.2019,EP,MOBILE ROBOT AND CONTROL METHOD THEREFOR,"The mobile robot according to one aspect of the present invention comprises: a drive unit for moving a main body; an image obtainment unit for obtaining images around the main body; a storage unit for storing the images obtained by the image obtainment unit; a sensor unit comprising one or more sensors for sensing obstacles during travel; and a control unit for controlling such that partial areas are extracted from the images obtained by the image obtainment unit so as to correspond to the directions of the obstacles sensed by the sensor unit, the mobile robot thus being capable of extracting efficient data for machine learning and obstacle attribute recognition.",B25J 11/00; A47L 9/28; B25J 9/00; B25J 9/16; B25J 19/02,LG ELECTRONICS INC,NOH DONGKI; LEE JUHYEON; KIM JUNGHWAN; BAEK SEUNGMIN; YANG WONKEUN,20160108384 25.08.2016 KR; 20160108385 25.08.2016 KR; 20160108386 25.08.2016 KR; 2017009257 24.08.2017 KR,
WO2016145379,PCT/US2016/022127,11.03.2016,WO/2016/145379,15.09.2016,WO,Automated Compilation of Probabilistic Task Description into Executable Neural Network Specification,"A mechanism for compiling a generative description of an inference task into a neural network. First, an arbitrary generative probabilistic model from the exponential family is specified (or received). The model characterizes a conditional probability distribution for measurement data given a set of latent variables. A factor graph is generated for the generative probabilistic model. Each factor node of the factor graph is expanded into a corresponding sequence of arithmetic operations, based on a specified inference task and a kind of message passing algorithm. The factor graph and the sequences of arithmetic operations specify the structure of a neural network for performance of the inference task. A learning algorithm is executed, to determine values of parameters of the neural network. The neural network is then ready for performing inference on operational measurements.",G06F 19/00; G06N 3/02; G10L 15/14,WILLIAM MARSH RICE UNIVERSITY,"PATEL, Ankit B.; BARANIUK, Richard G.","62/131,872 12.03.2015 US; 62/137,656 24.03.2015 US",
WO2010120307,PCT/US2009/040895,17.04.2009,WO/2010/120307,21.10.2010,WO,STORAGE DEVICE TESTING,A storage device testing system (100) includes at least one robotic arm (200) defining a first axis (205) substantially normal to a floor surface (10). The robotic arm is operable to rotate through a predetermined arc about and extend radially from the first axis. Multiple racks (300) are arranged around the robotic arm for servicing by the robotic arm. Each rack houses multiple test slots (310) that are each configured to receive a storage device transporter (550) configured to carry a storage device (500) for testing.,G01R 31/02; G11B 20/18; G02B 27/00,"TERADYNE, INC.; GARCIA, Edward; MERROW, Brian, S.; POLYAKOV, Evgeny; VAHEY, Walter; TRUEBENBACH, Eric, L.","GARCIA, Edward; MERROW, Brian, S.; POLYAKOV, Evgeny; VAHEY, Walter; TRUEBENBACH, Eric, L.",,MY-PI 2010002886; JP-2012505868; US-13264665; CN-200980104008.X; KR-1020107020738
EP14853550,07012599,27.06.2007,1875991,09.01.2008,EP,Measuring system and calibration method,"A measuring system and a calibration method for automatically calculating errors of mechanical parameters with high accuracy and correcting the parameters, by means of a relatively small and inexpensive measuring device. In relation to a plurality of positions of measurement, a robot (1) is automatically moved such that, on a light receiving surface of a camera (4), the distance between the centers of an ellipse indicating a mark (7) of a target and a circle of representing the shape of the target, and the difference between the length of the long axis of the ellipse and the diameter of the circle are within a predetermined error range.",B25J 9/16; B25J 9/10; B25J 13/08; G01B 21/04; G05B 19/18,FANUC CORP,BAN KAZUNORI; TAKIZAWA KATSUTOSHI; SHEN GANG,2006183375 03.07.2006 JP,
WO2015158885,PCT/EP2015/058370,17.04.2015,WO/2015/158885,22.10.2015,WO,OMNIDIRECTIONAL WHEELED HUMANOID ROBOT BASED ON A LINEAR PREDICTIVE POSITION AND VELOCITY CONTROLLER,"The object of the invention is a humanoid robot (100) with a body (190) joined to an omnidirectional mobile ground base (140), equipped with : - a body position sensor, a base position sensor and an angular velocity sensor to provide measures, - actuators (212) comprising at least 3 wheels located in the omnidirectional mobile base, - extractors (211) for converting sensored measures into useful data, - a supervisor (500) to calculate position, velocity and acceleration commands from the useful data, - means for converting commands into instructions for the actuators, characterized in that the supervisor comprises: - a no-tilt state controller (501), a tilt state controller (502) and a landing state controller (503), each controller comprising means for calculating, position, velocity and acceleration commands based on a double point-mass robot model with tilt motion and on a linear model predictive control law, expressed as a quadratic optimization formulation with a weighted sum of objectives, and a set of predefined linear constraints.",B25J 9/16; B25J 5/00,SOFTBANK ROBOTICS EUROPE; INSTITUT NATIONAL DE RECHERCHE EN INFORMATIQUE ET EN AUTOMATIQUE,"LAFAYE, Jory; COLLETTE, Cyrille; WIEBER, Pierre-Brice",14305585.3 17.04.2014 EP,JP-2017505722; CA-2946049; US-15300221; AU-2015248711; SG-11201608204Q; RU-2016144008; CN-201580020076.3; MX-MX/a/2016/013016
WO2019141197,PCT/CN2019/072049,16.01.2019,WO/2019/141197,25.07.2019,WO,"METHOD OF GENERATING TRAINING DATA FOR TRAINING NEURAL NETWORK, METHOD OF TRAINING NEURAL NETWORK AND USING NEURAL NETWORK FOR AUTONOMOUS OPERATIONS","A method of generating training data for training a neural network, method of training a neural network and using a neural network for autonomous operations, related devices and systems. In one aspect, a neural network for autonomous operation of an object in an environment is trained. Policy values are generated based a sample data set. An approximate action-value function is generated from the policy values. A set of approximated policy values is generated using the approximate action-value function for all states in the sample data set for all possible actions. Attaining target for the neural network is calculated based on the approximated policy values. A training error is calculated as the difference between the training target and the policy value for the corresponding state-action pair in the sample data set. At least some of the parameters of the neural network are updated to minimize the training error.",G06N 3/08,"HUAWEI TECHNOLOGIES CO., LTD.","YAO, Hengshuai","15/873,609 17.01.2018 US; 16/248,543 15.01.2019 US",
WO2020056279,PCT/US2019/051040,13.09.2019,WO/2020/056279,19.03.2020,WO,MANIPULATING FRACTURABLE AND DEFORMABLE MATERIALS USING ARTICULATED MANIPULATORS,"In an embodiment, a method and system use various sensors to determine a shape of a collection of materials (e.g., foodstuffs). A controller can determine a trajectory which achieves the desired end-state, possibly chosen from a set of feasible, collision-free trajectories to execute, and a robot executes that trajectory. The robot, executing that trajectory, scoops, grabs, or otherwise acquires the desired amount of material from the collection of materials at a desired location. The robot then deposits the collected material in the desired receptacle at a specific location and orientation.",B25J 9/16; B25J 19/00,"THE CHARLES STARK DRAPER LABORATORY, INC.","JOHNSON, David, M.S.; WAGNER, Syler; LINES, Steven","62/730,933 13.09.2018 US; 62/730,703 13.09.2018 US; 62/730,947 13.09.2018 US; 62/730,934 13.09.2018 US; 62/730,918 13.09.2018 US; 62/731,398 14.09.2018 US",
WO2019183859,PCT/CN2018/080959,28.03.2018,WO/2019/183859,03.10.2019,WO,METHOD AND DEVICE FOR ROBOT CONTROL,"Embodiments of the present disclosure provide a method and a device for robot control, a computer readable medium, and a computer program product. The method comprises determining correspondence between a plurality of robots and a plurality of objects to be operated by the plurality of robots comprising for each of the plurality of objects, selecting at least one of the plurality of robots to perform an operation on the object; determining a start time for the at least one robot to perform the operation on the object; and determining a time length for the at least one robot to perform the operation on the object. The correspondence is determined such that a sum of the time lengths for the plurality of objects meets a predetermined condition. With the method and device in accordance with the embodiments of the present disclosure, the operation strategy for a plurality of robots and a plurality of objects is optimized and the global production efficiency is improved.",B25J 9/16,"ABB SCHWEIZ AG; SHAO, Wenyao; CHENG, Shaojie; TAN, Jiajing","SHAO, Wenyao; CHENG, Shaojie; TAN, Jiajing",,
EP13947358,01972718,09.10.2001,1327503,16.07.2003,EP,ROBOT CONTROL SYSTEM AND ROBOT CONTROL METHOD,"To control articulated robots by dynamically modifying a combination of a hardware-dependent middleware layer and a hardware-independent application layer. An interface and a database for semantically performing operation are prepared between a middleware layer which depends upon the hardware configuration of a robot and an application layer which does not depend upon the hardware configuration, thereby making it possible to always guarantee normal operation even if a combination of the middleware and the application which is to be introduced onto the robot is modified. The application can acquire appropriate input data via the middleware, and can issue an appropriate command. <IMAGE>",B25J 5/00; B25J 9/16; B25J 13/08; G06N 3/00,SONY CORP,SAKAMOTO TAKAYUKI; INOUE MAKOTO; HOSONUMA NAOYASU; TAKAGI TSUYOSHI; FUJITA MASAHIRO,0108846 09.10.2001 JP; 2000310033 11.10.2000 JP,
WO2018184193,PCT/CN2017/079680,07.04.2017,WO/2018/184193,11.10.2018,WO,ADVANCED ARTIFICIAL INTELLIGENCE AGENT FOR MODELING PHYSICAL INTERACTIONS,"Described herein are advanced artificial intelligence agents for modeling physical interactions. An apparatus to provide an active artificial intelligence (AI) agent includes at least one database to store physical interaction data and compute cluster coupled to the at least one database. The compute cluster automatically obtains physical interaction data from a data collection module without manual interaction, stores the physical interaction data in the at least one database, and automatically trains diverse sets of machine learning program units to simulate physical interactions with each individual program unit having a different model based on the applied physical interaction data.",G06F 17/30,"INTEL CORPORATION; YAO, Anbang; CAI, Dongqi; WANG, Libin; XU, Lin; HU, Ping; WANG, Shandong; CHENG, Wenhua; GUO, Yiwen; YANG, Liu; HOU, Yuqing; SU, Zhou","YAO, Anbang; CAI, Dongqi; WANG, Libin; XU, Lin; HU, Ping; WANG, Shandong; CHENG, Wenhua; GUO, Yiwen; YANG, Liu; HOU, Yuqing; SU, Zhou",,EP-2017904807; CN-201780088086.X
WO2019191306,PCT/US2019/024400,27.03.2019,WO/2019/191306,03.10.2019,WO,"TRAINING, TESTING, AND VERIFYING AUTONOMOUS MACHINES USING SIMULATED ENVIRONMENTS","In various examples, physical sensor data may be generated by a vehicle in a real-world environment. The physical sensor data may be used to train deep neural networks (DNNs). The DNNs may then be tested in a simulated environment - in some examples using hardware configured for installation in a vehicle to execute an autonomous driving software stack - to control a virtual vehicle in the simulated environment or to otherwise test, verify, or validate the outputs of the DNNs. Prior to use by the DNNs, virtual sensor data generated by virtual sensors within the simulated environment may be encoded to a format consistent with the format of the physical sensor data generated by the vehicle.",G06N 3/02; B62D 15/02; G05D 1/00; G06K 9/00; G06N 3/063; G06N 3/04,NVIDIA CORPORATION,"FARABET, Clement; ZEDLEWSKI, John; TAYLOR, Zachary; HEINRICH, Greg; DELAUNEY, Claire; DALY, Mark; CAMPBELL, Matthew; BEESON, Curtis; HICOK, Gary; COX, Michael; LEBAREDIAN, Rev; TAMASI, Tony; AULD, David","62/648,399 27.03.2018 US; 16/366,875 27.03.2019 US",
WO2019133194,PCT/US2018/063669,03.12.2018,WO/2019/133194,04.07.2019,WO,SELF-LEARNING IN DISTRIBUTED ARCHITECTURE FOR ENHANCING ARTIFICIAL NEURAL NETWORK,"A vehicle having the first ANN model initially installed therein to generate outputs from inputs generated by one or more sensors of the vehicle. The vehicle selects an input based on an output generated from the input using the first ANN model. The vehicle has a module to incrementally train the first ANN model through unsupervised machine learning from sensor data that includes the input selected by the vehicle. Optionally, the sensor data used for the unsupervised learning may further include inputs selected by other vehicles in a population. Sensor inputs selected by vehicles are transmitted to a centralized computer server, which trains the first ANN model through supervised machine learning from sensor received inputs from the vehicles in the population and generates a second ANN model as replacement of the first ANN model previously incrementally improved via unsupervised machine learning in the population.",G06N 3/04; G06N 3/08,"MICRON TECHNOLOGY, INC.","MONDELLO, Antonino; TROIA, Alberto","15/858,505 29.12.2017 US",
WO2018055378,PCT/GB2017/052818,21.09.2017,WO/2018/055378,29.03.2018,WO,AUTONOMOUS ROUTE DETERMINATION,"A method (1300) of generating a training dataset for use in autonomous route determination, the method comprising obtaining (1302) data from a data collection vehicle (10) driven through an environment. The data comprises vehicle odometry data detailing a path taken by the vehicle(10) through the environment,obstacle sensing data detailing obstacles detected in the environment; and images (106) of the environment. The method (1300) further comprises using (1304) the obstacle sensing data to label one or more portions of at least some of the images (108) as obstacles and using (1306) the vehicle odometry data to label one or more portions of at least some of the images (108) as the path taken by the vehicle (10) through the environment.",G06K 9/00,OXFORD UNIVERSITY INNOVATION LIMITED,"BARNES, Daniel; MADDERN, William; POSNER, Ingmar",1616097.0 21.09.2016 GB; 1703527.0 06.03.2017 GB,EP-2017777333
WO2019162204,PCT/EP2019/053803,15.02.2019,WO/2019/162204,29.08.2019,WO,DEEP LEARNING FOR SEMANTIC SEGMENTATION OF PATTERN,"Described herein is a method for training a deep learning model of a patterning process. The method includes obtaining (i) training data comprising an input image of at least a part of a substrate having a plurality of features and a truth image, (ii) a set of classes, each class corresponding to a feature of the plurality of features of the substrate within the input image, and (iii) a deep learning model configured to receive the training data and the set of classes, generating a predicted image, by modeling and/or simulation of the deep learning model using the input image, assigning a class of the set of classes to a feature within the predicted image based on matching of the feature with a corresponding feature within the truth image, and generating, by modeling and/or simulation, a trained deep learning model by iteratively assigning weights using a loss function.",G06N 3/08; G06N 3/04; G06K 9/66; G03F 7/20,ASML NETHERLANDS B.V.,"KOOPMAN, Adrianus, Cornelis, Matheus; MIDDLEBROOKS, Scott, Anderson; KIERS, Antoine, Gaston, Marie; MASLOW, Mark, John","62/634,540 23.02.2018 US",
WO2017173141,PCT/US2017/025137,30.03.2017,WO/2017/173141,05.10.2017,WO,PERSISTENT COMPANION DEVICE CONFIGURATION AND DEPLOYMENT PLATFORM,"A development platform for developing a skill for a persistent companion device (PCD) includes an asset development library having an application programming interface (API) configured to enable a developer to at least one of find, create, edit and access one or more content assets utilizable for creating a skill, an expression tool suite having one or more APIs via which are received one or more expressions associated with the skill as specified by the developer wherein the skill is executable by the PCD in response to at least one defined input, a behavior editor for specifying one or more behavioral sequences of the PCD for the skill and a skill deployment facility having an API for deploying the skill to an execution engine of the PCD.",B25J 9/00; B25J 9/16; G06F 3/01; G06F 3/16; G06K 9/00; G06T 7/20; G10L 15/22,"JIBO, INC.","BREAZEAL, Cynthia; MICHAUD, Avida; LABERGE, Francois; ROSS, Jonathan, Louis; SAUND, Carolyn, Marothy; FARIDI, Fardad","62/316,247 31.03.2016 US",JP-2019502527; CA-3019535; KR-1020187031496
WO2020018679,PCT/US2019/042225,17.07.2019,WO/2020/018679,23.01.2020,WO,REGRESSION-BASED LINE DETECTION FOR AUTONOMOUS DRIVING MACHINES,"In various examples, systems and methods are disclosed that preserve rich spatial information from an input resolution of a machine learning model to regress on lines in an input image. The machine learning model may be trained to predict, in deployment, distances for each pixel of the input image at an input resolution to a line pixel determined to correspond to a line in the input image. The machine learning model may further be trained to predict angles and label classes of the line. An embedding algorithm may be used to train the machine learning model to predict clusters of line pixels that each correspond to a respective line in the input image. In deployment, the predictions of the machine learning model may be used as an aid for understanding the surrounding environment – e.g., for updating a world model – in a variety of autonomous machine applications.",G06K 9/00; G06K 9/46; G06K 9/62,NVIDIA CORPORATION,"PARK, Minwoo; LIN, Xiaolin; SEO, Hae-Jong; NISTER, David; CVIJETIC, Neda","62/699,669 17.07.2018 US; 16/514,230 17.07.2019 US",
WO2020056295,PCT/US2019/051061,13.09.2019,WO/2020/056295,19.03.2020,WO,CONTROLLING ROBOT TORQUE AND VELOCITY BASED ON CONTEXT,"In an embodiment, a method includes identifying a force and torque for a robot to accomplish a task and identifying context of a portion of a movement plan indicating motion of the robot to perform the task. Based on the identified force, torque, and context, a context specific torque is determined for at least one aspect of the robot while the robot executes the portion of the movement plan. In turn, a control signal is generated for the at least one aspect of the robot to operate in accordance with the determined context specific torque.",B25J 9/16; A47J 44/00,"THE CHARLES STARK DRAPER LABORATORY, INC.","JOHNSON, David, M.S.; WAGNER, Syler; LINES, Steven","62/731,398 14.09.2018 US; 62/730,918 13.09.2018 US; 62/730,933 13.09.2018 US; 62/730,947 13.09.2018 US; 62/730,934 13.09.2018 US; 62/730,703 13.09.2018 US",
WO2020077163,PCT/US2019/055747,10.10.2019,WO/2020/077163,16.04.2020,WO,GENERATION OF SIMULATED PATIENT DATA FOR TRAINING PREDICTED MEDICAL OUTCOME ANALYSIS ENGINE,"A system receives feature parameters, each identifying possible values for one of a set of features. The system, receives outcomes corresponding to the feature parameters. The system generates a simulated patient population dataset with multiple simulated patient datasets, each simulated patient dataset associated with the outcomes and including feature values falling within the possible values identified by the feature parameters. The system may train a machine learning engine based on the simulated patient population dataset and optionally additional simulated patient population datasets. The machine learning engine generates predicted outcomes based on the training in response to queries identifying feature values.",G09B 23/28; G06F 19/00; G06G 7/48; G06G 7/60,"KILJANEK, Lukasz, R.","KILJANEK, Lukasz, R.","62/743,789 10.10.2018 US",
WO2019224823,PCT/IL2019/050582,22.05.2019,WO/2019/224823,28.11.2019,WO,METHOD AND SYSTEM FOR IMAGING AND IMAGE PROCESSING,"A method of designing an element for the manipulation of waves, comprises: accessing a computer readable medium storing a machine learning procedure, having a plurality of learnable weight parameters. A first plurality of the weight parameters corresponds to the element, and a second plurality of the weight parameters correspond to an image processing. The method comprises accessing a computer readable medium storing training imaging data, and training the machine learning procedure on the training imaging data, so as to obtain values for at least the first plurality of the weight parameters.",G06N 3/02; G06K 9/46; G06T 5/00,RAMOT AT TEL-AVIV UNIVERSITY LTD.,"ELMALEM, Shay; GIRYES, Raja; HAIM, Harel; BRONSTEIN, Alexander; MAROM, Emanuel","62/674,724 22.05.2018 US",
EP76932563,12182383,30.08.2012,2573639,27.03.2013,EP,Mobile robot and controlling method of the same,"In a mobile robot and a controlling method of the same, the mobile robot is able to recognize a precise position thereof by detecting a plurality of images through an image detection unit, extracting one or more feature points from the plurality of images, and comparing and matching information related to the feature points. The mobile robot is also able to easily detect a position of a charging station based on image information, and quickly move to the charging station upon the lack of residual battery capacity. The mobile robot is also able to detect a position of the charging station based on the image information and receive a guideline signal within a signal reception range, so as to easily dock with the charging station.",G05D 1/02,LG ELECTRONICS INC,LEE SEONGSOO; BAEK SEUNGMIN,20110094803 20.09.2011 KR,
WO2019213443,PCT/US2019/030471,02.05.2019,WO/2019/213443,07.11.2019,WO,AUDIO ANALYTICS FOR NATURAL LANGUAGE PROCESSING,"A device includes a memory configured to store category labels associated with categories of a natural language processing library. A processor is configured to analyze input audio data to generate a text string and to perform natural language processing on at least the text string to generate an output text string including an action associated with a first device, a speaker, a location, or a combination thereof. The processor is configured to compare the input audio data to audio data of the categories to determine whether the input audio data matches any of the categories and, in response to determining that the input audio data does not match any of the categories: create a new category label, associate the new category label with at least a portion of the output text string, update the categories with the new category label, and generate a notification indicating the new category label.",G10L 17/04; G06F 17/27; G10L 15/22,QUALCOMM INCORPORATED,"VISSER, Erik; SAKI, Fatemeh; GUO, Yinyi; MOON, Sunkuk; KIM, Lae-Hoon; CHOUDHARY, Ravi","15/972,011 04.05.2018 US",
WO2012009817,PCT/CA2011/050449,22.07.2011,WO/2012/009817,26.01.2012,WO,"A NON-PROGRAMMER METHOD FOR CREATING SIMULATION-ENABLED 3D ROBOTIC MODELS FOR IMMEDIATE ROBOTIC SIMULATION, WITHOUT PROGRAMMING INTERVENTION","A system to design a virtual 3D model of the working robot so it can be tested in a virtual world is described. The system and the method for using same can be used to test, refine, redesign and improve multiple virtual prototypes of a robot. Once virtually tested, the optimized design specifications are printed out and used to build the optimized robot design.",G06F 17/50; G06T 19/00,"COGMATION ROBOTICS INC.; PETERSON, Jack Elmin; YANKE , Shane Nathaniel Richard; ALLEN, Jeffrey Craig","PETERSON, Jack Elmin; YANKE , Shane Nathaniel Richard; ALLEN, Jeffrey Craig","61/366,802 22.07.2010 US",CA-2838761; US-13811290; EP-2011809131
WO2020023740,PCT/US2019/043428,25.07.2019,WO/2020/023740,30.01.2020,WO,"METHODS, SYSTEMS, AND COMPUTER READABLE MEDIA FOR GENERATING AND PROVIDING ARTIFICIAL INTELLIGENCE ASSISTED SURGICAL GUIDANCE","A method for generating and providing artificial intelligence assisted surgical guidance includes analyzing video images from surgical procedure and training a neural network to identify at least one of anatomical objects, surgical objects, and tissue manipulation in video images. The method includes receiving, by the neural network, a live feed of video images from the surgery. The method further includes classifying, by the neural network, at least one of anatomical objects, surgical objects, and tissue manipulation in the live feed of video images. The method further includes outputting, in real time, surgical guidance based on algorithms created using the classified at least one of anatomical objects, surgical objects, and tissue manipulations in the live feed of video images.",A61B 1/00; A61B 1/313; A61B 1/317; G06K 9/00,THE TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA,"BUCH, Vivek Paresh; MADSEN, Peter John; SHI, Jianbo","62/703,400 25.07.2018 US",
WO2016098023,PCT/IB2015/059690,16.12.2015,WO/2016/098023,23.06.2016,WO,"MULTI-SENSOR, AUTONOMOUS ROBOTIC VEHICLE WITH LAWN CARE FUNCTION","A robotic vehicle may include one or more functional components configured to execute a lawn care function, a sensor network comprising one or more sensors configured to detect conditions proximate to the robotic vehicle, an object detection module configured to 5 detect objects proximate to the robotic vehicle using contact-less detection, a positioning module configured to determine robotic vehicle position, and a mapping module configured to generate map data regarding a parcel on which the robotic vehicle operates.",G05D 1/02,HUSQVARNA AB,"GRUFMAN, Stefan; MANNEFRED, Björn; JÄGENSTEDT, Patrik; ÖHRLUND, Magnus; DEIMERT, Johan","62/093,112 17.12.2014 US",EP-2015825957; US-15535500
EP21189670,09177019,25.11.2009,2336948,22.06.2011,EP,A method for multi modal object recognition based on self-referential classification strategies,The present invention relates to a technique for controlling a camera system towards interesting points learned from the correlation of visual and auditory properties of an environment. The presented system learns to autonomously build a representation of objects and a structure in its environment using a camera and a microphone.,G06K 9/62,HONDA RES INST EUROPE GMBH,GRAHL MIRANDA; JOUBLIN FRANK; KUMMERT FRANZ,EP20090177019  ; 09177019 25.11.2009 EP,
WO2018209551,PCT/CN2017/084496,16.05.2017,WO/2018/209551,22.11.2018,WO,SYSTEMS AND METHODS FOR DETERMINING AN ESTIMATED TIME OF ARRIVAL,The present disclosure relates to systems and methods for determining an estimated time of arrival. The systems may perform the methods to operate logical circuits to obtain a departure location associated with a terminal device and information relating to the departure location. The information may include one or more service providers. The system may operate the logical circuits to obtain a trained machine learning model. The system may operate the logical circuits to determine an estimated time of arrival for one of the one or more service providers to arrive at the departure location based on the information and the machine learning model.,G06F 19/00,"BEIJING DIDI INFINITY TECHNOLOGY AND DEVELOPMENT CO., LTD.","ZHONG, Xiaowei; WANG, Ziteng; MENG, Fanlin; WANG, Zheng",,CN-201780036609.6
WO2019216975,PCT/US2019/020044,28.02.2019,WO/2019/216975,14.11.2019,WO,"METHODS AND SYSTEMS FOR DATA COLLECTION, LEARNING, AND STREAMING OF MACHINE SIGNALS FOR ANALYTICS AND MAINTENANCE USING THE INDUSTRIAL INTERNET OF THINGS","An industrial machine predictive maintenance system may include an industrial machine data analysis facility that generates streams of industrial machine health monitoring data by applying machine learning to data representative of conditions of portions of industrial machines received via a data collection network. The system may include an industrial machine predictive maintenance facility that produces industrial machine service recommendations responsive to the health monitoring data by applying machine fault detection and classification algorithms thereto. A computerized maintenance management system (CMMS) that produces orders and/or requests for service and parts responsive to the industrial machine service recommendations can be included. The system may include a service and delivery coordination facility that processes information regarding services performed on industrial machines responsive to the orders and/or requests for service and parts, thereby validating the services performed while producing a ledger of service activity and results for individual industrial machines.",G05B 23/02; H04L 5/00; H04B 17/309; H04L 29/08; H04B 17/318; G05B 13/02; G05B 19/418,"STRONG FORCE IOT PORTFOLIO 2016, LLC","CELLA, Charles Howard; DUFFY, JR., Gerald William; MCGUCKIN, Jeffrey P.; DESAI, Mehul","15/973,406 07.05.2018 US; 62/713,897 02.08.2018 US; 62/714,078 02.08.2018 US; 16/143,286 26.09.2018 US; 62/757,166 08.11.2018 US; 62/799,732 31.01.2019 US",
WO2016172188,PCT/US2016/028406,20.04.2016,WO/2016/172188,27.10.2016,WO,MACHINE VISION WITH DIMENSIONAL DATA REDUCTION,"A method is described that includes receiving raw image data corresponding to a series of raw images, and processing the raw image data with an encoder of a processing device to generate encoded data. The encoder is characterized by an input/output transformation that substantially mimics the input/output transformation of at least one retinal cell of a vertebrate retina. The method also includes processing the encoded data to generate dimension reduced encoded data by applying a dimension reduction algorithm to the encoded data. The dimension reduction algorithm is configured to compress an amount of information contained in the encoded data. An apparatus and system usable with such a method is also described.",A61F 9/08; A61N 5/06; G06K 9/46; G06N 3/04; G06T 7/00; H04N 19/60; H04N 19/85,CORNELL UNIVERSITY,"NIRENBERG, Sheila","62/150,068 20.04.2015 US",KR-1020177033316; EP-2016783749; JP-2017554580; US-15567407; IL-255128
WO2014093838,PCT/US2013/075045,13.12.2013,WO/2014/093838,19.06.2014,WO,AUTOMATED ROBOTIC MICROSCOPY SYSTEMS,"The present disclosure provides automated robotic microscopy systems that facilitate high throughput and high content analysis of biological samples, such as living cells and/or tissues. In certain aspects, the systems are configured to reduce user intervention relative to existing technologies, and allow for precise return to and re-imaging of the same field (e.g., the same cell) that has been previously imaged. This capability enables experiments and testing of hypotheses that deal with causality over time with greater precision and throughput than conventional microscopy methods.",G06F 19/18; C12M 1/34,THE J. DAVID GLADSTONE INSTITUTES,"FINKBEINER, Steven M.; ANDO, Dale Michael; DAUB, Aaron C.","61/737,683 14.12.2012 US",CA-2893590; JP-2015547991; EP-2013862299
WO1997033212,PCT/EP1997/001027,01.03.1997,WO/1997/033212,12.09.1997,WO,AUTONOMOUS MOBILE ROBOT SYSTEM FOR SENSOR-BASED AND MAP-BASED NAVIGATION IN PIPE NETWORKS,"The autonomous mobile robot system is provided with a sensor-based and map-based navigation system for navigating in a pipe network. The navigation is based on the classification of pre-existing natural landmarks. The navigation system can compensate for inaccurate robot system's motion control, sensor information, and landmark classification.",E03F 7/12; G05D 1/02,"GMD - FORSCHUNGSZENTRUM INFORMATIONSTECHNIK GMBH; KIRCHNER, Frank; HERTZBERG, Joachim","KIRCHNER, Frank; HERTZBERG, Joachim",96103453.5 06.03.1996 EP,US-09077610; EP-1997906146
EP201048781,17152257,19.01.2017,3196788,26.07.2017,EP,COMPUTER SYSTEM FOR DETERMINING A STATE OF MIND AND PROVIDING A SENSORY-TYPE ANTIDOTE TO A SUBJECT,"Computer implemented method and system for achieving a preferred state of mind of a user are disclosed. In a first aspect, the method comprises detecting a biological marker (biomarker) of a user utilizing one or more sensors; and inferring a state of mind of the user based upon data received from the one or more sensors that are provided to computational hardware. Finally the method includes providing an antidote to the user if the inferred state of mind is different than the preferred state of mind utilizing an actuator. In a second aspect, the system comprises one or more sensors for detecting a biological marker (biomarker) of the user and computational hardware for inferring a state of mind of the user based upon data received from the one or more sensors. Finally the system includes an actuator for providing an antidote to the user if the inferred state of mind is different than a preferred state of mind.",G06F 19/00; A61M 21/00; A61M 21/02; G06F 17/30,SHERPA TRUNGRAM GYALTRUL R; CHEN DAVID H C,SHERPA TRUNGRAM GYALTRUL R; CHEN DAVID H C,201615003732 21.01.2016 US,
WO2019002465,PCT/EP2018/067414,28.06.2018,WO/2019/002465,03.01.2019,WO,TRAINING ACTION SELECTION NEURAL NETWORKS USING APPRENTICESHIP,"An off-policy reinforcement learning actor-critic neural network system configured to select actions from a continuous action space to be performed by an agent interacting with an environment to perform a task. An observation defines environment state data and reward data. The system has an actor neural network which learns a policy function mapping the state data to action data. A critic neural network learns an action-value (Q) function. A replay buffer stores tuples of the state data, the action data, the reward data and new state data. The replay buffer also includes demonstration transition data comprising a set of the tuples from a demonstration of the task within the environment. The neural network system is configured to train the actor neural network and the critic neural network off-policy using stored tuples from the replay buffer comprising tuples both from operation of the system and from the demonstration transition data.",G06N 3/04; G06N 3/08; G06N 3/00,DEEPMIND TECHNOLOGIES LIMITED,"PIETQUIN, Olivier; RIEDMILLER, Martin; FUMIN, Wang; PIOT, Bilal; VECERIK, Matej; HESTER, Todd Andrew; ROTHORL, Thomas; LAMPE, Thomas; HEESS, Nicolas Manfred Otto; SCHOLZ, Jonathan Karl","62/526,290 28.06.2017 US",CN-201880028844.3; EP-2018735278
WO2018057530,PCT/US2017/052319,19.09.2017,WO/2018/057530,29.03.2018,WO,MACHINE LEARNING MODELS FOR IDENTIFYING OBJECTS DEPICTED IN IMAGE OR VIDEO DATA,"Systems and methods are described for identifying sports-related objects in media content, such as image or video data, using machine learning models. Features of the media content may be provided as input to classification models trained to detect depiction of various sports-related objects and scenes in order to generate various metrics associated with an underlying sporting event depicted in the media content.",G06K 9/00; G06K 9/62,"GUMGUM, INC.","KATZ, Jeffrey, Benjamin; CARTER, Cambron, Neil; KIM, Brian, Jongmin","62/397,739 21.09.2016 US; 62/421,886 14.11.2016 US; 62/505,758 12.05.2017 US",CA-3037201; EP-2017778402
WO2016100814,PCT/US2015/066664,18.12.2015,WO/2016/100814,23.06.2016,WO,MULTI-MODAL SENSOR DATA FUSION FOR PERCEPTION SYSTEMS,A method includes fusing multi-modal sensor data from a plurality of sensors having different modalities. At least one region of interest is detected in the multi-modal sensor data. One or more patches of interest are detected in the multi-modal sensor data based on detecting the at least one region of interest. A model that uses a deep convolutional neural network is applied to the one or more patches of interest. Post-processing of a result of applying the model is performed to produce a post-processing result for the one or more patches of interest. A perception indication of the post-processing result is output.,G06K 9/00; G06N 3/04,UNITED TECHNOLOGIES CORPORATION,"GIERING, Michael J.; REDDY, Kishore K.; VENUGOPALAN, Vivek","62/094,681 19.12.2014 US",EP-2015826236; US-15536713
WO2019203851,PCT/US2018/028658,20.04.2018,WO/2019/203851,24.10.2019,WO,THREE-DIMENSIONAL SHAPE CLASSIFICATION AND RETRIEVAL USING CONVOLUTIONAL NEURAL NETWORKS AND MAJORITY VOTE,"A deep learning method employs a neural network having three sub-nets to classify and retrieve the most similar 3D model of an object, given a rough 3D model or scanned images. The most similar 3D model is present in a database and can be retrieved to use directly or as a reference to redesign the 3D model. The three sub-nets of the neural network include one dealing with object images and the other two dealing with voxel representations. Majority vote is used instead of view pooling to classify the object. A feature map and a list of top N most similar well-designed 3D models are also provided.",G06T 19/20; G06N 3/02; G06F 17/40,"HEWLETT-PACKARD DEVELOPMENT COMPANY, L.P.","SHAO, Ruiting; LEI, Yang; FAN, Jian; LIU, Jerry",,
WO2019084189,PCT/US2018/057382,24.10.2018,WO/2019/084189,02.05.2019,WO,GRADIENT NORMALIZATION SYSTEMS AND METHODS FOR ADAPTIVE LOSS BALANCING IN DEEP MULTITASK NETWORKS,"Systems and methods for training a multitask network is disclosed. In one aspect, training the multitask network includes determining a gradient norm of a single-task loss adjusted by a task weight for each task, with respect to network weights of the multitask network, and a relative training rate for the task based on the single-task loss for the task. Subsequently, a gradient loss function, comprising a difference between (1) the determined gradient norm for each task and (2) a corresponding target gradient norm, can be determined. An updated task weight for the task can be determined and used in the next iteration of training the multitask network, using a gradient of the gradient loss function with respect to the task weight for the task.",G06F 15/18,"MAGIC LEAP, INC.","CHEN, Zhao; BADRINARAYANAN, Vijay; RABINOVICH, Andrew","62/577,705 26.10.2017 US; 62/599,693 16.12.2017 US; 62/628,266 08.02.2018 US; 62/695,356 09.07.2018 US",
WO2019057987,PCT/EP2018/075953,25.09.2018,WO/2019/057987,28.03.2019,WO,MACHINE VISION SYSTEM,"A machine vision system comprising receiving means configured to receive image data indicative of an object to be classified where there is provided processing means with an initial neural network, the processing means configured to determine a differential equation describing the initial neural network algorithm based on the neural network parameters, and to determine a solution to the differential equation in the form of a series expansion; and to convert the series expansion to a finite series expansion by limiting the number of terms in the series expansion to a finite number; and to determine the output classification in dependence on the finite series expansion.",G06K 9/46; G06K 9/62; G06N 3/04; G06N 3/08; G06K 9/00,"NISSAN MOTOR CO., LTD.","BATCHELOR, Andrew; JONES, Garry; SATO, Yoshinori",1715456.8 25.09.2017 GB,
WO2019164938,PCT/US2019/018760,20.02.2019,WO/2019/164938,29.08.2019,WO,AUTONOMOUS MARKING SYSTEM,"Described in detail herein is an automated marking system. The autonomous robot device can locate and identify one or more cases stored in at least one of a plurality of bins in the first location of the facility, wherein each case containing a set of like physical objects. The autonomous robot device can transmit identifying information of the at least one of the one or more cases to the computing system. The computing system can determine a priority for a quantity of the first set of like physical objects to be moved from the at least one of the one or more cases to the second location of the facility. The computing system can instruct the at least one autonomous robot device to mark the at least one of the one or more cases with an identifying mark denoting the determined priority.",B65G 1/137; G05D 1/00; G05D 1/02; G05D 1/04; G05D 1/06; G06Q 10/00; G06Q 10/08,"WALMART APOLLO, LLC","HIGH, Donald; MCHALE, Brian, Gerard; ALEXANDER, Matthew, David; VELTEN, Jeremy; PROPES, William, Mark; CANTRELL, Robert","62/632,548 20.02.2018 US; 62/802,543 07.02.2019 US",
EP242528138,18207129,20.11.2018,3486041,22.05.2019,EP,"GRIPPING SYSTEM, LEARNING DEVICE, AND GRIPPING METHOD","A gripping system (1) according to an aspect of the present disclosure includes: a hand (3) that grips a workpiece (W), a robot (2) that supports the hand (3) and changes at least one of a position of the hand (3) and a posture of the hand (3), an image sensor (4) that acquires image information from a viewpoint interlocked with at least one of the position and the posture of the hand (3), a construction module (700) that constructs a model corresponding to at least a part of a process of specifying an operation command of the robot (2) based on the image information acquired by the image sensor (4) and hand position information representing at least one of the position of the hand (3) and the posture of the hand (3), by machine learning based on collection data, an operation module (600) that executes the operation command of the robot (2) based on the image information, the hand position information, and the model, and a robot control module (5) that operates the robot (2) based on the operation command of the robot (2) operated by the operation module (600).",B25J 9/16; G05B 13/02,YASKAWA ELECTRIC CORP; AI CUBE INC,ISHIKAWA SHOTA; SOKABE KOJI; NAKAMURA KEISUKE; ADACHI MASARU; SASAKI YUICHI; PASQUALI ANTOINE; WILMOTTE THOMAS,2017223053 20.11.2017 JP,
WO2019224162,PCT/EP2019/063003,20.05.2019,WO/2019/224162,28.11.2019,WO,METHOD AND SYSTEM FOR ANALYZING ROBOT SURROUNDINGS,"Disclosed are a system and methods for operating a mobile robot. One method comprises travelling in an outdoor setting, capturing data related to the outdoor setting, processing captured data and identifying occlusion present in the preprocessed data. The system comprises a mobile robot configured to travel in outdoor settings and comprising at least one first sensor and at least one processing component. The processing component is configured to process data captured by the first sensor and identify occlusion present in the preprocessed data.",G06K 9/00,STARSHIP TECHNOLOGIES OÜ,"KORJUS, Kristjan; KHARAGORGIIEV, Sergii; HEINLA, Ahti; PÄRNAMAA, Tanel",18215499.7 21.12.2018 EP; 18173530.9 22.05.2018 EP,
WO2018176035,PCT/US2018/024354,26.03.2018,WO/2018/176035,27.09.2018,WO,METHOD AND SYSTEM OF BUILDING HOSPITAL-SCALE CHEST X-RAY DATABASE FOR ENTITY EXTRACTION AND WEAKLY-SUPERVISED CLASSIFICATION AND LOCALIZATION OF COMMON THORAX DISEASES,"A new chest X-ray database, referred to as ""ChestX-ray8"", is disclosed herein, which comprises over 100,000 frontal view X-ray images of over 32,000 unique patients with the text-mined eight disease image labels (where each image can have multi-labels), from the associated radiological reports using natural language processing. We demonstrate that these commonly occurring thoracic diseases can be detected and spatially-located via a unified weakly supervised multi-label image classification and disease localization framework, which is validated using our disclosed dataset.",G06F 19/00; G06T 7/00; G06N 3/08; G06K 9/46; A61B 5/05,"THE UNITED OF AMERICA, AS REPRESENTED BY THE SECRETARY, DEPARTMENT OF HEALTH AND HUMAN SERVICES","WANG, Xiaosong; PENG, Yifan; LU, Le; LU, Zhiyong; SUMMERS, Ronald M.","62/476,029 24.03.2017 US",
WO2018213205,PCT/US2018/032607,14.05.2018,WO/2018/213205,22.11.2018,WO,"SYSTEMS AND METHODS FOR RAPIDLY BUILDING, MANAGING, AND SHARING MACHINE LEARNING MODELS","In some aspects, systems and methods for rapidly building, managing, and sharing machine learning models are provided. Managing the lifecycle of machine learning models can include: receiving a set of unannotated data; requesting annotations of samples of the unannotated data to produce an annotated set of data; building a machine learning model based on the annotated set of data; deploying the machine learning model to a client system, wherein production annotations are generated; collecting the generated production annotations and generating a new machine learning model incorporating the production annotations; and selecting one of the machine learning model built based on the annotated set of data or the new machine learning model.",G06F 9/44; G06F 17/00; G06F 17/24,"DIGITAL REASONING SYSTEMS, INC.","HUGHES, Cory; ESTES, Timothy; LIU, John; CARL, Brandon; KAMATH, Uday","62/505,936 14.05.2017 US",EP-2018803094; AU-2018269941; CA-3063738; SG-11201910380S
WO2018210404,PCT/EP2017/061650,16.05.2017,WO/2018/210404,22.11.2018,WO,METHOD AND CONTROL SYSTEM FOR CONTROLLING MOVEMENT SEQUENCES OF A ROBOT,"Method for controlling movement sequences (58) of a robot (12), the method comprising predicting values of at least one parameter related to the execution of alternative movement sequences (58) by the robot (12), where each movement sequence (58) comprises at least one movement segment (60) associated with a handling location (40); selecting a movement sequence (58) based on the predicted values of the at least one parameter; and executing the selected movement sequence (58) by the robot (12). A control system (50) for controlling movement sequences (58) of a robot (12) is also provided.",B25J 9/16; B25J 9/00,ABB SCHWEIZ AG,"LAGER, Anders; HOLMBERG, Johnny; WAHLSTRÖM, Magnus",,CN-201780090442.1; EP-2017724790
WO2003045640,PCT/SE2002/002196,28.11.2002,WO/2003/045640,05.06.2003,WO,AN INDUSTRIAL ROBOT SYSTEM AND A METHOD FOR PROGRAMMING THEREOF,"A method for programming an industrial robot, including pro-gramming a task comprising a set of successive waypoints through which the robot should pass during performance of the task. The method includes receiving information about way-points specified during programming of a current task, predicting the next waypoint of the current task based on the received in-formation about the waypoints of the current task and a set of previously stored tasks, and suggesting the next waypoint of the current task according to said prediction.An industrial robot system comprising a manipulator, a control unit for controlling the manipulator, and a unit for manually pro-gramming the robot to perform a task comprising a set of suc-cessive waypoints through which the robot should pass during performance of the task. The robot system comprises memory means for storing a set of previously created tasks, a waypoint receiver, receiving and storing information about waypoints specified during programming of a current task, a predictor, pre-dicting the next waypoint of the current task based on the stored waypoints of the current task and said set of previously stored tasks, and a suggestion unit, suggesting the next waypoint of the current task according to said prediction.",B25J 9/16,"ABB AB; STRAND, Martin; DIXON, Kevin","STRAND, Martin; DIXON, Kevin",0103994-0 29.11.2001 SE,JP-null
WO1993018483,PCT/US1993/001843,02.03.1993,WO/1993/018483,16.09.1993,WO,METHOD AND APPARATUS FOR IMAGE RECOGNITION,"A method for image recognition is provided which involves storing a plurality of two-dimensional hidden Markov models (60) each such model comprising a one-dimensional shape-level hidden Markov model comprising one or more shape-level states, each shape-level state comprising a one-dimensional pixel-level hidden Markov model comprising one or more pixel-level states. An image is scanned to produce one or more sequences of pixels. For a stored two-dimensional hidden Markov model, local Viterbi scores for a plurality of pixel-level hidden Markov models are determined for each sequence of pixels (6). A global Viterbi score of a shape-level hidden Markov model is determined based on a plurality of local Viterbi scores and the sequences of pixels. The scanned image is recognized based on one or more global Viterbi scores.",G06K 9/62; G06K 9/64,AMERICAN TELEPHONE AND TELEGRAPH COMPANY,"LEVIN, Esther; PIERACCINI, Roberto","07/844,810 02.03.1992 US",
WO2017007626,PCT/US2016/039651,27.06.2016,WO/2017/007626,12.01.2017,WO,CONTEXT-BASED PRIORS FOR OBJECT DETECTION IN IMAGES,"Context-based priors are utilized in machine learning networks (e.g., neural networks) for detecting objects in images. The likely locations of objects are estimated based on context labels. A machine learning network identifies a context label of an entire image. Based on the, the network selects a set of likely regions for detecting objects of interest in the image.",G06K 9/32; G06K 9/00; G06K 9/72; G06K 9/46,QUALCOMM INCORPORATED,"DIJKMAN, Daniel Hendricus Franciscus; TOWAL, Regan Blythe; ANNAPUREDDY, Venkata Sreekanta Reddy","62/190,685 09.07.2015 US; 14/882,373 13.10.2015 US",KR-1020187000472; EP-2016736704; JP-2018500365
WO2019075410,PCT/US2018/055723,12.10.2018,WO/2019/075410,18.04.2019,WO,DEEP LEARNING-BASED DIAGNOSIS AND REFERRAL OF OPHTHALMIC DISEASES AND DISORDERS,"Disclosed herein are systems, methods, devices, and media for carrying out medical diagnosis of ophthalmic diseases and conditions. Deep learning algorithms enable the automated analysis of ophthalmic images to generate predictions of comparable accuracy to clinical experts.",G16H 50/20; A61B 5/00,AI TECHNOLOGIES INC.; THE REGENTS OF THE UNIVERSITY OF CALIFORNIA,"ZHANG, Kang; HOU, Rui; ZHENG, Lianghong","62/572,384 13.10.2017 US; 62/668,698 08.05.2018 US; 62/694,939 06.07.2018 US",
WO2009058915,PCT/US2008/081656,29.10.2008,WO/2009/058915,07.05.2009,WO,"COMPUTER ASSISTED DIAGNOSIS (CAD) OF CANCER USING MULTI-FUNCTIONAL, MULTI-MODAL IN-VIVO MAGNETIC RESONANCE SPECTROSCOPY (MRS) AND IMAGING (MRI)","This invention relates to to computer-assisted diagnostics and classification of prostate cancer. Specifically, the invention relates to segmentation of the prostate boundary on MRI images, cancer detection using multimodal multi-protocol MR data; and their integration for a computer-aided diagnosis and classification system for prostate cancer.",G06K 9/62,"THE TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA; FELDMAN, Michael, D.; VISWANATH, Satish; RUTGERS, THE STATE UNIVERSITY OF NEW JERSEY; TIWARI, Pallavi; TOTH, Robert; MADABHUSHI, Anant; ROSEN, Mark; TOMASZEWESKI, John","FELDMAN, Michael, D.; VISWANATH, Satish; TIWARI, Pallavi; TOTH, Robert; MADABHUSHI, Anant; ROSEN, Mark; TOMASZEWESKI, John","60/983,553 29.10.2007 US",US-12740383
EP27770909,09822545,20.10.2009,2355711,17.08.2011,EP,ENVIRONMENT PROPERTY ESTIMATION AND GRAPHICAL DISPLAY,"A surgical robot including an imaging system comprising at least one camera, a processor in communication with the imaging system, a manipulation system in communication with the processor, and a visual display in communication with the processor. The processor is operable to calculate a stiffness estimate for an area of an environment based on an environment model of tool-environment interaction data, create a composite image comprising a stiffness map of the stiffness estimate overlaid on an environment image from the at least one camera, and output the composite image on the visual display.",A61B 34/10; A61B 34/30; A61B 90/00; B25J 9/16; G05B 19/42,UNIV JOHNS HOPKINS,OKAMURA ALLISON MARIKO; YAMAMOTO TOMONORI; VAGVOLGYI BALAZS PETER,10668308 20.10.2008 US; 2009061297 20.10.2009 US,
WO2018083671,PCT/IB2017/056906,04.11.2017,WO/2018/083671,11.05.2018,WO,REINFORCEMENT LEARNING WITH AUXILIARY TASKS,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for training a reinforcement learning system. The method includes: training an action selection policy neural network, and during the training of the action selection neural network, training one or more auxiliary control neural networks and a reward prediction neural network. Each of the auxiliary control neural networks is configured to receive a respective intermediate output generated by the action selection policy neural network and generate a policy output for a corresponding auxiliary control task. The reward prediction neural network is configured to receive one or more intermediate outputs generated by the action selection policy neural network and generate a corresponding predicted reward. Training each of the auxiliary control neural networks and the reward prediction neural network comprises adjusting values of the respective auxiliary control parameters, reward prediction parameters, and the action selection policy network parameters.",G06N 3/04; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"MNIH, Volodymyr; CZARNECKI, Wojciech; JADERBERG, Maxwell Elliot; SCHAUL, Tom; SILVER, David; KAVUKCUOGLU, Koray","62/418,120 04.11.2016 US",EP-2017808163; CN-201780080119.6; JP-2019523801; KR-1020197015648
EP276032574,19157204,14.02.2019,3564861,06.11.2019,EP,VISION-BASED SAMPLE-EFFICIENT REINFORCEMENT LEARNING FRAMEWORK FOR AUTONOMOUS DRIVING,,G06N 3/00; G06N 5/04; G06N 20/00,SONY CORP,CHIANG SU-HUI; LIU MING-CHANG,201815943223 02.04.2018 US,
WO2018022715,PCT/US2017/043886,26.07.2017,WO/2018/022715,01.02.2018,WO,EARLY PREDICTION OF AN INTENTION OF A USER'S ACTIONS,"A computer-implemented method includes recording, with a three-dimensional camera, one or more demonstrations of a user performing one or more reaching tasks. Training data is computed to describe the one or more demonstrations. One or more weights of a neural network are learned based on the training data, where the neural network is configured to estimate a goal location of the one or more reaching tasks. A partial trajectory of a new reaching task is recorded. An estimated goal location is computed, by a computer processor, by applying the neural network to the partial trajectory of the new reaching task.",B25J 9/16; G06N 3/02; G06N 3/08,UNIVERSITY OF CONNECTICUT,"DANI, Ashwin; RAVICHANDAR, Harish","62/366,663 26.07.2016 US",
WO2019159162,PCT/IL2019/050135,05.02.2019,WO/2019/159162,22.08.2019,WO,CLEANING ROBOT WITH ARM AND TOOL RECEPTACLES,"A cleaning robot includes a propulsion mechanism to propel the robot on a floor, a robotic arm with a gripper at its distal end, and a plurality of different cleaning tools, each cleaning tool including a handle that is configured to be grasped by the gripper. At least one of a plurality of receptacles is configured to hold one of the cleaning tools. A controller is configured to autonomously operate the propulsion system to transport the robot to region to be cleaned, operate the robotic arm to bring the gripper to a receptacle that is holding a selected cleaning tool, operate the gripper to grasp a handle of the selected cleaning tool and to manipulate the cleaning tool when cleaning the region, and operate the robotic arm and the gripper to return the selected cleaning tool to its receptacle.",B25J 13/08; B25J 11/00; B25J 9/16,"DUBIN, Uri; KARASIKOV, Nir","DUBIN, Uri; KARASIKOV, Nir","15/894,948 13.02.2018 US",
WO2018154092,PCT/EP2018/054614,26.02.2018,WO/2018/154092,30.08.2018,WO,ITERATIVE MULTISCALE IMAGE GENERATION USING NEURAL NETWORKS,"A method of generating an output image having an output resolution of N pixels x N pixels, each pixel in the output image having a respective color value for each of a plurality of color channels, the method comprising: obtaining a low-resolution version of the output image; and upscaling the low-resolution version of the output image to generate the output image having the output resolution by repeatedly performing the following operations: obtaining a current version of the output image having a current K x K resolution; and processing the current version of the output image using a set of convolutional neural networks that are specific to the current resolution to generate an updated version of the output image having a 2K x 2K resolution.",G06T 3/40,DEEPMIND TECHNOLOGIES LIMITED,"KALCHBRENNER, Nal Emmerich; BELOV, Daniel; GOMEZ COLMENAREJO, Sergio; VAN DEN OORD, Aaron Gerard Antonius; WANG, Ziyu; GOMES DE FREITAS, Joao Ferdinando; REED, Scott Ellison","62/463,538 24.02.2017 US",CN-201880004376.6; EP-2018707702; JP-2019538533; KR-1020197020922
WO2019079598,PCT/US2018/056514,18.10.2018,WO/2019/079598,25.04.2019,WO,"PROBABILISTIC OBJECT MODELS FOR ROBUST, REPEATABLE PICK-AND-PLACE","A method includes, as a robot encounters an object, creating a probabilistic object model to identify, localize, and manipulate the object, the probabilistic object model using light fields to enable efficient inference for object detection and localization while incorporating information from every pixel observed from across multiple camera locations.",G06K 9/46; G06T 7/00,BROWN UNIVERSITY,"TELLEX, Stefanie; OBERLIN, John","62/573,890 18.10.2017 US",
WO2018093806,PCT/US2017/061663,15.11.2017,WO/2018/093806,24.05.2018,WO,EMBODIED DIALOG AND EMBODIED SPEECH AUTHORING TOOLS FOR USE WITH AN EXPRESSIVE SOCIAL ROBOT,"A social robot provides more believable, spontaneous, and understandable expressive communication via embodied communication capabilities by which a robot can express one or more of: paralinguistic audio expressions, sound effects or audio/vocal filters, expressive synthetic speech or pre-recorded speech, body movements and expressive gestures, body postures, lighting effects, aromas, and on-screen content, such as graphics, animations, photos, videos. These are coordinated with produced speech to enhance the expressiveness of the communication and non-verbal communication apart from speech communication.",G06F 17/20; G06F 17/27,"JIBO, INC.","BREAZEAL, Cynthia; FARIDI, Fardad; ADALGEIRSSON, Sigurdur, Orn; DONAHU, Thomas, James; RAGHAVAN, Sridhar; SHONKOFF, Adam","62/422,217 15.11.2016 US; 15/812,223 14.11.2017 US",
EP20467848,10749589,21.05.2010,2286963,23.02.2011,EP,WORK-ASSISTING ROBOT SYSTEM,"The working support robot system of the present invention includes: a robot arm (11); a measuring unit (12) for measuring the worker's position; a work progress estimation unit (13) for estimating the work progress based on data input from the measuring unit (12) while referring to data on work procedure, and for selecting objects necessary for the next task when the work is found to have advanced to the next procedure; and an arm motion planning unit (14) for planning the trajectory of the robot arm (11) to control the robot arm (11) based on the work progress estimated by the work progress estimation unit (13) and selected objects. The working support robot system can deliver objects such as tools and parts to the worker according to the work to be performed by the worker.",B25J 9/16; B23P 21/00; B25J 13/00; G05B 19/418,TOYOTA MOTOR EAST JAPAN INC; UNIV TOHOKU,KOSUGE KAZUHIRO; SUGAHARA YUSUKE; KINUGAWA JUN; KAWAAI YUTA; ITO AKIYOSHI; MATSUI YOICHI; KAWABE SHINJI,2009124756 22.05.2009 JP; 2010056786 12.03.2010 JP; 2010058648 21.05.2010 JP,
WO2020016866,PCT/IB2019/057334,30.08.2019,WO/2020/016866,23.01.2020,WO,ROBOTIC LIGHT PROJECTION TOOLS,"A robotic surgical system is disclosed which comprises a structured light source, a shaft-less tool (3102, 3502) comprising a projector (3110, 3510a ) configured to emit a structured light pattern on a surface of an anatomical structure, and a cable (3112, 3512) extending from the shaft-less tool (3102, 3502) to the structured light source. Also, a surgical visualization system is disclosed. The surgical visualization system is configured to identify one or more structure(s) and/or determine one or more distances with respect to obscuring tissue and/or the identified structure(s). The surgical visualization system can facilitate avoidance of the identified structure(s) by a surgical device. The surgical visualization system can comprise a first emitter configured to emit a plurality of tissue-penetrating light waves and a second emitter configured to emit structured light onto the surface of tissue. The surgical visualization system can also include an image sensor configured to detect reflected visible light, tissue- penetrating light, and/or structured light. The surgical visualization system can convey information to one or more clinicians regarding the position of one or more hidden identified structures and/or provide one or more proximity indicators. In various instances, a shaft-less light projection tool can be manipulated around the surgical site by a robotic tool.",A61B 1/00; A61B 1/04; A61B 1/06; A61B 5/00; A61B 5/107; A61B 34/30; A61B 90/30; A61B 90/00; G01B 11/25; G01N 21/25; G01N 21/31; G01S 17/89,ETHICON LLC,"SCHEIB, Charles J.; RITCHIE, Paul G.; MOORE, Sarah A.; SWAYZE, Jeffrey S.; TALBERT, Joshua D.; YOUNG, Joshua D.; MORENO, Victor C.","62/698,625 16.07.2018 US; 16/128,197 11.09.2018 US",
WO2016181150,PCT/GB2016/051362,12.05.2016,WO/2016/181150,17.11.2016,WO,IMAGE PROCESSING METHOD,A method is provided for efficiently managing the data bandwidth and storage requirement of a video camera by using an object detection engine to process a video captured by an image sensor even prior to compression. The method manages the video transmission bandwidth by processing the captured video based on information extracted by the object detection engine on a frame by frame basis without the loss of critical information. A related computer vision system is also provided..,H04N 19/503; G06K 9/00; G06T 5/00; H04N 5/14; H04N 7/18; H04N 19/172; H04N 19/115; H04N 19/117; H04N 19/124; H04N 19/142; H04N 19/167; H04N 19/137; H04N 19/87,APICAL LIMITED,"ROMANENKO, Ilya; TUSCH, Michael",1508074.0 12.05.2015 GB,GB-1720694.7
EP242633061,17830472,18.07.2017,3489784,29.05.2019,EP,SELF-MOVING GARDENING ROBOT AND SYSTEM THEREOF,"A self-moving gardening robot (100), comprising: a positioning module (70); a control module (30); a material cavity (52); and an operation module (50). The positioning module (70) of the self-moving gardening robot (100) is used for path planning, and the control module (30) controls the self-moving gardening robot (100) to walk according to a planned path. During walking of the self-moving gardening robot (100), the operation module (50) performs a corresponding operation. By filling the material cavity (52) with different materials, the self-moving gardening robot (100) can complete different functions and tasks following the same control procedure. Preferably, the self-moving gardening robot (100) further comprises an attachment port (12), and different functional attachments can be attached via the attachment port (12) to enable the self-moving gardening robot (100) to realize multiple functions. The self-moving gardening robot (100) is capable of performing path planning and has multiple functions integrated therein, thus increasing the efficiency of using the robot and reducing the application costs for a user.",G05D 1/02; A01D 34/00; A01D 43/02; A01D 43/12; A01D 43/14,POSITEC POWER TOOLS SUZHOU CO LTD,HE MINGMING; TAN YIYUN; SHAO YONG,201610566840 19.07.2016 CN; 201611149286 14.12.2016 CN; 2017093437 18.07.2017 CN,
EP132410475,14188281,09.10.2014,2859999,15.04.2015,EP,"Robot controller, robot system, robot, robot control method, and program","A robot includes a control unit that controls a movable unit of the robot to move an end point of the movable unit closer to a target position, and an image acquisition unit that acquires a target image as an image containing the end point when the end point is in the target position, and a current image as an image containing the end point when the end point is in a current position. The control unit controls movement of the movable unit based on the current image and the target image and output from a force detection unit that detects a force acting on the movable unit.",B25J 9/16,SEIKO EPSON CORP,AISO SEIJI; HASEGAWA HIROSHI; INAZUMI MITSUHIRO; KARITO NOBUHIRO,2013212919 10.10.2013 JP; 2013212940 10.10.2013 JP,
WO2019036805,PCT/CA2018/051011,22.08.2018,WO/2019/036805,28.02.2019,WO,METHOD AND SYSTEM FOR ACTIVITY CLASSIFICATION,"A method and system for activity classification. A pressure sensor receives input data resulting from physical activity of a subject performing an activity. The input data includes pressure data from at least one pressure sensor, and may include other data acquired through other types of sensors. A deep learning neural network is applied to the input data for identifying the activity. The neural network is trained with reference to training data from a training database. The training data may include empirical data from a database of previous data of corresponding activities, synthesized data prepared from the empirical data or simulated data. The training data may include data from physical activity of the subject being monitored by the system. Different aspects of the neural network may be trained with reference to the training data, and some aspects may be locked or opened depending on the application and the circumstances.",G16H 50/30; A61B 5/00; G06N 3/02; G06N 3/08,KINETYX SCIENCES INC.,"CHENG, Chun Hing; EVERETT, Julia Breanne; PURDY, Michael Todd; STEVENS, Travis Michael; VIBERG, David Allan; YEE, Dale Barry","62/548,676 22.08.2017 US",
WO2016196512,PCT/US2016/035097,31.05.2016,WO/2016/196512,08.12.2016,WO,METHOD AND SYSTEM FOR ROBOTIC ADAPTIVE PRODUCTION,A method for robotic adaptive production includes modifying program instructions online while performing production activities in response to detecting a change in the production environment. A robotic adaptive production method includes modifying program instructions online while performing production activities to minimize a production task cycle time or improve a production task quality. A robotic adaptive production method includes estimating a relationship between a control parameter and a sensor input; and modifying the control parameter online to achieve an updated parameter based on the estimating. A robotic adaptive production method includes receiving sensor input relating to robotic performance during the performance of production tasks and online optimizing a process parameter based on robotic performance during the performance of the production tasks. A robotic adaptive production method includes determining the position and/or orientation of a feature based on a learned position and/or orientation of another feature and on a geometric relationship.,G06F 19/00,"ABB SCHWEIZ AG; ZHANG, George, Q.; GRAVEL, David, P.; KOCK, Soenke; FUHLBRIGGE, Thomas, A.; CHEN, Heping; CHOI, Sangeun; BELL, Arnold; ZHANG, Biao","ZHANG, George, Q.; GRAVEL, David, P.; KOCK, Soenke; FUHLBRIGGE, Thomas, A.; CHEN, Heping; CHOI, Sangeun; BELL, Arnold; ZHANG, Biao","62/167,933 29.05.2015 US",DE-112016002431
WO2018183812,PCT/US2018/025354,30.03.2018,WO/2018/183812,04.10.2018,WO,PERSISTENT COMPANION DEVICE CONFIGURATION AND DEPLOYMENT PLATFORM,"A development platform for developing a skill for a persistent companion device (PCD) includes an asset development library having an application programming interface (API) configured to enable a developer to at least one of find, create, edit and access one or more content assets utilizable for creating a skill, an expression tool suite having one or more APIs via which are received one or more expressions associated with the skill as specified by the developer wherein the skill is executable by the PCD in response to at least one defined input, a behavior editor for specifying one or more behavioral sequences of the PCD for the skill and a skill deployment facility having an API for deploying the skill to an execution engine of the PCD.",G06N 5/02; G06F 17/21; G06F 17/27; G06F 17/30; G06F 9/44; G06F 9/54; G06Q 30/02; H04N 7/18,"JIBO, INC.","BREAZEAL, Cynthia; MICHAUD, Avida; LABERGE, Francois; ROSS, Jonathan, Louis; SAUND, Carolyn, Marothy; FARIDI, Fardad","15/474,841 30.03.2017 US",
EP236976160,16897113,27.12.2016,3438892,06.02.2019,EP,INFORMATION PROCESSING APPARATUS,[Object] To improve generalization performance of the neural network.  [Solution] There is provided an information processing device including: a control unit configured to control display related to a setting of a parameter related to physical simulation; a communication unit configured to transmit the parameter to a physical simulator and receive image information obtained in the physical simulation from the physical simulator; and a machine learning unit configured to perform machine learning on the basis of the image information. The control unit causes a display unit to display a learning result obtained by the machine learning unit and the parameter in association with each other.,G06N 99/00; G06F 17/50; G06N 3/04; G06N 3/08; G06N 20/00; G06T 7/00; G06T 7/55,SONY CORP,NAKAMURA AKIRA; NARIHIRA TAKUYA; FUJITA TAKUYA,2016063379 28.03.2016 JP; 2016088889 27.12.2016 JP,
WO2019171060,PCT/GB2019/050634,06.03.2019,WO/2019/171060,12.09.2019,WO,CONTROL POLICY DETERMINATION METHOD AND SYSTEM,"The present invention relates to a method of providing behaviour models of and for dynamic objects. Specifically, the present invention relates to a method and system for generating models and/or control policies for dynamic objects, typically for use in simulators and/or autonomous vehicles. The present invention sets out to provide a set or sets of behaviour models of and for dynamic objects, such as, for example, drivers, pedestrians and cyclists, typically for use in such autonomous vehicle simulators.",G06K 9/00; G06K 9/62,LATENT LOGIC LTD,"WHITESON, Shimon Azariah; MESSIAS, Joao; CHEN, Xi; BEHBAHANI, Feryal; SHIARLI, Kyriacos; KASEWA, Sudhanshu; KURIN, Vitaly",1803599.8 06.03.2018 GB; 1817987.9 02.11.2018 GB,
WO2018195462,PCT/US2018/028621,20.04.2018,WO/2018/195462,25.10.2018,WO,MACHINE-VISION SYSTEM FOR DISCRIMINANT LOCALIZATION OF OBJECTS,"Described is a system for discriminant localization of objects. During operation, the system causes one or more processors to perform an operation of identifying an object in an image using a multi-layer network. Features of the object are derived from the activations of two or more layers of the multi-layer network. The image is then classified to contain one or more object classes, and the desired object class is localized. A device can then be controlled based on localization of the object in the image. For example, a robotic arm can be controlled to reach for the object.",G06K 9/62; G06N 3/04; B25J 9/16,"HRL LABORATORIES, LLC","KOLOURI, Soheil; MARTIN, Charles, E.; HOFFMANN, Heiko","62/487,824 20.04.2017 US",CN-201880015274.4; EP-2018787063
WO2018215344,PCT/EP2018/063125,18.05.2018,WO/2018/215344,29.11.2018,WO,NOISY NEURAL NETWORK LAYERS,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for selecting an action to be performed by a reinforcement learning agent. The method includes obtaining an observation characterizing a current state of an environment. For each layer parameter of each noisy layer of a neural network, a respective noise value is determined. For each layer parameter of each noisy layer, a noisy current value for the layer parameter is determined from a current value of the layer parameter, a current value of a corresponding noise parameter, and the noise value. A network input including the observation is processed using the neural network in accordance with the noisy current values to generate a network output for the network input. An action is selected from a set of possible actions to be performed by the agent in response to the observation using the network output.",G06N 3/00; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"PIETQUIN, Olivier; MENICK, Jacob Lee; AZAR, Mohammad Gheshlaghi; PIOT, Bilal; MNIH, Volodymyr; BLUNDELL, Charles; FORTUNATO, Meire; MUNOS, Remi","62/509,059 20.05.2017 US; 62/525,099 26.06.2017 US",EP-2018725534; CN-201880018376.1
EP11172958,09153712,26.02.2009,2224425,01.09.2010,EP,An audio signal processing system and autonomous robot having such system,"An audio signal processing system comprises: 
a) one or more sensors for sensing audio signals, 
b.) a module for computing audio signal segments of coherent signal elements, 
c.) at least one compressing module for computing a compressed representation of audio features of each audio signal segment, and 
d.) a module for storing audio proto objects, which are data objects comprising the compressed representation and time information of the associated audio signal segment.",B25J 13/00; G10L 25/00,HONDA RES INST EUROPE GMBH,RODEMANN TOBIAS,09153712 26.02.2009 EP,
EP14283207,03723395,19.05.2003,1508409,23.02.2005,EP,ROBOT DEVICE AND ROBOT CONTROL METHOD,"The invention provides a robot apparatus and a robot controlling method wherein the robot apparatus can behave so that its user may not lose interest in the robot apparatus. A behavior management section (72) selects one of a seeking behavior and a knowledge utilizing behavior based on a behavior selection probability. When the behavior management section (72) executes the selected behavior (a), a reward (r) is provided from an environment/user (111). The behavior (72) updates a behavior value based on the reward (r) and applies the behavior value to the Boltzmann distribution to determine the behavior selection probability. Further, the behavior management section (72) varies the Boltzmann temperature based on input information. The present invention can be applied to a reinforced learning system for a robot. <IMAGE>",B25J 5/00; B25J 13/00; A63H 11/00; B25J 5/00; B25J 13/00; G06N 3/00,SONY CORP,SAWADA TSUTOMU; FUJITA MASAHIRO; HANAGATA OSAMU; TAKAGI TSUYOSHI,0306179 19.05.2003 JP; 2002145334 20.05.2002 JP,
EP11200748,09160406,15.05.2009,2251157,17.11.2010,EP,"Autonomous robots with planning in unpredictable, dynamic and complex environments","A controller for the motion control of a robot, comprises: 
- a target input interface for supplying the controller with information about a target to be reached, 
- a predicting module predicting at least one future state of the controlled robot using an internal model of the robot, 
- a planning module for planning future states of the robot, wherein the planning starts from a predicted state supplied from the predicting module, 
- a reactive controller, for outputting motor commands in order to make the controlled robot reach a target, and 
- a target arbitrator for selecting the target output by the predicting module or the output from the planning module.",B25J 9/16,HONDA RES INST EUROPE GMBH,SUGIURA HISASHI; JANSSEN HERBERT,09160406 15.05.2009 EP,
WO2012129250,PCT/US2012/029848,20.03.2012,WO/2012/129250,27.09.2012,WO,HUMANOID ROBOT PUSH RECOVERY ON LEVEL AND NON-LEVEL GROUND,"A robot controller controls a robot to maintain balance in response to an external disturbance (e.g., a push) on level or non-level ground. The robot controller determines a predicted stepping location for the robot such that the robot will be able to maintain a balanced upright position if it steps to that location. As long as the stepping location predicted stepping location remains within a predefined region (e.g., within the area under the robot's feet), the robot will maintain balance in response to the push via postural changes without taking a step, If the predicted stepping location moves outside the predefined region, the robot will take a step to the predicted location in order to maintain its balance.",G05B 13/04,"HONDA MOTOR CO., LTD.; YUN, Seungkook; GOSWAMI, Ambarish; LEE, Sung-hee","YUN, Seungkook; GOSWAMI, Ambarish; LEE, Sung-hee","61/454,933 21.03.2011 US",JP-2014501193
EP29858094,10155045,01.03.2010,2363251,07.09.2011,EP,Robot with Behavioral Sequences on the basis of learned Petri Net Representations,"This invention relates to a computer system, a robot system, and a driver assistance system that is required to interact with its environment in order to recognize and anticipate tasks or to provide support or assistance or initiate actions. The invention also relates to a software program product for such a system. In general the invention can be used for purposes such as (intention) recognition, prediction or action generation (imitation/cooperation) which is applied in the above mentioned areas as well as computer games or agents therefore.",B25J 9/16,HONDA RES INST EUROPE GMBH,JANSSEN HERBERT; MORINGEN JAN; WACHSMUTH SVEN,EP20100155045  ; 10155045 01.03.2010 EP,
WO2018194960,PCT/US2018/027744,16.04.2018,WO/2018/194960,25.10.2018,WO,MULTI-STAGE MACHINE LEARNING AND RECOGNITION,"A multi-stage machine learning and recognition system comprises multiple individual machine learning systems arranged in multiple stages, where data is passed from a machine learning system in one stage to one or more machine learning systems in a subsequent, higher-level stage of the structure according to the logic of the machine learning system. The multi-stage machine learning system can be arranged in a final stage and one or more non- final stages, where the one or more non-final stages direct data generally towards a selected one or more machine learning systems within the final stage, but less than all of the machine learning systems in the final stage. The multi-stage machine learning system can additionally include a separate machine learning system designated as a learning coach and data management system, which is configured to control the distribution of data throughout the multi-stage structure of machine learning systems by observing the internal state of the structure. The learning coach and data management system can additionally optimize the performance of the overall system by controlling one or more of the hyperparameters of any of the machine learning systems in the overall system, reorganizing the multi-stage structure, or perform other functions.",G06K 9/62; G10L 15/00; G10L 21/00,D5AI LLC,"BAKER, James, K.","62/486,650 18.04.2017 US",EP-2018787062
WO2018120082,PCT/CN2016/113651,30.12.2016,WO/2018/120082,05.07.2018,WO,"APPARATUS, METHOD AND COMPUTER PROGRAM PRODUCT FOR DEEP LEARNING","Apparatus (10), method, computer program product and computer readable medium are disclosed for deep learning. The apparatus (10) comprises at least one processor (11); at least one memory (12) including computer program code, the memory (12) and the computer program code configured to, working with the at least one processor (11), cause the apparatus (10) to use a two-dimensional activation function in a deep learning architecture, wherein the two-dimensional activation function comprises a first parameter representing an element to be activated and a second parameter representing the element's neighbors.",G06N 3/02,"NOKIA TECHNOLOGIES OY; NOKIA TECHNOLOGIES (BEIJING) CO., LTD.","LI, Hongyang",,CN-201680091938.6
EP12813130,96303583,21.05.1996,0744699,27.11.1996,EP,Neural network solder paste inspection system,A solder paste brick inspection and physical quality scoring system 10 employs a neural network 70 trained with a fuzzified output vector. An image of solder paste bricks 64 on a printed circuit board 12 is acquired by a CCD camera 30. Values of a predetermined set of brick metrics are extracted from the image by a computer 28 and used as a crisp input vector to trained neural network 70. A defuzzifier 76 converts a fuzzy output vector from neural network 70 into a crisp quality score output which can be used for monitoring and process control. <IMAGE>,G06F 15/80; G06F 15/18; G05B 13/02; G06N 3/00; G06N 3/04; H05K 3/34,EASTMAN KODAK CO,BRYANT STEVEN M; LOEWENTHAL KENNETH M,44728295 22.05.1995 US,
EP13961876,03000490,11.01.2003,1335296,13.08.2003,EP,Research system with remote access,"A remote research system, comprising: a central laboratory site equipped to be used for chemical research tests; one or several laboratory robots for performing chemical research tests; a central processing unit (CPU); one or several workstations linked to said central processing unit and set up to control said laboratory robots; one or several cameras for detecting actions of said laboratory robots when performing one of said chemical research tests, said one or several cameras being linked to said central processing unit via said one or several workstations; one or several remote user workstations linked to said central processing unit via a computer network and set up to allow remote user access to chemical research tests performed in said central laboratory site, the execution of a test performed being transmitted by said one or several cameras via said central processing unit and said computer network to said one or several remote user workstations. <IMAGE>",H04N 7/18; G05B 23/02; G06F 7/00; G06F 15/00; G06F 19/00; G08B 25/00; G08B 25/08; H04M 11/00,BASF AG,SCHROF WOLFGANG DR; LORENZ THOMAS DR; LEHMANN STEPHAN DR; HADELER JOACHIM; IDEN RUEDIGER DR; BANDARA UPALI DR,5858302 30.01.2002 US,
WO2019167042,PCT/IL2019/050222,27.02.2019,WO/2019/167042,06.09.2019,WO,SYSTEMS AND METHODS FOR USING AND TRAINING A NEURAL NETWORK,"There is provided a controller for control of a processor based system, comprising: a hardware processor(s) executing a code for: during an inference process of a neural network: feeding into the neural network (NN) input signals from sensors monitoring the processor based system, wherein the feeding triggers propagation of a forward dataflow in a forward direction from input to output and a non-forward dataflow in a non-forward direction from output to input, wherein the non-forward dataflow occurs at least one of before and simultaneously with the forward dataflow, wherein the forward dataflow and the non-forward dataflow establish candidate communication channels each mapping the input signals to candidate outputs, wherein a single communication channel is selected from the candidate communication channels, and outputting a single response mapped to the input signals by the single communication channel, the single response denoting instructions for control of the processor based system.",G06N 3/02,YISSUM RESEARCH DEVELOPMENT COMPANY OF THE HEBREW UNIVERSITY OF JERUSALEM LTD.,"RAPPOPORT, Ari","62/635,767 27.02.2018 US",
WO2018073395,PCT/EP2017/076802,19.10.2017,WO/2018/073395,26.04.2018,WO,UNIVERSAL AUTOMATED TESTING OF EMBEDDED SYSTEMS,"A system and method are provided for testing features of an embedded system. The system includes a low-powered computing device communicatively coupled to a control application interface, a sensor interface, and a robotic interface. The low- powered computing device may receive sensor signals generated during a test, provide sensor data corresponding to the sensor signals, receive commands for the test, and provide instructions for movement of a robotic handler corresponding to at least one of the commands for the test. The system also includes a computing device communicatively coupled to the control application interface, an image processing interface, and a database interface. The computing device may receive sensor data, receive image data corresponding to images of the embedded system captured during the test, receive tests capable of being performed, and provide commands for the test.",G01R 31/28; G01R 31/319,"Y SOFT CORPORATION, A.S.","KYZLINK, Jiři; NOVOTNÝ, Václav; PERNIKÁŘ, Aleš; PAVLÁK, Jakub; KRAJĺČEK, Ondřej","62/410,666 20.10.2016 US",CN-201780065066.0; EP-2017790742; RU-2019114687; JP-2019519634; AU-2017347687
EP45863938,11183211,29.09.2011,2447014,02.05.2012,EP,Method and system for enhancing operating performance of an autonomic mobile robotic device,A mechanism for optimizing behavior of an autonomous mobile robotic device. A first set of robotic behaviors is created based on a set of work area parameters and a behavior selection. The autonomous mobile robotic device is controlled using the first set of robotic behaviors. Performance data indicative of a performance of the autonomous mobile robotic device when controlled by the first set of robotic behaviors is collected. The performance data is analyzed to create a second set of robotic behaviors having enhanced performance relative to the first set of robotic behaviors. The first set of robotic behaviors is replaced with the second set of robotic behaviors to control the autonomous mobile robotic device using the second set of robotic behaviors.,B25J 9/16,DEERE & CO,ANDERSON NOEL W; BODWELL MARK; FOESSEL ALEX; HEIN THOMAS K,91187210 26.10.2010 US,
WO2018045551,PCT/CN2016/098543,09.09.2016,WO/2018/045551,15.03.2018,WO,TRAINING AND DEPLOYING POSE REGRESSIONS IN NEURAL NETWORKS IN AUTONOMOUS MACHINES,"A mechanism is described for facilitating training and deploying of pose regression in neural networks in autonomous machines. A method, as described herein, includes facilitating capturing, by an image capturing device of a computing device, one or more images of one or more objects, where the one or more images include one or more training images associated with a neural network. The method may further include continuously estimating, in real-time, a present orientation of the computing device, where estimating includes continuously detecting a real-time view field as viewed by the image capturing device and based on the one or more images. The method may further include applying pose regression relating to the image capturing device using the real-time view field.",G06T 7/00,"INTEL CORPORATION; MA, Liwei","MA, Liwei",,
WO2019023984,PCT/CN2017/095621,02.08.2017,WO/2019/023984,07.02.2019,WO,SYSTEM AND METHOD ENABLING ONE-HOT NEURAL NETWORKS ON A MACHINE LEARNING COMPUTE PLATFORM,"A compute apparatus to perform machine learning operations, the compute apparatus comprising instruction decode logic to decode a single instruction including multiple operands into a single decoded instruction, the multiple operands including a first operand and a second operand, the first operand including vector of one-hot coded weights and the second operand including a vector of input data； and a general-purpose graphics compute unit including a first logic unit, the general-purpose graphics compute unit to execute the single decoded instruction, wherein to execute the single decoded instruction includes to perform multiple operations on the first set of operands and the second set of operands.",G06N 3/02,INTEL CORPORATION,"CHEN, Yurong; LI, Jianguo",,
WO2016154440,PCT/US2016/024017,24.03.2016,WO/2016/154440,29.09.2016,WO,SPARSE INFERENCE MODULES FOR DEEP LEARNING,"Described is a sparse inference module that can be incorporated into a deep learning •system. For example, the deep learning system includes a plurality of hierarchical feature channel layers, each feature channel layer having a set of filters. A plurality of sparse inference modules can be included, such that a sparse inference module resides electronically within each feature channel layer. Each sparse inference module is configured to receive data and match the data against a plurality of pattern templates to generate a. degree of match value for each of the pattern templates, wife the degree of match values being sparsified such that only those degree of match values that exceed a predetermined threshold, or a fixed number of the top degree of match values, are provided to subsequent feature, channels in the plurality of hierarchical feature channels, while other, losing degree of match values are quenched to zero.",G06N 5/04; G06N 3/08; G06F 15/18; G06F 17/00,"HRL LABORATORIES, LLC; PILLY, Praveen, K.; STEPP, Nigel, D.; SRINIVASA, Narayan","PILLY, Praveen, K.; STEPP, Nigel, D.; SRINIVASA, Narayan","62/155,355 30.04.2015 US; 62/137,665 24.03.2015 US",EP-2016769696
WO2018164740,PCT/US2017/062785,21.11.2017,WO/2018/164740,13.09.2018,WO,A METHOD AND SYSTEM FOR IMPLEMENTING REINFORCEMENT LEARNING AGENT USING REINFORCEMENT LEARNING PROCESSOR,"The embodiments herein disclose a system and method foe implementing reinforcement learning agents using a reinforcement learning processor. As application-domain specific instruction set (ASI) for implementing reinforcement learning agents and reward functions is created. Further, instructions are created by including at least one of the reinforcement teaming agent ID vectors, the reinforcement learning environment ID vectors, and length of vector as an operand. The reinforcement learning agent ID vectors and the reinforcement learning environment ID vectors are pointers to a base address of an operations memory. Further, at least one of said reinforcement learning agent ID vector and reinforcement learning environment ID vector is embedded into operations associated with the decoded instruction. The instructions retrieved by agent II) vector indexed operation are executed using a second processor, and applied onto a 'group of reinforcement learning agents. The operations defined fay the instructions are stored in an operations storage memory.",G06F 15/18,ALPHAICS CORPORATION,"NAGARAJA, Nagendra","15/455,126 09.03.2017 US; 15/720,723 29.09.2017 US; 15/659,501 25.07.2017 US",
WO2015030689,PCT/TR2014/000318,27.08.2014,WO/2015/030689,05.03.2015,WO,"A TOOL AND METHOD FOR ROBUST, SCALE AND ORIENTATION INVARIANT OBJECT DETECTION AND CLASSIFICATION",The invention relates to shape detection method and system and more particularly to automatic shape detection method and system that detects the shape of an object in an image acquired by a camera.,G06K 9/46; G06K 9/62,"ALTUN, Halis","ALTUN, Halis",2013/10136 27.08.2013 TR,
WO2015017355,PCT/US2014/048512,28.07.2014,WO/2015/017355,05.02.2015,WO,APPARATUS AND METHODS FOR CONTROLLING OF ROBOTIC DEVICES,"A robot may be trained based on cooperation between an operator and a trainer. During training, the operator may control the robot using a plurality of control instructions. The trainer may observe movements of the robot and generate a plurality of control commands, such as gestures, sound and/or light wave modulation. Control instructions may be combined with the trainer commands via a learning process in order to develop an association between the two. During operation, the learning process may generate one or more control instructions based on one or more gesture by the trainer. One or both the trainer or the operator may comprise a human, and/or computerized entity.",G06N 3/02,BRAIN CORPORATION,"PASSOT, Jean-Baptiste; LAURENT, Patryk; IZHIKEVICH, Eugene M.","13/953,595 29.07.2013 US",
WO2014201422,PCT/US2014/042412,13.06.2014,WO/2014/201422,18.12.2014,WO,APPARATUS AND METHODS FOR HIERARCHICAL ROBOTIC CONTROL AND ROBOTIC TRAINING,"A robot may be trained by a user guiding the robot along target trajectory using a control signal. A robot may comprise an adaptive controller. The controller may be configured to generate control commands based on the user guidance, sensory input and a performance measure. A user may interface to the robot via an adaptively configured remote controller. The remote controller may comprise a mobile device, configured by the user in accordance with phenotype and/or operational configuration of the robot. The remote controller may detect changes in the robot phenotype and/or operational configuration. The remote controller may comprise multiple control elements configured to activate respective portions of the robot platform. Based on training, the remote controller may configure composite controls configured based two or more of control elements. Activation of a composite control may enable the robot to perform a task.",G06F 19/00,BRAIN CORPORATION,"PASSOT, Jean-Baptiste; SINYAVSKIY, Oleg; PONULAK, Filip; LAURENT, Patryk; GABARDOS, Borja, Ibarz; IZHIKEVICH, Eugene; POLONICHKO, Vadim","13/918,298 14.06.2013 US; 13/918,338 14.06.2013 US",
WO2018111374,PCT/US2017/053727,27.09.2017,WO/2018/111374,21.06.2018,WO,ASSOCIATING FACES WITH VOICES FOR SPEAKER DIARIZATION WITHIN VIDEOS,A computer-implemented method for speech diarization is described. The method comprises determining temporal positions of separate faces in a video using face detection and clustering. Voice features are detected in the speech sections of the video. The method further includes generating a correlation between the determined separate faces and separate voices based at least on the temporal positions of the separate faces and the separate voices in the video. This correlation is stored in a content store with the video.,G06F 17/30; G10L 17/00,GOOGLE INC.,"CHAUDHURI, Sourish; HOOVER, Kenneth","15/497,497 26.04.2017 US; 62/435,710 16.12.2016 US",
WO2017045716,PCT/EP2015/071289,17.09.2015,WO/2017/045716,23.03.2017,WO,A COMPONENT FEEDER AND A SYSTEM FOR PICKING COMPONENTS COMPRISING THE COMPONENT FEEDER,"The present invention relates to a component feeder (1) comprising a stationary picking surface (2) for receiving components (14) to be picked, a vision system including an image unit arranged to take images of components distributed on the picking surface and a load device (5) including one or more load sensors adapted to detect the presence of a component on the picking surface and the vision system is configured to automatically trigger the image unit to take an image upon detecting the presence of the component on the picking surface.",B25J 9/16,ABB SCHWEIZ AG,"SIRKETT, Daniel; FRANSSON, Peter",,EP-2015766453; US-15756419
EP214091979,16190124,22.09.2016,3298874,28.03.2018,EP,ROBOTIC GARDENING DEVICE AND METHOD FOR CONTROLLING THE SAME,"The invention regards a robotic gardening device comprising driving means (2) for propelling the robotic gardening device, a working tool (3) for performing dedicated gardening work and a controlling unit (4) for controlling said driving means (2) and the working tool (3) and a method for controlling the same. The robotic gardening device further comprises at least one environment sensor (6) generating a signal indicative of objects in the environment of the robotic gardening device, a computing unit (7) for classifying these objects, wherein the classes comprise at least two different classes for objects being determined to be humans. The computing unit (7) is configured to control the driving means (2) and/or the working device (3) according to a predetermined behavior associated with the respective objects class.",A01D 34/00; A01D 75/18; G05D 1/02,HONDA RES INSTITUTE EUROPE GMBH,FRANZIUS MATHIAS; EINECKE NILS,16190124 22.09.2016 EP,
EP21408395,10151057,19.01.2010,2345984,20.07.2011,EP,Online learning of grounded categories using adaptive feature spaces,"The invention therefore provides a method for categorizing input patterns, comprising receiving from an accepting of means at least one input pattern including sensorial information representing observations, generating at least one feature pattern by transforming the input pattern by application of at least one feature extraction module which learns from the performed generating process, categorizing the feature pattern into a category by application of at least one learnable categorization module which learns from the performed categorization process. The learning of the feature extraction module uses input from at least one categorization module based on which the feature extraction module extracts a feature pattern discriminating the categories obtained by the categorization module, and the generating and categorization process are performed on a processing means. The method further comprises storing a category derived from the categorization process with features of the input pattern, and returning category information for the input pattern by an output means.",G06N 3/04; G06N 3/08,HONDA RES INST EUROPE GMBH,GLAESER CLAUDIUS,10151057 19.01.2010 EP,
WO2020013778,PCT/TR2019/050192,26.03.2019,WO/2020/013778,16.01.2020,WO,EVALUATION METHOD FOR THE HAIR TRANSPLANT PROCESS USING THE IMAGE PROCESSING AND ROBOTIC TECHNOLOGIES AND THE SYSTEM OF THE METHOD,"The present invention relates to a novel method and system which is based on the image processing technology and robotic technologies which are used for planning and evaluating the processes of the hair transplant operations. The invention relates to a method for planning the hair transplant operations being a common treatment in the medical field, so as to obtain more reliable and healthy results relative to the present operations and for evaluating the whole operational process through the systematic data, and a system facilitating said method to be applied.",G06T 7/00; G06T 17/00; A61B 34/10,KEBOT BİLİŞİM TEKNOLOJİLERİ SANAYİ VE TİCARET ANONİM ŞİRKETİ,"ERDOĞAN, Koray; URHAN, Oğuzhan",2018/05930 26.04.2018 TR,
EP11715207,86904361,01.07.1986,0227841,08.07.1987,EP,SYSTEM FOR CONTROLLING ARTICULATED ROBOT.,"A control unit for an articulated robot with an image sensor consists of two microprocessor CPU's, data buses, a serial interface which receives a control target information, memories a bubble memory and an input/output controller. The first CPU and the serial interface handles the data provided by the image sensor system and the second CPU converts the serial data into correction data on each axis to control the robot movement. These two processes are done in parallel and in real time.",B25J 9/16; B25J 9/18; G05B 19/18; G05B 19/404; G05B 19/414,FANUC LTD,KISHI HAJIMU; MIZUNO TOHRU; ISHIKAWA HARUYUKI,14425785 01.07.1985 JP,
WO2019089825,PCT/US2018/058552,31.10.2018,WO/2019/089825,09.05.2019,WO,SYSTEMS AND METHODS FOR OPTICAL MATERIAL CHARACTERIZATION OF WASTE MATERIALS USING MACHINE LEARNING,"Systems and methods for optical material characterization of waste materials using machine learning are provided. In one embodiment, a system comprises: an imaging device configured to generate image frames an area and target objects within the area; an object characterization processor coupled to the imaging device and comprising Neural Processing Units and a Neural Network Parameter Set. The Neural Network Parameter Set stores learned parameters utilized by the one or more Neural Processing Units for characterizing the one or more target objects. The Neural Processing Units are configured by the Neural Network Parameter Set to detect a presence of a plurality of different materials within the image frames based on a plurality of different features. For a first image frame of the plurality of image frames, the Neural Processing Units outputs material characterization data that identifies which of the plurality of different materials are detected in the first image frame.",G06K 9/00; G06K 9/62,AMP ROBOTICS CORPORATION,"HOROWITZ, Matanya B.; BAILEY, James A.","62/580,720 02.11.2017 US",
WO2020065001,PCT/EP2019/076163,27.09.2019,WO/2020/065001,02.04.2020,WO,LEARNING MOTOR PRIMITIVES AND TRAINING A MACHINE LEARNING SYSTEM USING A LINEAR-FEEDBACK-STABILIZED POLICY,"A computer-implemented method of training a student machine learning system comprises receiving data indicating execution of an expert, determining one or more actions performed by the expert during the execution and a corresponding state-action Jacobian, and training the student machine learning system using a linear-feedback-stabilized policy. The linear- feedback-stabilized policy may be based on the state-action Jacobian. Also a neural network system for representing a space of probabilistic motor primitives, implemented by one or more computers. The neural network system comprises an encoder configured to generate latent variables based on a plurality of inputs, each input comprising a plurality of frames, and a decoder configured to generate an action based on one or more of the latent variables and a state.",G06N 3/04; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"HASENCLEVER, Leonard; PHAM, Vu; MEREL, Joshua; GALASHOV, Alexandre","62/737,816 27.09.2018 US",
EP224637550,18154908,02.02.2018,3361414,15.08.2018,EP,TOPOGRAPHIC DATA MACHINE LEARNING METHOD AND SYSTEM,"Embodiments of the invention apply machine learning techniques for image recognition and classification to the processing of topographic imagery, in order to permit more accurate and detailed topographic representations of an area to be obtained. In particular, in one embodiment a machine learning system is trained with existing topographic imagery and corresponding topographic data relating to a particular area, so that the machine learning system is then able to relate actual physical topographical features to their topographic representations in existing data. Having been so trained, the machine learning system may then be used to process topographic imagery data of the same area to determine new topographic details thereof for incorporation into the topographic data.",G06K 9/00; G06K 9/62,ORDNANCE SURVEY LTD,SARGENT ISABEL; HARE JONATHON,201702095 08.02.2017 GB,
WO2006000103,PCT/CA2005/001018,29.06.2005,WO/2006/000103,05.01.2006,WO,SPIKING NEURAL NETWORK AND USE THEREOF,"Systems for audio and image processing using bio-inspired neural network are proposed. The first system allows separating a specific sound in a mixture of audio sources. The second system allows performing visual pattern processing and recognition robust to affine transforms and noise. The neural network system comprises first and second layers of spiking neurons, each neurons being configured for respectively first and second internal connections to other neurons from the same layer or for external connections to neurons from the other layer for receiving extra-layer stimuli therefrom and for receiving external stimuli from external signals; and global controllers connected to all neurons to allow inhibiting the neurons. In operation, upon receiving stimuli from said the first and second external signals, the internal connections are promoted, and synchronous spiking from neurons from the first and second layers are promoted by the external connections when some of the stimuli from the first external signals are similar to some of the stimuli from the second external signals. There is no need to tune the neural network when changing the signal nature. Furthermore, the proposed neural network is autonomous and there is neither training nor recognition phase.",G06N 3/02; G06K 9/62; G10L 15/16,"UNIVERSITE DE SHERBROOKE; ROUAT, Jean; PICHEVAR, Ramin","ROUAT, Jean; PICHEVAR, Ramin","2,472,864 29.06.2004 CA",EP-5761674; DE-null; EP-05761674
EP196378463,16197146,03.11.2016,3166049,10.05.2017,EP,SYSTEMS AND METHODS FOR ATTENTION-BASED CONFIGURABLE CONVOLUTIONAL NEURAL NETWORKS (ABC-CNN) FOR VISUAL QUESTION ANSWERING,"Described herein are systems and methods for generating and using attention-based deep learning architectures for visual question answering task (VQA) to automatically generate answers for image-related (still or video images) questions. To generate the correct answers, it is important for a model's attention to focus on the relevant regions of an image according to the question because different questions may ask about the attributes of different image regions. In embodiments, such question-guided attention is learned with a configurable convolutional neural network (ABC-CNN). Embodiments of the ABC-CNN models determine the attention maps by convolving image feature map with the configurable convolutional kernels determined by the questions semantics. In embodiments, the question-guided attention maps focus on the question-related regions and filters out noise in the unrelated regions.",G06N 3/02,BAIDU USA LLC,CHEN KAN; WANG JIANG; XU WEI,201562250260 03.11.2015 US; 201615184991 16.06.2016 US,
WO2019171116,PCT/IB2018/051387,05.03.2018,WO/2019/171116,12.09.2019,WO,METHOD AND DEVICE FOR RECOGNIZING OBJECT,"The present disclosure relates to a method and device for recognizing an object. The method includes: acquiring an image of the object; inputting the image into a first machine learning model, and acquiring, by means of the first machine learning model, one or more first probabilities respectively corresponding to one or more features of the object in the image, as a first output of the first machine learning model; inputting at least the first output into a second machine learning model, and acquiring, by means of the second machine learning model, a recognition result of the object in the image, as a second output of the second machine learning model; and providing the first output and the second output corresponding to the first output.",G06K 9/00; G06K 9/62,OMRON CORPORATION,"YANAGAWA, Yukiko",,
WO2017206156,PCT/CN2016/084621,03.06.2016,WO/2017/206156,07.12.2017,WO,LOOK-UP CONVOLUTIONAL LAYER IN CONVOLUTIONAL NEURAL NETWORK,"Embodiments provide for a processor including logic to accelerate convolutional neural network processing, the processor including first logic to apply a convolutional layer to an image to generate a first convolution result and second logic to apply a look-up convolutional layer to the first convolution result to generate a second convolution result, the second convolution result associated with a location of the first convolution result within a global filter kernel.",G06K 9/66,"INTEL CORPORATION; MA, Liwei; SONG, Jiqiang","MA, Liwei; SONG, Jiqiang",,EP-2016903541; CN-201680085331.7
WO2019113510,PCT/US2018/064569,07.12.2018,WO/2019/113510,13.06.2019,WO,TECHNIQUES FOR TRAINING MACHINE LEARNING,"A system and method are provided for training a machine learning system. In an embodiment, the system generates a three-dimensional model of an environment using a video sequence that includes individual frames taken from a variety of perspectives and environmental conditions. An object in the environment is identified and labeled, in some examples, by an operator, and a three-dimensional model of the object is created. Training data for the machine learning system is created by applying the label to the individual video frames of the video sequence, or by applying a rendering of the three-dimensional model to additional images or video sequences.",G06K 9/74; G06K 9/78; G06N 3/08; G06N 7/00,"BLUHAPTICS, INC.","WHITE, Steven James; RYDEN, Olof Fredrik; MARSH, Donald Mark","62/596,011 07.12.2017 US",
WO2013045314,PCT/EP2012/068337,18.09.2012,WO/2013/045314,04.04.2013,WO,CALIBRATION AND PROGRAMMING OF ROBOTS,"The invention pertains to a method of calibrating robots without the use of external measurement equipment. The invention furthermore pertains to a method of copying working programs between un-calibrated robots. Both methods utilize the properties of a closed chain and the relative position of the links in the chain in order to update the kinematic models of the robots,",B25J 9/16; G05B 19/408,"UNIVERSAL ROBOTS A/S; SØE-KNUDSEN, Rune; ØSTERGAARD, Esben Hallundbæk; PETERSEN, Henrik Gordon","SØE-KNUDSEN, Rune; ØSTERGAARD, Esben Hallundbæk; PETERSEN, Henrik Gordon","61/540,150 28.09.2011 US",MX-MX/a/2014/003540; EP-2012777867; JP-2014532317; EP-2014173234
EP82196143,11816333,02.08.2011,2605152,19.06.2013,EP,"INFORMATION PROCESSING DEVICE, INFORMATION PROCESSING METHOD, AND PROGRAM","The present invention relates to an information processing device, an information processing method, and a program capable of easily adding an annotation to content.  A feature amount extracting unit 21 extracts an image feature amount of each frame of an image of learning content and extracts word frequency information regarding frequency of appearance of each word in a description text describing a content of the image of the learning content (for example, a text of a caption) as a text feature amount of the description text. A model learning unit 22 learns an annotation model, which is a multi-stream HMM, by using an annotation sequence for annotation, which is a multi-stream including the image feature amount of each frame and the text feature amount. The present invention may be applied when adding the annotation to the content such as a television broadcast program, for example.",G06F 17/30; G06N 3/00,SONY CORP,SUZUKI HIROTAKA; ITO MASATO,2010180174 11.08.2010 JP; 2011067691 02.08.2011 JP,
WO2019204777,PCT/US2019/028389,19.04.2019,WO/2019/204777,24.10.2019,WO,SURGICAL SIMULATOR PROVIDING LABELED DATA,"A surgical simulator for simulating a surgical scenario comprises a display system, a user interface, and a controller. The controller includes one or more processors coupled to memory that stores instructions that when executed cause the system to perform operations. The operations include generating simulated surgical videos, each representative of the surgical scenario. The operations further include associating simulated ground truth data from the simulation with the simulated surgical videos. The ground truth data corresponds to context information of at least one of a simulated surgical instrument, a simulated anatomical region, a simulated surgical task, or a simulated action. The operations further include annotating features of the simulated surgical videos based, at least in part, on the simulated ground truth data for training a machine learning model.",G09B 9/00; G09B 23/28; G06K 9/00,VERILY LIFE SCIENCES LLC,"JIN, Xing; BARRAL, Joëlle K.; YANG, Lin; HABBECKE, Martin; CAMPION, Gianni","62/660,726 20.04.2018 US; 16/373,261 02.04.2019 US",
WO2019149949,PCT/EP2019/052692,05.02.2019,WO/2019/149949,08.08.2019,WO,DISTRIBUTED TRAINING USING OFF-POLICY ACTOR-CRITIC REINFORCEMENT LEARNING,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for training an action selection neural network used to select actions to be performed by an agent interacting with an environment. In one aspect, a system comprises a plurality of actor computing units and a plurality of learner computing units. The actor computing units generate experience tuple trajectories that are used by the learner computing units to update learner action selection neural network parameters using a reinforcement learning technique. The reinforcement learning technique may be an off-policy actor critic reinforcement learning technique.",G06N 3/04; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"SOYER, Hubert Josef; ESPEHOLT, Lasse; SIMONYAN, Karen; DORON, Yotam; FIROIU, Vlad; MNIH, Volodymyr; KAVUKCUOGLU, Koray; MUNOS, Remi; WARD, Thomas; HARLEY, Timothy James Alexander; DUNNING, Iain","62/626,643 05.02.2018 US",
WO2018051349,PCT/IL2017/051045,14.09.2017,WO/2018/051349,22.03.2018,WO,FACILITY MONITORING BY A DISTRIBUTED ROBOTIC SYSTEM,"Methods and systems of detecting a facility condition based on status data sensed within a facility using a plurality of mobile sensing platforms. The status data include sensing data and positions of the sensing. The facility condition is determined by operation of a computer processor using an associating data structure, which associates status data patterns to facility conditions. The status data patterns are defined in a combination of the status data from more than one of the mobile sensing platforms, and can form a status data pattern not defined in status data from any single one of the mobile sensing platforms.",G08B 23/00; B25J 9/00; G06N 5/00,R.A.S ROBOTICS ARTIFICIAL INTELLIGENCE LTD.,"EINAV, Omer; ROSENMANN, Shmuel; TALISMAN, Dror; BEN BASAT, Tal Haim","62/394,772 15.09.2016 US",
WO2013100978,PCT/US2011/067623,28.12.2011,WO/2013/100978,04.07.2013,WO,REAL-TIME NATURAL LANGUAGE PROCESSING OF DATASTREAMS,"Systems and methods for identifying and locating related content using natural language processing are generally disclosed herein. One embodiment includes an HTML5/JavaScript user interface configured to execute scripting commands to perform natural language processing and related content searches, and to provide a dynamic interface that enables both user-interactive and automatic methods of obtaining and displaying related content. The natural language processing may extract one or more context-sensitive key terms of text associated with a set of content. Related content may be located and identified using keyword searches that include the context-sensitive key terms. For example, text associated with video of a first content, such as text originating from subtitles or closed captioning, may be used to perform searches and locate related content such as a video of a second content, or text of a third content.",G06F 17/20; G06F 3/048; G06F 17/30,"INTEL CORPORATION; SMITH, Elliot; SZILAGYI, Victor","SMITH, Elliot; SZILAGYI, Victor",,KR-1020157019776; KR-1020187007765; KR-1020147017918; KR-1020167008857; EP-2011878980; US-13992406; JP-2014548776
EP278291161,18744662,16.01.2018,3575046,04.12.2019,EP,MOBILE ROBOT AND METHOD FOR CONTROLLING SAME,"A robot cleaner according to one embodiment of the present invention comprises: a traveling unit for moving a main body; an image acquisition unit for acquiring an image around the main body; a sensor unit including at least one sensor for sensing an obstacle during the movement; a storage unit for storing position information of a detected obstacle and position information of a mobile robot when the sensor unit detects the obstacle, registering an area having a predetermined size around a position of the detected obstacle as an obstacle area in a map, and storing the image acquired by the image acquisition unit in the obstacle area; an obstacle recognition module for recognizing sequentially attributes of the obstacles with respect to images acquired by the image acquisition unit in the obstacle area, on the basis of data learned by a machine learning, and determining a final attribute of the obstacle on the basis of the sequentially recognized plurality of recognition results; and a control unit for determining properties of a plurality of obstacles by the obstacle recognition module when detecting a constraint state in which all possible travel routes are blocked due to the plurality of obstacles, and controlling the traveling unit to move one of the plurality of obstacles.",B25J 11/00; A47L 9/28; B25J 5/00; B25J 9/00; B25J 9/16; B25J 19/02,LG ELECTRONICS INC,CHOI HYUKDOO; PARK SUNGGIL; SHIN DONGMYUNG; LEE JUNGHYUN; JEON HYEONGSHIN,20170012318 25.01.2017 KR; 2018000761 16.01.2018 KR,
EP231869832,18161702,14.03.2018,3389005,17.10.2018,EP,ABSTRACTION LIBRARY TO ENABLE SCALABLE DISTRIBUTED MACHINE LEARNING,"One embodiment provides for a non-transitory machine readable medium storing instructions which, when executed by one or more processors, cause the one or more processors to perform operations comprising providing an interface to define a neural network using machine-learning domain specific terminology, wherein the interface enables selection of a neural network topology and abstracts low-level communication details of distributed training of the neural network.",G06T 1/20,INTEL CORP,KALAMKAR DHIRAJ D; VAIDYANATHAN KARTHIKEYAN; SRIDHARAN SRINIVAS; DAS DIPANKAR,201715482925 10.04.2017 US,
EP281664870,17901629,16.11.2017,3593958,15.01.2020,EP,DATA PROCESSING METHOD AND NURSING ROBOT DEVICE,"Disclosed is a data processing method and nursing robot device, to solve a problem in the prior art that a nursing robot can only choose among given interaction modes by computing the emotional state of an interacting object, and cannot provide the interacting object with a more suitable interaction mode. The method comprises: a model engine receives data about a target object, so as to generate a matrix of capability parameters in a growth model for the target object (S401); according to a coefficient of an adjustment formula or according to a standard matrix of capability parameters in a growth model, the model engine makes adjustments on a capability parameter adjustment value in the matrix of capability parameters in a growth model, so as to determine an adjusted capability parameter adjustment value (S402); the model engine determines whether the adjusted capability parameter adjustment value exceeds a preset threshold (S403); and if the adjusted capability parameter adjustment value is within the preset threshold, the model engine sends to a machine learning engine the adjusted capability parameter adjustment value, wherein the machine learning engine provides, according to the capability parameter adjustment value, an artificial intelligence module with the capability parameters required to interact with the target object (S404).",B25J 9/16; A61H 3/00; B25J 11/00; G10L 25/63,HUAWEI TECH CO LTD,TANG WEIDONG; HUANG KANGMIN,201710184421 24.03.2017 CN; 2017111312 16.11.2017 CN,
WO2013019743,PCT/US2012/048881,30.07.2012,WO/2013/019743,07.02.2013,WO,APPARATUS AND METHODS FOR OBJECT RECOGNITION USING A GENETICALLY-DEFINED FEATURE SPACE TRANSFORM,"The instant disclosure relates to use of genetic algorithms that produce feature space transforms that are individually trained/evaluated extensively a priori to identify specific objects or features of such specific objects (e.g., man-made structures such as vehicles, buildings, flags, and the like and natural-objects such as human facial features, animals, and the like). A resulting optimized feature space transform results and can be implemented as a very compact algorithm operating on a small reconnaissance vehicle having limited processing capability, for example. The feature space transform can be utilized to identify diverse and distinct objects (e.g., two, five, ten, or more) from a single vehicle (or stationary location). Thus, if the objects of interest include a weapon, a vehicle, and/or a particular building the single vehicle can alternatively apply the single feature space transform upon a scene of interest and distinguish with a high degree of specificity and sensitivity which of the plurality of objects is present. The conclusions drawn from the transform can be wirelessly transmitted for appropriate follow-up, stored to a memory location, and/or quickly acted upon by the vehicle.",G06F 17/00; G06N 3/12; G06K 9/00,"RECONROBOTICS, INC.; SCHUPP, Daniel, Riley; ANDRIE-HER, Lue","SCHUPP, Daniel, Riley; ANDRIE-HER, Lue","61/513,279 29.07.2011 US",
WO2018144846,PCT/US2018/016624,02.02.2018,WO/2018/144846,09.08.2018,WO,SYSTEMS AND METHODS FOR ASSISTING A ROBOTIC APPARATUS,"Systems and methods for assisting a robotic apparatus are disclosed. In some exemplary implementations, a robot can encounter situations where the robot cannot proceed and/or does not know with a high degree of certainty it can proceed. Accordingly, the robot can determine that it has encountered an error and/or assist event. In some exemplary implementations, the robot can receive assistance from an operator and/or attempt to resolve the issue itself. In some cases, the robot can be configured to delay actions in order to allow resolution of the error and/or assist event.",G05D 1/00; G05D 1/02,BRAIN CORPORATION,"SINYAVSKIY, Oleg; PASSOT, Jean-Baptiste; GABARDOS, Borja Ibarz; LE, Diana Vu","15/423,442 02.02.2017 US",CN-201880019765.6; EP-2018706048; JP-2019541747
EP253957614,17874188,21.11.2017,3546139,02.10.2019,EP,MOBILE ROBOT AND CONTROL METHOD THEREOF,"A mobile robot according to one aspect of the present invention comprises: a travel unit for moving a main body; an image acquisition unit for acquiring an image of the surroundings of the main body; a sensor unit comprising at least one sensor for detecting an obstacle while moving; a control unit for, when the sensor unit detects an obstacle, recognizing the attribute of the detected obstacle on the basis of the image acquired by the image acquisition unit, and controlling driving of the travel unit on the basis of the recognized attribute of the obstacle; and a sound output unit for outputting a predetermined sound when the recognized attribute of the obstacle indicates that the robot can pass over the obstacle, whereby stability, a user's convenience, operation efficiency, and cleaning efficiency can be improved.",B25J 11/00; A47L 9/28; B25J 9/00; B25J 9/16; B25J 19/02; B25J 19/06,LG ELECTRONICS INC,NOH DONGKI; BAEK SEUNGMYUN; BAEK SEUNGMIN; LEE SUNGHUN,20160157552 24.11.2016 KR; 2017013274 21.11.2017 KR,
WO2018120932,PCT/CN2017/102498,20.09.2017,WO/2018/120932,05.07.2018,WO,METHOD AND APPARATUS FOR OPTIMIZING SCAN DATA AND METHOD AND APPARATUS FOR CORRECTING TRAJECTORY,"A novel method and an apparatus for optimizing scan data obtained by sensors on vehicle.An improved method and an apparatus for correcting trajectory for vehicle/robot based on the said method and apparatus for optimizing scan data.The method for optimizing scan data obtained by scanning environment elements, includes: step of obtaining the scan data (210), obtaining at least two frames of scan data respectively corresponding to different timings; step of cluster processing (220), based on the characteristic of the data points, classifying the plurality of data points in each frame of the scan data into one or more clusters; step of establishing correspondence (230), among the at least two frames of scan data, searching and obtaining at least one set of clusters having correspondence; step of optimizing clusters (240), among the at least two frames of scan data, conducting calculation to each set of the at least one set of clusters having correspondence, to obtain optimized clusters respectively corresponding to each set of the at least one set of clusters having correspondence; and step of optimizing the scan data (250),accumulating all optimized clusters to obtain an optimized scan date for the at least two frames of scan data.",G06K 9/66,"BAYERISCHE MOTOREN WERKE AKTIENGESELLSCHAFT; DOEMLING, Maximilian; JIANG, Wanli; LI, Qianshan; LI, Jianpeng; GRANZOW, Sebastian; XU, Tao; XU, Hongshan; LV, Shuhan","DOEMLING, Maximilian; JIANG, Wanli; LI, Qianshan; LI, Jianpeng; GRANZOW, Sebastian; XU, Tao; XU, Hongshan; LV, Shuhan",PCT/CN2016/11219.3 26.12.2016 CN,EP-2017885472
WO2018126228,PCT/US2017/069128,29.12.2017,WO/2018/126228,05.07.2018,WO,SIGN AND LANE CREATION FOR HIGH DEFINITION MAPS USED FOR AUTONOMOUS VEHICLES,"An HD map system represents landmarks on a high definition map for autonomous vehicle navigation, including describing spatial location of lanes of a road and semantic information about each lane, and along with traffic signs and landmarks. The system generates lane lines designating lanes of roads based on, for example, mapping of camera image pixels with high probability of being on lane lines into a three-dimensional space, and locating/connecting center lines of the lane lines. The system builds a large connected network of lane elements and their connections as a lane element graph. The system also represents traffic signs based on camera images and detection and ranging sensor depth maps. These landmarks are used in building a high definition map that allows autonomous vehicles to safely navigate through their environments.",G06T 7/00; G06K 9/00,DEEPMAP CAYMAN LIMITED,"WHEELER, Mark, Damon; YANG, Lin; MILLER, Derek, Thomas; JOSEPH STEPHEN MAX, Lenord Melvix; ZHANG, Yu; PIAO, Dongzhen; CUI, Ming","62/441,065 30.12.2016 US; 62/441,080 30.12.2016 US",
WO2018064794,PCT/CN2016/101427,05.10.2016,WO/2018/064794,12.04.2018,WO,GENERAL PURPOSE INPUT/OUTPUT DATA CAPTURE AND NEURAL CACHE SYSTEM FOR AUTONOMOUS MACHINES,"A mechanism is described for facilitating general purpose input/output data capture and neural cache system for autonomous machines. A method of embodiments, as described herein, includes capturing, by an image capturing device, one or more images of one or more objects, where the one or more images represent input data associated with a neural network. The method may further include determining accuracy of first output results generated by a default neural caching system by comparing the first output results with second output results predicted by a custom neural caching system. The method may further include outputting, based on the accuracy, a final output results including at least one of the first output results or the second output results.",G06F 17/00,"INTEL CORPORATION; MA, Liwei; SONG, Jiqiang","MA, Liwei; SONG, Jiqiang",,CN-201680088988.9
WO2017206144,PCT/CN2016/084512,02.06.2016,WO/2017/206144,07.12.2017,WO,ESTIMATION OF HUMAN ORIENTATION IN IMAGES USING DEPTH INFORMATION,"Techniques are provided for estimation of human orientation and facial pose, in images that include depth information. A methodology embodying the techniques includes detecting a human in an image generated by a depth camera and estimating an orientation category associated with the detected human. The estimation is based on application of a random forest classifier, with leaf node template matching, to the image. The orientation category defines a range of angular offsets relative to an angle corresponding to the human facing the depth camera. The method also includes performing a three dimensional (3D) facial pose estimation of the detected human, based on detected facial landmarks, in response to a determination that the estimated orientation category includes the angle corresponding to the human facing the depth camera.",G06K 9/00,"INTEL CORPORATION; REN, Haibing; ZHANG, Yimin; HU, Xiaobo; DUAN, Fei","REN, Haibing; ZHANG, Yimin; HU, Xiaobo; DUAN, Fei",,US-16098649; KR-1020187031883; DE-112016006921
EP45949505,11007903,29.09.2011,2450762,09.05.2012,EP,Robot cleaner and controlling method of the same,"A robot cleaner and a method for controlling the same are provided. A region to be cleaned may be divided into a plurality of sectors based on detection data collected by a detecting device, and a partial map for each sector may be generated. A full map of the cleaning region may then be generated based on a position of a partial map with respect to each sector, and a topological relationship between the partial maps. Based on the full map, the robot cleaner may recognize its position, allowing the entire region to be completely cleaned, and allowing the robot cleaner to rapidly move to sectors that have not yet been cleaned.",G05D 1/02; G01C 21/32,LG ELECTRONICS INC,LEE TAE-KYEONG; LEE SEONGSU; BAEK SEUNGMIN; NA SANGIK; OH SE-YOUNG; BAEK SANGHOON; JOO KWANGRO; YOON JEONGSUK; KIM YIEBIN,20100108850 03.11.2010 KR,
WO2019232471,PCT/US2019/035043,31.05.2019,WO/2019/232471,05.12.2019,WO,MACHINE LEARNING AT EDGE DEVICES BASED ON DISTRIBUTED FEEDBACK,Machine learning (ML) is provided at edge computing devices based on distributed feedback received from the edge computing devices. A trained instance of an ML model is received at the edge computing devices via communications networks from an ML model manager. Feedback data including labeled observations is generated by the execution of the trained instance of the ML model at the edge computing devices on unlabeled observations captured by the edge computing devices. The feedback data is transmitted from the edge computing devices to a machine learning model manager. A re-trained instance of the machine learning model is generated from the trained instance using the collected feedback data. The re-trained instance of the machine learning model is received at the edge computing devices from the machine learning model manager. The re-trained instance of the machine learning model is executed at the edge computing devices.,G06N 20/10; G06N 3/02; G06N 3/08,NAMI ML INC.,"PEZZILLO, Joseph D.; BURCAW, Daniel; CANTARERO, Alejandro","62/679,256 01.06.2018 US; 62/681,200 06.06.2018 US; 16/428,591 31.05.2019 US",
WO2008005661,PCT/US2007/070977,12.06.2007,WO/2008/005661,10.01.2008,WO,OCCUPANCY CHANGE DETECTION SYSTEM AND METHOD,"Robot platforms (10OA, IOOB and 1OOC), methods, and computer readable media are disclosed. The robot platform includes perceptors, locomotors (175), and a system controller. The system controller (110) executes instructions for producing an occupancy grid (390) map of an environment around the robot, scanning the environment to generate a current obstacle map relative to a current robot position, and converting the current obstacle map to a current occupancy grid (390) map. The instructions also include processing each grid cell (395) in the occupancy grid (390) map. Within the processing of each grid cell (395), the instructions include comparing each gπd cell (395) in the occupancy grid (390) map to a corresponding grid cell (395) in the current occupancy grid (390) map. For grid cells (395) with a difference, the instructions include defining a change vector for each changed grid cell (395), wherein the change vector includes a direction from the robot to the changed grid cell (395) and a range from the robot to the changed grid cell (395).",G06F 19/00,"BATTELLE ENERGY ALLIANCE, LLC","BRUEMMER, David, J.; FEW, Douglas, A.","11/428,646 05.07.2006 US",
WO2019140772,PCT/CN2018/079218,16.03.2018,WO/2019/140772,25.07.2019,WO,"METHOD OF GENERATING TRAINING DATA FOR TRAINING A NEURAL NETWORK, METHOD OF TRAINING A NEURAL NETWORK AND USING NEURAL NETWORK FOR AUTONOMOUS OPERATIONS","A method of generating training data for training a neural network, method of training a neural network and using a neural network for autonomous operations, related devices and systems. In one aspect, a neural network for autonomous operation of an object in an environment is trained. Policy values are generated based a sample data set. An approximate action-value function is generated from the policy values. A set of approximated policy values is generated using the approximate action-value function for all states in the sample data set for all possible actions. A training target for the neural network is calculated based on the approximated policy values. A training error is calculated as the difference between the training target and the policy value for the corresponding state-action pair in the sample data set. At least some of the parameters of the neural network are updated to minimize the training error.",G06F 17/30,"HUAWEI TECHNOLOGIES CO., LTD.","YAO, Hengshuai","15/873,609 17.01.2018 US",
EP246633930,17843973,24.08.2017,3505312,03.07.2019,EP,MOBILE ROBOT AND CONTROL METHOD THEREFOR,"The mobile robot according to one aspect of the present invention comprises: a drive unit for moving a main body; an image obtainment unit for obtaining a plurality of images by continuously photographing the surroundings of the main body; a storage unit for storing the plurality of continuous images obtained by the image obtainment unit; a sensor unit comprising one or more sensors for sensing obstacles during travel; and a control unit comprising an obstacle recognition module for, once the sensor unit has sensed an obstacle, selecting an image of a particular point prior to the point at which the sensor unit sensed the obstacle, among the plurality of continuous images, on the basis of the travel direction and travel speed of the main body and recognizing the attributes of the obstacle included in the selected image of the particular point, the mobile robot thus being capable of obtaining image data, which allows for the increased accuracy of obstacle attribute recognition, and accurately recognizing the attributes of obstacles.",B25J 11/00; A47L 9/28; B25J 9/00; B25J 9/16; B25J 19/02,LG ELECTRONICS INC,NOH DONGKI; LEE JUHYEON; KIM JUNGHWAN; BAEK SEUNGMIN; YANG WONKEUN,20160108384 25.08.2016 KR; 20160108385 25.08.2016 KR; 20160108386 25.08.2016 KR; 2017009260 24.08.2017 KR,
WO2020037127,PCT/US2019/046659,15.08.2019,WO/2020/037127,20.02.2020,WO,SYSTEMS AND METHODS FOR MODELING AND CONTROLLING PHYSICAL DYNAMICAL SYSTEMS USING ARTIFICIAL INTELLIGENCE,"The present disclosure provides systems, methods, and computer program products for controlling an object. An example method can comprise (a) obtaining video data of the object and (b) performing motion analysis on the video data to generate modified video data. The method can further comprise (c) using artificial intelligence (AI) to identify a set of features in the modified video data. The set of features may be indicative of a predicted state of the object. The AI may be been trained offline on historical training data. The method can further comprise (d) using the predicted state to determine a control signal and (e) transmitting, in real-time, the control signal to the object to adjust or maintain a state of the object in relation to the predicted state. Operations (a) to (d) can be performed without contacting the object.",G06T 7/20; G06K 9/00; G06T 7/00,"DAUNTLESS.IO, INC.","VAUGHAN, Adam","62/719,296 17.08.2018 US",
WO2018188993,PCT/EP2018/058516,04.04.2018,WO/2018/188993,18.10.2018,WO,PERSON IDENTIFICATION SYSTEMS AND METHODS,"Techniques disclosed herein relate to identifying individuals in digital images. In some embodiments, a digital image(s) (430, 530) that captures a scene containing one or more people may be acquired (402). The single digital image may be applied (406, 408) as input across a single machine learning model (534). In some implementations, the single machine learning model may be trained to perform a non-facial feature recognition task and a face-related recognition task. Output may be generated over the single machine learning model based on the input. The output may include first data indicative of non-facial features of a given person of the one or more people and second data indicative of at least a location of a face of the given person in the digital image relative to the non-facial features. In various embodiments, the given person may be identified (410) based at least in part on the output.",G06K 9/00; G06K 9/32; G06K 9/46; G06K 9/62,KONINKLIJKE PHILIPS N.V.,"SWISHER, Christine Menking; ASIF, Rahman","62/485,654 14.04.2017 US",EP-2018716980; JP-2019555972
WO2020000431,PCT/CN2018/093833,29.06.2018,WO/2020/000431,02.01.2020,WO,"METHOD, APPARATUS AND COMPUTER READABLE MEDIA FOR IMAGE PROCESSING","Embodiments of the present disclosure relate to methods, apparatuses and computer program products for image processing. A method comprises extracting a plurality of features of an image via a convolutional block of a convolutional neural network (CNN), the convolutional block including a plurality of convolutional layers and the plurality of features including position information of an object in the image; selecting features from the plurality features via a capsule layer of the CNN, the features selected maintaining the position information; and generating a detection result of the image based on the selected features.",G06K 9/62,"NOKIA TECHNOLOGIES OY; NOKIA TECHNOLOGIES (BEIJING) CO., LTD.","LI, Yazhao",,
EP77314966,12190813,31.10.2012,2590043,08.05.2013,EP,Walking robot and control method thereof,"A control method of a walking robot having at least one joint unit provided at a leg thereof, the method comprising:calculating a compensation value for the at least one joint unit using an angle between a ground and deepest corner points of stairs; generating a stairs-walking target-trajectory required to allow the robot to walk on the stairs using the calculated compensation value and a level-walking target-trajectory; calculating a torque that tracks the generated stairs-walking target-trajectory; andcontrolling walking of the robot on the stairs by transmitting the calculated torque to the at least one joint unit.",G05D 1/08; B25J 13/08; B62D 57/032,SAMSUNG ELECTRONICS CO LTD,LEE MIN HYUNG; ROH KYUNG SHIK,20110114040 03.11.2011 KR,
WO2013181637,PCT/US2013/043783,31.05.2013,WO/2013/181637,05.12.2013,WO,NEURAL NETWORK LEARNING AND COLLABORATION APPARATUS AND METHODS,"Apparatus and methods for learning and training in neural network-based devices. In one implementation, the devices each comprise multiple spiking neurons, configured to process sensory input In one approach, alternate heterosynaptic plasticity mechanisms are used to enhance learning and field diversity within the devices. The selection of alternate plasticity rules is based on recent post-synaptic activity of neighboring neurons. Apparatus and methods for simplifying training of the devices are also disclosed, including a computer- based application. A data representation of the neural network may be imaged and transferred to another computational environment, effectively copying the brain. Techniques and architectures for achieve this training, storing, and distributing these data representations are also disclosed.",G06N 3/04,BRAIN CORPORATION,"BUIBAS, Marius; IZHIKEVICH, Eugene, M.; SZATMARY, Botond; POLONICHKO, Vadim","61/654,738 01.06.2012 US; 13/830,398 14.03.2013 US",
EP289840112,18193035,06.09.2018,3620984,11.03.2020,EP,DIGITAL QUALITY CONTROL USING COMPUTER VISIONING WITH DEEP LEARNING,"Implementations include receiving sample data, the sample data being generated as digital data representative of a sample of the product, providing a set of features by processing the sample data through multiple layers of a residual network, a first layer of the residual network identifying one or more features of the sample data, and a second layer of the residual network receiving the one or more features of the first layer, and identifying one or more additional features, processing the set of features using a CNN to identify a set of regions, and at least one object in a region of the set of regions, and determine a type of the at least one object, and selectively issuing an alert at least partially based on the type of the at least one object, the alert indicating contamination within the sample of the product.",G06N 3/04; G06T 7/00,ACCENTURE GLOBAL SOLUTIONS LTD,BONNEAU OLIVIER; HAMANI SAMI; DE LA COMBLE ALOÏS PETER PRIEUR; COTTEREAU PATRICK,18193035 06.09.2018 EP,
WO2020058334,PCT/EP2019/075004,18.09.2019,WO/2020/058334,26.03.2020,WO,METHOD AND SYSTEM FOR MODIFYING IMAGE DATA CAPTURED BY MOBILE ROBOTS,The invention relates to a method and system for modifying images captured by mobile robots. The method comprises capturing at least one image via at least one visual sensor of a mobile robot; converting the at least one image into image data; storing image data; detecting at least one identifier present in the image data; applying an obfuscation to the at least one detected identifier in the image data to gain obfuscated image data; and providing the obfuscated image data to at least one authorized agent. The system comprises at least one capturing component wherein the capturing component is configured to capture at least one image at any positioning of the mobile robots; a converting component wherein the converting component is configured to convert at least one image into image data; a storing component for storing the image data; a processing component. The processing component comprises a detecting component for detecting at least one identifier present in the image data; an obfuscating component for obfuscating the identifier detected in at the image data; a transferring component for providing the obfuscated image data to an authorized agent.,H04W 12/02; G05D 1/02; G06F 21/62,STARSHIP TECHNOLOGIES OÜ,"PÄRNPUU, Rao; KORJUS, Kristjan; LAAS, Vahur; VOLKOV, Kalle-Rasmus; VÄIN, Lauri; KHARAGORGIIEV, Sergii; SAMUEL, Joonatan",18195936.2 21.09.2018 EP,
WO2019013960,PCT/US2018/039278,25.06.2018,WO/2019/013960,17.01.2019,WO,METHODS AND SYSTEMS FOR LEARNING-BASED IMAGE EDGE ENHANCEMENT OF SAMPLE TUBE TOP CIRCLES,"Methods for image-based detection of the tops of sample tubes used in an automated diagnostic analysis system may be based on a convolutional neural network to pre-process images of the sample tube tops to intensify the tube top circle edges while suppressing the edge response from other objects that may appear in the image. Edge maps generated by the methods may be used for various image-based sample tube analyses, categorizations, and/or characterizations of the sample tubes to control a robot in relationship to the sample tubes. Image processing and control apparatus configured to carry out the methods are also described, as are other aspects.",G06N 3/02; G06K 9/00,SIEMENS HEALTHCARE DIAGNOSTICS INC.,"CHANG, Yao-Jen; KLUCKNER, Stefan; POLLACK, Benjamin S.; CHEN, Terrence","62/531,121 11.07.2017 US",CN-201880046218.7; EP-2018832807
WO2020061193,PCT/US2019/051732,18.09.2019,WO/2020/061193,26.03.2020,WO,METHOD AND SYSTEM FOR EXECUTING MACHINE LEARNING ALGORITHMS,"A computer-implemented data processing method providing an improvement in executing machine learning processes on digital data representing physical properties related to agriculture is described. In an embodiment, the method comprises: receiving, from a computing device, a request to browse machine learning models stored in a digital model repository; retrieving, from the digital model repository and transmitting to the computing device, information about the machine learning models stored in the digital model repository; receiving, from the computing device, a selection, from the machine learning models, of a particular model and receiving particular input for the particular model; using resources available in a model execution infrastructure platform, executing the particular model on the particular input to generate particular outputs; transmitting the particular output to a computer configured on an agricultural machine to control the agricultural machine as the agricultural machine performs agricultural tasks in an agricultural field.",G06N 5/04; G06F 16/9535,THE CLIMATE CORPORATION,"ALVAREZ, Francisco; ALI, Mir; MELCHING, Jeff; HOCHMUTH, Erich","62/734,420 21.09.2018 US",
WO2017096570,PCT/CN2015/096882,10.12.2015,WO/2017/096570,15.06.2017,WO,VISUAL RECOGNITION USING DEEP LEARNING ATTRIBUTES,"A processing device for performing visual recognition using deep learning attributes and method for performing the same are described. In one embodiment, a processing device comprises: an interface to receive an input image； and a recognition unit coupled to the interface and operable to perform visual object recognition on the input image, where the recognition unit has an extractor to extract region proposals from the input image, a convolutional neural network (CNN) to compute features for each extracted region proposal, the CNN being operable to create a soft-max layer output, a cross region pooling unit operable to perform pooling of the soft-max layer output to create a set of attributes of the input image, and an image classifier operable to perform image classification based on the attributes of the input image.",G06K 9/66,"INTEL CORPORATION; LI, Jianguo; LUO, Jianwei; CHEN, Yurong","LI, Jianguo; LUO, Jianwei; CHEN, Yurong",,DE-112015007176; US-15300474
WO2019219962,PCT/EP2019/062909,20.05.2019,WO/2019/219962,21.11.2019,WO,REINFORCEMENT LEARNING USING AGENT CURRICULA,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for reinforcement learning using agent curricula.",G06N 3/00; G06N 3/04; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"CZARNECKI, Wojciech; JAYAKUMAR, Siddhant","62/673,747 18.05.2018 US",
WO2018182538,PCT/SG2018/050167,02.04.2018,WO/2018/182538,04.10.2018,WO,SYSTEMS AND METHODS THAT IMPROVE ALIGNMENT OF A ROBOTIC ARM TO AN OBJECT,"Systems and methods that improve alignment of a robotic arm to an object or parts of the object. Sensors sense a 3D protrusion on the object and a salient regular surface to which the 3D protrusion attaches. A method infers, based on a known geometry of the object, a component of the object that is next to the 3D protrusion and not detectable with the sensors. The robotic arm moves, based on a location of the 3D protrusion and a location of the component, with respect to the component.",B25J 9/10; G06F 19/00; G01S 17/88,"AGENCY FOR SCIENCE, TECHNOLOGY AND RESEARCH","LI, Jun; TEE, Keng Peng; WAN, Kong Wah; CHEN, Lawrence Tai Peng; YAU, Wei Yun; LI, Renjun; LAI, Fon Lin",10201702706P 31.03.2017 SG,SG-11201909082T
EP97851710,13179633,15.06.2010,2672356,11.12.2013,EP,"Robot cleaner system including robot cleaner and docking station, and method of controlling the robot with length modulated guiding signals","A system is described comprising a docking station having a first transmission unit to transmit a first docking signal in a first direction, the first docking signal comprising at least a first signal pulse and a second signal pulse, wherein the first signal pulse has a pulse width that has a different time length than a pulse width of the second signal pulse. The system further comprises a robot cleaner comprising a reception unit to receive the first docking signal from the docking station, and a control unit configured to determine if the received first docking signal is an unreflected wave received directly from the first transmission unit or if the received first docking signal is a reflected wave produced by reflection of the first docking signal by an obstacle, the control unit to control movement of the robot cleaner based on whether the received first docking signal is determined to be the reflected wave or the unreflected wave.",G05D 1/02; G05D 1/06,SAMSUNG ELECTRONICS CO LTD,KYUNG HWAN YOO; JOO JAE MAN; KIM DONG WON; LEE JUN HWA; HONG JUN PYO; WOO RAM CHUNG; JAE YOUNG JUNG; HWI CHAN JANG; JEONG GON SONG; JEUNG SAM JONG; KO JANG YOUN,10165910 15.06.2010 EP; 11151821 15.06.2010 EP; 20090075963 18.08.2009 KR; 20100019376 04.03.2010 KR; 21356909 19.06.2009 US,
WO2009155947,PCT/EP2008/005205,26.06.2008,WO/2009/155947,30.12.2009,WO,CONTROL SYSTEM AND METHOD FOR CONTROL,"The invention is related to a control system (18, 62) for at least one robot (16, 68), comprising a data processing means (66) and a robot program stored thereon, whereas the robot program determines at least one trajectory of the at least one robot (16, 68) by a given movement path and a given movement speed. The control system (18, 62) is configured to receive and process safety-relevant first information (46, 84) of a person (12) near or within the working range of the at least one robot (16, 68). The processed first information (88) causes either an emergency or protective stop of the at least one robot (16, 68) or no reaction during the execution of the robot program. The control system (18, 62) is configured to alternatively receive and process safety-relevant second information (42, 76, 78, 80, 82, 83) of a person (12) near or within the working range of the robot (16, 68), whereas the processed second information (86) adaptively influences the trajectory of the at least one robot (16, 68), so that the safety of the person (12) is ensured while executing the robot program. The invention is also related to a belonging method for control.",B25J 9/16,"ABB AG; MATTHIAS, Björn; BEHNISCH, Kevin; KRIEGER, Roland","MATTHIAS, Björn; BEHNISCH, Kevin; KRIEGER, Roland",,
EP246633928,17843972,24.08.2017,3505311,03.07.2019,EP,MOBILE ROBOT AND CONTROL METHOD THEREFOR,"The mobile robot according to one aspect of the present invention comprises: a drive unit for moving a main body; an image obtainment unit for obtaining images around the main body; a sensor unit comprising one or more sensors for sensing obstacles during travel; a storage unit for, if the sensor unit senses an obstacle, storing location information about the sensed obstacle and location information about the mobile robot, registering, as an obstacle area in a map, an area having a predetermined size around the location of the sensed obstacle, and storing images obtained by the image obtainment unit in the obstacle area; and a control unit comprising an obstacle recognition module for sequentially recognizing attributes of the obstacle from the images obtained by the image obtainment unit in the obstacle area and determining the final attributes of the obstacle on the basis of multiple recognition results sequentially recognized, the mobile robot thus being capable of accurately recognizing the attributes of obstacles and registering/managing obstacle areas.",B25J 11/00; A47L 9/28; B25J 9/00; B25J 9/16; B25J 19/02,LG ELECTRONICS INC,NOH DONGKI; LEE JUHYEON; KIM JUNGHWAN; BAEK SEUNGMIN; YANG WONKEUN,20160108384 25.08.2016 KR; 20160108385 25.08.2016 KR; 20160108386 25.08.2016 KR; 2017009258 24.08.2017 KR,
WO2018112833,PCT/CN2016/111500,22.12.2016,WO/2018/112833,28.06.2018,WO,EFFICIENT TRANSFERRING OF HUMAN EXPERIENCES TO ROBOTS AND OTHER AUTONOMOUS MACHINES,"A mechanism is described for facilitating transferring of human experiences to autonomous machines. A method of embodiments, as described herein, includes facilitating sensing, by one or more sensors, one or more inputs relating to a user, and evaluating the one or more inputs to capture one or more behavior traits of the user. The method may further include training a neural network model based on the one or more behavior traits, and applying the trained neural network model to a computing device to facilitate the computing device to adopt the one or more behavior traits to behave as the user.",G06N 3/02,"INTEL CORPORATION; MA, Liwei; SONG, Jiqiang; ZHANG, Hong","MA, Liwei; SONG, Jiqiang; ZHANG, Hong",,CN-201680090974.0
EP221780214,17197484,20.10.2017,3336776,20.06.2018,EP,COGNITIVE ROBOTICS ANALYZER,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for a cognitive robotics analyzer are disclosed. In one aspect, a method includes the actions of receiving, for each user characteristic of a plurality of user characteristics, first data that identifies one or more first actions that perform a first process and second data that identifies one or more second actions that perform a second process that is labeled as similar to the first process. The actions further include training a predictive model. The actions further include receiving data that identifies actions performed by a user. The actions further include applying the predictive model to one or more of the actions. The actions further include classifying a process performed by the one or more actions as similar to a particular process. The actions further include associating the user with the particular user characteristic.",G06N 5/04; G06N 5/02; G06N 99/00; G06Q 10/06; H04L 12/26; H04L 29/08,ACCENTURE GLOBAL SOLUTIONS LTD,BATALLER CYRILLE; SCHIOPU VITALIE; JACQUOT ADRIEN; TORRES SERGIO RAÚL DUARTE; HALL SIMON,201615360535 23.11.2016 US,
WO2009089369,PCT/US2009/030464,08.01.2009,WO/2009/089369,16.07.2009,WO,POINT AND GO NAVIGATION SYSTEM AND METHOD,A remote operator console provides point and go navigation of a robotic vehicle. The remote operator console provides a display for visual representation of the environment in which the robotic vehicle is operating based on sensor information received from the robotic vehicle. An operator may designate a target point on the display. The robotic vehicle is automatically navigated toward a location in the environment corresponding to the designated target point.,G05D 1/00,"RAYTHEON SARCOS, LLC; JACOBSEN, Stephen, C.; OLIVIER, Marc","JACOBSEN, Stephen, C.; OLIVIER, Marc","61/010,501 08.01.2008 US",
WO2019040179,PCT/US2018/039473,26.06.2018,WO/2019/040179,28.02.2019,WO,CONTROLLING LANDINGS OF AN AERIAL ROBOTIC VEHICLE USING THREE-DIMENSIONAL TERRAIN MAPS GENERATED USING VISUAL-INERTIAL ODOMETRY,"Various embodiments include methods that may be implemented in a processor or processing device of an aerial robotic vehicle for generating three-dimensional terrain map based on the plurality of altitude above ground level values generated using visual-inertial odometry, and using such terrain maps to control the altitude of the aerial robotic vehicle. Some methods may include using the generated three-dimensional terrain map during landing. Such embodiment may further include refining the three-dimensional terrain map using visual-inertial odometry as the vehicle approaches the ground and using the refined terrain maps during landing. Some embodiments may include using the three-dimensional terrain map to select a landing site for the vehicle.",G05D 1/06; G08G 5/02; B64C 19/02,QUALCOMM INCORPORATED,"SWEET III, Charles Wheeler; MELLINGER III, Daniel Warren; DOUGHERTY, John Anthony","15/683,240 22.08.2017 US",
WO2015116543,PCT/US2015/012948,26.01.2015,WO/2015/116543,06.08.2015,WO,APPARATUS AND METHODS FOR CONTROL OF ROBOT ACTIONS BASED ON CORRECTIVE USER INPUTS,"Robots have the capacity to perform a broad range of useful tasks, such as factory automation, cleaning, delivery, assistive care, environmental monitoring and entertainment. Enabling a robot to perform a new task in a new environment typically requires a large amount of new software to be written, often by a team of experts. It would be valuable if future technology could empower people, who may have limited or no understanding of software coding, to train robots to perform custom tasks. Some implementations of the present invention provide methods and systems that respond to users' corrective commands to generate and refine a policy for determining appropriate actions based on sensor-data input. Upon completion of learning, the system can generate control commands by deriving them from the sensory data. Using the learned control policy, the robot can behave autonomously.",G06F 19/00,BRAIN CORPORATION,"MEIER, Philip; PASSOT, Jean-Baptiste; IBARZ GABARDOS, Borja; LAURENT, Patryk; SINYAVSKIY, Oleg; O'CONNOR, Peter; IZHIKEVICH, Eugene","14/171,762 03.02.2014 US",
WO2019070388,PCT/US2018/051241,14.09.2018,WO/2019/070388,11.04.2019,WO,ROBOT AS PERSONAL TRAINER,"Methods for using a robot to provide feedback to a user when the user is engaged in a physical activity includes detecting presence of the user in a geo-location, monitoring user activity and when the robot detects the user is performing an exercise from an exercise routine, the robot is positioned to one or more positions proximate to the user so as to capture image of a posture held by the user while performing the exercise. The captured image is analyzed and feedback provided to the user to allow the user to improve his posture.",G05D 1/02; G05D 1/00; A63B 24/00,"SONY INTERACTIVE ENTERTAINMENT INC.; MALLINSON, Dominic","MALLINSON, Dominic","15/705,167 14.09.2017 US",
WO2016164326,PCT/US2016/025959,05.04.2016,WO/2016/164326,13.10.2016,WO,AUTOMATED COLLECTION AND LABELING OF OBJECT DATA,Data about a physical object in a real-world environment is automatically collected and labeled. A mechanical device is used to maneuver the object into different poses within a three-dimensional workspace in the real-world environment. While the object is in each different pose an image of the object is input from one or more sensors and data specifying the pose is input from the mechanical device. The image of the object input from each of the sensors for each different pose is labeled with the data specifying the pose and with information identifying the object. A database for the object that includes these labeled images can be generated. The labeled images can also be used to train a detector and classifier to detect and recognize the object when it is in an environment that is similar to the real-world environment.,G05B 19/408; G06K 9/62,"MICROSOFT TECHNOLOGY LICENSING, LLC","THIBODEAU, Bryan J.; REVOW, Michael; JALOBEANU, Mihai; SHIRAKYAN, Grigor","14/683,810 10.04.2015 US",EP-2016717743
WO2020044052,PCT/GB2019/052418,30.08.2019,WO/2020/044052,05.03.2020,WO,'LIVENESS' DETECTION SYSTEM,"A detection system assesses whether a person viewed by a computer-based system is a live person or not. The system has an interface configured to receive a video stream; a word, letter, character or digit generator subsystem configured to generate and output one or more words, letters, characters or digits to an end-user; and a computer vision subsystem. The computer vision subsystem is configured to analyse the video stream received, and to determine, using a lip reading or viseme processing subsystem, if the end-user has spoken or mimed the or each word, letter, character or digit, and to output a confidence score that the end-user is a ""live"" person or not.",G06K 9/00,LIOPA LTD,"STEWART, Darryl; COWAN, Alexandra; PASS, Adrian; CAMPBELL-WEST, Fabian; BEAR, Helen",1814121.8 30.08.2018 GB,
WO2018053430,PCT/US2017/052072,18.09.2017,WO/2018/053430,22.03.2018,WO,"SYSTEM AND CALIBRATION, REGISTRATION, AND TRAINING METHODS","One variation of a method for manipulating a multi-link robotic arm includes: accessing a virtual model of the target object; extracting an object feature representing the target object from the virtual model; at the robotic arm, scanning a field of view of an optical sensor for the object feature, the optical sensor arranged on a distal end of the robotic arm proximal an end effector; in response to detecting the object feature in the field of view of the optical sensor, calculating a physical offset between the target object and the end effector based on a position of the object feature in the field of view of the optical sensor and a known offset between the optical sensor and the end effector; and driving a set of actuators in the robotic arm to reduce the physical offset.",B25J 9/16; B25J 9/22; B25J 13/00; B25J 13/08; G05B 19/423; G06F 19/00,"CARBON ROBOTICS, INC.","CORKUM, Daniel; MYERS, Rosanna","62/395,990 16.09.2016 US",
WO2018085778,PCT/US2017/060216,06.11.2017,WO/2018/085778,11.05.2018,WO,UNSUPERVISED DETECTION OF INTERMEDIATE REINFORCEMENT LEARNING GOALS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for detecting intermediate reinforcement learning goals. One of the methods includes obtaining a plurality of demonstration sequences, each of the demonstration sequences being a sequence of images of an environment while a respective instance of a reinforcement learning task is being performed; for each demonstration sequence, processing each image in the demonstration sequence through an image processing neural network to determine feature values for a respective set of features for the image; determining, from the demonstration sequences, a partitioning of the reinforcement learning task into a plurality of subtasks, wherein each image in each demonstration sequence is assigned to a respective subtask of the plurality of subtasks; and determining, from the feature values for the images in the demonstration sequences, a respective set of discriminative features for each of the plurality of subtasks.",G06N 3/04; G06N 3/00; G06N 3/08,GOOGLE LLC,"SERMANET, Pierre","62/418,122 04.11.2016 US",CN-201780074215.X; EP-2017801215
WO2018064591,PCT/US2017/054528,29.09.2017,WO/2018/064591,05.04.2018,WO,GENERATING VIDEO FRAMES USING NEURAL NETWORKS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating video frames using neural networks. One of the methods includes processing a sequence of video frames using an encoder neural network to generate an encoded representation; and generating a predicted next frame pixel by pixel according to a pixel order and a channel order, comprising: for each color channel of each pixel, providing as input to a decoder neural network (i) the encoded representation, (ii) color values for any pixels before the pixel in the pixel order, and (iii) color values for the pixel for any color channels before the color channel in the channel order, wherein the decoder neural network is configured to generate an output defining a score distribution over a plurality of possible color values, and determining the color value for the color channel of the pixel by sampling from the score distribution.",G06N 3/04,DEEPMIND TECHNOLOGIES LIMITED,"KALCHBRENNER, Nal Emmerich; VAN DEN OORD, Aaron Gerard Antonius; SIMONYAN, Karen","62/402,914 30.09.2016 US",CN-201780060788.7; EP-2017790889
EP251296541,18180852,29.06.2018,3534235,04.09.2019,EP,UNSUPERVISED LEARNING OF METRIC REPRESENTATIONS FROM SLOW FEATURES,,G05D 1/02,HONDA RES INSTITUTE EUROPE GMBH,FRANZIUS MATHIAS; METKA BENJAMIN; BAUER-WERSING UTE,18159286 28.02.2018 EP,
WO2019222860,PCT/CA2019/050713,24.05.2019,WO/2019/222860,28.11.2019,WO,"SYSTEM, METHOD AND/OR COMPUTER READABLE MEDIUM FOR GROWING PLANTS IN AN AUTONOMOUS GREEN HOUSE","According to the invention, there is disclosed a system, method and/or non-transient computer readable medium for growing plants in a facility autonomously. The system includes an irrigation subsystem associated with the plants, including: (i) one or more spray heads; (ii) a water tank comprising a volume of water; and (iii) a pump adapted to transfer the water to the one or more spray heads to irrigate the plants; Also included is a robotic gardener subsystem including: (i) a chassis; (ii) tools adapted to manipulate the plants; (iii) on-board sensors adapted to receive data associated with the plants; and (iv) a command processor operative to (1) collect and transmit the data associated with the plants and (2) controlling the tools and/or the irrigation subsystem. An AI control system is included having: (i) a server operative to (1) electronically receive the data associated with the plants; (2) apply one or more artificial intelligence algorithms to the data associated with the plants to generate machine learning data and pattern data; (3) generate instructions for the tools and/or the irrigation subsystem based on the machine learning data and pattern data; and (4) transmit the instructions to the command processor; and (ii) a database to electronically store the data associated with the plants, the instructions for the tools and/or the irrigation subsystem, the machine learning data and the pattern data. The system is operative to autonomously optimize the growth of the plants in the facility based on the instructions.",A01G 9/26; A01G 27/00; A01G 31/02; B25J 9/18; G05D 3/12; G06N 20/00,"GREENEARTH AUTOMATION INC.; DUFFUS, Eric Arthur; THOMSON, Justin Michael","DUFFUS, Eric Arthur; THOMSON, Justin Michael","62/676,668 25.05.2018 US",
WO2020046203,PCT/SG2019/050421,26.08.2019,WO/2020/046203,05.03.2020,WO,DEVICE AND METHOD FOR TRACKING HUMAN SUBJECTS,"The present disclosure relates to a device (100) and method (200) for tracking human subjects. The device (100) comprises a 3D depth tracker (120) for capturing 3D mapping data of a space containing the human subjects, constructing 3D representations of the space from the 3D mapping data, and generating a first track for each human subject in each 3D representation for tracking the human subject. The device (100) comprises a 2D laser tracker (140) for capturing 2D mapping data of the space, constructing 2D representations of the space from the 2D mapping data, and generating a second track for each human subject in each 2D representation for tracking the human subject. The device (100) comprises a track fusion module (160) for associating the respective first tracks with the respective second tracks for each human subject, and collaboratively tracking each human subject based on the respective associated first and second tracks.",G06T 7/20; G01S 17/88; G06K 9/46,"AGENCY FOR SCIENCE, TECHNOLOGY AND RESEARCH","LI, Jun; SAPUTRA, Vincensius Billy; ADIWAHONO, Albertus Hendrawan; YAU, Wei Yun",10201807263Q 27.08.2018 SG,
WO2019178702,PCT/CA2019/050362,25.03.2019,WO/2019/178702,26.09.2019,WO,SYSTEMS AND METHODS FOR POLYGON OBJECT ANNOTATION AND A METHOD OF TRAINING AN OBJECT ANNOTATION SYSTEM,"The present invention relates generally to object annotation, specifically to polygonal annotations of objects. Described are methods of annotating an object including steps of receiving an image depicting an object, generating a set of image features using a CNN encoder implemented on one or more computers, and producing a polygon object annotation via a recurrent decoder or a Graph Neural Network. The recurrent decoder may include a recurrent neural network, a graph neural network or a gated graph neural network. A system for annotating an object and a method of training an object annotation system are also described.",G06K 9/46; G06N 3/02; G06N 3/08; G06T 1/40; G06T 11/60; G06T 7/10,THE GOVERNING COUNCIL OF THE UNIVERSITY OF TORONTO,"FIDLER, Sanja; KAR, Amlan; LING, Huan; GAO, Jun; CHEN, Wenzheng; ACUNA MARRERO, David","62/646,934 23.03.2018 US; 62/783,251 21.12.2018 US",
WO2010056868,PCT/US2009/064214,12.11.2009,WO/2010/056868,20.05.2010,WO,SYSTEM AND METHOD FOR AUTOMATIC SPEACH TO TEXT CONVERSION,"Speech recognition is performed in near-real-time and improved by exploiting events and event sequences, employing machine learning techniques including boosted classifiers, ensembles, detectors and cascades and using perceptual clusters. Speech recognition is also improved using tandem processing. An automatic punctuator injects punctuation into recognized text streams.",G10L 15/16,"SCTI HOLDINGS, INC.; PINSON, Mark; PINSON, David, Sr.; FLANAGAN, Mary; MAKANVAND, Shahrokh","PINSON, Mark; PINSON, David, Sr.; FLANAGAN, Mary; MAKANVAND, Shahrokh","61/113,910 12.11.2008 US; 12/616,723 11.11.2009 US",IN-1940/KOLNP/2011; CN-200980148155.7; KR-1020117013340; JP-2011536467; EP-2009826754
WO2020046213,PCT/SG2019/050433,30.08.2019,WO/2020/046213,05.03.2020,WO,A METHOD AND APPARATUS FOR TRAINING A NEURAL NETWORK TO IDENTIFY CRACKS,"There is provided a method for training a neural network to identify cracks on a surface - e.g. of a building or construction - the method including the steps of: (a) training a neural network to detect a crack; and (b) refining the trained neural network using a direction of the crack. This method can employ a scene recognition deep CNN model (Scene-CNN), a crack detection deep CNN model (Crack-CNN), and Bayesian inference module for post filtering.",G06N 3/08; G06N 7/00; G06N 20/00; G06T 7/00,"AGENCY FOR SCIENCE, TECHNOLOGY AND RESEARCH","FANG, Fen; LI, Liyuan; LIM, Joo Hwee",10201807490P 31.08.2018 SG,
WO2020048721,PCT/EP2019/071308,08.08.2019,WO/2020/048721,12.03.2020,WO,SYSTEM AND METHOD FOR NATURAL LANGUAGE PROCESSING,"A natural language processing system configured for receiving an input sequence of input tokens representing a first sequence of words in a natural language of a first text and generating an output sequence of output tokens representing a second sequence of words in a natural language of a second text. The natural language processing system has at least one sequence-to-sequence (seq2seq) model and a policy gradient generator. The seq2seq model comprises an encoder, an attention module and a decoder. The encoder and the decoder each comprise a forward recurrent neural network RNN and a backward RNN, and the attention module is configured for applying weights to the encoded representations.",G06F 17/27; G06F 16/34,SIEMENS AKTIENGESELLSCHAFT,"KUMAR KARN, Sanjeev; KROMPASS, Denis; WALTINGER, Ulli",18192464.8 04.09.2018 EP,
WO2019213763,PCT/CA2019/050613,09.05.2019,WO/2019/213763,14.11.2019,WO,METHOD AND SYSTEM FOR VEHICLE-TO-PEDESTRIAN COLLISION AVOIDANCE,"A method and a system for vehicle-to-pedestrian collision avoidance system, the system comprising participants consisting of Long-Term Evolution (LTE)-capable user equipment (UE) terminals physically linked to at least one vehicle and at least one pedestrian; wherein a spatiotemporal positioning of the terminals is determined from Long Term Evolution (LTE) cellular radio signals mediated by Long-Term Evolution (LTE) cellular base stations (BS) and a Location Service Client (LCS) server including an embedded Artificial Intelligence algorithm comprising a Recurrent Neural Network (RNN) algorithm and analyzes the spatiotemporal positioning of the terminals and determines the likely future trajectory and communicates the likely future trajectory of the participants to the terminals physically linked to the pedestrian; the terminals physically linked to the pedestrian include an embedded Artificial Intelligence algorithm comprising a Conditional Random Fields (CRFs) algorithm to determine if the likely future trajectory of the pedestrian is below a vehicle-to-pedestrian proximity threshold limit and, if this condition is reached, communicates a collision-avoidance emergency signal to the at least one pedestrian and/or vehicle that meet the proximity threshold limit.",G08G 1/16; G06N 3/02; H04W 4/40; H04W 64/00,"BEAUCHAMP, Bastien","BEAUCHAMP, Bastien","62/669,437 10.05.2018 US; 62/792,950 16.01.2019 US",DE-112019000057
WO2018170175,PCT/US2018/022504,14.03.2018,WO/2018/170175,20.09.2018,WO,PROBABILITY-BASED GUIDER,"The technology disclosed proposes using a combination of computationally cheap, less-accurate bag of words (BoW) model and computationally expensive, more-accurate long short-term memory (LSTM) model to perform natural processing tasks such as sentiment analysis. The use of cheap, less-accurate BoW model is referred to herein as ""skimming"". The use of expensive, more-accurate LSTM model is referred to herein as ""reading"". The technology disclosed presents a probability-based guider (PBG). PBG combines the use of BoW model and the LSTM model. PBG uses a probability thresholding strategy to determine, based on the results of the BoW model, whether to invoke the LSTM model for reliably classifying a sentence as positive or negative. The technology disclosed also presents a deep neural network-based decision network (DDN) that is trained to learn the relationship between the BoW model and the LSTM model and to invoke only one of the two models.",G06N 3/04,"SALESFORCE.COM, INC.","JOHANSEN, Alexander Rosenberg; MCCANN, Bryan; BRADBURY, James; SOCHER, Richard","62/471,934 15.03.2017 US; 15/853,530 22.12.2017 US",JP-2019550612; CA-3052212; CN-201880018349.4
EP238737727,18194720,08.02.2006,3451296,06.03.2019,EP,MULTIDIMENSIONAL EVIDENCE GRIDS AND SYSTEM AND METHODS FOR APPLYING SAME,"According to an aspect, a method of auto-navigating a robotic vehicle through an environment is provided. The robotic vehicle may comprise at least one stereo camera having two cameras. The method may comprise building and/or updating a three-dimensional evidence grid of the environment, the evidence grid comprising a three-dimensional pattern of voxels representing points in space containing occupancy information. The building/updating may include navigating the robotic vehicle through the environment to collect a plurality of stereo images comprising stereo image data using the at least one stereo camera. The building/updating may further include applying a sensor model to the stereo image data to remove noise introduced by the at least one stereo camera. The building/updating may further include processing the stereo image data to determine the presence of objects, parts of objects or features within the field of view of the at least one stereo camera, including analyzing pixels of the stereo image data and determining probabilities of occupancy of the points in space within the field of view of the at least one stereo cameras as voxel volumes associated with the voxels representing the points in space. The method may further include building and/or updating the evidence grid based on the voxel volumes, discarding the stereo images, and auto-navigating the robotic vehicle through the environment using the built and/or updated evidence grid.",G06T 17/00; G05D 1/02,SEEGRID CORP,MORAVEC HANS,06734625 08.02.2006 EP; 2006004516 08.02.2006 US; 65090405 08.02.2005 US,
WO2018112613,PCT/CA2017/051533,19.12.2017,WO/2018/112613,28.06.2018,WO,SYSTEM AND METHOD FOR CONTACTLESS BLOOD PRESSURE DETERMINATION,"A system and method for contactless blood pressure determination. The method includes: receiving a captured image sequence; determining, using a trained hemoglobin concentration (HC) changes machine learning model, bit values from a set of bitplanes in the captured image sequence that represent the HC changes of the subject; determining a blood flow data signal; extracting one or more domain knowledge signals associated with the determination of blood pressure; building a trained blood pressure machine learning model with a blood pressure training set, the blood pressure training set including the blood flow data signal of the one or more predetermined ROIs and the one or more domain knowledge signals; determining, using the blood pressure machine learning model trained with a blood pressure training set, an estimation of blood pressure; and outputting the determination of blood pressure.",A61B 5/021; A61B 5/026; A61B 5/145; G06F 15/18; G06F 19/00; G16H 50/20,NURALOGIX CORPORATION,"LEE, Kang; KABAKOV, Evgueni; LEVY, Phil","62/435,942 19.12.2016 US",EP-2017883981; CN-201780083795.9; CA-3047452
WO2019104133,PCT/US2018/062196,21.11.2018,WO/2019/104133,31.05.2019,WO,MAP-BASED FRAMEWORK FOR THE INTEGRATION OF ROBOTS AND SMART DEVICES,"A central controller for robotics and connected devices includes a first communication interface configured to receive data from a plurality of robots or connected devices, at least some of which plurality of robots or connected devices are of different types. The data generated by robots or connected devices of different types are generated in different native data formats. The central controller also includes a processor configured to translate said received data from the different native data formats into a common protocol format, a storage framework configured to store the data translated into the common protocol format; and a second communication interface configured to transmit commands based on data stored in the common protocol format and translated to the native data format of one or more of the plurality of robots or connected devices.",B25J 9/10; B25J 9/16; G01N 35/00; G05B 19/04; G05B 19/418; G06F 19/00,"SERVICE ROBOTICS & TECHNOLOGIES, INC.","SCOTT, Gregory P.; PERSHELL, Karoline P.","62/589,089 21.11.2017 US",
EP11010616,07122829,11.12.2007,2071515,17.06.2009,EP,Visually tracking an object in real world using 2D appearance and multicue depth estimations,"The invention relates to a method for the estimation of the dynamic state of a real-world object over time using a camera system, 2D image information and a combination of different measurements of the object's distance from the camera. The 2D image information is used to track an object's 2D position as well as its 2D size and 2D size change using its appearance. In addition, an object's distance from the camera is gained from one or several direct depth measurements. The 2D position and size, and the object's depth are coupled with each other to get an improved estimation of an object's 3D position and 3D velocity, and so get an improved real-world object tracking system, which can be used on a moving platform like a robot or a car with mounted cameras for a dynamic visual scene analysis.",G06T 7/20,HONDA RES INST EUROPE GMBH,EGGERT JULIAN DR; REBHAN SVEN; WILLERT VOLKER DR; ZHANG CHEN,07122829 11.12.2007 EP,
WO2007070812,PCT/US2006/061960,12.12.2006,WO/2007/070812,21.06.2007,WO,ROBOTICS PROGRAMMING INTERFACE,"A programming interface for a hardware system includes an embedded layer for programmatic access to a physical realization of hardware (216), a simulation system for simulation of the hardware (206), and a diagnostics engine (208) that analyzes and compares feedback data from the simulation system (206) and the physical realization. The programming interface may be usefully employed, for example, in the design, purchase, and deployment of robotics for semiconductor manufacturing.",G05B 11/01; G06F 19/00,"BLUESHIFT TECHNOLOGIES, INC.; PANESSE, Patrick","PANESSE, Patrick","11/302,563 13.12.2005 US",DE-null
EP14549501,05405685,02.12.2005,1667049,07.06.2006,EP,Facial feature analysis system,"The disclosed system includes a virtual filter bank and a virtual discriminator. The virtual filter bank comprises a feature localization main module (4) having an ancillary data bank (43) which supplies a special signal Sg for different control functions. The system is provided for calculating a face localization (3) based on the parameters of a holistic face model, for calculating a feature localization (4) based on the parameters of a general face graph, for calculating a feature extraction (5) by using stored feature values corresponding to a selected validation and for calculating out-put-signals by using a signal module (6) controlled by static and dynamic classification means. The virtual discriminator bank is intended for calculating a user adapted allocation (7) in accordance with a face feature of the user and for calculating a periphery allocation (8) in accordance with at least one command modus. The system may also be employed for calculating execution signals for at least one manipulator. The present invention may be used, for example, for door surveillance functions, alarm systems in private houses or in factories, to prevent accidents in manufacture and vehicles or for a robotic wheelchair system for impaired people.",G06K 9/00; A61F 4/00,INVACARE INT SARL,CANZLER ULRICH; KRAISS KARL-FRIEDRICH,102004059482 03.12.2004 DE; 72542705 11.10.2005 US; 72554005 11.10.2005 US,
WO2018067603,PCT/US2017/054987,03.10.2017,WO/2018/067603,12.04.2018,WO,EFFICIENT DATA LAYOUTS FOR CONVOLUTIONAL NEURAL NETWORKS,"Systems and methods for efficient implementation of a convolutional layer of a convolutional neural network are disclosed. In one aspect, weight values of kernels in a kernel stack of a convolutional layer can be reordered into a tile layout with tiles of runnels. Pixel values of input activation maps of the convolutional layer can be reordered into an interleaved layout comprising a plurality of clusters of input activation map pixels. The output activation maps can be determined using the clusters of the input activation map pixels and kernels tile by tile.",G06K 9/00; G06K 9/38; G06N 3/08; G06N 99/00; G06T 7/00,"MAGIC LEAP, INC.","ALIABADI, Ashkan; ROBERTS, Gregory, David","62/403,930 04.10.2016 US",CA-3038967; KR-1020197012230; JP-2019517768; CN-201780073892.X; EP-2017859043; IL-265720
WO2019122271,PCT/EP2018/086442,20.12.2018,WO/2019/122271,27.06.2019,WO,AUTHENTICATION MACHINE LEARNING FROM MULTIPLE DIGITAL REPRESENTATIONS,"A machine learning system may automatically produce classifier algorithms and configuration parameters by selecting them into a set of predetermined unitary algorithms and associated parametrization values. Multiple digital representations of input object items may be produced by varying the position and orientation of the object to be classified and/or of the sensor to capture a digital representation of the object, and/or by varying a physical environment parameter which changes the digital representation capture of the object by the sensor. A robot arm or a conveyor may vary the object and/or the sensor positions and orientations. The machine learning system may employ genetic programming to facilitate the production of classifiers suitable for the classification of multiple digital representations of input object items. The machine learning system may automatically generate reference template signals as configuration parameters for the unitary algorithms to facilitate the production of classifiers suitable for the classification of multiple digital representations of input object items.",G06K 9/62,ALPVISION S.A.,"JORDAN, Frederic; RUDAZ, Nicolas; DELACRETAZ, Yves; KUTTER, Martin","62/608,352 20.12.2017 US",
WO2019178253,PCT/US2019/022086,13.03.2019,WO/2019/178253,19.09.2019,WO,IMAGE-ENHANCED DEPTH SENSING USING MACHINE LEARNING,"Systems and methods are disclosed for training and using neural networks for computing depth maps based on a single image. One method Systems and methods are disclosed for training and using neural networks for computing depth maps. One method for training the neural network includes providing an image input to the neural network. The image input may include a camera image of a training scene. The method may also include providing a depth input to the neural network. The depth input may be based on a high-density depth map of the training scene and a sampling mask. The method may further include generating, using the neural network, a computed depth map of the training scene based on the image input and the depth input. The method may further include modifying the neural network based on an error between the computed depth map and the high-density depth map.",G06N 3/08; G06N 3/02; G06N 3/063; G06T 7/50; G06T 7/70; G01S 17/06; G01S 17/42,"MAGIC LEAP, INC.","BADRINARAYANAN, Vijay; CHEN, Zhao; RABINOVICH, Andrew","62/642,528 13.03.2018 US",
WO2018209094,PCT/US2018/032076,10.05.2018,WO/2018/209094,15.11.2018,WO,"METHOD FOR IDENTIFYING, ORDERING, AND PRESENTING IMAGES ACCORDING TO EXPRESSIONS","Embodiments are directed to digital image processing, storage, retrieval, and presentation systems and methods for ordering and ranking visually perceivable facial expressions identified within the selected set of digital images. In addition, arranging for presentation the ordered and ranked set of digital images in response to a user-selection of an emotional expression or range of emotional expressions and presenting the selected arranged set of digital images on a display device.",G06K 9/00,KODAK ALARIS INC.,"MITTELSTAEDT, Brian E.; MANICO, Joseph","62/504,932 11.05.2017 US",CN-201880031121.9; EP-2018732973
WO2020032947,PCT/US2018/045902,09.08.2018,WO/2020/032947,13.02.2020,WO,MANUFACTURING PROCESS CONTROL USING CONSTRAINED REINFORCEMENT MACHINE LEARNING,"For manufacturing process control, closed-loop control is provided (18) based on a constrained reinforcement learned network (32). The reinforcement is constrained (22) to account for the manufacturing application. The constraints may be for an amount of change, limits, or other factors reflecting capabilities of the controlled device and/or safety.",G06N 3/02; G06N 3/08,SIEMENS AKTIENGESELLSCHAFT; SIEMENS CORPORATION,"FAHRENKOPF, Max; WEN, Chengtao; APARICIO OJEA, Juan, L.",,
WO2018156891,PCT/US2018/019416,23.02.2018,WO/2018/156891,30.08.2018,WO,TRAINING POLICY NEURAL NETWORKS USING PATH CONSISTENCY LEARNING,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for training a policy neural network used to select actions to be performed by a reinforcement learning agent interacting with an environment. In one aspect, a method includes obtaining path data defining a path through the environment traversed by the agent. A consistency error is determined for the path from a combined reward, first and last soft-max state values, and a path likelihood. A value update for the current values of the policy neural network parameters is determined from at least the consistency error. The value update is used to adjust the current values of the policy neural network parameters.",G06N 3/04; G06N 3/08; G06N 3/00,GOOGLE LLC,"NACHUM, Ofir; NOROUZI, Mohammad; SCHUURMANS, Dale Eric; XU, Kelvin","62/463,562 24.02.2017 US",CN-201880013779.7; EP-2018710220
EP82196144,11816334,02.08.2011,2605153,19.06.2013,EP,"INFORMATION PROCESSING DEVICE, METHOD OF PROCESSING INFORMATION, AND PROGRAM","The present invention relates to an information processing device, an information processing method, and a program capable of easily adding an annotation to content and providing an application, which utilizes the annotation.  A learning device 312 extracts an image feature amount of each frame of an image of learning content and extracts word frequency information regarding a frequency of appearance of each word in a description text describing a content of the image of the learning content as a text feature amount of the description text, and learns an annotation model, which is a multi-stream HMM, by using a multi-stream including the image feature amount and the text feature amount. A browsing control device 314 extracts a scene, which is a group of one or more temporally continuous frames, from target content by using the annotation model and displays representative images of the scenes so as to be arranged in chronological order. The present invention may be applied to a case of adding the annotation to the content, for example.",G06K 9/00; G06N 3/00; H04N 9/87,SONY CORP,SUZUKI HIROTAKA; ITO MASATO,2010180175 11.08.2010 JP; 2011067692 02.08.2011 JP,
WO2018165038,PCT/US2018/020948,05.03.2018,WO/2018/165038,13.09.2018,WO,AUGMENTED REALITY-ENHANCED FOOD PREPARATION SYSTEM AND RELATED METHODS,"A food preparation system is configured to enhance the efficiency of food preparation operations in a commercial kitchen by displaying instructions on a surface in the kitchen work area. The food preparation system includes a plurality of cameras aimed at a kitchen workspace for preparing the plurality of food items and a processor operable to compute an instruction for a kitchen worker to perform a food preparation step based on one or more types of information selected from order information, recipe information, kitchen equipment information, data from the cameras, and food item inventory information. A projector in communication with the processor visually projects the instruction onto a location in the kitchen workspace for the kitchen worker to observe. Related methods for projecting food preparation instructions are described.",G06F 17/30; G06T 7/00,"MISO ROBOTICS, INC.","OLSON, Sean; ZITO, David; SINNET, Ryan, W.; ANDERSON, Robert; PELLETIER, Benjamin; STAFFORD, Grant; VINEGAR, Zachary, Zweig; WERST, William","62/467,735 06.03.2017 US; 62/592,130 29.11.2017 US; 62/467,743 06.03.2017 US",
EP232831978,18170151,30.04.2018,3399418,07.11.2018,EP,FINE-GRAIN COMPUTE COMMUNICATION EXECUTION FOR DEEP LEARNING FRAMEWORKS,"One embodiment provides for a system to configure distributed training of a neural network. The system includes memory to store a library to facilitate transmission of data during distributed training of the neural network; a network interface to transmit and receive gradient data associated with the trainable parameters; a general-purpose processor to execute instructions provided by the library, the instructions to cause the general-purpose processor to configure the network interface to transmit and receive the gradient data associated with the trainable parameters during a workflow of a machine learning framework; and a graphics processor to perform compute operations associated with machine learning framework workflow to generate the gradient data associated with the trainable parameters, wherein, based on the machine learning framework workflow, the library is to interleave the compute operations on the graphics processor with transmission and receipt of gradient data via the network interface.",G06F 9/54; G06N 3/063,INTEL CORP,SRIDHARAN SRINIVAS; MUDIGERE DHEEVATSA,201762502453 05.05.2017 US; 201815869502 12.01.2018 US,
WO2017199233,PCT/IL2017/050378,27.03.2017,WO/2017/199233,23.11.2017,WO,ANOMALY DETECTION USING SPIKING NEURAL NETWORKS,"A method, system and computer program product, for identifying anomalies in a monitored scene, the method comprising: receiving into a spiking neural network sensor readings from a capture device monitoring a scene; and outputting an indication to a change in the scene, wherein the spiking neural network comprises a multiplicity of layers, each of the multiplicity of layers comprising a neuron per substantially each pixel in a sensor capturing the monitored scene, and wherein one or more of the layers comprises a memory-like unit for comparing states occurring at a time difference.",G06N 3/04; G06N 3/08,AGT INTERNATIONAL GMBH; REINHOLD COHN AND PARTNERS,"DEBES, Christian; DEISEROTH, Bjorn","15/156,526 17.05.2016 US",
WO2019046790,PCT/US2018/049213,31.08.2018,WO/2019/046790,07.03.2019,WO,DEVICE LOCATION BASED ON MACHINE LEARNING CLASSIFICATIONS,"A venue system of a client device can submit a location request to a server, which returns multiple venues that are near the client device. The client device can use one or more machine learning schemes (e.g., convolutional neural networks) to determine that the client device is located in one of specific venues of the possible venues. The venue system can further select imagery for presentation based on the venue selection. The presentation may be published as ephemeral message on a network platform.",H04W 4/33; G06K 9/00; G06K 9/62; G06T 11/60; H04L 12/58; H04W 88/02,SNAP INC.,"CHARLTON, Ebony James; HANUMANTE, Sumant Milind; REN, Zhou; SAGAR, Dhritiman","15/692,990 31.08.2017 US; 15/967,201 30.04.2018 US",
WO2018224471,PCT/EP2018/064703,05.06.2018,WO/2018/224471,13.12.2018,WO,SELECTING ACTIONS USING MULTI-MODAL INPUTS,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for selecting actions to be performed by an agent interacting with an environment. In one aspect, a system includes a language encoder model that is configured to receive a text string in a particular natural language, and process the text string to generate a text embedding of the text string. The system includes an observation encoder neural network that is configured to receive an observation characterizing a state of the environment, and process the observation to generate an observation embedding of the observation. The system includes a subsystem that is configured to obtain a current text embedding of a current text string and a current observation embedding of a current observation. The subsystem is configured to select an action to be performed by the agent in response to the current observation.",G06N 3/00; G06N 3/04; G06N 3/08; G06F 17/27,DEEPMIND TECHNOLOGIES LIMITED,"HERMANN, Karl Moritz; BLUNSOM, Philip; HILL, Felix George","62/515,458 05.06.2017 US",EP-2018729406; CN-201880026852.4
WO2011161304,PCT/FI2011/050414,05.05.2011,WO/2011/161304,29.12.2011,WO,METHOD FOR THE SELECTION OF PHYSICAL OBJECTS IN A ROBOT SYSTEM,"The invention relates to a method in which an apparatus receives first sensor data from first sensors and determines a target position from the data, the target position may be a position in space or an orientation of a gripper in a robot arm First instructions are issued to the robot arm or the gripper in order to move a gripper to the target position. Force feedback sensor data is received from force feedback sensors associated with either the robot arm or the gripper or from the first sensors. A failure in carrying out the first instructions is determined. Second sensor data is received from the at least one first sensor. Successful gripping of an object is determined from the second sensor data. Verification sensor data is received from at least one second sensor, in response to the determining of the successful gripping, second instructions are issued to the robot arm in order to move the arm to a predetermined position to release the grip of the gripper.",B25J 13/08; B25J 19/02; B25J 9/10; B25J 9/16; B07C 5/36; B65G 47/90; B65F 5/00; G21C 19/32,"ZENROBOTICS OY; VALPOLA, Harri; LUKKA, Tuomas","VALPOLA, Harri; LUKKA, Tuomas",20105732 24.06.2010 FI,CN-201180031364.0; JP-2013515935; RU-2013102960; US-13806426; EP-2011797656
WO2020056380,PCT/US2019/051183,13.09.2019,WO/2020/056380,19.03.2020,WO,LOCATING AND ATTACHING INTERCHANGEABLE TOOLS IN-SITU,"Current technologies allow a robot to acquire a tool only if the tool is in a set known location, such as in a rack. In an embodiment, a method and corresponding system, can determine the previously unknown pose of a tool freely placed in an environment. The method can then calculate a trajectory that allows for a robot to move from its current position to the tool and attach with the tool. In such a way, tools can be located and used by a robot when placed at any location in an environment.",B25J 9/16; B25J 11/00,"THE CHARLES STARK DRAPER LABORATORY, INC.; TAYOUN, Anthony","TAYOUN, Anthony; JOHNSON, David M.S.; WAGNER, Syler; ROONEY, Justin; LINES, Steven","62/731,398 14.09.2018 US; 62/730,934 13.09.2018 US; 62/730,933 13.09.2018 US; 62/730,703 13.09.2018 US; 62/730,947 13.09.2018 US; 62/730,918 13.09.2018 US",
WO2018211140,PCT/EP2018/063281,22.05.2018,WO/2018/211140,22.11.2018,WO,DATA EFFICIENT IMITATION OF DIVERSE BEHAVIORS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a neural network used to select actions to be performed by an agent interacting with an environment. One of the methods includes: obtaining data identifying a set of trajectories, each trajectory comprising a set of observations characterizing a set of states of the environment and corresponding actions performed by another agent in response to the states; obtaining data identifying an encoder that maps the observations onto embeddings for use in determining a set of imitation trajectories; determining, for each trajectory, a corresponding embedding by applying the encoder to the trajectory; determining a set of imitation trajectories by applying a policy defined by the neural network to the embedding for each trajectory; and adjusting parameters of the neural network based on the set of trajectories, the set of imitation trajectories and the embeddings.",G06N 3/04; G06N 3/08; G06N 3/00,DEEPMIND TECHNOLOGIES LIMITED,"WAYNE, Gregory Duncan; MEREL, Joshua; WANG, Ziyu; HEESS, Nicolas Manfred Otto; FREITAS, Joao Ferdinando; REED, Scott Ellison","62/508,972 19.05.2017 US",EP-2018726145; CN-201880027559.X
WO2018214084,PCT/CN2017/085817,25.05.2017,WO/2018/214084,29.11.2018,WO,"METHOD AND APPARATUS FOR REPRESENTING ENVIRONMENTAL ELEMENTS, SYSTEM, AND VEHICLE/ROBOT","There is provided with a computer-implemented method for representing environmental elements, comprising: receiving (101) scan data comprising at least a point cloud representing at least an environmental element from a sensor; segmenting (102) the point cloud into point clusters; partitioning (103) the point clusters into hierarchical grids; establishing (104) a Gaussian distribution for points in each cell of each of the hierarchical grids; and constructing (105) a Gaussian Mixture Model based on the Gaussian distribution for representing the environmental element. There are also provided with an apparatus for representing environmental elements, a system and a vehicle/robot.",G06T 7/00,"BAYERISCHE MOTOREN WERKE AKTIENGESELLSCHAFT; DOEMLING, Maximilian; JIANG, Wanli; LI, Qianshan; XU, Hongshan; GRANZOW, Sebastian; XU, Tao; LI, Jianpeng; LV, Shuhan","DOEMLING, Maximilian; JIANG, Wanli; LI, Qianshan; XU, Hongshan; GRANZOW, Sebastian; XU, Tao; LI, Jianpeng; LV, Shuhan",,EP-2017910943; CN-201780091068.7
WO2019147939,PCT/US2019/015154,25.01.2019,WO/2019/147939,01.08.2019,WO,DETECTION OF HAZARDOUS DRIVING USING MACHINE LEARNING,"An autonomous driving system could create or exacerbate a hazardous driving situation due to incorrect machine learning, algorithm design, sensor limitations, environmental conditions or other factors. This technology presents solutions that use machine learning to detect when the autonomous driving system is in this state e.g., erratic or reckless driving and other behavior, in order to take remedial action to prevent a hazard such as a collision.",G06N 3/04; G06N 20/00; G06K 9/00,NVIDIA CORPORATION,"SHIRVANI, Philip; BRAMLEY, Richard; MONTRYM, John; SAXENA, Nirmal","62/622,538 26.01.2018 US",
WO2020027852,PCT/US2018/045162,03.08.2018,WO/2020/027852,06.02.2020,WO,NEURAL LOGIC CONTROLLERS,A method for executing a machine learning model with a controller includes a processor within the controller writing input values to a process image within the controller. The term process image refers to a predefined address space within volatile memory of the controller. A co-processor connected to the controller reads the input values from the process image and applies a machine learning model to the input values to generate output values. The co-processor writes output values to the process image and the processor reads those output values from the process image. The process can then execute an application program that utilizes the one or more output values.,G06N 3/10; G06N 3/063; G06F 9/54,SIEMENS AKTIENGESELLSCHAFT; SIEMENS CORPORATION,"MARTINEZ CANEDO, Arquimedes; BANK, Hasan Sinan; LUDWIG, Hartmut",,
WO2005057474,PCT/GB2004/005187,13.12.2004,WO/2005/057474,23.06.2005,WO,VISUAL OBJECT RECOGNITION SYSTEM,"A method and apparatus for automatic object or speech recognition, for example, which uses an algorithm for the unsupervised training of hierarchical feedforward neural networks to perform transform invariant visual object recognition, referred to herein as ‘continuous transformation (CT) learning’. This mechanism is based on continuous synaptic enhancement of the feedforward inter-layer connection weights using an associative (such as Hebbian) learning rule during continuous transformation (e.g. translation, rotation, etc) of the (e.g. visual) stimulus.",G06K 9/66,"ISIS INNOVATION LIMITED; STRINGER, Simon; ROLLS, Edmund; PERRY, Gavin","STRINGER, Simon; ROLLS, Edmund; PERRY, Gavin",0328830.5 12.12.2003 GB,
WO2018085749,PCT/US2017/060103,06.11.2017,WO/2018/085749,11.05.2018,WO,SYSTEM AND METHOD FOR LEARNING RANDOM-WALK LABEL PROPAGATION FOR WEAKLY-SUPERVISED SEMANTIC SEGMENTATION,"Systems and methods for training semantic segmentation. Embodiments of the present invention include predicting semantic labeling of each pixel in each of at least one training image using a semantic segmentation model. Further included is predicting semantic boundaries at boundary pixels of objects in the at least one training image using a semantic boundary model concurrently with predicting the semantic labeling. Also included is propagating sparse labels to every pixel in the at least one training image using the predicted semantic boundaries. Additionally, the embodiments include optimizing a loss function according the predicted semantic labeling and the propagated sparse labels to concurrently train the semantic segmentation model and the semantic boundary model to accurately and efficiently generate a learned semantic segmentation model from sparsely annotated training images.",G06N 3/08; G06N 3/04,"NEC LABORATORIES AMERICA, INC","VERNAZA, Paul; CHANDRAKER, Manmohan","62/418,420 07.11.2016 US; 62/421,422 14.11.2016 US; 15/801,688 02.11.2017 US",
WO2013074093,PCT/US2011/060884,15.11.2011,WO/2013/074093,23.05.2013,WO,MODELING PASSAGE OF A TOOL THROUGH A WELL,"In modeling passage of an elongate well tool through an interval of a well an adaptive machine learning model executed on a computing system receives a first set of inputs representing a plurality of characteristics of the well tool and a second set of inputs representing a plurality of characteristics of the well. The adaptive machine learning model also receives historical data representing a plurality of other well tools passed through a plurality of other wells and a plurality of characteristics of the other well tools and the other wells. The adaptive machine learning model matches the historical data with at least a portion of the first and second sets of inputs, and determines, based on the matching whether the well tool can pass through the interval of the well.",E21B 44/00; G06F 19/00,"FOX, Philip Edmund; KENNEDY, Ronnie; GARY, Ben; RUBIN, Heru; TRAN, Dominic Anh; WOOD, Josiah","FOX, Philip Edmund; KENNEDY, Ronnie; GARY, Ben; RUBIN, Heru; TRAN, Dominic Anh; WOOD, Josiah",,
WO2019156287,PCT/KR2018/005471,14.05.2018,WO/2019/156287,15.08.2019,WO,PROGRESSIVE COMPRESSED DOMAIN COMPUTER VISION AND DEEP LEARNING SYSTEMS,"Methods and systems for compressed domain progressive application of computer vision techniques. A method for decoding video data includes receiving a video stream that is encoded for multi-stage decoding. The method includes partially decoding the video stream by performing one or more stages of the multi-stage decoding. The method includes determining whether a decision for a computer vision system can be identified based on the partially decoded video stream. Additionally, the method includes generating the decision for the computer vision system based on decoding of the video stream. A system for encoding video data includes a processor configured to receive the video data from a camera, encode the video data received from the camera into a video stream for consumption by a computer vision system, and include metadata with the encoded video stream to indicate whether a decision for the computer vision system can be identified from the metadata.",H04N 21/4402; H04N 21/235; H04N 19/167; G06N 3/08; G06N 99/00,"SAMSUNG ELECTRONICS CO., LTD.","SHEIKH, Hamid R.; LIU, David; LUO, Chenchi; YOO, Youngjun; POLLEY, Michael","15/892,141 08.02.2018 US",
WO2019219965,PCT/EP2019/062936,20.05.2019,WO/2019/219965,21.11.2019,WO,META-GRADIENT UPDATES FOR TRAINING RETURN FUNCTIONS FOR REINFORCEMENT LEARNING SYSTEMS,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for reinforcement learning. The embodiments described herein apply meta-learning (and in particular, meta-gradient reinforcement learning) to learn an optimum return function G so that the training of the system is improved. This provides a more effective and efficient means of training a reinforcement learning system as the system is able to converge on an optimum set of one or more policy parameters θ more quickly by training the return function G as it goes. In particular, the return function G is made dependent on the one or more policy parameters θ and a meta-objective function J' is used that is differentiated with respect to the one or more return parameters η to improve the training of the return function G.",G06N 3/00; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"XU, Zhongwen; HASSELT, Hado Philip; SILVER, David","62/673,844 18.05.2018 US",
WO2020039247,PCT/IB2019/000353,08.01.2019,WO/2020/039247,27.02.2020,WO,AUTOMATICALLY DETERMINING LANGUAGE FOR SPEECH RECOGNITION OF SPOKEN UTTERANCE RECEIVED VIA AN AUTOMATED ASSISTANT INTERFACE,"Implementations relate to determining a language for speech recognition of a spoken utterance, received via an automated assistant interface, for interacting with an automated assistant. In various implementations, audio data indicative of a voice input that includes a natural language request from a user may be applied as input across multiple speech-to-text (""STT"") machine learning models to generate multiple candidate speech recognition outputs. Each STT machine learning model may trained in a particular language. For each respective STT machine learning model of the multiple STT models, the multiple candidate speech recognition outputs may be analyzed to determine an entropy score for the respective STT machine learning model. Based on the entropy scores, a target language associated with at least one STT machine learning model of the multiple STT machine learning models may be selected. The automated assistant may respond to the request using the target language.",G10L 15/00; G10L 15/32,GOOGLE LLC,"MORENO, Ignacio Lopez; LOPATOVSKY, Lukas; WEISZ, Ágoston","62/721,982 23.08.2018 US",EP-2019732435
WO2015066618,PCT/US2014/063699,03.11.2014,WO/2015/066618,07.05.2015,WO,CONTEXT BASED ALGORITHMIC FRAMEWORK FOR IDENTIFYING AND CLASSIFYING EMBEDDED IMAGES OF FOLLICLE UNITS,"The subject invention provides a method for detecting and analyzing the hair follicles on a scalp to assist with hair follicle transplantation. The methods of the subject invention are able to count the number of hair follicle groups and the number of follicles within each group based upon a microscopic image of a sample from a human scalp. An algorithm is then used to cluster the follicles and generate a neighboring connected graph to calculate the inter object distances. A report can then be generated that provides information regarding the density, placement, and percentage of hair follicle type in different areas of the scalp. This report can be used to generate a hair follicle transplant strategy to assist a physician or robotic system.",G06T 7/00,"THE FLORIDA INTERNATIONAL UNIVERSITY BOARD OF TRUSTEES; NRG MEDICAL, LLC","RAHMAN, MD Mahbubur; IYENGAR, S.S.; ZENG, Wei; HERNANDEZ, Frank; NUSBAUM, Bernard; ROSE, Paul","61/898,836 01.11.2013 US",US-15033778
WO2019018022,PCT/US2018/026951,10.04.2018,WO/2019/018022,24.01.2019,WO,ZERO SHOT MACHINE VISION SYSTEM VIA JOINT SPARSE REPRESENTATIONS,Described is a system that can recognize novel objects that the system has never before seen. The system uses a training image set to learn a model that maps visual features from known images to semantic attributes. The learned model is used to map visual features of an unseen input image to semantic attributes. The unseen input image is classified as belonging to an image class with a class label. A device is controlled based on the class label.,G06K 9/00; G06K 9/72; G06N 3/08; B60R 21/0134,"HRL LABORATORIES, LLC","KOLOURI, Soheil; RAO, Shankar, R.; KIM, Kyungnam","62/502,461 05.05.2017 US",EP-2018836170; CN-201880022737.X
WO2018119606,PCT/CN2016/112193,26.12.2016,WO/2018/119606,05.07.2018,WO,METHOD AND APPARATUS FOR REPRESENTING A MAP ELEMENT AND METHOD AND APPARATUS FOR LOCATING VEHICLE/ROBOT,"A method and an apparatus for representing a map element and a method and an apparatus for locating a vehicle/robot based thereupon. The method for representing a map element comprises: conducting process to each frame of data obtained in the moving of vehicle/robot, comprising: generating a Gaussian Mixture Model for each map element included in the data (110); generating a signature for identifying each map element, wherein the signature comprises properties of the map element (120); and generating a Signatured Gaussian Mixture Model for each map element included in the data, wherein the Signatured Gaussian Mixture Model for each map element comprises the Gaussian Mixture Model for the map element, the signature and an existence probability of the map element (130); conducting process to two frames of the data related to each other, to obtain processed map elements (140). The method provides a novel technology for representing optimized map elements as well as an improved vehicle/robot localization technology based thereupon.",G06T 7/20,"BAYERISCHE MOTOREN WERKE AKTIENGESELLSCHAFT; DOEMLING, Maximilian; JIANG, Wanli; LI, Qiangshan; LI, Jianpeng; GRANZOW, Sebastian; XU, Tao; XU, Hongshan; LV, Shuhan","DOEMLING, Maximilian; JIANG, Wanli; LI, Qiangshan; LI, Jianpeng; GRANZOW, Sebastian; XU, Tao; XU, Hongshan; LV, Shuhan",,CN-201680091934.8
WO2020023731,PCT/US2019/043408,25.07.2019,WO/2020/023731,30.01.2020,WO,SAFE TRAVERSABLE AREA ESTIMATION IN UNSTRUCTURE FREE-SPACE USING DEEP CONVOLUTIONAL NEURAL NETWORK,"Techniques described in this application are directed to determining safe path navigation of an unmanned vehicle, including a sidewalk robot, using LIDAR sensors and/or other data.",B25J 9/16; G05D 1/02; G06Q 10/08; G05D 1/00,POSTMATES INC.,"GUO, Zhenyu; YUAN, Kaiwen; HAGHIGHAT KASHANI, Ali; LEHMANN, Bastian Jan Michael; PLAICE, Sean Tracey","62/703,852 26.07.2018 US",
WO2011025662,PCT/US2010/045229,11.08.2010,WO/2011/025662,03.03.2011,WO,DETECTING ANOMALOUS TRAJECTORIES IN A VIDEO SURVEILLANCE SYSTEM,"Techniques are disclosed for determining anomalous trajectories of objects tracked over a sequence of video frames. In one embodiment, a symbol trajectory may be derived from observing an object moving through a scene. The symbol trajectory represents semantic concepts extracted from the trajectory of the object. Whether the symbol trajectory is anomalous may be determined, based on previously observed symbol trajectories. A user may be alerted upon determining that the symbol trajectory is anomalous.",G06T 1/00; G06T 7/00; G06F 17/00,"BEHAVIORAL RECOGNITION SYSTEMS, INC.; COBB, Wesley Kenneth; SEOW, Ming-Jung; XU, Gang","COBB, Wesley Kenneth; SEOW, Ming-Jung; XU, Gang","12/551,395 31.08.2009 US",EP-2010812486
EP14103960,02730881,03.06.2002,1406135,07.04.2004,EP,MAN-MACHINE INTERFACE UNIT CONTROL METHOD; ROBOT APPARATUS; AND ITS ACTION CONTROL METHOD,A general−purpose method controlling a man−machine interface unit&period; At least a target action &lpar;t&rpar; to be performed is derived and&sol;or initialized and a learning sample &lpar;l&rpar; is used so as to introduce a user from an arbitrary current state &lpar;e<sb>c</sb>&rpar; to an arbitrary desired target state &lpar;e<sb>t</sb>&rpar; as the final state &lpar;e<sb>f</sb>&rpar;&period; This learning sample &lpar;l&rpar; consists of triple data indicating the initial state &lpar;e<sb>i</sb>&rpar; preceding an action &lpar;a&rpar; performed by a user&comma; the final state &lpar;e<sb>f</sb>&rpar; of this action&comma; and the action &lpar;a&rpar; performed&period;,G05B 13/02; A63H 11/00; B62D 57/02; B62D 57/032; G05B 19/042,SONY DEUTSCHLAND GMBH; SONY CORP,KEMP THOMAS; KOMPE RALF; TATO RAQUEL; FUJITA MASAHIRO; MINAMINO KATSUKI; KAWAMOTO KENTA; HORINAKA RIKA,01113422 01.06.2001 EP; 02730881 03.06.2002 EP; 0205441 03.06.2002 JP,
WO2003051031,PCT/US2002/039247,06.12.2002,WO/2003/051031,19.06.2003,WO,METHOD AND APPARATUS FOR PLANARIZATION OF A MATERIAL BY GROWING AND REMOVING A SACRIFICIAL FILM,Caption boxes which are embedded in video content can be located and the text within the caption boxes decoded. Real time processing is enhanced by locating caption box regions in the compressed video domain (210) and performing pixel based processing operations within the region of the video frame in which a caption box is located. The captions boxes are further refined by identifying word regions (240) within the caption boxes and then applying character and word recognition processing (250) to the identified word regions. Domain based models are used to improve text recognition results. The extracted caption box text can be used to detect events of interest in the video content and a semantic model applied to extract a segment of video of the event of interest.,G06F 17/30; G06K 9/32; G06T 7/00; G11B 27/031; G11B 27/28; H04N 7/025; H04N 5/445,"THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK; CHANG, Shih-Fu; ZHANG, Dongqing","CHANG, Shih-Fu; ZHANG, Dongqing","60/337,911 06.12.2001 US",US-10494739; JP-null
WO2019081662,PCT/EP2018/079325,25.10.2018,WO/2019/081662,02.05.2019,WO,"HARDWARE MODULE FOR A ROBOTIC SYSTEM, AND MECHANICAL COUPLING","A Hardware Module (3) for a robotic system comprises at least one sensor (38) for measuring an internal property of the Hardware Module (3), a communication unit (37) for communicating with other Hardware Modules (3), a data storage unit (36) and an embedded controller (35). The embedded controller (35) is configured to collect collected data, the collected data comprising •status data representing the current status of the Hardware Module (3); and •operating data representing usage of the Hardware Module (3); wherein at least part of the collected data is determined from sensor data from the at least one sensor (38), and the embedded controller (35) is configured to perform at least one of •storing the collected data on the data storage unit (36) and •transmitting the collected data via the communication unit (37).",B25J 9/08; B25J 9/16; B25J 17/02,FESTO SE & CO. KG,"RIEK, Alfons; STOLL, Kurt; KLINGEL, Hans; AESCHLIMANN, Marcel; MALZACH, Samuel; SIGRIST, Martin; SCHMID, Christian; BERGER, Christoph; PUDEWILLS, Leif; IANNUCCI, Kilian",17198992.4 27.10.2017 EP,
WO2018189404,PCT/EP2018/059628,16.04.2018,WO/2018/189404,18.10.2018,WO,DISTRIBUTIONAL REINFORCEMENT LEARNING,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for selecting an action to be performed by a reinforcement learning agent interacting with an environment. A current observation characterizing a current state of the environment is received. For each action in a set of multiple actions that can be performed by the agent to interact with the environment, a probability distribution is determined over possible Q returns for the action - current observation pair. For each action, a measure of central tendency of the possible Q returns with respect to the probability distributions for the action - current observation pair is determined. An action to be performed by the agent in response to the current observation is selected using the measures of central tendency.",G06N 3/04; G06N 3/08; G06N 7/00; G06N 99/00,DEEPMIND TECHNOLOGIES LIMITED,"DABNEY, William Clinton; GENDRON-BELLEMARE, Marc","62/485,720 14.04.2017 US",CN-201880025072.8; EP-2018717923
WO2017189758,PCT/US2017/029689,26.04.2017,WO/2017/189758,02.11.2017,WO,SYSTEM AND METHODS FOR MEDICAL IMAGE ANALYSIS AND REPORTING,"The present invention relates generally to a system and methods for medical image analysis and reporting. Specifically, certain preferred embodiments relate to a system that is configurable to receive a variety of inputs such that a user may choose the images, information, data, or other content reviewed by the user, the information that will result from that review and be inputted into the system, and the type of report that may be generated. In certain embodiments, the system facilitates matching the inputs to terms of a set of structured data elements to produce one or more templates that a user may select. An identifier including at least one term from the selected template may be assigned to the image. The system may then access an identified image database and process images with the identifier to produce a machine learning model, which can then be used to train a machine learning algorithm.",A61B 3/14; A61B 3/113; A61B 5/05,ASCEND HIT LLC,"ROBERGE, James; SOBLE, Jeffrey; WOLFER, James","62/327,743 26.04.2016 US; 62/341,698 26.05.2016 US",EP-2017790368
WO2019103772,PCT/US2018/047022,20.08.2018,WO/2019/103772,31.05.2019,WO,DETECTION AND ROOT CAUSE ANALYSIS OF WELDING DEFECTS,"Methods for weld analysis and corresponding systems and computer-readable mediums. A method (300) includes simulating (302) a welding operation (102) by the weld analysis system (400). The method includes analyzing (304) a physical weld (112) corresponding to the simulated welding operation. The method includes detecting and predicting (306) welding defects based on the simulated welding operation and the analysis of the physical weld. The method includes performing a root cause analysis (124, 308), based on the detected and predicted welding defects, to identify at least one root cause of the welding defects. The method includes producing a corrective action (128, 310) based on the identified at least one root cause to remove the welding defects from subsequent physical welds.",G01N 29/44; B23K 9/095; B23K 31/00; B23K 31/02; B23K 31/12,SIEMENS AKTIENGESELLSCHAFT; SIEMENS CORPORATION,"VENUGOPALAN, Janani; XIA, Songtao; CHALUPKA, Krzysztof","62/589,589 22.11.2017 US",
WO2019238523,PCT/EP2019/064776,06.06.2019,WO/2019/238523,19.12.2019,WO,CHARACTERIZING ACTIVITY IN A RECURRENT ARTIFICIAL NEURAL NETWORK AND ENCODING AND DECODING INFORMATION,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for characterizing activity in a recurrent artificial neural network and encoding and decoding information. In one aspect, a method that is implemented by one or more data processing devices can include receiving a training set that includes a plurality of representations of topological structures in patterns of activity in a source neural network and training a neural network using the representations either as an input to the neural network or as a target answer vector. The activity is responsive to an input into the source neural network.",G06N 3/04; G06N 3/08; G06N 5/00; G06N 3/00,INAIT SA,"MARKRAM, Henry; LEVI, Ran; HESS BELLWALD, Kathryn Pamela; SCHUERMANN, Felix","16/004,635 11.06.2018 US; 16/004,837 11.06.2018 US; 16/004,796 11.06.2018 US; 16/004,757 11.06.2018 US; 16/004,671 11.06.2018 US",
WO2020033822,PCT/US2019/045893,09.08.2019,WO/2020/033822,13.02.2020,WO,CAPTURE AND ADAPTIVE DATA GENERATION FOR TRAINING FOR MACHINE VISION,"Machine vision prediction of digital images uses synthetically generated training assets by capturing assets; configuring each of the assets with asset attributes; under computer program control, selecting different combinations of parameters from among the attributes, and creating different synthetic dataset parameters; using computer graphics software, and example parameter values from among the synthetic dataset parameters, creating a synthetic dataset by compiling from example images and metadata; configuring and executing machine learning trials to train a machine vision model, resulting in creating a trained machine vision model; executing a validation of the trained model; and inferring a prediction using the trained machine vision model. Trained models are scored against success criteria and re-trained using pseudo-random sampling of different parameters clustered around failure points. Thus machine vision models may be trained with high accuracy using large datasets of synthesized digital images that are richly parameterized, rather than human captured digital images.",G06T 7/00,"VIS MACHINA, INC.","HARVILL, Alex; FU, Michael","62/717,513 10.08.2018 US; 16/534,763 07.08.2019 US",
WO2017212333,PCT/IB2017/000782,07.06.2017,WO/2017/212333,14.12.2017,WO,SYSTEMS AND METHODS FOR ANALYZING BRAIN ACTIVITY AND APPLICATIONS THEREOF,"In some embodiments, the present invention provides an exemplary inventive system that includes: an apparatus to record: individual's brain electrical activity, a physiological parameter of the individual, and iii) an environmental parameter; a computer processor configured to perform: obtaining a recording of the electrical signal data; projecting the obtained recording of electrical signal data onto a pre-determined ordering of a denoised optimal set wavelet packet atoms to obtain a set of projections; normalizing the particular set of projections of the individual using a pre-determined set of normalization factors to form a set of normalized projections; determining a personalized mental state of the individual by assigning a brain state; determining a relationship between: the physiological parameter, the environmental parameter, and the personalized mental state; generating an output, including: a visual indication, representative of the personalized mental state, and) a feedback output configured to affect the personalized mental state of the individual.",A61B 5/00,NEUROSTEER LTD.,"INTRATOR, Nathan","62/375,004 15.08.2016 US; 62/346,626 07.06.2016 US",IL-263427; CA-3026607; KR-1020197000489; AU-2017278992; EP-2017809796
WO2003015004,PCT/US2002/018279,10.06.2002,WO/2003/015004,20.02.2003,WO,PATTERN-RECOGNITION ARTIFICIAL NEURAL WITH EXPERT SYSTEM,"Artificial Neural Net (ANN) (350) coupled with an Expert System (ES) (320) which monitors production test plans (310, 320) in real-time is provided. The ANN (350) recognizes and classifies production yield patterns (360) occurring at individual tester, complete test stage, and production line test aggregation and executes a proscribed range of responses. The ANN (350) will automate human statistical analysis and line monitoring functions, identify emerging yield trends, identify proximate cause of a yield-degrading event, classify event severity, and provide conclusional accuracy. The ES (320), based on recognized or inferred conditions provided by the ANN (350), consults its knowledge base and applies cognitive heuristics to execute responses (380) in the manner described by the human expert it is modeled after. These responses may include a summary report electronically to the correct individuals, a voice/pager message to the individuals responsible to react to an event, a visual or audible alarm at the event site, and/or direct adjustment of the production process.",G05B 13/02; G05B 19/418; G05B 23/02; G06N 3/04; G21C 17/00,"NOKIA CORPORATION; GVENTER, Brian","GVENTER, Brian","09/923,215 06.08.2001 US",MX-PA/a/2004/001083; JP-null; EP-2002737443
EP289840207,19160748,05.03.2019,3621069,11.03.2020,EP,MANAGEMENT AND EXECUTION OF EQUIPMENT MAINTENANCE,"In some examples, a system may receive from a device, speech sound patterns corresponding to a voice input related to equipment. Further, the system may determine an identity of a person associated with the device, and may identify the equipment related to the voice input. Using at least one of the received speech sound patterns or a text conversion of the speech sound patterns, along with an equipment history of the identified equipment, as input to one or more machine learning models, the system may determine, at least partially, an instruction related to the equipment. Additionally, the system may send, to the device, the instruction related to the equipment as an audio file for playback on the device.",G10L 15/22; A61B 5/16; G06F 3/16; G06Q 10/00; G10L 13/02; G10L 15/18; G10L 15/26; G10L 17/00; G10L 25/48; G10L 25/63,HITACHI LTD,ARANTES ADRIANO; VIEIRA MARCOS; GUPTA CHETAN; FARAHAT AHMED; GONZALEZ DIAZ MARIA,201816121837 05.09.2018 US,
WO2018217890,PCT/US2018/034127,23.05.2018,WO/2018/217890,29.11.2018,WO,ROBOTIC ASSEMBLY OF TRANSPORT STRUCTURES USING ON-SITE ADDITIVE MANUFACTURING,"Techniques for flexible, on-site additive manufacturing of components or portions thereof for transport structures are disclosed. An automated assembly system for a transport structure may include a plurality of automated constructors to assemble the transport structure. In one aspect, the assembly system may span the full vertically integrated production process, from powder production to recycling. At least some of the automated constructors are able to move in an automated fashion between the station under the guidance of a control system. A first of the automated constructors may include a 3-D printer to print at least a portion of a component and to transfer the component to a second one of the automated constructors for installation during the assembly of the transport structure. The automated constructors may also be adapted to perform a variety of different tasks utilizing sensors for enabling machine-learning.",B22F 3/105; G06N 99/00; B25J 11/00; B33Y 50/02; B33Y 40/00; B33Y 70/00,"DIVERGENT TECHNOLOGIES, INC.","CZINGER, Kevin Robert; TENHOUTEN, Broc William; O'CONNELL, David Charles; GUNNER, John Paul; BUCKNELL, John Russell; HAMADE, Alex James; TENHOUTEN, David Brian","15/604,037 24.05.2017 US",EP-2018806928; KR-1020197037203
WO2017163759,PCT/JP2017/007263,21.02.2017,WO/2017/163759,28.09.2017,WO,"SYSTEM AND COMPUTER-IMPLEMENTED METHOD FOR SEMANTIC SEGMENTATION OF IMAGE, AND NON-TRANSITORY COMPUTER-READABLE MEDIUM","A computer-implemented method for semantic segmentation of an image determines unary energy of each pixel in an image using a first subnetwork, determines pairwise energy of at least some pairs of pixels of the image using a second subnetwork, and determines, using a third subnetwork, an inference on a Gaussian random field (GRF) minimizing an energy function including a combination of the unary energy and the pairwise energy. The GRF inference defining probabilities of semantic labels for each pixel in the image, and the method converts the image into a semantically segmented image by assigning to a pixel in the semantically segmented image a semantic label having the highest probability for a corresponding pixel in the image among the probabilities determined by the third subnetwork. The first subnetwork, the second subnetwork, and the third subnetwork are parts of a neural network.",G06K 9/46; G06K 9/62; G06T 7/143,MITSUBISHI ELECTRIC CORPORATION,"TUZEL, Oncel; VEMULAPALLI, Raviteja; LIU, Ming-Yu","15/081,337 25.03.2016 US",JP-2018523830
EP251457635,18857429,30.08.2018,3537349,11.09.2019,EP,MACHINE LEARNING MODEL TRAINING METHOD AND DEVICE,"A machine learning model training method, the method comprising: obtaining target task training data and N types of supporting task training data (S1010); inputting the target task training data and the N types of supporting task training data into a memory model and obtaining target task training feature data and N types of supporting task training feature data (S1020); training a target task model according to the target task training feature data and obtaining a first loss of the target task model, and respectively training respective corresponding supporting task models according to the N types of supporting task training feature data and obtaining a second loss of each of the N supporting task models (S1030); updating the memory model, the target task model and the N supporting task models according to the first loss and the second loss of each of the N supporting task models (S1040). By means of the method for training a machine learning model, the accuracy of prediction results may be improved.",G06N 99/00,HUAWEI TECH CO LTD,WU BIN; ZHOU FENGEI; LI ZHENGUO,201810027720 11.01.2018 CN; 2018103364 30.08.2018 CN,
WO2014048855,PCT/EP2013/069626,20.09.2013,WO/2014/048855,03.04.2014,WO,SPEAKER RECOGNITION,Method for text-dependent Speaker Recognition using a speaker adapted Universal Background Model; wherein the speaker adapted Universal Background Model is a speaker adapted Hidden Markov Model comprising channel correction.,G10L 17/24; G10L 17/04; G10L 17/16; G10L 17/10,"AGNITIO,S.L","BUERA RODRIGUEZ, Luis; VAQUERO AVILES-CASCO, Carlos; GARCIA GOMAR, Marta; ARTIAGA, Antonio Miguel",12006775.6 28.09.2012 EP,EP-2013765743; US-14119156
WO2008023995,PCT/NZ2007/000214,13.08.2007,WO/2008/023995,28.02.2008,WO,A METHOD OF AND SYSTEM FOR IMAGE PROCESSING,A method of correlating a representation of a body to a three dimensional representation of the body. A representation (such as a two dimensional image) of a body is acquired and a fitness function is generated for it. A two dimensional outline of the three dimensional representation of the body is then generated for a number of sets of three dimensional position and orientation values. These are compared to the fitness function to generate measures of fit for each set of three dimensional position and orientation values. New sets of position and orientation values are then bred using a genetic algorithm or other breeding algorithm. The method is repeated until the measure of fit converges to an acceptable solution. There is also disclosed a system for performing the method.,G06T 7/60; G06N 3/12; A61B 5/103,"DEVANE, Peter","DEVANE, Peter",549464 25.08.2006 NZ,US-12438721
WO2017151757,PCT/US2017/020183,01.03.2017,WO/2017/151757,08.09.2017,WO,RECURRENT NEURAL FEEDBACK MODEL FOR AUTOMATED IMAGE ANNOTATION,"A deep learning model is provided to efficiently detect disease from an image (e.g., an x-ray image) and annotate its contexts. In one example of the disclosed technology, a method of generating an annotation sequence describing an input image includes training a convolutional neural network (CNN) with a series of reference images and associated annotation sequences, training a recurrent neural network (RNN) by initializing the RNN with the trained CNN embedding of the reference image and a first word of an annotation sequence, sampling the CNN and RNN with a reference image, and producing a sequence of annotation describing the image, disease(s) in the image, one or more attributes or contexts. In one examples of the disclosed technology, mean pooling is applied to the state vectors of RNN to obtain a joint image/text context vector summarizing the contexts of image and text annotation.",G06N 3/04,"THE UNITED STATES OF AMERICA, AS REPRESENTED BY THE SECRETARY, DEPARTMENT OF HEALTH AND HUMAN SERVICES","SHIN, Hoo-Chang; LU, Le; SUMMERS, Ronald, M.","62/302,084 01.03.2016 US",
WO2018134589,PCT/GB2018/050134,17.01.2018,WO/2018/134589,26.07.2018,WO,DETERMINING THE LOCATION OF A MOBILE DEVICE,"A computer-implemented method of determining the location of a mobile device comprising a camera. The method comprises the steps of capturing, using the camera, a sequence of images over a period of time; for pairs of consecutive images from the sequence of images, determining, using a first neural network, features indicative of the motion of the device between the time the first image of the pair of images was captured and the time the second image of the pair of images was captured; for a sequence of consecutive images, determining, using a second neural network, features indicative of the location of the device from the features determined by the first neural network; and for a sequence of consecutive images, determining the location of the device from the features determined by the second neural network.",G06T 7/20; G06T 7/70,OXFORD UNIVERSITY INNOVATION LIMITED,"WANG, Sen; CLARK, Ronald; TRIGONI, Niki",20170100024 23.01.2017 GR; 1703005.7 24.02.2017 GB,EP-2018701541; CN-201880020542.1; AU-2018208816; JP-2019539772
WO2017134519,PCT/IB2017/000134,01.02.2017,WO/2017/134519,10.08.2017,WO,IMAGE CLASSIFICATION AND LABELING,"A method of training an image classification model includes obtaining training images associated with labels, where two or more labels of the labels are associated with each of the training images and where each label of the two or more labels corresponds to an image classification class. The method further includes classifying training images into one or more classes using a deep convolutional neural network, and comparing the classification of the training images against labels associated with the training images. The method also includes updating parameters of the deep convolutional neural network based on the comparison of the classification of the training images against the labels associated with the training images.",G06K 9/00; G06N 3/02; G06T 1/40,SEE-OUT PTY LTD.,"MAU, Sandra; SIVAPALAN, Sabesan","62/289,902 01.02.2016 US",EP-2017747065; JP-2018558501; SG-11201806541R; CN-201780020533.8; AU-2017214619
EP276032585,19169618,16.04.2019,3564871,06.11.2019,EP,ROBOTIC OPTIMIZATION FOR ROBOTIC PROCESS AUTOMATION PLATFORMS,,G06N 5/04,ACCENTURE GLOBAL SOLUTIONS LTD,GOYAL GAURAV; MORGAN-BAKER KATHERINE WHEELER; CLIFTON-HADLEY DANIEL; SRIDHAR ASHWIN KUMAR,201815966926 30.04.2018 US,
WO2020023590,PCT/US2019/043168,24.07.2019,WO/2020/023590,30.01.2020,WO,INTELLIGENT REASONING FRAMEWORK FOR USER INTENT EXTRACTION,"Embodiments of the present systems and methods may provide an intelligent systems framework for analysis of user-generated content from various capture points to determine user intent. For example, a method may be implemented in a computer system comprising a processor, memory accessible by the processor, and computer program instructions stored in the memory and executable by the processor, the method may comprise receiving, at the computer system, data relating to a plurality of aspects of at least one person, including data from at least one of physical or physiological sensors and communicatively connected devices, extracting, at the computer system, from the received data, features relevant to events relating to at least one person, extracting, at the computer system, at least one intent of at least one event relating to at least one person, and performing, at the computer system, an action based on the extracted at least one intent.",G06F 15/18,"HOWARD, Newton","HOWARD, Newton","62/702,815 24.07.2018 US; 16/520,673 24.07.2019 US",
WO2018182357,PCT/KR2018/003774,30.03.2018,WO/2018/182357,04.10.2018,WO,DATA LEARNING SERVER AND METHOD FOR GENERATING AND USING LEARNING MODEL THEREOF,"An apparatus and a method for a data learning server is provided. The apparatus of the disclosure includes a communicator configured to communicate with an external device, at least one processor configured to acquire a set temperature set in an air conditioner and a current temperature of the air conditioner at the time of setting the temperature via the communicator, and a generate or renew a learning model using the set temperature and the current temperature, and a storage configured to store the generated or renewed learning model to provide a recommended temperature to be set in the air conditioner as a result of generating or renewing the learning model. For example, the data learning server of the disclosure may generate a learned learning model to provide a recommended temperature using a neural network algorithm, a deep learning algorithm, a linear regression algorithm, or the like as an artificial intelligence algorithm.",F24F 11/30; G06N 3/02; F24F 11/65; F24F 11/59; F24F 11/52; F24F 11/62; F24F 120/20; F24F 110/10; F24F 110/20,"SAMSUNG ELECTRONICS CO., LTD.","OCK, Hyun-woo; KIM, Min-kyong; KIM, Tan; SONG, Hyung-seon; SHIN, Dong-jun; IM, Sung-bin; SEO, Hyeong-joon; JOO, Young-ju","62/479,207 30.03.2017 US; 10-2017-0123239 25.09.2017 KR",CA-3058373; EP-2018753038; CN-201880022241.2; AU-2018246843
WO2018170421,PCT/US2018/022905,16.03.2018,WO/2018/170421,20.09.2018,WO,ROOM LAYOUT ESTIMATION METHODS AND TECHNIQUES,"Systems and methods for estimating a layout of a room are disclosed. The room layout can comprise the location of a floor, one or more walls, and a ceiling, in one aspect, a neural network can analyze an image of a portion of a room to determine the room layout. The neural network can comprise a convolutional neural network having an encoder sub-network, a decoder sub-network, and a side sub-network. The neural network can determine a three-dimensional room layout using two-dimensional ordered keypoints associated with a room type. The room layout can be used in applications such as augmented or mixed reality, robotics, autonomous indoor navigation, etc.",G06N 3/02; G06F 15/18,"MAGIC LEAP, INC.","LEE, Chen-Yu; BADRINARAYANAN, Vijay; MALISIEWICZ, Tomasz; RABINOVICH, Andrew","62/473,257 17.03.2017 US",KR-1020197029282; JP-2019547140; CA-3055597; AU-2018236433; EP-2018767554; CN-201880017801.5
WO2019182378,PCT/KR2019/003305,21.03.2019,WO/2019/182378,26.09.2019,WO,ARTIFICIAL INTELLIGENCE SERVER,"Disclosed is an artificial intelligence (AI) server. The AI server includes a communication unit configured to communicate with an AI device; and an AI unit configured to receive feature data from the AI device, wherein the received feature data is generated by the AI device by obtaining sensing data and compressing the sensing data while preserving a a feature of the sensing data; and input the received feature data to a deep learning model to obtain second sensing data for use in a recognition model related to an AI function of the AI device.",G06N 3/08; H04L 29/08,LG ELECTRONICS INC.,"HAN, Jongwoo; JEONG, Hangil","62/645,813 21.03.2018 US; 10-2018-0111737 18.09.2018 KR",
WO2018208939,PCT/US2018/031833,09.05.2018,WO/2018/208939,15.11.2018,WO,"SYSTEMS AND METHODS TO ENABLE CONTINUAL, MEMORY-BOUNDED LEARNING IN ARTIFICIAL INTELLIGENCE AND DEEP LEARNING CONTINUOUSLY OPERATING APPLICATIONS ACROSS NETWORKED COMPUTE EDGES","Lifelong Deep Neural Network (L-DNN) technology revolutionizes Deep Learning by enabling fast, post-deployment learning without extensive training, heavy computing resources, or massive data storage. It uses a representation-rich, DNN-based subsystem (Module A) with a fast-learning subsystem (Module B) to learn new features quickly without forgetting previously learned features. Compared to a conventional DNN, L-DNN uses much less data to build robust networks, dramatically shorter training time, and learning on-device instead of on servers. It can add new knowledge without re-training or storing data. As a result, an edge device with L-DNN can learn continuously after deployment, eliminating massive costs in data collection and annotation, memory and data storage, and compute power. This fast, local, on-device learning can be used for security, supply chain monitoring, disaster and emergency response, and drone-based inspection of infrastructure and properties, among other applications.",G06K 9/46; G06K 9/62; G06K 9/00; G06K 9/36; G06K 9/48,"NEURALA, INC.","LUCIW, Matthew; OLIVERA, Santiago; GORSHECHNIKOV, Anatoly; WURBS, Jeremy; VERSACE, Heather Ames; VERSACE, Massimiliano","62/503,639 09.05.2017 US; 62/612,529 31.12.2017 US",CA-3061767; KR-1020197035963; EP-2018799281
EP289344239,19182451,25.06.2019,3617883,04.03.2020,EP,INFERENCE ENGINE ACCELERATION FOR VIDEO ANALYTICS IN COMPUTING ENVIRONMENTS,"A mechanism is described for facilitating deep learning inference acceleration in computing environments. An apparatus of embodiments, as described herein, includes one or more processors to compare a current input value associated with a layer of a plurality of layers of a neural network to a cached input value associated with the layer. The one or more processors are further to import the cached input value for the layer for further processing within the neural network, if the current input value and the cached input value are equal.",G06F 9/54; G06N 3/04; G06N 3/063; G06N 3/08,INTEL CORP,CHEN FAN,201816114818 28.08.2018 US,
WO2014075174,PCT/CA2013/000966,19.11.2013,WO/2014/075174,22.05.2014,WO,METHOD AND SYSTEM FOR THE SPOTTING OF ARBITRARY WORDS IN HANDWRITTEN DOCUMENTS,"A method and system for the spotting of keywords in a handwritten document, the method comprising the steps of inputting an image of the handwritten document, performing word segmentation on the image to obtain segmented words, performing word matching, and outputting the spotted keywords. The word matching itself consisting in the sub-steps of performing character segmentation on the segmented words, performing character recognition on the segmented characters, performing distance computations on the recognized characters using a Generalized Hidden Markov Model with ergodic topology to identify words based on character models and performing non-keyword rejection using a classifier based on a combination of Gaussian Mixture Models, Hidden Markov Models and Support Vector Machines.",G06K 9/80; G06F 15/18; G06K 9/40; G06K 9/50,IMDS AMERICA INC.,"HAJI, Mehdi; PONSON, Dominique","61/728,048 19.11.2012 US",US-14443918; EP-2013855555; CA-2891930
WO2018085946,PCT/CA2017/051355,14.11.2017,WO/2018/085946,17.05.2018,WO,SYSTEM AND METHOD FOR DETECTING SUBLIMINAL FACIAL RESPONSES IN RESPONSE TO SUBLIMINAL STIMULI,"A system and method for detecting subliminal facial responses of a human subject to subliminal stimuli. The method includes: receiving captured first facial response data approximately time- locked with a presentation of subliminal target stimuli to a plurality of human subjects; receiving captured second facial response data approximately time-locked with a presentation of subliminal foil stimuli to the plurality of human subjects; receiving captured unidentified facial response data to a subliminal stimulus from the target human subject; determining a target probability measure that the unidentified facial response data of the target human subject is in response to the subliminal target stimuli using a machine learning model trained with a subliminal response training set, the subliminal response training set comprising the first captured facial response data and the captured second facial response data; and outputting the target probability measure.",A61B 5/16; A61B 5/00; A61B 5/1455; G06F 15/18; G06F 19/00; G16H 50/20,NURALOGIX CORPORATION,"LEE, Kang; ZHENG, Pu; POZZUOLI, Marzio","62/421,508 14.11.2016 US",EP-2017854177; CA-2998687; US-15761891
EP236491132,17766614,13.03.2017,3432227,23.01.2019,EP,LEARNING SERVICE PROVISION DEVICE,"Provided is a mechanism for improving the efficiency of development operations for adding a new ability to an apparatus. Also, a mechanism is provided with which even a person who does not have a knowledge and a system relating to machine learning can easily add a new ability acquired by machine learning to his/her apparatus. A request acceptance unit accepts, as learning request information, information necessary for performing machine learning with respect to an ability to be added to a target apparatus, from a requester. A learning simulator performs machine learning according to the learning request information accepted from the requester. An ability providing data generation unit generates, based on a learning result obtained by the learning simulator, ability providing data, which is data for adding a new ability acquired as the learning result to the target apparatus. A service providing unit provides the ability providing data to the requester.",G06N 99/00; G06F 8/71; G06F 9/445; G06K 9/00; G06K 9/46; G06K 9/62; G06N 3/063; G06N 3/08; G06N 3/10,OMRON TATEISI ELECTRONICS CO,ANDO TANICHI,2016049236 14.03.2016 JP; 2017009984 13.03.2017 JP,
WO2018216493,PCT/JP2018/018142,10.05.2018,WO/2018/216493,29.11.2018,WO,"LEARNING APPARATUS, LEARNING CONTROL METHOD, AND PROGRAM THEREFOR","In order to provide a technique for shortening the time required for a learning apparatus to achieve a learning purpose, without performing manual manipulation, a learning apparatus configured to learn control of an operation involved in a predetermined task includes: a learning data accepting unit configured to accept learning data containing a learning purpose; a neural network configured to perform learning based on the learning data; and an output unit configured to output a learning result obtained by the neural network, wherein the neural network performs a first learning process for achieving an initial stage of the learning purpose, performs a second learning process for learning control with which an operation involved in the learning is made non-continuable, based on a result of the first learning process, and performs a third learning process for achieving the learning purpose, with the control with which an operation involved in the learning is made non-continuable being excluded, based on a result of the second learning process.",B25J 9/16; G05B 13/02; G05D 1/00; G05D 1/02; G06N 3/08,OMRON CORPORATION,"ANDO, Tanichi",2017-104523 26.05.2017 JP,
WO2019177732,PCT/US2019/017782,13.02.2019,WO/2019/177732,19.09.2019,WO,REAL-TO-SYNTHETIC IMAGE DOMAIN TRANSFER,"Systems, methods, and machine-readable media for deterministically generating labeled data for training or validating machine learning models for image analysis, and for using such machine learning models to determine the contents of real-domain images by using a domain transfer to synthetic-appearing images are described.",G06K 9/62,RECOGNI INC.,"BACKHUS, Gilles, J.C.A.; ABHIRAM, Shabarivas; FEINBERG, Eugene, M.","62/642,578 13.03.2018 US; 62/674,497 21.05.2018 US",
WO2019081783,PCT/EP2018/079566,29.10.2018,WO/2019/081783,02.05.2019,WO,REINFORCEMENT LEARNING USING DISTRIBUTED PRIORITIZED REPLAY,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training an action selection neural network used to select actions to be performed by an agent interacting with an environment. One of the systems includes (i) a plurality of actor computing units, in which each of the actor computing units is configured to maintain a respective replica of the action selection neural network and to perform a plurality of actor operations, and (ii) one or more learner computing units, in which each of the one or more learner computing units is configured to perform a plurality of learner operations.",G06N 3/08; G06N 3/04,DEEPMIND TECHNOLOGIES LIMITED,"BUDDEN, David; BARTH-MARON, Gabriel; QUAN, John; HORGAN, Daniel George","62/578,384 27.10.2017 US",
WO2019081778,PCT/EP2018/079526,29.10.2018,WO/2019/081778,02.05.2019,WO,DISTRIBUTIONAL REINFORCEMENT LEARNING FOR CONTINUOUS CONTROL TASKS,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for training an action selection neural network that is used to select actions to be performed by a reinforcement learning agent interacting with an environment. In particular, the actions are selected from a continuous action space and the system trains the action selection neural network jointly with a distribution Q network that is used to update the parameters of the action selection neural network.",G06N 3/08; G06N 3/04; G06N 3/00,DEEPMIND TECHNOLOGIES LIMITED,"BUDDEN, David; HOFFMAN, Matthew William; BARTH-MARON, Gabriel","62/578,389 27.10.2017 US",
WO2018216490,PCT/JP2018/018133,10.05.2018,WO/2018/216490,29.11.2018,WO,"LEARNING APPARATUS, LEARNING CONTROL METHOD, PROGRAM THEREFOR","In order to provide a technique for shortening the time required for a learning apparatus to achieve a learning purpose, without performing manual manipulation, a learning apparatus configured to learn control of an operation involved in a predetermined task includes: a learning data accepting unit configured to accept learning data containing a learning purpose and an allowable requirement for a learning operation performed when learning the control; a neural network configured to perform learning based on the learning data; and an output unit configured to output a learning result obtained by the neural network, wherein the neural network performs a first learning process for achieving an initial stage of the learning purpose, performs a second learning process for learning a control range in which a learning operation matches an allowable requirement, based on a result of the first learning process, and performs a third learning process for achieving the learning purpose within the control range based on a result of the second learning process.",B25J 9/16; G05B 13/02; G05D 1/00; G05D 1/02; G06N 3/08,OMRON CORPORATION,"ANDO, Tanichi",2017-104528 26.05.2017 JP,
WO2019234291,PCT/FI2019/050393,21.05.2019,WO/2019/234291,12.12.2019,WO,"AN APPARATUS, A METHOD AND A COMPUTER PROGRAM FOR SELECTING A NEURAL NETWORK","There is provided an apparatus comprising means for receiving data to be processed by one of a plurality of main neural networks (210). The apparatus comprises means for providing the data and signalling information associated with the data to a plurality of devices each comprising a main neural network and an auxiliary neural network, the auxiliary neural network comprising a subset of layers of the main neural network, wherein the signalling information comprises an identifier of an auxiliary task to be performed on the data by the auxiliary neural networks at the plurality of devices (220). The apparatus comprises means for receiving, from the plurality of devices, indications of performance of the auxiliary neural networks for performing the auxiliary task (230). The apparatus comprises means for selecting, based on the indications of performance of the auxiliary neural networks, one of the plurality of main neural networks for performing a main task on the data (240).",G06N 3/04; G06N 3/08; H04L 29/08; G06F 9/50; G06T 9/00; G06T 5/00,NOKIA TECHNOLOGIES OY,"CRICRI, Francesco; AYTEKIN, Caglar",20185527 08.06.2018 FI,
WO2019028761,PCT/CN2017/096886,10.08.2017,WO/2019/028761,14.02.2019,WO,OBJECT TRACKING USING DEPTH INFORMATION,"A technology for tracking a target object using depth information is disclosed. An object image contain a target object can be obtained from a reference image. A target distance from a robot to the target object can also be derived or accessed. When the robot captures a new image, 2D matching can be performed to find the horizontal and vertical movement of the target object. Distance change or depth change of the target object can also be calculated from the new image. A depth change ratio can be calculated and be utilized to scale a bounding box. The robot can then move to a new location according to the horizontal, vertical and depth changes. A new object image can be extracted from the new image according to the scaled bounding box. The object tracking can be continued using a similar process when the next image is captured.",H04N 5/232; G06T 7/20,"BEIJING AIRLANGO TECHNOLOGY, CO., LTD.","MAO, Yinian; LIU, Xinmin",,
WO2015020939,PCT/US2014/049563,04.08.2014,WO/2015/020939,12.02.2015,WO,AUTOMATIC PROCESS CONTROL OF ADDITIVE MANUFACTURING DEVICE,Automatic process control of additive manufacturing. The system includes an additive manufacturing device for making an object (16) and a local network computer controlling the device. At least one camera (10) is provided with a view of a manufacturing volume of the device to generate network accessible images of the object (16). The computer is programmed to stop the manufacturing process when the object (16) is defective based on the images of the object (16).,B29C 67/00; G06N 99/00,MASSACHUSETTS INSTITUTE OF TECHNOLOGY,"PEREZ, Alfonso, Alexander; HAID, Christopher, Michael; PENA DOLL, Mateo; PEIPER, Forrest, W.","61/863,110 07.08.2013 US; 14/448,229 31.07.2014 US",JP-2016533354; EP-2014755481; CA-2919508; CN-201480043784.4; AU-2014306218; MX-MX/a/2016/001685
WO2019005547,PCT/US2018/038433,20.06.2018,WO/2019/005547,03.01.2019,WO,"MOVING BODY CONTROL APPARATUS, MOVING BODY CONTROL METHOD, AND TRAINING METHOD","A moving body control apparatus (1) for controlling a moving body (100) includes: an acquisition device (10) that acquires a control command for the moving body (100) and an image of a view in the traveling direction of the moving body (100); and an information processing device (20) that uses a machine learning model (30) to output a control parameter for controlling the moving body (100), using the control command and the image acquired by the acquisition device (10) as inputs.",B25J 9/16; G06F 3/041; G09G 5/00; G10L 21/00,PANASONIC INTELLECTUAL PROPERTY CORPORATION OF AMERICA,"HARIHARA SUBRAMANIAN, Karthikk; ZHOU, Bin; SHEN, Sheng Mei; LIM, Sugiri Pranata","62/525,979 28.06.2017 US",
WO2018024944,PCT/FI2017/050556,27.07.2017,WO/2018/024944,08.02.2018,WO,"A METHOD, A COMPUTER PROGRAM, AN APPARATUS AND A SYSTEM FOR SEPARATING AT LEAST ONE OBJECT FROM A PLURALITY OF OBJECTS",Feedback information is an important aspect in all machine learning systems. In robot systems that are picking objects from a plurality of objects this has been arranged by acquiring images of objects that have been picked. When images are acquired after picking they can be imaged accurately and the information about picking and also dropping success can be improved by using acquired images as a feedback in the machine learning arrangement being used for controlling the picking and dropping of objects.,B07C 5/342; B25J 13/08; B25J 9/16; B07C 5/36,ZENROBOTICS OY,"LUKKA, Tuomas; KUJALA, Janne",20165603 04.08.2016 FI,AU-2017305864; EP-2017836465; JP-2019505157
WO2018134587,PCT/GB2018/050132,17.01.2018,WO/2018/134587,26.07.2018,WO,DETERMINING THE LOCATION OF A MOBILE DEVICE,"A computer-implemented method of determining the location of a mobile device comprising a camera and at least one inertial sensor. A sequence of images are captured over a period of time, and a first neural network determines features indicative of the motion of the device from pairs of consecutive images. Data indicative of the motion of the device is captured, and a second neural network determines features indicative of the motion of the device from the data. A third neural network then determines features indicative of the location of the device from the features determined by the first neural network and the second neural network. The location of the device is the determined from the features determined by the third neural network.",G06T 7/20; G06T 7/70,OXFORD UNIVERSITY INNOVATION LIMITED,"CLARK, Ronald; WANG, Sen; TRIGONI, Niki",20170100023 23.01.2017 GR; 1703006.5 24.02.2017 GB,CN-201880020559.7; EP-2018701218; AU-2018209336; JP-2019539805
WO2007076529,PCT/US2006/062689,28.12.2006,WO/2007/076529,05.07.2007,WO,A SYSTEM AND METHOD FOR ACCESSING IMAGES WITH A NOVEL USER INTERFACE AND NATURAL LANGUAGE PROCESSING,"Systems and methods for accessing images with natural language processing are provided. The methods for accessing images include linking an image with image-summarizing text by applying a hierarchical clustering algorithm to cluster one or more abstract sentences and one or more images, and linking an image with image-summarizing text if the abstract sentence belongs to a cluster that includes the image. The systems for accessing images include a natural language processor that applies a hierarchical clustering algorithm to link one or more abstract sentences in an article with one or more images in the article, and a user interface in which selecting image- summarizing text displays one or more linked images.",G06F 17/30,"THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK; YU, Hong","YU, Hong","60/754,380 28.12.2005 US; 60/779,837 07.03.2006 US",US-12139267; DE-null
WO2006083596,PCT/US2006/002204,19.01.2006,WO/2006/083596,10.08.2006,WO,RESPONDING TO SITUATIONS USING KNOWLEDGE REPRESENTATION AND INFERENCE,"A system, apparatus and application for providing robots with the ability to intelligently respond to perceived situations are described. A knowledge database is assembled automatically, based on distributed knowledge capture. The knowledge base embodies the 'common sense,' that is, the consensus, of the subjects who contribute the knowledge. Systems are provided to automatically preprocess, or 'clean' the information to make it more useful. The knowledge thus refined is utilized to construct a multidimensional semantic network, or MSN. The MSN provides a compact and efficient semantic representation suitable for extraction of knowledge for inference purposes and serves as the basis for task and response selection. When the robot perceives a situation that warrants a response, an appropriate subset of the MSN is extracted into a Bayes network. The resultant network is refined, and used to derive a set of response probabilities, which the robot uses to formulate a response.",G06N 5/02,"HONDA MOTOR CO., LTD.; GUPTA, Rakesh; VASCO CALAIS, Pedro","GUPTA, Rakesh; VASCO CALAIS, Pedro","11/046,343 28.01.2005 US",JP-2007553151; EP-6719163
WO2020023483,PCT/US2019/042989,23.07.2019,WO/2020/023483,30.01.2020,WO,CONTINUOUS PARAMETRIZATIONS OF NEURAL NETWORK LAYER WEIGHTS,"Methods, systems, and apparatus for more efficiently and accurately generating neural network outputs, for instance, for use in classifying image or audio data. In one aspect, a method includes processing a network input using a neural network including multiple neural network layers to generate a network output. One or more of the neural network layers is a conditional neural network layer. Processing a layer input using a conditional neural network layer to generate a layer output includes obtaining values of one or more decision parameters of the conditional neural network layer. The neural network processes the layer input and the decision parameters of the conditional neural network layer to determine values of one or more latent parameters of the conditional neural network layer from a continuous set of possible latent parameter values. The values of the latent parameters specify the values of the conditional layer weights.",G06N 3/04; G06N 3/08,GOOGLE LLC,"IZADI, Shahram; KESKIN, Cem","62/702,055 23.07.2018 US",EP-2019749159
WO2019243897,PCT/IB2019/000802,19.06.2019,WO/2019/243897,26.12.2019,WO,SYSTEM AND METHOD FOR DETECTION AND CLASSIFICATION OF OBJECTS OF INTEREST IN MICROSCOPE IMAGES BY SUPERVISED MACHINE LEARNING,"Methods are provided for efficient training of convoluted neural networks using computer-assisted microscope image acquisition and pre-classification of training images for biological objects of interest. The methods combine use of an automated scanning platform, on-the-fly image analysis parallel to the scanning process, and a user interface for review of the pre-classification performed by the software.",G06K 9/00,METASYSTEMS HARD AND SOFTWARE GMBH,"PLESCH, Andreas; LÖRCH, Thomas","62/687,215 19.06.2018 US",
WO2018045081,PCT/US2017/049458,30.08.2017,WO/2018/045081,08.03.2018,WO,ROBOTS FOR INTERACTIVE COMEDY AND COMPANIONSHIP,"Method, systems, and algorithms are provided to generate and deliver interactive jokes, comedy monologues, comedy dialogues and comedy routines i) to a user/group in-person, via an interactive comedic robot or ii) to the user/group remotely, via an animated robot, chat-bot, or chatter-bot on internet connected television-, or web-, or mobile-, or projector-interface. Methods include creating a database of topics, set-up comments, punch lines and audio- and video- recordings of canned laughter and emotions. Algorithms include the selection and delivery of the topics, the set-up comments, and the punch lines packaged with the canned laughter and emotions. The jokes/comedy are delivered in a synthesized/recorded robotic or human voice representing one or more than one personality of the robot. The disclosed robots are usable for interactive entertainment, companionship, education, training, greeting, guiding and customer service applications as well as for user feed-back, customization, and crowdsourcing.",G05B 15/00; G05B 19/418; G06F 9/00; G06F 17/30,TAECHYON ROBOTICS CORPORATION,"FAVIS, Stephen; SRIVASTAVA, Deepak","62/381,976 31.08.2016 US",
WO2018085945,PCT/CA2017/051354,14.11.2017,WO/2018/085945,17.05.2018,WO,SYSTEM AND METHOD FOR CAMERA-BASED HEART RATE TRACKING,A system and method for camera-based heart rate tracking. The method includes: determining bit values from a set of bitplanes in a captured image sequence that represent the HC changes; determining a facial blood flow data signal for each of a plurality of predetermined regions of interest (ROIs) of the subject captured by the images based on the HC changes; applying a band-pass filter of a passband approximating the heart rate to each of the blood flow data signals; applying a Hilbert transform to each of the blood flow data signals; adjusting the blood flow data signals from revolving phase-angles into linear phase segments; determining an instantaneous heart rate for each the blood flow data signals; applying a weighting to each of the instantaneous heart rates; and averaging the weighted instantaneous heart rates.,A61B 5/024; A61B 5/026; A61B 5/1455; G16H 30/40; G06F 15/18,NURALOGIX CORPORATION,"KABAKOV, Evgueni; LEE, Kang; LEVY, Phil","62/421,517 14.11.2016 US",CA-3042952; CN-201780070236.4
WO2019202073,PCT/EP2019/060070,18.04.2019,WO/2019/202073,24.10.2019,WO,NEURAL NETWORKS FOR SCALABLE CONTINUAL LEARNING IN DOMAINS WITH SEQUENTIALLY LEARNED TASKS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for scalable continual learning using neural networks. One of the methods includes receiving new training data for a new machine learning task; training an active subnetwork on the new training data to determine trained values of the active network parameters from initial values of the active network parameters while holding current values of the knowledge parameters fixed; and training a knowledge subnetwork on the new training data to determine updated values of the knowledge parameters from the current values of the knowledge parameters by training the knowledge subnetwork to generate knowledge outputs for the new training inputs that match active outputs generated by the trained active subnetwork for the new training inputs.",G06N 3/04; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"SCHWARZ, Jonathan; PASCANU, Razvan; HADSELL, Raia Thais; CZARNECKI, Wojciech; THE, Yee Whye; LUKETINA, Jelena","62/659,610 18.04.2018 US",
WO2010141180,PCT/US2010/033917,06.05.2010,WO/2010/141180,09.12.2010,WO,SUPERVISION AND CONTROL OF HETEROGENEOUS AUTONOMOUS OPERATIONS,"The different advantageous embodiments may provide an apparatus that may include a number of robotic machine groups, a mission planner, and a mission control. The mission planner may be capable of generating a mission for the number of robotic machine groups. The mission control may be capable of executing the mission using the number of robotic machine groups.",G05D 1/02; G05D 1/00,"THE BOEING COMPANY; JANG, Jung, Soon; VIAN, John, Lyle; CLARK, Gregory, John; SAAD, Emad","JANG, Jung, Soon; VIAN, John, Lyle; CLARK, Gregory, John; SAAD, Emad","12/560,569 16.09.2009 US; 12/479,667 05.06.2009 US",JP-2012513956; CN-201080024925.X; EP-2010731840; CA-2760693
WO2019219964,PCT/EP2019/062912,20.05.2019,WO/2019/219964,21.11.2019,WO,REINFORCEMENT LEARNING SYSTEMS COMPRISING A RELATIONAL NETWORK FOR GENERATING DATA ENCODING RELATIONSHIPS BETWEEN ENTITIES IN AN ENVIRONMENT,"A neural network system for reinforcement learning is proposed, including an input network for extracting, from state data, respective entity data for each a plurality of entities which are present, or at least potentially present, in the environment. The entity data describes the entity. The neural network contains a relational network for parsing this data, which includes one or more attention blocks which may be stacked to perform successive actions on the entity data. The attention blocks each include a respective transform network for each of the entities. The transform network for each entity is able to transform data which the transform network receives for the entity into modified entity data for the entity, based on data for a plurality of the other entities. An output network is arranged to receive data output by the relational network, and use the received data to select a respective action (e.g. an action from a predefined space of possible actions.",G06N 3/04; G06N 3/00; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"LI, Yujia; BAPST, Victor Constant; ZAMBALDI, Vinicius; RAPOSO, David Nunes; SANTORO, Adam Anthony","62/673,806 18.05.2018 US",
WO2019083779,PCT/US2018/056132,16.10.2018,WO/2019/083779,02.05.2019,WO,SECURE MESSAGING SYSTEMS AND METHODS,"Systems and methods for secure messaging and automation are disclosed herein. An example method includes providing, by an application server layer, a user-facing application that accesses a data retention system and a predictive analytics system through a web services layer, the user-facing application being secured through use of a security token cached on a web browser that provides the user-facing application, establishing a security protocol or security token utilized between the application server layer and the web services layer that is different from the security token cached on the web browser; and performing asynchronous processing based on user interaction with a goal-based planning application that processes data from a plurality of user accounts.",G06F 9/455; G06F 21/00; G06F 21/55; G06Q 40/06; H04L 9/32,BRIGHTPLAN LLC,"DE BEER, Marthin; SHAH, Krutarth; ROBINSON, Larry","15/796,613 27.10.2017 US",
WO2019180452,PCT/GB2019/050816,21.03.2019,WO/2019/180452,26.09.2019,WO,EMOTION DATA TRAINING METHOD AND SYSTEM,"The present invention relates to a computer implemented method for training one or more parameters of a model. More particularly, the present invention relates to a computer implemented method for training one or more parameters of a model based on emotion signals. Aspects and/or embodiments seek to provide a computer implemented method which can calculate and/or predict emotion signals for training software implementations of mathematical models or machine learned models based on these emotion signals.",G10L 25/51,LIMBIC LIMITED,"HARPER, Ross Edward Francis; DE VRIES, Sebastiaan",1804537.7 21.03.2018 GB; 1901158.4 28.01.2019 GB,
WO2018094590,PCT/CN2016/106857,23.11.2016,WO/2018/094590,31.05.2018,WO,METHOD AND APPARATUS FOR OPTIMIZING A TARGET WORKING LINE,"A method and an apparatus for optimizing a target working line (110, 210) are disclosed. The target working line (110, 210) includes at least one robot (112, 212) manipulator, at least one conveyor (111, 211) and at least one item (113, 213) on the conveyor (111, 211) to be displaced by the robot (112, 212) manipulator. The method includes: obtaining an evaluation model(140, 400) for the target working line (110, 210) (301), the evaluation model (140, 400) yielding an overall success rate of moving the item (113, 213) from one conveyor (111, 211) to another conveyor (111, 211) based on at least one measuring parameter, the measuring parameter being a physical attribute of the target working line (110, 210); yielding the overall success rate for the target working line (110, 210) as a function of a value for the measuring parameter for the target working line (110, 210) (302); and in case that the yielded overall success rate is lower than a predetermined threshold rate(303), updating a value for a configuring parameter based on the overall success rate (304), the configuring parameter corresponding to the measuring parameter, and the configuring parameter being states of the working line (110, 210). The optimization of the evaluation model (140, 400) does not require an implementation of an on-site process or an involvement of an experienced engineer or worker. Instead, simulation software can be used to obtain customized parameters used for the target working line (110, 210), resulting in an increased success rate within a short period of time.",G05B 11/01; B25J 9/16,"ABB SCHWEIZ AG; WANG, Ling; CHENG, Shaojie; FRASER, Roy; XU, Yan; YEO, Wenqi; WU, Yanlai","WANG, Ling; CHENG, Shaojie; FRASER, Roy; XU, Yan; YEO, Wenqi; WU, Yanlai",,CN-201680089450.X; EP-2016922152
WO2014194345,PCT/AU2014/000059,30.01.2014,WO/2014/194345,11.12.2014,WO,"REAL-TIME ROTATION, SHIFT, SCALE AND SKEW VISUAL RECOGNITION SYSTEM","A method of rapidly identifying an object (3, 5) by a battery-powered apparatus (1) using an artificial neural network (14). An image (6) of the object (3, 5) is captured by an image capturing unit (8). The captured image (6) is then processed by an image processing unit (12) to be in a format that the artificial neural network (14) is able to process. The processed captured image is projected onto the artificial neural network which produces a Time Series Signature (TSS) pattern. A pattern identification unit (16) then identifies the object (3, 5) based on the generated TSS pattern.",G06T 1/40; G06F 15/18; G06T 7/00,NEWSOUTH INNOVATIONS PTY LIMITED,"AFSHAR, Saeed; HAMILTON, Tara Julia",2013900288 30.01.2013 AU,AU-2014277600
WO2020064873,PCT/EP2019/075933,25.09.2019,WO/2020/064873,02.04.2020,WO,IMITATION LEARNING USING A GENERATIVE PREDECESSOR NEURAL NETWORK,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for training an action selection policy neural network. In one aspect, a method comprises: obtaining an expert observation; processing the expert observation using a generative neural network system to generate a given observation – given action pair, wherein the generative neural network system has been trained to be more likely to generate a particular observation – particular action pair if performing the particular action in response to the particular observation is more likely to result in the environment later reaching the state characterized by a target observation; processing the given observation using the action selection policy neural network to generate a given action score for the given action; and adjusting the current values of the action selection policy neural network parameters to increase the given action score for the given action.",G06N 3/04; G06N 3/08; G06N 3/00; G06N 7/00,DEEPMIND TECHNOLOGIES LIMITED,"VECERIK, Mel; SCHROECKER, Yannick; SCHOLZ, Karl Jonathan","62/737,866 27.09.2018 US",
WO2020033975,PCT/US2019/046233,12.08.2019,WO/2020/033975,13.02.2020,WO,IMAGE ANALYSIS USING MACHINE LEARNING AND HUMAN COMPUTATION,"Methods, systems, and computer readable media for analyzing an image using machine learning and human computation. A method for analyzing an image includes providing, via multiple instances of an interactive application (334) for analysis of the image, multiple instances, respectively, of the image and receiving, via the interactive application, data (240) from results of analyses of the image including multiple sets of user inputs from the analyses of the multiple instances of the image, respectively. The multiple sets of user inputs are from multiple users, respectively and the multiple users are associated with the multiple instances of the interactive application, respectively. The method further includes processing the received data to identify areas of interest within the image based on the multiple sets of user inputs and analyzing the image using a machine learning algorithm (245) to identify structures in the image based on the identified areas of interest within the image.",G06F 19/00,SOUTHERN METHODIST UNIVERSITY; RETINA FOUNDATION OF THE SOUTHWEST,"CLARK, Corey; CSAKY, Karl","62/717,681 10.08.2018 US; 16/538,662 12.08.2019 US",
WO2018106613,PCT/US2017/064558,04.12.2017,WO/2018/106613,14.06.2018,WO,PREDICTING A SEARCH ENGINE RANKING SIGNAL VALUE,"Methods, systems, and apparatus including computer programs encoded on a computer storage medium, for augmenting search engine index that indexes resources from a collection of resources. In one aspect, a method of augmenting a search engine index that indexes resources from a collection of resources includes the actions of identifying a resource, in the collection of resources, that is indexed in the search engine index for which a value of a search engine ranking signal is not available; processing data from the resource using a machine learning model, the machine learning model being configured to: process the data to predict a value of the search engine ranking signal for the resource; and updating the search engine index by associating the predicted value of the search engine ranking signal with the resource in the search engine index.",G06F 17/30,GOOGLE LLC,"ARRIZABALAGA, Javier, Spagnolo; NUHN, Malte; LE, Quoc, V.; DUCKWORTH, Daniel; HEILER, Matthias","15/369,849 05.12.2016 US",CN-201780074815.6
EP248178206,18209351,29.11.2018,3509017,10.07.2019,EP,EFFICIENT CONVOLUTION IN MACHINE LEARNING ENVIRONMENTS,"A mechanism is described for facilitating smart convolution in machine learning environments. An apparatus of embodiments, as described herein, includes one or more processors including one or more graphics processors, and detection and selection logic to detect and select input images having a plurality of geometric shapes associated with an object for which a neural network is to be trained. The apparatus further includes filter generation and storage logic (""filter logic"") to generate weights providing filters based on the plurality of geometric shapes, where the filter logic is further to sort the filters in filter groups based on common geometric shapes of the plurality of geographic shapes, and where the filter logic is further to store the filter groups in bins based on the common geometric shapes, wherein each bin corresponds to a geometric shape.",G06N 3/04; G06N 3/063; G06N 3/08,INTEL CORP,SRIVASTAVA DHAWAL,201715859487 30.12.2017 US,
EP219994053,17203852,27.11.2017,3333851,13.06.2018,EP,AUTOMATED OBJECT AND ACTIVITY TRACKING IN A LIVE VIDEO FEED,"An apparatus is provided for automated object and activity tracking in a live video feed. The apparatus receives and processes a live video feed to identify a plurality of objects and activities therein. The apparatus also generates natural language text that describes a storyline of the live video feed using the plurality of objects and activities so identified. The live video feed is processed using computer vision, natural language processing and machine learning, and a catalog of identifiable objects and activities. The apparatus then outputs the natural language text audibly or visually with a display of the live video feed.",G11B 27/28; G06K 9/00; G11B 27/031,BOEING CO,PAN JAN WEI; LEVCHUK YURI; JORGENSEN ZACHARY,201615374463 09.12.2016 US,
WO2019195593,PCT/US2019/025856,04.04.2019,WO/2019/195593,10.10.2019,WO,EFFICIENT AND SCALABLE THREE-DIMENSIONAL POINT CLOUD SEGMENTATION FOR NAVIGATION IN AUTONOMOUS VEHICLES,"Efficient and scalable three-dimensional point cloud segmentation. In an embodiment, a three-dimensional point cloud is segmented by adding points to a spatial hash. For each unseen point, a cluster is generated, the unseen point is added to the cluster and marked as seen, and, for each point that is added to the cluster, the point is set as a reference, a reference threshold metric is computed, all unseen neighbors are identified based on the reference threshold metric, and, for each identified unseen neighbor, the unseen neighbor is marked as seen, a neighbor threshold metric is computed, and the neighbor is added or not added to the cluster based on the neighbor threshold metric. When the cluster reaches a threshold size, it may be added to a cluster list. Objects may be identified based on the cluster list and used to control autonomous system(s).",G06K 9/34; G06K 9/62,"APEX.AI, INC.","HO, Christopher","62/653,438 05.04.2018 US",
WO2018002862,PCT/IB2017/053902,29.06.2017,WO/2018/002862,04.01.2018,WO,CLASSIFYING HORMONE RECEPTOR STATUS OF MALIGNANT TUMOROUS TISSUE FROM BREAST THERMOGRAPHIC IMAGES,"What is disclosed is a system and method for classifying the hormone receptor status of malignant tumorous tissue identified in a thermographic image of a breast. One embodiment of the present method involves the following. First, receive thermographic image(s) of both breasts of a patient with a malignant tumorous region and analyzing the image(s) to define a boundary contour of the breast. Then, the breast regions are segment into regions of elevated temperature. A function of first probability mass function Q, f(Q), is determined based on temperatures of pixels within a first segmented region. A function of the second probability mass function P,f(P), is determined based on temperatures of pixels within a second region. A distance measure between the two functions f(Q) and f(P) is calculated and provided to a classifier trained to classify the malignant tissue as hormone receptor positive, and negative otherwise, based on the distance measure.",A61B 5/01; G01N 33/574; G01N 25/72,NIRAMAI HEALTH ANALYTIX PVT. LTD.,"VENKATARAMANI, Krithika; TEJA KAKILETI, Siva; J. MADHU, Himanshu","62/356,208 29.06.2016 US",EP-2017819463; JP-2018567047
WO2018112795,PCT/CN2016/111311,21.12.2016,WO/2018/112795,28.06.2018,WO,LARGE SCALE CNN REGRESSION BASED LOCALIZATION VIA TWO-DIMENSIONAL MAP,A processing apparatus comprising compute logic to train a convolutional neural network (CNN) to perform autonomous re-localization for a service robot or mobile device. An apparatus comprises an image processor to process visual data received via a sensor and a general purpose graphics processing engine perform camera pose estimation for image data and generate a transformation matrix to transform positions of camera pose estimations to positions within a human readable map of the location. The images and transformed positions are uses to train the CNN to perform re-localization.,G06T 7/00; G09B 29/00; G01C 21/00,"INTEL CORPORATION; LIU, Zhongxuan","LIU, Zhongxuan",,CN-201680091003.8
WO2010053743,PCT/US2009/062119,26.10.2009,WO/2010/053743,14.05.2010,WO,LONG TERM ACTIVE LEARNING FROM LARGE CONTINUALLY CHANGING DATA SETS,"Methods and systems are disclosed for autonomously building a predictive model of outcomes. A most-predictive set of signals Sk is identified out of a set of signals s1, s2,..., SD for each of one or more outcomes ok. A set of probabilistic predictive models Ôk = Mk(Sk) is autonomously learned, where Ôk is a prediction of outcome ok derived from the model Mk that uses as inputs values obtained from the set of signals Sk. The step of autonomously learning is repeated incrementally from data that contains examples of values of signals s1, s2,..., sD and corresponding outcomes o1, o2,..., oK. Various embodiments are also disclosed that apply predictive models to various physiological events and to autonomous robotic navigation.",G06F 15/18,"THE REGENTS OF THE UNIVERSITY OF COLORADO; GRUDIC, Gregory Zlatko; MOULTON, Steven Lee","GRUDIC, Gregory Zlatko; MOULTON, Steven Lee","61/109,490 29.10.2008 US; 61/166,472 03.04.2009 US; 61/166,486 03.04.2009 US; 61/166,499 03.04.2009 US; 61/252,978 19.10.2009 US",EP-2009825222; US-13126727; CA-2775675
WO2018187712,PCT/US2018/026497,06.04.2018,WO/2018/187712,11.10.2018,WO,"ADAPTIVE, INTERACTIVE, AND COGNITIVE REASONER OF AN AUTONOMOUS ROBOTIC SYSTEM","An artificial intelligence problem is solved using an artificial intelligence memory graph data structure and a lexical database to identify supporting knowledge. A natural language input is received and classified into components. A starting node of an artificial intelligence memory graph data structure, which comprises one or more data nodes, is selected to begin a search for one or more supporting knowledge data nodes associated with the classified components. Starting at the starting node, the artificial intelligence memory graph data structure is searched using a lexical database to identify the one or more supporting knowledge data nodes. An artificial intelligence problem is identified and solved using the one or more identified supporting knowledge data nodes of the artificial intelligence memory graph data structure.",G06F 17/20; G06F 17/28; G06N 5/02; G06N 5/04; G10L 15/22; G06K 9/62; G06Q 30/02,"AIBRAIN, INC.","SHINN, Hong, Shik; HONG, Eunmi; LIM, Byoung-kwon; LEE, Cheogan","15/946,646 05.04.2018 US; 62/482,631 06.04.2017 US",
WO2019127233,PCT/CN2017/119463,28.12.2017,WO/2019/127233,04.07.2019,WO,METHODS AND APPARATUS TO SIMULATE SENSOR DATA,"Methods, apparatus, systems, and articles of manufacture to simulate sensor data. An example apparatus includes a noise characteristic identifier to extract a noise characteristic associated with a feature present in first sensor data obtained by a physical sensor. A feature identifier is to identify a feature present in second sensor data. The second sensor data is generated by an environment simulator (240) simulating a virtual representation of the real sensor. A noise simulator is to synthesize noise-adjusted simulated sensor data (260) based on the feature identified in the second sensor data and the noise characteristic associated with the feature present in the first sensor data.",G06T 7/00,"INTEL CORPORATION; WANG, Zhigang; SHI, Xuesong","WANG, Zhigang; SHI, Xuesong",,
WO2020016337,PCT/EP2019/069326,18.07.2019,WO/2020/016337,23.01.2020,WO,NEURAL NETWORKS HAVING REDUCED NUMBER OF PARAMETERS,"A method is provided. The method comprises: - providing a neural network having a set of weights (W) and being configured to receive an input data structure (x) for generating a corresponding output array (y(x,W)) according to values of said set of weights - training (200) the neural network (100) to obtain a trained neural network (100''), said training comprising setting values of the set of weights by means of a gradient descent algorithm which exploits a cost function comprising a loss term and a regularization term; - deploying the trained neural network (100'') on a device (620) through a communication network (650); - using the deployed trained neural network (100'') on the device, wherein: the regularization term is based on a rate of change of elements of the output array caused by variations of the set of weights values.",G06N 3/08; G06N 3/04,TELECOM ITALIA S.P.A.; POLITECNICO DI TORINO,"FIANDROTTI, Attilio; FRANCINI, Gianluca; LEPSØY, Skjalg; TARTAGLIONE, Enzo",102018000007377 20.07.2018 IT,
WO2019099622,PCT/US2018/061216,15.11.2018,WO/2019/099622,23.05.2019,WO,AUTONOMOUS VEHICLE LANE BOUNDARY DETECTION SYSTEMS AND METHODS,"Systems and methods for facilitating communication with autonomous vehicles are provided. In one example embodiment, a computing system can obtain rasterized LIDAR data associated with a surrounding environment of an autonomous vehicle. The rasterized LIDAR data can include LIDAR image data that is rasterized from a LIDAR point cloud. The computing system can access data indicative of a machine-learned lane boundary detection model. The computing system can input the rasterized LIDAR data associated with the surrounding environment of the autonomous vehicle into the machine-learned lane boundary detection model. The computing system can obtain an output from the machine-learned lane boundary detection model. The output can be indicative of one or more lane boundaries within the surrounding environment of the autonomous vehicle.",G06K 9/00,"UATC, LLC","BAI, Min; MATTYUS, Gellert Sandor; HOMAYOUNFAR, Namdar; WANG, Shenlong; LAKSHMIKANTH, Shrinidhi Kowshika; URTASUN, Raquel; MA, Wei-Chiu","62/586,725 15.11.2017 US; 62/586,741 15.11.2017 US; 16/122,267 05.09.2018 US; 16/122,413 05.09.2018 US",
WO2018126073,PCT/US2017/068826,28.12.2017,WO/2018/126073,05.07.2018,WO,DEEP LEARNING HARDWARE,"A network of matrix processing units (MPUs) is provided on a device, where each MPU is connected to at least one other MPU in the network, and each MPU is to perform matrix multiplication operations. Computer memory stores tensor data and a master control central processing unit (MCC) is provided on the device to receive an instruction from a host device, where the instruction includes one or more tensor operands based on the tensor data. The MCC invokes a set of operations on one or more of the MPUs based on the instruction, where the set of operations includes operations on the tensor operands. A result is generated from the set of operations, the result embodied as a tensor value.",G06N 3/063; G06N 3/04,INTEL CORPORATION,"LAU, Horace H.; ARORA, Prashant; WU, Olivia K.; WERNER, Tony L.; KLOSS, Carey K.; KHOSROWSHAHI, Amir; YANG, Andrew; KALAIAH, Aravind; KORTHIKANTI, Vijay Anand R.","62/440,980 30.12.2016 US",EP-2017888101
WO2006091111,PCT/NZ2006/000025,22.02.2006,WO/2006/091111,31.08.2006,WO,A METHOD OF GENERATING BEHAVIOUR FOR A GRAPHICS CHARACTER AND ROBOTIC DEVICES,"The present invention relates to a method for determining behaviour of an autonomous entity within an environment using a weighted memory (14) of observed objects (3, 4, 6-9), including the steps: of processing the weighted memory (14); generating an image (1) of the environment from the perspective of the entity; recognising visible objects (20) within the image (1) from a list of object types; storing data (19) about the visible objects (20) within the memory (18) and processing object data (19) extracted from the memory (18) in accordance with the object's type (11) using an artificial intelligence engine (63) in order to determine behaviour of the entity. A system and software for determining behaviour of an autonomous entity are also disclosed.",G06T 1/40; G06K 9/62; G06T 13/00; G06T 15/70,"REGELOUS, Stephen, John; REGELOUS, Stephen, Noel","REGELOUS, Stephen, John; REGELOUS, Stephen, Noel",538487 25.02.2005 NZ,EP-6716802; US-11884866
WO2019110824,PCT/EP2018/084035,07.12.2018,WO/2019/110824,13.06.2019,WO,USING SILHOUETTE FOR FAST OBJECT RECOGNITION,"An object recognition method comprising the steps of obtaining an image from an image sensor and a 3D point cloud from a depth sensor; synchronizing the image and the 3D point cloud; 3D point clustering to separate objects from the 3D point cloud; extracting silhouettes by segmentation of the image using the 3D point clustering, and contour detection of the separated objects into the segmented image; recognizing silhouette by transforming each detected contour into a silhouette descriptor, and classifying these silhouette descriptors into recognized objects using a trained neural network for object recognition.",G06K 9/00; G06K 9/62,IMRA EUROPE S.A.S.,"BOUGNOUX, Sylvain",1761804 07.12.2017 FR,
WO2019048506,PCT/EP2018/073914,05.09.2018,WO/2019/048506,14.03.2019,WO,TRAINING METHODS FOR MACHINE LEARNING ASSISTED OPTICAL PROXIMITY ERROR CORRECTION,A method including: obtaining an optical proximity correction for a spatially shifted version of a training design pattern (5000); and training a machine learning model (5200) configured to predict optical proximity corrections for design patterns using data (5051; 5053) regarding the spatially shifted version of the training design pattern and data (5041; 5043) based on the optical proximity corrections for the spatially shifted version of the training design pattern.,G03F 7/20; G03F 1/36; G06F 17/50; G06N 99/00,ASML NETHERLANDS B.V.,"SU, Jing; LU, Yen-Wen; LUO, Ya","62/556,246 08.09.2017 US; 62/725,734 31.08.2018 US",
WO2010064907,PCT/NL2009/050728,01.12.2009,WO/2010/064907,10.06.2010,WO,METHOD FOR RECOGNIZING OBJECTS IN A SET OF IMAGES RECORDED BY ONE OR MORE CAMERAS,"Method for improving the visibly of objects and recognizing objects in a set of images recorded by one or more cameras, the images of said set of images being made from mutual different geometric positions, the method comprising the steps or recording a set or subset of images by means of one camera which is moved rather freely and which makes said images during its movement, thus providing an array of subsequent images, estimating the camera movement between subsequent image recordings, also called ego-motion hereinafter, based on features of those recorded images, registering the camera images using a synthetic aperture method, recognizing said objects.",G06T 7/20; G06T 7/00,"NEDERLANDSE ORGANISATIE VOOR TOEGEPAST-NATUURWETENSCHAPPELIJK ONDERZOEK TNO; VAN DER MARK, Wannes; TETTELAAR, Peter; DEN HOLLANDER, Richard, Jacobus, Maria","VAN DER MARK, Wannes; TETTELAAR, Peter; DEN HOLLANDER, Richard, Jacobus, Maria",08170358.9 01.12.2008 EP,US-13132007; EP-2009764617
WO2018013200,PCT/US2017/029699,26.04.2017,WO/2018/013200,18.01.2018,WO,DEEP NEURAL NETWORK FOR IRIS IDENTIFICATION,"Systems and methods for iris authentication are disclosed. In one aspect, a deep neural network (DNN) with a triplet network architecture can be trained to learn an embedding (e.g., another DNN) that maps from the higher dimensional eye image space to a lower dimensional embedding space. The DNN can be trained with segmented iris images or images of the periocular region of the eye (including the eye and portions around the eye such as eyelids, eyebrows, eyelashes, and skin surrounding the eye). With the triplet network architecture, an embedding space representation (ESR) of a person's eye image can be closer to the ESRs of the person's other eye images than it is to the ESR of another person's eye image. In another aspect, to authenticate a user as an authorized user, an ESR of the user's eye image can be sufficiently close to an ESR of the authorized user's eye image.",G06K 9/20; G06K 9/40; G06K 9/00; G06K 9/36,"MAGIC LEAP, INC.","SPIZHEVOY, Alexey; KAEHLER, Adrian; BRADSKI, Gary",2016128792 14.07.2016 RU,KR-1020197004054; JP-2019501636; EP-2017828103
WO2008144638,PCT/US2008/064098,19.05.2008,WO/2008/144638,27.11.2008,WO,SYSTEMS AND METHODS OF A STRUCTURED GRAMMAR FOR A SPEECH RECOGNITION COMMAND SYSTEM,"In embodiments of the present invention, a system and method for enabling a user to interact with a computer platform using a voice command may comprise the steps of defining a structured grammar for handling a global voice command, defining a global voice command of the structured grammar wherein the global voice command enables access to an object of the computer platform using a single command, and mapping at least one function of the object to the global voice command, wherein upon receiving voice input from the user of the computer platform the object recognizes the global voice command and controls the function.",G10L 15/22; G10L 15/00,"REDSTART SYSTEMS INC.; PATCH, Kimberly","PATCH, Kimberly","60/938,599 17.05.2007 US",
WO2017090954,PCT/KR2016/013471,22.11.2016,WO/2017/090954,01.06.2017,WO,ELECTRONIC DEVICE AND OPERATING METHOD THEREOF,A method of operating an electronic device according to various example embodiments of the present disclosure may include: acquiring a plurality of text messages; acquiring a keyword corresponding to the plurality of text messages by analyzing each of the plurality of text messages; transmitting a query including the keyword; and performing an operation corresponding to an analysis result of the keyword after receiving the analysis result of the keyword.,G06F 17/30; G06F 17/28; G06N 99/00,"SAMSUNG ELECTRONICS CO., LTD.","LEE, Hae-Jun; RHO, Ji-Hyun; KIM, Deok-Ho",10-2015-0165070 24.11.2015 KR; 10-2016-0107179 23.08.2016 KR,EP-2016868850
WO2019155061,PCT/EP2019/053315,11.02.2019,WO/2019/155061,15.08.2019,WO,DISTRIBUTIONAL REINFORCEMENT LEARNING USING QUANTILE FUNCTION NEURAL NETWORKS,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for selecting an action to be performed by a reinforcement learning agent interacting with an environment. In one aspect, a method comprises: receiving a current observation; for each action of a plurality of actions: randomly sampling one or more probability values; for each probability value: processing the action, the current observation, and the probability value using a quantile function network to generate an estimated quantile value for the probability value with respect to a probability distribution over possible returns that would result from the agent performing the action in response to the current observation; determining a measure of central tendency of the one or more estimated quantile values; and selecting an action to be performed by the agent in response to the current observation using the measures of central tendency for the actions.",G06N 3/04; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"OSTROVSKI, Georg; DABNEY, William Clinton","62/628,875 09.02.2018 US; 62/646,154 21.03.2018 US",
WO2016182674,PCT/US2016/027620,14.04.2016,WO/2016/182674,17.11.2016,WO,ADAPTIVE SELECTION OF ARTIFICIAL NEURAL NETWORKS,A method of adaptively selecting a configuration for a machine learning process includes determining current system resources and performance specifications of a current system. A new configuration for the machine learning process is determined based at least in part on the current system resources and the performance specifications. The method also includes dynamically selecting between a current configuration and the new configuration based at least in part on the current system resources and the performance specifications.,G06N 3/00,QUALCOMM INCORPORATED,"LIN, Dexu; ANNAPUREDDY, Venkata Sreekanta Reddy; TALATHI, Sachin Subhash; STASKAUSKAS, Mark; VARTAK, Aniket; TOWAL, Regan Blythe; JULIAN, David Jonathan; SARAH, Anthony","62/159,068 08.05.2015 US; 14/878,689 08.10.2015 US",
WO2019023487,PCT/US2018/043943,26.07.2018,WO/2019/023487,31.01.2019,WO,ARMBAND FOR TRACKING HAND MOTION USING ELECTRICAL IMPEDANCE MEASUREMENT,"A system includes a wearable device including sensors arranged at different locations on the wearable device. Each sensor measures electrical signals transmitted from a wrist or arm of a user. A position computation circuit is coupled to the sensors. The position computation circuit computes, using information derived from the electrical signals with a machine learning model, an output that describes a hand position of a hand of the wrist or arm of the user.",G06F 3/01; G06F 3/00; G06F 1/16; G06F 3/0346; G02B 27/01; G06N 99/00,"FACEBOOK TECHNOLOGIES, LLC","MU, Beipeng; DE NARDI, Renzo; NEWCOMBE, Richard Andrew; KING, Raymond; GANDER, Evan Paul; WANG, Robert Y.","15/661,317 27.07.2017 US",EP-2018837872
WO2019068235,PCT/CN2017/109551,06.11.2017,WO/2019/068235,11.04.2019,WO,METHOD OF PREDICTION OF A STATE OF AN OBJECT IN THE ENVIRONMENT USING AN ACTION MODEL OF A NEURAL NETWORK,"A method, device and system of prediction of a state of an object in the environment using an action model of a neural network. In accordance with one aspect, a control system for an object comprises a processor, a plurality of sensors coupled to the processor for sensing a current state of the object and an environment in which the object is located, and a first neural network coupled to the processor. One or more predicted subsequent states of the object in the environment are determined using an action model of the neural network and a current state of the object in the environment and a plurality of action sequences. The action model comprises a mapping of states of the object in the environment and actions performed by the object for each state to predicted subsequent states of the object in the environment.",B60W 30/14; G06N 3/04; G05D 1/00,"HUAWEI TECHNOLOGIES CO., LTD.","YAO, Hengshuai; NOSRATI, Seyed Masoud; CHEN, Hao; YADMELLAT, Peyman; ZHANG, Yunfei","15/725,043 04.10.2017 US",
EP212505526,17181575,17.07.2017,3284563,21.02.2018,EP,PICKING SYSTEM,"A picking system includes a shape obtainer, a weight estimator, a picking robot, and a controller. The shape obtainer is configured to obtain shape information of an object. The weight estimator is configured to estimate a weight of the object based on the shape information obtained by the shape obtainer. The picking robot is configured to perform a picking operation on the object. The controller is configured to control the picking operation based on the weight estimated by the weight estimator.",B25J 9/16,YASKAWA ELECTRIC CORP,TAKANISHI KANJI; KUTSUKAKE FUMINORI; YAMAMOTO AKIHIRO; ISHIKAWA SHINICHI,2016159901 17.08.2016 JP,
WO2018212918,PCT/US2018/028743,21.04.2018,WO/2018/212918,22.11.2018,WO,HYBRID REWARD ARCHITECTURE FOR REINFORCEMENT LEARNING,"Aspects provided herein are relevant to machine learning techniques, including decomposing single-agent reinforcement learning problems into simpler problems addressed by multiple agents. Actions proposed by the multiple agents are then aggregated using an aggregator, which selects an action to take with respect to an environment. Aspects provided herein are also relevant to a hybrid reward model.",G06N 3/04; G06N 3/08; G06N 3/00,"MICROSOFT TECHNOLOGY LICENSING, LLC","VAN SEIJEN, Harm Hendrik; FATEMI BOOSHEHRI, Seyed Mehdi; LAROCHE, Romain Michel Henri; ROMOFF, Joshua Samuel","62/508,340 18.05.2017 US; 62/524,461 23.06.2017 US; 15/634,914 27.06.2017 US",EP-2018723249
WO2016123201,PCT/US2016/015093,27.01.2016,WO/2016/123201,04.08.2016,WO,"SYSTEMS, DEVICES, AND METHODS FOR ROBOTIC REMOTE SENSING FOR PRECISION AGRICULTURE","The present subject matter relates to systems, devices, and methods for data-driven precision agriculture through close-range remote sensing with a versatile imaging system. This imaging system can be deployed onboard low-flying unmanned aerial vehicles (UAVs) and/or carried by human scouts. Additionally, the present technology stack can include methods for extracting actionable intelligence from the rich datasets acquired by the imaging system, as well as visualization techniques for efficient analysis of the derived data products. In this way, the present systems and methods can help specialty crop growers reduce costs, save resources, and optimize crop yield.",G06K 9/00,THE TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA,"KUMAR, R. Vijay; CROSS, Gareth Benoit; QU, Chao; DAS, Jnaneshwar; MAKINENI, Anurag; MULGAONKAR, Yash Shailesh","62/108,509 27.01.2015 US",US-15545266
WO2017041008,PCT/US2016/050223,02.09.2016,WO/2017/041008,09.03.2017,WO,INTELLIGENT VIRTUAL ASSISTANT SYSTEMS AND RELATED METHODS,"Provided herein are intelligent virtual assistant systems and related methods. The intelligent virtual assistant systems include a processor; and memory coupled to the processor, the memory comprising at least one executable instruction that when executed by the process causes the processor to effectuate operations comprising: receiving at least one input parameters indicative of a plurality of campaigns and a plurality of prompts from at least one campaign applications; determining a campaign flow based on the at least one input parameters; and generating, based on the campaign flow, an intelligent virtual assistance application. The disclosed intelligent virtual assistant systems and related methods can be used for counseling and coaching people, for example children and adults with special needs, such as autism.",G06F 9/44; G06F 15/18; G06F 17/20; G01N 5/04,"TRUE IMAGE INTERACTIVE, INC.","SCHOLAR, Wayne","62/213,276 02.09.2015 US",EP-2016843117; KR-1020187009347; US-15757105
WO2015016988,PCT/US2014/034990,22.04.2014,WO/2015/016988,05.02.2015,WO,OBJECT RECOGNITION AND TRACKING USING A CLASSIFIER COMPRISING CASCADED STAGES OF MULTIPLE DECISION TREES,"An image processor comprises first and second hardware accelerators and is configured to implement a classifier. The classifier in some embodiments comprises a cascaded classifier having a plurality of stages with each such stage implementing a plurality of decision trees. At least one of the first and second hardware accelerators of the image processor is configured to generate an integral image based on a given input image, and the second hardware accelerator is configured to process image patches of the integral image through one or more of a plurality of decision trees of the classifier implemented by the image processor. By way of example, the first and second hardware accelerators illustratively comprise respective front-end and back-end accelerators of the image processor, and an integral image calculator configured to generate the integral image based on the given input image is implemented in one of the front-end accelerator and the back-end accelerator.",G06F 15/18; G06G 7/00,LSI CORPORATION,"SMIRINOV, Maxim; PUSATERI, Michael, A.","61/860,735 31.07.2013 US; 14/212,312 14.03.2014 US; 61/908,260 25.11.2013 US",
WO2011047508,PCT/CN2009/074564,22.10.2009,WO/2011/047508,28.04.2011,WO,EMBEDDED VISION TRACKER AND MOBILE GUIDING METHOD FOR TRACKING SEQUENTIAL DOUBLE COLOR BEACONS ARRAY WITH EXTREMELY WIDE-ANGLE LENS,"An embedded vision tracker and a mobile guiding method (MGM) for tracking sequential beacons array are provided to provide accurately processing for extremely wide-angle lens images for tracking sequential double color beacons array. The embedded vision tracker includes a Digital Signal Processor (DSP 214), a Field-Programmable Gate Array (FPGA 210), a CMOS image sensor (213), a FLASH memory (215), a Synchronous Dynamic Random Access Memory (SDRAM 216) and an Ethernet interface (217). A vision tracking method based on probability approximated by a set of prediction samples of the targets is provided. The embedded vision tracker can be applied to vehicle guidance, an on-board mobile robot, a mobile monitor and other related areas.",G05D 1/02; G01C 21/00,"TIANJIN UNIVERSITY OF TECHNOLOGY; CAO, Zuoliang; ZHANG, Minglu; FU, Huazhu; FENG, Weijia; LIU, Qingjie; ZHANG, Baofeng; ZHU, Junchao","CAO, Zuoliang; ZHANG, Minglu; FU, Huazhu; FENG, Weijia; LIU, Qingjie; ZHANG, Baofeng; ZHU, Junchao",,
WO2014144129,PCT/US2014/028412,14.03.2014,WO/2014/144129,18.09.2014,WO,BIOMARKERS AND METHODS FOR PREDICTING PRETERM BIRTH,"The disclosure provides biomarker panels, methods and kits for determining the probability for preterm birth in a pregnant female. The present disclosure is based, in part, on the discovery that certain proteins and peptides in biological samples obtained from a pregnant female are differentially expressed in pregnant females that have an increased risk of developing in the future or presently suffering from preterm birth relative to matched controls. The present disclosure is further based, in part, on the unexpected discovery that panels combining one or more of these proteins and peptides can be utilized in methods of determining the probability for preterm birth in a pregnant female with relatively high sensitivity and specificity. These proteins and peptides disclosed herein serve as biomarkers for classifying test samples, predicting a probability of preterm birth, monitoring of progress of preterm birth in a pregnant female, either individually or in a panel of biomarkers.",G01N 33/48,"SERA PROGNOSTICS, INC.","HICKOK, Durlin, Edward; BONIFACE, John, Jay; CRITCHFIELD, Gregory, Charles; FLEISCHER, Tracey, Cristine","61/919,586 20.12.2013 US; 61/798,504 15.03.2013 US",EP-2014765203; AU-2014227891; CA-2907120; RU-2015144304
EP233149191,18168442,20.04.2018,3401847,14.11.2018,EP,"TASK EXECUTION SYSTEM, TASK EXECUTION METHOD, TRAINING APPARATUS, AND TRAINING METHOD","Provided is technology for allowing a user to make adjustments according to conditions for work, during the execution of work, in cases where a system realizes execution of a predetermined task using a learning module. A system that uses a learning module to realize execution of a predetermined task includes: a first input unit configured to receive information that is acquired from one or more external systems, and generate at least a portion of information that is to be input to the learning module; an output unit configured to acquire information that is output from the learning module, and generate information that is to be output from the system, the information output from the system being information based on which execution of a predetermined task is to be realized; and a second input unit configured to receive an input from a user so that information that is based on the input from the user is input to at least one of the first input unit, the learning module, and the output unit, and information that is output from the output unit varies based on the input from the user.",G06N 99/00,OMRON TATEISI ELECTRONICS CO,SHIBATA YOSHIYA; MINATO YOSHIHISA,2017093222 09.05.2017 JP,
WO2019190518,PCT/US2018/025054,29.03.2018,WO/2019/190518,03.10.2019,WO,SIMILAR MEDICAL IMAGE SEARCH,"A system for searching for similar medical images includes a reference library in the form of a multitude of medical images, at least some of which are associated with metadata including clinical information relating to the specimen or patient associated with the medical images. A computer system is configured as a search tool for receiving an input image query from a user. The computer system is trained to find one or more similar medical images in the reference library system which are similar to the input image. The reference library is represented as an embedding of each of the medical images projected in a feature space having a plurality of axes, wherein the embedding is characterized by two aspects of a similarity ranking: (1) visual similarity, and (2) semantic similarity such that neighboring images in the feature space are visually similar and semantic information is represented by the axes of the feature space. The computer system supports additional queries from a user to thereby further refine a search for medical images similar to the input image within a search space consisting of the one or more similar medical images.",G06F 17/30; G16H 30/20,GOOGLE LLC,"PENG, Lily; STUMPE, Martin; SMILKOV, Daniel; HIPP, Jason",,
EP283496595,18306104,10.08.2018,3608844,12.02.2020,EP,METHODS FOR TRAINING A CRNN AND FOR SEMANTIC SEGMENTATION OF AN INPUTTED VIDEO USING SAID CRNN,"The present invention relates to a method for training a convolutional recurrent neural network, CRNN, for semantic segmentation in videos; the method being characterized in that it comprises the implementation, by a data processor (11a) of a first server (1a), of steps of:(a) Training from a base of training images already semantically segmented, a first convolutional neural network, CNN;(b) Training from a base of training videos already semantically segmented, a recurrent convolutional neural network, CRNN, corresponding to the first CNN wherein a convolutional layer has been replaced by a recurrent module having a hidden state; said training comprising, for each pair of successive frames (t- 1,t∈1;T<sup>2</sup>) of a video of said base of training videos already semantically segmented:(b1) Warping the internal state of the recurrent layer according to an estimated optical flow between the frames of the pair, so as to adapt the internal state to the motion of pixels between the frames of the pair;(b2) learning parameters of at least the recurrent moduleA method for semantic segmentation of an inputted video is further proposed.",G06N 3/04; G06N 3/08,NAVER CORP,WEINZAEPFEL PHILIPPE,18306104 10.08.2018 EP,
WO2008109665,PCT/US2008/055900,05.03.2008,WO/2008/109665,12.09.2008,WO,FAST SEMANTIC EXTRACTION USING A NEURAL NETWORK ARCHITECTURE,"A system and method for semantic extraction using a neural network architecture includes indexing (102) each word in an input sentence into a dictionary and using these indices to map each word to a d-dimensional vector (the features of which are learned). Together with this, position information for a word of interest {the word to labeled) and a verb of interest (the verb that the semantic role is being predicted for) with respect to a given word are also used. These positions are integrated (106) by employing a linear layer that is adapted to the input sentence. Several linear transformations (108) and squashing functions (110) are then applied to output class probabilities for semantic role labels. All the weights for the whole architecture are trained by backpropagation.",G06F 17/21,"NEC LABORATORIES AMERICA. INC.; COLLOBERT, Ronan","COLLOBERT, Ronan; WESTON, Jason","60/893,712 08.03.2007 US",
WO2017161189,PCT/US2017/022812,16.03.2017,WO/2017/161189,21.09.2017,WO,PARALLEL-HIERARCHICAL MODEL FOR MACHINE COMPREHENSION ON SMALL DATA,"Examples of the present disclosure provide systems and methods relating to a machine comprehension test with a learning-based approach, harnessing neural networks arranged in a parallel hierarchy. This parallel hierarchy enables the model to compare the passage, question, and answer from a variety of perspectives, as opposed to using a manually designed set of features. Perspectives may range from the word level to sentence fragments to sequences of sentences, and networks operate on word-embedding representations of text. A training methodology for small data is also provided.",G06F 17/28; G06N 3/02; G06N 99/00,MALUUBA INC.,"TRISCHLER, Adam; YE, Zheng; YUAN, Xingdi; BACHMAN, Philip","62/309,139 16.03.2016 US",EP-2017714120
WO2019219963,PCT/EP2019/062911,20.05.2019,WO/2019/219963,21.11.2019,WO,NEURAL NETWORKS WITH RELATIONAL MEMORY,"DeepMind Technologies Limited M ay 20, 2019 F&R ref.: 45288-0008WO 2 ABSTRACT A system including one or more computers and one or more storage devices storing instructions that when executed by the one or more computers cause the one or more computers to implement a memory and memory-based neural network is described. The memory is configured to store a respective memory vector at each of a plurality of memory locations in the memory. The memory-based neural network is configured to: at each of a plurality of time steps: receive an input; determine an update to the memory, wherein determining the update comprising applying an attention mechanism over the memory vectors in the memory and the received input; update the memory using the determined update to the memory; and generate an output for the current time step using the updated memory.",G06N 3/04,DEEPMIND TECHNOLOGIES LIMITED,"RAE, Jack William; FAULKNER, Ryan; WEBER, Theophane Guillaume; RAPOSO, David Nunes; SANTORO, Adam Anthony; CHRZANOWSKI, Mike","62/673,818 18.05.2018 US",
WO2017102937,PCT/EP2016/081174,15.12.2016,WO/2017/102937,22.06.2017,WO,METHODS AND SYSTEMS FOR VALIDATING AN AUTONOMOUS SYSTEM THAT INCLUDES A DYNAMIC-CODE MODULE AND A STATIC-CODE MODULE,"Disclosed herein are methods and systems for validating an autonomous system that comprises a static-code module and a dynamic-code module, the method including the steps of performing a code-integrity-validation process on the static-code module and performing a behavior-integrity-validation process on the dynamic-code module. In some embodiments, performing the code-integrity-validation process on the static-code module includes performing a signature-verification process on the static-code module. In some embodiments, performing the behavior-integrity-validation process on the dynamic-code module includes using an encrypted-and-signed test vector. In some embodiments, performing the behavior-integrity-validation process on the dynamic-code module includes selecting a test vector from among a plurality of test vectors, generating a modified test vector at least in part by modifying the selected test vector, and performing the behavior-integrity-validation process on the dynamic-code module using the modified test vector.",G06F 21/51; G06F 21/57; G06N 99/00,NAGRAVISION S.A.,"JANTZ, Scott; SELTZER, Steven","14/970,167 15.12.2015 US",
EP74602675,09851255,10.11.2009,2500847,19.09.2012,EP,OPTIMAL TECHNIQUE SEARCH METHOD AND SYSTEM,"Disclosed are an optimal technique search method and system that can enable a more effective search for optimal techniques for problem solutions than in the past through the use of a neural network employing genetic algorithm. Provided therein are an execution unit (1) that uses a neural network employing a genetic algorithm to search for an optimal technique and which executes operations using said technique, and an evaluation unit (2) that, along with creating initial setting to transmit to said execution unit, evaluates the content of the operations of the execution unit after the operations have been executed and has the execution unit (1) execute operations a plurality of times, and thereby derives as the optimal technique the initial settings that executed the most effective operation when transmitted to the execution unit (1) out of the results derived from said plurality of operation executions. As a result, a small scale and effective optimal technique search becomes possible when using a neural network, as described in [0024] and [0025].",G06N 3/00; G05B 13/02; G06N 3/08,YOSHINOBU MASAYUKI,YOSHINOBU MASAYUKI,2009069139 10.11.2009 JP,
WO2014210368,PCT/US2014/044421,26.06.2014,WO/2014/210368,31.12.2014,WO,SYSTEMS AND METHODS FOR QUANTUM PROCESSING OF DATA,"Systems, methods and aspects, and embodiments thereof relate to unsupervised or semi-supervised features learning using a quantum processor. To achieve unsupervised or semi-supervised features learning, the quantum processor is programmed to achieve Hierarchal Deep Learning (referred to as HDL) over one or more data sets. Systems and methods search for, parse, and detect maximally repeating patterns in one or more data sets or across data or data sets. Embodiments and aspects regard using sparse coding to detect maximally repeating patterns in or across data. Examples of sparse coding include L0 and L1 sparse coding. Some implementations may involve appending, incorporating or attaching labels to dictionary elements, or constituent elements of one or more dictionaries. There may be a logical association between label and the element labeled such that the process of unsupervised or semi-supervised feature learning spans both the elements and the incorporated, attached or appended label.",G06N 99/00,D-WAVE SYSTEMS INC.,"ROSE, Geordie; GILDERT, Suzanne; MACREADY, William, G.; WALLIMAN, Dominic, Christoph","61/841,129 28.06.2013 US; 61/873,303 03.09.2013 US",CN-201480047692.3; EP-2014817299; JP-2016524211
WO2014042646,PCT/US2012/055370,14.09.2012,WO/2014/042646,20.03.2014,WO,ASSOCIATING AN IDENTITY TO A CREATOR OF A SET OF VISUAL FILES,Technologies and implementations for associating a personal identity of a creator to a set of visual files are generally disclosed.,G06K 9/62,"EMPIRE TECHNOLOGY DEVELOPMENT LLC; UR, Shmuel; BUSHINSKY, Shay","UR, Shmuel; BUSHINSKY, Shay",,
WO2019099515,PCT/US2018/061048,14.11.2018,WO/2019/099515,23.05.2019,WO,FULLY CONVOLUTIONAL INTEREST POINT DETECTION AND DESCRIPTION VIA HOMOGRAPHIC ADAPTATION,"Systems, devices, and methods for training a neural network and performing image interest point detection and description using the neural network. The neural network may include an interest point detector subnetwork and a descriptor subnetwork. An optical device may include at least one camera for capturing a first image and a second image. A first set of interest points and a first descriptor may be calculated using the neural network based on the first image, and a second set of interest points and a second descriptor may be calculated using the neural network based on the second image. A homography between the first image and the second image may be determined based on the first and second sets of interest points and the first and second descriptors. The optical device may adjust virtual image light being projected onto an eyepiece based on the homography.",G06K 9/00; G06T 3/40,"MAGIC LEAP, INC.","RABINOVICH, Andrew; DETONE, Daniel; MALISIEWICZ, Tomasz Jan","62/586,149 14.11.2017 US; 62/608,248 20.12.2017 US",
WO2019241022,PCT/US2019/035868,06.06.2019,WO/2019/241022,19.12.2019,WO,PATH DETECTION FOR AUTONOMOUS MACHINES USING DEEP NEURAL NETWORKS,"In various examples, a deep learning solution for path detection is implemented to generate a more abstract definition of a drivable path – without reliance on explicit lane-markings – by using a detection-based approach. Using approaches of the present disclosure, the identification of drivable paths may be possible in environments where conventional approaches are unreliable, or fail – such as where lane markings do not exist or are occluded. The deep learning solution may generate outputs that represent geometries for one or more drivable paths in an environment and confidence values corresponding to path types or classes that the geometries correspond. These outputs may be directly useable by an autonomous vehicle – such as an autonomous driving software stack – with minimal post-processing.",G05D 1/02; G06K 9/62; G06T 7/20,NVIDIA CORPORATION,"TOWAL, Regan Blythe; FAROOQ, Maroof Mohammed; CHINTALAPUDI, Vijay; PARADA, Carolina; NISTER, David","62/684,328 13.06.2018 US; 16/433,994 06.06.2019 US",
WO2017196963,PCT/US2017/031934,10.05.2017,WO/2017/196963,16.11.2017,WO,COMPUTATIONAL METHOD FOR CLASSIFYING AND PREDICTING PROTEIN SIDE CHAIN CONFORMATIONS,"Computational methods for classifying and predicting protein side chain conformations utilizing a data driven scoring function are disclosed. According to some embodiments, the methods may include obtaining structure data representing a plurality of conformations of a compound. The methods may also include determining structural differences among the conformations. The methods may also include classifying, based on the structural differences, the conformations into one or more clusters. The methods may also include determining representative conformations of the clusters, wherein an average structural difference between a representative conformation of a cluster and conformations in the cluster is below a predetermined threshold. The method may further include determining the representative conformations as poses of the compound.",C07K 1/00; G06F 17/50; G06F 19/10; G06F 19/16; G06F 19/22,ACCUTAR BIOTECHNOLOGY INC.,"FAN, Jie; LIU, Ke","62/334,173 10.05.2016 US; 62/357,634 01.07.2016 US; 62/475,328 23.03.2017 US",EP-2017796752
WO2017040691,PCT/US2016/049739,31.08.2016,WO/2017/040691,09.03.2017,WO,SYSTEMS AND METHODS FOR ANALYZING REMOTE SENSING IMAGERY,"Disclosed systems and methods relate to remote sensing, deep learning, and object detection. Some embodiments relate to machine learning for object detection, which includes, for example, identifying a class of pixel in a target image and generating a label image based on a parameter set. Other embodiments relate to machine learning for geometry extraction, which includes, for example, determining heights of one or more regions in a target image and determining a geometric object property in a target image. Yet other embodiments relate to machine learning for alignment, which includes, for example, aligning images via direct or indirect estimation of transformation parameters.",G06K 9/62; G06K 9/66; G06T 1/40; G06N 3/02; H01Q 5/22,"CAPE ANALYTICS, INC.","KOTTENSTETTE, Ryan; LORENZEN, Peter; GEDIKLI, Suat","62/212,424 31.08.2015 US; 62/315,180 30.03.2016 US",EP-2016842927; AU-2016315938
WO2018081640,PCT/US2017/058872,27.10.2017,WO/2018/081640,03.05.2018,WO,PREDICTIVE MODELS FOR VISUALLY CLASSIFYING INSECTS,"Insects can be localized and classified using a predictive model. To begin, image data is obtained that corresponds to the insects.. Using a predictive model, samples of the image data are evaluated to determine whether the image portions include an insect and, if so, into what category the insect should be classified (e.g., male/female, species A/species B, etc.).",G06F 19/00; G06K 9/46; G06K 9/52; G06K 9/62; G06T 7/00,VERILY LIFE SCIENCES LLC,"ZHA, Tiantian; OVADIA, Yaniv; NEWBURGER, Daniel; KRISHNAN, Dilip; LIVNI, Josh; DESNOYER, Mark","62/414,597 28.10.2016 US",SG-11201903022U; CN-201780067066.4; AU-2017350945; EP-2017863802
WO1996008781,PCT/US1995/011365,11.09.1995,WO/1996/008781,21.03.1996,WO,SYSTEM AND METHOD OF AUTOMATICALLY GENERATING CHEMICAL COMPOUNDS WITH DESIRED PROPERTIES,"A computer-based, iterative process for generating chemical entities with defined physical, chemical and/or bioactive properties. During each iteration of the process, a directed diversity chemical library (208) is robotically generated in accordance with robotic synthesis instructions (204); the compounds in the directed diversity chemical library (208) are analyzed to identify compounds with the desired properties; structure-property data (210) are used to select compounds to be synthesized in the next iteration; and new robotic synthesis instructions are automatically generated to control the synthesis of the directed diversity chemical library (208) for the next iteration.",B01J 19/00; C07B 61/00; C07K 1/04; G06F 17/50,"3-DIMENSIONAL PHARMACEUTICALS, INC.","AGRAFIOTIS, Dimitris, K.; BONE, Roger, F.; SALEMME, Francis, R.; SOLL, Richard, M.","08/306,915 16.09.1994 US",EP-1995933748; CA-2199264
WO2019173325,PCT/US2019/020730,05.03.2019,WO/2019/173325,12.09.2019,WO,SYSTEMS AND METHODS FOR SYNERGISTIC SHARING OF ARCHITECTURAL COMPONENTS OF INTELLIGENT AGENTS,"Systems and methods are described for sharing components among intelligent agents, such as robot agents that perform tasks autonomously. The intelligent agents may include functional components implemented in a middleware layer that provides an interface among the functional components. The functional components may include components for sensory information processing, managing goals and tasks, planning tasks, knowledge bases, and effector information processing. The middleware layer of the intelligent agents may include a component sharing layer. The component sharing layer may search for and identify components running on agents of an agent group that satisfy one or more constraints specified by a requesting component. The component sharing layer may establish a connection between the requesting component and the identified component. The requesting component may utilize services of the identified component to complete a goal or task.",G06F 9/455,"TRUSTEES OF TUFTS COLLEGE; SCHEUTZ, Matthias J.","SCHEUTZ, Matthias J.","62/638,752 05.03.2018 US",
WO2012000649,PCT/EP2011/003176,28.06.2011,WO/2012/000649,05.01.2012,WO,METHOD FOR CONTROLLING A LASER PROCESSING OPERATION BY MEANS OF A REINFORCEMENT LEARNING AGENT AND LASER MATERIAL PROCESSING HEAD USING THE SAME,"The present invention relates to a method for controlling a processing operation of a workpiece by means of a Reinforcement Learning (RL) agent unit, comprising the steps of: (a) observing an interaction zone in the workpiece by means of at least one radiation sensor to generate at least one sensor signal st, wherein the workpiece is processed using an actuator having an initial actuator value at; (b) determining a basis function Φ(st) from the set of sensor signals st; (c) determining a reward function rt giving the probability of good results of the processing operation; (d) choosing a next actuator value at+1 on the basis of a policy π depending on the reward function rt and the basis function Φ(st); and (e) repeating the steps (a) to (d) for further time points to perform a RL controlled processing operation.",B23K 26/00; G06T 7/00; G05B 13/00; G05B 19/408,"PRECITEC KG; PRECITEC ITM GMBH; STORK GENANNT WERSBORG, Ingo; GARCEA, Adrian","STORK GENANNT WERSBORG, Ingo; GARCEA, Adrian",10006692.7 28.06.2010 EP; 10012614.3 30.09.2010 EP; 10015914.4 21.12.2010 EP; 11000995.8 08.02.2011 EP; 11001371.1 18.02.2011 EP; 11004209.0 20.05.2011 EP,EP-2011741515; US-13807290
EP260717398,19163040,15.03.2019,3556444,23.10.2019,EP,GAME ENGINE AND ARTIFICIAL INTELLIGENCE ENGINE ON A CHIP,,A63F 13/67; A63F 13/52; G06F 9/30; G06N 3/06; G06T 15/00,TMRW ENTERTAINMENT EUROPE S A R L,YERLI CEVAT,201862643524 15.03.2018 US,
WO2017117568,PCT/US2016/069580,30.12.2016,WO/2017/117568,06.07.2017,WO,ACCELERATED TRAINING OF A MACHINE LEARNING BASED MODEL FOR SEMICONDUCTOR APPLICATIONS,Methods and systems for accelerated training of a machine learning based model for semiconductor applications are provided. One method for training a machine learning based model includes acquiring information for non-nominal instances of specimen(s) on which a process is performed. The machine learning based model is configured for performing simulation(s) for the specimens. The machine learning based model is trained with only information for nominal instances of additional specimen(s). The method also includes re-training the machine learning based model with the information for the non-nominal instances of the specimen(s) thereby performing transfer learning of the information for the non-nominal instances of the specimen(s) to the machine learning based model.,G06N 99/00,KLA-TENCOR CORPORATION,"BHASKAR, Kris; KARSENTI, Laurent; YOUNG, Scott A.; MAHADEVAN, Mohan; ZHANG, Jing; DUFFY, Brian","62/273,985 31.12.2015 US; 15/394,792 29.12.2016 US",IL-259705; JP-2018534670; KR-1020187021817; EP-2016882778
WO2018164717,PCT/US2017/053244,25.09.2017,WO/2018/164717,13.09.2018,WO,SYSTEM AND METHOD FOR TRAINING ARTIFICIAL INTELLIGENCE SYSTEMS USING A SIMA BASED PROCESSOR,A reinforcement learning processor specifically configured to train reinforcement learning agents in the AI systems by the way of implementing an application-specific instruction set is disclosed. The application-specific instruction set incorporates 'Single Instruction Multiple Agents (SIMA)' instructions. SIMA type instructions are specifically designed to be implemented simultaneously on a plurality of reinforcement learning agents which interact with corresponding reinforcement learning environments. The SIMA type instructions are specifically configured to receive either a reinforcement learning agent ID or a reinforcement learning environment ID as the operand. The reinforcement learning processor is designed for parallelism in reinforcement teaming operations. The reinforcement learning processor executing of a plurality of threads associated with an operation or task in parallel.,G06F 15/18,ALPHAICS CORPORATION,"NAGENDRA, Nagaraja","15/455,126 09.03.2017 US; 15/659,501 25.07.2017 US",
WO2019100436,PCT/CN2017/114140,30.11.2017,WO/2019/100436,31.05.2019,WO,METHODS AND SYSTEMS FOR FACE RECOGNITION,"Systems and methods for face recognition are provided. The systems may perform the methods to obtain a neural network comprising a first sub-neural network and a second sub-neural network; generate a plurality of preliminary feature vectors based on an image associated with a human face, the plurality of preliminary feature vectors comprising a color-based feature vector; obtain at least one input feature vector based on the plurality of preliminary feature vectors; generate a deep feature vector based on the at least one input feature vector using the first sub-neural network; and recognize the human face based on the deep feature vector.",G06K 9/00; G06K 9/62; G06N 3/04,"ZHEJIANG DAHUA TECHNOLOGY CO., LTD.","CHENG, Fuyun; HAO, Jingsong",201711174490.7 22.11.2017 CN; 201711176849.4 22.11.2017 CN; 201711174440.9 22.11.2017 CN,
WO2010105214,PCT/US2010/027218,12.03.2010,WO/2010/105214,16.09.2010,WO,QUESTION-ANSWERING SYSTEM AND METHOD BASED ON SEMANTIC LABELING OF TEXT DOCUMENTS AND USER QUESTIONS,"A question-answering system for searching exact answers in text documents provided in the electronic or digital form to questions formulated by user in the natural language is based on automatic semantic labeling of text documents and user questions. The system performs semantic labeling with the help of markers in terms of basic knowledge types, their components and attributes, in terms of question types from the predefined classifier for target words, and in terms of components of possible answers. A matching procedure makes use of mentioned types of semantic labels to determine exact answers to questions and present them to the user in the form of fragments of sentences or a newly synthesized phrase in the natural language. Users can independently add new types of questions to the system classifier and develop required linguistic patterns for the system linguistic knowledge base.",G06F 17/30; G06F 17/20; G06F 17/28; G06F 17/21,"INVENTION MACHINE CORPORATION; TODHUNTER, James; SOVPEL, Igor; PASTANOHAU, Dzianis","TODHUNTER, James; SOVPEL, Igor; PASTANOHAU, Dzianis","61/159,959 13.03.2009 US; 61/159,972 13.03.2009 US",EP-2010751508; JP-2011554249; CN-201080020564.1; KR-1020117023697
WO2019129819,PCT/EP2018/097037,27.12.2018,WO/2019/129819,04.07.2019,WO,"METHOD, APPARATUS, AND SYSTEM FOR GENERATING SYNTHETIC IMAGE DATA FOR MACHINE LEARNING","An approach is provided for generating synthetic image data for machine learning. The approach, for instance,involvesdetermining, by a processor, a set of parameters for indicating an action by one or more objects. The action is a dynamic movement of the one or more objects through a geographic space over a period of time. The approach also involves processing the set of parameters to generate synthetic image data. The synthetic image data includes a computer- generated image sequence of the one or more objects performing the action in the geographic space over the period of time. The approach further involves automatically labeling the synthetic image data with at least one label representing the action, the set of parameters, or a combination thereof. The approach further involves providing the labeled synthetic image data for training or evaluating a machine learning model to detect the action.",G06K 9/62; G06K 9/00,HERE GLOBAL B.V.,"AVIDAN, Avi; LUK-ZILBERMAN, Evgeny","15/858,772 29.12.2017 US",
WO2018058509,PCT/CN2016/101043,30.09.2016,WO/2018/058509,05.04.2018,WO,DYNAMIC NEURAL NETWORK SURGERY,Techniques related to compressing a pre-trained dense deep neural network to a sparsely connected deep neural network for efficient implementation are discussed. Such techniques may include iteratively pruning and splicing available connections between adjacent layers of the deep neural network and updating weights corresponding to both currently disconnected and currently connected connections between the adjacent layers.,G06N 3/08,"INTEL CORPORATION; YAO, Anbang; GUO, Yiwen; LI, Yan; CHEN, Yurong","YAO, Anbang; GUO, Yiwen; LI, Yan; CHEN, Yurong",,
WO2019112912,PCT/US2018/063459,30.11.2018,WO/2019/112912,13.06.2019,WO,SYSTEM AND METHOD OF PREDICTING HUMAN INTERACTION WITH VEHICLES,"Systems and methods for predicting user interaction with vehicles. A computing device receives an image and a video segment of a road scene, the first at least one of an image and a video segment being taken from a perspective of a participant in the road scene and then generates stimulus data based on the image and the video segment. Stimulus data is transmitted to a user interface and response data is received, which includes at least one of an action and a likelihood of the action corresponding to another participant in the road scene. The computing device aggregates a subset of the plurality of response data to form statistical data and a model is created based on the statistical data. The model is applied to another image or video segment and a prediction of user behavior in the another image or video segment is generated.",G06K 9/00; B60W 30/08; B60W 30/095; B60W 30/16; G05D 1/00; G05D 1/02,"PERCEPTIVE AUTOMATA, INC.","ANTHONY, Sam; MISRA, Kshitij; FALLER, Avery","15/830,549 04.12.2017 US",
WO2020062911,PCT/CN2019/090092,05.06.2019,WO/2020/062911,02.04.2020,WO,ACTOR ENSEMBLE FOR CONTINUOUS CONTROL,"A method of training a reinforcement learning agent to output actions from a continuous action space, comprising: providing an actor ensemble that includes a plurality of actor neural networks that each output a respective action from the continuous action space in response to an observed state of an environment; providing a critic neural network that approximates a state-action value function indicating an impact of an action on the environment based on a reward from the environment and the observed state of the environment; training the actor ensemble and the critic neural network to maximize a state-action value from the state-action value function over successive time steps by, in each time step: selecting from the respective actions output by the plurality of actor neural networks the action that will provide a best state-action value from the state-action value function; applying the selected action to the environment; based on an observed state of the environment of in response to the selected action, determine a gradient ascent for the plurality of actor neural networks for updating the parameters of the plurality of actor neural networks and determine a gradient descent for the critic neural network for updating the parameters of the critic neural network.",G06N 3/08,"HUAWEI TECHNOLOGIES CO., LTD.","ZHANG, Shangtong; YAO, Hengshuai; CHEN, Hao","62/736,914 26.09.2018 US",
WO2019234156,PCT/EP2019/064790,06.06.2019,WO/2019/234156,12.12.2019,WO,TRAINING SPECTRAL INFERENCE NEURAL NETWORKS USING BILEVEL OPTIMIZATION,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a neural network having a plurality of network parameters and being configured to process an input data item to generate a feature representation comprising a values for each of a plurality of features of the input data item.",G06N 3/08; G06N 20/10; G06N 5/00,DEEPMIND TECHNOLOGIES LIMITED,"PFAU, David Benjamin; PETERSEN, Stig; AGARWAL, Ashish; BARRETT, David; STACHENFELD, Kimberly","62/681,621 06.06.2018 US",
WO2008086032,PCT/US2008/000364,10.01.2008,WO/2008/086032,17.07.2008,WO,METHOD AND APPARATUS FOR CLASSIFYING MULTIMEDIA ARTIFACTS USING ONTOLOGY SELECTION AND SEMANTIC CLASSIFICATION,"A method and apparatus is provided for automatically classifying a multimedia artifact (204) based on scoring, and selecting the appropriate set of ontologies from among all possible sets of ontologies (206), preferably using a recursive routing selection technique (202). The semantic tagging of the multimedia artifact (204) is enhanced by applying only classifiers (208) from the selected ontology (206), for use in classifying the multimedia artifact (204), wherein the classifiers are selected based on the context of the multimedia artifact (204). One embodiment of the invention, directed to a method for classifying a multimedia artifact (204), uses a specified criteria to select one or more ontologies (206), wherein the specified criteria indicates the comparative similarity between specified characteristics of the multimedia artifact (204) and each ontology (206). The method further comprises scoring and selecting one or more classifiers (208) from a plurality of classifiers (208) that respectively correspond to semantic element of the selected ontologies (206), and evaluating the multimedia artifact (204) using the selected classifiers (208) to determine a classification for the multimedia artifact (204).",G06F 17/30,INTERNATIONAL BUSINESS MACHINES CORPORATION,"NAPHADE, Milind R.; SMITH, John R.; TESIC, Jelena","11/620,838 08.01.2007 US",
WO2019137967,PCT/EP2019/050462,09.01.2019,WO/2019/137967,18.07.2019,WO,METHODS AND APPARATUS TO OPERATE A MOBILE CAMERA FOR LOW-POWER USAGE,"An example mobile camera includes a first convolutional neural network to recognize a first feature in first sensor data in response to the first feature being detected in the first sensor data; a state transitioner to transition the mobile camera from a first feature detection state to a second feature detection state in response to the first convolutional neural network recognizing the first feature, the mobile camera to operate using higher power consumption in the second feature detection state than in the first feature detection state; a second convolutional neural network to recognize a second feature in second sensor data in the second feature detection state; and a communications interface to send to an external device at least one of first metadata corresponding to the first feature or second metadata corresponding to the second feature.",H04N 5/232; H04N 5/225; G10L 15/16; G06K 9/00; G06K 9/62,MOVIDIUS LTD.,"MOLONEY, David; DEHGHANI, Alireza","15/870,007 12.01.2018 US",
EP11221241,09175410,09.11.2009,2259215,08.12.2010,EP,Method and structure for a neural associative memory based on optimal Bayesian learning,"This invention is in the field of machine learning and neural associative memory. In particular the invention discloses a neural associative memory structure for storing and maintaining associations between memory address patterns and memory content patterns using a neural network, as well as methods for storing and retrieving such associations. Bayesian learning is applied to achieve non-linear learning.",G06N 7/00; G06N 3/04,HONDA RES INST EUROPE GMBH,KNOBLAUCH ANDREAS,09161922 04.06.2009 EP; 09175410 09.11.2009 EP,
EP290833613,19197164,13.09.2019,3623118,18.03.2020,EP,"EMOTION RECOGNIZER, ROBOT INCLUDING THE SAME, AND SERVER INCLUDING THE SAME","An emotion recognizer according to an aspect of the present invention includes: an uni-modal preprocessor configured to include a plurality of recognizers for each modal learned to recognize emotion information of a user contained in uni-modal input data; and a multi-modal recognizer configured to merge output data of the plurality of recognizers for each modal, and be learned to recognize the emotion information of the user contained in the merged data, wherein the emotion recognizer outputs a complex emotion recognition result including an emotion recognition result of each of the plurality of recognizers for each modal and an emotion recognition result of the multi-modal recognizer.",B25J 11/00; G06F 40/30; G06K 9/00; G10L 15/26; G10L 25/63,LG ELECTRONICS INC,SHIN YONGKYOUNG; MOON YOONJI; PARK JOONWOO; CHO TAEGIL,20180110500 14.09.2018 KR,
WO2020065024,PCT/EP2019/076213,27.09.2019,WO/2020/065024,02.04.2020,WO,STACKED CONVOLUTIONAL LONG SHORT-TERM MEMORY FOR MODEL-FREE REINFORCEMENT LEARNING,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for controlling an agent interacting with an environment. One of the methods includes obtaining a representation of an observation; processing the representation using a convolutional long short-term memory (LSTM) neural network comprising a plurality of convolutional LSTM neural network layers; processing an action selection input comprising the final LSTM hidden state output for the time step using an action selection neural network that is configured to receive the action selection input and to process the action selection input to generate an action selection output that defines an action to be performed by the agent at the time step; selecting, from the action selection output, the action to be performed by the agent at the time step in accordance with an action selection policy; and causing the agent to perform the selected action.",G06N 3/00; G06N 3/04; G06N 3/08; G06N 7/00,DEEPMIND TECHNOLOGIES LIMITED,"MIRZA MOHAMMADI, Mehdi; GUEZ, Arthur Clement; GREGOR, Karol; KABRA, Rishabh","62/737,821 27.09.2018 US",
WO2018053257,PCT/US2017/051768,15.09.2017,WO/2018/053257,22.03.2018,WO,METHODS AND SYSTEMS OF SPATIOTEMPORAL PATTERN RECOGNITION FOR VIDEO CONTENT DEVELOPMENT,"Providing enhanced video content includes processing at least one video feed through at least one spatiotemporal pattern recognition algorithm that uses machine learning to develop an understanding of a plurality of events and to determine at least one event type for each of the plurality of events. The event type includes an entry in a relationship library detailing a relationship between two visible features. Extracting and indexing a plurality of video cuts from the video feed is performed based on the at least one event type determined by the understanding that corresponds to an event in the plurality of events detectable in the video cuts. Lastly, automatically and under computer control, an enhanced video content data structure is generated using the extracted plurality of video cuts based on the indexing of the extracted plurality of video cuts.",H04N 21/466; H04N 21/44; H04N 21/434; H04N 21/234; H04N 21/25; H04N 21/4223; H04N 21/45; G06N 99/00,"SECOND SPECTRUM, INC.","CHANG, Yu-Han; MAHESWARAN, Rajiv; SU, Jeffrey, Wayne; HOLLINGSWORTH, Noel","62/395,886 16.09.2016 US; 15/586,379 04.05.2017 US; 62/532,744 14.07.2017 US",EP-2017851597
WO2020016868,PCT/IB2019/057338,30.08.2019,WO/2020/016868,23.01.2020,WO,SURGICAL VISUALIZATION AND MONITORING,"A surgical visualization system is disclosed. The surgical visualization system is configured to identify one or more structure(s) and/or determine one or more distances with respect to obscuring tissue and/or the identified structure(s). The surgical visualization system can facilitate avoidance of the identified structure(s) by a surgical device. The surgical visualization system can comprise a first emitter configured to emit a plurality of tissue-penetrating light waves and a second emitter configured to emit structured light onto the surface of tissue. The surgical visualization system can also include an image sensor configured to detect reflected visible light, tissue-penetrating light, and/or structured light. The surgical visualization system can convey information to one or more clinicians regarding the position of one or more hidden identified structures and/or provide one or more proximity indicators. In various instances, a robotic camera of the surgical visualization system can monitor and track one or more tagged structures.",A61B 1/00; A61B 1/04; A61B 1/06; A61B 5/00; A61B 5/107; A61B 34/30; A61B 90/30; A61B 90/00; G01B 11/25; G01N 21/25; G01N 21/31; G01S 17/89,ETHICON LLC,"SCHEIB, Charles J.; RITCHIE, Paul G.; MOORE, Sarah A.; SWAYZE, Jeffrey S.; TALBERT, Joshua D.; YOUNG, Joshua D.; MORENO, Victor C.","62/698,625 16.07.2018 US; 16/128,193 11.09.2018 US",
WO2019222543,PCT/US2019/032732,16.05.2019,WO/2019/222543,21.11.2019,WO,CONTINUOUS RELAXATION OF QUANTIZATION FOR DISCRETIZED DEEP NEURAL NETWORKS,A method for quantizing a neural network includes modeling noise of parameters of the neural network. The method also includes assigning grid values to each realization of the parameters according to a concrete distribution that depends on a local fixed-point quantization grid and the modeled noise and. The method further includes computing a fixed-point value representing parameters of a hard fixed-point quantized neural network.,G06N 3/063; G06N 3/04; G06N 3/08,QUALCOMM INCORPORATED,"LOUIZOS, Christos; REISSER, Matthias; BLANKEVOORT, Tijmen Pieter Frederik; WELLING, Max","20180100211 17.05.2018 GR; 16/413,535 15.05.2019 US",
WO2018085013,PCT/US2017/056072,11.10.2017,WO/2018/085013,11.05.2018,WO,ROBOTIC SENSING APPARATUS AND METHODS OF SENSOR PLANNING,"The present disclosure is directed to a computer-implemented method of sensor planning for acquiring samples via an apparatus including one or more sensors. The computer- implemented method includes defining, by one or more computing devices, an area of interest; identifying, by the one or more computing devices, one or more sensing parameters for the one or more sensors; determining, by the one or more computing devices, a sampling combination for acquiring a plurality of samples by the one or more sensors based at least in part on the one or more sensing parameters; and providing, by the one or more computing devices, one or more command control signals to the apparatus including the one or more sensors to acquire the plurality of samples of the area of interest using the one or more sensors based at least on the sampling combination.",B25J 9/16; G05B 19/401; G05D 1/00,GENERAL ELECTRIC COMPANY,"LIM, Ser, Nam; DIWINSKY, David, Scott; BIAN, Xiao; GRADY, Wayne, Ray; UZUNBAS, Mustafa, Gokhan; KABA, Mustafa, Devrim","15/342,500 03.11.2016 US",JP-2019522860; EP-2017794817; CN-201780080502.1; CA-3041787
WO2019191506,PCT/US2019/024700,28.03.2019,WO/2019/191506,03.10.2019,WO,DETECTING DATA ANOMALIES ON A DATA INTERFACE USING MACHINE LEARNING,"The disclosure provides systems and processes for applying neural networks to detect intrusions and other anomalies in communications exchanged over a data bus between two or more devices in a network. The intrusions may be detected in data being communicated to an embedded system deployed in vehicular or robotic platforms. The disclosed system and process are well suited for incorporation into autonomous control or advanced driver assistance system (ADAS) vehicles including, without limitation, automobiles, motorcycles, boats, planes, and manned and un-manned robotic devices. Data communicated to an embedded system can be detected over any of a variety of data buses. In particular, embodiments disclosed herein are well suited for use in any data communication interface exhibiting the characteristics of a lack of authentication or following a broadcast routing scheme -- including, without limitation, a control area network (CAN) bus.",G06N 3/04; G06F 21/55; H04L 29/06; H04L 12/40; G06N 5/04,NVIDIA CORPORATION,"BATMAZ, Gorkem; DIMISCIO, Nicola; OVERBY, Mark; PETE, Ildiko","62/649,531 28.03.2018 US; 16/368,589 28.03.2019 US",
WO2017201220,PCT/US2017/033218,18.05.2017,WO/2017/201220,23.11.2017,WO,REINFORCEMENT LEARNING USING PSEUDO-COUNTS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a neural network used to select actions to be performed by an agent interacting with an environment. One of the methods includes obtaining data identifying (i) a first observation characterizing a first state of the environment, (ii) an action performed by the agent in response to the first observation, and (iii) an actual reward received resulting from the agent performing the action in response to the first observation; determining a pseudo-count for the first observation; determining an exploration reward bonus that incentivizes the agent to explore the environment from the pseudo-count for the first observation; generating a combined reward from the actual reward and the exploration reward bonus; and adjusting current values of the parameters of the neural network using the combined reward.",G06N 3/04; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"GENDRON-BELLEMARE, Marc; MUNOS, Remi; SRIRAM, Srinivasan","62/339,778 20.05.2016 US",EP-2017726168; JP-2018560871; CN-201780031296.5
WO2008073366,PCT/US2007/025221,10.12.2007,WO/2008/073366,19.06.2008,WO,TARGET OBJECT RECOGNITION IN IMAGES AND VIDEO,"A computer-readable medium for performing target object recognition in images and video includes instructions for receiving target image data including a target object, applying non-negative matrix factorization with enforced sparseness to the target image data to generate target extracted image feature data, training a neural network to identify the target object using the target extracted image feature data to obtain a trained neural network, receiving object image data, applying non-negative matrix factorization with enforced sparseness to the object image data to generate object extracted image feature data, analyzing the object extracted image feature data with the trained neural network to obtain a result indicating whether the presence of the target object is identified in the object image data, and storing the result of analyzing the object extracted image feature data.",G06K 9/62,"SOBAYLI, LLC; AGNIHOTRI, Naveen; BORDEN, Walter; SCHIEFFELIN, David","AGNIHOTRI, Naveen; BORDEN, Walter; SCHIEFFELIN, David","60/873,573 08.12.2006 US",
WO2016150472,PCT/EP2015/056008,20.03.2015,WO/2016/150472,29.09.2016,WO,RELEVANCE SCORE ASSIGNMENT FOR ARTIFICIAL NEURAL NETWORK,"The task of relevance score assignment to a set of items onto which an artificial neural network is applied is obtained by redistributing an initial relevance score derived from the network output, onto the set of items by reversely propagating the initial relevance score through the artificial neural network so as to obtain a relevance score for each item. In particular, this reverse propagation is applicable to a broader set of artificial neural networks and/or at lower computational efforts by performing same in a manner so that for each neuron, preliminarily redistributed relevance scores of a set of downstream neighbor neurons of the respective neuron are distributed on a set of upstream neighbor neurons of the respective neuron according to a distribution function.",G06K 9/00; G06T 1/20; G06N 3/04; G06N 3/08,FRAUNHOFER-GESELLSCHAFT ZUR FÖRDERUNG DER ANGEWANDTEN FORSCHUNG E.V.; TECHNISCHE UNIVERSITÄT BERLIN,"BACH, Sebastian; SAMEK, Wojciech; MÜLLER, Klaus-Robert; BINDER, Alexander; MONTAVON, Grégoire",,CA-2979579; JP-2017567524; RU-2017135085; KR-1020177030274; EP-2015711738
WO2018102717,PCT/US2017/064269,01.12.2017,WO/2018/102717,07.06.2018,WO,DETERMINING STRUCTURE AND MOTION IN IMAGES USING NEURAL NETWORKS,"A system comprising an encoder neural network, a scene structure decoder neural network, and a motion decoder neural network. The encoder neural network is configured to: receive a first image and a second image; and process the first image and the second image to generate an encoded representation of the first image and the second image. The scene structure decoder neural network is configured to process the encoded representation to generate a structure output characterizing a structure of a scene depicted in the first image. The motion decoder neural network configured to process the encoded representation to generate a motion output characterizing motion between the first image and the second image.",G06T 7/269; G06T 7/11; G06K 9/00,GOOGLE LLC,"SCHMID, Cordelia Luise; VIJAYANARASIMHAN, Sudheendra; RICCO, Susanna Maria; SEYBOLD, Bryan Andrew; SUKTHANKAR, Rahul; FRAGKIADAKI, Aikaterini","62/429,637 02.12.2016 US",EP-2017830044; CN-201780076244.X
WO2020055910,PCT/US2019/050469,10.09.2019,WO/2020/055910,19.03.2020,WO,SYSTEMS AND METHODS FOR GRAPH-BASED AI TRAINING,"Graphs are powerful structures made of nodes and edges. Information can be encoded in the nodes and edges themselves, as well as the connections between them. Graphs can be used to create manifolds which in turn can be used to efficiently train more robust Al systems. Systems and methods for graph-based Al training in accordance with embodiments of the invention are illustrated. In one embodiment, a graph interface system including a processor, and a memory configured to store a graph interface application, where the graph interface application directs the processor to obtain a set of training data, where the set of training data describes a plurality of scenarios, encode the set of training data into a first knowledge graph, generate a manifold based on the first knowledge graph, and train an Al model by traversing the manifold.",G06K 9/62; G06N 3/04; G06K 9/46,"DRISK, INC.","STETSON, Robert, Chess; CHAISANGUANTHUM, Kris; FERGUSON, Robert; REVECHKIS, Boris","62/789,955 08.01.2019 US; 62/729,368 10.09.2018 US",
EP232159380,18162142,15.03.2018,3392825,24.10.2018,EP,EXTEND GPU/CPU COHERENCY TO MULTI-GPU CORES,"In an example, an apparatus comprises a plurality of processing unit cores, a plurality of cache memory modules associated with the plurality of processing unit cores, and a machine learning model communicatively coupled to the plurality of processing unit cores, wherein the plurality of cache memory modules share cache coherency data with the machine learning model. Other embodiments are also disclosed and claimed.",G06T 1/20,INTEL CORP,SAKTHIVEL CHANDRASEKARAN; SURTI PRASOONKUMAR; WEAST JOHN C; BAGHSORKHI SARA S; GOTTSCHLICH JUSTIN E; APPU ABHISHEK R; GALOPPO VON BORRIES NICOLAS C; RAY JOYDEEP; SRINIVASA NARAYAN; CHEN FENG; ASHBAUGH BEN J; BARIK RAJKISHORE; LIN TSUNG-HAN; SINHA KAMAL; NURVITADHI ERIKO; VEMBU BALAJI; KOKER ALTUG,201715489149 17.04.2017 US,
EP251648371,18210163,04.12.2018,3539728,18.09.2019,EP,SYSTEM AND METHOD FOR FAULT DETECTION IN ROBOTIC ACTUATION,,B25J 9/16,TATA CONSULTANCY SERVICES LTD,GHOSE AVIK; DEY SWARNAVA; MUKHERJEE ARIJIT,201821009841 17.03.2018 IN,
WO2017002637,PCT/JP2016/068022,10.06.2016,WO/2017/002637,05.01.2017,WO,METHOD FOR DETERMINING A MOTION BETWEEN A FIRST COORDINATE SYSTEM AND A SECOND COORDINATE SYSTEM,"A method determines motion between first and second coordinate systems by first extracting first and second sets of keypoints from first and second images acquired of a scene by a camera arranged on a moving object. First and second poses are determined from the first and second sets of keypoints. A score for each possible motion between the first and the second poses is determined using a scoring function and a pose-transition graph constructed from training data where each node in the post-transition graph represents a relative pose and each edge represents a motion between two consecutive relative poses. Then, based on the score, a best motion is selected as the motion between the first and second coordinate systems.",G06T 7/20; G05D 1/00,MITSUBISHI ELECTRIC CORPORATION,"RAMALINGAM, Srikumar; LEE, Gim Hee","14/755,324 30.06.2015 US",DE-112016002995; JP-2017513572
WO2018211178,PCT/FI2018/050380,21.05.2018,WO/2018/211178,22.11.2018,WO,NEURAL NETWORK BASED SOLUTION,"The present invention relates to a method for generating an output signal of a system based on input data received by the system, the method comprising: receiving training data; training a neural network for generating the output signal by optimizing a primary cost function and an auxiliary cost function and modulating the auxiliary cost function with a gradient-based attention mask during the training; wherein the method further comprising: receiving the input data; inputting the received input data to the trained neural network: generating the output signal of the system in accordance with a processing of the received input data with the trained neural network. The invention also relates to a system and a computer program product.",G06N 3/08,CURIOUS AI OY,"HERRANEN, Matti; VALPOLA, Harri",20175457 19.05.2017 FI,FI-20196098
WO2019171363,PCT/IB2019/055905,11.07.2019,WO/2019/171363,12.09.2019,WO,A SYSTEM AND A METHOD FOR DETECTION AND CLASSIFICATION OF GASSES,"The present invention describes a system and a method for detection and classification of gasses. The system (101) comprises a plurality of sensing units (103), a processor and a memory coupled with the processor. The system (101) comprises receiving a plurality of training data from the plurality of sensing units (103), extracting one or more features from the plurality of training data, encoding the one or more features to generate an encoded data, decoding the encoded data to obtain a decoded data, comparing the decoded data and the plurality of training data to obtain an output value, continuously modifying the encoded data, to generate a trained encoded data, until the output value satisfies a pre-defined criterion. The system (101) comprises fusing, a plurality of new data received from the plurality of sensing units (103) to generate a fused data and detecting and classifying presence and type of gas.",G01N 27/00; G06F 17/00; G06F 15/04; G06N 7/02,SYMBIOSIS INTERNATIONAL (DEEMED UNIVERSITY),"WALAMBE, Rahee; NARKHEDE, Parag",201921018281 07.05.2019 IN,
EP243305113,18209934,03.12.2018,3492946,05.06.2019,EP,"METHOD, APPARATUS, AND SYSTEM FOR OBJECT TRACKING AND NAVIGATION",,G01S 5/02; G01S 5/06; G01S 11/02; H04B 7/00; H04B 7/06; H04L 1/06; H04L 25/02,ORIGIN WIRELESS INC,ZHANG FENG; CHEN CHEN; XU QINYI; WANG BEIBEI; WU CHENSHU; ZHANG HANGFANG; WONG CHAU-WAI; CLAFFEY DAVID N; CHEN CHUN-I; DUC LAI HUNG-QUOC; WU ZHUNG-HAN; WU MIN; HAN YI; CHI-LIM AU OSCAR; LIU K J RAY,201762593826 01.12.2017 US; 201815861422 03.01.2018 US; 201815873806 17.01.2018 US; 201816101444 11.08.2018 US; 201816200608 26.11.2018 US; 201816200616 26.11.2018 US; 201816203299 28.11.2018 US; 201816203317 28.11.2018 US; 201862678207 30.05.2018 US; 201862734224 20.09.2018 US; 201862744093 10.10.2018 US; 201862753017 30.10.2018 US,
WO2018184195,PCT/CN2017/079683,07.04.2017,WO/2018/184195,11.10.2018,WO,JOINT TRAINING OF NEURAL NETWORKS USING MULTI-SCALE HARD EXAMPLE MINING,An example apparatus for mining multi-scale hard examples includes a convolutional neural network to receive a mini-batch of sample candidates and generate basic feature maps. The apparatus also includes a feature extractor and combiner to generate concatenated feature maps based on the basic feature maps and extract the concatenated feature maps for each of a plurality of received candidate boxes. The apparatus further includes a sample scorer and miner to score the candidate samples with multi-task loss scores and select candidate samples with multi-task loss scores exceeding a threshold score.,G06K 9/00,"INTEL CORPORATION; YAO, Anbang; REN, Yun; ZHAO, Hao; KONG, Tao; CHEN, Yurlong","YAO, Anbang; REN, Yun; ZHAO, Hao; KONG, Tao; CHEN, Yurlong",,
WO2019092439,PCT/GB2018/053259,12.11.2018,WO/2019/092439,16.05.2019,WO,DETECTING STATIC PARTS OF A SCENE,"A method of distinguishing between static and ephemeral parts of an experienced environment in representations of the experienced environment, the method comprising automatically generating training data comprising a set of training representations and corresponding ephemerality masks segmenting each of the training representations into static and ephemeral parts, wherein the training representations are representations of a training environment, and wherein the ephemerality masks are generated by comparing each training representation to a corresponding portion of a 3D static model of the static parts of the training environment, computing a discrepancy between the training representation and the corresponding portion of the 3D static model; and calculating an ephemerality mask for the training representation based on the discrepancy, the ephemerality mask segmenting the training representation into static and ephemeral parts, training a neural network with the training data, providing experienced representations of the environment to the trained neural network; and predicting, using the trained neural network, which parts of the experienced representation relate to static parts of the experienced environment and which to ephemeral parts of the experienced environment.",G06K 9/62; G06K 9/00; G06N 3/08,OXFORD UNIVERSITY INNOVATION LIMITED,"POSNER, Ingmar; BARNES, Daniel; MADDERN, Will; PASCOE, Geoffrey",1718692.5 13.11.2017 GB,
WO2019160700,PCT/US2019/016407,01.02.2019,WO/2019/160700,22.08.2019,WO,DETECTING BLOCKING STATIONARY VEHICLES,"A method and system of determining whether a stationary vehicle is a blocking vehicle to improve control of an autonomous vehicle. A perception engine may detect a stationary vehicle in an environment of the autonomous vehicle from sensor data received by the autonomous vehicle. Responsive to this detection, the perception engine may determine feature values of the environment of the vehicle from sensor data (e.g., features of the stationary vehicle, other object(s), the environment itself). The autonomous vehicle may input these feature values into a machine-learning model to determine a probability that the stationary vehicle is a blocking vehicle and use the probability to generate a trajectory to control motion of the autonomous vehicle.",G06K 9/00; G06K 9/62; G08G 1/16,"ZOOX, INC.","GHAFARIANZADEH, Mahsa; SAPP, Benjamin John; LEVINSON, Jesse Sol","15/897,028 14.02.2018 US",
WO2020051620,PCT/AU2019/000057,16.05.2019,WO/2020/051620,19.03.2020,WO,AUTOMATED VEHICLE,The present invention relates to an automated vehicle comprising a vision system comprising at least one vision sensor to detect a terrain; a manipulator comprising an effector configured for performing an outdoor activity in the terrain; and an arm configured to position the effector in the vicinity of a feature of the terrain and at least one control unit which utilises scanned terrain data from the vision system to improve movement of the automated vehicle and the manipulator during use.,G05D 1/02; G05B 19/42; G06K 9/52; B25J 5/00; B25J 9/16; A01D 46/30,UNIVERSAL FIELD ROBOTICS PTY LTD,"STERLING, Jeffrey James; MCKERCHER, Rhys Andrew; CASSELL, Timothy",2018901710 16.05.2018 AU,
WO2017079522,PCT/US2016/060471,04.11.2016,WO/2017/079522,11.05.2017,WO,SUBCATEGORY-AWARE CONVOLUTIONAL NEURAL NETWORKS FOR OBJECT DETECTION,"A computer-implemented method for detecting objects by using subcategory-aware convolutional neural networks (CNNs) is presented. The method includes generating object region proposals from an image by a region proposal network (RPN) which utilizes subcategory information, and classifying and refining the object region proposals by an object detection network (ODN) that simultaneously performs object category classification, subcategory classification, and bounding box regression. The image is an image pyramid used as input to the RPN and the ODN. The RPN and the ODN each include a feature extrapolating layer to detect object categories with scale variations among the objects.",G06N 3/04; G06N 3/08,"NEC LABORATORIES AMERICA, INC.","CHOI, Wongun; LIN, Yuanqing; XIANG, Yu; SAVARESE, Silvio","62/250,790 04.11.2015 US; 15/342,823 03.11.2016 US",JP-2018522963; DE-112016005059
WO2020026223,PCT/IL2019/050714,27.06.2019,WO/2020/026223,06.02.2020,WO,SYSTEMS AND METHODS FOR AUTOMATED DETECTION OF VISUAL OBJECTS IN MEDICAL IMAGES,"There is provided a computer implemented method for identification of an indication of visual object(s) in anatomical image(s) of a target individual, comprising: providing anatomical image(s) of a body portion of a target individual, inputting the anatomical image(s) into a classification component of a neural network (NN) and into a segmentation component of the NN, feeding a size feature into the classification component of the NN, wherein the size feature comprises an indication of a respective size of each segmented visual object identified in the anatomical image(s), the size feature computed according to segmentation data outputted by the segmentation component for each pixel element of the anatomical image(s), and computing, by the classification component of the NN, an indication of visual object(s) in the anatomical image(s).",G06K 9/00,ZEBRA MEDICAL VISION LTD.,"BAR, Amir","62/711,535 29.07.2018 US",
WO2019222951,PCT/CN2018/088125,24.05.2018,WO/2019/222951,28.11.2019,WO,METHOD AND APPARATUS FOR COMPUTER VISION,"Method and apparatus are disclosed for computer vision. The method may comprise processing, by using a neural network, first input feature maps of an image to obtain output feature maps of the image. The neural network may comprise at least two branches and a first addition block, each of the at least two branches comprises at least one first dilated convolution layer, at least one first upsampling block and at least one second addition block, a dilated rate of the first dilated convolution layer in an branch is different from that in another branch, the at least one first upsampling block is configured to upsample the first input feature maps or the feature maps output by the at least one second addition block, the at least one second addition block is configured to add the upsampled feature maps with second input feature maps of the image respectively, the first addition block is configured to add the feature maps output by each of the at least two branches, the first dilated convolution layer has one convolution kernel and an input channel of the first dilated convolution layer performs dilated convolution separately as an output channel of the first dilated convolution layer.",G06K 9/62; G06N 3/04,"NOKIA TECHNOLOGIES OY; NOKIA TECHNOLOGIES (BEIJING) CO., LTD.","ZHANG, Zhijie",,
WO2018067495,PCT/US2017/054833,03.10.2017,WO/2018/067495,12.04.2018,WO,PROCESSING TEXT SEQUENCES USING NEURAL NETWORKS,"A computer-implemented method for training a neural network that is configured to generate a score distribution over a set of multiple output positions. The neural network is configured to process a network input to generate a respective score distribution for each of a plurality of output positions including a respective score for each token in a predetermined set of tokens that includes n-grams of multiple different sizes. Example methods described herein provide trained neural networks which produce results with improved accuracy compared to the state of the art, e.g. translations that are more accurate compared to the state of the art, or more accurate speech recognition compared to the state of the art.",G06N 3/08,GOOGLE LLC,"JAITLY, Navdeep; ZHANG, Yu; LE, Quoc V.; CHAN, William","62/403,615 03.10.2016 US",EP-2017784512; CN-201780067511.7
WO2018094296,PCT/US2017/062435,18.11.2017,WO/2018/094296,24.05.2018,WO,SENTINEL LONG SHORT-TERM MEMORY,"The technology disclosed presents a novel spatial attention model that uses current hidden state information of a decoder long short-term memory (LSTM) to guide attention and to extract spatial image features for use in image captioning. The technology disclosed also presents a novel adaptive attention model for image captioning that mixes visual information from a convolutional neural network (CNN) and linguistic information from an LSTM. At each timestep, the adaptive attention model automatically decides how heavily to rely on the image, as opposed to the linguistic model, to emit the next caption word. The technology disclosed further adds a new auxiliary sentinel gate to an LSTM architecture and produces a sentinel LSTM (Sn-LSTM). The sentinel gate produces a visual sentinel at each timestep, which is an additional representation, derived from the LSTM's memory, of long and short term visual and linguistic information.",G06N 3/04,"SALESFORCE.COM, INC.","LU, Jiasen; XIONG, Caiming; SOCHER, Richard","62/424,353 18.11.2016 US; 15/817,153 17.11.2017 US; 15/817,161 17.11.2017 US; 15/817,165 18.11.2017 US",
WO2020056375,PCT/US2019/051177,13.09.2019,WO/2020/056375,19.03.2020,WO,VOICE MODIFICATION TO ROBOT MOTION PLANS,"In an embodiment, a method during execution of a motion plan by a robotic arm includes determining a voice command from speech of a user said during the execution of the motion plan, determining a modification of the motion plan based on the voice command from the speech of the user, and executing the modification of the motion plan by the robotic arm.",B25J 9/16,"THE CHARLES STARK DRAPER LABORATORY, INC.; TAYOUN, Anthony","TAYOUN, Anthony; JOHNSON, David, M.S.; WAGNER, Syler; LINES, Steven","62/730,703 13.09.2018 US; 62/730,933 13.09.2018 US; 62/731,398 14.09.2018 US; 62/730,947 13.09.2018 US; 62/730,934 13.09.2018 US; 62/730,918 13.09.2018 US",
EP232545798,18159838,02.03.2018,3396622,31.10.2018,EP,COORDINATION AND INCREASED UTILIZATION OF GRAPHICS PROCESSORS DURING INFERENCE,"A mechanism is described for facilitating inference coordination and processing utilization for machine learning at autonomous machines. A method of embodiments, as described herein, includes detecting, at training time, information relating to one or more tasks to be performed according to a training dataset relating to a processor including a graphics processor. The method may further include analyzing the information to determine one or more portions of hardware relating to the processor capable of supporting the one or more tasks, and configuring the hardware to pre-select the one or more portions to perform the one or more tasks, while other portions of the hardware remain available for other tasks.",G06T 1/20,INTEL CORP,APPU ABHISHEK R; KOKER ALTUG; WEAST JOHN C; MACPHERSON MIKE B; HURD LINDA L; BAGHSORKHI SARA S; GOTTSCHLICH JUSTIN E; SURTI PRASOONKUMAR; SAKTHIVEL CHANDRASEKARAN; MA LIWEI; OULD-AHMED-VALL ELMOUSTAPHA; SINHA KAMAL; RAY JOYDEEP; VEMBU BALAJI; JAHAGIRDAR SANJEEV; RANGANATHAN VASANTH; KIM DUKHWAN,201715495054 24.04.2017 US,
EP14444147,05011721,31.05.2005,1603071,07.12.2005,EP,Three-dimensional object recognizing system,"A three-dimensional object recognizing system comprises a distance image generating portion for generating a distance image by using image pairs picked up by a stereoscopic camera, a grouping processing portion for grouping the distance data indicating the same three-dimensional object on the distance image, an input value setting portion for setting an area containing distance data group of grouped three-dimensional object on the distance image and also setting input values having typical distance data as elements every small area that is obtained by dividing the area by a set number of partition, a computing portion for computing output values having a pattern that responds to a previously set three-dimensional object by using a neural network that has at least the input values Xin as inputs to an input layer, and a discriminating portion for discriminating the type of the three-dimensional object based on the pattern of the output values. <IMAGE>",G06K 9/00; G06T 1/00; G06N 3/08; G06T 7/00,FUJI HEAVY IND LTD,KISE KATSUYUKI,2004163611 01.06.2004 JP,
WO2010104480,PCT/SI2009/000050,14.10.2009,WO/2010/104480,16.09.2010,WO,SYSTEM AND PROCEDURE FOR ESTIMATION OF PSYCHOLOGICAL STATE BASED ON PSYCHOPHYSIOLOGICAL RESPONSES AND TRANSMISSION OF THE ESTIMATED STATE OVER VARIOUS NETWORKS,"The invention relates to a system for estimation of psychological state based on psychophysiological responses and transmission of the estimated state over various networks. The system and procedure for estimation of psychological state based on psychophysiological responses and transmission of the estimated state over various networks consists of the measurement subsystem (1), which comprises rings with sensors for photoplethysmography, skin conductance skin temperature (21, 22, 23, 24), a bracelet (3), connections (41, 42, 43, 44), a belt with ECG and respiration sensors (5), a microphone, camera, encoders (K1-K6) and wireless transmitters (01- 06). The system also includes a wireless receiver (6) connected to a computer subsystem (7). The computer subsystem (7) continuously stores the signals from the wireless transmitter (6) into memory or onto the hard drive. Signals in memory are filtered by the computer subsystem and used to calculate the psychophysiological parameters needed to estimate psychological state. The system allows the user to choose among different algorithms for psychological state estimation. It is designed modularly so that different sensors can be added or removed. The estimate of psychological state can be transmitted to a different location over various networks.",A61B 5/16; G06F 19/00,"UNIVERZA V LJUBLJANI; MATJAZ, Mihelj; MUNIH, Marko; NOVAK, Domen","MATJAZ, Mihelj; MUNIH, Marko; NOVAK, Domen",P-200900067 12.03.2009 SI,
WO2019170785,PCT/EP2019/055626,06.03.2019,WO/2019/170785,12.09.2019,WO,DETERMINING WEIGHTS OF CONVOLUTIONAL NEURAL NETWORKS,"An example includes sending (502) first weight values to first client devices; accessing (504) sets of updated weight values provided by the first client devices, the updated weight values generated by the first client devices training respective first convolutional neural networks, CNNs, based on: the first weight values, and sensor data generated at the client devices; testing (506) performance in a second CNN of at least one of: the sets of the updated weight values, or a combination of ones of the updated weight values from the sets of the updated weight values; selecting (512) server-synchronized weight values from the at least one of: the sets of the updated weight values, or a combination of ones of the updated weight values from the sets of the updated weight values; and sending (518) the server- synchronized weight values to at least one of: at least some of the first client devices, or second client devices.",G06K 9/00; G06K 9/62; G06K 9/46; G06N 3/04,MOVIDIUS LTD.,"MOLONEY, David; DEHGHANI, Alireza; DUNNE, Aubrey, Keith","15/914,854 07.03.2018 US",
WO2019013913,PCT/US2018/036814,11.06.2018,WO/2019/013913,17.01.2019,WO,SPATIO-TEMPORAL INTERACTION NETWORK FOR LEARNING OBJECT INTERACTIONS,Systems and methods for improving video understanding tasks based on higher-order object interactions (HOIs) between object features are provided. A plurality of frames of a video are obtained. A coarse-grained feature representation is generated by generating an image feature for each of for each of a plurality of timesteps respectively corresponding to each of the frames and performing attention based on the image features. A fine-grained feature representation is generated by generating an object feature for each of the plurality of timesteps and generating the HOIs between the object features. The coarse-grained and the fine-grained feature representations are concatenated to generate a concatenated feature representation.,G06N 99/00,"NEC LABORATORIES AMERICA, INC.","KADAV, Asim; MA, Chih-Yao; MELVIN, Iain; GRAF, Hans-Peter","62/532,499 14.07.2017 US; 62/576,264 24.10.2017 US; 15/978,738 14.05.2018 US",
EP13227351,99303390,29.04.1999,0953970,03.11.1999,EP,Method and apparatus using decision trees to generate and score multiple pronunciations for a spelled word,"The mixed decision tree includes a network of yes-no questions about adjacent letters in a spelled word sequence and also about adjacent phonemes in the phoneme sequence corresponding to the spelled word sequence. Leaf nodes of the mixed decision tree provide information about which phonetic transcriptions are most probable. Using the mixed trees, scores are developed for each of a plurality of possible pronunciations, and these scores can be used to select the best pronunciation as well as to rank pronunciations in order of probability. The pronunciations generated by the system can be used in speech synthesis and speech recognition applications as well as lexicography applications. <IMAGE>",G10L 13/04; G10L 13/08,MATSUSHITA ELECTRIC IND CO LTD,KUHN ROLAND; JUNQUA JEAN-CLAUDE; CONTOLINI MATTEO,6776498 29.04.1998 US; 6930898 29.04.1998 US; 7030098 30.04.1998 US,
WO2019023376,PCT/US2018/043745,25.07.2018,WO/2019/023376,31.01.2019,WO,DEEP LEARNING VOLUME QUANTIFYING METHODS AND APPARATUS,"A neural network-based method for quantifying a volume of a specimen. The method includes providing a specimen, capturing images of the specimen, and directly classifying to one of a plurality of volume classes or volumes using a trained neural network. Quality check modules and specimen testing apparatus adapted to carry out the volume quantification method are described, as are other aspects.",G06K 9/00,SIEMENS HEALTHCARE DIAGNOSTICS INC.,"KLUCKNER, Stefan; CHANG, Yao-Jen; MA, Kai; SINGH, Vivek; CHEN, Terrence; POLLACK, Benjamin S.","62/538,460 28.07.2017 US",EP-2018837576
WO2014190018,PCT/US2014/038920,21.05.2014,WO/2014/190018,27.11.2014,WO,A SYSTEM AND METHOD FOR A HUMAN MACHINE INTERFACE UTILIZING NEAR-FIELD QUASI-STATE ELECTRICAL FIELD SENSING TECHNOLOGY,"The system and method for non-contact and/or touch-sensitive human machine interface, for use in numerous capacities wherein a lack of physical contact, with control apparatuses or devices is desirable. Electrical near field three-dimensional tracking and gesture control systems are utilized to interpret the location and movement of an operator, or to provide navigation, mapping, avoidance, localization, and the like for robotics applications.",G06F 19/00,"STANLEY INNOVATION, INC.","HUSSEY, Patrick; SHAFFER, Benjamin","61/825,825 21.05.2013 US",
EP14265133,04018616,05.08.2004,1505534,09.02.2005,EP,Plural model time series pattern processing,"An information processing method and an information processing apparatus in which the learning efficiency may be improved and the scale may be extended readily. An integrated module 42 is formed by a movement pattern learning module by a local expression scheme. The local modules 43-1 to 43-3 of the integrated module 42 are each formed by a recurrent neural network as a movement pattern learning model by a distributed expression scheme. The local modules 43-1 to 43-3 are caused to learn plural movement patterns. Outputs from the local modules 43-1 to 43-3, supplied with preset parameters, as inputs, are multiplied by gates 44-1 to 44-3 with coefficients W1 to W3, respectively, and the resulting products are summed together and output.",G06K 9/62; G06N 3/04; G06K 9/00; G06K 9/66; G06K 9/68,SONY CORP; RIKEN,ITO MASATO; TANI JUN,2003289138 07.08.2003 JP,
WO2017139516,PCT/US2017/017275,09.02.2017,WO/2017/139516,17.08.2017,WO,SYSTEM AND METHOD FOR ACHIEVING FAST AND RELIABLE TIME-TO-CONTACT ESTIMATION USING VISION AND RANGE SENSOR DATA FOR AUTONOMOUS NAVIGATION,"Described is a robotic system for detecting obstacles reliably with their ranges by a combination of two-dimensional and three-dimensional sensing. In operation, the system receives an image from a monocular video and range depth data from a range sensor of a scene proximate a mobile platform. The image is segmented, into multiple object regions of interest and time-to-contact (TTC) value are calculated by estimating motion field and operating on image intensities. A two-dimensional (2D) TTC map is then generated by estimating average TTC values over the multiple object regions of interest. A three-dimensional TTC map is then generated by fusing the range depth data with image. Finally, a range-fused TTC map is generated by averaging the 2D TTC map and the 3D TTC map,",G05D 1/00; G05D 1/02; G06T 7/11; G06T 7/70,"HRL LABORATORIES, LLC","MONTERROZA, Fredy; KIM, Kyungnam; KHOSLA, Deepark","15/271,025 20.09.2016 US; 62/293,649 10.02.2016 US",EP-2017750795
WO2018128741,PCT/US2017/064624,05.12.2017,WO/2018/128741,12.07.2018,WO,SEGMENTING GENERIC FOREGROUND OBJECTS IN IMAGES AND VIDEOS,"A method, system and computer program product for segmenting generic foreground objects in images and videos. For segmenting generic foreground objects in videos, an appearance stream of an image in a video frame is processed using a first deep neural network. Furthermore, a motion stream of an optical flow image in the video frame is processed using a second deep neural network. The appearance and motion streams are then joined to combine complementary appearance and motion information to perform segmentation of generic objects in the video frame. Generic foreground objects are segmented in images by training a convolutional deep neural network to estimate a likelihood that a pixel in an image belongs to a foreground object. After receiving the image, the likelihood that the pixel in the image is part of the foreground object as opposed to background is then determined using the trained convolutional deep neural network.",H04N 19/60; H04N 19/85; G06T 7/10; G06T 7/20; G06K 9/46; G06N 3/04,"BOARD OF REGENTS, THE UNIVERSITY OF TEXAS SYSTEM","GRAUMAN, Kristen; JAIN, Suyog, Dutt; XIONG, Bo","62/443,283 06.01.2017 US",
WO2018140885,PCT/US2018/015753,29.01.2018,WO/2018/140885,02.08.2018,WO,MEMORY SIDE ACCELERATION FOR DEEP LEARNING PARAMETER UPDATES,"Examples disclosed herein relate to using a memory side accelerator to calculate updated deep learning parameters. A globally addressable memory includes deep learning parameters. The deep learning parameters are partitioned, where each partition is associated with a memory side accelerator. A memory side accelerator is to receive calculated gradient updates associated with its partition and calculate an update to the deep learning parameters associated with the partition.",G06N 3/08; G06N 3/04; G06F 9/22,HEWLETT PACKARD ENTERPRISE DEVELOPMENT LP,"XU, Cong; CAI, Qiong","15/417,760 27.01.2017 US",
WO2017201483,PCT/US2017/033655,19.05.2017,WO/2017/201483,23.11.2017,WO,METHOD FOR TRACKING PLACEMENT OF PRODUCTS ON SHELVES IN A STORE,"One variation of a method for tracking placement of products in a store includes: accessing an image recorded by a mobile robotic system within a store; detecting a shelf in a region of the image; based on an address of the shelf, retrieving a list of products assigned to the shelf by a planogram of the store; retrieving a set of template images - from a database of template images - defining visual features of products specified in the list of products; extracting a set of features from the region of the image; determining that a unit of the product is mis-stocked on the shelf in response to deviation between the set of features and features in a template image, in the set of template images, representing the product; and in response to determining that the unit of the product is mis-stocked on the shelf, generating a restocking prompt for the product.",G06K 9/00; G06Q 10/08,SIMBE ROBOTICS INC.,"BOGOLEA, Bradley; SHAH, Mirza, Akbar; VANDEGRIFT, Lorin; FRASER, Luke; SAFI, Jariullah; GEE, Jeffrey","15/347,689 09.11.2016 US; 62/339,039 19.05.2016 US",CN-201780044524.2; EP-2017800295; KR-1020187035807; JP-2018561047
WO2006020154,PCT/US2005/025332,15.07.2005,WO/2006/020154,23.02.2006,WO,SYSTEM AND METHOD FOR AUTOMATED SEARCH BY DISTRIBUTED ELEMENTS,"A system and method for decentralized cooperative control of a team of agents for geographic and other search tasks. The approach is behavior-based and uses probability particle approach to the search problem. Agents are attracted to probability distributions in the form of virtual particles of probability that represent hypotheses about the existence of objects of interest in a geographic area or a data-space. Reliance on dependable, high-bandwidth communication is reduced by modeling the movements of other team members and the objects of interest between periodic update messages.",G05D 1/12,"RAYTHEON COMPANY; HOWARD, Michael, D.; PAYTON, David; BRADSHAW, Wendell; SMITH, Timothy","HOWARD, Michael, D.; PAYTON, David; BRADSHAW, Wendell; SMITH, Timothy","10/892,747 15.07.2004 US",RU-2007105730; CA-2569480; CN-200580023541.5; AU-2005274861; IL-179502; EP-2005772338; JP-2007521706; DE-null
EP238739037,17188406,29.08.2017,3451084,06.03.2019,EP,METHOD FOR SETTING PARAMETERS IN AN AUTONOMOUS WORKING DEVICE AND AN AUTONOMOUS WORKING DEVICE,"The invention regards a system and method for setting parameters in an autonomous working device, the autonomous working device being controlled based on a plurality of parameters, and such autonomous working device. First, for each of a plurality of different working environments a set of sensor values, that sensors of the autonomous working device produce while being operated in the respective working environment, is generated. The plurality of sets of sensor values is partitioned into categories, each category corresponding to a prototypical working environment. The parameters for each category are optimized to find an optimized parameter set for each prototypical working environment. For an individual working environment in which operation of the autonomous working device shall be performed, an individual set of sensor values that the sensors of the autonomous working device produce while being operated in this individual working environment is generated. Then, based at least on the individual set of sensor values, the prototypical working environment showing highest similarity to the individual environment is determined, and the parameters in the autonomous working device are set according to the optimized parameter set corresponding to the determined prototypical working environment.",G05B 13/02; A01D 34/00; G05D 1/00,HONDA RES INSTITUTE EUROPE GMBH,SCHMITT SEBASTIAN; OLHOFER MARKUS; SHIMAMURA HIDEAKI; MATSUI YUKI,17188406 29.08.2017 EP,
EP251457656,18747326,29.01.2018,3537368,11.09.2019,EP,DEVICE AND METHOD FOR RECOMMENDING PRODUCT,"The present disclosure relates to an artificial intelligence (AI) system for simulating human brain functions such as perception and judgement by using a machine learning algorithm such as deep learning, and an application thereof. Provided is a device and method for recommending products to a user on the basis of facial expression information of the user through an artificial intelligence system. The method for recommending products by a device comprises the steps of: displaying a product selected by a user; acquiring information on the user's facial expression for the displayed product; determining the user's satisfaction with the displayed product, on the basis of the acquired information on the user's facial expression; selecting a product set to be recommended to the user among a plurality of product sets, on the basis of the determined user's satisfaction; and displaying at least one product included in the selected product set.",G06Q 30/00; G06K 9/00; G06Q 30/02; G06Q 30/06,SAMSUNG ELECTRONICS CO LTD,YUN SO-JUNG; JANG JUN-IK,20170014376 01.02.2017 KR; 20180007889 22.01.2018 KR; 2018001240 29.01.2018 KR,
WO2019173233,PCT/US2019/020588,04.03.2019,WO/2019/173233,12.09.2019,WO,METHODS FOR USING ARTIFICIAL NEURAL NETWORK ANALYSIS ON FLOW CYTOMETRY DATA FOR CANCER DIAGNOSIS,"The present disclosure provides methods for applying artificial neural networks to flow cytometry data generated from biological samples to diagnose and characterize cancer in a subject. The disclosure also provides methods of training, testing, and validating artificial neural networks.",G01N 33/574; G01N 21/64; G06E 1/00; G06E 3/00; G06F 15/18,ANIXA DIAGNOSTICS CORPORATION,"KUMAR, Amit; ROOP, John; CAMPISI, Anthony J.; DOMINGUEZ, George","15/912,511 05.03.2018 US",
EP232545763,18163805,23.03.2018,3396591,31.10.2018,EP,"RECOGNITION, REIDENTIFICATION AND SECURITY ENHANCEMENTS USING AUTONOMOUS MACHINES","A mechanism is described for facilitating recognition, reidentification, and security in machine learning at autonomous machines. A method of embodiments, as described herein, includes facilitating a camera to detect one or more objects within a physical vicinity, the one or more objects including a person, and the physical vicinity including a house, where detecting includes capturing one or more images of one or more portions of a body of the person. The method may further include extracting body features based on the one or more portions of the body, comparing the extracted body features with feature vectors stored at a database, and building a classification model based on the extracted body features over a period of time to facilitate recognition or reidentification of the person independent of facial recognition of the person.",G06K 9/00,INTEL CORP,DAS BARNAN; VARERKAR MAYURESH M; BISWAL NARAYAN; BARAN STANLEY J; CILINGIR GOKCEN; SHAH NILESH V; SHARMA ARCHIE; ABDELHAK SHERINE; KOTHA PRANEETHA; PANDIT NEELAY; WEAST JOHN C; MACPHERSON MIKE B; KIM DUKHWAN; HURD LINDA L; APPU ABHISHEK R; KOKER ALTUG; RAY JOYDEEP,201715495327 24.04.2017 US,
WO2020076610,PCT/US2019/054499,03.10.2019,WO/2020/076610,16.04.2020,WO,SYSTEM AND METHOD FOR GEOMETRICAL USER INTERACTIONS VIA THREE-DIMENSIONAL MAPPING,"Systems and methods for providing geometric interactions via three-dimensional mapping. A method includes determining a plurality of first descriptors for a plurality of key points in a plurality of first images, wherein each first image shows a portion of a 3D environment in which a robotic device and a visual sensor are deployed; generating a 3D map of the 3D environment based on the plurality of key points and the plurality of descriptors; determining a pose of the visual sensor based on at least one second descriptor and the plurality of first descriptors, wherein the second image is captured by the visual sensor; and determining a target action location based on at least one user input made with respect to a display of the second image and the pose of the visual sensor, wherein the target action location is a location within the 3D environment.",G06K 9/46; G01C 21/34; B25J 11/00,R-GO ROBOTICS LTD.; R-GO ROBOTICS INC.,"HORESH, Nizan; BOUSANI, Amir","62/742,565 08.10.2018 US",
WO2007127695,PCT/US2007/067207,23.04.2007,WO/2007/127695,08.11.2007,WO,PREFERNCE BASED AUTOMATIC MEDIA SUMMARIZATION,"Methods, devices, systems and tools are presented that allow the summarization of text, audio, and audiovisual presentations, such as movies, into less lengthy forms. High-content media files are shortened in a manner that preserves important details, by splitting the files into segments, rating the segments, and reassembling preferred segments into a final abridged piece Summarization of media can be customized by user selection of criteria, and opens new possibilities for delivering entertainment, news, and information in the form of dense, information-rich content that can be viewed by means of broadcast or cable distribution: 'on-demand' distribution, internet and cell phone digital video streaming, or can be downloaded onto iPodTM and other portable video playback devices.",G06F 15/00; G06F 17/00,"FRANK, Elmo, Weber","FRANK, Elmo, Weber","60/745,588 25.04.2006 US; 60/890,214 16.02.2007 US; 60/892,311 01.03.2007 US",US-12298709
WO2020007818,PCT/EP2019/067661,02.07.2019,WO/2020/007818,09.01.2020,WO,CONTROLLING MOVEMENT OF AUTONOMOUS DEVICE,"An example system includes an autonomous device. The system includes a movement assembly to move the autonomous device, memory storing information about classes of objects and storing rules governing operation of the autonomous device based on a class of an object in a path of the autonomous device, one or more sensors to detect at least one attribute of the object, and one or more processing devices. The one or more processing devices determine the class of the object based on the at least one attribute, execute a rule to control the autonomous device based on the class, and control the movement assembly based on the rule.",G06K 9/00,MOBILE INDUSTRIAL ROBOTS A/S,"JACOBSEN, Niels Jul; DE CASTRO, Lourenco Barbosa; NIELSEN, Soren Eriksen","16/025,483 02.07.2018 US",
WO2019156877,PCT/US2019/015927,30.01.2019,WO/2019/156877,15.08.2019,WO,DOMAIN ADAPTION LEARNING SYSTEM,"Described is a system for adapting a deep convolutional neural network (CNN). A deep CNN is first trained on an annotated source image domain. The deep CNN is adapted to a new target image domain without requiring new annotations by determining domain agnostic features that map from the annotated source image domain and a target image domain to a joint latent space, and using the domain agnostic features to map the joint latent space to annotations for the target image domain.",G06F 16/55; G06F 16/51; G06N 3/08,"HRL LABORATORIES, LLC","MUREZ, Zachary; KIM, Kyungnam; KOLOURI, Soheil; ROSTAMI, Mohammad","62/627,179 06.02.2018 US",
WO2019063449,PCT/EP2018/075705,21.09.2018,WO/2019/063449,04.04.2019,WO,SEMANTIC SEARCH ENGINE AND VISUALIZATION PLATFORM,"Disclosed herein are systems, devices, and methods for translating natural language queries into data source-specific structured queries and automatically identifying visualization options based on the result of executing a structured query. In one embodiment, a method comprises receiving a natural language query; generating one or more interpretations based on the natural language query using one or more natural language processing procedures; generating a structured query based on the one or more interpretations, the structured query generated based on an identified data source type; executing a search on the data source using the structured query, the execution of the search resulting a result set; identifying a visualization type based on a type of data included within the result set; and generating a visualization based on the visualization type and the result set.",G06F 17/30,"NOVABASE SGPS, S.A.","ANTUNES, Bruno; VERRUMA, Pedro; QUINTAS, Ricardo; LEAL, João; PINTO, Sara; MATEUS, Tiago","15/720,662 29.09.2017 US",
WO2018208791,PCT/US2018/031620,08.05.2018,WO/2018/208791,15.11.2018,WO,SYSTEMS AND METHODS FOR INSPECTION AND DEFECT DETECTION USING 3-D SCANNING,"A method for detecting defects in objects includes: controlling, by a processor, one or more depth cameras to capture a plurality of depth images of a target object; computing, by the processor, a three-dimensional (3-D) model of the target object using the depth images; rendering, by the processor, one or more views of the 3-D model; computing, by the processor, a descriptor by supplying the one or more views of the 3-D model to a convolutional stage of a convolutional neural network; supplying, by the processor, the descriptor to a defect detector to compute one or more defect classifications of the target object; and outputting the one or more defect classifications of the target object.",G06K 9/66; G06K 9/46; G06K 9/52; G06K 9/62; G03F 1/72; G11C 29/02; B23K 31/02; B23K 9/127,"AQUIFI, INC.","MEMO, Alvise; DEMIRDJIAN, David; MARIN, Giulio; TIEU, Kinh; PERUCH, Francesco; SALVAGNINI, Pietro; MURALI, Giridhar; DAL MUTTO, Carlo; CESARE, Guido","62/503,115 08.05.2017 US",
WO2018039269,PCT/US2017/048068,22.08.2017,WO/2018/039269,01.03.2018,WO,AUGMENTED REALITY DISPLAY DEVICE WITH DEEP LEARNING SENSORS,"A head-mounted augmented reality (AR) device can include a hardware processor programmed to receive different types of sensor data from a plurality of sensors (e.g., an inertial measurement unit, an outward-facing camera, a depth sensing camera, an eye imaging camera, or a microphone); and determining an event of a plurality of events using the different types of sensor data and a hydra neural network (e.g., face recognition, visual search, gesture identification, semantic segmentation, object detection, lighting detection, simultaneous localization and mapping, relocalization).",G06F 3/01; G02B 27/01; G06T 19/00; G06N 3/02; G06N 3/04,"MAGIC LEAP, INC.","RABINOVICH, Andrew; MALISIEWICZ, Tomasz, Jan; DETONE, Daniel","62/377,835 22.08.2016 US",EP-2017844303; KR-1020197008125; CN-201780064460.2; JP-2019509558; CA-3034644; AU-2017317599; IL-264820
WO2020036786,PCT/US2019/045507,07.08.2019,WO/2020/036786,20.02.2020,WO,DETECTION OF UNINTENTIONAL MOVEMENT OF A USER INTERFACE DEVICE,"A user interface system includes one or more controllers configured to move freely in three dimensions, where the one or more controllers include an inertial sensor coupled to measure movement of the one or more controllers, and output movement data including information about the movement. The user interface system further includes a processor coupled to receive the movement data, where the processor includes logic that, when executed by the processor, causes the user interface system to perform operations, including receiving the movement data with the processor, identifying an unintentional movement in the movement data with the processor, and outputting unintentional movement data that identifies the unintentional movement.",A61B 34/00; A61B 5/11; A61B 34/30; A61B 34/37; A61B 90/00,VERILY LIFE SCIENCES LLC,"TEKIELA, Kamilla; BARRAL, Jöelle K.; DONHOWE, Caitlin","62/718,169 13.08.2018 US; 16/517,387 19.07.2019 US",
WO2020000171,PCT/CN2018/092809,26.06.2018,WO/2020/000171,02.01.2020,WO,METHOD AND APPARATUS FOR COMPUTER VISION,"Method and apparatus are disclosed for computer vision. The method may comprise processing, by using a neural network, input feature maps of an image to obtain output feature maps of the image. The neural network may comprise a convolution part and/or a pooling part, and an aggregation part. The convolution part may comprise at least one parallel unit each of which contains two parallel paths, each path of the two parallel paths contains two cascaded convolution layers. The kernel sizes are 1 dimension and are different in different unit. The pooling part comprises at least one parallel unit each of which contains two parallel paths, each path of the two parallel paths contains two cascaded pooling layers. The size of filters of pooling is 1 dimension and is different in different unit. The aggregation part is configured to concatenate results of the convolution part and/or the pooling part to obtain the output feature maps of the image.",G06K 9/00,"NOKIA TECHNOLOGIES OY; NOKIA TECHNOLOGIES (BEIJING) CO., LTD.","LIAN, Xuhang",,
WO2006047508,PCT/US2005/038350,25.10.2005,WO/2006/047508,04.05.2006,WO,EMBEDDED IMAGING AND CONTROL SYSTEM,"A stand alone imaging system is disclosed that captures undistorted, high resolution, stop-action images of objects (e.g., medicine pills) moving at automation speeds, processes the images in real time, and then performs real-time I/O based control that is a function of the image processing results. The imaging system has a form factor that enables it to be embedded inside a product (e.g., a pill dispenser). The imaging system also has a flexible I/O system so that a variety of different applications can be handled by changing only the programming and the external hardware connected to the device in which the imaging system is embedded. In the case of pill dispensing and quality control, a miniature, low cost imaging system can be embedded in a pill dispenser to obtain a pill image and then process the image in real time as the pill moves through a counting system. The embedded imaging system processes the images fast enough and with sufficient quality and resolution so as to command a pill counting mechanism to dispense or reject the pill based on the image processing results. Images of the pills can also be sent to a remote location or an archive. The embedded imaging system has sufficient processing power and I/O to control the entire pill counting mechanism. Lighting may be provided by a separate solid state lighting source which may be controlled by the embedded imaging system's camera or operated independently. Because of the rules governing abstracts, this abstract should not be used to construe the claims.",G06T 7/00; B07C 5/342,"MCKESSON AUTOMATION SYSTEMS, INC.","POPOVICH, Joseph, Jr.; VOLKAR, John; REMIS, Steven, J.; TOOLE, William","10/972,492 25.10.2004 US",MX-MX/a/2007/004915; EP-2005812197; AU-2005299505; CA-2579431
WO2018153807,PCT/EP2018/054002,19.02.2018,WO/2018/153807,30.08.2018,WO,ACTION SELECTION FOR REINFORCEMENT LEARNING USING NEURAL NETWORKS,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for a system configured to select actions to be performed by an agent that interacts with an environment. The system comprises a manager neural network subsystem and a worker neural network subsystem. The manager subsystem is configured to, at each of the multiple time steps, generate a final goal vector for the time step. The worker subsystem is configured to, at each of multiple time steps, use the final goal vector generated by the manager subsystem to generate a respective action score for each action in a predetermined set of actions.",G06N 3/04; G06N 3/08; G06N 3/00,DEEPMIND TECHNOLOGIES LIMITED,"OSINDERO, Simon; KAVUKCUOGLU, Koray; VEZHNEVETS, Alexander","62/463,532 24.02.2017 US",JP-2019546129; EP-2018705929; CN-201880013632.8
WO2020074741,PCT/EP2019/077704,14.10.2019,WO/2020/074741,16.04.2020,WO,CONTROLLING AGENTS OVER LONG TIME SCALES USING TEMPORAL VALUE TRANSPORT,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a neural network system used to control an agent interacting with an environment to perform a specified task, One of the methods includes causing the agent to perform a task episode in which the agent attempts to perform the specified task; for each of one or more particular time steps in the sequence: generating a modified reward for the particular time step from (i) the actual reward at the time step and (ii) value predictions at one or more time steps that are more than a threshold number of time steps after the particular time step in the sequence; and training, through reinforcement learning, the neural network system using at least the modified rewards for the particular time steps.",G06N 3/08; G06N 3/04,DEEPMIND TECHNOLOGIES LIMITED,"WAYNE, Gregory Duncan; LILLICRAP, Timothy Paul; HUNG, Chia-Chun; ABRAMSON, Joshua Simon","62/745,202 12.10.2018 US",
WO2019039708,PCT/KR2018/006085,29.05.2018,WO/2019/039708,28.02.2019,WO,MAGNETIC RESONANCE IMAGING APPARATUS AND METHOD OF RECONSTRUCTING MR IMAGE BY USING NEURAL NETWORK,"A magnetic resonance imaging (MRI) apparatus includes a processor, and a memory storing a program including instructions that, when executed by the processor, cause the processor to acquire first data of a subsampled magnetic resonance (MR) image, acquire, based on a learning model using a neural network, first reconstructed data with respect to rows of pixels in a first phase encoding direction of the first data of the subsampled MR image, and obtain a reconstructed image corresponding to the subsampled MR image, using the first reconstructed data.",G01R 33/56; G06N 3/08; G06T 5/00; A61B 5/055,"SAMSUNG ELECTRONICS CO., LTD.; KOREA ADVANCED INSTITUTE OF SCIENCE AND TECHNOLOGY","LEE, Dae-ho; PARK, Hyun-wook; KWON, Ki-nam; SEO, Hyun-seok",10-2017-0108136 25.08.2017 KR,EP-2018847463
WO2019175686,PCT/IB2019/051294,18.02.2019,WO/2019/175686,19.09.2019,WO,ON-DEMAND ARTIFICIAL INTELLIGENCE AND ROADWAY STEWARDSHIP SYSTEM,"The present disclosure relates to artificial intelligence based systems and method for determination of traffic violations. The present disclosure use deep convolutional neural networks and machine vision based algorithms to perform a task of detection and recognition to provide complete solution to safe, legal and comfortable parking, driving and riding for commuters on the roadways. Roadway stewardship systems, Parking management systems when made on-demand and crowdsourced, can play a very strong role in regulating driving conditions in cities and highways. By allowing the on-demand, crowdsourced, roadway stewardship system to be automated, through the use of Artificial Intelligence (AI) sub-systems, users can be trained to recognize and be educated as well in the laws & regulations around the use of roadways; can help the process through an interactive console / game-play, which can also be used for monetization for individuals to earn money for their contribution.",G06K 9/00; G06N 5/00,"RATTI, Jayant","RATTI, Jayant","15/919,033 12.03.2018 US",SG-11201909815R
WO2015188275,PCT/CA2015/050539,10.06.2015,WO/2015/188275,17.12.2015,WO,SYSTEM AND METHOD FOR NETWORK BASED APPLICATION DEVELOPMENT AND IMPLEMENTATION,"An application provisioning system and method. A server provides an application provisioning service. A user of a client provides a schema defining an application. The application interacts with peripherals coupled to the client and receives input from sensors coupled to the peripherals. The sensor data is provided to the server for processing, including by neural networks. The application includes a workflow defining a finite state machine that traverses states at least partially based on the response to sensor data. The server may provide dynamic reallocation of compute resources to resolve demand for classifier training jobrequests; use of jurisdictional certificates to define data usage and sharing; and data fusion. Applications include manufacturing verification, medical diagnosis and treatment, genomics and viral detection.",H04L 12/24; G06F 9/44; G06N 3/08; H04L 12/16,SIGHTLINE INNOVATION INC.,"TRENHOLM, Wallace; MAVINKURVE, Maithili; ALEXIUK, Mark; CASSIDY, Jason","62/010,172 10.06.2014 US; 62/072,590 30.10.2014 US; 62/081,152 18.11.2014 US; 62/157,041 05.05.2015 US",EP-2015806697; CA-2951723
WO2018194765,PCT/US2018/022358,14.03.2018,WO/2018/194765,25.10.2018,WO,"METHODS AND SYSTEMS FOR DETECTING, RECOGNIZING, AND LOCALIZING PALLETS","Example implementations may relate methods and systems for detecting, recognizing, and localizing pallets. For instance, a computing system may receive sensor data representing aspects of an environment, and identify a- set of edge points in the sensor data. The computing system may finite determine a set of line segments from the set of edge points where each line segment may fit to a subset of the set of edge points. Additionally, the computing system may also filter the set of line segments to exclude line segments that have a length outside a height range and a width range associated with dimensions of a pallet template, and identify, from the filtered set of line segments, a subset Of line segments that align with the pallet template. Based on the identified subset of line segments, the computing system may determine a pose of a pallet in the environment.",G06T 7/73; G06T 7/13; B66F 9/00; B25J 19/02; G05D 1/02,X DEVELOPMENT LLC,"HOLZ, Dirk","15/494,227 21.04.2017 US",EP-2018718015
WO2017074966,PCT/US2016/058723,25.10.2016,WO/2017/074966,04.05.2017,WO,JOINT PROCESSING FOR EMBEDDED DATA INFERENCE,"Systems and methods are provided for embedded data inference. The systems and methods may process camera and other sensor data in by leveraging processing and storage capacity of one or more devices nearby or in the cloud to augment or update the sensor processing of an embedded device. The joint processing may be used in stationary cameras or in vehicular systems such as cars and drones, and may improve crop assessments, navigation, and safety.",G06F 15/18,NETRADYNE INC.,"JULIAN, David; AGRAWAL, Avneesh","62/246,595 26.10.2015 US",US-15770487
WO2019238522,PCT/EP2019/064773,06.06.2019,WO/2019/238522,19.12.2019,WO,CHARACTERIZING ACTIVITY IN A RECURRENT ARTIFICIAL NEURAL NETWORK AND ENCODING AND DECODING INFORMATION,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for characterizing activity in a recurrent artificial neural network and encoding and decoding information. In one aspect, a device can include a neural network trained to produce: in response to a first input, an approximation of a first representation of topological structures in patterns of activity arising in a source neural network in response to the first input, in response to a second input, an approximation of a second representation of topological structures in patterns of activity arising in the source neural network in response to the second input, and in response to a third input, an approximation of a third representation of topological structures in patterns of activity arising in the source neural network in response to the third input.",G06N 3/04; G06N 3/00; G06N 3/08; G06N 5/00,INAIT SA,"MARKRAM, Henry; LEVI, Ran; HESS BELLWALD, Kathryn Pamela; SCHUERMANN, Felix","16/004,635 11.06.2018 US; 16/004,837 11.06.2018 US; 16/004,796 11.06.2018 US; 16/004,757 11.06.2018 US; 16/004,671 11.06.2018 US",
WO2011154165,PCT/EP2011/052943,28.02.2011,WO/2011/154165,15.12.2011,WO,METHODS AND SYSTEMS FOR SEMANTIC LABEL PROPAGATION,A method (100) and system (300) is described for processing video data comprising a plurality of images. The method and apparatus is for obtaining for labelling of a plurality of objects or regions in an image of a sequence of images followed by label propagation to other images in the sequence based on an inference step and a model.,G06K 9/62; G06T 7/20,"TOYOTA MOTOR EUROPE NV/SA; CAMBRIDGE ENTERPRISE LIMITED; OTHMEZOURI, Gabriel; SAKATA, Ichiro; CIPOLLA, Roberto; BADRINARAYANAN, Vijay","OTHMEZOURI, Gabriel; SAKATA, Ichiro; CIPOLLA, Roberto; BADRINARAYANAN, Vijay",10165774.0 12.06.2010 EP,EP-2011714237; US-13702700; JP-2013513590
WO2013029008,PCT/US2012/052348,24.08.2012,WO/2013/029008,28.02.2013,WO,RETINAL ENCODER FOR MACHINE VISION,"A method is disclosed including: receiving raw image data corresponding to a series of raw images; processing the raw image data with an encoder to generate encoded data, where the encoder is characterized by an input/output transformation that substantially mimics the input/output transformation of one or more retinal cells of a vertebrate retina; and applying a first machine vision algorithm to data generated based at least in part on the encoded data.",G06K 9/20,"CORNELL UNIVERSITY; NIRENBERG, Sheila; BOMASH, Illya","NIRENBERG, Sheila; BOMASH, Illya","61/527,493 25.08.2011 US; 61/657,406 08.06.2012 US",US-14239828; IL-231063; CA-2883091; JP-2014527338; KR-1020147007453; EP-2012825425; KR-1020197012590
EP14006083,02710486,04.02.2002,1359481,05.11.2003,EP,"AGENT LEARNING APPARATUS, METHOD, AND PROGRAM","An agent learning apparatus comprises a sensor (301) for acquiring a sense input, an action controller (307) for creating an action output in response to the sense input and giving the action output to a controlled object, an action state evaluator (303) for evaluating the behavior of the controlled object, a selective attention mechanism (304) for storing the action output and the sense input corresponding to the action output in one of the columns according to the evaluation, calculating a probability model from the action outputs stored in the columns, and outputting, as a learning result, the action output related to a newly given sense input in the column where the highest confidence obtained by applying the newly given sense input to the probability model is stored. By thus learning, the selective attention mechanism (304) obtains a probability relationship between the sense input and the column. An action output is calculated on the basis of the column evaluated as a stable column. As a result, the dispersion of the action output is quickly minimized, and thereby the controlled object can be stabilized. <IMAGE>",G05B 13/02; G06F 15/18; G06N 3/00; G06N 99/00,HONDA MOTOR CO LTD,KOSHIZEN TAKAMASA; TSUJINO HIROSHI,0200878 04.02.2002 JP; 2001028758 05.02.2001 JP; 2001028759 05.02.2001 JP,
WO2019027259,PCT/KR2018/008759,01.08.2018,WO/2019/027259,07.02.2019,WO,APPARATUS AND METHOD FOR PROVIDING SUMMARIZED INFORMATION USING AN ARTIFICIAL INTELLIGENCE MODEL,An artificial intelligence system using a machine learning algorithm for providing summary information of a document input to an artificial intelligence learning model trained to obtain summary information.,G06F 17/27; G06N 99/00,"SAMSUNG ELECTRONICS CO., LTD.","HWANG, Jin-young","62/539,686 01.08.2017 US; 10-2018-0007169 19.01.2018 KR",EP-2018840709; CN-201880035705.3
WO2019180414,PCT/GB2019/050755,18.03.2019,WO/2019/180414,26.09.2019,WO,"LOCALISATION, MAPPING AND NETWORK TRAINING","Methods, systems and apparatus are disclosed. A method of simultaneous localisation and mapping of a target environment responsive to a sequence of mono images of the target environment comprises providing the sequence of mono images to a first and a further neural network, wherein the first and further neural networks are unsupervised neural networks pretrained using a sequence of stereo image pairs and one or more loss functions defining geometric properties of the stereo image pairs providing the sequence of mono images into a still further neural network, wherein the still further neural network is pretrained to detect loop closures and providing simultaneous localisation and mapping of the target environment responsive to an output of the first, further and still further neural networks.",G06N 3/04; G06N 3/08; G06T 7/593; G06T 7/00; G06T 7/579,UNIVERSITY OF ESSEX ENTERPRISES LIMITED,"GU, Dongbing; LI, Ruihao",1804400.8 20.03.2018 GB,
WO2019204824,PCT/US2019/028570,22.04.2019,WO/2019/204824,24.10.2019,WO,IMPROVING IMAGE CLASSIFICATION THROUGH LABEL PROGRESSION,"Systems and methods are disclosed for generating labeled images based on crops of the images. Particular embodiments may train neural networks using labels for training data that are dynamically refined using neural networks and using these trained neural networks to perform detection and/or classification of one or more objects appearing in an image. Particular embodiments may generate a set of crops of images from a corpus of images, then apply a first neural network to the set of crops to obtain a set of respective outputs. A second neural network may then be trained using the set of crops as training examples. The set of respective outputs may be applied as labels for the set of crops.",G06K 9/62; G06N 3/02,"XNOR.AI, INC.","BAHGERINEZHAD, Hessam; HORTON, Maxwell; RASTEGARI, Mohammad; FARHADI, Ali","16/386,151 16.04.2019 US; 62/660,901 20.04.2018 US",
WO2012047834,PCT/US2011/054689,04.10.2011,WO/2012/047834,12.04.2012,WO,"A SYSTEM AND METHOD OF PROVIDING AGRICULTURAL PEDIGREE FOR AGRICULTURAL PRODUCTS THROUGHOUT PRODUCTION AND DISTRIBUTION AND USE OF THE SAME FOR COMMUNICATION, REAL TIME DECISION MAKING, PREDICTIVE MODELING, RISK SHARING AND SUSTAINABLE AGRICULTURE","A method for establishing an agricultural pedigree for agricultural products comprises the steps of: (a) Providing an open communication network accessible information storage device adapted to receive input of data relating to agricultural product production and distribution from multiple sources; (b) Inputting said data into said information storage device; (c) Storing and said data; and (d) Providing access to said data via the open communication network, wherein the information storage device is configured to be used as at least: (i) A tool for traceability of the agricultural products, (ii) A real time decision making tool, and (iii) A predictive modeling tool.",G06F 19/00,"BAYER CROPSCIENCE LP; KLAVINS, Maris","KLAVINS, Maris","61/389,851 05.10.2010 US",CA-2776577
WO2012125146,PCT/US2011/028302,14.03.2011,WO/2012/125146,20.09.2012,WO,METHOD FOR UNCOVERING HIDDEN MARKOV MODELS,"The invention uses the ModelGrower program to generate possible candidates from an original or aggregated model. An isomorphic reduction program operates on the candidates to identify and exclude isomorphic models. A Markov model evaluation and optimization program operates on the remaining non-isomorphic candidates. The candidates are optimized and the ones that most closely conform to the data are kept. The best optimized candidate of one stage becomes the starting candidate for the next stage where ModelGrower and the other programs operate on the optimized candidate to generate a new optimized candidate. The invention repeats the steps of growing, excluding isomorphs, evaluating and optimizing until such repetitions yield no significantly better results.",G06F 19/00,"GALICK, Albert","GALICK, Albert",,CA-2830159; EP-2011861132; AU-2011362611; JP-2013557997
WO2017120253,PCT/US2017/012209,04.01.2017,WO/2017/120253,13.07.2017,WO,GENERATING HIGH RESOLUTION IMAGES FROM LOW RESOLUTION IMAGES FOR SEMICONDUCTOR APPLICATIONS,Methods and systems for generating a high resolution image for a specimen from one or more low resolution images of the specimen are provided. One system includes one or more computer subsystems configured for acquiring one or more low resolution images of a specimen. The system also includes one or more components executed by the one or more computer subsystems. The one or more components include a model that includes one or more first layers configured for generating a representation of the one or more low resolution images. The model also includes one or more second layers configured for generating a high resolution image of the specimen from the representation of the one or more low resolution images.,G06T 3/40; G06N 3/08; G06N 99/00,KLA-TENCOR CORPORATION,"ZHANG, Jing; CHEN, Grace H.; BHASKAR, Kris; WELLS, Keith; BAI, Nan; GU, Ping; GAO, Lisheng","62/274,731 04.01.2016 US; 15/396,800 02.01.2017 US",IL-259822; KR-1020187022260
EP236801788,17769585,06.01.2017,3435296,30.01.2019,EP,INFORMATION PROCESSING DEVICE,"[Object] To efficiently realize control learning in accordance with an environment in the real world.  [Solution] There is provided an information processing apparatus including: a generating unit configured to generate response information relating to a control target in an environmental model generated on a basis of an environmental parameter; and a transmitting unit configured to transmit the response information and the environmental parameter to a learning unit which performs machine learning relating to control of the control target. In addition, there is provided an information processing apparatus including: a communication unit configured to receive response information relating to a control target in an environmental model generated on a basis of a first environmental parameter, and the first environmental parameter; and a learning unit configured to perform machine learning relating to control of the control target using the received response information and the received first environmental parameter.",G06N 99/00; G06N 3/00; G06N 3/04; G06N 3/08,SONY CORP,FUKUI AKIRA,2016062770 25.03.2016 JP; 2017000346 06.01.2017 JP,
WO2017052709,PCT/US2016/039661,27.06.2016,WO/2017/052709,30.03.2017,WO,TRANSFER LEARNING IN NEURAL NETWORKS,"A method of transfer learning includes receiving second data and generating, via a first network, second labels for the second data. In one configuration, the first network has been previously trained on first labels for first data. Additionally, the second labels are generated for training a second network.",G06N 3/04,QUALCOMM INCORPORATED,"WIERZYNSKI, Casimir Matthew","62/195,763 22.07.2015 US; 14/851,911 11.09.2015 US",EP-2016826207; JP-2018502806; KR-1020187001459
WO2019238513,PCT/EP2019/064741,06.06.2019,WO/2019/238513,19.12.2019,WO,CHARACTERIZING ACTIVITY IN A RECURRENT ARTIFICIAL NEURAL NETWORK AND ENCODING AND DECODING INFORMATION,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for characterizing activity in a recurrent artificial neural network and encoding and decoding information. In one aspect, a method can include outputting digits from a recurrent artificial neural network, wherein each digit represents whether or not activity within a particular group of nodes in the recurrent artificial neural network comports with a respective pattern of activity.",G06N 3/04; G06N 3/00; G06N 3/08; G06N 5/00,INAIT SA,"MARKRAM, Henry; LEVI, Ran; HESS BELLWALD, Kathryn Pamela","16/004,635 11.06.2018 US; 16/004,837 11.06.2018 US; 16/004,796 11.06.2018 US; 16/004,757 11.06.2018 US; 16/004,671 11.06.2018 US",
WO2019116354,PCT/IB2018/060144,15.12.2018,WO/2019/116354,20.06.2019,WO,TRAINING OF ARTIFICIAL NEURAL NETWORKS USING SAFE MUTATIONS BASED ON OUTPUT GRADIENTS,"Systems and methods are disclosed herein for ensuring a safe mutation of a neural network. A processor determines a threshold value representing a limit on an amount of divergence of response for the neural network. The processor identifies a set of weights for the neural network, the set of weights beginning as an initial set of weights. The processor trains the neural network by repeating steps including determining a safe mutation representing a perturbation that results in a response of the neural network that is within the threshold divergence, and modifying the set of weights of the neural network in accordance with the safe mutation.",G06N 3/08; G06N 3/04,"UBER TECHNOLOGIES, INC.","LEHMAN, Joel Anthony; STANLEY, Kenneth Owen; CLUNE, Jeffrey Michael","62/599,577 15.12.2017 US",
WO2018224695,PCT/EP2018/065409,11.06.2018,WO/2018/224695,13.12.2018,WO,TRAINING ACTION SELECTION NEURAL NETWORKS,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for training a policy neural network. The policy neural network is used to select actions to be performed by an agent that interacts with an environment by receiving an observation characterizing a state of the environment and performing an action from a set of actions in response to the received observation. A trajectory is obtained from a replay memory, and a final update to current values of the policy network parameters is determined for each training observation in the trajectory. The final updates to the current values of the policy network parameters are determined from selected action updates and leave-one-out updates.",G06N 3/04; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"GENDRON-BELLEMARE, Marc; AZAR, Mohammad Gheshlaghi; GRUSLYS, Audrunas; MUNOS, Remi","62/517,826 09.06.2017 US; 62/578,387 27.10.2017 US",CN-201880027689.3; EP-2018731064
EP277550977,19175294,20.05.2019,3572984,27.11.2019,EP,IMPLEMENTING TRADITIONAL COMPUTER VISION ALGORITHMS AS NEURAL NETWORKS,,G06N 3/04; G06N 3/063; G06N 3/08; G06N 3/10,IMAGINATION TECH LTD,BRASNETT PAUL; BALDERAS DANIEL VALDEZ; DIKICI CAGATAY; CSEFALVAY SZABOLCS; HOUGH DAVID; SMITH TIMOTHY; IMBER JAMES,201808323 21.05.2018 GB,
EP198011332,15306836,18.11.2015,3171297,24.05.2017,EP,JOINT BOUNDARY DETECTION IMAGE SEGMENTATION AND OBJECT RECOGNITION USING DEEP LEARNING,"The present invention concerns methods and devices for image processing to achieve boundary detection, image segmentation into regions, image labeling into object classes ('semantic segmentation') and detection of the positions of objects in images using deep convolutional neural networks",G06K 9/46; G06K 9/48; G06K 9/62,CENTRALESUPÉLEC,KOKKINOS IASONAS; PARAGIOS NIKOS,15306836 18.11.2015 EP,
WO2015040450,PCT/IB2013/058604,17.09.2013,WO/2015/040450,26.03.2015,WO,MULTI-PURPOSE IMAGE PROCESSING CORE,"Object detection, recognition and tracking algorithms are used in many applications in vision. The outputs of these algorithms are essential for situational awareness and decision making. The accuracy and the processing latency of these algorithms are important parameters for the success of the system. This invention enhances the accuracy by enabling the neural network based techniques while fulfilling the latency constraints.",G06K 9/00,ASELSAN ELEKTRONIK SANAYI VE TICARET ANONIM SIRKETI,"OZSARAC, Ismail; YILMAZ, Ozgür; GUNAY, Omer",,KR-1020157033283; KZ-2015/1200.1
WO2019031083,PCT/JP2018/023910,18.06.2018,WO/2019/031083,14.02.2019,WO,METHOD AND SYSTEM FOR DETECTING ACTION,"A method and system for detecting actions of an object in a scene from a video of the scene. The video is a video sequence partitioned into chunks, and each chunk includes consecutive video frames. The method including the following elements. Acquiring the video of the scene, wherein the video includes a sequence of images. Tracking the object in the video, and for each object and each chunk of the video, further comprising: determining a sequence of contour images from video frames of the video sequence to represent motion data within a bounding box located around the object. Using the bounding box to produce cropped contour images and cropped images for one or more images in each chunk. Passing the cropped contour images and the cropped images to a recurrent neural network (RNN) that outputs a relative score for each action of interest.",G06K 9/00; G06K 9/46,MITSUBISHI ELECTRIC CORPORATION,"JONES, Michael; MARKS, Tim; KULKARNI, Kuldeep","15/670,021 07.08.2017 US",EP-2018742612
WO2018175750,PCT/US2018/023810,22.03.2018,WO/2018/175750,27.09.2018,WO,INTELLIGENT VISUAL OBJECT MANAGEMENT SYSTEM,"The inventors have recognized that improved management systems are required for visual objects. Stated broadly, various aspects and embodiments are directed to systems and methods for aggregating, curating, organizing, executing, and exchanging visual objects. Some embodiments relate to modeling user behavior and analyzing user behavior to drive more efficient processing involving visual objects. Other aspects include automatically monitoring user actions to build and maintain a continuously evolving, and more accurate data model of a user's visual object preferences. Additionally, various aspects relate to systems and methods for integration with third party services that allow users to automatically capture differences resulting from activation of visual objects.",G06F 3/048; G06F 17/30; G06Q 30/06,"SWOUP, LLC","PARROTTA, Philip, M. Jr.; TRAKAKIS, Aletia; KAIRINOS, Nikolas","62/474,968 22.03.2017 US",
EP232545709,18163728,23.03.2018,3396548,31.10.2018,EP,BARRIERS AND SYNCHRONIZATION FOR MACHINE LEARNING AT AUTONOMOUS MACHINES,"A mechanism is described for facilitating barriers and synchronization for machine learning at autonomous machines. A method of embodiments, as described herein, includes detecting thread groups relating to machine learning associated with one or more processing devices. The method may further include facilitating barrier synchronization of the thread groups across multiple dies such that each thread in a thread group is scheduled across a set of compute elements associated with the multiple dies, where each die represents a processing device of the one or more processing devices, the processing device including a graphics processor.",G06F 9/52; G06N 3/063,INTEL CORP,APPU ABHISHEK R; KOKER ALTUG; RAY JOYDEEP; VEMBU BALAJI; WEAST JOHN C; MACPHERSON MIKE B; KIM DUKHWAN; HURD LINDA L; JAHAGIRDAR SANJEEV; RANGANATHAN VASANTH,201715495112 24.04.2017 US,
WO2018083672,PCT/IB2017/056907,04.11.2017,WO/2018/083672,11.05.2018,WO,ENVIRONMENT NAVIGATION USING REINFORCEMENT LEARNING,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for training a reinforcement learning system. In one aspect, a method of training an action selection policy neural network for use in selecting actions to be performed by an agent navigating through an environment to accomplish one or more goals comprises: receiving an observation image characterizing a current state of the environment; processing, using the action selection policy neural network, an input comprising the observation image to generate an action selection output; processing, using a geometry-prediction neural network, an intermediate output generated by the action selection policy neural network to predict a value of a feature of a geometry of the environment when in the current state; and backpropagating a gradient of a geometry-based auxiliary loss into the action selection policy neural network to determine a geometry-based auxiliary update for current values of the network parameters.",G06N 3/04; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"VIOLA, Fabio; MIROWSKI, Piotr Wojciech; BANINO, Andrea; PASCANU, Razvan; SOYER, Hubert Josef; BALLARD, Andrew James; KUMARAN, Sudarshan; HADSELL, Raia Thais; SIFRE, Laurent; GOROSHIN, Rostislav; KAVUKCUOGLU, Koray; DENIL, Misha Man Ray","62/418,074 04.11.2016 US",JP-2019523617; EP-2017812054; KR-1020197015991; CN-201780078260.2
EP133853634,14191033,30.10.2014,2874097,20.05.2015,EP,Automatic scene parsing,"A method comprising: obtaining an image about an at least one object of interest and a three-dimensional (3D) point cloud about said object of interest; aligning the 3D point cloud with the image; segmenting the image into a plurality of superpixels preserving a graph structure and spatial neighbourhood of pixel data of the image; associating the superpixels in the image with a subset of said 3D points, said subset of 3D points representing a planar patch in said object of interest; extracting a plurality of 3D features for each patch; and assigning at least one vector representing at least one 3D feature with a semantic label on the basis of at least one extracted 3D feature of the patch.",G06K 9/00; G06T 7/00,NOKIA CORP,FAN LIXIN; HAJIANI M POURIA,201320361 19.11.2013 GB,
WO2016210432,PCT/US2016/039638,27.06.2016,WO/2016/210432,29.12.2016,WO,"ROBOTIC APPARATUS, SYSTEMS, AND RELATED METHODS","The present disclosure is directed to robotic systems, unmanned aerial vehicles in particular, and various systems and improvements within the field of robotics. Specifically, the present disclosure includes advancements in unmanned vehicle safety management systems and methods for unmanned vehicle safety management implementation and unmanned vehicle communication system and methods for unmanned vehicle communication through short message service (SMS). The use of a non-inertial frame lock for unmanned aerial vehicles, a foldable unmanned aerial vehicle landing platform, and an unmanned aerial vehicle landing and containment station is also provided. Additionally, a method and design for unmanned aerial vehicle delivery optimization and wind mapping using power consumption data of unmanned vehicles is disclosed.",G05D 1/00; B64C 39/02; G08C 17/02; G08G 5/00; H04B 7/185; H04W 4/02,APOLLO ROBOTIC SYSTEMS INCORPORATED,"DIXON, Taylor, Duane; WELLS, Alton, Vincent; HEWITT, Jake, August; BURNETT, Ethan, Ryan; HICKS, Steven, Pierre","62/185,098 26.06.2015 US; 62/188,855 06.07.2015 US; 62/191,009 10.07.2015 US; 62/191,670 13.07.2015 US; 62/193,854 17.07.2015 US; 62/194,897 21.07.2015 US; 62/201,394 05.08.2015 US; 62/218,696 15.09.2015 US; 14/924,475 27.10.2015 US; 62/247,918 29.10.2015 US; 62/255,413 14.11.2015 US",
WO2012047857,PCT/US2011/054727,04.10.2011,WO/2012/047857,12.04.2012,WO,COUPLING OF RATIONAL AGENTS TO QUANTUM PROCESSES,"The present invention provides devices, methods, and systems for coupling a rational agent to a quantum process. In particular, the present invention provides rational agents configured to influence a quantum process, or to derive information from a quantum process, and methods and uses thereof.",G06F 19/00; G06N 99/00,"MIND OVER MATTER AI, LLC.; LEVIN, Michael","LEVIN, Michael","61/389,483 04.10.2010 US",
WO2018055377,PCT/GB2017/052817,21.09.2017,WO/2018/055377,29.03.2018,WO,A NEURAL NETWORK AND METHOD OF USING A NEURAL NETWORK TO DETECT OBJECTS IN AN ENVIRONMENT,"A neural network comprising at least one layer containing a set of units having an input thereto and an output therefrom, the input being arranged to have data input thereto representing an n-dimensional grid comprising a plurality of cells; the set of units within the layer being arranged to output result data to a further layer the set of units within the layer being arranged to perform a convolution operation on the input data; and wherein the convolution operation is implemented using a feature centric voting scheme applied to the non-zero cells in the input to the layer.",G06K 9/46; G06K 9/00,OXFORD UNIVERSITY INNOVATION LTD.,"ENGELCKE, Martin; RAO, Dushyant; WANG, Dominic Zeng; TONG, Chi Hay; POSNER, Ingmar",1616095.4 21.09.2016 GB; 1705404.0 04.04.2017 GB,EP-2017777642
WO2018107128,PCT/US2017/065475,08.12.2017,WO/2018/107128,14.06.2018,WO,SYSTEMS AND METHODS FOR AUTOMATING DATA SCIENCE MACHINE LEARNING ANALYTICAL WORKFLOWS,Systems and methods for automating data science machine learning using analytical workflows are disclosed that provide for user interaction and iterative analysis including automated suggestions based on at least one analysis of a dataset.,G06F 15/18; G06Q 10/06; G06N 5/00,"U2 SCIENCE LABS, INC.","MINKIN, Andrew M.; MCNALLY, Mark; KNIGHT, William; MAJOR, Stephane; LAMOREAUX, Richard; HERNANDEZ, Leandro","62/432,558 09.12.2016 US",
WO2016187472,PCT/US2016/033363,19.05.2016,WO/2016/187472,24.11.2016,WO,MULTILINGUAL IMAGE QUESTION ANSWERING,"Embodiments of a multimodal question answering (mQA) system are presented to answer a question about the content of an image. In embodiments, the model comprises four components: a Long Short-Term Memory (LSTM) component to extract the question representation; a Convolutional Neural Network (CNN) component to extract the visual representation; an LSTM component for storing the linguistic context in an answer, and a fusing component to combine the information from the first three components and generate the answer. A Freestyle Multilingual Image Question Answering (FM-IQA) dataset was constructed to train and evaluate embodiments of the mQA model. The quality of the generated answers of the mQA model on this dataset is evaluated by human judges through a Turing Test.",G01C 21/36; G06E 1/00; G06E 3/00; G06F 3/01; G06F 17/00; G06F 17/27; G06F 17/30,BAIDU USA LLC,"GAO, Haoyuan; MAO, Junhua; ZHOU, Jie; HUANG, Zhiheng; WANG, Lei; XU, Wei","62/164,984 21.05.2015 US; 15/137,179 25.04.2016 US",JP-2017514532; EP-2016797334
WO2019005999,PCT/US2018/039804,27.06.2018,WO/2019/005999,03.01.2019,WO,METHOD AND SYSTEM FOR PERFORMING SIMULTANEOUS LOCALIZATION AND MAPPING USING CONVOLUTIONAL IMAGE TRANSFORMATION,"Augmented reality devices and methods for computing a homography based on two images. One method may include receiving a first image based on a first camera pose and a second image based on a second camera pose, generating a first point cloud based on the first image and a second point cloud based on the second image, providing the first point cloud and the second point cloud to a neural network, and generating, by the neural network, the homography based on the first point cloud and the second point cloud. The neural network may be trained by generating a plurality of points, determining a 3D trajectory, sampling the 3D trajectory to obtain camera poses viewing the points, projecting the points onto 2D planes, comparing a generated homography using the projected points to the ground-truth homography and modifying the neural network based on the comparison.",G06K 9/46; G06K 9/62,"MAGIC LEAP, INC.","DETONE, Daniel L.; MALISIEWICZ, Tomasz Jan; RABINOVICH, Andrew","62/526,203 28.06.2017 US",AU-2018292610; IL-271519; CN-201880043635.6; EP-2018824287
WO2018064169,PCT/US2017/053729,27.09.2017,WO/2018/064169,05.04.2018,WO,FACE MODEL CAPTURE BY A WEARABLE DEVICE,"Systems and methods for generating a face model for a user of a head-mounted device are disclosed. The head-mounted device can include one or more eye cameras configured to image the face of the user while the user is putting the device on or taking the device off. The images obtained by the eye cameras may be analyzed using a stereoscopic vision technique, a monocular vision technique, or a combination, to generate a face model for the user.",G02B 27/01; G06F 3/01; G06K 9/00; G06T 7/62; G06T 19/00; G06T 19/20; G09G 5/00,"MAGIC LEAP, INC.","AMAYEH, Gholamreza; KAEHLER, Adrian; LEE, Douglas","62/400,907 28.09.2016 US",AU-2017335736; KR-1020197010685; IL-265520; CA-3037047; EP-2017857333; JP-2019515206; CN-201780072862.7
WO2020042169,PCT/CN2018/103645,31.08.2018,WO/2020/042169,05.03.2020,WO,3D OBJECT RECOGNITION USING 3D CONVOLUTIONAL NEURAL NETWORK WITH DEPTH BASED MULTI-SCALE FILTERS,"Techniques related to training and implementing convolutional neural networks for object recognition are discussed. Such techniques may include applying, at a first convolutional layer of the convolutional neural network, 3D filters of different spatial sizes to an 3D input image segment to generate multi-scale feature maps such that each feature map has a pathway to fully connected layers of the convolutional neural network, which generate object recognition data corresponding to the 3D input image segment.",G06N 3/04; G06N 3/08; G06K 9/46,"INTEL CORPORATION; YOU, Ganmei; WANG, Zhigang; WANG, Dawei","YOU, Ganmei; WANG, Zhigang; WANG, Dawei",,
WO2019238483,PCT/EP2019/064593,05.06.2019,WO/2019/238483,19.12.2019,WO,CHARACTERIZING ACTIVITY IN A RECURRENT ARTIFICIAL NEURAL NETWORK AND ENCODING AND DECODING INFORMATION,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for characterizing activity in a recurrent artificial neural network and encoding and decoding information. In one aspect, a method can include characterizing activity in an artificial neural network. The method is performed by data processing apparatus and can include identifying clique patterns of activity of the artificial neural network. The clique patterns of activity can enclose cavities.",G06N 3/00; G06N 3/04; G06N 3/08; G06N 5/00,INAIT SA,"MARKRAM, Henry; LEVI, Ran; HESS BELLWALD, Kathryn Pamela","16/004,635 11.06.2018 US; 16/004,837 11.06.2018 US; 16/004,796 11.06.2018 US; 16/004,757 11.06.2018 US; 16/004,671 11.06.2018 US",
WO2018187788,PCT/US2018/026616,06.04.2018,WO/2018/187788,11.10.2018,WO,METHOD FOR TRACKING STOCK LEVEL WITHIN A STORE,"One variation of a method for tracking stock level within a store includes: at a robotic system, navigating along a first inventory structure in the store, broadcasting radio frequency interrogation signals according to a first set of wireless scan parameters, and recording a first set of wireless identification signals returned by radio frequency identification tags coupled to product units arranged on the first inventory structure; generating a first list of product units arranged on the first inventory structure based on the first set of wireless identification signals; detecting a first product quantity difference between the first list of product units and a first target stock list assigned to the first inventory structure by a planogram of the store; and generating a stock correction prompt for the first inventory structure in response to the first product quantity difference.",G06Q 10/08; G06Q 10/06; G06K 9/20; G06K 9/60; G06K 9/78,SIMBE ROBOTICS INC,"TIWARI, Durgesh; BOGOLEA, Bradley; SHAH, Mirza, Akbar; GEE, Jeffrey","62/482,907 07.04.2017 US",CN-201880037830.8; EP-2018780360; JP-2019554749
WO2015048573,PCT/US2014/057900,26.09.2014,WO/2015/048573,02.04.2015,WO,STRUCTURE BASED PREDICTIVE MODELING,"Disclosed are methods for building a sequence activity model with reference to structural data, which model can be used to guide directed evolution of proteins having beneficial properties. Some embodiments use genetic algorithms and structural data to filter out uninformative data. Some embodiments use a support vector machine to train the sequence activity model. The filtering and training methods can generate a sequence activity model having higher predictive power than conventional modeling methods. Systems and computer program products implementing the methods are also provided.",G06F 19/16,"CODEXIS, INC.","SARMIENTO, Russell Javiniar; BASKERVILLE, Donald Scott; ZHANG, Xiyun","61/883,919 27.09.2013 US",EP-2014786396; CN-201480065176.3; CA-2923758; JP-2016516871; AU-2014324670; SG-11201601692P; IL-244458; RU-2016116261
WO2019238512,PCT/EP2019/064740,06.06.2019,WO/2019/238512,19.12.2019,WO,CHARACTERIZING ACTIVITY IN A RECURRENT ARTIFICIAL NEURAL NETWORK AND ENCODING AND DECODING INFORMATION,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for characterizing activity in a recurrent artificial neural network and encoding and decoding information. In one aspect, a method for identifying decision moments in a recurrent artificial neural network can include determining a complexity of patterns of activity in the recurrent artificial neural network, determining a timing of activity having a complexity that is distinguishable from complexity of other activity that is responsive to the input, and identifying a decision moment based on the timing of the activity that has the distinguishable complexity",G06N 3/04; G06N 3/00; G06N 3/08; G06N 5/00,INAIT SA,"MARKRAM, Henry; LEVI, Ran; HESS BELLWALD, Kathryn Pamela","16/004,635 11.06.2018 US; 16/004,837 11.06.2018 US; 16/004,796 11.06.2018 US; 16/004,757 11.06.2018 US; 16/004,671 11.06.2018 US",
WO2017192181,PCT/US2016/069262,29.12.2016,WO/2017/192181,09.11.2017,WO,AUTOMATIC DETERMINATION OF TIMING WINDOWS FOR SPEECH CAPTIONS IN AN AUDIO STREAM,"A content system accessing an audio stream. The content system inputs segments of the audio stream into a speech classifier for classification, the speech classifier generating, for the segments of the audio stream, raw scores representing likelihoods that the respective segment of the audio stream includes an occurrence of a speech sound. The content system generates binary scores for the audio stream based on the set of raw scores, each binary score generated based on an aggregation of raw scores from consecutive series of the segments of the audio stream. The content system generates one or more timing windows for the speech sounds in the audio stream based on the binary scores, each timing window indicating an estimate of a beginning and ending timestamps of one or more speech sounds in the audio stream.",G10L 19/16; G10L 21/04; G10L 25/93,GOOGLE LLC,"CHAUDHURI, Sourish; ĆIRIĆ, Nebojša; PHAM, Khiem","15/225,513 01.08.2016 US; 62/330,836 02.05.2016 US",EP-2016901159
WO2014100029,PCT/US2013/075848,17.12.2013,WO/2014/100029,26.06.2014,WO,METHOD AND APPARATUS FOR CONDUCTING CONTEXT SENSITIVE SEARCH WITH INTELLIGENT USER INTERACTION FROM WITHIN A MEDIA EXPERIENCE,"In some embodiments, the invention involves context based search engine using a user selected term within a media experience. A natural language processor module is configured to provide context based keywords related to the search term and from within the media experience. In some embodiments, a proximity based statistical analysis is used to derive the keywords. The keywords are provided to at least one content browser or other search engine(s) to effect the search. In some embodiments, a machine learning module is communicatively coupled to the natural language processer to further refine the context for selecting relevant keywords. The context search engine, natural language processor module, machine learning module and search engine may reside on the same computing device or be distributed among a variety of local, remote and cloud devices for processing. Other embodiments are described and claimed.",G06F 17/30,"INTEL CORPORATION; MO, Stanley; SZILAGYI, Victor; WOUHAYBI, Rita H.","MO, Stanley; SZILAGYI, Victor; WOUHAYBI, Rita H.","13/722,274 20.12.2012 US",EP-2013866022
WO2020018726,PCT/US2019/042296,17.07.2019,WO/2020/018726,23.01.2020,WO,WIRELESS COMMUNICATIONS SYSTEM AND METHOD,"A wireless communication system includes a smart device configured for transcribing text- to- speech (STT) for display. The smart device interfaces with a radio communications device, for example, in an aircraft (AC). The system includes a filter for optimizing STT functions. Such functions are further optimized by restricting the databases of information, including geographic locations, aircraft identifications and carrier information, whereby the database search functions are optimized. Methods for wireless communications using smart devices and STT functionality are disclosed.",G10L 15/02; G10L 15/16; G10L 15/18; G10L 15/20; G10L 15/22; G10L 15/26,"APPAREO SYSTEMS, LLC","GELINSKE, Joshua, N.; THUROW, Bradley, R.; TRANA, Jesse, S.; SMITH, Dakota, M.; BUTTS, Nicholas, L.; JOHNSON, Jeffrey, L.; ASLAKSON, Derek, B.; YOUNG, Jaden, C.","62/699,044 17.07.2018 US; 62/715,380 07.08.2018 US",
EP289840121,19199521,04.04.2018,3620992,11.03.2020,EP,NEURAL NETWORK PROCESSOR AND NEURAL NETWORK COMPUTATION METHOD,"The present disclosure provides a neural network processor and neural network computation method that deploy a memory and a cache to perform a neural network computation, where the memory may be configured to store data and instructions of the neural network computation, the cache may be connected to the memory via a memory bus, thereby, the actual compute ability of hardware may be fully utilized, the cost and power consumption overhead may be reduced, parallelism of the network may be fully utilized, and the efficiency of the neural network computation may be improved.",G06N 3/04; G06N 3/063,SHANGHAI CAMBRICON INFORMATION TECH CO LTD,CHEN TIANSHI; CHEN XIAOBING; ZHI TIAN; DU ZIDONG,201710222232 06.04.2017 CN; 201710227493 07.04.2017 CN; 201710256444 19.04.2017 CN; 201710266052 21.04.2017 CN; 201710312415 05.05.2017 CN; 2018081929 04.04.2018 CN; 18780474 04.04.2018 EP,
WO2019040763,PCT/US2018/047775,23.08.2018,WO/2019/040763,28.02.2019,WO,CINEMATIC SPACE-TIME VIEW SYNTHESIS FOR ENHANCED VIEWING EXPERIENCES IN COMPUTING ENVIRONMENTS,"A mechanism is described for facilitating cinematic space-time view synthesis in computing environments according to one embodiment. A method of embodiments, as described herein, includes capturing, by one or more cameras, multiple images at multiple positions or multiple points in times, where the multiple images represent multiple views of an object or a scene, where the one or more cameras are coupled to one or more processors of a computing device. The method further includes synthesizing, by a neural network, the multiple images into a single image including a middle image of the multiple images and representing an intermediary view of the multiple views.",G06T 3/40,"INTEL CORPORATION; SOMANATH, Gowri; NESTARES, Oscar","SOMANATH, Gowri; NESTARES, Oscar","15/685,213 24.08.2017 US",
WO2020051087,PCT/US2019/049077,30.08.2019,WO/2020/051087,12.03.2020,WO,SYSTEMS AND METHODS FOR QUERYING A DISTRIBUTED INVENTORY OF VISUAL DATA,"System, methods, and other embodiments described herein relate to using vehicles as mobile observation platforms and improving the querying of visual data within the vehicles by leveraging edge computing resources of the vehicles in a distributed network. In one embodiment, a method includes, in response to receiving (610), in a selected vehicle (100) that is equipped with at least one camera (126), a visual query (260) from a remote device, identifying search parameters (620) from the query that specify at least visual content that is to be identified. The method includes analyzing (640) a subset of a visual inventory (250) to identify whether the subset includes the visual content by using at least a machine vision model executing on a processor within the selected vehicle (100). The visual inventory includes camera data that is acquired by the selected vehicle. The method includes communicating (650) detection results about whether the subset includes the visual content to the remote device.",G06K 9/00,"TOYOTA CONNECTED NORTH AMERICA, INC.","KURSAR, Brian M.","16/120,810 04.09.2018 US",
WO2011014810,PCT/US2010/043980,30.07.2010,WO/2011/014810,03.02.2011,WO,"SYSTEMS, METHODS, AND APPARATUS FOR RECONSTRUCTION OF 3-D OBJECT MORPHOLOGY, POSITION, ORIENTATION AND TEXTURE USING AN ARRAY OF TACTILE SENSORS","Systems, methods, and apparatus are provided using signals from a set of tactile sensors mounted on a surface to determine the three-dimensional morphology (e.g., size, shape, orientation, and/or position) and texture of objects of arbitrary shape. Analytical, numerical, and/or neural network approaches can be used to interpret the sensory data.",G06K 9/00; G06T 7/00; G01B 5/20; G01B 5/28,"NORTHWESTERN UNIVERSITY; HARTMANN, Mitra, J.; SOLOMON, Joseph, H.","HARTMANN, Mitra, J.; SOLOMON, Joseph, H.","61/229,991 30.07.2009 US",
WO2020033594,PCT/US2019/045571,07.08.2019,WO/2020/033594,13.02.2020,WO,INTERPRETABLE DEEP MACHINE LEARNING FOR CLINICAL RADIOLOGY,"One aspect of the invention provides a computer-implemented method of identifying one or more clinical factors associated with an artificial intelligence prediction. The computer implemented method includes: applying a previously trained deep neural network to one or more images for a subject to produce a prediction, the previously trained deep neural network comprising a plurality of nodes; comparing outputs of the nodes to previously identified patterns of node outputs for a plurality of individual clinical factors; and identifying which of the plurality of individual clinical factors are most correlated with the outputs of the nodes.",G06F 19/24; G06N 3/08; G16H 50/20; G01N 33/574,YALE UNIVERSITY,"DUNCAN, James S.; LETZEN, Brian; CHAPIRO, Julius; WANG, Clinton","62/715,647 07.08.2018 US",
WO2018210796,PCT/EP2018/062486,15.05.2018,WO/2018/210796,22.11.2018,WO,ACTION RECOGNITION IN VIDEOS USING 3D SPATIO-TEMPORAL CONVOLUTIONAL NEURAL NETWORKS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for processing video data. An example system receives video data and generates optical flow data. An image sequence from the video data is provided to a first 3D spatio-temporal convolutional neural network to process the image data in at least three space-time dimensions and to provide a first convolutional neural network output. A corresponding sequence of optical flow image frames is provided to a second 3D spatio- temporal convolutional neural network to process the optical flow data in at least three space- time dimensions and to provide a second convolutional neural network output. The first and second convolutional neural network outputs are combined to provide a system output.",G06K 9/00; G06K 9/46; G06K 9/62; G06N 3/04,DEEPMIND TECHNOLOGIES LIMITED,"CARREIRA, Joao; ZISSERMAN, Andrew","62/506,507 15.05.2017 US",EP-2018732665; CN-201880028962.4
WO2018211138,PCT/EP2018/063275,22.05.2018,WO/2018/211138,22.11.2018,WO,MULTITASK NEURAL NETWORK SYSTEMS WITH TASK-SPECIFIC POLICIES AND A SHARED POLICY,"A method is proposed for training a multitask computer system, such as a multitask neural network system. The system comprises a set of trainable workers and a shared module. The trainable workers and shared module are trained on a plurality of different tasks, such that each worker learns to perform a corresponding one of the tasks according to a respective task policy, and said shared policy network learns a multitask policy which represents common behavior for the tasks. The coordinated training is performed by optimizing an objective function comprising, for each task: a reward term indicative of an expected reward earned by a worker in performing the corresponding task according to the task policy; and at least one entropy term which regularizes the distribution of the task policy towards the distribution of the multitask policy.",G06N 3/04; G06N 3/00; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"PASCANU, Razvan; HADSELL, Raia Thais; BAPST, Victor Constant; CZARNECKI, Wojciech; KIRKPATRICK, James; TEH, Yee Whye; HEESS, Nicolas Manfred Otto","62/508,991 19.05.2017 US",EP-2018726143
WO2017044415,PCT/US2016/050389,06.09.2016,WO/2017/044415,16.03.2017,WO,SYSTEM AND METHOD FOR ELICITING OPEN-ENDED NATURAL LANGUAGE RESPONSES TO QUESTIONS TO TRAIN NATURAL LANGUAGE PROCESSORS,"Systems and methods gathering text commands in response to a command context using a first crowdsourced are discussed herein. A command context for a natural language processing system may be identified, where the command context is associated with a command context condition to provide commands to the natural language processing system. One or more command creators associated with one or more command creation devices may be selected. A first application one the one or more command creation devices may be configured to display command creation instructions for each of the one or more command creators to provide text commands that satisfy the command context, and to display a field for capturing a user-generated text entry to satisfy the command creation condition in accordance with the command creation instructions. Systems and methods for reviewing the text commands using second and crowdsourced jobs are also presented herein.",G10L 15/183; G10L 15/26,VOICEBOX TECHNOLOGIES CORPORATION,"ROTHWELL, Spencer, John; BRAGA, Daniela; ELSHENAWY, Ahmad, Khamis; CARTER, Stephen, Steele","62/215,115 07.09.2015 US",
WO2018110963,PCT/KR2017/014617,13.12.2017,WO/2018/110963,21.06.2018,WO,MOVABLE OBJECT AND METHOD FOR CONTROLLING THE SAME,"Embodiments of the present disclosure relate to a movable object and a method for controlling the same. A method for controlling a movable object may include acquiring virtual data representing distances between each of a plurality of positions within an area and surfaces in the area, in a plurality of directions, respectively, based on a map of the area. An algorithm, such as a machine learning algorithm, may be executed that outputs positions corresponding to the virtual data. Actual distance data between the movable object and a plurality of surfaces in the vicinity of the movable object may be acquired. An actual position of the movable object may then be estimated corresponding to the actual distance data by executing the algorithm using the actual distance data. The movable object may be controlled based on the estimated actual position.",G05D 1/02; G06N 3/08,"SAMSUNG ELECTRONICS CO., LTD.","YOON, Suk June; PARK, Soon Yong; KWAK, No San; ROH, Kyung Shik; AHN, Sung Hwan; CHOI, Min Yong",10-2016-0172299 16.12.2016 KR,EP-2017880334
EP284291901,19191329,12.08.2019,3611698,19.02.2020,EP,AUTOMATED SUPERVISION AND INSPECTION OF ASSEMBLY PROCESS,A method and apparatus for performing automated supervision and inspection of an assembly process. The method is implemented using a computer system. Sensor data is generated at an assembly site using a sensor system positioned relative to the assembly site. A current stage of an assembly process for building an assembly at the assembly site is identified using the sensor data. A context for the current stage is identified. A quality report for the assembly is generated based on the sensor data and the context for the current stage.,G06T 7/00,BOEING CO,YU HUAFENG; REMINE DANIEL S; STAUDINGER TYLER CHARLES,2021599 11.09.2018 NL; 201862718786 14.08.2018 US,
WO2018236587,PCT/US2018/036329,06.06.2018,WO/2018/236587,27.12.2018,WO,ROBOTIC SYSTEMS FOR DETERMINING A POSE OF A MEDICAL DEVICE IN LUMINAL NETWORKS,Certain aspects relate to systems and techniques for navigation-assisted medical devices. Some aspects relate to correlating features of depth information generated based on captured images of an anatomical luminal network with virtual features of depth information generated based on virtual images of a virtual representation of the anatomical luminal network in order to automatically determine aspects of a pose of a medical device within the luminal network.,A61B 34/20; A61B 34/30; A61B 34/00; A61B 5/06; B25J 9/16; A61B 6/12,"AURIS HEALTH, INC.","UMMALANENI, Ritwik","15/631,691 23.06.2017 US",EP-2018821509; CN-201880044512.4; KR-1020207002269; AU-2018289116
WO2018084577,PCT/KR2017/012275,01.11.2017,WO/2018/084577,11.05.2018,WO,"DATA RECOGNITION MODEL CONSTRUCTION APPARATUS AND METHOD FOR CONSTRUCTING DATA RECOGNITION MODEL THEREOF, AND DATA RECOGNITION APPARATUS AND METHOD FOR RECOGNIZING DATA THEREOF","Disclosed is a data recognition model construction apparatus. The data recognition model construction apparatus includes a video inputter configured to receive a video, an image composition unit configured to, based on a common area included in each of a plurality of images that form at least a portion of the video, generate a composition image by overlaying at least a portion of the plurality of images, a learning data inputter configured to receive the generated composition image, a model learning unit configured to make a data recognition model learn using the generated composition image, and a model storage configured to store the learnt data recognition model.",G06K 9/00; G06T 17/00; G06Q 50/22,"SAMSUNG ELECTRONICS CO., LTD.","KIM, Ji-man; PARK, Chan-jong; YANG, Do-jun; LEE, Hyun-woo",10-2016-0145748 03.11.2016 KR; 10-2017-0104312 17.08.2017 KR,CN-201780067877.4; EP-2017867457
WO2019132518,PCT/KR2018/016678,26.12.2018,WO/2019/132518,04.07.2019,WO,IMAGE ACQUISITION DEVICE AND METHOD OF CONTROLLING THE SAME,"Provided are an artificial intelligence (AI) system that mimics functions, such as recognition and determination by human brains, by utilizing a machine learning algorithm and applications of the AI system. An image acquisition device is disclosed including a camera configured to acquire a first image, at least one processor configured to: input the first image to a first AI neural network; detect, by the first AI neural network from data corresponding to a plurality of object included the first image, first data corresponding to the main object and second data corresponding to the sub-object, and generate, using a second AI neural network, a second image by restoring third data corresponding to at least a portion of the main object hidden by the sub-object, wherein the third data replaces the second data; and a display configured to display at least one of the first image and the second image.",G06T 1/00; G06T 7/11; G06T 5/00; G06T 7/20,"SAMSUNG ELECTRONICS CO., LTD.","JUNG, Jaeho; SUNG, Yeultak",10-2017-0180036 26.12.2017 KR,
WO2017160516,PCT/US2017/020846,06.03.2017,WO/2017/160516,21.09.2017,WO,DEPTH FROM TIME-OF-FLIGHT USING MACHINE LEARNING,"A depth detection apparatus is described which has a memory storing raw time-of-flight sensor data received from a time-of-flight sensor. The depth detection apparatus also has a trained machine learning component having been trained using training data pairs. A training data pair comprises at least one simulated raw time-of-flight sensor data value and a corresponding simulated ground truth depth value. The trained machine learning component is configured to compute in a single stage, for an item of the stored raw time-of-flight sensor data, a depth value of a surface depicted by the item, by pushing the item through the trained machine learning component.",G06K 9/62; G06K 9/20; G01S 17/89,"MICROSOFT TECHNOLOGY LICENSING, LLC","NOWOZIN, Sebastian; ADAM, Amit; MAZOR, Shai; YAIR, Omer","15/068,632 13.03.2016 US",EP-2017714934
WO2017031356,PCT/US2016/047627,18.08.2016,WO/2017/031356,23.02.2017,WO,DISCRETE VARIATIONAL AUTO-ENCODER SYSTEMS AND METHODS FOR MACHINE LEARNING USING ADIABATIC QUANTUM COMPUTERS,"A computational system can include digital circuitry and analog circuitry, for instance a digital processor and a quantum processor. The quantum processor can operate as a sample generator providing samples. Samples can be employed by the digital processing in implementing various machine learning techniques. For example, the computational system can perform unsupervised learning over an input space, for example via a discrete variational auto-encoder, and attempting to maximize the log-likelihood of an observed dataset. Maximizing the log-likelihood of the observed dataset can include generating a hierarchical approximating posterior.",G06N 99/00,D-WAVE SYSTEMS INC.,"ROLFE, Jason","62/206,974 19.08.2015 US; 62/268,321 16.12.2015 US; 62/307,929 14.03.2016 US",EP-2016837861; US-15753666
WO2017150032,PCT/JP2017/003079,24.01.2017,WO/2017/150032,08.09.2017,WO,METHOD AND SYSTEM FOR DETECTING ACTIONS OF OBJECT IN SCENE,"A method and system detects actions of an object in a scene by first acquiring a video of the scene as a sequence of images, wherein each image includes pixels, wherein the video is partitioned into chunks. The object in the video is tracked. For each object and each chunk of the video, trajectories of the pixels within a bounding box located over the object are tracked, and cropped trajectories and cropped images for one or more images in the chunk are produced using the bounding box. Then, the cropped trajectories and cropped images are passed to a recurrent neural network (RNN) that outputs a relative score for each action of interest.",G06K 9/00; G06K 9/46,MITSUBISHI ELECTRIC CORPORATION,"JONES, Michael, J.; MARKS, Tim; TUZEL, Oncel; SINGH, Bharat","15/058,264 02.03.2016 US",JP-2018532185
WO2020038699,PCT/EP2019/070808,01.08.2019,WO/2020/038699,27.02.2020,WO,METHOD AND SYSTEM FOR TRAFFIC LIGHT SIGNAL DETECTION AND USAGE,"The present invention relates to a method comprising a data processing device predicting a time for a future state change of a first traffic light. The present invention further relates to a method comprising a data processing device generating a map of traffic lights, wherein the map of traffic lights comprises a location of at least one localization traffic light. The present invention also relates to methods combining these methods, and to corresponding systems.",G06K 9/00,STARSHIP TECHNOLOGIES OÜ,"KORJUS, Kristjan; KHARAGORGIIEV, Sergii; RAAG, Rasmus",18190327.9 22.08.2018 EP,
WO2019028725,PCT/CN2017/096755,10.08.2017,WO/2019/028725,14.02.2019,WO,CONVOLUTIONAL NEURAL NETWORK FRAMEWORK USING REVERSE CONNECTIONS AND OBJECTNESS PRIORS FOR OBJECT DETECTION,"A convolutional neural network framework is described that uses reverse connection and obviousness priors for object detection. A method includes performing a plurality of layers of convolutions and reverse connections on a received image to generate a plurality of feature maps, determining an objectness confidence for candidate bounding boxes based on outputs of an objectness prior, determining a joint loss function for each candidate bounding box by combining an objectness loss, a bounding box regression loss and a classification loss, calculating network gradients over positive boxes and negative boxes, updating network parameters within candidate bounding boxes using the joint loss function, repeating performing the convolutions through to updating network parameters until the training converges, and outputting network parameters for object detection based on the training images.",G06K 9/62,"INTEL CORPORATION; YAO, Anbang; KONG, Tao; LU, Ming; GUO, Yiwen; CHEN, Yurong","YAO, Anbang; KONG, Tao; LU, Ming; GUO, Yiwen; CHEN, Yurong",,
EP260716741,17883649,12.10.2017,3557521,23.10.2019,EP,INDUSTRIAL DEVICE IMAGE RECOGNITION PROCESSOR AND CONTROLLER,"[Problem] To improve practical applicability of an image recognition process. [Solution] Provided is an image recognition processor 11, the integrated circuit of which implements the functions of: storing an algorithm of an image data process which has been determined on the basis of prior learning; acquiring image data of an image which includes a prescribed pattern; carrying out an image data recognition process on the basis of the algorithm; and outputting identification information for identifying the recognized pattern. The output of the identification information is processed by a neural network which has learned correspondences between prescribed patterns and types, and the neural network selectively classifies and outputs from the types of plurality of patterns prepared in advance. A position region of the recognized pattern is detected in the image, and the image data is processed and outputted in the image.",G06T 1/40,YASKAWA ELECTRIC CORP,ADACHI MASARU,2016245763 19.12.2016 JP; 2017036974 12.10.2017 JP,
WO2004027704,PCT/EP2002/010646,23.09.2002,WO/2004/027704,01.04.2004,WO,SPIKING NEURAL NETWORK DEVICE,"Device comprising storage means (51) for storing a genotypic representation (3) of a spiking neural network comprising spiking neurons (1) and input neurons (2) connected by synapses, and computer program portions for performing the steps of mutating said genotypic representation (3) and computing a fitness value associated to said mutated genotypic representation (3). The spiking neural network implemented in this device can thus be trained and used for various control systems, achieving better results, thanks to its highly non-linear behavior, than standard prior art neural networks.",G06N 3/04; G06N 3/08,"ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE (EPFL); FLOREANO, Dario","FLOREANO, Dario","60/412,315 20.09.2002 US",JP-null
WO2014205231,PCT/US2014/043206,19.06.2014,WO/2014/205231,24.12.2014,WO,DEEP LEARNING FRAMEWORK FOR GENERIC OBJECT DETECTION,"Object detection remains a fundamental problem and bottleneck to be addressed for making vision algorithms practical. Despite the promise, deep learning methods have not been extensively investigated on object detection problems. In this disclosure, deep learning approaches are developed for object detection problems. Specifically, learning algorithms are developed that learn hierarchical features (e.g., object parts) that can provide useful discriminative information for object detection tasks. In addition, algorithms are developed to improve invariance and discriminative power of the learned features.",G06T 7/20; G06K 9/00,THE REGENTS OF THE UNIVERSITY OF MICHIGAN,"LEE, Honglak; SOHN, Kihyuk","61/836,845 19.06.2013 US",
WO2019147687,PCT/US2019/014775,23.01.2019,WO/2019/147687,01.08.2019,WO,COMPUTER VISION SYSTEMS AND METHODS FOR UNSUPERVISED REPRESENTATION LEARNING BY SORTING SEQUENCES,"Systems and methods for unsupervised representation learning by sorting sequences are provided. An unsupervised representation learning approach is provided which uses videos without semantic labels. The temporal coherence as a supervisory signal can be leveraged by formulating representation learning as a sequence sorting task. A plurality of temporally shuffled frames (i.e., in non-chronological order) can be used as inputs and a convolutional neural network can be trained to sort the shuffled sequences and to facilitate machine learning of features by the convolutional neural network. Features are extracted from all frame pairs and aggregated to predict the correct sequence order. As sorting shuffled image sequence requires an understanding of the statistical temporal structure of images, training with such a proxy task can allow a computer to learn rich and generalizable visual representations from digital images.",G06T 7/246; G06K 9/32; G06K 9/46; G06T 7/215,"INSURANCE SERVICES OFFICE, INC.","LEE, Hsin-ying; HUANG, Jia-bin; SINGH, Maneesh, Kumar; YANG, Ming-Hsuan","62/620,700 23.01.2018 US",
EP241675072,18193107,07.09.2018,3477638,01.05.2019,EP,DIALOG SYSTEM WITH SELF-LEARNING NATURAL LANGUAGE UNDERSTANDING,"Example implementations described herein are directed to a dialog system with self-learning natural language understanding (NLU), involving a client-server configuration. If the NLU results in the client is not confident, the NLU will be done again in the server. In the dialog system, the human user and the system communicate via speech or text information. The examples of such products include robots, interactive voice response system (IVR) for call centers, voice-enabled personal devices, car navigation system, smart phones, and voice input devices in the work environments where the human operator cannot operate the devices by hands.",G10L 15/30; G06F 16/332; G06F 17/27; G10L 15/06; G10L 15/065; G10L 15/18; G10L 15/22,HITACHI LTD,HOMMA TAKESHI; TOGAMI MASAHITO,201715794825 26.10.2017 US,
WO2018017973,PCT/US2017/043325,21.07.2017,WO/2018/017973,25.01.2018,WO,COMPUTATIONAL ANALYSIS OF OBSERVATIONS FOR DETERMINATION OF FEEDBACK,"A system comprises one or more observation stations. Each observation station of the one or more observation stations comprises a corresponding set of one or more sensors. Additionally, the system comprises one or more physical machines that implement a computation engine configured to receive first observation data from the one or more observation stations. The computation engine may use the first observation data to train a machine learning system. The computation engine may subsequently use the trained machine learning system to provide feedback regarding an additional instance of the observation subject. The computation engine outputs the feedback.",G05B 17/02; G05B 19/418; G05B 23/02; G06F 15/16; G06F 19/00; G06Q 10/06,SRI INTERNATIONAL,"AKELLA, Prasad Narasimha; RAMAMURTHY, Bhaskar; KOTHARI, Manish; MARCOTULLIO, John Peter","62/365,508 22.07.2016 US",
WO2020047314,PCT/US2019/048903,29.08.2019,WO/2020/047314,05.03.2020,WO,SECURE EXPLORATION FOR REINFORCEMENT LEARNING,"A secured exploration agent for reinforcement learning (RL) is provided. Securitizing an exploration agent includes training the exploration agent to avoid dead-end states and dead-end trajectories. During training, the exploration agent ""learns"" to identify and avoid dead-end states of a Markov Decision Process (MDP). The secured exploration agent is utilized to safely and efficiently explore the environment, while significantly reducing the training time, as well as the cost and safety concerns associated with conventional RL. The secured exploration agent is employed to guide the behavior of a corresponding exploitation agent. During training, a policy of the exploration agent is iteratively updated to reflect an estimated probability that a state is a dead-end state. The probability, via the exploration policy, that the exploration agent chooses an action that results in a transition to a dead-end state is reduced to reflect the estimated probability that the state is a dead-end state.",G06N 3/08; G06N 3/00; G06N 7/00,"MICROSOFT TECHNOLOGY LICENSING, LLC","VAN SEIJEN, Harm Hendrik; FATEMI BOOSHEHRI, Seyed Mehdi","62/725,981 31.08.2018 US; 16/554,525 28.08.2019 US",
EP234473538,18173840,23.05.2018,3410348,05.12.2018,EP,METHOD AND APPARATUS FOR BUILDING A PARKING OCCUPANCY MODEL,An approach is provided for generating parking occupancy data using a machine learning model. The approach involves determining one or more classification features of a road link. The approach also involves processing the one or more classification features using the machine learning model to match the road link to a link category. The approach further involves determining a parking occupancy pattern for the road link based on the link category. The approach further involves creating or updating a parking occupancy record of a geographic record corresponding to road link using the parking occupancy pattern.,G06K 9/00,HERE GLOBAL BV,YUNJIE ZHAO; GIURGIU GAVRIL; CAJIAS RAUL; STENNETH LEON; LINDER ERIC,201715610237 31.05.2017 US,
WO2020047338,PCT/US2019/048939,29.08.2019,WO/2020/047338,05.03.2020,WO,COMPUTER VISION SYSTEM,"A raycaster performs a raycasting algorithm, where the raycasting algorithm takes, as an input, a sparse hierarchical volumetric data structure. Performing the raycasting algorithm includes casting a plurality of rays from a reference point into the 3D volume, and, for each of the plurality of rays, traversing the ray to determine whether voxels in the set of voxels are intersected by the ray and are occupied, where the ray is to be traversed according to an approximate traversal algorithm.",G06T 15/06; G06T 15/08; G06T 15/00; G06N 3/02,"MOVIDIUS LTD.; KOMENDA, J. Kyle; PEÑA, Dexmont; MARTÍN DE LA SIERRA, Luis Manuel Rodríguez; RODRIGUEZ-PERAL, Carlos Marquez; MOLONEY, David Macdara; BYRNE, Jonathan David","PEÑA, Dexmont; MARTÍN DE LA SIERRA, Luis Manuel Rodríguez; RODRIGUEZ-PERAL, Carlos Marquez; MOLONEY, David Macdara; BYRNE, Jonathan David; SARTI, Luca; CAULFIELD, Sam","62/724,446 29.08.2018 US",
WO2020022956,PCT/SG2018/050379,27.07.2018,WO/2020/022956,30.01.2020,WO,METHOD AND APPARATUS FOR VIDEO CONTENT VALIDATION,"A method and apparatus for video content validation, the method comprising: inputting a pair of videos for comparison; extracting video frame descriptors from each frame of the pair of videos, wherein the video frame descriptors to be extracted are predetermined; processing the video frame descriptors to generate input to a model derived from a trained computer neural network; and outputting from the model, a distance vector to be used for calculation of a similarity value indicative of similarity between the pair of videos.",G06N 3/02; G06T 1/40,AIOZ PTE LTD,"NGUYEN, Sang; TRAN, Quang; TJIPUTRA, Erman",,
EP232832033,17305519,05.05.2017,3399465,07.11.2018,EP,FORMING A DATASET FOR FULLY-SUPERVISED LEARNING,"The invention notably relates to a computer-implemented method of signal processing comprising providing images; for each respective one of at least a subset of the images: applying a weakly-supervised learnt function, the weakly-supervised learnt function outputting respective couples each including a respective localization and one or more respective confidence scores, each confidence score representing a probability of instantiation of a respective object category at the respective localization; determining, based on the output of the weakly-supervised learnt function, one or more respective annotations, each annotation including a respective localization and a respective label representing instantiation a respective object category at the respective localization; and forming a dataset including pieces of data, each piece of data including a respective image of the subset and at least a part of the one or more annotations determined for the respective image.  Such a method improves the field of object detection.",G06K 9/62; G06K 9/32; G06K 9/46,DASSAULT SYSTEMES,DUPONT DE DINECHIN LOUIS; REJEB SFAR ASMA,17305519 05.05.2017 EP,
WO2018140332,PCT/US2018/014602,22.01.2018,WO/2018/140332,02.08.2018,WO,REAL-TIME SEMANTIC-AWARE CAMERA EXPOSURE CONTROL,"An ""Exposure Controller"" provides various techniques for training and applying a deep convolution network to provide real-time automated camera exposure control, as a real-time function of scene semantic context, in a way that improves image quality for a wide range of image subject types in a wide range of real-world lighting conditions. The deep learning approach applied by the Exposure Controller to implement this functionality first uses supervised learning to achieve a good anchor point that mimics integral exposure control for a particular camera model or type, followed by refinement through reinforcement learning. The end-to-end system (e.g., exposure control and image capture) provided by the Exposure Controller provides real-time performance for predicting and setting camera exposure values to improve overall visual quality of the resulting image over a wide range of image capture scenarios (e.g., back-lit scenes, front lighting, rapid changes to lighting conditions, etc.).",H04N 5/235; G06K 9/00,"MICROSOFT TECHNOLOGY LICENSING, LLC","WANG, Baoyuan; KANG, Sing Bing","62/451,689 28.01.2017 US; 15/671,067 07.08.2017 US",EP-2018704649; CN-201880008842.8
WO2004029659,PCT/US2003/018819,13.06.2003,WO/2004/029659,08.04.2004,WO,PEDESTRIAN DETECTION AND TRACKING WITH NIGHT VISION,"A system and method for detecting humans, such as pedestrians, in low visibility conditions or otherwise. A night vision camera periodically captures an infrared image of a road from a single perspective. A pedestrian detection module determines a position of a pedestrian in the frame by processing the captured image. The pedestrian detection module includes a support vector machine to compare information derived from the night vision camera to a training database. A pedestrian tracking module estimates pedestrian movement of the detected pedestrian from in subsequent frames by applying filters. The tracking module uses Kalman filtering to estimate pedestrian movement at periodic times and mean-shifting to adjust the estimation. An output display module interleaves detection frames and tracking frames in generating output video for the display.",G06K 9/00,HONDA GIKEN KOGYO KABUSHIKI KAISHA; THE OHIO STATE UNIVERSITY,"FUJIMURA, Kikuo; XU, Fengliang","60/388,727 14.06.2002 US",JP-null
WO2019145795,PCT/IB2019/000215,25.01.2019,WO/2019/145795,01.08.2019,WO,SYSTEMS AND METHODS FOR OPTICAL ASSESSMENTS OF BIOINK PRINTABILITY,"Systems and methods for optical assessments of bioink printability are described. The systems and methods include the use of hardware, software and optical targets to aid in the evaluation of bioink printability. The optical targets are developed and fabricated from 3D printable materials determined to be ""nozzle fidelic"" and/or materials that possess well characterized thermosensitivity. The optical targets make it possible to rapidly compare and evaluate bioink printability and can be easily customized and tailored for specific applications.",B33Y 50/02; B41M 3/06; G05B 19/418; G06N 3/02; G06T 7/00; B29C 64/106; B29C 64/209; B29C 64/393; G06N 20/00; B29C 48/92; B29C 48/00,CELLINK AB,"THAYER, Patrick; ABUSHALL, Hany; MARTINEZ, Hector; GATENHOLM, Erik","62/622,650 26.01.2018 US",
WO2003010753,PCT/US2002/023410,22.07.2002,WO/2003/010753,06.02.2003,WO,PATTERN RECOGNITION USING AN OBSERVABLE OPERATOR MODEL,"Data structures, systems, and methods are aspects of pattern recognition using observable operator models (OOMs). OOMs are more efficient than Hidden Markov Models (HMMs). A data structure for an OOM has characteristic events, an initial distribution vector, a probability transition matrix, an occurrence count matrix, and at least one observable operator. System applications include computer systems, cellular phones, wearable computers, home control systems, fire safety or security systems, PDAs, and flight systems. A method of pattern recognition comprises training OOMs, receiving unknown input, computing matching probabilities, selecting the maximum probability, and displaying the match. A method of speech recognition comprises sampling a first input stream, performing a spectral analysis, clustering, training OOMs, and recognizing speech using the OOMs.",G10L 15/14,"HONEYWELL INTERNATIONAL, INC.","SHETTY, Ravindra, K.; THYAGARAJAN, Venkatesan","09/912,114 24.07.2001 US",JP-null
WO2011085819,PCT/EP2010/050487,15.01.2010,WO/2011/085819,21.07.2011,WO,A MACHINE-LEARNING SYSTEM AND A METHOD FOR DETERMINING DIFFERENT OPERATING POINTS IN SUCH A SYSTEM,A machine- learning system comprising an initialiser configured to estimate an initial series of values for a latent variable; a modelling module configured to generate a response to a given input signal; and an input for inputting the initial series of values obtained from the initialiser into the modelling module as input signals therefor. The initialiser comprises: a pre-processor configured to remove constant correlations between two or more input variables; and a processor configured to apply a non-linear function to said two or more input variables to obtain a series of instantaneous correlations for use as said initial series of values for said latent variable.,G06N 3/08,"ZENROBOTICS LTD.; VALPOLA, Harri","VALPOLA, Harri",,EP-2010705562
WO2018146682,PCT/IL2018/050148,08.02.2018,WO/2018/146682,16.08.2018,WO,A MEDICAL MONITORING SYSTEM AND METHOD,"A medical monitoring device comprises at least one inspection sensor, configured to detect one or more events, changes or characteristic of tissue, when interfaced with a patient's body, and at least one auxiliary sensor configured to provide data regarding actuation of the device with relation to the anatomy of the patient's body.",A61B 5/06; A61B 34/00,GYNISUS LTD,"FRIEDMANN, Hila","62/456,929 09.02.2017 US",EP-2018750706
EP14282200,04728905,22.04.2004,1515277,16.03.2005,EP,"IMAGE RECOGNITION DEVICE AND METHOD, AND ROBOT DEVICE","In an image recognition apparatus (1), feature point extraction sections (10a) and (10b) extract feature points from a model image and an object image. Feature quantity retention sections (11a) and (11b) extract a feature quantity for each of the feature points and retain them along with positional information of the feature points. A feature quantity comparison section (12) compares the feature quantities with each other to calculate the similarity or the dissimilarity and generates a candidate-associated feature point pair having a high possibility of correspondence. A model attitude estimation section (13) repeats an operation of projecting an affine transformation parameter determined by three pairs randomly selected from the candidate-associated feature point pair group onto a parameter space. The model attitude estimation section (13) assumes each member in a cluster having the largest number of members formed in the parameter space to be an inlier. The model attitude estimation section (13) finds the affine transformation parameter according to the least squares estimation using the inlier and outputs a model attitude determined by this affine transformation parameter. <IMAGE>",B25J 5/00; G06T 7/00; B25J 13/08; B25J 19/04; G06K 9/46; G06K 9/64; G06T 7/60,SONY CORP,SUZUKI HIROTAKA; SABE KOHTARO; FUJITA MASAHIRO,2003124225 28.04.2003 JP; 2004005784 22.04.2004 JP,
WO2014143032,PCT/US2013/032449,15.03.2013,WO/2014/143032,18.09.2014,WO,CONTINUOUS INTERACTION LEARNING AND DETECTION IN REAL-TIME,"Systems and methods may provide for partitioning a plurality of training samples into a first sequential list of centroids, removing one or more repeating centroids in the first sequential list of centroids to obtain a first reduced list of centroids and generating a set of Hidden Markov Model (HMM) parameters based on the first reduced list of centroids. Additionally, a plurality of detection samples may be partitioned into a second sequential list of centroids, wherein one or more repeating centroids in the second sequential list of centroids may be removed to obtain a second reduced list of centroids. The second reduced list of centroids may be used to determine a match probability for the plurality of detection samples against the set of HMM parameters. In one example, the reduced lists of centroids lack temporal variability.",G06T 17/00; G06T 7/00; G10L 15/14,"INTEL CORPORATION; EVANS, Chuck","EVANS, Chuck",,EP-2013878402; US-13976744
WO2016149794,PCT/CA2016/000081,24.03.2016,WO/2016/149794,29.09.2016,WO,"OPERATING ROOM BLACK-BOX DEVICE, SYSTEM, METHOD AND COMPUTER READABLE MEDIUM","A multi-channel recorder/encoder for collecting, integrating, synchronizing and recording medical or surgical data received as independent live or real-time data streams from a plurality of hardware units. The medical or surgical data relating to a live or real-time medical procedure. Example hardware units include a control interface, cameras, sensors, audio devices, and patient monitoring hardware. Further example systems may include a cloud based platform incorporating the encoder.",G06F 19/00; G06F 17/40; G06Q 50/22,SURGICAL SAFETY TECHNOLOGIES INC.,"GRANTCHAROV, Teodor Pantchev; YANG, Kevin Lee","62/138,647 26.03.2015 US; PCT/CA2015/000504 23.09.2015 CA",CA-2980618; US-15561877; EP-2016767561
EP232545777,18163752,23.03.2018,3396604,31.10.2018,EP,ACCELERATED DECISION TREES ON DATA CENTER CLUSTERS,"In an example, an apparatus comprises a plurality of execution units and logic, at least partially including hardware logic, to implement training of a deep tree application at a data center. Other embodiments are also disclosed and claimed.",G06N 5/00; G06N 99/00,INTEL CORP,BLEIWEISS AMIT; FAIVISHEVSKY LEV; SCHWARTZ TOMER; FAIS YANIV; SUBAG JACOB,201715499899 28.04.2017 US,
WO2019164251,PCT/KR2019/002051,20.02.2019,WO/2019/164251,29.08.2019,WO,METHOD OF PERFORMING LEARNING OF DEEP NEURAL NETWORK AND APPARATUS THEREOF,An encoding apparatus connected to a learning circuit processing learning of a deep neural network and configured to perform encoding for reconfiguring connection or disconnection of a plurality of edges in a layer of the deep neural network using an edge sequence generated based on a random number sequence and dropout information indicating a ratio between connected edges and disconnected edges of a plurality of edges included in a layer of the deep neural network.,G06N 3/08; G06N 5/04; G06N 3/063,"SAMSUNG ELECTRONICS CO., LTD.","KANG, Sungho; KWON, Hyungdal; LEE, Cheon; LIM, Yunjae",10-2018-0020005 20.02.2018 KR,
WO2019242001,PCT/CN2018/092398,22.06.2018,WO/2019/242001,26.12.2019,WO,"METHOD, COMPUTING DEVICE AND SYSTEM FOR GENERATING CONTENT","Embodiments of the present disclosure provide a method for generating content, a computing and a system. The method may receive original material; obtain a first word set including at least a word describing affective feature of the original material; and generate the content by predicting each segment from a respective word in the first word set through a Recurrent Neural Network (RNN), wherein the RNN has been pre-trained by using at least one literary genre including modern poem. The content generated by the method according to the present disclosure may bring more impression and touching, have more space and better consistence.",G06F 17/27; G06N 3/02; G06N 5/02,"MICROSOFT TECHNOLOGY LICENSING, LLC; SONG, Ruihua; XU, Yuanchun; YUAN, Jing; FU, Jianlong; ZHOU, Guang; CHENG, Wenfeng","SONG, Ruihua; XU, Yuanchun; YUAN, Jing; FU, Jianlong; ZHOU, Guang; CHENG, Wenfeng",,
EP279871158,17897328,17.11.2017,3588385,01.01.2020,EP,"CONVOLUTIONAL NEURAL NETWORK AND PROCESSING METHOD, APPARATUS AND SYSTEM THEREFOR, AND MEDIUM","Provided are a convolutional neural network and a processing method, apparatus and system therefor, and a medium. The method comprises: using an activation recorder layer as an activation function layer in a convolutional neural network, wherein in response to inputting a probe image with contents to the convolutional neural network, the activation recorder layer performs the same activation operation as the activation function layer and records an activation result of the activation operation; modifying the convolutional neural network, with the modification step comprising replacing the activation recorder layer with a masking layer, wherein the masking layer uses the recorded activation result; and inputting, to the modified convolutional neural network, an analysis image as an input image to output an output image of the modified convolutional neural network, so as to analyze a positive influence or a negative influence between the input image and the output image, wherein the analysis image is a pixel-level binary image.",G06N 3/02,BOE TECHNOLOGY GROUP CO LTD,NAVARRETE MICHELINI PABLO; LIU HANWEN,201710094069 21.02.2017 CN; 2017111617 17.11.2017 CN,
WO2010075310,PCT/US2009/069059,21.12.2009,WO/2010/075310,01.07.2010,WO,NEURAL NETWORK BASED PATTERN RECOGNIZER,"An image-based pattern recognizer and a method and apparatus for making such a pattern recognizer are disclosed. By employing positional coding, the meaning of any feature present in an image can be defined implicitly in space. The pattern recognizer can be a neural network including a plurality of stages of observers. The observers are configured to cooperate to identify the presence of features in the input image and to recognize a pattern in the input image based on the features. Each of the observers includes a plurality of neurons. The input image includes a plurality of units, and each of the observers is configured to generate a separate output set that includes zero or more coordinates of such units.",G06T 7/40; G06T 7/00,"FIVE APES, INC.; PAQUIER, Williams J. F.","PAQUIER, Williams J. F.","12/344,344 26.12.2008 US",EP-2009835720
WO2018057809,PCT/US2017/052819,21.09.2017,WO/2018/057809,29.03.2018,WO,POINTER SENTINEL MIXTURE ARCHITECTURE,"The technology disclosed provides a so-called ""pointer sentinel mixture architecture"" for neural network sequence models that has the ability to either reproduce a token from a recent context or produce a token from a predefined vocabulary. In one implementation, a pointer sentinel-LSTM architecture achieves state of the art language modeling performance of 70.9 perplexity on the Penn Treebank dataset, while using far fewer parameters than a standard softmax LSTM.",G06N 3/04,"SALESFORCE.COM, INC.","MERITY, Stephen Joseph; XIONG, Caiming; BRADBURY, James; SOCHER, Richard","62/397,926 22.09.2016 US; 62/398,461 22.09.2016 US; 62/417,334 04.11.2016 US; 15/421,016 31.01.2017 US",CN-201780060729.X; CA-3034918; JP-2019537050; EP-2017780275
WO2018065073,PCT/EP2016/074088,07.10.2016,WO/2018/065073,12.04.2018,WO,"ELECTRONIC DEVICE, SYSTEM AND METHOD FOR RECOGNIZING AND LOCATING AN OBJECT","The invention relates to an electronic device (1) for recognizing and locating an object. The electronic device is configured to: receive 3D image data of an optical sensor (3), the sensor sensing the object (O), decompose the 3D image data into a set of patches, extract a set of features of each patch by using a pre-trained convolutional neural network (CNN) auto-encoder (12), for each patch classify the object pose by using the set of features of the patch as an input to a k-nearest neighbors algorithm (13) to match against predetermined object representations, and determine the pose of the object by combining the classified object poses of the set of patches. The invention further relates to a system and a method.",G06K 9/00; G06K 9/46; G06K 9/62,TOYOTA MOTOR EUROPE,"MEIER, Sven; KOBORI, Norimasa; KEHL, Wadim; MILLETARI, Fausto",,JP-2019518923
EP277550974,18174351,25.05.2018,3572982,27.11.2019,EP,MACHINE LEARNING SYSTEM,,G06N 3/00; G06N 3/04,BOSCH GMBH ROBERT,VAN HOOF HERKE; WELLING MAX; SHANG WENLING; VAN DER WAL DOUWE,18174351 25.05.2018 EP,
WO2014151964,PCT/US2014/026738,13.03.2014,WO/2014/151964,25.09.2014,WO,ADAPTIVE PREDICTOR APPARATUS AND METHODS,"Apparatus and methods for training and operating of robotic devices. Robotic controller may comprise a predictor apparatus configured to generate motor control output. The predictor may be operable in accordance with a learning process based on a teaching signal comprising the control output. An adaptive controller block may provide control output that may be combined with the predicted control output. The predictor learning process may be configured to learn the combined control signal. Predictor training may comprise a plurality of trials. During initial trial, the control output may be capable of causing a robot to perform a task. During intermediate trials, individual contributions from the controller block and the predictor may be inadequate for the task. Upon learning, the control knowledge may be transferred to the predictor so as to enable task execution in absence of subsequent inputs from the controller. Control output and/or predictor output may comprise multi-channel signals.",G06N 3/08,BRAIN CORPORATION,"IZHIKEVICH, Eugene; SINYAVSKIY, Oleg; PASSOT, Jean-Baptiste","13/842,530 15.03.2013 US",
WO2019236885,PCT/US2019/035840,06.06.2019,WO/2019/236885,12.12.2019,WO,SYSTEM AND METHOD FOR FINDING AND CLASSIFYING PATTERNS IN AN IMAGE WITH A VISION SYSTEM,"This invention provides a system and method for finding patterns in images that incorporates neural net classifiers. A pattern finding tool is coupled with a classifier that can be run before or after the tool to have labeled pattern results with sub-pixel accuracy. In the case of a pattern finding tool that can detect multiple templates, its performance is improved when a neural net classifier informs the pattern finding tool to work only on a subset of the originally trained templates. Similarly, in the case of a pattern finding tool that initially detects a pattern, a neural network classifier can then determine whether it has found the correct pattern. The neural network can also reconstruct/ clean-up an imaged shape, and/or to eliminate pixels less relevant to the shape of interest, therefore reducing the search time, as well significantly increasing the chance of lock on the correct shapes.",G06K 9/20; G06K 9/62; G06N 3/08,COGNEX CORPORATION,"WANG, Lei; ANAND, Vivek; JACOBSON, Lowell, D.; LI, David, Y.","62/681,619 06.06.2018 US; 62/793,364 16.01.2019 US",
WO2019024083,PCT/CN2017/096004,04.08.2017,WO/2019/024083,07.02.2019,WO,ARTIFICIAL NEURAL NETWORK,"There is provided an apparatus comprising at least one processing core, at least one memory including computer program code, at least one memory and the computer program code being configured to, with at least one processing core, cause the apparatus at least to obtain, from a first sequential input(102), a first output from a first recurrent neural network, the first sequential input being of a first modality, obtain, from a second sequential input(103), a second output from a second recurrent neural network, the second sequential input being of a second modality, and process the first output and the second output to obtain a correlation of the first and second sequential inputs.",G06N 3/08,"NOKIA TECHNOLOGIES OY; NOKIA TECHNOLOGIES (BEIJING) CO., LTD.","WANG, Meng",,
WO2019231289,PCT/KR2019/006604,31.05.2019,WO/2019/231289,05.12.2019,WO,METHOD AND APPARATUS FOR MACHINE LEARNING BASED WIDE BEAM OPTIMIZATION IN CELLULAR NETWORK,"The present disclosure relates to a pre-5th-Generation (5G) or 5G communication system to be provided for supporting higher data rates Beyond 4th-Generation (4G) communication system such as Long Term Evolution (LTE). The present disclosure relates an artificial intelligence (AI) system and its application that sumltate functions such as recognition and judgment of a human brain using a machine learning algorithm such as deep learning. An apparatus and method for controlling and optimizing the broadcast beam for base stations (BS) using user equipment (UE) measurements with machine learning is provided. The apparatus and method is configured to select a first beam for each BS, send selected beams for each BS, receive measurement information of a first beam from UEs via BSs, preprocess the measurement results, use a neural network or a table for each BS to give a score for each broadcast beam in the beam pool, select a second beam with the highest score for each BS either from a neural network or a table, train the neural network for broadcast beam optimization offline based on a UE distribution pattern and ray-tracing data, identify typical UE distribution patterns based on AI classification algorithms and UE history measurement and location infomraiton, and create scenario-specific ray-tracing data based on typical UE distribution patterns.",H04W 16/28; H04W 24/10; H04W 24/02; H04W 72/04; G06N 3/02; G06N 20/00; H04B 7/06,"SAMSUNG ELECTRONICS CO., LTD.","CHEN, Hao; ZHANG, Jianzhong; SHAFIN, Rubayet; NAM, Younghan","62/679,409 01.06.2018 US; 62/719,964 20.08.2018 US; 62/741,982 05.10.2018 US; 62/743,919 10.10.2018 US; 16/361,061 21.03.2019 US",
WO2002073530,PCT/US2002/006248,01.03.2002,WO/2002/073530,19.09.2002,WO,DATA MINING APPARATUS AND METHOD WITH USER INTERFACE BASED GROUND-TRUTH TOOL AND USER ALGORITHMS,"Various modes and embodiment of a method, apparatus, user interface, article of manufacture including a computer readable medium, computer data signals embodied on a carrier wave, and computer system for a GUI-based ground truth tool (155) and insertion of user algorithm written in multiple programming languages. One embodiment comprises user interface for inseting a custom algorithm in a data-mining application (250). Another embodiment comprises a ground truth toll (155) in a data-mining-application (250). A third embodiment comproses seamless inseriton of custom algorithms in a data-mining application using tap points (920).",G06N 5/00; G06N 5/02,"ROCKWELL SCIENTIFIC COMPANY, LLC","KIL, David; BRADLEY, Andrew","60/274,008 07.03.2001 US; 09/945,530 30.08.2001 US; 09/942,435 16.11.2001 US",JP-null
EP14036983,02708744,01.04.2002,1376536,02.01.2004,EP,SOUND PROCESSING APPARATUS,"The present invention relates to a voice recognition apparatus capable of easily registering a word which has not been registered. The registering of an unregistered word into a dictionary can be easily performed without causing a significant increase in the size of the dictionary. The clustering unit 29 detects a cluster (detected cluster) to which a new unregistered word is to be added as a new member, from existing clusters obtained by clustering unregistered words. The unregistered word is added as a new member to the detected cluster, and the cluster is divided depending on the members of the cluster such that unregistered words which are acoustically similar to each other belong to the same cluster. The maintenance unit 31 updates the word dictionary on the basis of the result of the clustering. The present invention may be applied to a robot including a voice recognition apparatus. <IMAGE>",G06F 3/16; G10L 15/00; G06F 3/16; G06F 17/28; G10L 15/00; G10L 15/06; G10L 15/06; G10L 15/14; G10L 15/14; G10L 15/20; G10L 15/20; G10L 15/22; G10L 15/24,SONY CORP,OMOTE MASANORI; LUCKE HELMUT,0203248 01.04.2002 JP; 2001097843 30.03.2001 JP; 2002069603 14.03.2002 JP,
WO2020061884,PCT/CN2018/107886,27.09.2018,WO/2020/061884,02.04.2020,WO,COMPOSITE BINARY DECOMPOSITION NETWORK,"Embodiments are directed to a composite binary decomposition network. An embodiment of a computer-readable storage medium includes executable computer program instructions for transforming a pre-trained first neural network into a binary neural network by processing layers of the first neural network in a composite binary decomposition process, where the first neural network having floating point values representing weights of various layers of the first neural network. The composite binary decomposition process includes a composite operation to expand real matrices or tensors into a plurality of binary matrices or tensors, and a decompose operation to decompose one or more binary matrices or tensors of the plurality of binary matrices or tensors into multiple lower rank binary matrices or tensors.",G06N 3/06,"INTEL CORPORATION; LI, Jianguo; CHEN, Yurong","LI, Jianguo; CHEN, Yurong; WANG, Zheng",,
WO2020056374,PCT/US2019/051176,13.09.2019,WO/2020/056374,19.03.2020,WO,DETERMINING HOW TO ASSEMBLE A MEAL,"In an embodiment, a method includes determining a given material to manipulate to achieve a goal state. The goal state can be one or more deformable or granular materials in a particular arrangement. The method further includes, for the given material, determining, a respective outcome for each of a plurality of candidate actions to manipulate the given material. The determining can be performed with a physics-based model, in one embodiment. The method further can include determining a given action of the candidate actions, where the outcome of the given action reaching the goal state is within at least one tolerance. The method further includes, based on a selected action of the given actions, generating a first motion plan for the selected action.",B25J 9/16,"THE CHARLES STARK DRAPER LABORATORY, INC.","JOHNSON, David, M.S.; WAGNER, Syler; LINES, Steven","62/731,398 14.09.2018 US; 62/730,934 13.09.2018 US; 62/730,918 13.09.2018 US; 62/730,933 13.09.2018 US; 62/730,703 13.09.2018 US; 62/730,947 13.09.2018 US",
WO2014182246,PCT/SG2014/000200,07.05.2014,WO/2014/182246,13.11.2014,WO,A METHOD AND/ OR SYSTEM FOR MAGNETIC LOCALIZATION,A method of real time magnetic localization comprising: providing an artificial neural network field model that is calibrated and optimized for a predetermined magnet; receiving signals from one or more magnetic sensors; and solving the location of the magnet using the model based on the signals.,G01B 7/00; A61B 5/06,SINGAPORE UNIVERSITY OF TECHNOLOGY AND DESIGN; MASSACHUSETTS INSTITUTE OF TECHNOLOGY,"FOONG, Shaohui; WU, Faye","61/820,472 07.05.2013 US",US-14889578
WO2019226670,PCT/US2019/033345,21.05.2019,WO/2019/226670,28.11.2019,WO,SYSTEMS AND METHODS FOR DEEP NEURAL NETWORKS ON DEVICE LEARNING (ONLINE AND OFFLINE) WITH AND WITHOUT SUPERVISION,"An artificial neural network (ANN) that learns at the Edge (e.g., on a smart phone) can be faster and use less network bandwidth than an ANN trained on a server and distributed to the Edge. Learning at the compute edge can be accomplished by executing Lifelong Deep Neural Network (L-DNN) technology at the compute edge. L-DNN technology uses a representation-rich, DNN- based subsystem with a fast-learning subsystem to learn new features quickly without forgetting previously learned features. Compared to a conventional DNN, L-DNN uses much less data to build robust networks, has dramatically shorter training time, and learns on-device instead of on servers without re-training or storing data. An edge device with L-DNN can learn continuously after deployment, eliminating costs in data collection and annotation, memory, and compute power. This fast, local, on-device learning can be used in unsupervised mode to make personal assistants more intelligent and enhance frequently used apps.",G06K 9/62,"NEURALA, INC.; VERSACE, Massimiliano; GLASSER, Daniel; TORMANEN, Vesa; GORCHET, Anatoli; VERSACE, Heather, Ames; WURBS, Jeremy","VERSACE, Massimiliano; GLASSER, Daniel; TORMANEN, Vesa; GORCHET, Anatoli; VERSACE, Heather, Ames; WURBS, Jeremy","62/674,346 21.05.2018 US; 62/680,937 05.06.2018 US",
WO2007042148,PCT/EP2006/009402,27.09.2006,WO/2007/042148,19.04.2007,WO,"A NEURAL NETWORK, A DEVICE FOR PROCESSING INFORMATION, A METHOD OF OPERATING A NEURAL NETWORK, A PROGRAM ELEMENT AND A COMPUTER-READABLE MEDIUM","A neural network (100) comprising a plurality of neurons (101 to 106) and a plurality of wires (109) adapted for connecting the plurality of neurons (101 to 106), wherein at least a part of the plurality of wires (109) comprises a plurality of input connection and exactly one output connection.",G06N 3/04; G06N 3/063; G06N 3/08,"OETRINGER, Eugen","OETRINGER, Eugen","05021910.4 07.10.2005 EP; 60/724,482 07.10.2005 US",US-12089535; EP-2006792289
WO2002009033,PCT/AU2001/000885,20.07.2001,WO/2002/009033,31.01.2002,WO,A DEVELOPMENT SYSTEM FOR EXPERT SYSTEMS,"An expert system builder, including a node control for selecting and defining nodes of a knowledge base structure of an expert system, and a link control for creating decision links between the nodes to define the structure. The nodes are decision nodes and can include question nodes for presenting questions and receiving answers to the questions. The question nodes store values for a received answer. The decision links each have a source node and a destination node and represent a decision path. The links may have conditions to be met by the source node before the path is traversed by the expert system. The structure may include nested lattices of nodes.",G06N 5/02,"TELSTRA R & D MANAGEMENT PTY LTD; ZHAO, Ming","ZHAO, Ming",PQ 8899 20.07.2000 AU,
WO2020039121,PCT/FI2019/050589,19.08.2019,WO/2020/039121,27.02.2020,WO,METHOD AND SYSTEM FOR GENERATING ANNOTATED TRAINING DATA,"Disclosed is a method of generating an annotated synthetic training data for training a machine learning module for processing an operational data set. The method comprises creating a first procedural model for the object,the first procedural model having a first set of parameters relating to the object, creating a second procedural model for the background, the second procedural model having a second set of parameters relating to the background, creating the task environment model pertaining to the machine learning task using the first and the second procedural models; creating a synthetic data set using the task environment model; and allocating at least one parameter of the first set of parameters as an annotation for the simulation data to generate the annotated synthetic training data.",G06K 9/00; G06K 9/62; G06N 3/08; G06N 7/00; G06N 20/00; G06T 7/11; G06T 7/143; G06T 7/194,AALTO UNIVERSITY FOUNDATION SR.,"GILLBERG, Jussi; JUNTUNEN, Harri; WAGNER, Paul; LINTUSAARI, Jarno; NGUYEN, Linh",20185687 20.08.2018 FI,
WO2020047657,PCT/CA2019/051231,04.09.2019,WO/2020/047657,12.03.2020,WO,REAL-TIME REAL-WORLD REINFORCEMENT LEARNING SYSTEMS AND METHODS,"A reinforcement learning architecture for facilitating reinforcement learning in connection with operation of an external real-time system that includes a plurality of devices operating in a real-world environment. The reinforcement learning architecture includes a plurality of communicators, a task manager, and a reinforcement learning agent that interact with each other to effectuate a policy for achieving a defined objective in the real-world environment. Each of the communicators receives sensory data from a corresponding device and the task manager generates a joint state vector based on the sensory data. The reinforcement learning agent generates, based on the joint state vector, a joint action vector, which the task manager parses into a plurality of actuation commands. The communicators transmit the actuation commands to the plurality of devices in the real-world environment.",G05B 19/042; B25J 9/18; G06F 9/06; G06N 20/00,KINDRED SYSTEMS INC.,"MAHMOOD, Ashique Rupam; KOMER, Brent J.; KORENKEVYCH, Dmytro","62/726,788 04.09.2018 US",
WO2017145172,PCT/IN2016/000239,03.10.2016,WO/2017/145172,31.08.2017,WO,SYSTEM AND METHOD FOR EXTRACTION AND ANALYSIS OF SAMPLES UNDER A MICROSCOPE,A system and method is provided for automatically classifying and identifying the types of cells and structures using microscopic images captured with an application installed on a smart computing device. The captured image is pre-processed by normalizing the parameters of the captured image. The application is run to identify the patches of the cells and structures in the captured image to extract the features and attributes of the cells and structures in the captured image. The pre-trained machine learning models/algorithms are applied for classifying the cells and structures in the image based on the extracted features and attributes of the cells and structures. A report is generated on a server based on the cell classification.,G06K 9/00; G06F 17/00,SIGTUPLE TECHNOLOGIES PRIVATE LIMITED,"ROHIT, Kumar Pandey; APURV, Arnand; BHARATH, Cheluvaraju; TATHAGATO, Rai Dastidar",201641006272 23.02.2016 IN,
WO2018110985,PCT/KR2017/014672,14.12.2017,WO/2018/110985,21.06.2018,WO,METHOD AND APPARATUS FOR AUTOMATED DECISION MAKING,"A method for a first electronic device comprises generating a decision-making data structure using a machine learning data structure; transmitting, to a second electronic device, the decision-making data structure; receiving, from the electronic device, result data regarding a result of performing a selected action selected from the decision-making data structure; and updating the machine learning data structure using the result data.",G06N 99/00; G06N 3/08,"SAMSUNG ELECTRONICS CO., LTD.","LOBETE, Daniel Ansorregui; SARAVANAN, Karthikeyan Palavedu",1621347.2 15.12.2016 GB,EP-2017881319; KR-1020197020085
WO2018093796,PCT/US2017/061618,14.11.2017,WO/2018/093796,24.05.2018,WO,DEEP LEARNING SYSTEM FOR CUBOID DETECTION,"Systems and methods for cuboid detection and keypoint localization in images are disclosed. In one aspect, a deep cuboid detector can be used for simultaneous cuboid detection and keypoint localization in monocular images. The deep cuboid detector can include a plurality of convolutional layers and non-convolutional layers of a trained convolution neural network for determining a convolutional feature map from an input image. A region proposal network of the deep cuboid detector can determine a bounding box surrounding a cuboid in the image using the convolutional feature map. The pooling layer and regressor layers of the deep cuboid detector can implement iterative feature pooling for determining a refined bounding box and a parameterized representation of the cuboid.",G06F 3/01; G06F 3/0346; G06K 9/66; G06N 3/04; G06T 7/215,"MAGIC LEAP, INC.","MALISIEWICZ, Tomasz; RABINOVICH, Andrew; BADRINARAYANAN, Vijay; DWIBEDI, Debidatta","62/422,547 15.11.2016 US",EP-2017870853; CA-3043352; JP-2019524982; KR-1020197015993; IL-266482; CN-201780082830.5; AU-2017361061
WO2019108371,PCT/US2018/060213,10.11.2018,WO/2019/108371,06.06.2019,WO,TRAINING NEURAL NETWORKS TO DETECT SIMILAR THREE-DIMENSIONAL OBJECTS USING FUZZY IDENTIFICATION,A system for training a neural network generates a plurality of training meshes based on an input mesh. The plurality of training meshes include at least one mesh perceptually similar to the input mesh and one arbitrarily selected mesh perceptually dissimilar to the input mesh. The neural network is trained using the input mesh and the plurality of training meshes by tuning output of the neural network to identify similar non-identical meshes. The trained neural network is robust in identifying meshes similar to an unknown mesh input to the trained neural network.,G06N 3/04; G06N 3/08; G06T 17/20,"MICROSOFT TECHNOLOGY LICENSING, LLC","LJUNG LARHED, Fredrik Carl Anders; LINDAHL, Hans-Ulrik Tord","15/826,664 29.11.2017 US",
WO2006086086,PCT/US2005/046939,28.12.2005,WO/2006/086086,17.08.2006,WO,BIOLOGICAL INTERFACE SYSTEM WITH GATED CONTROL SIGNAL,"Various embodiments of a biological interface system and related methods are disclosed. The biological interface system may comprise a sensor comprising a plurality of electrodes for detecting multicellular signals emanating from one or more living cells of a patient, a processing unit configured to receive the multicellular signals from the sensor and process the multicellular signals to produce a processed signal, and a signal gate configured to receive the processed signal from the processing unit and an alternative signal generated by the system, the signal gate being configured to transmit a control signal to a controlled device based on either the processed signal or the alternative signal. A monitoring unit may receive system data and process the system data to produce a system status signal. The system status signal may be used to determine which of the processed signal and the alternative signal is to be used as the control signal.",A61B 5/04; A61B 5/0488,"CYBERKINETICS NEUROTECHNOLOGY SYSTEMS, INC.; FLAHERTY, J., Christopher","FLAHERTY, J., Christopher","60/642,199 06.01.2005 US",EP-5857204
WO2018075400,PCT/US2017/056777,16.10.2017,WO/2018/075400,26.04.2018,WO,ADVANCED CONTROL SYSTEMS FOR MACHINES,"Machines can be controlled using advanced control systems. Such control systems may use an automated version of singular spectrum analysis to control a machine. For example, a control system can perform singular spectrum analysis on a time series by: generating a trajectory matrix from the time series, performing singular value decomposition on the trajectory matrix to determine elementary matrices and corresponding eigenvalues, and automatically categorizing the elementary matrices into groups. The elementary matrices can be automatically categorized into the groups by: generating a matrix of w-correlation values based on the eigenvalues, categorizing the w-correlation values into a predefined number of w-correlation sets, and forming the groups based on the predefined number of w-correlation sets. The control system can then determine component time-series based on the groups, and generate a predictive forecast using the component time-series. The control system can use the predictive forecast to control operation of the machine.",G06F 17/00; G06F 17/16; G06F 17/18; G06F 17/30; G06N 99/00,SAS INSTITUTE INC.,"LEONARD, Michael James; ELSHEIMER, David Bruce","62/409,964 19.10.2016 US; 62/433,002 12.12.2016 US",
EP11126736,09168308,20.08.2009,2169507,31.03.2010,EP,Distributed knowledge base method for vehicular localization and work-site management,"In a method for controlling a vehicle, a dynamic condition is identified and the vehicle is controlled using a knowledge base comprising a fixed knowledge base and a learned knowledge base.",G05D 1/02,DEERE & CO,ANDERSON NOEL WAYNE,20878208 11.09.2008 US,
EP232545772,18159840,02.03.2018,3396599,31.10.2018,EP,HARDWARE OPTIMIZED CONVOLUTIONAL NEURAL NETWORK,"In an example, an apparatus comprises at least one execution platform; and logic, at least partially including hardware logic, to receive a trained neural network model in a model optimizer and convert the trained neural network model to an optimized model comprising parameters that are fit to the at least one execution platform. Other embodiments are also disclosed and claimed.",G06N 3/04; G06F 8/52; G06F 9/445,INTEL CORP,BLEIWEISS AMIT; BEN-ARI LTAMAR; BEHAR MICHAEL; JACOB GUY; LEIBOVICH GAL; SUBAG JACOB; FAIVISHEVSKY LEV; FAIS YANIV; SCHWARTZ TOMER,201715494861 24.04.2017 US,
WO2018023356,PCT/CN2016/092762,01.08.2016,WO/2018/023356,08.02.2018,WO,MACHINE TRANSLATION METHOD AND APPARATUS,"A neural network based translation method, wherein the method includes: mapping a source sentence to a semantic space predefined by a knowledge base by using a first machine learning module, to extract key information of the source sentence (910); and generating a target sentence by using a second machine learning module based on the extracted key information (920).",G06F 17/28,"MICROSOFT TECHNOLOGY LICENSING, LLC; LI, Mu; ZHOU, Ming; LIU, Shujie","LI, Mu; ZHOU, Ming; LIU, Shujie",,
EP241923903,18203124,29.10.2018,3480741,08.05.2019,EP,REINFORCEMENT AND IMITATION LEARNING FOR A TASK,"A neural network control system for controlling an agent to perform a task in a real-world environment, operates based on both image data and proprioceptive data describing the configuration of the agent. The training of the control system includes both imitation learning, using datasets generated from previous performances of the task, and reinforcement learning, based rewards calculated from control data output by the control system.",G06N 3/04; G06N 3/00; G06N 3/08,DEEPMIND TECH LIMITED,TUNYASUVUNAKOOL SARAN; ZHU YUKE; MEREL JOSHUA; KRAMAR JANOS; WANG ZIYU; HEESS NICHOLAS MANFRED OTTO,201762578368 27.10.2017 US,
WO2017175232,PCT/IL2017/050433,09.04.2017,WO/2017/175232,12.10.2017,WO,VOCALLY ACTIVATED SURGICAL CONTROL SYSTEM,"The present invention provides a vocally activated control system for controlling at least one apparatus in a surgical setting. The control system comprises a voice sensor to detect vocal commands generated by at least one surgeon in a surgical setting; a signal transmitter operatively connected to the voice sensor to convert vocal commands into transmittable vocal signals and to transmit the transmittable vocal signals; and a processor operatively connected to the signal transmitter to receive the transmittable vocal signals. The processor converts transmittable vocal signals to members of a predetermined set of operative instructions, where each operative instruction is associated with apparatus in the surgical environment. Each apparatus comprises control means, the control means operatively connected to the processor and the apparatus. The control means receives the operative instructions and causes the apparatus to operate accordingly.",G10L 15/00; G10L 15/05; A61B 1/04; A61B 5/06; A61B 6/03,M.S.T. MEDICAL SURGERY TECHNOLOGIES LTD.,"ATAROT, Gal; FRIMER, Motti; NIR, Tal; ALPERT, Lior","62/319,289 07.04.2016 US",CN-201780034382.1; EP-2017778802
EP276409731,19165062,26.03.2019,3567586,13.11.2019,EP,"VOICE INTERACTION SYSTEM, VOICE INTERACTION METHOD, AND PROGRAM",,G10L 15/22; G06F 3/16; G10L 15/18; G10L 17/26; G10L 25/51,TOYOTA MOTOR CO LTD,HORI TATSURO; WATANABE NARIMASA,2018092139 11.05.2018 JP,
WO2000043910,PCT/SG1999/000001,22.01.1999,WO/2000/043910,27.07.2000,WO,METHOD AND APPARATUS FOR INDEXING AND RETRIEVING IMAGES USING VISUAL KEYWORDS,"A method, an apparatus and a computer program product for indexing and retrieving image data using visual keywords (108) is disclosed. Visual keywords (108) are prototypical, visual tokens (104) and are extracted from samples of visual documents (100) in a visual-content domain via supervised and/or unsupervised learning processes. An image or a video-shot key frame is described and indexed by a signature (112) that registers the spatial distribution of the visual keywords (108) present in its visual content. Visual documents (100) are retrived for a sample query (120) by comparing the similarities between the signature (112) of the query (120) and those of visual documents (100) in the database. The signatures (112) of visual documents (100) are generated based on spatial distributions of the visual keywords (108). Singular-value decomposition (114) is applied to the signatures (112) to obtain a coded description (116).",G06F 17/30,"KENT RIDGE DIGITAL LABS; LIM, Joo, Hwee","LIM, Joo, Hwee",,GB-GB0117734.4; US-09341348
WO2018221863,PCT/KR2018/004978,30.04.2018,WO/2018/221863,06.12.2018,WO,METHOD AND DEVICE FOR PROCESSING MULTI-CHANNEL FEATURE MAP IMAGES,"A convolutional neural network-based image processing method is provided. The method includes: receiving, in a second layer, multi-channel feature map images generated by applying a convolution operation to an input image of a convolutional neural network having a pluraltiy of layers with a plurality of filter kernels of a first layer; analyzing a dynamic range of the multi-channel feature map images; re-ordering the multi-channel feature map images, based on the dynamic range; and processing the re-ordered multi-channel feature map images in the second layer.",G06T 5/00; G06T 7/30; G06T 9/00; G06T 1/20; G06N 3/02,"SAMSUNG ELECTRONICS CO., LTD.","CHO, Dae-sung; LEE, Won-jae",10-2017-0067630 31.05.2017 KR,EP-2018809961; CN-201880023698.5
WO2015195765,PCT/US2015/036177,17.06.2015,WO/2015/195765,23.12.2015,WO,ACTIVITY RECOGNITION SYSTEMS AND METHODS,"An activity recognition system is disclosed. A plurality of temporal features is generated from a digital representation of an observed activity using a feature detection algorithm. An observed activity graph comprising one or more clusters of temporal features generated from the digital representation is established, wherein each one of the one or more clusters of temporal features defines a node of the observed activity graph. At least one contextually relevant scoring technique is selected from similarity scoring techniques for known activity graphs, the at least one contextually relevant scoring technique being associated with activity ingestion metadata that satisfies device context criteria defined based on device contextual attributes of the digital representation, and a similarity activity score is calculated for the observed activity graph as a function of the at least one contextually relevant scoring technique, the similarity activity score being relative to at least one known activity graph.",G06K 9/00; G06T 7/20,"NANT VISION, INC.; NANTWORKS, LLC","WNUK, Kamil; WITCHEY, Nicholas, J.","62/013,508 17.06.2014 US",JP-2017519218
WO2019197855,PCT/IB2018/000513,09.04.2018,WO/2019/197855,17.10.2019,WO,DYNAMIC PRUNING OF NEURONS ON-THE-FLY TO ACCELERATE NEURAL NETWORK INFERENCES,"﻿Systems, apparatuses and methods may provide for technology that aggregates contextual information from a first network layer in a neural network having a second network layer coupled to an output of the first network layer, wherein the context information is to be aggregated in real-time and after a training of the neural network, and wherein the context information is to include channel values. Additionally, the technology may conduct an importance classification of the aggregated context information and selectively exclude one or more channels in the first network layer from consideration by the second network layer based on the importance classification.",G06N 3/04; G06N 3/08,INTEL CORPORATION,"GOROKHOV, Dmitry; KOZLOV, Alexander",,
WO2018005395,PCT/US2017/039350,27.06.2017,WO/2018/005395,04.01.2018,WO,ARTIFICIAL NEURAL NETWORK WITH SIDE INPUT FOR LANGUAGE MODELLING AND PREDICTION,"The present invention relates to an improved artificial neural network for predicting one or more next items in a sequence of items based on an input sequence item. The artificial neural network is implemented on an electronic device comprising a processor, and at least one input interface configured to receive one or more input sequence items, wherein the processor is configured to implement the artificial neural network and generate one or more predicted next items in a sequence of items using the artificial neural network by providing an input sequence item received at the at least one input interface and a side input as inputs to the artificial neural network, wherein the side input is configured to maintain a record of input sequence items received at the input interface.",G06N 3/04; G06N 3/08; G10L 15/16; G06F 3/023,"MICROSOFT TECHNOLOGY LICENSING, LLC","ISO-SIPILA, Juha; WILLSON, Matthew, James","1611380.5 30.06.2016 GB; 15/245,934 24.08.2016 US",EP-2017735358; CN-201780040077.3
WO2016149881,PCT/CN2015/074757,20.03.2015,WO/2016/149881,29.09.2016,WO,OBJECT RECOGNTION BASED ON BOOSTING BINARY CONVOLUTIONAL NEURAL NETWORK FEATURES,Techniques related to implementing convolutional neural networks for object recognition are discussed. Such techniques may include generating a set of binary neural features via convolutional neural network layers based on input image data(601) and applying a strong classifier to the set of binary neural features to generate an object label for the input image data(602).,G06K 9/00,"INTEL CORPORATION; YAO, Anbang; XU, Lin; LI, Jianguo; CHEN, Yurong","YAO, Anbang; XU, Lin; LI, Jianguo; CHEN, Yurong",,
WO2017101036,PCT/CN2015/097534,16.12.2015,WO/2017/101036,22.06.2017,WO,FULLY CONVOLUTIONAL PYRAMID NETWORKS FOR PEDESTRIAN DETECTION,"A fully convolutional pyramid network and method for object (e.g., pedestrian) detection are disclosed. The object detection system is a pedestrian detection system that comprises: a multi-scale image generator (112) to generate a set of images from an input image, the set of images being versions of the input image at different scales; a pedestrian-specific fully convolutional network (FCN) model (113) operable to generate a set of detection results for each image in the set of images that is indicative of objects that are potentially pedestrians; and a post processor (114) to combine sets of detection results generated by the FCN model (113) for the set of images into an output image with each object location determined as potentially being a pedestrian being marked.",G06K 9/62,INTEL CORPORATION,"YAO, Anbang; WANG, Ruoyan; CHEN, Yurong",,US-15300490; EP-2015910509
EP260716688,18167677,17.04.2018,3557476,23.10.2019,EP,DEVICE FOR DETERMINING A CAPTION FOR AN UNKNOWN TRAFFIC SIGN,,G06K 9/00,CONTINENTAL AUTOMOTIVE GMBH,ANTONY JERIN; KIZHIYEDATH SREEJITH; RAMACHANDRAN RADHIKA,18167677 17.04.2018 EP,
WO2019154911,PCT/EP2019/053006,07.02.2019,WO/2019/154911,15.08.2019,WO,SYSTEM FOR PERSONALIZED ROBOTIC THERAPY AND RELATED METHODS,The present invention provides an apparatus and a method able to estimate motor improvement in real-time during three-dimensional rehabilitation tasks and to consequently dynamically personalize the therapy.The method can be carried out by a computer program. The use of said apparatus for restoring motor functions in a subject suffering from neuromotor impairment is also within the scope of the invention.,G16H 20/30; A63B 23/035; B25J 9/00; A61B 5/11,ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE; SCUOLA SUPERIORE DI STUDI UNIVERSITARI E DI PERFEZIONAMENTO SANT'ANNA,"GIANG, Christian; PIRONDINI, Elvira; KINANY, Nawal; PANARESE, Alessandro; PIERELLA, Camilla; MICERA, Silvestro",18155711.7 08.02.2018 EP,
EP281666278,18215868,24.12.2018,3594898,15.01.2020,EP,SYSTEMS FOR FACILITATING MOTION ANALYSIS IN AN ENVIRONMENT USING CAMERAS AND MOTION SENSORS AND A GATEWAY,"Disclosed herein is a system for facilitating motion analysis in an environment, in accordance with some embodiments. Accordingly, the system may include a plurality of motions sensors configured to be disposed in the environment. Further, the plurality of motion sensors may be configured to generate a plurality of motion data corresponding to at least one motion of at least one object in the environment. Further, the system may include a plurality of video cameras disposable at a plurality of key locations in the environment. Further, at least one video camera may be configured to transmit a part of a corresponding image sequence to a remote monitoring center through at least one gateway. Further, the system may include at least one gateway disposable proximal to the environment, which may be configured as a two-way interface capable of communicating with the remote monitoring center and the plurality of motion sensors.",G06T 7/20; G08B 13/196; H04N 5/232,RELIANCE CORE CONSULTING LLC,LEDUC JEAN-PIERRE,201762609594 22.12.2017 US,
WO2011072177,PCT/US2010/059781,09.12.2010,WO/2011/072177,16.06.2011,WO,BIOMARKER ASSAY FOR DIAGNOSIS AND CLASSIFICATION OF CARDIOVASCULAR DISEASE,"The disclosed methods, assays and kits identify biomarkers, particularly miRNA and/or protein biomarkers, for assessing the cardiovascular health of a human. In certain embodiments, methods, assays and kits, circulating miRNA and/or protein biomarkers are identified for assessing the cardiovascular health of a human.",C12Q 1/68; G06F 19/18; G01N 33/68,"AVIIR, INC.; HARRINGTON, Doug; HYTOPOULOS, Evangelos; PHELPS, Bruce","HARRINGTON, Doug; HYTOPOULOS, Evangelos; PHELPS, Bruce","61/285,121 09.12.2009 US",JP-2012543298; IN-6094/DELNP/2012; AU-2010328019; CA-2783536; EP-2010791032; CN-201080063521.1
WO2017079521,PCT/US2016/060470,04.11.2016,WO/2017/079521,11.05.2017,WO,CASCADED NEURAL NETWORK WITH SCALE DEPENDENT POOLING FOR OBJECT DETECTION,"A computer-implemented method for training a convolutional neural network (CNN) is presented. The method includes receiving regions of interest from an image, generating one or more convolutional layers from the image, each of the one or more convolutional layers having at least one convolutional feature within a region of interest, applying at least one cascaded rejection classifier to the regions of interest to generate a subset of the regions of interest, and applying scale dependent pooling to convolutional features within the subset to determine a likelihood of an object category.",G06N 3/04; G06N 3/08,"NEC LABORATORIES AMERICA, INC.","CHOI, Wongun; YANG, Fan; LIN, Yuanqing; SAVARESE, Silvio","62/250,750 04.11.2015 US; 15/343,017 03.11.2016 US",DE-112016005062; JP-2018523012
WO2018168536,PCT/JP2018/008140,02.03.2018,WO/2018/168536,20.09.2018,WO,LEARNING APPARATUS AND LEARNING METHOD,"A mechanism for imparting a new ability to an apparatus placed at a remote location is provided. A learning apparatus according to an aspect of the present invention includes: a learning request accepting unit configured to accept, as a learning request, designation of a learning target apparatus for which machine learning is to be performed, and designation of an ability that the learning target apparatus is to acquire through the machine learning, the learning request accepting unit being placed at a location that is remote from the learning target apparatus; a remote manipulation unit configured to remotely manipulate the learning target apparatus so as to execute an operation that is associated with the designated ability; a learning data collection unit configured to collect learning data for the machine learning of the designated ability, based on a result of remotely manipulating the learning target apparatus; and a learning processing unit configured to perform machine learning of a learning device so as to acquire the designated ability, using the collected learning data.",B25J 9/16; G06N 99/00,OMRON CORPORATION,"ANDO, Tanichi; TAKIZAWA, Koji",2017-048320 14.03.2017 JP; 2018-023612 14.02.2018 JP,
WO2019136449,PCT/US2019/012717,08.01.2019,WO/2019/136449,11.07.2019,WO,ERROR CORRECTION IN CONVOLUTIONAL NEURAL NETWORKS,"Systems and methods are disclosed for error correction in convolutional neural networks. In one implementation, a first image is received. A first activation map is generated with respect to the first image within a first layer of the convolutional neural network. A correlation is computed between data reflected in the first activation map and data reflected in a second activation map associated with a second image. Based on the computed correlation, a linear combination of the first activation map and the second activation map is used to process the first image within a second layer of the convolutional neural network. An output is provided based on the processing of the first image within the second layer of the convolutional neural network.",G06N 20/00; G06N 3/02,"FROLOVA, Darya; SIVAN, Ishay","FROLOVA, Darya; SIVAN, Ishay","62/614,602 08.01.2018 US",
WO2019116352,PCT/IB2018/060142,15.12.2018,WO/2019/116352,20.06.2019,WO,SCALABLE PARAMETER ENCODING OF ARTIFICIAL NEURAL NETWORKS OBTAINED VIA AN EVOLUTIONARY PROCESS,"A source system initializes, using an initialization seed, a first parameter vector representing weights of a neural network. The source system determines a second parameter vector by performing a sequence of mutations on the first parameter vector, the mutations each being based on a perturbation seed. The source system generates, and stores to memory, an encoded representation of the second parameter vector that comprises the initialization seed and a sequence of perturbation seeds corresponding to the sequence of mutations. The source system transmits the data structure to a target system, which processes a neural network based on the data structure.",G06N 3/08; G06N 3/04,"UBER TECHNOLOGIES, INC.","PETROSKI SUCH, Felipe; CLUNE, Jeffrey Michael; STANLEY, Kenneth Owen; CONTI, Edoardo; MADHAVAN, Vashisht; LEHMAN, Joel Anthony","62/599,600 15.12.2017 US",
WO2019246116,PCT/US2019/037758,18.06.2019,WO/2019/246116,26.12.2019,WO,APPARATUS AND METHOD FOR UTILIZING A PARAMETER GENOME CHARACTERIZING NEURAL NETWORK CONNECTIONS AS A BUILDING BLOCK TO CONSTRUCT A NEURAL NETWORK WITH FEEDFORWARD AND FEEDBACK PATHS,"A method of forming a neural network includes specifying layers of neural network neurons. A parameter genome is defined with numerical parameters characterizing connections between neural network neurons in the layers of neural network neurons, where the connections are defined from a neuron in a current layer to neurons in a set of adjacent layers, and where the parameter genome has a unique representation characterized by kilobytes of numerical parameters. Parameter genomes are combined into a connectome characterizing all connections between all neural network neurons in the connectome, where the connectome has in excess of millions of neural network neurons and billions of connections between the neural network neurons.",G06N 3/00; G06N 3/02; G06N 3/06; G06N 3/10; G06N 3/12,"ORBAI TECHNOLOGIES, INC.","OSTER, Brent Leonard","62/687,179 19.06.2018 US",
WO2007058950,PCT/US2006/043815,09.11.2006,WO/2007/058950,24.05.2007,WO,BIOLOGICAL INTERFACE SYSTEM WITH NEURAL SIGNAL CLASSIFICATION SYSTEMS AND METHODS,"Systems and methods for neural signal classification for the processing of multicellular signals of a patient are disclosed. The system includes a preprocessing device operatively coupled to an input channel and configured to receive multicellular signals collected from a sensor, at least a portion of the sensor configured to be disposed within the brain of a patient. The preprocessing device is also configured to filter the multicellular signals to extract a neural signal portion of the multicellular signals, the neural signal portion including a neural spike portion and a local field potential portion. The system also includes a neural spike processing device operatively coupled to the preprocessing device. The system is configured to project information associated with a neural spike onto a feature space, the feature space indicative of a correlation of the neural spike with a benchmark signal. The system is also configured to adaptively determining a spike sorting statistical model for the feature space samples. The system is further configured to identify one or more types of voluntary stimuli based on analysis of the feature space, wherein the projected information is grouped in clusters, each cluster defining a particular type of voluntary stimuli.",A61B 5/04,"CYBERKINETICS NEUROTECHNOLOGY SYSTEMS, INC.; SEBALD, Daniel J.; BRANNER, Almut; KORVER, Kirk F.; PUNGOR, Andras; FLAHERTY, J. Christopher","SEBALD, Daniel J.; BRANNER, Almut; KORVER, Kirk F.; PUNGOR, Andras; FLAHERTY, J. Christopher","60/735,158 10.11.2005 US",EP-6837341
WO2018183221,PCT/US2018/024411,26.03.2018,WO/2018/183221,04.10.2018,WO,MACHINE-VISION METHOD TO CLASSIFY INPUT DATA BASED ON OBJECT COMPONENTS,"Described is a system for classifying objects and scenes in images. The system identifies salient regions of an image based on activation patterns of a convolutional neural network (CNN). Multi-scale features for the salient regions are generated by probing the activation patterns of the CNN at different layers. Using an unsupervised clustering technique, the multi-scale features are clustered to identify key attributes captured by the CNN. The system maps from a histogram of the key attributes onto probabilities for a set of object categories. Using the probabilities, an object or scene in the image is classified as belonging to an object category, and a vehicle component is controlled based on the object category causing the vehicle component to perform an automated action.",G06T 7/10; G06K 9/00; G06T 3/40; G06N 3/08,"HRL LABORATORIES, LLC","KOLOURI, Soheil; MARTIN, Charles, E.; HOFFMANN, Heiko","62/478,033 28.03.2017 US",EP-2018776168; CN-201880013120.1
WO2016049757,PCT/CA2015/050975,29.09.2015,WO/2016/049757,07.04.2016,WO,SYSTEM AND METHOD FOR DETECTING INVISIBLE HUMAN EMOTION,A system and method for emotion detection and more specifically to an image-capture based system and method for detecting invisible and genuine emotions felt by an individual. The system provides a remote and non-invasive approach by which to detect invisible emotion with a high confidence. The system enables monitoring of hemoglobin concentration changes by optical imaging and related detection systems.,A61B 5/145; A61B 5/02; A61B 5/04; A61B 5/16,NURALOGIX CORPORATION,"LEE, Kang; ZHENG, Pu","62/058,227 01.10.2014 US",EP-2015837220; CA-2962083
WO2018083667,PCT/IB2017/056902,04.11.2017,WO/2018/083667,11.05.2018,WO,REINFORCEMENT LEARNING SYSTEMS,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for prediction of an outcome related to an environment. In one aspect, a system comprises a state representation neural network that is configured to: receive an observation characterizing a state of an environment being interacted with by an agent and process the observation to generate an internal state representation of the environment state; a prediction neural network that is configured to receive a current internal state representation of a current environment state and process the current internal state representation to generate a predicted subsequent state representation of a subsequent state of the environment and a predicted reward for the subsequent state; and a value prediction neural network that is configured to receive a current internal state representation of a current environment state and process the current internal state representation to generate a value prediction.",G06N 3/04; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"SILVER, David; SCHAUL, Tom; HESSEL, Matteo; VAN HASSELT, Hado Philip","62/418,159 04.11.2016 US",EP-2017807934; JP-2019523612; CN-201780078702.3
WO2014022441,PCT/US2013/052797,30.07.2013,WO/2014/022441,06.02.2014,WO,CLASSIFICATION OF NUCLEOTIDE SEQUENCES BY LATENT SEMANTIC ANALYSIS,"DNA sequences are analyzed using latent semantic analysis. A set of nucleotide sequences is received in which the set has a first number of sequences. A set of basis vectors is determined, in which the set has a second number of basis vectors, the second number being smaller than the first number. Each basis vector represents a specific combination of predetermined nucleotide segments. For each of the nucleotide sequences, an approximate representation of the nucleotide sequence is determined based on a combination of the basis vectors. For each pair of nucleotide sequences, a distance between the pair of nucleotide sequences is determined according the distance between the approximate representation of the pair of nucleotide sequences. The set of nucleotide sequences are classified based on the distances between the pairs of nucleotide sequences.",G06F 19/00,"SAYOOD, Khalid; WAY, Sam; NALBANTOGLU, Ozkan Ufuk; GARRITY, George","SAYOOD, Khalid; WAY, Sam; NALBANTOGLU, Ozkan Ufuk; GARRITY, George","61/677,316 30.07.2012 US",
EP11126734,09168302,20.08.2009,2169505,31.03.2010,EP,Distributed knowledge base for vehicular localization and work-site management,"A vehicle is comprised of a machine controller, a steering system, a propulsion system, a braking system, a sensor system, and a knowledge base used by the machine controller. The machine controller identifies a dynamic condition and sends commands to the steering system, the propulsion system, and the braking system to move the vehicle.",G05D 1/02; G05D 1/00,DEERE & CO,ANDERSON NOEL WAYNE,20866608 11.09.2008 US,
WO2014149070,PCT/US2013/057724,30.08.2013,WO/2014/149070,25.09.2014,WO,NEURAL NETWORK AND METHOD OF PROGRAMMING,"A neural network, wherein a portion of the neural network comprises: a first array having a first number of neurons, wherein the dendrite of each neuron of the first array is provided for receiving an input signal indicating that a measured parameter gets closer to a predetermined value assigned to said neuron; and a second array having a second number of neurons, wherein the second number is smaller than the first number, the dendrite of each neuron of the second array forming an excitatory STDP synapse with the axon of a plurality of neurons of the first array; the dendrite of each neuron of the second array forming an excitatory STDP synapse with the axon of neighboring neurons of the second array.",G06N 3/02,"HRL LABORATORIES, LLC","SRINIVASA, Narayan; CHO, Youngkwan","61/799,883 15.03.2013 US; 14/015,001 30.08.2013 US",EP-2013878741
WO2018200072,PCT/US2018/020101,28.02.2018,WO/2018/200072,01.11.2018,WO,CYCLIC GENERATIVE ADVERSARIAL NETWORK FOR UNSUPERVISED CROSS-DOMAIN IMAGE GENERATION,A system is provided for unsupervised cross-domain image generation relative to a first and second image domain that each include real images. A first generator generates synthetic images similar to real images in the second domain while including a semantic content of real images in the first domain. A second generator generates synthetic images similar to real images in the first domain while including a semantic content of real images in the second domain. A first discriminator discriminates real images in the first domain against synthetic images generated by the second generator. A second discriminator discriminates real images in the second domain against synthetic images generated by the first generator. The discriminators and generators are deep neural networks and respectively form a generative network and a discriminative network in a cyclic GAN framework configured to increase an error rate of the discriminative network to improve synthetic image quality.,G06K 9/62; G06N 3/02,"NEC LABORATORIES AMERICA, INC.","CHOI, Wongun; SCHULTER, Samuel; SOHN, Kihyuk; CHANDRAKER, Manmohan","62/489,529 25.04.2017 US; 15/906,710 27.02.2018 US",JP-2019546011; DE-112018002166
WO2006076175,PCT/US2005/047682,30.12.2005,WO/2006/076175,20.07.2006,WO,BIOLOGICAL INTERFACE SYSTEM WITH PATIENT TRAINING APPARATUS,"Various embodiments of a biological interface system and related methods are disclosed. The system may include a sensor having a plurality of electrodes for detecting multicellular signals emanating from one or more living cells of a patient, and a processing unit configured to receive the multicellular signals from the sensor and process the multicellular signals to produce a processed signal. The processing unit may be configured to transmit the processed signal to a controlled device that is configured to receive the processed signal. The system may also include a patient training apparatus configured to receive a patient training signal that causes the patient training apparatus to controllably move one or more joints of the patient. The system may be configured to perform an integrated patient training routine to produce the patient training signal, to store a set of multicellular signal data detected during a movement of the one or more joints, and to correlate the set of multicellular signal data to a second set of data related to the movement of the one or more joints.",G06N 3/06; G06F 3/00; A61B 5/00; G09B 21/00,"CYBERKINETICS NEUROTECHNOLOGY SYSTEMS, INC.; FLAHERTY, J. Christopher; CAPLAN, Abraham, H.","FLAHERTY, J. Christopher; CAPLAN, Abraham, H.","60/643,358 10.01.2005 US",EP-5856134
WO2020046066,PCT/KR2019/011197,30.08.2019,WO/2020/046066,05.03.2020,WO,METHOD FOR TRAINING CONVOLUTIONAL NEURAL NETWORK TO RECONSTRUCT AN IMAGE AND SYSTEM FOR DEPTH MAP GENERATION FROM AN IMAGE,"A method for training a convolutional neural network to reconstruct an image. The method includes forming a common loss function basing on the left and right images, reconstructed left and right images, disparity maps, reconstructed disparity maps for the left and right images and the auxiliary images and training the neural network based on the formed loss function.",G06T 7/593; G06N 3/08,"SAMSUNG ELECTRONICS CO., LTD.","SHCHERBININ, Andrey Yurievich; ANISIMOVSKIY, Valery Valerievich; TURKO, Sergey Alexandrovich",2018131290 30.08.2018 RU,
WO2018213399,PCT/US2018/032902,16.05.2018,WO/2018/213399,22.11.2018,WO,INTEGRATED CIRCUIT DESIGNS FOR RESERVOIR COMPUTING AND MACHINE LEARNING,"An integrated circuit device for reservoir computing can include a weighted input layer, an unweighted, asynchronous, internal recurrent neural network made up of nodes having binary weighting, and a weighted output layer. Weighting of output signals can be performed using predetermined weighted sums stored in memory. Application specific integrated circuit (ASIC) embodiments may include programmable nodes. Characteristics of the reservoir of the device can be tunable to perform rapid processing and pattern recognition of signals at relatively large rates.",G06N 3/04; G06N 3/063; G11C 7/00; H03K 21/00,"UNIVERSITY OF MARYLAND, COLLEGE PARK","LATHROP, Daniel; SHANI, Itamar; MEGSON, Peter; RESTELLI, Alessandro; MAUTINO, Anthony Robert","62/662,119 24.04.2018 US; 62/506,951 16.05.2017 US; 62/555,511 07.09.2017 US",
WO2016053194,PCT/SG2015/050363,02.10.2015,WO/2016/053194,07.04.2016,WO,SYSTEM FOR PERFORMING TASKS IN AN OPERATING REGION AND METHOD OF CONTROLLING AUTONOMOUS AGENTS FOR PERFORMING TASKS IN THE OPERATING REGION,"In a system for performing a task in an operating region, there is a plurality of agents. Each of the plurality of agents has a start position in the operating region and an end position in the operating region. There is a ground control device comprising: a processor; and a storage device for storing one or more routines which, when executed under control of the processor, control the ground control device to: divide the operating region into a plurality of sub-regions based on the start and end positions of the plurality of agents so as to assign ones of the plurality of agents to each sub- region, wherein a number of the ones of the plurality of agents in each sub-region is smaller than a number of the plurality of agents in the operating region; generate sub-region data of each of the sub-regions; and generate a plurality of paths of movement based on the sub-region data of the sub- regions for allowing the plurality of agents to move in the operating region to perform the task.",G05D 1/10,INFINIUM ROBOTICS PTE LTD,"WOON, Junyang; ZHAO, Weihua; CHIEW, Soon Hooi; EKA, Richard",10201406357Q 03.10.2014 SG,CA-2963541; US-15516452; EP-2015808289
WO2013083650,PCT/EP2012/074552,05.12.2012,WO/2013/083650,13.06.2013,WO,POSITION AND ORIENTATION DETERMINATION IN 6-DOF,"A method for a six degree of freedom position and orientation determination of a three dimensional known shape in a scenery, by taking a range image by means of a range imaging camera and taking a visual picture by means of a digital camera. The range imaging camera comprises a range image module having a sensor array with a first number of pixels, wherein for each of the first pixels range information from the sensor to a point of the scenery is determined, resulting in a 3D cluster of points. The digital camera comprises an image sensor having a second number of pixels, resulting in a 2D picture. The relation of the first and the second pixels fields of view is known. The method comprises a geometrically fitting of a stored 3D digital representation of the known shape in a virtual space to match with the reproduction of the known object in the 2D picture and the 3D cluster of points and determining the six degree of freedom position and orientation of the known shape in the scenery according to the virtual match.",G01C 15/06; B25J 9/16; E02F 3/84; G01C 15/00,"HEXAGON TECHNOLOGY CENTER GMBH; PETTERSSON, Bo; SIERCKS, Knut; VOIT, Eugen; HINDERLING, Jürg; ZEBHAUSER, Benedikt; SCHNEIDER, Klaus","PETTERSSON, Bo; SIERCKS, Knut; VOIT, Eugen; HINDERLING, Jürg; ZEBHAUSER, Benedikt; SCHNEIDER, Klaus",11192220.9 06.12.2011 EP,US-14363102; EP-2012797905
WO1998033451,PCT/US1998/001975,02.02.1998,WO/1998/033451,06.08.1998,WO,MULTIMODALITY INSTRUMENT FOR TISSUE CHARACTERIZATION,"A system with multimodality instrument for tissue identification includes a computer-controlled motor driven heuristic probe with a multisensory tip. For neurosurgical applications, the instrument is mounted on a stereotactic frame for the probe to penetrate the brain in a precisely controlled fashion. The resistance of the brain tissue being penetrated is continually monitored by a miniaturized strain gauge attached to the probe tip. Other modality sensors may be mounted near the probe tip to provide real-time tissue characterizations and the ability to detect the proximity of blood vessels, thus eliminating errors normally associated with registration of pre-operative scans, tissue swelling, elastic tissue deformation, human judgement, etc., and rendering surgical procedures safer, more accurate, and efficient. A neural network program adaptively learns the information on resistance and other characteristic features of normal brain tissue during the surgery and provides near real-time modeling. Identification of abnormal brain tissue is determined by the detection of change and comparison with previously learned models of abnormal brain tissues. The operation of the instrument is controlled through a user friendly graphical interface. Patient data is presented in a 3D stereographics display.",A61B 1/00; A61B 5/00; A61B 5/026; A61B 5/03; A61B 5/0476; A61B 8/08; A61B 17/00; A61B 19/00,"NATIONAL AERONAUTICS AND SPACE ADMINISTRATION; MAH, Robert, W.; RUSSELL, J., Andrews","MAH, Robert, W.; RUSSELL, J., Andrews","08/795,272 04.02.1997 US; null 02.02.1998 US",
WO2017124116,PCT/US2017/013829,17.01.2017,WO/2017/124116,20.07.2017,WO,"SEARCHING, SUPPLEMENTING AND NAVIGATING MEDIA","One or more computing devices, systems, and/or methods for searching, supplementing and/or navigating media are provided. For example, a query for media may be used to identify results and provide the results based upon temporal properties of the results. In another example, media may be segmented into portions based upon time-associated text information of the media, and each portion of the media may be supplemented with content selected based upon a context of the portion. In another example, an area of a video may be selected based upon image analysis of the video, and the video may be supplemented with content at the area. In another example, a video may be supplemented with content, and properties of the content may be adjusted based upon image analysis of the video. In another example, media may be navigated through at different rates of advancement.",G06F 17/30,"BAO, Sheng; LIU, Yang","BAO, Sheng; LIU, Yang","62/279,616 15.01.2016 US; 62/446,650 16.01.2017 US",
WO2007071070,PCT/CA2006/002129,22.12.2006,WO/2007/071070,28.06.2007,WO,SPATIO-TEMPORAL PATTERN RECOGNITION USING A SPIKING NEURAL NETWORK AND PROCESSING THEREOF ON A PORTABLE AND/OR DISTRIBUTED COMPUTER,"A system and method for characterizing a pattern, in which a spiking neural network having at least one layer of neurons is provided. The spiking neural network has a plurality of connected neurons for transmitting signals between the connected neurons. A model for inducing spiking in the neurons is specified. Each neuron is connected to a global regulating unit for transmitting signals between the neuron and the global regulating unit. Each neuron is connected to at least one other neuron for transmitting signals from this neuron to the at least one other neuron, this neuron and the at least one other neuron being on the same layer. Spiking of each neuron is synchronized according to a number of active neurons connected to the neuron. At least one pattern is submitted to the spiking neural network for generating sequences of spikes in the spiking neural network, the sequences of spikes (i) being modulated over time by the synchronization of the spiking and (ii) being regulated by the global regulating unit. The at least one pattern is characterized according to the sequences of spikes generated in the spiking neural network.",G06N 3/02; G06K 9/62; G06N 3/04,"UNIVERSITE DE SHERBROOKE; ROUAT, Jean; PICHEVAR, Ramin; LOISELLE, Stéphane; TAI, Le Tan Thanh; HAI, Anh Hoang; LAVOIE, Jean; BERGERON, Jocelyn","ROUAT, Jean; PICHEVAR, Ramin; LOISELLE, Stéphane; TAI, Le Tan Thanh; HAI, Anh Hoang; LAVOIE, Jean; BERGERON, Jocelyn","60/752,869 23.12.2005 US",CA-2642041; DE-null; US-12158134; EP-2006840555
EP278936865,19178438,05.06.2019,3579185,11.12.2019,EP,SYSTEMS AND METHODS FOR DATA ACQUISITION AND ASSET INSPECTION IN PRESENCE OF MAGNETIC INTERFERENCE,,G06T 7/00,TATA CONSULTANCY SERVICES LTD,JOSHI SUNIL DATTATRAYA; MISHRA MAYANK; VYAWAHARE VAIBHAV; SALSINGIKAR SHRIPAD; GUBBI LAKSHMINARASIMHA JAYAVARDHANA RAMA; KOTAMRAJU SRINIVAS; BHOGINENI SREEHARI KUMAR; RAJ RISHIN; HARIHARAN ANAND VISHNU; BAJPAI VISHAL; MOHAN PONRAJ JEGAN; RANGARAJ MAHESH; PURUSHOTHAMAN BALAMURALIDHAR; KANDASWAMY GOPI,201821020933 05.06.2018 IN,
WO2019217106,PCT/US2019/029525,27.04.2019,WO/2019/217106,14.11.2019,WO,TRAINING NEURAL NETWORKS USING MIXED PRECISION COMPUTATIONS,"A system for training a neural network receives training data and performing lower precision format training calculations using lower precision format data at one or more training phases. One or more results from the lower precision format training calculations are converted to higher precision format data, and higher precision format training calculations are performed using the higher precision format data at one or more additional training phases. The neural network is modified using the results from the one or more additional training phases. The mixed precision format training calculations train the neural network more efficiently, while maintaining an overall accuracy.",G06N 3/063; G06N 3/08,"MICROSOFT TECHNOLOGY LICENSING, LLC","LO, Daniel; CHUNG, Eric Sen; ROUHANI, Bita Darvish","15/974,637 08.05.2018 US",
WO2018128672,PCT/US2017/058212,25.10.2017,WO/2018/128672,12.07.2018,WO,SYSTEMS AND METHODS FOR CLASSIFYING ROAD FEATURES,"An electronic device is described. The electronic device includes a memory and a processor in communication with the memory. The memory is configured to store precalibration data for a camera mounted on a vehicle, the precalibration data including a camera height determined relative to a road plane the vehicle is configured to contact during operation. The processor is configured to receive a plurality of images. The processor is also configured to classify one or more features in the plurality of images as road features based on the precalibration data.",G06K 9/00,QUALCOMM INCORPORATED,"JOSHI, Avdhut; RAMANANDAN, Arvind; CHARI, Murali","62/442,415 04.01.2017 US; 15/629,311 21.06.2017 US",EP-2017794878; CN-201780073418.7
WO2010022391,PCT/US2009/054781,24.08.2009,WO/2010/022391,25.02.2010,WO,"INTEGRATED, AUTOMATED SYSTEM FOR THE STUDY OF CELL AND TISSUE FUNCTION","The present invention provides for an automated, high-throughput, multi-parameter integrated analysis system to monitor, in parallel, cellular parameters descriptive of cell function and associated physiology both singly and in interactions with other cells in tissues. Parameters may be measured with cell or tissue samples confined in arrays of chambers microfabricated in cassettes. System variants provide for cell or tissue harvesting for (optionally destructive) further analysis. The present invention relates to a system for biological laboratory automation, providing for full automation of cell manipulation using capillary micropipettes and associated robotics. This invention provides a robust and flexible technology that can be deployed in research and corporate laboratories, enabling new experimental protocols. Applications include microinjection and high-throughput, single- to multi-cell, multi-parameter monitoring of parameters such as respiration rates, moiety of interest concentrations, metabolic fluxes, chemotactic gradients, gene expression and transcription, translation to proteins (intracellular, membrane, and extracellular), membrane integrity, and cellular ion gradients.",G01N 33/48; G01N 35/00; C12Q 1/68,"AZTE ARIZONA TECHNOLOGY ENTERPRISES; THE UNIVERSITY OF WASHINGTON; HOLL, Mark; MELDRUM, Deirdre; ANIS, Yassir; ASHILI, Shashanka; HOUKAL, Jeff; JOHNSON, Roger; KELBAUSKAS, Laimonas; LI, Yongzhong; MERZA, Saeed; NANDAKUMAR, Vivek; SMITH, Dean; YOUNG, Cody; TIAN, Xanqing; ZHU, Haixin; CHAO, Joseph","HOLL, Mark; MELDRUM, Deirdre; ANIS, Yassir; ASHILI, Shashanka; HOUKAL, Jeff; JOHNSON, Roger; KELBAUSKAS, Laimonas; LI, Yongzhong; MERZA, Saeed; NANDAKUMAR, Vivek; SMITH, Dean; YOUNG, Cody; TIAN, Xanqing; ZHU, Haixin; CHAO, Joseph","61/091,036 22.08.2008 US",
WO2018140517,PCT/US2018/015075,24.01.2018,WO/2018/140517,02.08.2018,WO,CHIP EMBEDDED PRINTED CIRCUIT BOARDS AND METHODS OF FABRICATION,"The disclosure relates to systems, methods and compositions for direct printing of printed circuit boards with embedded integrated chips. Specifically, the disclosure relates to systems methods and compositions for the direct, top-down inkjet printing of printed circuit board with embedded chip and/or chip packages using a combination of print heads with conductive and dielectric ink compositions, creating predetermined dedicated compartments for locating the chips and/or chip packages and covering these with an encapsulating layer while maintaining interconnectedness among the embedded chips. Placing of the chips can be done automatically using robotic arms.",G06F 17/50; B33Y 10/00,"NANO-DIMENSION TECHNOLOGIES, LTD.; THE IP LAW FIRM OF GUY LEVI, LLC","KOZLOVSKI, Dan","62/450,722 26.01.2017 US",KR-1020197024904; EP-2018744134; CA-3049984; JP-2019539936; CN-201880008444.6
WO2020069039,PCT/US2019/053028,25.09.2019,WO/2020/069039,02.04.2020,WO,CONTINUAL NEURAL NETWORK LEARNING VIA EXPLICIT STRUCTURE LEARNING,Embodiments for training a neural network using sequential tasks are provided. A plurality of sequential tasks are received. For each task in the plurality of tasks a copy of the neural network that includes a plurality of layers is generated. From the copy of the neural network a task specific neural network is generated by performing an architectural search on the plurality of layers in the copy of the neural network. The architectural search identifies a plurality of candidate choices in the layers of the task specific neural network. Parameters in the task specific neural network that correspond to the plurality of candidate choices and that maximize architectural weights at each layer are identified. The parameters are retrained and merged with the neural network. The neural network trained on the plurality of sequential tasks is a trained neural network.,G06N 3/08; G06N 3/04,"SALESFORCE.COM, INC.","ZHOU, Yingbo; LI, Xilai; XIONG, Caiming","62/737,636 27.09.2018 US; 16/176,419 31.10.2018 US",
EP232832034,18170077,30.04.2018,3399466,07.11.2018,EP,NEURAL NETWORK TRAINING IMAGE GENERATION SYSTEM,A system (100) that generates training images for neural networks includes one or more processors configured to receive input representing one or more selected areas in an image mask. The one or more processors are configured to form a labeled masked image by combining the image mask with an unlabeled image of equipment. The one or more processors also are configured to train an artificial neural network using the labeled masked image to one or more of automatically identify equipment damage appearing in one or more actual images of equipment and/or generate one or more training images for training another artificial neural network to automatically identify the equipment damage appearing in the one or more actual images of equipment.,G06K 9/62; G06T 7/00,GEN ELECTRIC,LIM SER NAM; JAIN ARPIT; DIWINSKY DAVID SCOTT; BONDUGULA SRAVANTHI,201715584129 02.05.2017 US,
WO2017196640,PCT/US2017/031176,05.05.2017,WO/2017/196640,16.11.2017,WO,SEGMENTING SCENES INTO SEMATIC COMPONENTS USING NEUROLOGICAL READINGS,"Computer vision systems for segmenting scenes into semantic components identify a differential within the physiological readings from the user. The differential corresponds to a semantic boundary associated with the user's gaze. Based upon data gathered by a gaze tracking device, the computer vision system identifies a relative location of the user's gaze at the time of the identified differential. The computer vision system then associates the relative location of the user's gaze with a semantic boundary.",G06K 9/00; G06F 3/01,"MICROSOFT TECHNOLOGY LICENSING, LLC","GORDON, John C.; KESKIN, Cem","15/151,850 11.05.2016 US",EP-2017724189
WO2017025954,PCT/IL2016/050859,07.08.2016,WO/2017/025954,16.02.2017,WO,METHODS FOR DETERMINING THE RISK OF A SYSTEMIC LUPUS ERYTHEMATOSUS (SLE) PATIENT TO DEVELOP NEUROPSYCHIATRIC SYNDROMES,Methods and kits are provided for diagnosing of neuropsychiatric syndromes concurrent with SLE (NPSLE) and for determining whether an SLE subject is at risk of developing a neuropsychiatric disease.,G01N 33/564; G06F 19/20; G06F 19/24,IMMUNARRAY LTD,"JAKOBI, Keren; REINER-BENAIM, Anat","62/202,844 09.08.2015 US",US-15751242
EP222933513,17208265,18.12.2017,3346464,11.07.2018,EP,ELECTRONIC DEVICE FOR RECOGNIZING SPEECH,"An electronic device includes a microphone obtaining an audio signal, a memory in which a speaker model is stored, and at least one processor. The at least one processor is configured to obtain a voice signal from the audio signal, to compare the voice signal with the speaker model to verify a user, and, if a verification result indicates that the user corresponds to a pre-enrolled speaker, to perform an operation corresponding to the obtained voice signal.",G10L 17/22; G10L 15/22; G10L 17/04,SAMSUNG ELECTRONICS CO LTD,LEE YOUNG WOO; SHIN HO SEON; LEE SANG HOON,20170003085 09.01.2017 KR,
WO2019105974,PCT/EP2018/082782,28.11.2018,WO/2019/105974,06.06.2019,WO,SYSTEMS AND METHODS FOR TRAINING AND CONTROLLING AN ARTIFICIAL NEURAL NETWORK WITH DISCRETE VEHICLE DRIVING COMMANDS,"Systems, devices, and methodologies are provided for training and controlling a neural network. The neural network is trained using definitive and random training modes to train neurons in a monolithic network. The neural network output is used to control an autonomous or semi-autonomous vehicle.",G05D 1/02; B60W 30/00,VOLKSWAGEN AKTIENGESELLSCHAFT; AUDI AG,"SALEEM, Muneeb",15/827982 30.11.2017 US,
EP243363842,17836414,03.08.2017,3496007,12.06.2019,EP,DEVICE AND METHOD FOR EXECUTING NEURAL NETWORK OPERATION,"A device and method for executing a neural network operation. The device comprises: an on-chip interconnection module and a plurality of neural network processing modules connected thereto and communicating therewith. The neural network processing modules can read or write, via the on-chip interconnection module, data to or form another neural network processing module. For multi-core multi-layer artificial neural network operations, the neural network operations in each layer are divided for the plurality of neural network processing modules to execute the same, so as to obtain data of respective operation results. Further, the plurality of neural network processing modules exchange therebetween the data of respective operation results.",G06N 3/063,CAMBRICON TECH CORPORATION LIMITED,CHEN YUNJI; LIU SHAOLI; HAN DONG; CHEN TIANSHI,201610635286 05.08.2016 CN; 2017095810 03.08.2017 CN,
WO2018116248,PCT/IB2017/058297,21.12.2017,WO/2018/116248,28.06.2018,WO,SYSTEM AND METHOD FOR ITERATIVE CLASSIFICATION USING NEUROPHYSIOLOGICAL SIGNALS,"A method of training an image classification neural network comprises: presenting a first plurality of images to an observer as a visual stimulus, while collecting neurophysiological signals from a brain of the observer; processing the neurophysiological signals to identify a neurophysiological event indicative of a detection of a target by the observer in at least one image of the first plurality of images; training the image classification neural network to identify the target in the image, based on the identification of the neurophysiological event; and storing the trained image classification neural network in a computer-readable storage medium.",A61B 5/00; G06T 7/00,INNEREYE LTD.,"GEVA, Amir B.; NETZER, Eitan; MANOR, Ran El; VAISMAN, Sergey; DEOUELL, Leon Y.; ANTMAN, Uri","62/437,065 21.12.2016 US",CN-201780081627.6; CA-3046939; IL-267518; EP-2017883157; JP-2019533183
EP238739207,16899898,04.05.2016,3451236,06.03.2019,EP,METHOD AND DEVICE FOR EXECUTING FORWARDING OPERATION OF FULLY-CONNECTED LAYERED NEURAL NETWORK,"The present invention provides a device performing a forward propagation process for fully connected layers of artificial neural network, comprising an instruction storage unit, a controller unit, a data access unit, an interconnection module, a master operation module and a plurality of slave operation modules. The device may implement a forward propagation process of single-layer or multi-layer fully connected layers of artificial neural network. For each layer, the intermediate vector of the layer is first calculated by weighted summation of the input neuron vector, then the intermediate result vector is biased and activated to obtain the output neuron vector. The output neuron vector is the input neuron vector of the next layer.",G06N 3/02; G06F 13/28; G06N 3/04; G06N 3/063; G06N 5/00,CAMBRICON TECH CORPORATION LIMITED,LIU SHAOLI; LAN HUIYING; GUO QI; CHEN YUNJI; CHEN TIANSHI,2016080968 04.05.2016 CN; 201610270004 27.04.2016 CN,
WO2020018370,PCT/US2019/041590,12.07.2019,WO/2020/018370,23.01.2020,WO,MULTI-MODAL ELECTRONIC DOCUMENT CLASSIFICATION,"A method comprising operating at least one hardware processor for: receiving, as input, a plurality of electronic documents, training a machine learning classifier based, at least on part, on a training set comprising: (i) labels associated with the electronic documents, (ii) raw text from each of said plurality of electronic documents, and (iii) a rasterized version of each of said plurality of electronic documents, and applying said machine learning classifier to classify one or more new electronic documents.",G06K 9/00; G06K 9/46; G06K 9/62,"NETAPP, INC.","LEIBOVITZ, Guy; BALI, Adam","62/698,168 15.07.2018 US; 16/037,194 17.07.2018 US; 16/271,847 10.02.2019 US",
WO2019079907,PCT/CA2018/051364,29.10.2018,WO/2019/079907,02.05.2019,WO,METHOD AND SYSTEM FOR FACILITATING IDENTIFICATION OF AN OBJECT-OF-INTEREST,"There are described methods and systems for facilitating identification of an object-of-interest. A face similarity score and a body similarity score of a query image relative to a gallery image are determined. A fused similarity score of the query image relative to the gallery image is determined by applying a relationship between the face similarity score, the body similarity score, and the fused similarity score. The fused similarity score is indicative of whether or not the object-of-interest and the potential object-of-interest are the same object-of-interest. For example, a machine learning process is used to fuse the face similarity score and the body similarity into the fused similarity score. The process is repeated for multiple gallery images. The gallery images may then be ranked according to their respective fused similarity scores.",G06K 9/68; G06N 20/00; G06N 3/02; G08B 13/196,AVIGILON CORPORATION,"DOUMBOUYA, Moussa; HE, Lu; HU, Yanyan; SAPTHARISHI, Mahesh; ZHANG, Hao; ALCOCK, Nicholas John; DONALDSON, Roger David; AZIZABADIFARAHANI, Seyedmostafa; JESSEN, Ken","62/578,237 27.10.2017 US; 62/655,702 10.04.2018 US",
WO2020061273,PCT/US2019/051868,19.09.2019,WO/2020/061273,26.03.2020,WO,VENTRAL-DORSAL NEURAL NETWORKS: OBJECT DETECTION VIA SELECTIVE ATTENTION,Embodiments described herein relate generally to a methodology of efficient object classification within a visual medium. The methodology utilizes a first neural network to perform an attention based object localization within a visual medium to generate a visual mask. The visual mask is applied to the visual medium to generate a masked visual medium. The masked visual medium may be then fed into a second neural network to detect and classify objects within the visual medium.,G06N 3/04; G06K 9/46; G06K 9/62; G06N 3/02; G06T 7/00,ANCESTRY.COM OPERATIONS INC.,"EBRAHIMPOUR, Mohammad K.; YU, Yen-Yun; LI, Jiayun; REESE, Jack; MOGHTADERI, Azadeh","62/734,897 21.09.2018 US; 16/573,180 17.09.2019 US",
WO2018170512,PCT/US2018/023155,19.03.2018,WO/2018/170512,20.09.2018,WO,"ONLINE, INCREMENTAL REAL-TIME LEARNING FOR TAGGING AND LABELING DATA STREAMS FOR DEEP NEURAL NETWORKS AND NEURAL NETWORK APPLICATIONS","Today, artificial neural networks are trained on large sets of manually tagged images. Generally, for better training, the training data should be as large as possible. Unfortunately, manually tagging images is time consuming and susceptible to error, making it difficult to produce the large sets of tagged data used to train artificial neural networks. To address this problem, the inventors have developed a smart tagging utility that uses a feature extraction unit and a fast-learning classifier to learn tags and tag images automatically, reducing the time to tag large sets of data. The feature extraction unit and fast-learning classifiers can be implemented as artificial neural networks that associate a label with features extracted from an image and tag similar features from the image or other images with the same label. Moreover, the smart tagging system can learn from user adjustment to its proposed tagging. This reduces tagging time and errors.",G06F 17/00; G06F 17/30; G06K 9/00,"NEURALA, INC.","WURBS, Jeremy; GORSHECHNIKOV, Anatoly; VERSACE, Massimiliano; KATZ, Warren; NEVES, Lucas; DEBEASI, Liam; VERSACE, Heather Ames","62/472,925 17.03.2017 US",KR-1020197030696; CA-3056884; CN-201880032375.2; JP-2019551365; EP-2018767344
WO2017083775,PCT/US2016/061702,11.11.2016,WO/2017/083775,18.05.2017,WO,DUELING DEEP NEURAL NETWORKS,"Systems, methods, and apparatus, including computer programs encoded on a computer storage medium, for selecting an actions from a set of actions to be performed by an agent interacting with an environment. In one aspect, the system includes a dueling deep neural network. The dueling deep neural network includes a value subnetwork, an advantage subnetwork, and a combining layer. The value subnetwork processes a representation of an observation to generate a value estimate. The advantage subnetwork processes the representation of the observation to generate an advantage estimate for each action in the set of actions. The combining layer combines the value estimate and the respective advantage estimate for each action to generate a respective Q value for the action. The system selects an action to be performed by the agent in response to the observation using the respective Q values for the actions in the set of actions.",G06N 3/04; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"WANG, Ziyu; GOMES DE FREITAS, Joao Ferdinando; LANCTOT, Marc","62/254,684 12.11.2015 US",KR-1020187016564; JP-2018524773; EP-2016809575
WO2019018649,PCT/US2018/042896,19.07.2018,WO/2019/018649,24.01.2019,WO,SYSTEMS AND METHODS FOR PREDICTING AND IDENTIFYING RETAIL SHRINKAGE ACTIVITY,"A retail shrinkage activity prediction and identification system that includes: a sensor control system, a first shrinkage database, a second shrinkage database, an analytics engine, and a machine learning engine. The sensor control system is communicatively coupled with a plurality of sensors arranged in a retail environment. The sensor control system is configured to control a setting of each of the plurality of sensors. The first shrinkage database includes retail shrinkage data for at least the retail environment. The retail shrinkage data includes at least one item at high risk for shrinkage or at least one time at high risk for shrinkage activity. The second shrinkage database includes external data related to shrinkage in a geographic area of the retail environment. The analytics engine is communicatively coupled with the first shrinkage database, the second shrinkage database, and the sensor control system.",G06E 1/00,"WALMART APOLLO, LLC","LOBO, Charles; ZHANG, Jinzhi; MOORE, Trisha; TYAGI, Aman","62/534,304 19.07.2017 US",
EP13837841,02010724,14.05.2002,1260968,27.11.2002,EP,"Method and system for recognizing, indexing, and searching acoustic signals",A computerized method extracts features from an acoustic signal generated from one or more sources. The acoustic signal are first windowed and filtered to produce a spectral envelope for each source. The dimensionality of the spectral envelope is then reduced to produce a set of features for the acoustic signal. The features in the set are clustered to produce a group of features for each of the sources. The features in each group include spectral features and corresponding temporal features characterizing each source. Each group of features is a quantitative descriptor that is also associated with a qualitative descriptor. Hidden Markov models are trained with sets of known features and stored in a database. The database can then be indexed by sets of unknown features to select or recognize like acoustic signals. <IMAGE>,G10L 15/10; G10L 11/00; G10L 15/02; G10L 15/06; G10L 15/14; G10L 19/00; G10L 21/02,MITSUBISHI ELECTRIC CORP,CASEY MICHAEL A,86180801 21.05.2001 US,
WO2018128362,PCT/KR2018/000069,03.01.2018,WO/2018/128362,12.07.2018,WO,ELECTRONIC APPARATUS AND METHOD OF OPERATING THE SAME,"An electronic apparatus includes a processor configured to obtain a plurality of images, extract deep features with respect to the plurality of images using a feature extraction model, classify the plurality of images into certain groups using the extracted deep features and a classification model, display a result of the classification on the display, determine whether the feature extraction model and/or the classification model need to be updated using the result of the classification, and train and update at least one of the feature extraction model and the classification model based on a result of the determination. The electronic apparatus may estimate a deep feature of an image using a rule-based or artificial intelligence (AI) algorithm. When the deep feature of the image is estimated using the AI algorithm, the electronic apparatus may use a machine learning, neural network, or deep learning algorithm, or the like.",G06F 17/30; G06N 3/04; G06N 3/08,"SAMSUNG ELECTRONICS CO., LTD.","KANG, Seong-min; HAN, Heung-woo",10-2017-0000789 03.01.2017 KR; 10-2017-0136612 20.10.2017 KR,EP-2018735947; CN-201880005869.1
WO2017165701,PCT/US2017/023898,23.03.2017,WO/2017/165701,28.09.2017,WO,Fog Computing Facilitated Flexible Factory,"Provided herein are exemplary systems and methods for a fog computing facilitated flexible factory including establishing a physical production process as part of a work cell, establishing a sensing process as part of the work cell for the physical production process, establishing a monitoring process for the sensing process and the physical production process, establishing a managing process for the monitoring process, the sensing process and the physical production process, establishing a planning process for the managing process, the monitoring process, the sensing process and the physical production process, and establishing a fog node as part of the work cell for all of the processes.",H04L 12/24; H04L 12/26; H04W 24/00,"NEBBIOLO TECHNOLOGIES, INC.","BONOMI, Flavio; JOSHI, Chandra Shekhar; DEVARAJAN, Kannan; BHAGRA, Pankaj; CHINNAKANNAN, Palani","62/313,640 25.03.2016 US",EP-2017771191; JP-2019500751
WO2015191652,PCT/US2015/034994,10.06.2015,WO/2015/191652,17.12.2015,WO,MODELING INTERESTINGNESS WITH DEEP NEURAL NETWORKS,"An ""Interestingness Modeler"" uses deep neural networks to learn deep semantic models (DSM) of ""interestingness."" The DSM, consisting of two branches of deep neural networks or their convolutional versions, identifies and predicts target documents that would interest users reading source documents. The learned model observes, identifies, and detects naturally occurring signals of interestingness in click transitions between source and target documents derived from web browser logs. Interestingness is modeled with deep neural networks that map source-target document pairs to feature vectors in a latent space, trained on document transitions in view of a ""context"" and optional ""focus"" of source and target documents. Network parameters are learned to minimize distances between source documents and their corresponding ""interesting"" targets in that space. The resulting interestingness model has applicable uses, including, but not limited to, contextual entity searches, automatic text highlighting, prefetching documents of likely interest, automated content recommendation, automated advertisement placement, etc.",G06F 17/30,"MICROSOFT TECHNOLOGY LICENSING, LLC","GAO, Jianfeng; DENG, Li; GAMON, Michael; HE, Xiaodong; PANTEL, Patrick","14/304,863 13.06.2014 US",CN-201580031793.6; EP-2015731189
WO2019178404,PCT/US2019/022342,14.03.2019,WO/2019/178404,19.09.2019,WO,AUTOMATED CARDIAC FUNCTION ASSESSMENT BY ECHOCARDIOGRAPHY,"A computer vision pipeline is provided for fully automated interpretation of cardiac function, using a combination of machine learning strategies to enable building a scalable analysis pipeline for echocardiogram interpretation. Videos from patients with heart failure can be analyzed and processed as follows: 1) preprocessing of echo studies; 2) convolutional neural networks (CNN) processing for view identification; 3) segmentation of chambers and delineation of cardiac boundaries using CNNs; 4); particle tracking to compute longitudinal strain; and 5) targeted disease detection.",A61B 5/00,THE REGENTS OF THE UNIVERSITY OF CALIFORNIA,"DEO, Rahul C.; ZHANG, Jeffrey","62/642,930 14.03.2018 US",
WO2004114145,PCT/IB2004/002119,21.06.2004,WO/2004/114145,29.12.2004,WO,NEURAL NETWORKS WITH LEARNING AND EXPRESSION CAPABILITY,A neural network comprising a plurality of neurons in which any one of the plurality of neurons is able to associate with itself or another neuron in the plurality of neurons via active connections to a further neuron in the pluarlity of neurons.,G06F 15/18,"NEURAMATIX SDN. BHD.; HERCUS, Robert George","HERCUS, Robert George",26.06.2003 MY 00.24.2003 PI,US-10560666; EP-2004737088; CN-200480017847.5; IL-172201; EP-2012156393; JP-2006516581; AU-2004250403; EP-2012156398; EP-2012156406; EP-2012156467; EP-2012156468; IN-5916/DELNP/2005
WO2015002114,PCT/JP2014/067295,23.06.2014,WO/2015/002114,08.01.2015,WO,METHOD AND APPARATUS FOR DETERMINING POSE OF OBJECT IN SCENE,"A method for determining a pose of an object in a scene by determining a set of scene features from data acquired of the scene and matching the scene features to model features to generate weighted candiate poses when the scene feature matches one of the model features, wherein the weight of the candidate pose is proportional to the model weight. Then, the pose of the object is determined from the candidate poses based on the weights.",G06T 7/00,MITSUBISHI ELECTRIC CORPORATION,"TUZEL, Oncel; LIU, Ming-Yu; TAGUCHI, Yuichi; RAGHUNATHAN, Arvind U.","13/934,315 03.07.2013 US",
WO2019081891,PCT/GB2018/053001,17.10.2018,WO/2019/081891,02.05.2019,WO,ARTIFICIAL INTELLIGENCE SYSTEMS AND AUTONOMOUS ENTITY APPARATUSES INCLUDING ARTIFICIAL INTELLIGENCE SYSTEMS,"Autonomous entity apparatuses and artificial intelligence systems comprising: an artificial neural network at least part of which is hardware implemented, the neural network being a multiple-layer neural network having input layer nodes, output layer nodes and at least one hidden layer of nodes, the neural network being configured to repeatedly propagate its inputs to its outputs with each propagation being termed a decision cycle, wherein the neural network has encoded within it at least one node which is a symbolic representation (symbol) for 'self which has within at least part of its definition an association with said at least part of the neural network which is hardware implemented and wherein at least one of the output layer nodes is connected to at least one of the input layer nodes such that internal feedback data may be provided to said at least one of the input layer nodes and the neural network is configured to carry out successive decision cycles in response to said internal feedback data irrespective of whether any data external to the neural network is provided to the input layer nodes.",G06N 3/00; G06N 3/04,ZYZZLE LIMITED,"SLADE, Glen Jonathan",1717458.2 24.10.2017 GB,
WO2007005464,PCT/US2006/025167,27.06.2006,WO/2007/005464,11.01.2007,WO,BUILDING AND USING PREDICTIVE MODELS OF CURRENT AND FUTURE SURPRISES,"Methods are described for identifying events that would be considered surprising by people and identifying how and when to transmit information to a user about situations that they would likely find surprising. Additionally, the methods of identifying surprising situations can be used to build a case library of surprising events, joined with a set of observations before the surprising events occurred. Statistical machine learning methods can be applied with data from the case library to build models that can predict when a user will likely be surprised at future times. One or more models of context-sensitive expectations of people, a view of the current world, and methods for recording streams or events before surprises occur, and for building predictive models from a case library of surprises and such historical observations can be employed. The models of current and future surprises can be coupled with display and alerting machinery.",G06F 15/16,MICROSOFT CORPORATION,"HORVITZ, Eric, J.","11/172,581 30.06.2005 US",EP-6785741; DE-null
WO2019116353,PCT/IB2018/060143,15.12.2018,WO/2019/116353,20.06.2019,WO,TRAINING NEURAL NETWORKS USING EVOLUTION BASED STRATEGIES AND NOVELTY SEARCH,"Systems and methods are disclosed herein for selecting a parameter vector from a set of parameter vectors for a neural network and generating a plurality of copies of the parameter vector. The systems and methods generate a plurality of modified parameter vectors by perturbing each copy of the parameter vector with a different perturbation seed, and determine, for each respective modified parameter vector, a respective measure of novelty. The systems and methods determine an optimal new parameter vector based on each respective measure of novelty for each respective one of the plurality of modified parameter vectors, and determine behavior characteristics of the new parameter vector. The systems and methods store the behavior characteristics of the new parameter vector in an archive.",G06N 3/08; G06N 3/04,"UBER TECHNOLOGIES, INC.","CONTI, Edoardo; MADHAVAN, Vashisht; CLUNE, Jeffrey Michael; PETROSKI SUCH, Felipe; LEHMAN, Joel Anthony; STANLEY, Kenneth Owen","62/599,611 15.12.2017 US; 62/778,237 11.12.2018 US",
EP91284327,13158198,07.03.2013,2639766,18.09.2013,EP,"Model generation apparatus, information processing apparatus, model generation method, and information processing method",A three-dimensional shape model of a target object is input. A position and orientation of at least one image sensing device used to capture an image of the target object is set so as to virtually set a relative position and orientation between the target object and the image sensing device for the three-dimensional shape model of the target object. At least one position and orientation of the image sensing device is selected. Geometric features are grouped based on a relationship between an image to be obtained at the selected position and orientation of the image sensing device and the geometric features of the three-dimensional shape model.,G06T 7/00; B25J 9/16,CANON KK,TATENO KEISUKE; FURIHATA HISAYOSHI; UCHIYAMA SHINJI,2012056489 13.03.2012 JP; 2012167647 27.07.2012 JP,
EP173662520,15178864,29.07.2015,3023910,25.05.2016,EP,METHOD AND SYSTEM FOR LEARNING PIXEL VISUAL CONTEXT FROM OBJECT CHARACTERISTICS TO GENERATE RICH SEMANTIC IMAGES,"Both object-oriented analysis and the faster pixel-oriented analysis are used to recognize patterns in an image of stained tissue. Object-oriented image analysis is used to segment a small portion of the image into object classes. Then the object class to which each pixel in the remainder of the image most probably belongs is determined using decision trees with pixelwise descriptors. The pixels in the remaining image are assigned object classes without segmenting the remainder of the image into objects. After the small portion is segmented into object classes, characteristics of object classes are determined. The pixelwise descriptors describe which pixels are associated with particular object classes by matching the characteristics of object classes to the comparison between pixels at predetermined offsets. A pixel heat map is generated by giving each pixel the color assigned to the object class that the pixelwise descriptors indicate is most probably associated with that pixel.",G06K 9/00; G06K 9/46; G06K 9/62,DEFINIENS AG,PAULY OLIVIER; BRIEU NICOLAS; SCHMIDT GÜNTER; ZIMMERMANN JOHANNES; BINNIG GERD,201414473096 29.08.2014 US,
WO2000016243,PCT/IL1999/000487,08.09.1999,WO/2000/016243,23.03.2000,WO,METHOD OF FACE INDEXING FOR EFFICIENT BROWSING AND SEARCHING OFP EOPLE IN VIDEO,"A method and apparatus for generating an index (250) of at least one class of objects appearing in a collection of images (210, 230) for use in searching or browsing (240) for particular members of the class, by: processing (260) the collection of images to extract therefrom features characteristic of the class of objects; and grouping the images in groups according to extracted features helpful in identifying individual members of the class of objects. In the described preferred embodiments, the collection of images represents a sequence of video frames, identified by the starting and ending frames and containing face segments characteristic of a respective face. Audio characteristic data and/or annotations (270, 280) may also be associated with the face tracks.",G06F 17/30; G06K 9/00,"MATE - MEDIA ACCESS TECHNOLOGIES LTD.; WILF, Itzhak; GREENSPAN, Hayit; PIKAZ, Arie; MENADEVA, Ovadya; CASPI, Yaron","WILF, Itzhak; GREENSPAN, Hayit; PIKAZ, Arie; MENADEVA, Ovadya; CASPI, Yaron","60/099,702 10.09.1998 US",EP-1999943190; US-09786865
WO2004110030,PCT/US2004/015902,20.05.2004,WO/2004/110030,16.12.2004,WO,ASSISTIVE CALL CENTER INTERFACE,"Unstructured voice information from an incoming caller (12) is processed by automatic speech recognition (24) and semantic categorization system (44) to convert the information into structured data that may then be used to access one or more databases to retrieve associated supplemental data. The structured data and associated supplemental data are then made available through a presentation system that provides information to the center agent and, optionally, to the incoming caller. The system thus allows a call center information processing system to handle unstructured voice input for use by the live agent in handling the incoming call and for storage and retrieval at a later time. The semantic analysis system may be implemented by a global parser or by an information retrieval technique, such as latent semantic analysis. Co-occurrence of keywords may be used to associate prior calls with an incoming call to assist in understanding the purpose of the incoming call.",G10L 15/18,"MATSUSHITA ELECTRIC INDUSTRIAL CO., LTD.; APPLEBAUM, Ted; JUNQUA, Jean-Claude","APPLEBAUM, Ted; JUNQUA, Jean-Claude","10/454,716 04.06.2003 US",IN-5587/DELNP/2005
WO2019222383,PCT/US2019/032465,15.05.2019,WO/2019/222383,21.11.2019,WO,MULTI-PERSON POSE ESTIMATION USING SKELETON PREDICTION,"Embodiments provide functionality for identifying joints and limbs in images. An embodiment extracts features from an image to generate feature maps and, in turn, processes the feature maps using a single convolutional neural network trained based on a target model that includes joints and limbs. The processing generates both a directionless joint confidence map indicating confidence with which pixels in the image depict one or more joints and a directionless limb confidence map indicating confidence with which the pixels in the image depict one or more limbs between adjacent joints of the one or more joints, wherein adjacency of joints is provided by the target model. To continue, indications of the one or more joints and the one or more limbs in the image are generated using the directionless joint confidence map, the directionless limb confidence map, and the target model. Embodiments can be deployed on mobile and embedded systems.",G06K 9/00; G06K 9/46; G06K 9/62,NORTHEASTERN UNIVERSITY,"FU, Yun; WU, Yue","62/672,025 15.05.2018 US",
EP232545799,18162611,19.03.2018,3396623,31.10.2018,EP,REAL TIME CONTEXT DEPENDENT DEEP LEARNING,"In an example, an apparatus comprises a plurality of execution units comprising and logic, at least partially including hardware logic, to receive a plurality of data inputs for training a neural network, wherein the data inputs comprise training data and weights inputs; represent the data inputs in a first form; and represent the weight inputs in a second form. Other embodiments are also disclosed and claimed.",G06T 1/20,INTEL CORP,FAIVISHEVSKY LEV; BAR-ON TOMER; FAIS YANIV; SUBAG JACOB; DREYFUSS JEREMIE; BLEIWEISS AMIT; SCHWARTZ TOMER,201715494887 24.04.2017 US,
EP11965693,89104158,09.03.1989,0334113,27.09.1989,EP,EXPERT SYSTEM INFERENCE ENGINE,"An expert system includes a knowledge base manager which is fact-based, as opposed to rule-based; i.e., a semantic network with tangled hierarchies. The system includes an inference engine which is capable of providing solutions to indeterminate problems with a high degree of confidence. ""Entities"" (e.g., propositions, facts and ideas) are understood in eight different ways depending on the context of entity relationships. Each such relationship may be characterized anywhere along a spectrum from stong to weak. The knowledge base is designed so that entities and relationships are easily modified. The analysis performed may be at any of various levels of detail. The system can accept data as keyed input as well as from independently executed programs. Results developed by the inference engine are presented in various levels of detail in terms of relative degree of agreement of divergence from anticipated conclusions and the inference engine's degree of confidence in the results.",G06F 9/44; G06N 5/02; G06N 5/04,INTERNATIONAL BUSINESS MACHINES CORPORATION,"TYLER, IRWIN",17348988 25.03.1988 US,
WO2019154541,PCT/EP2018/083649,05.12.2018,WO/2019/154541,15.08.2019,WO,METHODS AND APPARATUSES FOR OBJECT DETECTION IN A SCENE REPRESENTED BY DEPTH DATA OF A RANGE DETECTION SENSOR AND IMAGE DATA OF A CAMERA,The present disclosure relates to a concept of object detection in a scene represented by depth data of a range detection sensor and image data of a camera. The depth data is projected onto the image data to generate projected depth data. The projected depth data is encoded to multi- channel information to generate encoded projected depth data. Hybrid data comprising the image data and the encoded projected depth is fed data into one or more convolutional neural networks configured to detect or classify objects in the scene based on the image data and the encoded projected depth data.,G06K 9/00; G06K 9/62,BAYERISCHE MOTOREN WERKE AKTIENGESELLSCHAFT,"BANERJEE, Koyel; NOTZ, Dominik; HE, Mingkang; GAVARRAJU, Sumanth",18155944.4 09.02.2018 EP,
EP234205439,18173804,23.05.2018,3407292,28.11.2018,EP,NEURAL NETWORK POINT CLOUD GENERATION SYSTEM,"A system includes one or more processors (204) and a memory (206) that stores a generative adversarial network (GAN) (210). The one or more processors (204) are configured to receive a low resolution point cloud (306) comprising a set of three-dimensional (3D) data points (410) that represents an object (110, 112). A generator (302) of the GAN (210) is configured to generate a first set of generated data points based at least in part on one or more characteristics of the data points (410) in the low resolution point cloud (306), and to interpolate the generated data points into the low resolution point cloud (306) to produce a super-resolved point cloud (310) that represents the object (110, 112) and has a greater resolution than the low resolution point cloud (306). The one or more processors are further configured to analyze the super-resolved point cloud (310) for detecting one or more of an identity of the object (110, 112) or damage to the object (110, 112).",G06T 3/40; G06T 7/00,GEN ELECTRIC,LIM SER NAM; ZHENG JINGJING; LUO JIAJIA; DIWINSKY DAVID SCOTT,201715604012 24.05.2017 US,
EP241675065,18202915,26.10.2018,3477633,01.05.2019,EP,SYSTEMS AND METHODS FOR ROBUST SPEECH RECOGNITION USING GENERATIVE ADVERSARIAL NETWORKS,"Described herein are systems and methods for a general, scalable, end-to-end framework that uses the generative adversarial network (GAN) objective to enable robust speech recognition. Encoders trained with the proposed approach enjoy improved invariance by learning to map noisy audio to the same embedding space as that of clean audio. Embodiments of a Wasserstein GAN framework increase the robustness of seq-to-seq models in a scalable, end-to-end fashion. An encoder component is treated as the generator of GAN and is trained to produce indistinguishable embeddings between labeled and unlabeled audio samples. This new robust training approach can learn to induce robustness without alignment or complicated inference pipeline and even where augmentation of audio data is not possible.",G10L 15/06; G10L 15/16; G10L 15/20,BAIDU USA LLC,SRIRAM ANUROOP; JUN HEE WOO; GAUR YASHESH; SATHEESH SANJEEV,201762578102 27.10.2017 US; 201816154648 08.10.2018 US,
WO2019005722,PCT/US2018/039391,26.06.2018,WO/2019/005722,03.01.2019,WO,"SYSTEM, METHOD, AND COMPUTER-ACCESSIBLE MEDIUM FOR VIRTUAL PANCREATOGRAPHY","A system, method, and computer-accessible medium for using medical imaging data to screen for a cystic lesion(s) can include, for example, receiving first imaging information for an organ(s) of a one patient(s), generating second imaging information by performing a segmentation operation on the first imaging information to identify a plurality of tissue types, including a tissue type(s) indicative of the cystic lesion(s), identifying the cystic lesion(s) in the second imaging information, and applying a first classifier and a second classifier to the cystic lesion(s) to classify the cystic lesion(s) into one or more of a plurality of cystic lesion types. The first classifier can be a Random Forest classifier and the second classifier can be a convolutional neural network classifier. The convolutional neural network can include at least 6 convolutional layers, where the at least 6 convolutional layers can include a max-pooling layer(s), a dropout layer(s), and fully-connected layer(s).",G06K 9/00,THE RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK,"KAUFMAN, Arie; DMITRIEV, Konstantin","62/524,819 26.06.2017 US",EP-2018824396
WO2009070676,PCT/US2008/084864,26.11.2008,WO/2009/070676,04.06.2009,WO,DETERMINING POSTURAL STABILITY,A method for determining postural stability of a person can include acquiring a plurality of pressure data points over a period of time from at least one pressure sensor. The method can also include the step of identifying a postural state for each pressure data point to generate a plurality of postural states. The method can include the step of determining a postural state of the person at a point in time based on at least the plurality of postural states.,A61B 5/103,"MASSACHUSETTS INSTITUTE OF TECHNOLOGY; PRESIDENT AND FELLOWS OF HARVARD COLLEGE; THE UNITED STATES OF AMERICA AS REPRESENTED BY THE ADMINISTRATOR OF THE NATIONAL AERONAUTICS AND SPACE ADMINISTRATION; LIEBERMAN, Erez; FORTH, Katharine, E.; PALOSKI, William, H.","LIEBERMAN, Erez; FORTH, Katharine, E.; PALOSKI, William, H.","60/990,817 28.11.2007 US",
WO2020025684,PCT/EP2019/070649,31.07.2019,WO/2020/025684,06.02.2020,WO,METHOD AND SYSTEM FOR AUGMENTED IMAGING IN OPEN TREATMENT USING MULTISPECTRAL INFORMATION,"Disclosed herein is a method of generating augmented images of tissue of a patient undergoing open treatment, in particular open surgery, wherein each augmented image associates at least one tissue parameter with a region or pixel of the image of the tissue, said method comprising the following steps: estimating a spectral composition of light illuminating a region of interest of the tissue, obtaining one or more multispectral images of the region of interest, applying a machine learning based regressor or classifier to the one or more multispectral images, or an image derived from said multispectral image, to thereby derive one or more tissue parameters associated with image regions or pixels of the corresponding multispectral image, wherein said regressor or classifier has been trained to predict the one or more tissue parameters from a multispectral image under a given spectral composition of illumination, wherein the regressor or classifier employed is made to match the estimated spectral composition of light illuminating said region of interest of the tissue.",A61B 5/00; A61B 5/1455; A61B 5/1495; G06T 7/00,DEUTSCHES KREBSFORSCHUNGSZENTRUM STIFTUNG DES ÖFFENTLICHEN RECHTS,"MAIER-HEIN, Lena; WIRKERT, Sebastian Josef; VEMURI, Anant Suraj; MENJIVAR, Leonardo Antonio Ayala; SEIDLITZ, Silvia; KIRCHNER, Thomas; ADLER, Tim",18186670.8 31.07.2018 EP,
WO2018218034,PCT/US2018/034411,24.05.2018,WO/2018/218034,29.11.2018,WO,SHEET MUSIC SEARCH AND DISCOVERY SYSTEM,"A sheet music search and discovery system is disclosed that uses specific mathematical rules to analyze and characterize sheet music and provides functionality for users to identify sheet music based on those characterizations. The system stores sheet music data and metadata characterizing each composition, provides a graphical user interface that provides functionality for users to search the sheet music data for compositions, and generates search results based at least in part on the metadata characterizing each composition. In one embodiment, metadata describing structured sheet music data is generated using a global vector space that includes semantic representations of elements extracted from a large corpus. In another embodiment, metadata describing unstructured sheet music data is generated using machine learning-based pattern recognition. In another embodiment, the interface provides functionality for users to identify instruments and a range for each of the instruments and identify compositions with similar instruments and ranges.",G06F 17/00,"J. W. PEPPER & SON, INC.","SAWRUK, Jeremy; DONNELLY, Bruce; HAMILTON, Michael","62/511,025 25.05.2017 US",CA-3062700
WO2017173100,PCT/US2017/025050,30.03.2017,WO/2017/173100,05.10.2017,WO,"APPLICATIONS, SYSTEMS AND METHODS TO MONITOR, FILTER AND/OR ALTER OUTPUT OF A COMPUTING DEVICE","A system for to monitor image input of a computing device having a control circuit with a programmable processor, and configured to receive images and to output the images to an image output device coupled to the computing device. The computing device can be configured to monitor the received images via the processor of the computing device being programmed using a Machine Learning Image Classification (MLIC) algorithm configured to determine a score of at least one received image within a predetermined criteria for classifying said at least one received image as a restricted subject image. Based on determination of the score, a modify or non-modify command is generated; and wherein in response to said at least one received image being scored by said processor within the modify criteria, the processor is programmed to generate a command to output the modified image.",H04N 21/454; G06F 17/00; G06F 21/00; G06T 1/40; H04N 21/45,"COVENANT EYES, INC.","HOLM, Michael; RIBIERO, Matt; HAMMERSLEY, Scott; DEHAAS, Ronald","62/315,348 30.03.2016 US",AU-2017240604; CA-3019567; EP-2017776663
WO2018053537,PCT/US2017/052335,19.09.2017,WO/2018/053537,22.03.2018,WO,IMPROVEMENTS OF SPEAKER RECOGNITION IN THE CALL CENTER,Utterances of at least two speakers in a speech signal may be distinguished and the associated speaker identified by use of dianzation together with automatic speech recognition of identifying words and phrases commonly in the speech signal. The diarization process clusters turns of the conversation while recognized special form phrases and entity names identify the speakers. A trained probabilistic model deduces which entity name(s) correspond to the clusters.,H04M 1/27; G10L 17/24; G10L 15/26,"PINDROP SECURITY, INC.","KHOURY, Elie; GARLAND, Matthew","62/396,670 19.09.2016 US; 15/709,290 19.09.2017 US",
WO2020068311,PCT/US2019/047480,21.08.2019,WO/2020/068311,02.04.2020,WO,POWER SAVINGS FOR NEURAL NETWORK ARCHITECTURE WITH ZERO ACTIVATIONS DURING INFERENCE,"Embodiments are generally directed to providing power savings for a neural network architecture with zero activations during inference. An embodiment of an apparatus includes one or more processors including one or more processor cores; and a memory to store data for processing including neural network processing, wherein the apparatus to perform a fast clear operation to initialize activation buffers for a neural network by updating metadata to indicate zero values, the neural network including a plurality of layers, wherein the apparatus is to compare outputs for the neural network to the metadata values and to write an output to memory only if the output is non-zero.",G06N 3/063; G06N 3/08; G06F 1/3206; G06F 1/3234; G06N 3/04,INTEL CORPORATION,"DESAI, Kinchit; JAHAGIRDAR, Sanjeev; SURTI, Prasoonkumar; RAY, Joydeep","16/144,538 27.09.2018 US",
WO2020073147,PCT/CN2018/109262,08.10.2018,WO/2020/073147,16.04.2020,WO,VEHICLE ENTRY DETECTION,"A method for event state detection includes receiving a plurality of sensor signals at a computing device (502), determining, at the computing device, probabilities of sub-event states based on the plurality of sensor signals using an artificial neural network for each of a plurality of time intervals (504), and detecting, at the computing device, the event state based on the probabilities of the sub-event states via a state sequence model (506).",G06K 9/62,"QUALCOMM INCORPORATED; LEE, Mingu; CHANG, Wonil; KIM, Yeon seok; HWANG, Kyu Woong; HUANG, Yin; WANG, Ruowei; ZHAO, Haijun; CHO, Janghoon","LEE, Mingu; CHANG, Wonil; KIM, Yeon seok; HWANG, Kyu Woong; HUANG, Yin; WANG, Ruowei; ZHAO, Haijun; CHO, Janghoon",,
EP238739214,16899905,05.05.2016,3451242,06.03.2019,EP,DEVICE AND METHOD FOR PERFORMING REVERSETRAINING OF FULLY CONNECTED LAYERS OF NEURAL NETWORK,"The present invention provides a device for performing a reverse training for fully connected layers of artificial neural network, comprising an instruction storage unit (1), a controller unit (2), a data access unit (3), an interconnection module (4), a master operation module (5) and a plurality of slave operation modules (6). The device can implement a reverse training of fully connected layers of artificial neural network. For each layer, an output gradient vector of the layer is first calculated by weighted summation of the input gradient vector. The output gradient vector is multiplied by the derivative value of the activation function of the next layer in the forward propagation process to obtain an input gradient vector of the next layer. The input gradient vector is multiplied by the input neuron upon forward propagation process to obtain a gradient of the weight for this layer, and then the weight of this layer can be updated according to the obtained gradient of the weight for this layer.",G06N 3/08; G06N 3/04; G06N 3/063; G06N 5/00,CAMBRICON TECH CORPORATION LIMITED,GUO QI; ZHANG SHIJIN; CHEN YUNJI; CHEN TIANSHI,2016081114 05.05.2016 CN; 201610285062 29.04.2016 CN,
WO2018203470,PCT/JP2018/015636,16.04.2018,WO/2018/203470,08.11.2018,WO,"LEARNING APPARATUS, LEARNING METHOD, AND LEARNING PROGRAM","A learning apparatus according to an aspect of the present invention includes: a learning data acquisition unit configured to acquire a first learning data group for enabling a learning device to learn a predetermined ability through machine learning, the first learning data group including a plurality of pieces of learning data; a learning processing unit configured to construct a first learning device that has learned the predetermined ability, by carrying out machine learning of the learning device using the first learning data group; and an evaluation unit configured to evaluate quantity of insufficient learning data in machine learning of the first learning device, based on a result of the first learning device carrying out processing using the predetermined ability with respect to sample data.",G06N 99/00; G06N 3/04,OMRON CORPORATION,"ANDO, Tanichi",2017-091295 01.05.2017 JP,
WO2019079530,PCT/US2018/056407,18.10.2018,WO/2019/079530,25.04.2019,WO,CONTROLLING AN AUTONOMOUS VEHICLE BASED ON INDEPENDENT DRIVING DECISIONS,"A computer-readable medium stores instructions executable by one or more processors to implement an aggregate self-driving control architecture (SDCA) for controlling an autonomous vehicle. The aggregate SDCA includes a plurality of SDCAs each including a different motion planner. Each motion planner is configured to receive signals descriptive of a current state of an environment through which the autonomous vehicle is moving, and each SDCA is configured to generate candidate decisions for controlling the autonomous vehicle by using the respective motion planner to process the received signals. The aggregate SDCA also includes a decision arbiter configured to receive the candidate decisions generated by the SDCAs, generate decisions for controlling the autonomous vehicle by processing the candidate decisions, and provide signals indicative of the generated decisions to one or more operational subsystems of the vehicle to effectuate maneuvering of the vehicle.",G05D 1/02,"LUMINAR TECHNOLOGIES, INC.","ENGLARD, Benjamin; MAHESHWARI, Pranav; AUGENBRAUN, Joseph; GANDHI, Gauri; KHILARI, Shubham C.; RAMEZANI, Vahid R.","62/573,795 18.10.2017 US; 16/149,219 02.10.2018 US; 16/149,221 02.10.2018 US; 16/149,223 02.10.2018 US; 16/149,225 02.10.2018 US",
WO2007036843,PCT/IB2006/053386,20.09.2006,WO/2007/036843,05.04.2007,WO,METHOD AND APPARATUS FOR RETRIEVING A TEXT ASSOCIATION WITH AN OBJECT OR SUBJECT,"Text data associated with an object or subject appearing in an image is retrieved. The text and recognition data of said object or subject are generated and stored such that, during subsequent appearances of the targeted object or subject, the targeted object or subject can be recognised, the stored text associated with the recognised object or subject is retrieved and can be displayed with subsequent appearances of the object or subject.",G06F 17/30; G06K 9/00,"KONINKLIJKE PHILIPS ELECTRONICS N.V.; HOLLEMANS, Gerrit; NESVADBA, Jan, A., D.","HOLLEMANS, Gerrit; NESVADBA, Jan, A., D.",05109108.0 30.09.2005 EP,EP-6821120; EP-06821120
WO1988010474,PCT/US1988/002110,17.06.1988,WO/1988/010474,29.12.1988,WO,STATE ANALOG NEURAL NETWORK AND METHOD OF IMPLEMENTING SAME,"A neural network is implemented by discrete-time, continuous voltage state analog devices in which neuron signals (9), synapse signals (7) and synaptic strength signals (15) are generated in highly parallel analog circuits in successive states from stored values of the interdependent signals calculated in a previous state. The neuron and synapse signals are refined in a relaxation loop (9), (5), (7) while the synaptic strength signals are held constant. In learning modes, the synaptic strength signals are modified in successive states from stable values of the analog neuron signals. The analog signals are stored for as long as required in master/slave sample and hold circuits (69) as digitized signals which are periodically refreshed to maintain the stored voltage within a voltage window bracketing the original analog signal.",G06J 1/00; G06N 3/04; G06N 3/063,UNIVERSITY OF WEST VIRGINIA,"BROWN, Paul, B.","064,097 18.06.1987 US",
WO1997046929,PCT/US1997/009724,04.06.1997,WO/1997/046929,11.12.1997,WO,3-BRAIN ARCHITECTURE FOR AN INTELLIGENT DECISION AND CONTROL SYSTEM,"A method and system (100) for intelligent control of external devices using a mammalian brain-like structure having three parts. The method and system include a computer storage medium (19) for storing a computer program code which causes the computer (102) to implement a neural  network system which is an extension of the model-based adaptive critic design and is applicable to real-time control (e.g., robotic control) and real-time distributed control. Additional uses include data visualization, data mining, and other tasks requiring complex analysis of inter-relationships between data.",G05B 13/02; G06N 3/10,"WERBOS, Paul, J.","WERBOS, Paul, J.","60/019,154 04.06.1996 US",US-09147338
WO2019175532,PCT/GB2019/050513,25.02.2019,WO/2019/175532,19.09.2019,WO,URBAN ENVIRONMENT LABELLING,"The present invention relates to a method and system for automatic localisation of static objects in an urban environment. More particularly, the present invention relates to the use of noisy 2-Dimensional (2D) image data to identify and determine 3-Dimensional (3D) positions of objects in large scale urban or city environments. Aspects and/or embodiments seek to provide a method, system, and vehicle for automatically locating static 3D objects in urban environments by using a voting-based triangulation technique. Aspects and/or embodiments also provide a method for updating map data after automatically new 3D static objects in an environment.",G06K 9/00,BLUE VISION LABS UK LIMITED,"ONDRUSKA, Peter; PLATINSKY, Lukas; DABISIAS, Giacomo",1804194.7 15.03.2018 GB; 1813101.1 10.08.2018 GB,
WO2015004502,PCT/IB2013/055640,09.07.2013,WO/2015/004502,15.01.2015,WO,METHOD FOR IMPUTING CORRUPTED DATA BASED ON LOCALIZING ANOMALOUS PARTS,"The method in this invention is a novel, anomaly detection based imputation technique designed for handling the local corruptions in a given data set. For a given data instance, the method first localizes the corruption through several statistical checks via an appropriate anomaly detection algorithm from the machine learning literature. Then the corrupted attributes, which might be considered as ""missing"" after the corruption is localized, are imputed using the average statistics extracted from the data set. In the machine learning applications such as data classification and clustering, data imputation is an important technique to improve the performance of the algorithms, i.e., empirical error rates in case of a binary classification, when a fraction of the data is corrupted under severe noise conditions. For instance, this corruption might be due to a scratch on the compact disc where the data are stored, or occlusion of a visual object in computer vision tasks. In this regard, data imputation techniques and our invention aim at replacing the corrupted or missing parts with statistically meaningful substituted values such that the corrupted parts after imputations becomes statistically consistent with the intact parts.",G06N 7/00; G06N 99/00,ASELSAN ELEKTRONIK SANAYI VE TICARET ANONIM SIRKETI,"OZKAN, Huseyin; YILMAZ, Ozgur",,UA-a201600281; PH-12016500066; KZ-2016/0044.1
WO2018211142,PCT/EP2018/063291,22.05.2018,WO/2018/211142,22.11.2018,WO,IMAGINATION-BASED AGENT NEURAL NETWORKS,"A neural network system is proposed to select actions to be performed by an agent interacting with an environment to perform a task in an attempt to achieve a specified result. The system may include a controller to receive state data and context data, and to output action data. The system may also include an imagination module to receive the state and action data, and to output consequent state data. The system may also include a manager to receive the state data and the context data, and to output route data which defines whether the system is to execute an action or to imagine. The system may also include a memory to store the context data.",G06N 3/04; G06N 3/08; G06N 3/00,DEEPMIND TECHNOLOGIES LIMITED,"WIERSTRA, Daniel Pieter; LI, Yujia; PASCANU, Razvan; BATTAGLIA, Peter William; WEBER, Theophane Guillaume; BUESING, Lars; REICHERT, David Paul; VINYALS, Oriol; HEESS, Nicolas Manfred Otto; RACANIERE, Sebastien Henri","62/509,040 19.05.2017 US",EP-2018726782; CN-201880013648.9
WO2017198909,PCT/FI2017/050379,19.05.2017,WO/2017/198909,23.11.2017,WO,SEGMENTATION OF DATA,"The present invention relates to a computer-implemented method for segmenting input data. In the method a plurality of tags is generated (110); the input data is masked with the plurality of tags (120); a plurality of output reconstructions (130) is generated by inputting the plurality of masked input data to one of the following: a denoising neural network, a variational autoencoder; a plurality of values representing distances of each plurality of output reconstructions to the input data are determined (140); a plurality of updated versions of input data is generated (150) by applying at least one of the determined values representing distances of each plurality of output reconstructions to the input data; and updated output reconstructions (160) are generated by inputting the plurality of updated versions of input data to one of the networks. The invention also relates to a method for training the network and a processing unit.",G06N 3/02,CURIOUS AI OY,"VALPOLA, Harri; GREFF, Klaus",20160136 20.05.2016 FI,
WO2019040783,PCT/US2018/047808,23.08.2018,WO/2019/040783,28.02.2019,WO,SYSTEM AND METHOD FOR CENTIMETER PRECISION LOCALIZATION USING CAMERA-BASED SUBMAP AND LIDAR-BASED GLOBAL MAP,"A method of localization for a non-transitory computer readable storage medium storing one or more programs is disclosed. The one or more programs comprise instructions, which when executed by a computing device, cause the computing device to perform by one or more autonomous vehicle driving modules execution of processing of images from a camera and data from a LiDAR using the following steps comprising: constructing a 3D submap and a global map; extracting features from the 3D submap and the global map; matching features extracted from the 3D submap against features extracted from the global map; refining feature correspondence; and refining location of the 3D submap.",G05D 1/02; G01S 17/89; G01S 17/02,TUSIMPLE,"LUO, Yi; WANG, Yi; XU, Ke","15/684,339 23.08.2017 US",
WO2020016864,PCT/IB2019/057330,30.08.2019,WO/2020/016864,23.01.2020,WO,VISUALIZATION OF SURGICAL DEVICES,"A surgical visualization system is disclosed. The surgical visualization system is configured to identify one or more structure(s) and/or determine one or more distances with respect to obscuring tissue and/or the identified structure(s). The surgical visualization system can facilitate avoidance of the identified structure(s) by a surgical device. The surgical visualization system can comprise a first emitter configured to emit a plurality of tissue-penetrating light waves and a second emitter configured to emit structured light onto the surface of tissue. The surgical visualization system can also include an image sensor configured to detect reflected visible light, tissue-penetrating light, and/or structured light. The surgical visualization system can convey information to one or more clinicians regarding the position of one or more hidden identified structures and/or provide one or more proximity indicators.",A61B 5/00; A61B 5/107; A61B 90/00; A61B 34/30; A61B 90/30; G01B 11/25; G01N 21/25; G01N 21/31; G01S 17/89,ETHICON LLC,"SCHEIB, Charles J.; RITCHIE, Paul G.; MOORE, Sarah A.; SWAYZE, Jeffrey S.; TALBERT, Joshua D.; YOUNG, Joshua D.; MORENO, Victor C.","62/698,625 16.07.2018 US; 16/128,176 11.09.2018 US; 16/128,187 11.09.2018 US; 16/128,192 11.09.2018 US",
WO2015148189,PCT/US2015/021077,17.03.2015,WO/2015/148189,01.10.2015,WO,DIFFERENTIAL ENCODING IN NEURAL NETWORKS,Differential encoding in a neural network includes predicting an activation value for a neuron in the neural network based on at least one previous activation value for the neuron. The encoding further includes encoding a value based on a difference between the predicted activation value and an actual activation value for the neuron in the neural network.,G06N 3/04,QUALCOMM INCORPORATED,"ANNAPUREDDY, Venkata Sreekanta Reddy; JULIAN, David Jonathan; TOWAL, Regan Blythe; LIU, Yinyin","61/969,747 24.03.2014 US; 14/513,155 13.10.2014 US",KR-1020167029200; EP-2015716612; JP-2016558315
WO2020025696,PCT/EP2019/070669,31.07.2019,WO/2020/025696,06.02.2020,WO,METHOD AND SYSTEM FOR AUGMENTED IMAGING USING MULTISPECTRAL INFORMATION,"Disclosed herein is a method of generating augmented images of tissue of a patient, wherein each augmented image associates at least one tissue parameter with a region or pixel of the image of the tissue, said method comprising the following steps: obtaining one or more multispectral images of said tissue, and applying a machine learning based regressor or classifier, or an out of distribution (OoD) detection algorithm for determining information about the closeness of the multispectral image or parts of said multispectral image to a given training data set, or a change detection algorithm to at least a part of said one or more multispectral images, or an image derived from said multispectral image, or to a time sequence of multispectral images, parts of multiple images or images derived therefrom, to thereby derive one or more tissue parameters associated with image regions or pixels of the corresponding multispectral image.",G06T 7/00; G06T 7/254,DEUTSCHES KREBSFORSCHUNGSZENTRUM STIFTUNG DES ÖFFENTLICHEN RECHTS,"MAIER-HEIN, Lena; WIRKERT, Sebastian Josef; VEMURI, Anant Suraj; MENJIVAR, Leonardo Antonio Ayala; SEIDLITZ, Silvia; KIRCHNER, Thomas; ADLER, Tim",18186700.3 31.07.2018 EP,
WO2019207421,PCT/IB2019/053173,17.04.2019,WO/2019/207421,31.10.2019,WO,NAVIGATION AND COGNITIVE DIALOG ASSISTANCE,"A system, computer program product, and method are provided to apply artificial intelligence and natural language processing to a route navigation module. An artificial intelligence platform transforms the functionality of the navigation module in real-time. As natural language input is received, a parser is leveraged to parse the input into grammatical sub-components. An analyzer is involved to analyze and identify an associated category for the parsed sub-component(s). A sensor is provided operatively couple to the navigation module. The parsed and analyzed data are applied to an operating state of the sensor. The artificial intelligence platform dynamically translates the identified category of the received input to a natural language instruction congruent with the parsed grammatical sub-components.",G06F 17/28,INTERNATIONAL BUSINESS MACHINES CORPORATION; IBM UNITED KINGDOM LIMITED; IBM (CHINA) INVESTMENT COMPANY LIMITED,"KOCHURA, Nadiya; LU, Fang","15/959,625 23.04.2018 US",
WO2019100065,PCT/US2018/062057,20.11.2018,WO/2019/100065,23.05.2019,WO,IMAGE SEGMENTATION USING NEURAL NETWORKS,"A method for generating a segmentation of an image that assigns each pixel to a respective segmentation category from a set of segmentation categories is described. The method includes obtaining features of the image, the image including a plurality of pixels. For each of one or more time steps starting from an initial time step and continuing until a final time step, the method includes generating a network input from the features of the image and a current segmentation output as of the time step, processing the network input using a convolutional recurrent neural network to generate an intermediate segmentation output for the time step, and generating an updated segmentation output for the time step from the intermediate segmentation output for the time step and the current segmentation output as of the time step. The method includes generating a final segmentation of the image from the updated segmentation output.",G06N 3/04; G06T 7/11; G06N 3/08,GOOGLE LLC,"SHLENS, Jonathon; MAHESWARANATHAN, Niruban; SUSSILLO, David","62/588,883 20.11.2017 US",
WO2019161300,PCT/US2019/018348,15.02.2019,WO/2019/161300,22.08.2019,WO,DETECTING OBJECTS AND DETERMINING CONFIDENCE SCORES,"In various examples, detected object data representative of locations of detected objects in a field of view may be determined. One or more clusters of the detected objects may be generated based at least in part on the locations and features of the cluster may be determined for use as inputs to a machine learning model(s). A confidence score, computed by the machine learning model(s) based at least in part on the inputs, may be received, where the confidence score may be representative of a probability that the cluster corresponds to an object depicted at least partially in the field of view. Further examples provide approaches for determining ground truth data for training object detectors, such as for determining coverage values for ground truth objects using associated shapes, and for determining soft coverage values for ground truth objects.",G06K 9/00; G06N 3/04; G06K 9/32; G06K 9/46; G06K 9/48; G06K 9/62,NVIDIA CORPORATION,"KOIVISTO, Tommi; JANIS, Pekka; KUOSMANEN, Tero; ROMAN, Timo; SARATHY, Sriya; ZHANG, William; ASSAF, Nizar; TRACEY, Colin","62/631,781 18.02.2018 US; 16/277,895 15.02.2019 US",DE-112019000049
WO2010008520,PCT/US2009/004061,14.07.2009,WO/2010/008520,21.01.2010,WO,METHOD AND SYSTEM FOR AUTOMATED ANNOTATION OF PERSONS IN VIDEO CONTENT,"Methods and systems for automated annotation of persons in video content are disclosed. In one embodiment, a method of identifying faces in a video includes the stages of: generating face tracks from input video streams; selecting key face images for each face track; clustering the face tracks to generate face clusters; creating face models from the face clusters; and correlating face models with a face model database. In another embodiment, a system for identifying faces in a video includes a face model database having face entries with face models and corresponding names, and a video face identifier module. In yet another embodiment, the system for identifying faces in a video can also have a face model generator.",G06K 9/00,"GOOGLE INC.; YAGNIK, Jay; ZHAO, Ming","YAGNIK, Jay; ZHAO, Ming","12/172,939 14.07.2008 US",KR-1020117003427; EP-2009788910; CN-200980135721.0
WO2015074157,PCT/CA2014/051117,24.11.2014,WO/2015/074157,28.05.2015,WO,SYSTEM AND METHOD FOR FACE RECOGNITION,"A system and method for generating a descriptor for a face is provided. The descriptor is operable to generate information about a given region in a face image to enable face recognition. The descriptor provided herein is a low dimension relative to many existing descriptors providing similar face recognition accuracy. In another aspect, a system and method for face recognition is provided.",G06K 9/80; G06K 9/36; G06K 9/68,"FAZL ERSI, Ehsan; TSOTSOS, John Konstantine","FAZL ERSI, Ehsan; TSOTSOS, John Konstantine","61/908,212 25.11.2013 US",EP-2014864771; US-15038812; CA-2931348
WO2019236281,PCT/US2019/033326,21.05.2019,WO/2019/236281,12.12.2019,WO,METHOD AND SYSTEM FOR DETECTING CHANGE OF CONTEXT IN VIDEO STREAMS,"Described is a system for detecting change of context in a video stream on an autonomous platform. The system extracts salient patches from image frames in the video stream. Each salient patch is translated to a concept vector. A recurrent neural network is enervated with the concept vector, resulting in activations of the recurrent neural network. The activations are classified, and the classified activations are mapped onto context classes. A change in context class is detected in the image frames, and the system causes the autonomous platform to perform an automatic operation to adapt to the change of context class.",H04N 5/14; G06N 3/08,"HRL LABORATORIES, LLC","MARTIN, Charles E.; STEPP, Nigel D.; KOLOURI, Sohell; HOFFMANN, Heiko","62/680,966 05.06.2018 US; 16/415,942 17.05.2019 US",
WO2017123553,PCT/US2017/012875,10.01.2017,WO/2017/123553,20.07.2017,WO,ACCELERATING SEMICONDUCTOR-RELATED COMPUTATIONS USING LEARNING BASED MODELS,Methods and systems for performing one or more functions for a specimen using output simulated for the specimen are provided. One system includes one or more computer subsystems configured for acquiring output generated for a specimen by one or more detectors included in a tool configured to perform a process on the specimen. The system also includes one or more components executed by the one or more computer subsystems. The one or more components include a learning based model configured for performing one or more first functions using the acquired output as input to thereby generate simulated output for the specimen. The one or more computer subsystems are also configured for performing one or more second functions for the specimen using the simulated output.,G06N 3/08; G06N 3/04; G06N 99/00,KLA-TENCOR CORPORATION,"BHASKAR, Kris; YOUNG, Scott A.; ROULO, Mark; ZHANG, Jing; KARSENTI, Laurent; MAHADEVAN, Mohan; BRAUER, Bjorn","62/277,227 11.01.2016 US; 15/402,169 09.01.2017 US",KR-1020187022848; IL-260104
WO2018058307,PCT/CN2016/100361,27.09.2016,WO/2018/058307,05.04.2018,WO,SYSTEMS AND METHODS FOR INITIALIZATION OF TARGET OBJECT IN A TRACKING SYSTEM,"The disclosed embodiments include methods, apparatuses, systems, and UAVs configured to an interactive and automatic initialization of the tracking systems. The disclosed embodiments observe an object of interest in a surrounding of the movable object and detect a feature of the object of interest, which acts as a trigger for automatically initializing the tracking system. As a result, the disclosed embodiments may provide efficiency and reliability to initializing a robotic system.",G05D 1/12,"SZ DJI TECHNOLOGY CO., LTD.","FENG, Xuyang; ZHAO, Cong; YANG, Zhe",,US-16061896
WO2020014903,PCT/CN2018/096171,18.07.2018,WO/2020/014903,23.01.2020,WO,COMPLEXITY-BASED PROGRESSIVE TRAINING FOR MACHINE VISION MODELS,"Methods and systems for training machine vision models (MVMs) with ""noisy"" training datasets are described. A noisy set of images is received, where labels for some of the images are ""noisy"" and/or incorrect. A progressively-sequenced learning curriculum is designed for the noisy dataset, where the images that are easiest to learn machine-vision knowledge from are sequenced near the beginning of the curriculum and images that are harder to learn machine-vision knowledge from are sequenced later in the curriculum. An MVM is trained via providing the sequenced curriculum to a supervised learning method, so that the MVM learns from the easiest examples first and the harder training examples later, i. e., the MVM progressively accumulates knowledge from simplest to most complex. To sequence the curriculum, the training images are embedded in a feature space and the ""complexity"" of each image is determined via density distributions and clusters in the feature space.",G06F 16/55; G06F 16/906; G06K 9/62,"SHENZHEN MALONG TECHNOLOGIES CO., LTD.","GUO, Sheng; HUANG, Weilin; ZHANG, Haozhi; ZHUANG, Chenfan; DONG, Dengke; SCOTT, Matthew R.; HUANG, Dinglong",,
WO2017148536,PCT/EP2016/054694,04.03.2016,WO/2017/148536,08.09.2017,WO,"ELECTRONIC DEVICES, ARTIFICIAL EVOLUTIONARY NEURAL NETWORKS, METHODS AND COMPUTER PROGRAMS FOR IMPLEMENTING EVOLUTIONARY SEARCH AND OPTIMISATION",An electronic device comprising a processor configured to implement an evolutionary neural network that is formed of attractor networks,G06N 3/04; G06N 3/12,"VON MÜLLER, Albrecht; SZATHMÁRY, Eörs","SZATHMÁRY, Eörs; SZILÁGYI, András; ZACHAR, István; FEDOR, Anna; DE VLADAR, Harold P.",,
WO2010041034,PCT/GB2009/002425,09.10.2009,WO/2010/041034,15.04.2010,WO,"VISUAL TRACKING OF OBJECTS IN IMAGES, AND SEGMENTATION OF IMAGES","A method is discussed of tracking objects in a series of n-D images (102) that have objects (106, 108) appearing in a background (110, 112), that method comprises using a probabilistic model of the appearance of the objects and of the appearance of the background in the images, and using an evaluation of whether particular pixels in the images (102) are a part of an object (106, 108) or a part of the background (110, 112), that evaluation comprising determining the posterior model probabilities that a particular pixel (x) or group of pixels belongs to an object or to the background, and further comprising marginalising over these object/background membership probabilities to yield a function of the pose parameters of the objects, where at least the object/background membership is adjudged to be a nuisance parameter and marginalised out.",G06T 7/00,"ISIS INNOVATION LIMITED; BIBBY, Charles, Colin; REID, Ian, David","BIBBY, Charles, Colin; REID, Ian, David",0818561.3 09.10.2008 GB,CN-200980146343.6; EP-2009752439; US-13123485
WO2020051816,PCT/CN2018/105380,13.09.2018,WO/2020/051816,19.03.2020,WO,CONDENSE-EXPANSION-DEPTH-WISE CONVOLUTIONAL NEURAL NETWORK FOR FACE RECOGNITION,"Techniques related to implementing convolutional neural networks for face or other object recognition are discussed. Such techniques may include applying, in turn, a depth-wise separable convolution, a condense point-wise convolution, and an expansion point-wise convolution to input feature maps to generate output feature maps such that the output from the expansion point-wise convolution has more channels than the output from the condense point-wise convolution.",G06T 7/00; G06N 3/04,"INTEL CORPORATION; CHEN, Yurong; LI, Jianguo","CHEN, Yurong; LI, Jianguo",,
WO2018158601,PCT/IB2017/000187,01.03.2017,WO/2018/158601,07.09.2018,WO,"MONITORING DEVICES, MONITORED CONTROL SYSTEMS AND METHODS FOR PROGRAMMING SUCH DEVICES AND SYSTEMS","Monitored control system comprising an action device (2) and a monitoring device (3) for monitoring the operation of the action device (2). The action device (2) comprises actuator modules (4), a sensor module (5) and a control module (6) to command the actuator modules (4) to perform a predefined task using the sensor data. The monitoring device (3) receive monitored data from the action device (2) and compute an action device operation indicator indicative of a correct or abnormal operation of the action device (2) on the basis of said monitored data. The action device operation indicator is computed on the basis of a learned value of an adjustable monitoring parameter. The learned value is determined from a set of labelled data generated from trial datasets recorded by the action device (2) during an iterative learning procedure.",B25J 9/16; G06N 99/00; G05B 19/418,OMRON CORPORATION,"ANDO, Tanichi",,CN-201780082093.9; EP-2017711745
WO2017049350,PCT/AU2016/050884,22.09.2016,WO/2017/049350,30.03.2017,WO,"METHODS FOR THE AUTOMATED GENERATION OF SPEECH SAMPLE ASSET PRODUCTION SCORES FOR USERS OF A DISTRIBUTED LANGUAGE LEARNING SYSTEM, AUTOMATED ACCENT RECOGNITION AND QUANTIFICATION AND IMPROVED SPEECH RECOGNITION","Methods for automated generation of speech sample asset production scores for users of a distributed language learning system, automated accent recognition and quantification and improved speech recognition. Utilising a trained supervised machine learning module which is trained utilising a training set comprising a plurality of production speech sample asset recordings, associated production scores generated by system users performing perception exercises and user background information. The trained supervised machine learning module may be configured for automated accent recognition, by feeding a candidate production speech sample asset so as to automate the generation of a speech sample asset production score and user background information. As such, the user background information may be translated into an accent type categorisation and the speech sample asset production score may be translated into an accent strength. In further embodiments, the accent type categorisation generated using the trained system may be utilised for improved speech recognition.",G09B 19/06; G09B 5/04; G06F 15/18; G06F 17/28,VENDOME CONSULTING PTY LTD,"CASSAGNE, Gregory; SCHAPOTSCHNIKOW, Philipp",2015903856 22.09.2015 AU,US-15762062; EP-2016847648; AU-2016327448
WO2019040214,PCT/US2018/043134,20.07.2018,WO/2019/040214,28.02.2019,WO,SYSTEM AND METHOD FOR DISTRIBUTIVE TRAINING AND WEIGHT DISTRIBUTION IN A NEURAL NETWORK,"A system for distributive training and weight distribution in a neural network. The system includes a training facility having a training neural network that detects and classifies objects in training images so as to train weights of nodes in the training neural network, and a plurality of object detection and classification units each including an image source that provides image frames, and at least one classification and prediction neural network that identifies, classifies and indicates relative velocity of objects in the image frames. Each unit transmits its image frames to the training facility so that the training neural network further trains the weights of the nodes in the training neural network, and the trained neural network weights are transmitted from the training facility to each of the object detection and classification units so as to train weights of nodes in the at least one classification and prediction neural network.",G06N 3/04; G06N 3/08; G06K 9/00,NORTHROP GRUMMAN SYSTEMS CORPORATION,"WANG, Victor, Y.; CALCOTE, Kevin, A.","15/683,534 22.08.2017 US",
WO2018184208,PCT/CN2017/079726,07.04.2017,WO/2018/184208,11.10.2018,WO,METHODS AND APPARATUS FOR DEEP LEARNING NETWORK EXECUTION PIPELINE ON MULTI-PROCESSOR PLATFORM,"Methods and systems are disclosed using an execution pipeline on a multi-processor platform for deep learning network execution. In one example, a network workload analyzer receives a workload, analyzes a computation distribution of the workload, and groups the network nodes into groups. A network executor assigns each group to a processing core of the multi-core platform so that the respective processing core handle computation tasks of the received workload for the respective group.",G06F 15/76,"INTEL CORPORATION; YANG, Liu; YAO, Anbang","YANG, Liu; YAO, Anbang",,CN-201780088118.6; EP-2017904717
EP245433799,18213051,17.12.2018,3502963,26.06.2019,EP,METHOD AND APPARATUS FOR PROVIDING UNKNOWN MOVING OBJECT DETECTION,,G06K 9/00; G06K 9/32; G06K 9/46,HERE GLOBAL BV,FOWE JAMES,201715847469 19.12.2017 US,
WO2016132371,PCT/IL2016/050202,22.02.2016,WO/2016/132371,25.08.2016,WO,GESTURE RECOGNITION USING MULTI-SENSORY DATA,"A system comprising: a camera configured to capture one or more images of a user's hand; and a computer configured to: receive the one or more captured images, apply a mapping function to the received one or more images, thereby yielding one or more coordinates associated with at least one feature of the user's hand, wherein the mapping function is derived from a set of labeled images that are produced by applying a machine learning algorithm to training data which comprises images of a trainer's hand, wherein the images are labeled with coordinates obtained from multiple magnetic sensors attached to the trainer's hand.",G06F 17/00; G06F 3/00; G06F 3/01; G06T 7/00; G06K 9/62; G06K 9/78,TECHNION RESEARCH & DEVELOPMENT FOUNDATION LIMITED,"WETZLER, Aaron; KIMMEL, Ron","62/119,226 22.02.2015 US",US-15543092
WO2019103836,PCT/US2018/059304,06.11.2018,WO/2019/103836,31.05.2019,WO,SENSOR DATA SEGMENTATION,"A system may include one or more processors configured to receive a plurality of images representing an environment. The images may include image data generated by an image capture device. The processors may also be configured to transmit the image data to an image segmentation network configured to segment the images. The processors may also be configured to receive sensor data associated with the environment including sensor data generated by a sensor of a type different than an image capture device. The processors may be configured to associate the sensor data with segmented images to create a training dataset. The processors may be configured to transmit the training dataset to a machine learning network configured to run a sensor data segmentation model, and train the sensor data segmentation model using the training dataset, such that the sensor data segmentation model is configured to segment sensor data.",G06K 9/00,"ZOOX, INC.","PFEIFFER, David","15/820,245 21.11.2017 US",
WO2013169805,PCT/US2013/039985,07.05.2013,WO/2013/169805,14.11.2013,WO,SPIKING NEURAL NETWORK FEEDBACK APPARATUS AND METHODS,"Apparatus and methods for feedback in a spiking neural network. In one approach, spiking neurons receive sensory stimulus and context signal that correspond to the same context. When the stimulus provides sufficient excitation, neurons generate response. Context connections are adjusted according to inverse spike-timing dependent plasticity. When the context signal precedes the post synaptic spike, context synaptic connections are depressed. Conversely, whenever the context signal follows the post synaptic spike, the connections are potentiated. The inverse STDP connection adjustment ensures precise control of feedback- induced firing, eliminates runaway positive feedback loops, enables self-stabilizing network operation. In another aspect of the invention, the connection adjustment methodology facilitates robust context switching when processing visual information. When a context (such an object) becomes intermittently absent, prior context connection potentiation enables firing for a period of time. If the object remains absent, the connection becomes depressed thereby preventing further firing.",G06N 3/04,BRAIN CORPORATION,"PIEKNIEWSKI, Filip; IZHIKEVICH, Eugene; SZATMARY, Botond; PETRE, Csaba","13/465,924 07.05.2012 US",
EP96036595,12004348,08.06.2012,2672396,11.12.2013,EP,Method for annotating images,"A method for annotating a set of images by automatically identifying and visually marking objects (2) in the images (1) comprises performing for at least a subset of the set of images the following steps 
—� for each image, generating (81) one or more object hypotheses defining a region within the image associated with an object class; 
—� for each image, computing (82) an estimated annotation cost as a measure of the effort for correcting the object hypotheses in the image (1); 
—� selecting (83) one of the images of the subset on the basis of the annotation cost; 
—� displaying (84) the selected image, including a visual representation (3) of a subset of the object hypotheses of the selected image, on a graphical user interface (95); 
—� in an annotation step (85), a user correcting false (positive or negative) hypotheses.",G06F 17/30; G06K 9/00,ETH ZUERICH,LEISTNER CHRISTIAN; GALL JUERGEN; YAO ANGELA; VAN GOOL LUC,12004348 08.06.2012 EP,
WO2007032819,PCT/US2006/028620,21.07.2006,WO/2007/032819,22.03.2007,WO,CAMERA PLACEMENT AND VIRTUAL-SCENE CONSTRUCTION,"Multiple cameras are placed at a site to optimize observability of motion paths or other tasks relating to the site, according to a quality-of-view metric. Constraints such as obstacles may be accommodated. Image sequences from multiple cameras may be combined to produce a virtual sequence taken from a desired location relative to a motion path.",G06T 7/00,"REGENTS OF THE UNIVERSITY OF MINNESOTA; PAPANIKOLOPOULOS, Nikolaos; BODOR, Robert","PAPANIKOLOPOULOS, Nikolaos; BODOR, Robert","60/701,465 21.07.2005 US",DE-null
WO2013182298,PCT/EP2013/001640,05.06.2013,WO/2013/182298,12.12.2013,WO,METHOD FOR ANNOTATING IMAGES,"A method for annotating a set of images by automatically identifying and visually marking objects (2) in the images (1) comprises performing for at least a subset of the set of images the following steps • for each image, generating (81) one or more object hypotheses defining a region within the image associated with an object class; • for each image, computing (82) an estimated annotation cost as a measure of the effort for correcting the object hypotheses in the image (1); • selecting (83) one of the images of the subset on the basis of the annotation cost; • displaying (84) the selected image, including a visual representation (3) of a subset of the object hypotheses of the selected image, on a graphical user interface (95); • in an annotation step (85), a user correcting false (positive or negative) hypotheses.",G06F 17/30; G06K 9/00,ETH ZURICH,"LEISTNER, Christian; GALL, Juergen; YAO, Angela; VAN GOOL, Luc",12004348.4 08.06.2012 EP,
EP254727624,18208898,28.11.2018,3552755,16.10.2019,EP,SYSTEM SUPPORTING PREDICTIVE AND PREVENTATIVE MAINTENANCE,,B23K 31/12; B23K 9/04; B23K 9/095; B23K 9/10; B23K 10/02; B23K 11/00; B23K 15/00; B23K 26/342; B23K 31/00; G05B 19/418,LINCOLN GLOBAL INC,DANIEL JOSEPH A; MATTHEWS WILLIAM THOMAS; GUYMON LANCE F,201762592072 29.11.2017 US; 201816115778 29.08.2018 US,
EP237647402,18159948,05.03.2018,3444807,20.02.2019,EP,NEURAL NETWORK METHOD AND APPARATUS,"A neural network method and apparatus, the method including providing a voice signal to a main neural network and a sub-neural network, obtaining a scaling factor by implementing the sub-neural network configured to generate the scaling factor by interpreting the provided voice signal, determining a size of a future context, based on the scaling factor, to be considered by the main neural network configured to perform speech recognition, obtaining a result of a recognizing of the voice signal by implementing the main neural network with the determined size of the future context.",G10L 15/16,SAMSUNG ELECTRONICS CO LTD,YOO SANG HYUN,20170103044 14.08.2017 KR,
WO2018222900,PCT/US2018/035439,31.05.2018,WO/2018/222900,06.12.2018,WO,COMPUTATIONALLY-EFFICIENT QUATERNION-BASED MACHINE-LEARNING SYSTEM,"A quaternion deep neural network (QTDNN) includes a plurality of modular hidden layers, each comprising a set of QT computation sublayers, including a quaternion (QT) general matrix multiplication sublayer, a QT non-linear activations sublayer, and a QT sampling sublayer arranged along a forward signal propagation path. Each QT computation sublayer of the set has a plurality of QT computation engines. In each modular hidden layer, a steering sublayer precedes each of the QT computation sublayers along the forward signal propagation path. The steering sublayer directs a forward-propagating quaternion-valued signal to a selected at least one QT computation engine of a next QT computation subsequent sublayer.",G06N 3/04; G06N 99/00,INTEL CORPORATION,"MARTINEZ-CANALES, Monica Lucia; SINGH, Sudhir K.; SHARMA, Vinod; BHANDARU, Malini Krishnan","62/513,390 31.05.2017 US",EP-2018808832; CN-201880028685.7
EP13107747,98304770,17.06.1998,0887761,30.12.1998,EP,Method and apparatus for improving the efficiency of support vector machines,"A method and apparatus is described for improving the efficiency of any machine that uses an algorithm that maps to a higher dimensional space in which a given set of vectors is used in a test phase. In particular, reduced set vectors are used. These reduced set vectors are different from the vectors in the set and are determined pursuant to an optimization approach other than the eigenvalue computation used for homogeneous quadratic kernels. An illustrative embodiment is described in the context of a support vector machine (SVM). <IMAGE>",G06K 9/62; G06F 15/18; G06K 9/62; G06N 3/00,LUCENT TECHNOLOGIES INC,BURGES CHRISTOPHER JOHN,88319397 26.06.1997 US,
WO2018112782,PCT/CN2016/111256,21.12.2016,WO/2018/112782,28.06.2018,WO,CAMERA RE-LOCALIZATION BY ENHANCED NEURAL REGRESSION USING MIDDLE LAYER FEATURES IN AUTONOMOUS MACHINES,"An apparatus for facilitating accurate camera re-localization in autonomous machines includes an image capturing device to capture an image of an object, selection/comparison logic to select a middle layer from a plurality of convolutional network (CNN) layers, processing/training logic to process superiority of one or more original keyframes of the image with one or more layer-based keyframes associated with the middle layer, and execution/outputting logic to output a first result based on the one or more original keyframes if one of the one or more original keyframes is superior than the one or more layer-based keyframes. A method, a machine-readable medium, a system, an apparatus, a computing device, and a communications device of the embodiments are also described.",G05D 1/00; G06N 3/02,"INTEL CORPORATION; LIU, Zhongxuan; MA, Liwei","LIU, Zhongxuan; MA, Liwei",,CN-201680091001.9
WO2019168869,PCT/US2019/019656,26.02.2019,WO/2019/168869,06.09.2019,WO,REAL-TIME DETECTION OF LANES AND BOUNDARIES BY AUTONOMOUS VEHICLES,"In various examples, sensor data representative of an image of a field of view of a vehicle sensor may be received and the sensor data may be applied to a machine learning model. The machine learning model may compute a segmentation mask representative of portions of the image corresponding to lane markings of the driving surface of the vehicle. Analysis of the segmentation mask may be performed to determine lane marking types, and lane boundaries may be generated by performing curve fitting on the lane markings corresponding to each of the lane marking types. The data representative of the lane boundaries may then be sent to a component of the vehicle for use in navigating the vehicle through the driving surface.",G06K 9/00; G06K 9/46; G06K 9/48; G06K 9/62,NVIDIA CORPORATION,"XU, Yifang; LIU, Xin; CHEN, Chia-Chih; PARADA, Carolina; ONOFRIO, Davide; PARK, Minwoo; MOHAMMADABADI, Mehdi Sajjadi; CHINTALAPUDI, Vijay; TONKAL, Ozan; ZEDLEWSKI, John; JANIS, Pekka; FRITSCH, Jan Nikolaus; GRIGOR, Gordon; WANG, Zuoguan; CHEN, I-Kuei; SAINZ, Miguel","62/636,142 27.02.2018 US; 16/286,329 26.02.2019 US",
WO2019213023,PCT/US2019/029808,30.04.2019,WO/2019/213023,07.11.2019,WO,SYSTEM AND METHOD FOR ENVIRONMENTAL MONITORING,"A system and method for monitoring an environment and performing analysis of collected samples are provided. The samples can be collected by personnel, a robot or a cobot, and the system may receive results of the monitoring/analysis and output information (e.g., alerts, reports, trends, forecasts) to environmental services, infection prevention personnel, and/or an electronic health/medical record system. If a contaminant is detected in the environment, appropriate personnel may automatically be alerted so that the contaminant can be eliminated/contained. The system may dynamically schedule the monitoring based on needs and ongoing changes in the environment, provide routing and work instructions to personnel, robots and/or cobots, and manage, maintain, and organize all information associated with the environmental monitoring so that information can be accessed, analyzed, and, if necessary, responded to, in real-time and/or in a timely manner, or where corrective actions need to be initiated as part of overall improvement plans.",B08B 7/00; B23K 26/08; G06K 9/00; G06Q 50/22,LONZA LIMITED,"GUEST, Anna; PREUSS, Andrea; HUMMEL, Hans; GOETTER, Michael; POLLEY, Rex","62/664,628 30.04.2018 US",
EP260716697,17882134,14.12.2017,3557484,23.10.2019,EP,NEURAL NETWORK CONVOLUTION OPERATION DEVICE AND METHOD,"A neural network convolution operation device and method, the device being used for implementing a convolution operation of a weight matrix and neurons in a neural network using a matrix multiplication mode, and comprising: a shift operator, used for carrying out Winograd transformation on a neuron matrix and a weight matrix respectively so as to obtain a transformed neuron matrix and a transformed weight matrix; a matrix multiplication operator, used for carrying out a matrix multiplication operation on the transformed neuron matrix and the transformed weight matrix so as to obtain a multiplication matrix, the shift operator also being used for carrying out Winograd inverse transformation on the multiplication matrix so as to obtain a convolution operation result; a controller, used for controlling the shift operator to perform Winograd transformation or Winograd inverse transformation, and also used for controlling the matrix multiplication operator to perform the matrix multiplication operation.",G06N 3/04,SHANGHAI CAMBRICON INFORMATION TECH CO LTD,CHEN YUNJI; ZHUANG YIMIN; LIU SHAOLI; GUO QI; CHEN TIANSHI,201611152537 14.12.2016 CN; 2017116161 14.12.2017 CN,
EP252257023,17884410,15.12.2017,3543896,25.09.2019,EP,"METHOD FOR ESTIMATING LANE INFORMATION, AND ELECTRONIC DEVICE","Disclosed are: an artificial intelligence (AI) system for mimicking functions such as cognition and determination of the human brain by utilizing a machine learning algorithm such as deep learning; and an application thereof. Disclosed is an electronic device comprising: a camera for capturing an external image of a vehicle; and a processor for executing one or more instructions stored in a memory, wherein the processor determines at least one object for estimating lane information from a captured image by executing one or more instructions, estimates lane information of a road, on which the vehicle is traveling, in an image on the basis of the distance between the determined at least one object and the vehicle and the vanishing point of the image, and outputs guide information for guiding the traveling of the vehicle on the basis of the estimated lane information.",G06K 9/00; G06K 9/62; H04N 5/225,SAMSUNG ELECTRONICS CO LTD,KIM JI-MAN; PARK CHAN-JONG; YANG DO-JUN; LEE HYUN-WOO,20160178012 23.12.2016 KR; 20170142567 30.10.2017 KR; 2017014810 15.12.2017 KR,
WO2016122787,PCT/US2015/065327,11.12.2015,WO/2016/122787,04.08.2016,WO,HYPER-PARAMETER SELECTION FOR DEEP CONVOLUTIONAL NETWORKS,"Hyper-parameters are selected for training a deep convolutional network by selecting a number of network architectures as part of a database. Each of the network architectures includes one or more local logistic regression layer and is trained to generate a corresponding validation error that is stored in the database. A threshold error for identifying a good set of network architectures and a bad set of network architectures may be estimated based on validation errors in the database. The method also includes choosing a next potential hyper-parameter, corresponding to a next network architecture, based on a metric that is a function of the good set of network architectures. The method further includes selecting a network architecture, from among next network architectures, with a lowest validation error.",G06N 3/08; G06N 7/00,QUALCOMM INCORPORATED,"TALATHI, Sachin Subhash; JULIAN, David Jonathan","62/109,470 29.01.2015 US; 14/848,296 08.09.2015 US",EP-2015817719
WO2016083657,PCT/FI2014/050911,26.11.2014,WO/2016/083657,02.06.2016,WO,NEURAL NETWORK STRUCTURE AND A METHOD THERETO,The present invention relates to a neural network structure enabling efficient training of the network and a method thereto. The structure is a ladder-type structure wherein one or more lateral input(s) is/are taken to decoding functions. By minimizing one or more cost function(s) belonging to the structure the neural network structure may be trained in an efficient way.,G06N 3/02,CURIOUS Al OY,"VALPOLA, Harri",,JP-2017547076; KR-1020177017402; US-15531212
WO2001059741,PCT/EP2001/000478,17.01.2001,WO/2001/059741,16.08.2001,WO,SIGN LANGUAGE TO SPEECH CONVERTING METHOD AND APPARATUS,"A portable appliance converts gesture-based inputs from a signer to audible speech in real time. The device employs a portable main processor, for example, one of the portable computers now in common use. For its input the appliance uses a data glove and for its output a speaker. Dynamic and static gestures are classified by a Continuous Hidden Markov Model (CHMM) which is capable of robust and rapid real time classification of both static and dynamic gestures. A natural language processor is used to transform the gesture classes into grammatically correct sequences of words. A speech synthesizer converts the word sequences into audible speech.",G06K 9/00; G09B 21/00,KONINKLIJKE PHILIPS ELECTRONICS N.V.,"VAITHILINGAM, Gandhimathi","09/501,894 10.02.2000 US",JP-2001558982; EP-2001900465
EP75563979,11305768,20.06.2011,2538388,26.12.2012,EP,Method and arrangement for image model construction,"A method for constructing an image model (M1; M) from at least one image data input (IV1; IV1-IVn), comprises the steps of, in an iterative way , 
- determining at least one state (PS1; PS1-PSn) of said at least one image data input (IV1; IV1-IVn), and a state (PSMF) of an intermediate learning model (MF; MIF) 
- determining a target state (TSP) from said at least one state (PS1; PS1-PSn) of said at least one image data input, and from the state (PSMF) of said intermediate learning model (MF; MIF), 
- performing at least one transformation in accordance with the determined target state (TSP) on said at least one image data input (IV1; IV1-IVn) , thereby generating at least one transformed image (IV1T; IV1 T-IVnT), 
- aggregating said at least one transformed image (IV1T; IV1T-IVnt) with intermediate learning model (MF; MIF; MIT; MFT) information, thereby generating an updated estimate of said image model (M1; M), 
- providing said updated estimate of said image model (M1; M) as said image model (M1;M) while also 
- providing said updated estimate of said image model (M1;M) in a feedback loop to a model object learning module (500) for deriving an update of said intermediate learning model (MF, MIF).",G06T 19/20; G06T 7/20,ALCATEL LUCENT,TYTGAT DONNY; SIX ERWIN; LIEVENS SAMMY; AERTS MAARTEN,11305768 20.06.2011 EP,
EP11221240,09179260,15.12.2009,2259214,08.12.2010,EP,Implementing a neural associative memory based on non-linear learning of discrete synapses,"This invention is in the field of machine learning and neural associative memory. In particular the invention discloses a neural associative memory structure for storing and maintaining associations between memory address patterns and memory content patterns using a neural network, as well as methods for retrieving such associations. A method for a non-linear synaptic learning of discrete synapses is disclosed and its application on neural networks is laid out.",G06N 3/04; G06N 3/08,HONDA RES INST EUROPE GMBH,KNOBLAUCH ANDREAS,09161923 04.06.2009 EP; 09179260 15.12.2009 EP,
WO2017079229,PCT/US2016/060030,02.11.2016,WO/2017/079229,11.05.2017,WO,SIMULATION SYSTEM AND METHODS FOR AUTONOMOUS VEHICLES,"Various embodiments relate generally to autonomous vehicles and associated mechanical, electrical and electronic hardware, computer software and systems, and wired and wireless network communications to provide an autonomous vehicle fleet as a service. More specifically, systems, devices, and methods are configured to simulate navigation of autonomous vehicles in various simulated environments. In particular, a method may include receiving data representing characteristics of a dynamic object, calculating a classification of a dynamic object to identify a classified dynamic object, identifying data representing dynamic-related characteristics associated with the classified dynamic object, forming a data model of the classified dynamic object, simulating a predicted range of motion of the classified dynamic object in a simulated environment to form a simulated dynamic object, and simulating a predicted response of a data representation of a simulated autonomous vehicle.",B60W 40/02; G06N 7/00,"ZOOX, INC.","LEVINSON, Jesse, Sol; SIBLEY, Gabriel, Thurston; REGE, Ashutosh, Gajanan","14/932,963 04.11.2015 US; 14/757,016 05.11.2015 US; 14/932,959 04.11.2015 US; 14/932,966 04.11.2015 US; 14/932,940 04.11.2015 US; 14/756,995 04.11.2015 US; 14/756,992 04.11.2015 US; 14/756,994 04.11.2015 US; 14/756,993 04.11.2015 US; 14/756,991 04.11.2015 US; 14/756,996 04.11.2015 US; 14/932,948 04.11.2015 US; 14/932,952 04.11.2015 US; 14/932,954 04.11.2015 US; 14/932,958 04.11.2015 US; 14/932,962 04.11.2015 US",JP-2018544031; EP-2016862835
WO2019222745,PCT/US2019/033138,20.05.2019,WO/2019/222745,21.11.2019,WO,SAMPLE-EFFICIENT REINFORCEMENT LEARNING,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for sample-efficient reinforcement learning. One of the methods includes maintaining an ensemble of Q networks, an ensemble of transition models, and an ensemble of reward models; obtaining a transition; generating, using the ensemble of transition models, M trajectories; for each time step in each of the trajectories: generating, using the ensemble of reward models, N rewards for the time step, generating, using the ensemble of Q networks, L Q values for the time step, and determining, from the rewards, the Q values, and the training reward, L * N candidate target Q values for the trajectory and for the time step; for each of the time steps, combining the candidate target Q values; determining a final target Q value; and training at least one of the Q networks in the ensemble using the final target Q value.",G06N 3/00; G06N 3/08; G06N 3/04,GOOGLE LLC,"HAFNER, Danijar; BUCKMAN, Jacob; LEE, Honglak; BREVDO, Eugene; TUCKER, George Jay","62/673,838 18.05.2018 US",
WO2014143977,PCT/US2014/028188,14.03.2014,WO/2014/143977,18.09.2014,WO,BIOMARKERS AND METHODS FOR PREDICTING PREECLAMPSIA,"The disclosure provides biomarker panels, methods and kits for determining the probability for preeclampsia in a pregnant female. The present disclosure is based, in part, on the discovery that certain proteins and peptides in biological samples obtained from a pregnant female are differentially expressed in pregnant females that have an increased risk of developing in the future or presently suffering from preeclampsia relative to matched controls. The present disclosure is further based, in part, on the unexepected discovery that panels combining one or more of these proteins and peptides can be utilized in methods of determining the probability for preeclampsia in a pregnant female with relatively high sensitivity and specificity. These proteins and peptides dislosed herein serve as biomarkers for classifying test samples, predicting a probability of preeclampsia, monitoring of progress of preeclampsia in a pregnant female, either individually or in a panel of biomarkers.",G01N 33/68,"SERA PROGNOSTICS, INC.","HICKOK, Durlin, Edward; BONIFACE, John, Jay; CRITCHFIELD, Gregory, Charles; FLEISCHER, Tracey, Cristine","61/798,413 15.03.2013 US",AU-2014228009; EP-2014762389; CA-2907224
EP179476525,15290128,12.05.2015,3093846,16.11.2016,EP,ACCOUSTIC CONTEXT RECOGNITION USING LOCAL BINARY PATTERN METHOD AND APPARATUS,,G10L 21/06; G06K 9/46; G10L 21/0232; G10L 25/18; G10L 25/48,NXP BV,BATTAGLINO DANIELE; LEPAULOUX LUDOVICK; PILATI LAURENT; EVANS NICHOLAS,15290128 12.05.2015 EP,
WO2014047142,PCT/US2013/060352,18.09.2013,WO/2014/047142,27.03.2014,WO,SPIKING NEURON NETWORK ADAPTIVE CONTROL APPARATUS AND METHODS,"Adaptive controller apparatus of a plant may be implemented. The controller may comprise an encoder block and a control block. The encoder may utilize basis function kernel expansion technique to encode an arbitrary combination of inputs into spike output. The controller may comprise spiking neuron network operable according to reinforcement learning process. The network may receive the encoder output via a plurality of plastic connections. The process may be configured to adaptively modify connection weights in order to maximize process performance, associated with a target outcome. The relevant features of the input may be identified and used for enabling the controlled plant to achieve the target outcome.",G06N 3/02; G05B 13/04,BRAIN CORPORATION,"COENEN, Olivier; SINYAVSKIY, Oleg","13/623,842 20.09.2012 US",
WO2019134987,PCT/EP2019/050210,07.01.2019,WO/2019/134987,11.07.2019,WO,PARALLEL VIDEO PROCESSING SYSTEMS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for parallel processing of video frames using neural networks. One of the methods includes receiving a video sequence comprising a respective video frame at each of a plurality of time steps; and processing the video sequence using a video processing neural network to generate a video processing output for the video sequence, wherein the video processing neural network includes a sequence of network components, wherein the network components comprise a plurality of layer blocks each comprising one or more neural network layers, wherein each component is active for a respective subset of the plurality of time steps, and wherein each layer block is configured to, at each time step at which the layer block is active, receive an input generated at a previous time step and to process the input to generate a block output.",G06N 3/04; G06K 9/00,DEEPMIND TECHNOLOGIES LIMITED,"OSINDERO, Simon; CARREIRA, Joao; PATRAUCEAN, Viorica; ZISSERMAN, Andrew","62/614,323 05.01.2018 US",
WO2017006104,PCT/GB2016/052022,05.07.2016,WO/2017/006104,12.01.2017,WO,IMPROVED ARTIFICIAL NEURAL NETWORK FOR LANGUAGE MODELLING AND PREDICTION,"The present invention relates to an improved artificial neural network for predicting one or more next items in a sequence of items based on an input sequence item. The improved artificial neural network has greatly reduced memory requirements, making it suitable for use on electronic devices such as mobile phones and tablets. The invention includes an electronic device on which the improved artificial neural network operates, and methods of predicting the one or more next items in the sequence using the improved artificial neural network.",G06N 3/04,TOUCHTYPE LTD.,"REI, Marek; WILLSON, Matthew James",1511887.0 07.07.2015 GB,US-15742486; EP-2016738856
WO2020040517,PCT/KR2019/010547,20.08.2019,WO/2020/040517,27.02.2020,WO,ELECTRONIC APPARATUS AND CONTROL METHOD THEREOF,"A method of controlling an electronic apparatus is provided. The method includes obtaining a name referring to a user of another electronic apparatus in a chat with the user of the other electronic apparatus using an artificial intelligence (AI) model trained by an AI algorithm while conducting the chat with the user of the other electronic apparatus using the electronic apparatus; and storing the obtained name in association with contact information of the user of the other electronic apparatus. At least some of the control method of the disclosure may use an AI model trained according to at least one of machine learning, neural network, or deep learning algorithm.",G06F 17/27; G06F 3/048; G06F 3/16; G06N 3/08; H04M 1/725; G10L 15/22,"SAMSUNG ELECTRONICS CO., LTD.","KIM, Soofeel; CHOI, Wonjong; HAM, Jina",10-2018-0096867 20.08.2018 KR; 10-2019-0096871 08.08.2019 KR,
WO2017197170,PCT/US2017/032243,11.05.2017,WO/2017/197170,16.11.2017,WO,SAFELY CONTROLLING AN AUTONOMOUS ENTITY IN PRESENCE OF INTELLIGENT AGENTS,"A controller controls motion of an autonomous entity. The controller determines a baseline trajectory for the autonomous entity that achieves a particular goal (e.g., moves the autonomous entity to a particular location). A safety controller then modifies the baseline trajectory to avoid other entities (e.g., humans or other entities) in the vicinity of the autonomous entity based on a prediction motion of those entities. The controller may be applied to, for example, a robot co-working in a factory with humans or an autonomous vehicle moving around other vehicles.",A61B 34/30; B25J 9/10; B25J 9/16; B25J 13/08; B25J 19/02; B25J 19/06; G05B 19/42,THE REGENTS OF THE UNIVERSITY OF CALIFORNIA,"LIU, Changliu; TOMIZUKA, Masayoshi","62/335,373 12.05.2016 US",
EP13535465,00310492,27.11.2000,1103952,30.05.2001,EP,Context-dependent acoustic models for speech recognition with eigenvoice training,"A reduced dimensionality eigenvoice analytical technique is used during training to develop context-dependent acoustic models fcr allophones. The eigenvoice technique is also used during run time upon the speech of a new speaker. The technique removes individual speaker idiosyncrasies, to produce more universally applicable and robust allophone models. In one embodiment the eigenvoice technique is used to identify the centroid of each speaker, which may then be ""subtracted out"" of the recognition equation. In another embodiment maximum likelihood estimation techniques are used to develop common decision tree frameworks that may be shared across all speakers when constructing the eigenvoice representation of speaker space. <IMAGE>",G10L 15/06; G10L 15/18; G10L 15/06; G10L 15/10; G10L 15/14,MATSUSHITA ELECTRIC IND CO LTD,KUHN ROLAND; CONTOLINI MATTEO; JUNQUA JEAN CLAUDE,45039299 29.11.1999 US,
EP283376998,18187125,02.08.2018,3603902,05.02.2020,EP,METHOD FOR BUILDING AND/OR MAINTAINING AN INDUSTRIAL MACHINE,"The present invention relates to a method for building and/or maintaining an industrial machine, the machine comprising a plurality of machine components, the industrial machine being controlled by a machine application, wherein- a vision system identifies the states of the machine components,- an assistant system compares the identified states to expected states of the machine components,- in case a deviation of the identified state from the expected state of at least one machine component is detected, then the machine application is modified by the assistant system, preferably automatically, based on the deviating identified state.",B25J 9/16; G05B 19/042; G05B 19/05; G05B 23/02; G06F 3/01; H04L 12/24,SCHNEIDER ELECTRIC IND SAS,STEFAN IULIA D; PLATZER CHRISTIAN,18187125 02.08.2018 EP,
WO2012175320,PCT/EP2012/060507,04.06.2012,WO/2012/175320,27.12.2012,WO,METHOD AND ARRANGEMENT FOR IMAGE MODEL CONSTRUCTION,"A method for constructing an image model (M1; M) from at least one image data input (IV1; IV1 -IVn ), comprises the steps of, in an iterative way, - determining at least one state (PS1; PS1 -PSn) of said at least one image data input (IV1; IV1 -IVn), and a state (PSMF) of an intermediate learning model (MF; MIF) - determining a target state (TSP) from said at least one state (PS1; PS1 -PSn) of said at least one image data input, and from the state (PSMF) of said intermediate learning model (MF; MIF), - performing at least one transformation in accordance with the determined target state (TSP) on said at least one image data input (IV1; IV1 -IVn), thereby generating at least one transformed image (IV1T; IV1T-IVnT), - aggregating said at least one transformed image (IV1T; IV1T-IVnt) with intermediate learning model (MF; MIF; MIT; MFT) information, thereby generating an updated estimate of said image model (M1; M), - providing said updated estimate of said image model (M1; M) as said image model (M1;M) while also - providing said updated estimate of said image model (M1;M) in a feedback loop to a model object learning module (500) for deriving an update of said intermediate learning model (MF, MIF).",G06T 7/20,"ALCATEL LUCENT; TYTGAT, Donny; SIX, Erwin; LIEVENS, Sammy; AERTS, Maarten","TYTGAT, Donny; SIX, Erwin; LIEVENS, Sammy; AERTS, Maarten",11305768.1 20.06.2011 EP,US-14122143; KR-1020147001410; JP-2014516259
WO2018125928,PCT/US2017/068567,27.12.2017,WO/2018/125928,05.07.2018,WO,MULTI-CHANNEL SENSOR SIMULATION FOR AUTONOMOUS CONTROL SYSTEMS,"An autonomous control system combines sensor data from multiple sensors to simulate sensor data from high-capacity sensors. The sensor data contains information related to physical environments surrounding vehicles for autonomous guidance. For example, the sensor data may be in the form of images that visually capture scenes of the surrounding environment, geo-location of the vehicles, and the like. The autonomous control system simulates high-capacity sensor data of the physical environment from replacement sensors that may each have lower capacity than high-capacity sensors. The high-capacity sensor data may be simulated via one or more neural network models. The autonomous control system performs various detection and control algorithms on the simulated sensor data to guide the vehicle autonomously.",G06T 15/20; G06T 15/06; G05D 1/02,"DEEPSCALE, INC.","IANDOLA, Forrest, Nelson; MACMILLEN, Donald, Benton; SHEN, Anting; SIDHU, Harsimran, Singh; TOMASELLO, Daniel, Paden; PHADTE, Rohan, Nandkumar; JAI, Paras, Jagdish","62/530,788 10.07.2017 US; 62/440,289 29.12.2016 US",
WO2018102016,PCT/US2017/054183,28.09.2017,WO/2018/102016,07.06.2018,WO,TRAINING AND/OR USING NEURAL NETWORK MODELS TO GENERATE INTERMEDIARY OUTPUT OF A SPECTRAL IMAGE,"Systems, methods, and computer readable media related to training and/or using a neural network model. The trained neural network model can be utilized to generate (e.g., over a hidden layer) a spectral image based on a regular image, and to generate output indicative of one or more features present in the generated spectral image (and present in the regular image since the spectral image is generated based on the regular image). As one example, a regular image may be applied as input to the trained neural network model, a spectral image generated over multiple layers of the trained neural network model based on the regular image, and output generated over a plurality of additional layers based on the spectral image. The generated output may be indicative of various features, depending on the training of the additional layers of the trained neural network model.",G06N 3/04,GOOGLE LLC,"GORBAN, Alexander","15/363,149 29.11.2016 US",EP-2017791488; CN-201780073913.8
WO2020027540,PCT/KR2019/009474,30.07.2019,WO/2020/027540,06.02.2020,WO,APPARATUS AND METHOD FOR PERSONALIZED NATURAL LANGUAGE UNDERSTANDING,"An electronic device for training a machine learning model includes at least one memory and at least one processor coupled to the at least one memory. The at least one processor is configured to train a classification layer of the model. To train the classification layer, the at least one processor is configured to receive, by the classification layer, one or more language contexts from an utterance encoder layer and to classify, by the classification layer, at least one portion of an utterance into an information type among a plurality of information types. The at least one processor may be further configured to jointly train a slot filling layer and an intent detection layer of the model.",G10L 15/00; G10L 15/18; G06F 17/27,"SAMSUNG ELECTRONICS CO., LTD.","SHEN, Yilin; ZENG, Xiangyu; WANG, Yu; JIN, Hongxia","62/712,773 31.07.2018 US; 16/404,012 06.05.2019 US",
WO2019089455,PCT/US2018/057992,29.10.2018,WO/2019/089455,09.05.2019,WO,SEMANTIC OBJECT CLUSTERING FOR AUTONOMOUS VEHICLE DECISION MAKING,"The technology relates to controlling a vehicle (100) in an autonomous driving mode. For example, sensor data identifying a plurality of objects may be received. Pairs of objects of the plurality of objects may be identified. For each identified pair of objects of the plurality of objects, a similarity value which indicates whether the objects of that identified pair of objects can be responded to by the vehicle as a group may be determined. The objects of one of the identified pairs of objects may be clustered together based on the similarity score. The vehicle may be controlled in the autonomous mode by responding to each object in the cluster (610, 620, 710, 740, 760) in a same way.",G05D 1/02,WAYMO LLC,"RUSSELL, Jared, Stephen; DA, Fang","15/798,926 31.10.2017 US; 15/798,881 31.10.2017 US",
WO2016156236,PCT/EP2016/056616,24.03.2016,WO/2016/156236,06.10.2016,WO,METHOD AND ELECTRONIC DEVICE,"A method comprising capturing current and past data frames of a vehicle scenery with an automotive imaging sensor, and predicting, by means of a recurrent neural network, the future position of a moving object in the vehicle scenery based on the current and past data frames.",G08G 1/16; G06K 9/00,SONY CORPORATION; SONY DEUTSCHLAND GMBH,"CARDINAUX, Fabien",15161897.2 31.03.2015 EP,EP-2016713830
WO2017216786,PCT/IL2017/050648,11.06.2017,WO/2017/216786,21.12.2017,WO,AUTOMATIC SPEECH RECOGNITION,"It is depicts a method of speech recognition, sequentially executed by a processor on consecutive speech segments that comprises: obtaining digital information, which is a spectrogram representation, of a speech segment, and extracting from it speech features that characterizes the segment from the spectrogram representation. Then, a consistent structure segment vector based on the speech features is determined onto which machine learning is deployed to determine at least one label of the segment vector. A method of voice recognition and image recognition sequentially executed by a processor, on consecutive voice segments is also described. A system for executeing speech, voice, and image recognition is also provided that comprises client devices to obtain and display information, a segment vector generator to determine a consistent structure segment vector based on features, and a machine learning server to determine at least one label of the segment vector.",G06K 9/62,"NETZER, Omry","NETZER, Omry","62/349,676 14.06.2016 US",IL-263655; EP-2017812878; CN-201780043461.9
WO2019173734,PCT/US2019/021381,08.03.2019,WO/2019/173734,12.09.2019,WO,SYSTEMS AND METHODS FOR PROVIDING MACHINE LEARNING MODEL EVALUATION BY USING DECOMPOSITION,"Systems and methods for model evaluation. A model is evaluated by performing a decomposition process for a model output, relative to a baseline input data set.",G06K 9/62; G06Q 40/00; H04L 12/58,"ZESTFINANCE, INC.","MERRILL, Douglas, C.; RUBERRY, Michael, Edward; SAYIN, Ozan; TUNGUZ, Bojan; SONG, Lin; ALIZADEH, Esfandiar; DEBRUIN, Melanie, Eunique; YAN, Yachen; WILCOX, Derek; CANDIDO, John; SOLECKI, Benjamin, Anthony; HE, Jiahuan; BUDZIK, Jerome, Louis; DONIGIAN, Armen, Avedis; DVIR, Eran; KAMKAR, Sean, Javad; RAJIV, Vishwaesh; KRIMINGER, Evan, George","62/641,176 09.03.2018 US",
WO2019092672,PCT/IB2018/058891,13.11.2018,WO/2019/092672,16.05.2019,WO,SYSTEMS AND METHODS FOR NEURONAL VISUAL-LINGUISTIC DATA RETRIEVAL FROM AN IMAGED DOCUMENT,Systems and methods for automatic information retrieval from imaged documents. Deep network architectures retrieve information from imaged documents using a neuronal visual-linguistic mechanism including a geometrically trained neuronal network. An expense management platform uses the neuronal visual-linguistic mechanism to determine geometric-semantic information of the imaged document.,G06K 9/18,WAY2VAT LTD.,"SIMANTOV, Amos; SHILKROT, Roy; MORAG, Nimrod; GAL, Rinon","62/585,116 13.11.2017 US; 62/642,686 14.03.2018 US",
WO2019222206,PCT/US2019/032207,14.05.2019,WO/2019/222206,21.11.2019,WO,MULTITASK LEARNING AS QUESTION ANSWERING,"Approaches for natural language processing include a multi-layer encoder for encoding words from a context and words from a question in parallel, a multi-layer decoder for decoding the encoded context and the encoded question, a pointer generator for generating distributions over the words from the context, the words from the question, and words in a vocabulary based on an output from the decoder, and a switch. The switch generates a weighting of the distributions over the words from the context, the words from the question, and the words in the vocabulary, generates a composite distribution based on the weighting of the distribution over the first words from the context, the distribution over the second words from the question, and the distribution over the words in the vocabulary, and selects words for inclusion in an answer using the composite distribution.",G06F 17/27; G06N 3/04,"SALESFORCE.COM, INC.","MCCANN, Bryan; KESKAR, Nitish Shirish; XIONG, Caiming; SOCHER, Richard","62/673,606 18.05.2018 US; 16/006,691 12.06.2018 US",
WO2017116924,PCT/US2016/068163,22.12.2016,WO/2017/116924,06.07.2017,WO,NEURAL NETWORK TRAINING PERFORMANCE OPTIMIZATION FRAMEWORK,"A neural network training tool selects from a plurality of parallelizing techniques and selects from a plurality of forward-propagation computation techniques. The neural network training tool performs a forward-propagation phase to train a neural network using the selected parallelizing technique and the selected forward-propagation computation technique based on one or more inputs. Additionally, the neural network training tool selects from a plurality computation techniques and from a plurality of parallelizing techniques for a backward-propagation phase. The neural network training tool performs a backward-propagation phase of training the neural network using the selected backward-propagation parallelizing technique and the selected backward-propagation computation technique to generate error gradients and weight deltas and to update weights associated with one or more layers of the neural network.",G06N 3/063; G06N 3/08,"MICROSOFT TECHNOLOGY LICENSING, LLC","CHILIMBI, Trishul A.; RUWASE, Olatunji; RAJBHANDARI, Samyam; CARBIN, Michael; HE, Yuxiong","14/986,186 31.12.2015 US",
EP11783585,87106697,08.05.1987,0254825,03.02.1988,EP,Adaptive mechanisms for execution of sequential decisions.,"An adaptive mechanism is presented in the context of optimization of expert system applications. Both single and multiple processor implementations are disclosed. The mechanism is used to maintain a near-optimal sequence for scanning rule lists in expert systems. For a program containing a sequential-decision, chain with many independent or mutually exclusive outcomes with each decision having associated with it some fixed cost and probability, the adaptive mechanism tends to produce the optimal ordering automatically from repeated observations of the execution of the decision chain. <IMAGE>",G06F 9/44; G06F 15/18; G06F 17/30; G06N 3/00; G06N 5/00; G06N 5/04; G06N 99/00,IBM,NATARAJAN KADATHUR SUBRAMANYA; STONE HAROLD STUART,88510186 14.07.1986 US,
WO2006095292,PCT/IB2006/050668,03.03.2006,WO/2006/095292,14.09.2006,WO,SUMMARIZATION OF AUDIO AND/OR VISUAL DATA,"Summarization of audio and/or visual data based on clustering of object type features is disclosed. Summaries of video, audio and/or audiovisual data may be provided without any need of knowledge about the true identity of the objects that are present in the data. In one embodiment of the invention are video summaries of movies provided. The summarization comprising the steps of inputting audio and/or visual data, locating an object in a frame of the data, such as locating a face of an actor, extracting type features of the located object in the frame. The extraction of type features is done for a plurality of frames and similar type features are grouped together in individual clusters, each cluster being linked to an identity of the object. After the processing of the video content, the largest clusters correspond to the most important persons in the video.",G06F 17/30,"KONINKLIJKE PHILIPS ELECTRONICS N.V.; BARBIERI, Mauro; DIMITROVA, Nevenka; AGNIHOTRI, Lalitha","BARBIERI, Mauro; DIMITROVA, Nevenka; AGNIHOTRI, Lalitha",05101853.9 10.03.2005 EP,JP-2008500311; KR-1020077023211; CN-200680007810.3; US-11817798; EP-2006711015; RU-null; IN-3951/CHENP/2007
EP224031935,17152333,20.01.2017,3352112,25.07.2018,EP,ARCHITECTURE ADAPTED FOR RECOGNISING A CATEGORY OF AN ELEMENT FROM AT LEAST ONE IMAGE OF SAID ELEMENT,"Architecture for recognising a category (CA, CA') of an element (E1, E2) from an image (I, 11, 12), comprising: a DCNN network (N, N1, N2) with k convolution layers (C k , C 1 -C 5 ) to detect a feature (f k ) in an image (I, 11, 12), comprising each n k  kernels adapted to filter said feature (f k ), the first layer (C 1 ) filtering an input image (I, 11, 12) for producing n 1  feature maps (F 1 ) representing spatial locations of its feature (f 1 ), the following layers (C 2 -C k ) filtering output feature maps (F 1 -Fk- 1 ) of the preceding layer (C 1 -C k-1 ) for producing n2-nk feature maps (F 2 -F k ); and a fully-connected layer (FC) for predicting a possible category (CA, CA'), the architecture further comprising a SVM machine (V) for classifying and furnishing the last feature maps (F 5 , F k ) to the layer (FC) to improve the prediction accuracy with a lower computational complexity; means for establishing a confusion matrix to evaluate the pairs of categories (CA, CA') most often confused.",G06K 9/46; G06K 9/62,NOKIA TECHNOLOGIES OY,MILIORIS DIMITRIOS,17152333 20.01.2017 EP,
EP232159381,18163810,23.03.2018,3392826,24.10.2018,EP,CONVOLUTIONAL NEURAL NETWORK OPTIMIZATION MECHANISM,An apparatus to facilitate optimization of a convolutional neural network (CNN) is disclosed. The apparatus includes optimization logic to receive a CNN model having a list of instructions and including pruning logic to optimize the list of instructions by eliminating branches in the list of instructions that comprise a weight value of 0.,G06T 1/20,INTEL CORP,MA LIWEI; OULD-AHMED-VALL ELMOUSTAPHA; LAKSHMANAN BARATH; ASHBAUGH BEN J; JIN JINGYI; BOTTLESON JEREMY; MACPHERSON MIKE B; NEALIS KEVIN; SRIVASTAVA DHAWAL; RAY JOYDEEP; TANG PING T; STRICKLAND MICHAEL S; CHEN XIAOMING; YAO ANBANG; SHPEISMAN TATIANA; KOKER ALTUG; APPU ABHISHEK R,201715488551 17.04.2017 US,
EP252257046,19163921,19.03.2019,3543917,25.09.2019,EP,DYNAMIC ADAPTATION OF DEEP NEURAL NETWORKS,,G06N 3/04; G06N 3/063; G06N 3/08,SRI INT INC,CHAI SEK MENG; RAGHAVAN ASWIN NADAMUNI; PARAJULI SAMYAK,201816133446 17.09.2018 US; 201862644715 19.03.2018 US; 201862645358 20.03.2018 US,
WO2006002320,PCT/US2005/022294,22.06.2005,WO/2006/002320,05.01.2006,WO,SYSTEM AND METHOD FOR 3D OBJECT RECOGNITION USING RANGE AND INTENSITY,"A system and method for performing object and class recognition that allows for wide changes of viewpoint and distance of objects is disclosed. The invention provides for choosing pose-invariant interest points of a three-dimensional (3D) image, and for computing pose-invariant feature descriptors of the image. The system and method also allows for the construction of three-dimensional (3D) object and class models from the pose-invariant interest points and feature descriptors of previously obtained scenes. Interest points and feature descriptors of a newly acquired scene may be compared to the object and/or class models to identify the presence of an object or member of the class in the new scene.",G06K 9/00; G06K 9/36; G06K 9/46; G06K 9/62,"STRIDER LABS, INC.; HAGER, Gregory; WEGBREIT, Eliot","HAGER, Gregory; WEGBREIT, Eliot","60/582,461 23.06.2004 US",DE-null; EP-2005763226
EP123434313,11819099,12.12.2011,2792435,22.10.2014,EP,METHOD AND SYSTEM FOR SEPARATING CAST PARTS FROM CLUSTERS OBTAINED BY MEANS OF CASTING PROCESSES,"The invention relates to a method and system for separating cast parts from clusters obtained by means of casting processes. The method comprises placing the cluster (3) in a first working area (z1), obtaining an image of the cluster (3) by means of a first computer vision system (4) and processing it, obtaining the orientation of the cast parts and the coordinates of the cutting points referenced to the spatial reference system (X, Y, Z) of the first computer vision system (4), converting the coordinates of the cutting points and orientation of the parts to the spatial reference system (X', Y', Z') of a first manipulator (2) arranged in a second working area (z2), determining the entering angle for separating each cast part (14) and transmitting the coordinates of the cutting points, orientation and entering angle to the first industrial manipulator (2) to apply the separating tool (8) at the cutting point, with the suitable orientation and with the determined entering angle. The method comprises securing the cluster in the second working area (z2).",B22D 31/00; B25J 9/16; G05B 19/418,FUNDACIÓN TECNALIA RES & INNOVATION,LOPEZ GONZALEZ JESUS MARIA; ANDRES ALONSO MAITE; ARMENTIA ORTIZ JORGE; DURO RODRIGUEZ GORKA; PEREZ LARRAZABAL JOSE; DEL POZO ROJO DIONISIO; PEDRERO IÑIGUEZ JUAN MANUEL; CABALLERO OGUIZA PATRICIA; BELOKI ZUBIRI OIHANE; COLLADO JIMENEZ VALENTÍN,2011070851 12.12.2011 ES,
WO2018168537,PCT/JP2018/008141,02.03.2018,WO/2018/168537,20.09.2018,WO,LEARNING TARGET APPARATUS AND OPERATING METHOD,"A mechanism is provided that ensures the safety around a learning target apparatus that is placed at a remote location, when the learning target apparatus is remotely manipulated in order to carry out machine learning. A learning target apparatus according to an aspect of the present invention executes: an accepting step of accepting, from the learning apparatus, a command made through remote manipulation that instructs the learning target apparatus to execute an operation associated with the designated ability; an execution step of executing the operation associated with the designated ability in accordance with the accepted command made through the remote manipulation; and a display step of causing the display unit to display that an operation is being executed in accordance with the remote operation from the learning apparatus, while the operation is being executed in accordance with the command made through the remote manipulation.",B25J 9/16; G06N 99/00,OMRON CORPORATION,"ANDO, Tanichi; TAKIZAWA, Koji",2017-048335 14.03.2017 JP; 2018-023614 14.02.2018 JP,
WO2003096063,PCT/US2003/014067,06.05.2003,WO/2003/096063,20.11.2003,WO,NINE DIMENSIONAL LASER TRACKING SYSTEM AND METHOD,"A laser based tracking unit (100) communicates with a target (150) to obtain position information about the target. Specifically, the target is placed at the point to be measured. The pitch, yaw and roll of the target, and the spherical coordinates of the target relative to the tracking unit are then obtained. Then additional information regarding a probe (610) attached to the target reconciled with the above determination to determine a position of a probe tip (620). The target can be, for example, an active device incorporated into a moveable device such a remote controlled robot.",B25J 9/16; B25J 13/08; G01S 17/02; G01S 17/42; G01S 17/74,"AUTOMATED PRECISION, INC.","LAU, Kam, C.","60/377,596 06.05.2002 US",JP-null
WO2009130693,PCT/IL2009/000430,21.04.2009,WO/2009/130693,29.10.2009,WO,SYSTEM AND METHOD FOR STATISTICAL MAPPING BETWEEN GENETIC INFORMATION AND FACIAL IMAGE DATA,"A method and system for statistical mapping between genetic information and facial image data including collecting a multiplicity of sets of genetic information and matching facial image data representing a multiplicity of individuals, representing the genetic information of each of the multiplicity of individuals as a first multidimensional representation, representing the facial image data of each of the multiplicity of individuals as a second multidimensional representation; and inferring correlative, non-causal, statistical relationships between the first multidimensional representations and the second multidimensional representations. A system and method for estimating the likelihood of donor-recipient transplant compatibility using facial images of potential donors, the method including inferring correlative, non-causal, statistical relationships, indicative of transplant compatibility, between multidimensional representations of facial image data of potential donors and a multidimensional representation of information relating to a potential recipient.",A61B 5/05,"MTS INVESTMENTS INC.; WOLF, Lior; DONNER, Yonatan; SCHNIBERG, Rona","WOLF, Lior; DONNER, Yonatan; SCHNIBERG, Rona","61/046,689 21.04.2008 US",US-12989021
WO2019025788,PCT/GB2018/052188,31.07.2018,WO/2019/025788,07.02.2019,WO,A METHOD OF CONSTRUCTING A MODEL OF THE MOTION OF A MOBILE DEVICE AND RELATED SYSTEMS,"A computer-implemented method 1000 of constructing a model of the motion of a mobile device, wherein the method comprises using a sensor of the device to obtain 1002 positional data providing an estimated pose of the mobile device, generating an initial graph 1004 based upon the positional data from the sensor, nodes of which graph provide a series of possible poses of the device, and edges of which graph represent odometry and/or loop closure constraints; processing the graph to estimate 1006 confidence scores for each loop closure by performing pairwise consistency tests between each loop closure and a set of other loop closures; and generating an augmented graph from the initial graph by retaining or deleting 1008 each loop closure based upon the confidence scores.",G06T 7/20; G06T 7/70,OXFORD UNIVERSITY INNOVATION LIMITED,"XIE, Linhai; WANG, Sen; MARKHAM, Andrew; TRIGONI, Niki",20170100360 31.07.2017 GR; 1718507.5 09.11.2017 GB,AU-2018311303; EP-2018765966
WO2020000383,PCT/CN2018/093717,29.06.2018,WO/2020/000383,02.01.2020,WO,"SYSTEMS AND METHODS FOR LOW-POWER, REAL-TIME OBJECT DETECTION","Described herein are systems and methods for object detection to achieve hard real-time performance with low latency. Real-time object detection frameworks are disclosed. In one or more embodiments, a framework comprises a first CPU core, a second CPU core, and a plurality of shaves. In one or more embodiments, the first CPU core handles general CPU tasks, while the second CPU core handles the image frames from a camera sensor and computation task scheduling. In one or more embodiments, the scheduled computation tasks are implemented by the plurality of shaves using at least one object-detection model to detect an object in an image frame. In one or more embodiments, computation results from the object-detection model with a higher detection probability is used to form an output for object detection. In one or more embodiments, the object-detection models share some parameters for smaller size and higher implementing speed.",G06T 1/20,"BAIDU.COM TIMES TECHNOLOGY (BEIJING) CO., LTD.; BAIDU USA LLC","KOU, Haofeng; WANG, Kuipeng; KANG, Le; WANG, Xuejun; BAO, Yingze",,
WO2015021404,PCT/US2014/050381,08.08.2014,WO/2015/021404,12.02.2015,WO,METHOD FOR KNOWLEDGE EXTRACTION THROUGH DATA MINING,"The disclosed embodiments relate to data mining methods for determining economically valuable cause effect relationships between objects and properties associated with objects using co-occurrence frequency measurements of semantic terms characterizing observations of properties., effects or behaviors of objects in different environments and using these measurements as object descriptors in calculations determining object similarities. Specifically, these methods may be used to identify new indications of medicines, identify biomarkers associated with disease, identify biomarkers associated with drug effects, quantify disease diagnosis, identify novel drug targets, identify pharmacologic equivalencies of medicines, identify pharmacologic equivalencies between medicines and traditional medicines, identify pharmacologic equivalencies between medicines and Natural products, identify equivalencies between alternate medical procedures, identify risk benefit profiles of medicine combinations, identify targets for antibodies, identify synergies between medicines, identify Side effects of medicines, identify risks of experimental medicines, identify functions of biological networks.",G06F 17/00,SYSTAMEDIC INC.,"FLIRI, Anton, F.; LOGING, William, T.; VOLKMANN, Robert, A.","61/863,721 08.08.2013 US",US-15022808
EP237647347,16898264,15.04.2016,3444758,20.02.2019,EP,DISCRETE DATA REPRESENTATION-SUPPORTING APPARATUS AND METHOD FOR BACK-TRAINING OF ARTIFICIAL NEURAL NETWORK,"The present disclosure provides a device configured to perform reverse training of an artificial neural network supporting discrete data representation. The device includes an instruction caching unit, a controller unit, a data access unit, an interconnecting module, a primary operating module, a plurality of secondary operating modules, a discrete data operating module, and a converting module. The reverse training of the multilayer artificial neural network may be achieved by means of using the device. The device is characterized by support for discrete data, including storage, operation of the discrete data and conversion of the successive data into the discrete data. The data, such as weights and neurons, in the reverse training of the artificial neural network performed by the device may be discretely or successively represented. The discrete data representation refers to a storage manner of replacing data with specified numbers. For example, four numbers, 00, 01, 02, and 03, may represent four numbers, -1, -1/8, 1/8, and 1, respectively. This storage manner differs from that of using 00/01/10/11 in the decimal system to represent four numbers 0/1/2/3. The discrete data operating module replaces basic operations of the successive data, for example a multiplication operation and an addition operation, with different bitwise operations, for example an exclusive-OR operation and a NOT operation, according to the values of the discrete data. The converting module converts the successive data into the discrete data.",G06N 3/08; G06N 3/04; G06N 3/063; G06N 5/00,CAMBRICON TECH CORPORATION LIMITED,GUO QI; YU YONG; CHEN TIANSHI; CHEN YUNJI,2016079443 15.04.2016 CN,
WO2019094882,PCT/US2018/060611,13.11.2018,WO/2019/094882,16.05.2019,WO,DEEP NEURAL NETWORK PROCESSOR WITH INTERLEAVED BACKPROPAGATION,"Processing circuitry for a deep neural network can include input/output ports, and a plurality of neural network layers coupled in order from a first layer to a last layer, each of the plurality of neural network layers including a plurality of weighted computational units having circuitry to interleave forward propagation of computational unit input values from the first layer to the last layer and backward propagation of output error values from the last layer to the first layer.",G06N 3/063; G06N 3/04; G06N 3/08,RAYTHEON COMPANY,"GOULDING, John R.; MIXTER, John E.; MUCHA, David R.; GANGWER, Troy A.; SILVA, Ryan D.","15/810,946 13.11.2017 US",
WO1998002825,PCT/US1997/011905,10.07.1997,WO/1998/002825,22.01.1998,WO,COMPUTER IMPLEMENTED MACHINE LEARNING METHOD AND SYSTEM,"One or more machine code entities (50) such as programs or functions are created which represent solutions to a problem and are directly executable by a computer system (10). The programs (50) are created and altered by a program (32) in a higher level language such as 'C' which is not directly executable, but requires translation into executable machine code through compilation, interpretation, translation, etc. The entities (50) are initially created as an integer array (32b) that can be altered by the program (32) as data, and are executed by the program (32) by recasting a pointer to the array as a function type. The entities (50) are evaluated by executing them with training data as inputs, and calculating fitnesses based on a predetermined criterion. The entities (50) are then altered based on their fitnesses using a genetic machine learning algorithm by recasting the pointer to the array as a data (e.g. integer) type. This process is iteratively repeated until an end criterion is reached. The entities (50) evolve in such a manner as to improve their fitness, and one entity is ultimately produced which represents an optimal solution to the problem. Each entity (50) includes a plurality of directly executable machine code instructions (52a, 52b, 52c), a header (50a), a footer (50c), and a return instruction (50d). The instructions (50) can include branch instructions which enable subroutines, leaf functions, external function calls, recursion, and loops. The system (10) can be implemented on an integrated circuit chip (90), with the entities (50) stored in high speed memory (96) in a central processing unit (92). The system (10) can be used to control an autonomous agent such as a robot.",G06F 15/18; G06N 3/12,"FRANCONE, Frank, D.","FRANCONE, Frank, D.; NORDIN, Peter; BANZHAF, Wolfgang","08/679,555 12.07.1996 US; 08/682,859 12.07.1996 US; 08/674,337 12.07.1996 US",
WO2018087941,PCT/JP2017/010209,14.03.2017,WO/2018/087941,17.05.2018,WO,ILLUMINATION CONTROL USING A NEURAL NETWORK,"Provided is an illumination device (3) that can appropriately illuminate an illumination target (10) even when the state of the illumination target (10) changes. An illumination device (3) according to the present invention includes at least one light source (311) configured to perform illumination with a plurality of illumination patterns, a detection unit (33) for detecting state information on the state of an illumination target (10) that is to be illuminated by the light source (311), an arithmetic unit (362) configured to calculate, using a neural network, illumination pattern information for generating an illumination pattern appropriate for the illumination target (10) from the state information, and an illumination control unit (312) configured to control the light source (311) in order to perform illumination with an illumination pattern based on the illumination pattern information.",G06K 9/20; G06K 9/46; H05B 37/02,OMRON CORPORATION,"ANDO, Tanichi",2016-220432 11.11.2016 JP,JP-2019547206; EP-2017717887; CN-201780054880.2
WO2020073037,PCT/US2019/054941,07.10.2019,WO/2020/073037,09.04.2020,WO,METHOD FOR TRACKING AND CHARACTERIZING PERISHABLE GOODS IN A STORE,"One variation of a method for tracking fresh produce in a store includes: accessing a first hyper-spectral image, of a produce display in a store, recorded at a first time; extracting a first spectral profile from a first region of the first hyper-spectral image depicting a first set of produce units in the produce display; identifying a first varietal of the first set of produce units; characterizing qualities (e.g., ripeness, bruising, spoilage) of the first set of produce units in the produce display based on the first spectral profile; and, in response to qualities of the first set of produce units in the produce display deviating from a target quality range assigned to the first varietal, generating a prompt to audit the first set of produce units in the produce display.",G01J 3/28; G01N 21/25; G01N 33/02; G01N 21/49; G05B 23/02; G06F 9/44,"SIMBE ROBOTICS, INC.","BOGOLEA, Bradley; TIWARI, Durgesh; SAFI, Jariullah","62/742,213 05.10.2018 US",
EP275493176,17883465,22.12.2017,3561732,30.10.2019,EP,OPERATION APPARATUS AND METHOD FOR ARTIFICIAL NEURAL NETWORK,"An operation apparatus and method for an artificial neural network. The operation apparatus for an artificial neural network comprises: a mapping unit for receiving an input neural cell and a weight value, producing connection relationship data of the input neural cell and an output neural cell, and outputting the input neural cell and the weight value after mapping, wherein a correlation between the input neural cell and the weight value after mapping is an input neural cell-weight value pair, and the mapping unit comprises: a first mapping unit for removing a weight value, the absolute value of which is less than or equal to a first threshold value or the value of which is 0 or less than the first threshold value; and/or a second mapping unit for removing an input neural cell, the absolute value of which is less than or equal to a second threshold value or the value of which is 0 or less than the second threshold value.",G06N 3/04,CAMBRICON TECH CORPORATION LIMITED; SHANGHAI CAMBRICON INFORMATION TECH CO LTD,LIU SHAOLI; HAO YIFAN; CHEN YUNJI; GUO QI; CHEN TIANSHI,201611214028 23.12.2016 CN; 2017118124 22.12.2017 CN,
EP30721443,10173087,17.08.2010,2386998,16.11.2011,EP,A Two-Stage Correlation Method for Correspondence Search,"The invention presents a method for comparing the similarity between image patches comprising the steps of receiving form at least two sources at least two image patches, wherein each source supplies an image patch, comparing the received image patches by extracting a number of corresponding subpart pairs from each image patch, calculating a normalized local similarity score between all corresponding subpart pairs, calculating a total matching score by integrating the local similarity scores of all corresponding subpart pairs, and using the total matching score as an indicator for an image patch similarity, determining corresponding similar image patches based on the total matching score.",G06T 7/00; H04N 13/00,HONDA RES INSTITUTE EUROPE GMBH,EGGERT JULIAN; EINECKE NILS,10162822 14.05.2010 EP; 10173087 17.08.2010 EP,
WO2018161217,PCT/CN2017/075764,06.03.2017,WO/2018/161217,13.09.2018,WO,A TRANSDUCTIVE AND/OR ADAPTIVE MAX MARGIN ZERO-SHOT LEARNING METHOD AND SYSTEM,"An apparatus and method to implement object detection with a zero-shot learning model. The apparatus and method are configured to provide at least one embedding matrix of the zero-shot learning model, to provide unseen data for one or more unseen instances, to update the embedding matrix according to selected one or more unseen instances that have higher predicted confidence when the embedding matrix is applied, and to detect an object of interest in an unseen category from a region of an image using the updated embedded matrix. The initial embedding matrix can be refined beforehand using an adaptive max margin approach.",G06K 9/62,"NOKIA TECHNOLOGIES OY; NOKIA TECHNOLOGIES (BEIJING) CO., LTD.","YU, Yunlong",,EP-2017899880; CN-201780088157.6
WO2010078018,PCT/US2009/068427,17.12.2009,WO/2010/078018,08.07.2010,WO,EFFICIENT 3-D TELESTRATION FOR LOCAL AND REMOTE ROBOTIC PROCTORING,"An apparatus is configured to show telestration in 3-D to a surgeon in real time. A proctor is shown one side of a stereo image pair, such that the proctor can draw a telestration line on the one side with an input device. Points of interest are identified for matching to the other side of the stereo image pair. In response to the identified points of interest, regions and features are identified and used to match the points of interest to the other side. Regions can be used to match the points of interest. Features of the first image can be matched to the second image and used to match the points of interest to the second image, for example when the confidence scores for the regions are below a threshold value. Constraints can be used to evaluate the matched points of interest, for example by excluding bad points.",G06T 7/00; H04N 5/262; H04N 13/00,"INTUITIVE SURGICAL OPERATIONS, INC.","ZHAO, Wenyi; WU, Chenyu; HIRVONEN, David; HASSER, Christopher J.; MILLER, Brian; MOHR, Catherine J.; CURET, Myriam J.; ZHAO, Tao; DIMAIO, Simon; HOFFMAN, Brian D.","61/204,046 31.12.2008 US; 12/465,020 13.05.2009 US",
WO2019203488,PCT/KR2019/004173,09.04.2019,WO/2019/203488,24.10.2019,WO,ELECTRONIC DEVICE AND METHOD FOR CONTROLLING THE ELECTRONIC DEVICE THEREOF,"An artificial intelligence (AI) system utilizing a machine learning algorithm such as deep learning for controlling an electronic device when a video is reproduced and a user's voice instruction is received, to acquire a frame corresponding to the time point when the input of the user's voice instruction is received, and obtain a search result for information on objects in the frame using an AI model trained according to at least one of machine learning, a neural network or a deep learning algorithm.",H04N 21/472; H04N 21/4722; H04N 21/422; G06N 3/08; G06F 16/903; G06F 3/16,"SAMSUNG ELECTRONICS CO., LTD.","LEE, Jungmin",10-2018-0046072 20.04.2018 KR,
WO2020072667,PCT/US2019/054326,02.10.2019,WO/2020/072667,09.04.2020,WO,TRAJECTORY PREDICTION ON TOP-DOWN SCENES,"Techniques are discussed for determining predicted trajectories based on a top-down representation of an environment. Sensors of a first vehicle can capture sensor data of an environment, which may include agent(s) separate from the first vehicle, such as a second vehicle or a pedestrian. A multi-channel image representing a top-down view of the agent(s) and the environment and comprising semantic information can be generated based on the sensor data. Semantic information may include a bounding box and velocity information associated with the agent, map data, and other semantic information. Multiple images can be generated representing the environment over time. The image(s) can be input into a prediction system configured to output a heat map comprising prediction probabilities associated with possible locations of the agent in the future. A predicted trajectory can be generated based on the prediction probabilities and output to control an operation of the first vehicle.",G01C 21/34; G01C 21/36; G05D 1/02,"ZOOX, INC.","HONG, Xi Joey; SAPP, Benjamin John","16/151,607 04.10.2018 US",
EP280245506,19192341,17.03.2015,3591577,08.01.2020,EP,"INFORMATION PROCESSING APPARATUS, INFORMATION PROCESSING METHOD, AND PROGRAM",,G06K 9/00; G06F 1/16; G06F 3/00; G06F 3/01; G06F 3/03; G06F 3/0489; G06F 16/435; G06F 17/20; G06K 9/62; G06K 9/72; G06Q 50/00,SONY CORP,MURATA MAKOTO; SHIBUYA NAOKI; TAKABAYASHI JUNKO; TAKIMOTO YUUJI; SATO KOJI,15796082 17.03.2015 EP; 2014106276 22.05.2014 JP; 2015057861 17.03.2015 JP,
EP137965569,14200230,23.12.2014,2889709,01.07.2015,EP,Industrial Automation Device with Editor and Graphical Object Mobile Visualization,"A remote visualization editing and monitoring system facilitates development, management, and deployment of graphical web pages that can be stored on industrial devices (e.g., industrial controllers, drives, etc.) and remotely accessed by mobile devices using a web browser. The remote visualization editing and monitoring system can leverage web technologies to provide simple but powerful graphical web-based HMIs that can be accessed using a client device. The system allows a user to develop and deploy both web-based human-machine interfaces for monitoring of an industrial process, as well as web pages that render graphical representations of the control program executing on the industrial device.",G05B 19/042; G06F 9/44,ROCKWELL AUTOMATION TECH INC,CHOUINARD JULIEN; TRANG CHAN-DARA; DEMERS HENRI,201361922499 31.12.2013 US; 201414567088 11.12.2014 US,
WO2018184194,PCT/CN2017/079682,07.04.2017,WO/2018/184194,11.10.2018,WO,METHODS AND SYSTEMS USING IMPROVED CONVOLUTIONAL NEURAL NETWORKS FOR IMAGE PROCESSING,"Methods and systems are disclosed using improved Convolutional Neural Networks (CNN) for image processing. In one example, an input image is down-sampled into smaller images with a smaller resolution than the input image. The down-sampled smaller images are processed by a CNN having a last layer with a reduced number of nodes than a last layer of a full CNN used to process the input image at a full resolution. A result is outputted based on the processed down-sampled smaller images by the CNN having a last layer with a reduced number of nodes. In another example, shallow CNN networks are built randomly. The randomly built shallow CNN networks are combined to imitate a trained deep neural network (DNN).",G06K 9/00,"INTEL CORPORATION; WANG, Shandong; GUO, Yiwen; YAO, Anbang; CAI, Dongqi; WANG, Libin; XU, Lin; HU, Ping; CHENG, Wenhua; CHEN, Yurong","WANG, Shandong; GUO, Yiwen; YAO, Anbang; CAI, Dongqi; WANG, Libin; XU, Lin; HU, Ping; CHENG, Wenhua; CHEN, Yurong",,EP-2017904390
WO2007086486,PCT/JP2007/051213,19.01.2007,WO/2007/086486,02.08.2007,WO,SYSTEM FOR DETECTING ACTIVITIES IN PHYSICAL ENVIRONMENT AND METHOD FOR DETECTING ACTIVITIES IN ENVIRONMENT,"Binary motion events are detected by individual motion sensors placed in a physical environment. The motions events are transmitted to a cluster leader, each motion detector being a cluster leader of immediately spatially adjacent motion sensors. Movements of objects are detected by the cluster leaders according to the motion events. The movements are transmitted to supercluster leaders, each motion detector being a supercluster leader of immediately spatially adjacent motion clusters of sensors. Activities of the objects are detected by the supercluster leaders, and actions of the objects are detected according to the activities.",G06K 9/00; G06K 9/62; G08B 13/194,"MITSUBISHI ELECTRIC CORPORATION; WREN, Christopher, R.; TAPIA, Emmanuel, Munguia","WREN, Christopher, R.; TAPIA, Emmanuel, Munguia","11/341,649 27.01.2006 US",CN-200780000553.5; DE-null; JP-2007539406
EP249227640,18201299,18.10.2018,3514734,24.07.2019,EP,METHOD AND APPARATUS FOR GENERATING A CHEMICAL STRUCTURE USING A NEURAL NETWORK,"A method of generating a chemical structure performed by a neural network device includes receiving a target property value and a target structure characteristic value; selecting first generation descriptors; generating second generation descriptors; determining, using a first neural network of the neural network device, property values of the second generation descriptors; determining, using a second neural network of the neural network device, structure characteristic values of the second generation descriptors; selecting, from the second generation descriptors, candidate descriptors that satisfy the target property value and the target structure characteristic value; and generating, using the second neural network of the neural network device, chemical structures for the selected candidate descriptors.",G06N 3/04; G06N 3/12; G16C 20/50; G16C 20/70; G16C 20/80,SAMSUNG ELECTRONICS CO LTD; RESEARCH & BUSINESS FOUND SUNGKYUNKWAN UNIV,KWON YOUNGCHUN; KANG SEOKHO; KIM KYUNGDOC; YOO JIHO; CHOI YOUNSUK,20180006275 17.01.2018 KR,
EP13257709,99203440,17.05.1993,0969386,05.01.2000,EP,Asynchronous temporal neural processing element,"The invention relates to a neural network processing system, comprising one or more temporal neural processing elements each comprising means for processing signals. The network comprises data driven means for adjustably controlling a processing delay period of said processing means to a value from a maximum of one second or more to a minimum of one nanosecond. Said system is selectively operable to receive and process numerical or non-numerical input data. <IMAGE>   <IMAGE>   <IMAGE>   <IMAGE>",G06F 15/80; G06N 3/04; G06N 3/063; G06N 3/067,UNIV NEW MEXICO STATE TECH TRA,DE YONG MARK R; ESKRIDGE THOMAS C; FINDLEY RANDALL L; FIELDS CHRISTOPHER A,93913970 17.05.1993 EP; 88542392 18.05.1992 US,
EP283377999,17901932,21.03.2017,3605405,05.02.2020,EP,"SERVER DEVICE, TRAINED MODEL PROVIDING PROGRAM, TRAINED MODEL PROVIDING METHOD, AND TRAINED MODEL PROVIDING SYSTEM","A server device configured to communicate, via a communication network, with at least one device including a learner configured to perform processing by using a learned model, the server device including: a storage unit configured to store a plurality of shared models pre-learned in accordance with environments and conditions of various devices; a device data acquisition unit configured to acquire device data including information on an environment and conditions from the at least one device; a target shared model selection unit configured to select an optimum shared model for the at least one device based on acquired device data; and a transmitter configured to transmit a selected shared model to the at least one device.",G06N 99/00,PREFERRED NETWORKS INC,KAWAAI KEIGO; HIDO SHOHEI; KUBOTA NOBUYUKI; TANAKA DAISUKE,2017011216 21.03.2017 JP,
WO2008072874,PCT/KR2007/006427,11.12.2007,WO/2008/072874,19.06.2008,WO,ADVERTISEMENT PROVIDING METHOD AND SYSTEM FOR MOVING PICTURE ORIENTED CONTENTS WHICH IS PLAYING,"A method of providing advertising content customized for the content of a moving picture using text information acquired from the moving picture is disclosed. The method includes acquiring text information from a moving picture that can be played by a player; transmitting at least one piece of search target text, included in the acquired text information, to at least one search server capable of providing search results for the search target text; receiving the search results from the search server; and displaying the received search results while the moving picture is being played.",G06F 17/30,"KANG, Min Soo","KANG, Min Soo",10-2006-0125705 11.12.2006 KR,JP-2009541220; CN-200780045687.9; US-12518403
WO2009111559,PCT/US2009/036024,04.03.2009,WO/2009/111559,11.09.2009,WO,COMBINATORIAL STOCHASTIC LOGIC,"Circuits that solve stochastic problems and techniques for operating them. These natively stochastic circuits may produce samples from probability distributions of interest for particular stochastic problems, and may be combined together in any suitable way to yield potential solutions to stochastic problems. In some implementations, the stochastic circuits may generate samples from conditional probability distributions conditioned on input data provided to the stochastic circuits. The circuits may be constructed from multiple interconnected stochastic subcircuits such that a circuit may produce a sample from a joint probability distribution, or from a marginal distribution of a joint distribution. These circuits may be used to implement stochastic sampling algorithms to solve stochastic processes, and may include stochastic subcircuits that operate concurrently.",G01R 31/28,"MASSACHUSETTS INSTITUTE OF TECHNOLOGY; MANSINGHKA, Vikash, Kumar; JONAS, Eric, Michael","MANSINGHKA, Vikash, Kumar; JONAS, Eric, Michael","61/033,540 04.03.2008 US; 12/397,754 04.03.2009 US",CN-200980116076.8; EP-2009717984
WO2017044484,PCT/US2016/050545,07.09.2016,WO/2017/044484,16.03.2017,WO,BACKSCATTER IMAGING FOR PRECISION AGRICULTURE,"Methods for characterizing living plants, wherein one or more beams of penetrating radiation such as x-rays are scanned across the plant under field conditions. Compton scatter is detected from the living plant and processed to derive characteristics of the living plant such as water content, root structure, branch structure, xylem size, fruit size, fruit shape, fruit aggregate volume, cluster size and shape, fruit maturity and an image of a part of the plant. Ground water content is measured using the same technique. Compton backscatter is used to guide a robotic gripper to grasp a portion of the plant such as for harvesting a fruit.",G01N 23/20; G01N 33/02; G01N 9/02,"AMERICAN SCIENCE AND ENGINEERING, INC.","COUTURE, Aaron; ADAMS, Calvin; FONSECA, Rafael; SCHUBERT, Jeffrey; MASTRONARDI, Richard","62/337,971 18.05.2016 US; 62/215,456 08.09.2015 US",EP-2016844975; GB-1805701.8; AU-2016321171; US-15758134
WO2018176017,PCT/US2018/024218,24.03.2018,WO/2018/176017,27.09.2018,WO,"METHOD, SYSTEM, AND APPARATUS FOR IDENTIFYING AND REVEALING SELECTED OBJECTS FROM VIDEO","A method, system, and apparatus for identifying and revealing objects from video identifies or infers objects from images or sequences of images upon a command, interrogative, or inferred interest of a user. The system is trained to identify or infer the objects using neural network or statistical learning-based models. The system may respond to the user in accordance with an expected user latency in requesting the system to reveal a specific object to the user. Semantic techniques may be applied to enable the system to interpret contextual or object attribute information that is provided by the users' communications to the system. The system may be applied in product promotional processes that are with respect to video that is associated with television, movies, and other video content.",H04N 19/17; G06N 7/00; G06N 99/00; H04N 19/00,REVEALIT CORPORATION,"SMITH, Garry, Anthony; MONEYPENNY, Naomi, Felina; OAKES, Zachary; FLINN, Steven, Dennis; RENIE, Michael, George","62/475,942 24.03.2017 US",
WO2018075674,PCT/US2017/057243,18.10.2017,WO/2018/075674,26.04.2018,WO,AUTOMATED PRUNING OR HARVESTING SYSTEM FOR COMPLEX MORPHOLOGY FOLIAGE,"Method and apparatus for automated operations, such as pruning, harvesting, spraying and/or maintenance, on plants, and particularly plants with foliage having features on many length scales or a wide spectrum of length scales, such as female flower buds of the marijuana plant. The invention utilizes a convolutional neural network for image segmentation classification and/or the determination of features. The foliage is imaged stereoscopically to produce a three-dimensional surface image, a first neural network determines regions to be operated on, and a second neural network determines how an operation tool operates on the foliage. For pruning of resinous foliage the cutting tool is heated or cooled to avoid having the resins make the cutting tool inoperable.",G06F 15/18; G06K 9/00; G06T 7/00; G06N 3/08; A01G 3/00; B23Q 17/00,"BURDEN, Keith Charles","BURDEN, Keith Charles","15/331,841 22.10.2016 US",CA-3040334; IL-265952; CN-201780065154.0; EP-2017862970; MX-MX/a/2019/004247
WO2019083809,PCT/US2018/056460,18.10.2018,WO/2019/083809,02.05.2019,WO,VR BODY TRACKING WITHOUT EXTERNAL SENSORS,"Plural individual sensor assemblies (1700) are engaged with respective parts of a person's body. Each assembly may include accelerometers, magnetometers, and gyroscopes. Sensor data is fused together to get the orientation at each body location. To simplify, the body is assumed to consist of rigid bars of known length connected with ball joints so that once the relative orientations of all bars are given by the respective assemblies, body pose can be computed (1802). Then the body pose is translated as a virtual body into a virtual world either by a ray cast method that anchors a foot of the virtual body to the ground assuming infinite gravity and infinite friction and then translating the other body parts to make the ground contact point fixed, or by implementing an approximate dynamics physics engine on the virtual body. The technique may be used in VR location-based entertainment and for motion capture.",A61B 5/11; A61B 5/04,"SONY INTERACTIVE ENTERTAINMENT INC.; BASHKIROV, Sergey; MATSUKAWA, Takeo","BASHKIROV, Sergey; MATSUKAWA, Takeo","15/791,029 23.10.2017 US",
WO2019081705,PCT/EP2018/079401,26.10.2018,WO/2019/081705,02.05.2019,WO,USING HIERARCHICAL REPRESENTATIONS FOR NEURAL NETWORK ARCHITECTURE SEARCHING,"A computer-implemented method for automatically determining a neural network architecture represents a neural network architecture as a data structure defining a hierarchical set of directed acyclic graphs in multiple levels. Each graph has an input, an output, and a plurality of nodes between the input and the output. At each level, a corresponding set of the nodes are connected pairwise by directed edges which indicate operations performed on outputs of one node to generate an input to another node. Each level is associated with a corresponding set of operations. At a lowest level, the operations associated with each edge are selected from a set of primitive operations. The method includes repeatedly generating new sample neural network architectures, and evaluating their fitness. The modification is performed by selecting a level, selecting two nodes at that level, and modifying, removing or adding an edge between those nodes according to operations associated with lower levels of the hierarchy.",G06N 3/08; G06N 3/04,DEEPMIND TECHNOLOGIES LIMITED,"FERNANDO, Chrisantha Thomas; SIMONYAN, Karen; KAVUKCUOGLU, Koray; LIU, Hanxiao; VINYALS, Oriol","62/578,356 27.10.2017 US",
EP289344282,18853051,05.09.2018,3617921,04.03.2020,EP,VIDEO DISPLAY DEVICE AND OPERATING METHOD THEREFOR,"Provided is an artificial intelligence (Al) system simulating functions of a human brain, such as recognition and decision, by using a machine learning algorithm, such as deep-learning.Image display apparatuses are more convenient for a user, by performing user authentication by using an authentication image set generated based on an object recognized from content viewed by the user.",G06F 21/36; G06F 16/00; G06N 3/08; G06T 7/11,SAMSUNG ELECTRONICS CO LTD,CHO EUN-AE; KIM JIN-HYUN; PARK GI-HOON; KWON JAE-OOK,20170113352 05.09.2017 KR; 20180083651 18.07.2018 KR; 2018010350 05.09.2018 KR,
WO2018229490,PCT/GB2018/051631,14.06.2018,WO/2018/229490,20.12.2018,WO,A SYSTEM AND COMPUTER-IMPLEMENTED METHOD FOR SEGMENTING AN IMAGE,"A computer-implemented method for segmenting an input image, the method comprises: generating a first segmentation of the input image using a first machine learning system, the first segmentation comprising multiple segments; receiving, from a user, at least one indication, wherein each indication corresponds to a particular segment from the multiple segments, and indicates one or more locations of the input image as belonging to that particular segment; constructing, for each segment of the multiple segments having at least one corresponding indication, a respective geodesic distance map, based on the input image and the user indications received for that segment; and generating a second segmentation using a second machine learning system based on the input image and the constructed geodesic distance maps.",G06T 7/00; G06T 7/11,UCL BUSINESS LTD,"WANG, Guotai; VERCAUTEREN, Tom; OURSELIN, Sebastien; LI, Wenqi; FIDON, Lucas",1709672.8 16.06.2017 GB,EP-2018734897
WO2019160611,PCT/US2018/067684,27.12.2018,WO/2019/160611,22.08.2019,WO,SYSTEM AND METHOD FOR DYNAMIC ROBOT CONFIGURATION FOR ENHANCED DIGITAL EXPERIENCES,"The present teaching relates to method, system, medium, and implementations for configuring an animatronic device. Information is received about performance of a user exhibited in a dialogue between the user and an animatronic device which conducts the dialogue with the user in accordance with a configuration. The effectiveness of the configuration with respect to the user is assessed based on the information about the performance of the user and is used for machine learning at least one model, which is then used to adjust the configuration to generate an updated configuration for the animatronic device to use to continue the dialogue.",G06F 19/00,"DMAI, INC.","NELSON, Jeremy","62/630,909 15.02.2018 US",
WO2018084941,PCT/US2017/052083,18.09.2017,WO/2018/084941,11.05.2018,WO,TEMPORAL DIFFERENCE ESTIMATION IN AN ARTIFICIAL NEURAL NETWORK,A method of computation in a deep neural network includes discretizing input signals and computing a temporal difference of the discrete input signals to produce a discretized temporal difference. The method also includes applying weights of a first layer of the deep neural network to the discretized temporal difference to create an output of a weight matrix. The output of the weight matrix is temporally summed with a previous output of the weight matrix. An activation function is applied to the temporally summed output to create a next input signal to a next layer of the deep neural network.,G06N 3/04,QUALCOMM INCORPORATED,"O'CONNOR, Peter; WELLING, Max","62/417,224 03.11.2016 US; 15/590,609 09.05.2017 US",
WO2019171291,PCT/IB2019/051807,06.03.2019,WO/2019/171291,12.09.2019,WO,EPISTEMIC AND ALEATORIC DEEP PLASTICITY BASED ON SOUND FEEDBACK,Simulating uncertainty in an artificial neural network is provided. Aleatoric uncertainty is simulated to measure what the artificial neural network does not understand from sensor data received from an object operating in a real-world environment by adding random values to edge weights between nodes in the artificial neural network during backpropagation of output data of the artificial neural network and measuring impact on the output data by the added random values to the edge weights between the nodes. Epistemic uncertainty is simulated to measure what the artificial neural network does not know by dropping out a selected node from each respective layer of the artificial neural network during forward propagation of the sensor data and measuring impact of dropped out nodes on the output data of the artificial neural network. An action corresponding to the object is performed based on the impact of simulating the aleatoric and epistemic uncertainty.,G06N 3/02,INTERNATIONAL BUSINESS MACHINES CORPORATION; IBM UNITED KINGDOM LIMITED; IBM (CHINA) INVESTMENT COMPANY LIMITED,"BAUGHMAN, Aaron; HAMMER, Stephen; FORSTER, Micah","15/914,222 07.03.2018 US",
WO2018185763,PCT/IL2018/050393,03.04.2018,WO/2018/185763,11.10.2018,WO,NEURAL NETWORK PROCESSOR INCORPORATING SEPARATE CONTROL AND DATA FABRIC,"A novel and useful neural network (NN) processing core adapted to implement artificial neural networks (ANNs) and incorporating strictly separate control and data planes. The NN processor is constructed from self-contained computational units organized in a hierarchical architecture. The homogeneity enables simpler management and control of similar computational units, aggregated in multiple levels of hierarchy. Computational units are designed with minimal overhead as possible, where additional features and capabilities are aggregated at higher levels in the hierarchy. On-chip memory provides storage for content inherently required for basic operation at a particular hierarchy and is coupled with the computational resources in an optimal ratio. Lean control provides just enough signaling to manage only the operations required at a particular hierarchical level. Dynamic resource assignment agility is provided which can be adjusted as required depending on resource availability and capacity of the device.",G06N 3/063; G06N 3/04; G06F 17/50,HAILO TECHNOLOGIES LTD.,"BAUM, Avi; DANON, Or; ZEITLIN, Hadar; CIUBOTARIU, Daniel; FEIG, Rami","62/481,492 04.04.2017 US; 62/531,372 12.07.2017 US",CN-201880022239.5; JP-2019554909; EP-2018780642
EP232545773,18163730,23.03.2018,3396600,31.10.2018,EP,NEURAL NETWORK OPTIMIZATION MECHANISM,"An apparatus to facilitate optimization of a neural network (NN) is disclosed. The apparatus includes optimization logic to define a NN topology having one or more macro layers, adjust the one or more macro layers to adapt to input and output components of the NN and train the NN based on the one or more macro layers.",G06N 3/04; G06N 3/063; G06N 3/08,INTEL CORP,SRINIVASA NARAYAN; RAY JOYDEEP; GALOPPO VON BORRIES NICOLAS C; ASHBAUGH BEN; SURTI PRASOONKUMAR; CHEN FENG; LAKSHMANAN BARATH; OULD-AHMED-VALL ELMOUSTAPHA; MA LIWEI; HURD LINDA L; APPU ABHISHEK R; WEAST JOHN C; BAGHSORKHI SARA S; GOTTSCHLICH JUSTIN E; SAKTHIVEL CHANDRASEKARAN; AKHBARI FARSHAD; KIM DUKHWAN; KOKER ALTUG; SATISH NADATHUR RAJAGOPALAN,201715494948 24.04.2017 US,
WO2020016786,PCT/IB2019/056080,16.07.2019,WO/2020/016786,23.01.2020,WO,SURGICAL VISUALIZATION PLATFORM,"A surgical visualization system is disclosed. The surgical visualization system is configured to identify one or more structure(s) and/or determine one or more distances with respect to obscuring tissue and/or the identified structure(s). The surgical visualization system can facilitate avoidance of the identified structure(s) by a surgical device. The surgical visualization system can comprise a first emitter configured to emit a plurality of tissue-penetrating light waves and a second emitter configured to emit structured light onto the surface of tissue. The surgical visualization system can also include an image sensor configured to detect reflected visible light, tissue-penetrating light, and/or structured light. The surgical visualization system can convey information to one or more clinicians regarding the position of one or more hidden identified structures and/or provide one or more proximity indicators.",A61B 5/00; A61B 5/107; A61B 90/00; A61B 34/30; A61B 90/30; G01B 11/25; G01N 21/25; G01N 21/31; G01S 17/89,ETHICON LLC,"SCHEIB, Charles J.; RITCHIE, Paul G.; MOORE, Sarah A.; SWAYZE, Jeffrey S.; TALBERT, Joshua D.","62/698,625 16.07.2018 US; 16/128,179 11.09.2018 US; 16/128,191 11.09.2018 US",
WO2018184222,PCT/CN2017/079771,07.04.2017,WO/2018/184222,11.10.2018,WO,METHODS AND SYSTEMS USING IMPROVED TRAINING AND LEARNING FOR DEEP NEURAL NETWORKS,"Methods and systems are disclosed using improved training and learning for deep neural networks. In one example, a deep neural network includes a plurality of layers, and each layer has a plurality of nodes. For each L layer in the plurality of layers, the nodes of each L layer are randomly connected to nodes in a L+1 layer. For each L+1 layer in the plurality of layers, the nodes of each L+1 layer are connected to nodes in a subsequent L layer in a one-to-one manner. Parameters related to the nodes of each L layer are fixed. Parameters related to the nodes of each L+1 layers are updated, and L is an integer starting with 1. In another example, a deep neural network includes an input layer, output layer, and a plurality of hidden layers. Inputs for the input layer and labels for the output layer are determined related to a first sample. Similarity between different pairs of inputs and labels between a second sample with the first sample is estimated using Gaussian regression process.",G06N 3/02; G06N 3/04; G06N 3/08,"INTEL CORPORATION; GUO, Yiwen; YAO, Anbang; CAI, Dongqi; WANG, Libin; XU, Lin; HU, Ping; WANG, Shandong; CHENG, Wenhua; CHEN, Yurong","GUO, Yiwen; YAO, Anbang; CAI, Dongqi; WANG, Libin; XU, Lin; HU, Ping; WANG, Shandong; CHENG, Wenhua; CHEN, Yurong",,EP-2017904931; CN-201780088106.3
EP194955005,16192602,06.10.2016,3154053,12.04.2017,EP,SPEECH RECOGNITION APPARATUS AND METHOD WITH ACOUSTIC MODELLING,"Provided is a speech recognition apparatus. The apparatus includes a preprocessor configured to extract select frames from all frames of a first speech of a user, and a score calculator configured to calculate an acoustic score of a second speech, made up of the extracted select frames, by using a Deep Neural Network (DNN)-based acoustic model, and to calculate an acoustic score of frames, of the first speech, other than the select frames based on the calculated acoustic score of the second speech.",G10L 15/16,SAMSUNG ELECTRONICS CO LTD,SONG IN CHUL,20150140646 06.10.2015 KR,
WO2020016870,PCT/IB2019/057341,30.08.2019,WO/2020/016870,23.01.2020,WO,SAFETY LOGIC FOR SURGICAL SUTURING SYSTEMS,"A surgical suturing tracking system (5700) configured for use with a suturing needle (5703) is disclosed. The surgical suturing tracking system (5700) comprises a spectral light emitter, a waveform sensor, and a control circuit coupled to the waveform sensor. The control circuit is configured to cause the spectral light emitter to emit spectral light waves toward a suturing needle and a tissue structure, receive an input corresponding to the spectral light waves reflected by the needle and the tissue structure and determine a distance between the needle and the tissue structure based on the received input.",A61B 1/00; A61B 1/04; A61B 1/06; A61B 5/00; A61B 5/107; A61B 34/30; A61B 90/30; A61B 90/00; G01B 11/25; G01N 21/25; G01N 21/31; G01S 17/89; A61B 17/04; A61B 17/062,ETHICON LLC,"SCHEIB, Charles J.; RITCHIE, Paul G.; MOORE, Sarah A.; SWAYZE, Jeffrey S.; TALBERT, Joshua D.; YOUNG, Joshua D.; MORENO, Victor C.","62/698,625 16.07.2018 US; 16/128,170 11.09.2018 US; 16/128,183 11.09.2018 US",
WO2019107674,PCT/KR2018/003912,03.04.2018,WO/2019/107674,06.06.2019,WO,COMPUTING APPARATUS AND INFORMATION INPUT METHOD OF THE COMPUTING APPARATUS,"Provided are a method and apparatus for classifying and storing input information based on machine learning and artificial intelligence and automatically inputting the stored information. According to an exemplary embodiment, input information is classified and stored using machine learning, an input item to which the stored input information is to be input is identified using machine learning, and the stored input information is input to the input item.",G06K 9/62; G06N 99/00; G06K 9/32,"SAMSUNG ELECTRONICS CO., LTD.","HAN, Jun Kyu",10-2017-0163447 30.11.2017 KR,
WO2017196822,PCT/US2017/031722,09.05.2017,WO/2017/196822,16.11.2017,WO,SYSTEM AND METHOD FOR COMPUTER VISION DRIVEN APPLICATIONS WITHIN AN ENVIRONMENT,"A system and method for computer vision driven applications in an environment that can include collecting image data across an environment; maintaining an environmental object graph from the image data whereby maintaining the environmental object graph is an iterative process that includes: classifying objects, tracking object locations, detecting interaction events, instantiating object associations in the environmental object graph, and updating the environmental object graph by propagating change in at least one object instance across object associations; and inspecting object state for at least one object instance in the environmental object graph and executing an action associated with the object state. The system and method can be applied to automatic checkout, inventory management, and/or other system integrations.",A47F 9/00; A47F 9/02; A47F 9/04; G06K 9/00; G06K 15/00; G06Q 30/00; G06Q 30/06,GRABANGO CO.,"GLASER, William; VAN OSDOL, Brian","62/333,668 09.05.2016 US",JP-2018557901; CN-201780041801.4; EP-2017796677
WO2013086257,PCT/US2012/068346,07.12.2012,WO/2013/086257,13.06.2013,WO,CLUSTERING OBJECTS DETECTED IN VIDEO,"Identification of facial images representing both animate and inanimate objects appearing in media, such as videos, may be performed using clustering. Clusters contain facial images representing the same or similar objects, providing a database for future automated facial image identification to be performed more quickly and easily. Clustering also allows videos or other media to be indexed so that segments that contain a certain object may be found without having to search through the entire length of the media. Clustering involves separating media data into individual frames and filtering for frames with facial images. A digital media processor may then process each facial image, compare it to other facial images, and form clusterizer tracks with the objective of forming a cluster. These newly formed clusters may be compared with previously formed clusters via key faces in order to determine the identity of facial images contained in the clusters.",G06K 9/00; G06F 17/30,"VIEWDLE, INC.","MITURA, Michael Jason; MUSATENKO, Yuriy S.,; KOVTUN, Ivan,; OTCHENASHKO, Denis; TSAROV, Andril,; GIL, Laurent,","61/569,168 09.12.2011 US; 13/706,371 06.12.2012 US",
WO1998000793,PCT/US1997/011160,27.06.1997,WO/1998/000793,08.01.1998,WO,METHOD AND SYSTEM FOR COMPUTING SEMANTIC LOGICAL FORMS FROM SYNTAX TREES,"Methods and computer systems for semantically analyzing natural language sentences. The natural language processing subsystems for morphological and syntactic analysis transform an input sentence into a syntax parse tree. Semantic analysis applies three sets of semantic rules to create a skeletal logical form graph from a syntax parse tree. Semantic analysis then applies two additional sets of semantic rules to provide semantically meaningful labels for the links of the logical form graph, to create additional logical form graph nodes for missing elements, and to unify redundant elements. The final logical form graph represents the complete semantic analysis of an input sentence.",G06F 17/27,MICROSOFT CORPORATION,"HEIDORN, George; JENSEN, Karen","08/674,610 28.06.1996 US",CN-97196852.7; EP-1997932316
EP290833375,19199528,04.04.2018,3624018,18.03.2020,EP,NEURAL NETWORK COMPUTATION DEVICE AND METHOD,"The present disclosure provides a computation device including: a computation module for executing a neural network computation, and a power conversion module connected to the computation module, for converting input data and/or output data of the neural network computation into power data. The present disclosure further provides a computation method. The computation device and method of the present disclosure may reduce the cost of storage resources and computing resources, and may increase the computation speed.",G06N 3/04; G06N 3/063,SHANGHAI CAMBRICON INFORMATION TECH CO LTD,ZHANG LEI; LIU SHAOLI; HU SHUAI; CHEN TIANSHI,201710222232 06.04.2017 CN; 201710227493 07.04.2017 CN; 201710256444 19.04.2017 CN; 201710266052 21.04.2017 CN; 201710312415 05.05.2017 CN; 2018081929 04.04.2018 CN; 18780474 04.04.2018 EP,
WO2018217829,PCT/US2018/033987,22.05.2018,WO/2018/217829,29.11.2018,WO,METHODS AND APPARATUS FOR ENHANCING A NEURAL NETWORK USING BINARY TENSOR AND SCALE FACTOR PAIRS,"Methods and apparatus are disclosed for enhancing a neural network using binary tensor and scale factor pairs. For one example, a method of optimizing a trained convolutional neural network (CNN) includes initializing an approximation residue as a trained weight tensor for the trained CNN. A plurality of binary tensors and scale factor pairs are determined. The approximation residue is updated using the binary tensors and scale factor pairs.",G06N 3/04; G06N 3/08,INTEL CORPORATION,"GUO, Yiwen; YAO, Anbang; ZHAO, Hao; LU, Ming; CHEN, Yurong","62/510,025 23.05.2017 US",CN-201880026768.2; EP-2018805760
WO2018033591,PCT/EP2017/070822,17.08.2017,WO/2018/033591,22.02.2018,WO,APPARATUS COMPRISING A SUPPORT SYSTEM FOR A USER AND ITS OPERATION IN A GRAVITY-ASSIST MODE,"The present application relates to devices and systems for rehabilitation of the locomotor system, for example limbs. In particular, the present application discloses an apparatus, more in particular a robotic platform capable of optimizing gravity-dependent trunk movements, enabling overground locomotion in non-ambulatory individuals with spinal cord injury and stroke, while promoting durable motor improvement when delivered during gait rehabilitation facilitated by electrical spinal cord stimulation.",A61N 1/05; A61B 5/00; A61B 5/04; A61B 5/0476; A61B 5/0488; A61B 5/11; A61N 1/36; A63B 24/00; A63B 69/00; A61H 1/02; B25J 9/00; A61H 3/00; A61G 7/10,ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE (EPFL),"VON ZITZEWITZ, Joachim; MIGNARDOT, Jean Baptiste; LE GOFF, Camille Georgette Marie; COURTINE, Grégoire; VALLERY, Heike",16184544.1 17.08.2016 EP,CN-201780063362.7; EP-2017758830
WO2019139922,PCT/US2019/012774,08.01.2019,WO/2019/139922,18.07.2019,WO,METHODS AND APPARATUS FOR BIO-FLUID SPECIMEN CHARACTERIZATION USING NEURAL NETWORK HAVING REDUCED TRAINING,"A method of training a neural network (Convolutional Neural Network - CNN) including reduced graphical annotation input is provided. The training method can be used to train a Testing CNN that can be used for determining Hemolysis (H), Icterus (I), and/or Lipemia (L), or Normal (N) of a serum or plasma portion of a test specimen. The training method includes capturing training images of multiple specimen containers including training specimens, generating region proposals of the serum or plasma portions of the training specimens; and selecting the best matches for the location, size and shape of the region proposals for the multiple training specimens. The obtained features (network and weights) from the training CNN can be used in a testing CNN. Quality check modules and testing apparatus adapted to carry out the training method, and characterization methods using a bounding box regressor are described, as are other aspects.",G01N 21/31; G01N 33/49,SIEMENS HEALTHCARE DIAGNOSTICS INC.,"KLUCKNER, Stefan; CHANG, Yao-Jen; MA, Kai; SINGH, Vivek; CHEN, Terrence; POLLACK, Benjamin S.","62/615,873 10.01.2018 US",
WO2018222904,PCT/US2018/035446,31.05.2018,WO/2018/222904,06.12.2018,WO,TENSOR-BASED COMPUTING SYSTEM FOR QUATERNION OPERATIONS,"A machine-learning system includes a quaternion (QT) computation engine. Input data to the QT computation engine includes quaternion values, each comprising a real component and three imaginary components, represented as a set of real-valued tensors. A single quaternion value is represented as a 1-dimensional real-valued tensor having four real-valued components, wherein a first real-valued component represents the real component of the single quaternion value, and wherein a second, a third, and a fourth real-valued component each respectively represents one of the imaginary components. A quaternion-valued vector having a size N is represented as a 2-dimensional real-valued tensor comprising N 1-dimensional real-valued tensors. A quaternion-valued matrix having N x M dimensions is represented as a 3-dimensional real-valued tensor comprising M 2-dimensional real-valued tensors comprising N 1-dimensional real-valued tensors.",G06N 99/00,INTEL CORPORATION,"MARTINEZ-CANALES, Monica Lucia; SINGH, Sudhir K.; SHARMA, Vinod; BHANDARU, Malini Krishnan","62/513,390 31.05.2017 US",EP-2018809474; CN-201880028672.X
WO2018185765,PCT/IL2018/050395,03.04.2018,WO/2018/185765,11.10.2018,WO,NEURAL NETWORK PROCESSOR INCORPORATING INTER-DEVICE CONNECTIVITY,"A novel and useful neural network (NN) processing core incorporating inter-device connectivity and adapted to implement artificial neural networks (ANNs). A chip-to-chip interface spreads a given ANN model across multiple devices in a seamless manner. The NN processor is constructed from self-contained computational units organized in a hierarchical architecture. The homogeneity enables simpler management and control of similar computational units, aggregated in multiple levels of hierarchy. Computational units are designed with minimal overhead as possible, where additional features and capabilities are aggregated at higher levels in the hierarchy. On-chip memory provides storage for content inherently required for basic operation at a particular hierarchy and is coupled with the computational resources in an optimal ratio. Lean control provides just enough signaling to manage only the operations required at a particular hierarchical level. Dynamic resource assignment agility is provided which can be adjusted as required depending on resource availability and capacity of the device.",G06N 3/063; G06F 17/50,HAILO TECHNOLOGIES LTD.,"BAUM, Avi; DANON, Or; ZEITLIN, Hadar; CIUBOTARIU, Daniel; FEIG, Rami","62/481,492 04.04.2017 US; 62/531,372 12.07.2017 US",JP-2019555011; CN-201880022145.8; EP-2018781194
WO2019155064,PCT/EP2019/053322,11.02.2019,WO/2019/155064,15.08.2019,WO,"DATA COMPRESSION USING JOINTLY TRAINED ENCODER, DECODER, AND PRIOR NEURAL NETWORKS","Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for training an encoder neural network, a decoder neural network, and a prior neural network, and using the trained networks for generative modeling, data compression, and data decompression. In one aspect, a method comprises: providing a given observation as input to the encoder neural network to generate parameters of an encoding probability distribution; determining an updated code for the given observation; selecting a code that is assigned to an additional observation; providing the code assigned to the additional observation as input to the prior neural network to generate parameters of a prior probability distribution; sampling latent variables from the encoding probability distribution; providing the latent variables as input to the decoder neural network to generate parameters of an observation probability distribution; and determining gradients of a loss function.",G06N 3/04; G06N 3/08; G06N 3/00; G10L 19/00; H03M 7/40,DEEPMIND TECHNOLOGIES LIMITED,"MENICK, Jacob Lee; GRAVES, Alexander Benjamin","62/628,908 09.02.2018 US",
EP241458895,18201567,19.10.2018,3474194,24.04.2019,EP,METHOD AND APPARATUS WITH NEURAL NETWORK PARAMETER QUANTIZATION,"Provided is a processor implemented method that includes performing training or an inference operation with a neural network by obtaining a parameter for the neural network in a floating-point format, applying a fractional length of a fixed-point format to the parameter in the floating-point format, performing an operation with an integer arithmetic logic unit (ALU) to determine whether to round off a fixed point based on a most significant bit among bit values to be discarded after a quantization process, and performing an operation of quantizing the parameter in the floating-point format to a parameter in the fixed-point format, based on a result of the operation with the ALU.",G06N 3/063,SAMSUNG ELECTRONICS CO LTD,KANG SHINHAENG; LEE SEUNGWON,20170135868 19.10.2017 KR,
WO2020008339,PCT/IB2019/055608,01.07.2019,WO/2020/008339,09.01.2020,WO,SENSING SYSTEM AND METHOD FOR MONITORING TIME-DEPENDENT PROCESSES,"Systems and methods for detecting the quality of signals captured by a sensor device monitoring a biological function. Sensor data associated with the sensor device is received, the sensor data representing time -series measurement samples of one or more parameters associated with the biological function, the sensor data including usable and unusable samples of the time- series measurements. Data representing two or more features of samples of the time-series measurements is extracted and filtered to reduce outliers in the extracted data based on an expected outlier ratio. A machine learning algorithm is then trained to identify events based on the filtered extracted data.",A61B 5/00; A61B 5/08; G06F 19/10; G06F 19/24; G16H 50/20; G16H 50/70,3M INNOVATIVE PROPERTIES COMPANY,"TAGHVAEEYAN, Saber; GOLNARI, Golshan; KADKHODAIE ELYADERANI, Mojtaba; SHANNON, Robert W.; BARTON, Roger W.; PACHAURI, Deepti","62/693,364 02.07.2018 US",
WO2016159961,PCT/US2015/023417,30.03.2015,WO/2016/159961,06.10.2016,WO,VOICE DRIVEN OPERATING SYSTEM FOR INTERFACING WITH ELECTRONIC DEVICES,"A system comprising an electronic device, a means for the electronic device to receive input text, a means to generate a response wherein the means to generate the response is a software architecture organized in the form of a stack of functional elements. These functional elements comprise an operating system kernel whose blocks and elements are dedicated to natural language processing, a dedicated programming language specifically for developing programs to run on the operating system, and one or more natural language processing applications developed employing the dedicated programming language, wherein the one or more natural language processing applications may run in parallel. Moreover, one or more of these natural language processing applications employ an emotional overlay.",G06F 17/20; G06F 3/16; G06N 7/02,"CUBIC ROBOTICS, INC.; KRESTNIKOV, Konstantin; BUROV, Yuri; SHALABY, Nadia; GRJAZNOV, Andrej","KRESTNIKOV, Konstantin; BUROV, Yuri; SHALABY, Nadia; GRJAZNOV, Andrej",2014111971 30.03.2015 RU,
WO2019053052,PCT/EP2018/074585,12.09.2018,WO/2019/053052,21.03.2019,WO,A METHOD FOR (RE-)TRAINING A MACHINE LEARNING COMPONENT,"A computer-implemented method, comprising: evolving a set of augmented training data (209) and training a machine learning component (204) by: synthesizing (304) a set of augmentation data (204) based on a set of parameter values in accordance with a parametric representation of an artefact; generating (305) a set of augmented training data (209) by augmenting training data (203) based on the augmentation data (204); evolving (309) the set of augmented training data (209) over generations based on evolving the set of parameter values in accordance with optimization of a fitness function, which is configured to reward a performance deficiency associated with an output produced by the machine learning component in response to receiving augmented training data (209) as its input; among the augmented training data (209), determining (310) a set of adversarial augmented training data (211) which are augmented training data in the set of augmented training data (209) that caused a performance deficiency associated with an output produced by the machine learning component (204) in response to receiving augmented training data as its input; and training the machine learning (204) component based on the set of adversarial training data (211). The computer-implemented method is related to improve machine learning component for self-driving cars and image-based identification of persons.",G09B 9/00; G06N 3/08; G06N 3/04,ITU BUSINESS DEVELOPMENT A/S,"RISI, Sebastian; TOGELIUS, Julian; SHAKER, Noor",PA201770681 12.09.2017 DK,
EP291472785,18465576,20.09.2018,3627403,25.03.2020,EP,TRAINING OF A ONE-SHOT LEARNING CLASSIFIER,"The present disclosure is related to a method for training a one-shot learning classifier, as well as to a computer program code and a one-shot learning classifier implementing said method. In a first step, an input training sample is received (10) . A set of synthetic training samples is then generated (11) from the input training sample. For this purpose a set of generalization functions is used. Finally, a deep neural network classifier is trained (12) on the set of synthetic training samples.",G06N 7/00; G06N 3/04; G06N 3/08; G06N 5/00,ELEKTROBIT AUTOMOTIVE GMBH,GRIGORESCU SORIN MIHAI,18465576 20.09.2018 EP,
WO2019067238,PCT/US2018/051105,14.09.2018,WO/2019/067238,04.04.2019,WO,MOBILE AND AUTONOMOUS PERSONAL COMPANION BASED ON AN ARTIFICIAL INTELLIGENCE (AI) MODEL FOR A USER,"A method for building an artificial intelligence (AI) model. The method includes accessing data related to monitored behavior of a user. The data is classified, wherein the classes include an objective data class identifying data relevant to a group of users including the user, and a subjective data class identifying data that is specific to the user. Objective data is accessed and relates to monitored behavior of a plurality of users including the user. The method includes providing as a first set of inputs into a deep learning engine performing AI the objective data and the subjective data of the user, and a plurality of objective data of the plurality of users. The method includes determining a plurality of learned patterns predicting user behavior when responding to the first set of inputs. The method includes building a local AI model of the user including the plurality of learned patterns.",G06N 3/00; G06N 20/00,"SONY INTERACTIVE ENTERTAINMENT INC.; BERAN, Erik","BERAN, Erik; TAYLOR, Michael; OMOTE, Masanori","15/724,011 03.10.2017 US; 62/566,170 29.09.2017 US",
WO2017091751,PCT/US2016/063641,23.11.2016,WO/2017/091751,01.06.2017,WO,DEPLOYED END-TO-END SPEECH RECOGNITION,"Embodiments of end-to-end deep learning systems and methods are disclosed to recognize speech of vastly different languages, such as English or Mandarin Chinese. In embodiments, the entire pipelines of hand-engineered components are replaced with neural networks, and the end-to-end learning allows handling a diverse variety of speech including noisy environments, accents, and different languages. Using a trained embodiment and an embodiment of a batch dispatch technique with GPUs in a data center, an end-to-end deep learning system can be inexpensively deployed in an online setting, delivering low latency when serving users at scale.",G10L 15/16; G10L 15/06; G10L 15/08; G10L 15/183,BAIDU USA LLC,"CATANZARO, Bryan; CHEN, Jingdong; CHRZANOWSKI, Mike; ELSEN, Erich; ENGEL, Jesse; FOUGNER, Christopher; HAN, Xu; HANNUN, Awni; PRENGER, Ryan; SATHEESH, Sanjeev; SENGUPTA, Shubhabrata; YOGATAMA, Dani; WANG, Chong; ZHAN, Jun; ZHU, Zhenyao; AMODEI, Dario","62/260,206 25.11.2015 US; 15/358,102 21.11.2016 US; 15/358,083 21.11.2016 US",JP-2017544340; KR-1020177023173
EP232545687,18162625,19.03.2018,3396528,31.10.2018,EP,DYNAMIC DISTRIBUTED TRAINING OF MACHINE LEARNING MODELS,"In an example, an apparatus comprises a plurality of execution units comprising at least a first type of execution unit and a second type of execution unit and logic, at least partially including hardware logic, to analyze a workload and assign the workload to one of the first type of execution unit or the second type of execution unit. Other embodiments are also disclosed and claimed.",G06F 9/28; G06F 9/50; G06N 3/04; G06N 3/063,INTEL CORP,KOKER ALTUG; APPU ABHISHEK R; SINHA KAMAL; RAY JOYDEEP; VEMBU BALAJI; OULD-AHMED-VALL ELMOUSTAPHA; BAGHSORKHI SARA S; YAO ANBANG; NEALIS KEVIN; CHEN XIAOMING; WEAST JOHN C; GOTTSCHLICH JUSTIN E; SURTI PRASOONKUMAR; SAKTHIVEL CHANDRASEKARAN; AKHBARI FARSHAD; SATISH NADATHUR RAJAGOPALAN; MA LIWEI; BOTTLESON JEREMY; NURVITADHI ERIKO; SCHLUESSLER TRAVIS T; SHAH ANKUR N; KENNEDY JONATHAN; RANGANATHAN VASANTH; JAHAGIRDAR SANJEEV,201715494971 24.04.2017 US,
WO2018160751,PCT/US2018/020303,28.02.2018,WO/2018/160751,07.09.2018,WO,SYSTEMS AND METHODS USING ARTIFICIAL NEURAL NETWORK ANALYSIS ON FLOW CYTOMETRY DATA FOR CANCER DIAGNOSIS,"The present disclosure provides devices and systems for diagnosing and characterizing cancer in a subject. Devices include flow cytometry systems useful for the isolation and characterization of cells from a subject, and artificial neural networks for analysis of flow cytometry data.",G06F 19/00; G06F 19/20; G06N 3/04; G01N 33/574,ANIXA DIAGNOSTICS CORPORATION,"KUMAR, Amit; ROOP, John; CAMPISI, Anthony J.","15/445,913 28.02.2017 US",EP-2018761495; CN-201880028146.3; CA-3054800
WO2016037160,PCT/US2015/048742,06.09.2015,WO/2016/037160,10.03.2016,WO,FOREIGN OBJECT DETECTION PROTOCOL SYSTEM AND METHOD,"The present invention relates to the coupling of medical procedures with protocols and advanced software applications, coordinating existing medical procedures and protocols with image detection software to integrate and enhance the identification of IMDs and the detection of RSIs. In one aspect, the emergency room or the operating room protocol is modified so that a scan or XR of the patient is taken for identification of any IMD's. In another aspect, the operating room protocol is modified so that there is an additional step of calibrating an intraoperative or post-operative scans or XR specifically for detecting RSIs and / or identifying IMDs in addition to any scans or XRs performed for the purpose of monitoring the treatment of the patient. In a further aspect, the image processing may be managed conducted in a remote location, using public key encryption to de-identify the personal information associated with the image.",A61B 6/12; G06T 7/00; G06F 19/00; A61B 6/10,"RAPID MEDICAL TECHNOLOGIES, LLC","GLUNCIC, Vicko; AGAM, Gady; MORIC, Mario; RICHARD, Shirley, Virginia; LIN, Gan; ERDMAN, Kevin, Richard","62/116,384 14.02.2015 US; 62/046,925 06.09.2014 US; 62/046,926 06.09.2014 US",EP-2015837652
EP217785388,17200472,07.11.2017,3323566,23.05.2018,EP,A FEEDER AND METHOD FOR FEEDING COMPONENTS INTO AN ASSEMBLY LINE,"A system for presenting isolated components to an assembly line over a plurality of cycles includes a container configured to direct components towards a central axis. An elongated pedestal within the container has ribs which define a flat upper surface and a plurality of channels. The pedestal is reciprocally mounted to move along the central axis, and isolates components during each cycle. The isolated components are transferred to an assembly line.",B25J 9/16; B65G 47/14,SENSATA TECHNOLOGIES INC,RYDER MATTHEW,201615353345 16.11.2016 US,
EP236491133,17766620,13.03.2017,3432228,23.01.2019,EP,EXPANDABILITY RETENTION DEVICE,"A mechanism for increasing efficiency of development work for adding a new ability to a device is provided. Also, a device with excellent extensibility, having a mechanism for easily adding a new ability provided from the outside, is provided. A device with extensibility includes an architecture modeled as an ability acquisition model including an ability unit for implementing an ability, an data input unit that is an interface for an input from the ability unit, and a data output unit that is an interface for an output from the ability unit, as an architecture for additionally incorporating a new ability to a basic configuration of the device, and includes an ability setting unit for adding the new ability to the device by setting a function to each of the ability unit, the data input unit, and the data output unit, based on ability providing data including ability setting data, input setting data, and output setting data.",G06N 99/00; G05B 13/02; G06F 9/445; G06F 16/25; G06N 3/02; G06N 7/02; G06N 20/00; G10L 15/16,OMRON TATEISI ELECTRONICS CO,ANDO TANICHI,2016049438 14.03.2016 JP; 2017009997 13.03.2017 JP,
WO2017157112,PCT/CN2017/073070,07.02.2017,WO/2017/157112,21.09.2017,WO,METHOD AND SYSTEM FOR BIT-DEPTH REDUCTION IN ARTIFICIAL NEURAL NETWORKS,"A bit-depth optimization engine reduces the hardware cost of a neural network. When training data is applied to a neural network during training routines, accuracy cost and hardware costs are generated. A hardware complexity cost generator generates costs for weights near bit-depth steps where the number of binary bits required to represent a weight decreases, such as from 2N to 2N–1, where one less binary bit is required. Gradients are generated from costs for each weight, and weights near bit-depth steps are easily selected since they have a large gradient, while weights far away from a bit-depth step have near-zero gradients. The selected weights are reduced during optimization. Over many cycles of optimization, a low-bit-depth neural network is generated that uses fewer binary bits per weight, resulting in lower hardware costs when the low-bit-depth neural network is manufactured on an Application-Specific Integrated Circuit (ASIC).",G06N 3/08,HONG KONG APPLIED SCIENCE AND TECHNOLOGY RESEARCH INSTITUTE COMPANY LIMITED,"SHI, Chao; LIANG, Luhong; HUNG, Kwok Wai; CHIU, King Hung","62/309,239 16.03.2016 US; 15/415,810 25.01.2017 US",CN-201780000106.3
WO2020064134,PCT/EP2018/076533,28.09.2018,WO/2020/064134,02.04.2020,WO,RADIO-NETWORK SELF-OPTIMIZATION BASED ON DATA FROM RADIO NETWORK AND SPATIOTEMPORAL SENSORS,"A technique includes receiving, from one or more sensors, sensor data samples; receiving radio network information data samples associated with a radio network; determining, based on an association of one or more received sensor data samples with one or more of the received radio network information data samples, a first set of one or more associated sensor and radio network information data samples; developing a model that is trained based on at least a portion of the first set the associated sensor and radio network information data samples that are relevant to performance of the radio network; and improving performance of the radio network based on at least the model.",H04L 12/24; H04L 12/26,NOKIA TECHNOLOGIES OY,"VEIJALAINE, Teemu Mikael; KURU, Lauri Ilari; MOILANEN, Jani Matti Johannes; HONKALA, Mikko Johannes",,
WO2008053161,PCT/GB2007/004047,23.10.2007,WO/2008/053161,08.05.2008,WO,MACHINE LEARNING,"Computer implemented machine learning methods are described. A co-operative learning method involves a first rule based system and a second rule based system. A rule base is generated from input data and recursion data is used to recursively update the rule base as a result of newly received input data. Rule data defining at least one rule and associated data are sent to the second system which determines whether to update its rule base using the transmitted rule data, and if so the recursion data is used to recursively determine the updated rules for its rule base. A father machine learning method for a rule based system, involves receiving time series data, determining whether the data increases or decreases the spatial density for previously existing rules, and if so then creating a new cluster and associated rule, otherwise a new cluster is not created.",G06N 5/02,"THE UNIVERSITY OF LANCASTER; ANGELOV, Plamen","ANGELOV, Plamen",0621734.3 01.11.2006 GB; 0713632.8 13.07.2007 GB,EP-2007824295; US-12447859
WO2017059500,PCT/AU2016/050950,10.10.2016,WO/2017/059500,13.04.2017,WO,"FRAMEWORKS AND METHODOLOGIES CONFIGURED TO ENABLE STREAMLINED INTEGRATION OF NATURAL LANGUAGE PROCESSING FUNCTIONALITY WITH ONE OR MORE USER INTERFACE ENVIRONMENTS, INCLUDING ASSISTED LEARNING PROCESS","The present disclosure relates to frameworks and methodologies configured to enable streamlined integration of natural language processing functionality with user interface environments. For example, embodiments provide technology that enable integration of a natural language query processing functionality into existing use interface environments, such as websites (although websites are used as an illustrative example below, the technology is applicable to a wide range of other user interface environments). At a broad level, the technology allows a query to be submitted in natural language form (for example via text input and/or voice input), and for that query to be processed thereby to trigger an action that is specific to the user interface environment.",G06F 17/28,SAYITY PTY LTD,"PARTRIDGE, Matthew",2015904121 09.10.2015 AU; 2015905046 04.12.2015 AU; 2015905061 07.12.2015 AU,
WO2017079301,PCT/US2016/060118,02.11.2016,WO/2017/079301,11.05.2017,WO,CALIBRATION FOR AUTONOMOUS VEHICLE OPERATION,"Various embodiments relate generally to autonomous vehicles and associated mechanical, electrical and electronic hardware, computer software and systems, and wired and wireless network communications to provide an autonomous vehicle fleet as a service. In particular, a method may include receiving data associated with a sensor measurement of a perceived object, determining a label associated with the perceived object based on an initial calibration, retrieving log file data associated with the label, determining a calibration parameter associated with the sensor measurement based on the retrieved log file data, and storing the calibration parameter in association with a sensor associated with the sensor measurement. Sensors may be calibrated on the fly while the autonomous vehicle is in operation using one or more other sensors and/or fused data from multiple types of sensors.",G05D 1/00; G07C 5/00,"ZOOX, INC.","LEVINSON, Jesse, Sol; SIBLEY, Gabriel, Thurston; DOUILLARD, Bertrand, Robert","14/756,996 04.11.2015 US",
WO2007048137,PCT/US2006/060138,20.10.2006,WO/2007/048137,26.04.2007,WO,INTELLIGENT HUMAN-MACHINE INTERFACE,"Embodiments in accordance with the present invention relate to methods and apparatus for an intelligent human-machine interface. By way of example, but not limited thereto, embodiments of methods and apparatus are presented of an intelligent human-machine interface for the operating room, and more particularly, to systems and processes for real-time management and feedback of process control, situational awareness, logistics, communication, and documentation, herein referred to as system. One element of the system, among others, provides a knowledge base that organizes information and rules that enables an accurate, relevant and timely decision support system. The knowledge base is represented in a hierarchical structure of functions and systems. The system serves as platform for the avoidance, detection and timely correction of errors, and as such, acts as a countermeasure to error.",A61B 5/103; A61B 5/117; G06F 15/18; G06F 17/00; G06N 5/00,"BAUER LABS; BAUER, James Dean; FUNK, Kenneth H.; NICOLADE, Roberto Javier","BAUER, James Dean; FUNK, Kenneth H.; NICOLADE, Roberto Javier","11/255,593 20.10.2005 US",EP-6846133; US-12091056
WO2018232518,PCT/CA2018/050761,21.06.2018,WO/2018/232518,27.12.2018,WO,DETERMINING POSITIONS AND ORIENTATIONS OF OBJECTS,Methods and apparatus for determining poses of objects acquire plural images of the objects from different points of view. The images may be obtained by plural cameras arranged in a planar array. Each image may be processed to identify features such as contours of objects. The images may be projected onto different depth planes to yield depth plane images. The depth plane images for each depth plane may be compared to identify features lying in the depth plane. A pattern matching algorithm may be performed on the features lying in the depth plane to determine the poses of one or more of the objects. The described apparatus and methods may be applied in bin-picking and other applications.,G06K 9/20; G03B 15/02; G06T 15/00; H04N 5/247; H04N 5/262; G03B 35/08,VANCOUVER COMPUTER VISION LTD.,"KHATOONABADI, Armin; STAPLETON, Mehdi Patrick","62/523,108 21.06.2017 US",
EP234205406,18162246,16.03.2018,3407264,28.11.2018,EP,"LISTEN, INTERACT, AND TALK: LEARNING TO SPEAK VIA INTERACTION","Described herein are systems and methods for grounded natural language learning in an interactive setting. In embodiments, during a learning process, an agent learns natural language by interacting with a teacher and learning from feedback, thus learning and improving language skills while taking part in the conversation. In embodiments, a model is used to incorporate both imitation and reinforcement by leveraging jointly sentence and reward feedback from the teacher. Various experiments are conducted to validate the effectiveness of a model embodiment.",G06N 3/00; G06F 17/20; G06N 3/04; G06N 3/08,BAIDU USA LLC,ZHANG HAICHAO; YU HAONAN; XU WEI,201715821452 22.11.2017 US; 201762511295 25.05.2017 US,
WO2016118257,PCT/US2015/065783,15.12.2015,WO/2016/118257,28.07.2016,WO,MODEL COMPRESSION AND FINE-TUNING,"Compressing a machine learning network, such as a neural network, includes replacing one layer in the neural network with compressed layers to produce the compressed network. The compressed network may be fine-tuned by updating weight values in the compressed layer(s).",G06N 3/04; G06N 3/08,QUALCOMM INCORPORATED,"ANNAPUREDDY, Venkata Sreekanta Reddy; DIJKMAN, Daniel Hendricus Franciscus; JULIAN, David Jonathan","62/106,608 22.01.2015 US; 14/846,579 04.09.2015 US",KR-1020177020008; JP-2017538296
WO2014061021,PCT/IL2013/050838,17.10.2013,WO/2014/061021,24.04.2014,WO,A DEVICE FOR DETECTION AND PREVENTION OF AN ATTACK ON A VEHICLE,"A new device for detection and prevention of an attack on a vehicle via its communication channels, having: an input-unit configured to collect real-time and/or offline data from various sources such as sensors, network based services, navigation applications, the vehicles electronic control units, the vehicle's bus-networks, the vehicle's subsystems, and on board diagnostics; a database, for storing the data; a detection-unit in communication with the input-unit; and an action-unit, in communication with the detection unit, configured for sending an alert via the communication channels and/or prevent the attack, by breaking or changing the attacked communication channels. The detection-unit is configured to simultaneously monitor the content, the meta-data and the physical-data of the data and detect the attack.",B60R 25/00; H04L 12/24,TOWER-SEC LTD.,"RUVIO, Guy; DICKMAN, Saar Dickman; WEISGLASS, Yuval","61/795,426 17.10.2012 US",US-14436123; CN-201380066166.7; EP-2013847130; MX-MX/a/2015/004828; IL-238359; JP-2015537418
WO2017075611,PCT/US2016/059777,31.10.2016,WO/2017/075611,04.05.2017,WO,SYSTEM AND METHODS FOR ON-BODY GESTURAL INTERFACES AND PROJECTION DISPLAYS,"A wearable system with a gestural interface for wearing on, for instance, the wrist of a user. The system comprises an ultrasonic transceiver array structure and may comprise a pico projector display element for displaying an image on a surface. User anatomical feature inputs are received in the form of ultrasound signals representative of a spatio-temporal cross-section of the wrist of the user by articulating wrist, finger and hand postures, which articulations are translated into gestures. Inputs from inertial and other sensors are used by the system as part of the anatomical feature posture identification method and device. Gestures are recognized using a mathematically-modeled, simulation-based set of biological metrics of tissue objects, which gestures are converted to executable computer instructions. Embodiments of the system disclosed herein may also be used to monitor biometric and health data over computer networks or using onboard systems.",G06F 3/01; G06K 9/00; A63F 13/00,"OSTENDO TECHNOLOGIES, INC.","HAZRA, Siddharth S.; EL-GHOROURY, Hussein S.","62/249,021 30.10.2015 US; 15/338,189 28.10.2016 US",EP-2016861058; KR-1020187014478; JP-2018522056
WO2019090268,PCT/US2018/059278,05.11.2018,WO/2019/090268,09.05.2019,WO,CONTEXTUAL TRAINING SYSTEMS AND METHODS,"The systems and methods provide an action recognition and analytics tool for use in manufacturing, health care services, shipping, retailing and other similar contexts. Machine learning action recognition can be utilized to determine cycles, processes, actions, sequences, objects and or the like in one or more sensor streams. The sensor streams can include, but are not limited to, one or more video sensor frames, thermal sensor frames, infrared sensor frames, and or three-dimensional depth frames. The analytics tool can provide for contextual training using the one or more sensor streams and machine learning based action recognition.",G05B 19/418; G06Q 10/06; G06Q 50/04; G06T 7/00; G06N 99/00; G06K 17/00,"DRISHTI TECHNOLOGIES, INC.","AKELLA, Prasad Narasimha; ASSOUL, Zakaria Ibrahim; CHAUDHURY, Krishnendu; CHHABRA, Yash Raj; DALMIA, Aditya; NARUMANCHI, Sujay Venkata Krishna; RAVINDRA, Chirag; UGGIRALA, Ananth; ASHOK, Ananya Honnedevasthana; GUPTA, Sameer","62/581,541 03.11.2017 US",
WO2000020932,PCT/US1999/023295,06.10.1999,WO/2000/020932,13.04.2000,WO,DEVELOPMENTAL LEARNING MACHINE AND METHOD,"A machine and method capable of developing intelligent behavior from interaction with its environment directly using the machine's sensors (12, 14) and effectors (16). The method described is independent of the type of sensors and actuators, or the tasks to be executed, and therefore provides a general purpose learner that learns while performing. It senses the world, recalls what is learned, judges what to do, and acts according to what is has learned. The learner enables the machine to learn directly from sensory input streams while interacting with the environment, including human teachers. The presented approach enables the system to self-organized its internal representation, and uses a systematic way to automatically build a multi-level representation using the Markov random process model. Reward and punishment are combined with sensor-based teaching to develop intelligent behavior.",G05B 13/02; G06N 3/00,MICHIGAN STATE UNIVERSITY,"WENG, Juyang","09/167,751 07.10.1998 US",
WO2016193716,PCT/GB2016/051600,01.06.2016,WO/2016/193716,08.12.2016,WO,A COMPUTER IMPLEMENTED METHOD OF DETECTING THE DISTANCE OF AN OBJECT FROM AN IMAGE SENSOR,"There is provided a method for estimating a distance of an object detected by an image sensor. Multiple detections are performed automatically to detect features of an object and to estimate the object proportions, which are then used to relate to additional measurements such as the distance of the object from the image sensor. The method detects human and non-human objects. The method uses available anthropometry tables. The method takes into account the image sensor optical aberrations such as lens distortion. A related system and a related computer program product are also provided.",G06T 7/00,UNIFAI HOLDINGS LIMITED,"TEREKHOV, Vladislav; ROMANENKO, Ilya; TUSCH, Michael",1509387.5 01.06.2015 GB,EP-2016736545
WO2020063715,PCT/CN2019/108037,26.09.2019,WO/2020/063715,02.04.2020,WO,METHOD AND SYSTEM FOR TRAINING BINARY QUANTIZED WEIGHT AND ACTIVATION FUNCTION FOR DEEP NEURAL NETWORKS,"A method of training a neural network (NN) block for a neural network, including: performing a first quantization operation on a real-valued feature map tensor to generate a corresponding binary feature map tensor; performing a second quantization operation on a real-valued weight tensor to generate a corresponding binary weight tensor; convoluting the binary feature map tensor with the binary weight tensor to generate a convoluted output; scaling the convoluted output with a scaling factor to generate a scaled output, wherein the scaled output is equal to an estimated weight tensor convoluted with the binary feature map tensor, the estimated weight tensor corresponding to a product of the binary weight tensor and the scaling factor; calculating a loss function, the loss function including a regularization function configured to train the scaling factor so that the estimated weight tensor is guided towards the real-valued weight tensor; and updating the real-valued weight tensor and scaling factor based on the calculated loss function.",G06N 3/08,"HUAWEI TECHNOLOGIES CO., LTD.","LI, Xinlin; DARABI, Sajad; BELBAHRI, Mouloud; PARTOVI NIA, Vahid","62/736,630 26.09.2018 US; 16/582,131 25.09.2019 US",
WO2007016936,PCT/EP2005/008254,29.07.2005,WO/2007/016936,15.02.2007,WO,AUTOMATIC BIOMETRIC IDENTIFICATION BASED ON FACE RECOGNITION AND SUPPORT VECTOR MACHINES,"Disclosed herein is an automatic biometric identification method based on face recognition and support vector machines, including enrolling a user to generate a user's reference template; and identifying the user based on the user's reference template, wherein generating a user's reference template includes acquiring a number of user's face images, and training a one-class support vector machine based on the user's face images only.",G06K 9/62,"TELECOM ITALIA, S.P.A.; BALTATU, Madalina; D'ALESSANDRO, Rosalia; D'AMICO, Roberta; TISTARELLI, Massimo; GROSSO, Enrico; BICEGO, Manuele","BALTATU, Madalina; D'ALESSANDRO, Rosalia; D'AMICO, Roberta; TISTARELLI, Massimo; GROSSO, Enrico; BICEGO, Manuele",,KR-1020087005073; DE-null; EP-2005775914; US-11989639
WO2018005933,PCT/US2017/040222,30.06.2017,WO/2018/005933,04.01.2018,WO,TECHNOLOGIES FOR USER-ASSISTED MACHINE LEARNING,"Technologies for user-assisted machine learning includes a compute device configured to request user assistance to classify sensor data in response to a determination that a confidence score associated with the classification of the sensor data is below a threshold value and/or if the classification of the sensor data is unknown. In an illustrative embodiment, the compute device is configured to communicate with an activity monitor device, such as a smart pet collar, to determine activities of the subject (e.g., a pet) based on classification data received from the smart pet collar.",G06N 99/00,INTEL CORPORATION,"MCNAMARA, Edward Gerard","62/357,657 01.07.2016 US",
WO2020014683,PCT/US2019/041720,12.07.2019,WO/2020/014683,16.01.2020,WO,SYSTEMS AND METHODS FOR AUTONOMOUS OBJECT DETECTION AND VEHICLE FOLLOWING,"Systems and methods for implementing one or more autonomous features for autonomous and semi-autonomous control of one or more vehicles are provided. More specifically, image data may be obtained from an image acquisition device and processed utilizing one or more machine learning models to identify, track, and extract one or more features of the image utilized in decision making processes for providing steering angle and/or acceleration/deceleration input to one or more vehicle controllers. In some instances, techniques may be employed such that the autonomous and semi-autonomous control of a vehicle may change between vehicle follow and lane follow modes. In some instances, at least a portion of the machine learning model may be updated based on one or more conditions.",B60W 30/165; B60W 40/02; B60W 30/12; G05D 1/02; G08G 1/00; B60W 50/00,KACHE.AI,"LEVANDOWSKI, Anthony; BERNSTEIN, David; ARGUETA, Oscar; VO, Albert; RICCI, Christopher","62/697,960 13.07.2018 US; 62/697,940 13.07.2018 US; 62/697,971 13.07.2018 US; 62/697,930 13.07.2018 US; 62/697,962 13.07.2018 US; 62/697,965 13.07.2018 US; 62/697,969 13.07.2018 US; 62/697,952 13.07.2018 US; 62/697,938 13.07.2018 US; 62/697,946 13.07.2018 US; 62/697,922 13.07.2018 US; 62/697,957 13.07.2018 US; 62/697,912 13.07.2018 US; 62/697,915 13.07.2018 US; 62/697,919 13.07.2018 US",
WO2018185762,PCT/IL2018/050392,03.04.2018,WO/2018/185762,11.10.2018,WO,NEURAL NETWORK PROCESSOR INCORPORATING MULTI-LEVEL HIERARCHICAL AGGREGATED COMPUTING AND MEMORY ELEMENTS,"A novel and useful neural network (NN) processing core adapted to implement artificial neural networks (ANNs). The NN processor is constructed from self-contained computational units organized in a hierarchical architecture. The homogeneity enables simpler management and control of similar computational units, aggregated in multiple levels of hierarchy. Computational units are designed with minimal overhead as possible, where additional features and capabilities are aggregated at higher levels in the hierarchy. On-chip memory provides storage for content inherently required for basic operation at a particular hierarchy and is coupled with the computational resources in an optimal ratio. Lean control provides just enough signaling to manage only the operations required at a particular hierarchical level. Dynamic resource assignment agility is provided which can be adjusted as required depending on resource availability and capacity of the device.",G06N 3/063; G06N 3/04; G06F 17/50,HAILO TECHNOLOGIES LTD.,"BAUM, Avi; DANON, Or; ZEITLIN, Hadar; CIUBOTARIU, Daniel; FEIG, Rami","62/481,492 04.04.2017 US; 62/531,372 12.07.2017 US",EP-2018780640; JP-2019555007; CN-201880021608.9
EP251064690,19159082,25.02.2019,3531348,28.08.2019,EP,ARITMETIC UNIT FOR DEEP LEARNING ACCELERATION,,G06N 3/04; G06N 3/063,ST MICROELECTRONICS INT NV; ST MICROELECTRONICS SRL,SINGH SURINDER PAL; BOESCH THOMAS; DESOLI GIUSEPPE,201862636009 27.02.2018 US,
EP96170896,12178238,27.07.2012,2690582,29.01.2014,EP,System for controlling an automated device,"The present invention uses context information, in order to control an incremental learning process of a system 1 for controlling an automated device even in an unexpected environment. The system 1 is able to correct errors, which are produced by a pre-trained mapping unit 4 that maps an input obtained by primary sensors 2 onto a first control signal 4a for controlling the automated device. The context information obtained by context sensors 3 helps to constrain the learning process of a learning unit 8 to situations, which can be uniquely identified and cannot be covered by the mapping unit 4. A control signal 9a of the combined control signals 4a and 8a of the mapping unit 4 and the learning unit 8, respectively, is computed in a fusion unit 9 by evaluating the confidence values of the two control signals 4a, 8a, and by either choosing one of the two control signals or interpolating between the two control signals. The confidence value evaluation can be done by quantizing the input space according to the incremental learning data, and using the quantized regions for evaluating the performance of both the learned and pre-trained unit within each region.",G06K 9/62; G05D 1/02,HONDA RES INST EUROPE GMBH,WERSING HEIKO; QUEISSER JEFFREY FREDERIC,12178238 27.07.2012 EP,
WO2019169358,PCT/US2019/020438,01.03.2019,WO/2019/169358,06.09.2019,WO,CAMERA BASED LOCALIZATION FOR AUTONOMOUS VEHICLES,"Camera based localization performed to determine a current pose of an autonomous vehicle without the aid of depth sensors such as LiDAR. The vehicle comprises an imaging system configured to capture image frames depicting portions of the surrounding area. Based on an initial pose of the vehicle, edgels corresponding to three-dimensional locations are loaded and mapped to corresponding edge pixels of the captured image frame. A pose of the vehicle is optimized based upon the determined correspondences by identifying a transformation that minimizes a distance between the edgels and their corresponding edge pixels. The determined transformation can be applied to the initial pose to determine an updated pose of the vehicle.",G05D 1/00; B60W 30/18,DEEPMAP INC.,"ZHANG, Ronghua; YANG, Lin","62/637,997 02.03.2018 US",
EP225889645,18160192,06.03.2018,3373200,12.09.2018,EP,OFFLINE COMBINATION OF CONVOLUTIONAL/DECONVOLUTIONAL AND BATCH-NORM LAYERS OF CONVOLUTIONAL NEURAL NETWORK MODELS FOR AUTONOMOUS DRIVING VEHICLES,"In one embodiment, a system to accelerate batch-normalized convolutional neural network (CNN) models is disclosed. The system extracts a plurality of first groups of layers from a first CNN model, each group of the first groups having a first convolutional layer and a first batch-norm layer. For each group of the plurality of first groups, the system calculates a first scale vector and a first shift vector based on the first batch-norm layer, and generates a second convolutional layer representing the corresponding group of the plurality of first groups based on the first convolutional layer and the first scale and the first shift vectors. The system generates an accelerated CNN model based on the second convolutional layer corresponding to the plurality of the first groups, such that the accelerated CNN model is utilized subsequently to classify an object perceived by an autonomous driving vehicle (ADV).",G06K 9/00; G06K 9/62; G06N 3/04; G06N 3/08,BAIDU USA LLC,YU ZHENHUA; BO XIAO; ZHOU JUN; ZHANG WEIDE; HAN TONY,201715451345 06.03.2017 US,
WO2019109290,PCT/CN2017/114960,07.12.2017,WO/2019/109290,13.06.2019,WO,CONTEXT SET AND CONTEXT FUSION,"In an aspect of the disclosure, a method, a computer readable medium, and apparatus for operating a computational network are provided. The apparatus includes a memory and at least one processor coupled to the memory. In an aspect, the at least one processor may obtain a plurality of features associated with the apparatus. The at least one processor may generate a context based on the plurality of features, the context comprising a multidimensional output. The at least one processor may provide at least a portion of the context to a component of the apparatus.",G06N 3/02,"QUALCOMM INCORPORATED; HUANG, Yin; JAIN, Rajeev; ZHAO, Haijun; LEWIS, M Anthony; SADASIVAM, Shankar","HUANG, Yin; JAIN, Rajeev; ZHAO, Haijun; LEWIS, M Anthony; SADASIVAM, Shankar",,
WO2019171117,PCT/IB2018/051389,05.03.2018,WO/2019/171117,12.09.2019,WO,"METHOD, DEVICE AND PROGRAM FOR CONTROLLING MOVEMENT OF MOVING BODY AND STORAGE MEDIUM","The present application discloses a method, device and program for controlling movement of a moving body and a storage medium, wherein the method comprises: determining that at least one object exists in an advancing direction of the moving body to acquire a first determination result; executing first control on movement of the moving body on the basis of the first determination result; determining predetermined parameters of the at least one object to acquire a second determination result; and executing second control on movement of the moving body on the basis of the second determination result. The present disclosure solves the technical problem that it is too late to take a measure due to the fact that the corresponding measure is taken to the moving body only after it learns about what specific entity the object in the advancing direction of the moving body really is.",G05D 1/02; B62D 15/02; B60W 30/00,OMRON CORPORATION,"YANAGAWA, Yukiko; IJIRI, Yoshihisa",,
WO2018078471,PCT/IB2017/056146,05.10.2017,WO/2018/078471,03.05.2018,WO,AUGMENTED CONTROL OF ROBOTIC PROSTHESIS BY COGNITIVE SYSTEM,"Methods and systems for one or more processors receive image data of an object selected by a user and determine image attributes of the object selected, based on image analytics on the image data. One or more processors determine whether the image attributes of the object selected match an identified object of a knowledge base, in which an identified object includes image attributes and manipulation data corresponding to the identified objects; and responsive to determining that the object selected by the user of the prosthetic device matches an identified object of the knowledge base, one or more processors transmits manipulation data corresponding to the identified object matching the object selected by the user, to a mobile controlling device communicatively connected to the prosthetic device, wherein the mobile controlling device applies the manipulation data corresponding to the identified object to the prosthetic device.",B25J 9/16,INTERNATIONAL BUSINESS MACHINES CORPORATION; IBM UNITED KINGDOM LIMITED; IBM (CHINA) INVESTMENT COMPANY LIMITED,"RAKSHIT, Sarbajit; GANCI JR, John; BOSTICK, James; KEEN, Martin; TRIM, Craig","15/337,207 28.10.2016 US",JP-2019519664; GB-1907096.0; CN-201780066938.5; DE-112017003723
WO2016189274,PCT/GB2016/051423,17.05.2016,WO/2016/189274,01.12.2016,WO,MODELLING A THREE-DIMENSIONAL SPACE,"Certain examples described herein relate to modelling a three-dimensional space. Image data from at least one capture device is used to generate a three-dimensional model of the three-dimensional space. In certain examples, the three-dimensional model is segmented into active and inactive portions based on at least one model property. The examples are configured to use the active portions to update the three- dimensional model over time. Registration is also performed to align active portions of the three-dimensional model with inactive portions of the three-dimensional model over time. The registration aligns active portions of the three-dimensional model generated following an observation of a region of the three-dimensional space with inactive portions of the model generated following at least one previous observation of said region.",G06T 7/00,"IMPERIAL COLLEGE OF SCIENCE, TECHNOLOGY AND MEDICINE","WHELAN, Thomas; SALAS MORENO, Renato Fernando; LEUTENEGGER, Stefan; DAVISON, Andrew; GLOCKER, Ben",1509068.1 27.05.2015 GB,KR-1020177037549; AU-2016266968; RU-2017141158; SG-11201709118P; EP-2016731625; JP-2017561728
EP14186532,04004440,26.02.2004,1452935,01.09.2004,EP,Control system using immune network and control method,"To provide a new method for autonomously controlling the behavior of a control target device based on a stimulating action and a suppressing action among antibodies in an immune network, an operating unit 3 calculates an antibody concentration ai(t) serving as an index for selecting an antibody module ABi, while plural antibody modules ABi different in stimulating conditions are set as processing targets. A convergence judging unit 4 judges whether the antibody concentration ai(t) is converged to a predetermined target value ri. When a judgment of non-convergence is made, a convergence controlling unit 5 calculates a correction parameter ul(t) for correcting the antibody concentration so that the antibody concentration ai (t) approaches to the target value ri. When a judgment of convergence is made, an antibody estimating unit 7 calculates an estimation value Pi, and selects some antibody module ABi based on the estimation values Pi calculated for the plural antibody modules. The behavior of the control target device is controlled in accordance with a control content defined by the selected antibody module ABi.",B25J 5/00; G05B 13/02; B25J 13/00; G06F 19/12; G06N 3/00; G06N 3/10,FUJI HEAVY IND LTD,MATSUDA KAZUHIKO; NOHARA TSUTOMU,2003054850 28.02.2003 JP,
WO2020041893,PCT/CA2019/051212,30.08.2019,WO/2020/041893,05.03.2020,WO,IMAGE PROCESSING METHODS AND SYSTEMS,"A computer-implemented method performable with an imaging device comprises selecting a frame from a video feed output with the imaging device during a movement of the imaging device relative to a body part and detecting the body part in the frame. If the body part is detected, a first process is performed comprising: calculating an azimuth angle of the imaging device relative to the body part, calculating a metering region for the body part, and measuring a motion characteristic of the movement. The method also involves qualifying the frame based on at least one of the azimuth angle and the motion characteristic. If the frame is qualified, a second process is performed comprising: adjusting a setting of the imaging device based on the metering region, capturing an image of the body part with the imaging device based on the setting, identifying a location of the image relative to the body part based on the azimuth angle, and associating the image with a reference to the location.",G06T 7/00; G06T 1/40; G06T 7/10; G06T 7/20; A43D 1/00,DIGITAL ANIMAL INTERACTIVE INC.,"SHERRAH, Jamie Roy; HENSON, Michael; SMITH, William Ryan","62/726,204 01.09.2018 US",
EP13402852,00102461,04.02.2000,1035494,13.09.2000,EP,System and method for recognizing scanned objects with deformable volumetric templates,A method recognizes three-dimensional physical objects using three-dimensional deformable templates. A particular object is scanned with a camera to generate volumetric data representing the object. The volumetric data is compared to each of a plurality of three-dimensional deformable templates stored in a database to obtain a score for each comparison. The deforming of the template is done by optimizing an objective function. <IMAGE>   <IMAGE>,G06K 9/64; G06T 7/00; G06K 9/64,MITSUBISHI ELECTRIC CORP,ANDERSON DAVID B; BEARDSLEY PAUL A; AGARWALA ASEEM; MARKS JOSEPH W,26237699 04.03.1999 US,
WO2019145951,PCT/IL2019/050098,23.01.2019,WO/2019/145951,01.08.2019,WO,AUTOMATED MONITORING OF MEDICAL IMAGING PROCEDURES,"A method for automated image capture of a body tissue in situ, comprising: providing an imaging device configured to transmit an image stream of a body tissue; and using at least one hardware processor for: receiving the image stream, identifying a medical accessory appearing in the image stream, and capturing multiple images of the body tissue, wherein (i) at least one of the images is captured before said identifying, and (ii) at least one of the images is captured at one or more specified times upon said identifying.",G06T 7/10; G06K 9/00; A61B 5/00,MOBILEODT LTD.,"BERNAT, Amir Shlomo; LEVITZ, David; BOLTON, Frank John; FERNANDES, Kelwin","62/620,579 23.01.2018 US; 62/689,991 26.06.2018 US",
WO2019022472,PCT/KR2018/008355,24.07.2018,WO/2019/022472,31.01.2019,WO,ELECTRONIC DEVICE AND METHOD FOR CONTROLLING THE ELECTRONIC DEVICE,"A method for controlling an electronic device including at least one processor configured to encrypt an image and upload the encrypted image to an external server by using an artificial intelligence neural network model is provided. The method includes receiving a command to upload an image to the external server; acquiring, based on the command, a characteristic value corresponding to the image by inputting the image and a key of the electronic device into a neural network model trained to identify characteristic values based on an input image and an input key; and transmitting identification information of the image and the characteristic value to the external server.",G06F 21/60; G06F 21/62; G06F 21/46; G06T 7/00; G06T 9/00; H04N 21/2347; H04N 21/4405; G06N 3/08,"SAMSUNG ELECTRONICS CO., LTD.","KANG, Seong-min; HAN, Heung-woo","62/536,042 24.07.2017 US; 10-2017-0142106 30.10.2017 KR",EP-2018838530
WO2007109571,PCT/US2007/064217,16.03.2007,WO/2007/109571,27.09.2007,WO,METHODS OF PREDICTING AND MONITORING TYROSINE KINASE INHIBITOR THERAPY,"The present invention provides methods for analyzing a combination of biomarkers to individualize tyrosine kinase inhibitor therapy in patients who have been diagnosed with cancer. In particular, the assay methods of the present invention are useful for predicting, identifying, or monitoring the response of a tumor, tumor cell, or patient to treatment with a tyrosine kinase inhibitor using an algorithm based upon biomarker profiling. The assay methods of the present invention are also useful for predicting whether a patient has a risk of developing toxicity or resistance to treatment with a tyrosine kinase inhibitor. In addition, the assay methods of the present invention are useful for monitoring tyrosine kinase inhibitor therapy in a patient receiving the drug to evaluate whether the patient will develop resistance to the drug. Furthermore, the assay methods of the present invention are useful for optimizing the dose of a tyrosine kinase inhibitor in a patient receiving the drug to achieve therapeutic efficacy and/or reduce toxic side-effects.",C12Q 1/68; G06F 19/18; G06F 19/24,"PROMETHEUS LABORATORIES, INC.; HARVEY, Jeanne; NERI, Bruce; SINGH, Sharat","HARVEY, Jeanne; NERI, Bruce; SINGH, Sharat","60/783,743 17.03.2006 US; 60/829,812 17.10.2006 US",
WO2006113248,PCT/US2006/013566,11.04.2006,WO/2006/113248,26.10.2006,WO,PARTIALLY SUPERVISED MACHINE LEARNING OF DATA CLASSIFICATION BASED ON LOCAL-NEIGHBORHOOD LAPLACIAN EIGENMAPS,"A local-neighborhood Laplacian Eigenmap (LNLE) is provided for methods and systems for semi-supervised learning on manifolds of data points in a high-dimensional space. A labeled set and unlabeled data points are received as seen in Figure 4 (402). An adjacency Matrix/Graph is built (404). An unlabeled point is selected (406), then a local neighborhood/subgraph is found (408). Next, a Local Eigen Decomposition is computed (41) and evaluated (412) and the point is classified (414). A check is made to see if more points are available (416). If more points are available, select an unlabeled point (4Q6), otherwise output the classification (418).",G06F 15/18,"HONDA MOTOR CO., LTD.; RIFKIN, Ryan; ANDREWS, Stuart","RIFKIN, Ryan; ANDREWS, Stuart","11/108,031 14.04.2005 US",RU-null; JP-2008506612; DE-null; EP-6749820
WO2019141992,PCT/GB2019/050133,18.01.2019,WO/2019/141992,25.07.2019,WO,LOCALISING A VEHICLE,"A computerised method of generating a first trainable transform arranged to be used in localisation of an entity, the transform being arranged to transform a first representation of an environment to a second, different, representation of the environment, the method comprising processing a plurality of first training representations of an environment using the first trainable transform to generate a transformed first training representation; performing at least one of: i)) running at least one known process on the first training representation and a modified version of the first training representation to generate an error signal where in the process is selected such that the first trainable transform is arranged to enhance features within the first training representation;and ii) running at least one known process on a second training representation, corresponding to the first training representation, but under a different lighting condition, and on the modified version of the first training representation to generate an error signal wherein the process is selected such that the first trainable transform is arranged to enhance features within the first training representation; and; c) using the error signal to train the first transform.",G06N 3/08; G06N 3/02; G06K 9/00; G05D 1/02,OXFORD UNIVERSITY INNOVATION LIMITED,"NEWMAN, Paul; PORAV, Horia; MADDERN, Will",1800811.0 18.01.2018 GB,
EP13760068,00128558,27.12.2000,1220063,03.07.2002,EP,Non-integer order dynamic systems,"A circuit implementing a non-integer order dynamic system includes a neural network (1 to 5) adapted to receive at least one input signal (IS) and to generate therefrom at least one output signal (OS). The input and output signals (IS, OS) are related to each by a non-integer order integro-differential relationship through the coefficients of the neural network (1 to 5). A plurality (I, II) of such circuits, implementing respective non-integer order (PI< lambda >D< mu >) controllers can be interconnected in an arrangement wherein any of the integral (200) or differential (202) blocks included in one of those circuits generates a signal which is fed to any of the integral (200) or differential (204) blocks of another circuit in the system. <IMAGE>",G05B 11/42; G05B 13/02; G06N 3/00; G05B 11/42; G05B 13/02,ST MICROELECTRONICS SRL,ABBISSO SALVATORE; CAPONETTO RICCARDO; DIAMANTE OLGA; PORTO DOMENICO; DI COLA EUSEBIO; FORTUNA LUIGI,00128558 27.12.2000 EP,
WO2019141813,PCT/EP2019/051260,18.01.2019,WO/2019/141813,25.07.2019,WO,A COMPUTER-IMPLEMENTED METHOD FOR AUTOMATED DETECTION OF A MOVING AREA OF INTEREST IN A VIDEO STREAM OF FIELD SPORTS WITH A COMMON OBJECT OF INTEREST,"A computer-implemented method for automated detection of a moving area of interest, such as a ball, in a video stream of filed sports with a common object of interest encompassing a plurality of players and the object of interest. Images of a sports ground are captured by means of a video camera system producing a video stream which is digitally processed to continuously identify a detected concentration of action within the boundaries of the field. Concentration of action in the field is determined on the basis of an estimated position of the object of interest in at least one frame of the video stream. Players' postures and/or orientations may be detected with a view to improving the accuracy of the determination of the object of interest.",H04N 5/222; H04N 5/232; G06K 9/00; G06T 7/70; G06K 9/32,VEO TECHNOLOGIES APS,"TAXBØL, Jesper, Molbech; TEISBÆK, Henrik, Bjørn; REINICKE, Keld",18152486.9 19.01.2018 EP; 18152483.6 19.01.2018 EP,
WO2019112646,PCT/US2018/037858,15.06.2018,WO/2019/112646,13.06.2019,WO,GRAPHICAL USER INTERFACE RENDERING MANAGEMENT BY VOICE-DRIVEN COMPUTING INFRASTRUCTURE,"Managing rendering of a graphical user interface is provided. A system receives data packets comprising an input audio signal. The system determines an application identifier and query. The system provides the query to the application to cause the application to generate a second query for transmission to a third-party server, and identify responses to the query. The system intercepts the responses, and generates a keyword based on the responses. The system selects a digital component using the keyword, executes a deduplication process, and determines to add the digital component to the responses. The system constructs a display output using a graphical user interface template that integrates the plurality of responses generated by the application with the digital component, and provides the display output to the computing device for rendering.",G06F 9/451; G10L 15/22; G10L 17/22; G06F 17/30; G06F 3/16,GOOGLE LLC,"KOTHARI, Anshul; BHAYA, Gaurav; JAIN, Tarun","15/836,746 08.12.2017 US",EP-2018740948
WO1991010196,PCT/GB1990/002006,21.12.1990,WO/1991/010196,11.07.1991,WO,NEURAL NETWORKS,"A neural net in which new nodes and connections are created in both input and intermediate layers during training, which is by punishment, reward and teaching. This can use a small increase in memory requirement to preclude the necessity for long training times applicable problems in speech and natural language processing, video recognition and simple logic functions.",G06N 3/08,"BRITISH TELECOMMUNICATIONS PUBLIC LIMITED COMPANY; NIGHTINGALE, Charles; WYARD, Peter, Joseph","NIGHTINGALE, Charles; WYARD, Peter, Joseph",8929146.2 22.12.1989 GB,EP-1991900886; CA-2070677
WO2019040705,PCT/US2018/047679,23.08.2018,WO/2019/040705,28.02.2019,WO,SURGICAL DECISION SUPPORT USING A DECISION THEORETIC MODEL,"A surgical procedure on a patient is monitored at a sensor to provide an observation. A current surgical state is estimated as a belief state over of a plurality of surgical states, representing different phases of the surgery, from the observation and an observation function for each surgical state. A world state of a plurality of world states representing a state of one of the patient, a medical professional performing the surgical procedure, and the environment in which the surgical procedure is being conducted is estimated from the estimated surgical state. From the estimated surgical state, the estimated world state, and a model, at least one surgical state that will be entered during the surgical procedure is predicted and an output representing the predicted at least one surgical state is provided at an associated output device.",A61B 19/00; A61B 17/00; A61B 5/00; G06F 19/00,THE GENERAL HOSPITAL CORPORATION,"RUS, Daniela; MEIRELES, Ozanan; ROSMAN, Guy; HASIMOTO, Daniel","62/549,272 23.08.2017 US",
EP289840470,18828204,06.02.2018,3621304,11.03.2020,EP,METHOD AND DEVICE FOR ENCODING OR DECODING IMAGE,"Provided is in-loop filtering technology using a trained deep neural network (DNN) filter model. An image decoding method according to an embodiment includes receiving a bitstream of an encoded image, generating reconstructed data by reconstructing the encoded image, obtaining information about a content type of the encoded image from the bitstream, determining a deep neural network (DNN) filter model trained to perform in-loop filtering by using at least one computer, based on the information about the content type, and performing the in-loop filtering by applying the reconstructed data to the determined DNN filter model.",H04N 19/117; G06N 3/08; G06T 9/00; H04N 19/105; H04N 19/124; H04N 19/82; H04N 19/86,SAMSUNG ELECTRONICS CO LTD,PARK YOUNG-O; KIM JAE-HWAN; LEE JONG-SEOK; JEON SUN-YOUNG; PARK JEONG-HOON; CHOI KWANG-PYO,2017007263 06.07.2017 KR; 2018001539 06.02.2018 KR,
WO2018092044,PCT/IB2017/057147,15.11.2017,WO/2018/092044,24.05.2018,WO,DATA OBJECT CREATION AND RECOMMENDATION USING MACHINE LEARNING BASED OFFLINE AND ONLINE EVOLUTION,"The technology disclosed relates to neural network-based systems and methods of preparing a data object creation and recommendation database. Roughly described, it relates to, for each of a plurality of preliminary data object images, providing a representation of the image in conjunction with a respective conformity parameter indicating level of conformity of the image with a predefined goal, training a neural network system with the preliminary data object image representations in conjunction with their respective conformity parameters, to evaluate future data object image representations for conformity with the predefined goal, selecting a subset of secondary data object image representations, from a provided plurality of secondary data object image representations, in dependence upon the trained neural network system, and storing the image representations from the selected subset of secondary data object image representations in a tangible machine readable memory for use in a data object creation and recommendation system.",G06N 3/02; G06F 15/18,SENTIENT TECHNOLOGIES (BARBADOS) LIMITED,"BRUNDAGE, Myles; MIIKKULAINEN, Risto","62/422,497 15.11.2016 US; 62/422,507 15.11.2016 US; 15/813,019 14.11.2017 US; 15/813,041 14.11.2017 US",
WO2017156640,PCT/CA2017/050349,17.03.2017,WO/2017/156640,21.09.2017,WO,METHOD AND DEVICE FOR AUTOMATICALLY LEARNING RELEVANCE OF WORDS IN A SPEECH RECOGNITION SYSTEM,"There is provided a system and method for processing and/or recognizing acoustic signals. The method comprises obtaining at least one pre-existing speech recognition model; adapting and/or training the at least one pre-existing speech recognition model incrementally when new, previously unseen, user-specific data is received, the data comprising input acoustic signals and/or user action demonstrations and/or semantic information about a meaning of the acoustic signals, wherein the at least one model is incrementally updated by associating new input acoustic signals with input semantic frames to enable recognition of changed input acoustic signals. The method further comprises adapting to a user's vocabulary over time by learning new words and/or removing words no longer being used by the user, generating a semantic frame from an input acoustic signal according to the at least one model, and mapping the semantic frame to a predetermined action.",G10L 15/06; G10L 15/16,FLUENT.AI INC.,"TOMAR, Vikrant; RENKENS, Vincent P. G.; VAN HAMME, Hugo R. J. G.",1604592.4 18.03.2016 GB; 1604594.0 18.03.2016 GB,EP-2017765625; US-16086294
WO2016142690,PCT/GB2016/050620,07.03.2016,WO/2016/142690,15.09.2016,WO,"INLET INSTRUMENTATION FOR ION ANALYSER COUPLED TO RAPID EVAPORATIVE IONISATION MASS SPECTROMETRY (""REIMS"") DEVICE","An apparatus is disclosed comprising a first device (1) for generating aerosol, smoke or vapour (5) from one or more regions of a target, an inlet conduit to an ion analyser or mass spectrometer,the inlet conduit having an inlet through which the aerosol, smoke or vapour (5) passes, and a Venturi pump arrangement arranged and adapted to direct the aerosol, smoke or vapour5towards the inlet.",G01N 27/62; H01J 49/00; G01N 33/92; G01N 33/68; G01N 3/00; G01N 9/00; A61B 10/02; A61B 17/00; A61B 18/00; A61B 18/14,MICROMASS UK LIMITED,"TAKÁTS, Zoltán; BALOG, Júlia; PRINGLE, Steven Derek; KARANCSI, Tamás; MORRIS, Michael Raymond; GÖDÖRHÁZY, Lajos; SZALAY, Dániel; SIMON, Dániel",1503879.7 06.03.2015 GB; 1503876.3 06.03.2015 GB; 1503864.9 06.03.2015 GB; 1503877.1 06.03.2015 GB; 1503867.2 06.03.2015 GB; 1503863.1 06.03.2015 GB; 1503878.9 06.03.2015 GB; 1516003.9 09.09.2015 GB; 1518369.2 16.10.2015 GB,CA-2978166; US-15555720; EP-2016710791; KR-1020177028158; GB-1714126.8; JP-2017546862
WO2004049191,PCT/NL2003/000824,24.11.2003,WO/2004/049191,10.06.2004,WO,"METHOD, SYSTEM AND COMPUTER PROGRAM FOR COMPUTING ONE MARGINAL PROBABILITY FOR AN OBSERVED PHENOMENON","Method for computing at least one marginal probability for an observed phenomenon in a probability model which describes probabilities for relationships between said phenomenon and physical parameters by using a Cluster Variation Method (CVM), said model comprising a set of variables xi said variables xi representing observations of said physical parameters, the set of variables including a plurality of subsets; the marginal probability including a subset of the set of variables, the probability model being defined by a probability distribution pψ(x), the probability distribution pψ(x) having a potential ψ(xi) for each of the subsets.",G06F 17/17; G06F 17/18,"STICHTING VOOR DE TECHNISCHE WETENSCHAPPEN; KAPPEN, Hilbert, Johan; HESKES, Thomas, Maria","KAPPEN, Hilbert, Johan; HESKES, Thomas, Maria",1021987 25.11.2002 NL,JP-null
WO2018084324,PCT/JP2017/040343,01.11.2017,WO/2018/084324,11.05.2018,WO,METHOD AND SYSTEM FOR CONTROLLING VEHICLE,A method and a system generate a time-series signal indicative of a variation of the environment in vicinity of the vehicle with respect to a motion of the vehicle and submit the time-series signal to the neural network to produce a reference trajectory as a function of time that satisfies time and spatial constraints on a position of the vehicle. The neural network is trained in to transform time-series signals to reference trajectories of the vehicle. The motion trajectory tracking the reference trajectory while satisfying constraints on the motion of the vehicle is determined and the motion of the vehicle is controlled to follow the motion trajectory.,G05D 1/02; G06K 9/00; G06K 9/32,MITSUBISHI ELECTRIC CORPORATION,"BERNTORP, Karl; LIU, Ming-Yu; WEISS, Avishai","15/342,216 03.11.2016 US",JP-2018564859; EP-2017809053; CN-201780066782.0
WO2019212776,PCT/US2019/028426,22.04.2019,WO/2019/212776,07.11.2019,WO,EXTENDING PREVIOUSLY TRAINED DEEP NEURAL NETWORKS,"Sensor data is provided to a deep neural network previously trained to detect a feature within the physical environment. Result signals are received from the neural network, and the computing system determines if the feature is present within the physical environment based on the result signals. Responsive to determining that the feature is present, the computing system implements a function of a rule assigned to the feature. Responsive to determining that the feature is not present, the computing system determines whether one or more activation parameters of the neural network have been met indicative of an alternative feature being present within the physical environment. An indication that the activation parameters have been met is output by the computing system, enabling the rule to be extended to the alternative feature.",G06N 3/04; G06N 3/08,"MICROSOFT TECHNOLOGY LICENSING, LLC","FINKELSTEIN, Erich-Soren","15/968,694 01.05.2018 US",
WO2020043162,PCT/CN2019/103277,29.08.2019,WO/2020/043162,05.03.2020,WO,SYSTEM AND METHOD FOR PERFORMING MULTI-MODEL AUTOMATIC SPEECH RECOGNITION IN CHALLENGING ACOUSTIC ENVIRONMENTS,"A speech recognition method includes: providing a system having a local computational device, the local computational device having a microphone, processing circuitry, and a non-transitory computer-readable medium; recording a raw audio waveform utilizing the microphone; determining a background noise condition for the raw audio waveform; comparing the background noise condition to a plurality of linguistic models having associated background noise conditions; determining a nearest match between the background noise condition of the raw audio waveform and the associated background noise condition of at least one of the plurality of linguistic models; and performing an automatic speech recognition (ASR) function between the raw audio waveform and the linguistic model having the matching associated background noise condition.",G10L 15/20; G10L 15/16,"CLOUDMINDS (SHENZHEN) ROBOTICS SYSTEMS CO., LTD.","JANKOWSKI, Charles; LIN, Ruixi","62/726,194 31.08.2018 US",
WO2019116891,PCT/JP2018/043700,28.11.2018,WO/2019/116891,20.06.2019,WO,ROBOT SYSTEM AND ROBOT CONTROL METHOD,"A robot system (1) comprises a robot (10), an image acquisition unit (21), an image prediction unit (22), and a movement control unit (24). The image acquisition unit (21) acquires a current image, which is an image captured by a robot camera (31) disposed so as to move with an end effector (13). The image prediction unit (22) performs processing to predict a next image, which is the image that the robot camera (31) should capture next, on the basis of the current image and a teaching image model that is constructed by performing machine learning wherein a teaching image is the image that the robot camera (31) is expected to capture when an adjustment action is performed by a mobile unit (12). The movement control unit (24) calculates a command value for moving the mobile unit (12) so the image captured by the robot camera (31) approximates the next image and controls the mobile unit (12) on the basis of the command value.",B25J 9/22,KAWASAKI JUKOGYO KABUSHIKI KAISHA; 川崎重工業株式会社,"HASUNUMA, Hitoshi; 蓮沼　仁志; ENOMOTO, Masayuki; 榎本　雅幸",2017-240252 15.12.2017 JP,
EP238739210,16899858,29.04.2016,3451239,06.03.2019,EP,APPARATUS AND METHOD FOR EXECUTING RECURRENT NEURAL NETWORK AND LSTM COMPUTATIONS,"The present disclosure provides an apparatus for performing a recurrent neural network and an LSTM operation, comprising an instruction storage unit, a controller unit, an interconnection module, a main operation module, and a plurality of slave operation modules. The slave operation module is configured to multiply and add input data to obtain a partial sum and save the partial sum until neuron data is all inputted, and a result is returned to the main operation module. The main operation module is configured to perform interpolation activation on the sum returned from the slave operation module during a forward process, and perform interpolation to get an activation derivative during a reverse process and multiplied by a gradient. The present disclosure can solve the problem that the operational performance of the CPU and the GPU is insufficient, and the power consumption of previous decoding is large, and effectively improved the support for the forward operation of the multiple layer artificial neural network.",G06N 3/063; G06N 3/04; G06N 3/08,CAMBRICON TECH CORPORATION LIMITED,GUO QI; CHEN XUNYU; CHEN YUNJI; CHEN TIANSHI,2016080744 29.04.2016 CN,
WO2018204371,PCT/US2018/030465,01.05.2018,WO/2018/204371,08.11.2018,WO,SYSTEM AND METHOD FOR BATCH-NORMALIZED RECURRENT HIGHWAY NETWORKS,"Embodiments of the present disclosure relate to a recurrent framework based on Recurrent Highway Networks (RHNs) for sequence modeling using batch normalization. In certain embodiments, constraints within the RHNs are relaxed to reduce or avoid gradient vanishing or exploding by normalizing the current transition units in highway layers",G06N 3/04; G06N 3/08; G06K 9/00,KODAK ALARIS INC.,"ZHANG, Chi; PTUCHA, Raymond; LOUI, Alexander; SALVAGGIO, Carl","62/500,347 02.05.2017 US",CN-201880028894.1; EP-2018725729
WO2019083227,PCT/KR2018/012376,19.10.2018,WO/2019/083227,02.05.2019,WO,"METHOD OF PROCESSING MEDICAL IMAGE, AND MEDICAL IMAGE PROCESSING APPARATUS PERFORMING THE METHOD","A device and a method for medical image processing are provided. The medical image processing method may include: obtaining a plurality of actual medical images corresponding to a plurality of patients and including lesions; training a deep neural network (DNN), based on the plurality of actual medical images, to obtain a first neural network for predicting a variation in a lesion over time, the lesion being included in a first medical image of the plurality of actual medical images, wherein the first medical image is obtained at a first time point; and obtaining, via the first neural network, a second medical image representing a state of the lesion at a second time point different from the first time point.",G16H 50/20; G06N 3/02; G16H 50/30; G06T 7/00; G06T 1/00,"SAMSUNG ELECTRONICS CO., LTD.","LEE, Dong-jae; OH, Hyun-hwa; KIM, Se-min; SONG, Jeong-yong; LEE, Hyun-jung",10-2017-0140317 26.10.2017 KR,
WO2017163596,PCT/JP2017/002689,26.01.2017,WO/2017/163596,28.09.2017,WO,AUTONOMOUS NAVIGATION USING VISUAL ODOMETRY,"A system and method are provided for autonomously navigating a vehicle. The method captures a sequence of image pairs using a stereo camera. A navigation application stores a vehicle pose (history of vehicle position). The application detects a plurality of matching feature points in a first matching image pair, and determines a plurality of corresponding object points in three-dimensional (3D) space from the first image pair. A plurality of feature points are tracked from the first image pair to a second image pair, and the plurality of corresponding object points in 3D space are determined from the second image pair. From this, a vehicle pose transformation is calculated using the object points from the first and second image pairs. The rotation angle and translation are determined from the vehicle pose transformation. If the rotation angle or translation exceed a minimum threshold, the stored vehicle pose is updated.",G01C 22/00; B60W 40/10; G03B 15/00; G03B 35/08; G06T 7/60,SHARP KABUSHIKI KAISHA,"LIAO, Miao; LI, Ming; HONG, Soonhac","15/076,745 22.03.2016 US",
WO2019164140,PCT/KR2019/001030,24.01.2019,WO/2019/164140,29.08.2019,WO,SYSTEM FOR PROCESSING USER UTTERANCE AND CONTROLLING METHOD THEREOF,"A system includes a communication interface, at least one processor, and at least one memory storing information about a plurality of chatbots and a plurality of categories of the chatbots. The memory may further store instructions that, when executed, cause the processor to receive from a client device including a user interface (UI), data associated with a voice-based or text-based user input associated with or indicative of a request to perform at least one task, to select at least one chatbot from the plurality of chatbots for at least one category for performing the at least one task among the plurality of categories of the plurality of chatbots, and to transmit information on the selected at least one chatbot and the at least one category via the communication interface to the client device such that the client device provides the information through the UI.",G10L 15/04; G10L 15/28; G10L 15/22; G06F 3/048,"SAMSUNG ELECTRONICS CO., LTD.","BYUN, Dooho; KIM, Woonsoo; UM, Taekwang; LEE, Dasom",10-2018-0019610 20.02.2018 KR,
WO2012051346,PCT/US2011/056024,12.10.2011,WO/2012/051346,19.04.2012,WO,METHODS FOR ESTIMATING GENOME-WIDE COPY NUMBER VARIATIONS,"Methods for determining the copy number of a genomic region at a detection position of a target sequence in a sample are disclosed. Genomic regions of a target sequence in a sample are sequenced and measurement data for sequence coverage is obtained. Sequence coverage bias is corrected and may be normalized against a baseline sample. Hidden Markov Model (HMM) segmentation, scoring, and output are performed, and in some embodiments population-based no-calling and identification of low-confidence regions may also be performed. A total copy number value and region-specific copy number value for a plurality of regions are then estimated.",G06F 19/00,"COMPLETE GENOMICS, INC.; HALPERN, Aaron; PANT, Krishna","HALPERN, Aaron; PANT, Krishna","13/270,989 11.10.2011 US; 61/503,327 30.06.2011 US; 61/392,567 13.10.2010 US",EP-2011833368
WO2019152177,PCT/US2019/013513,14.01.2019,WO/2019/152177,08.08.2019,WO,SYSTEM AND METHOD FOR NEUROMORPHIC VISUAL ACTIVITY CLASSIFICATION BASED ON FOVEATED DETECTION AND CONTEXTUAL FILTERING,"Described is a system for visual activity recognition. In operation, the system detects a set of objects of interest (OI) in video data and determines an object classification for each object in the set of OI, the set including at least one OI. A corresponding activity track is formed for each object in the set of OI by tracking each object across frames. Using a feature extractor, the system determines a corresponding feature in the video data for each OI, which is then used to determine a corresponding initial activity classification for each OI. One or more OI are then detected in each activity track via foveation, with the initial object detection and foveated object detection thereafter being appended into a new detected-objects list. Finally, a final classification is provided for each activity track using the new detected-objects list and filtering the initial activity classification results using contextual logic.",G06K 9/00; G06N 3/04; G05D 1/02,"HRL LABORATORIES, LLC","KHOSLA, Deepak; UHLENBROCK, Ryan, M.; CHEN, Yang; SU, Huapeng","15/947,032 06.04.2018 US; 62/642,959 14.03.2018 US; 15/883,822 30.01.2018 US",
WO2019081623,PCT/EP2018/079241,25.10.2018,WO/2019/081623,02.05.2019,WO,AUTO-REGRESSIVE NEURAL NETWORK SYSTEMS WITH A SOFT ATTENTION MECHANISM USING SUPPORT DATA PATCHES,"A system comprising a causal convolutional neural network to autoregressively generate a succession of values of a data item conditioned upon previously generated values of the data item. The system includes support memory for a set of support data patches each of which comprises an encoding of an example data item. A soft attention mechanism attends to one or more patches when generating the current item value. The soft attention mechanism determines a set of scores for the support data patches, for example in the form of a soft attention query vector dependent upon the previously generated values of the data item. The soft attention query vector is used to query the memory. When generating the value of the data item at a current iteration layers of the causal convolutional neural network are conditioned upon the support data patches weighted by the scores.",G06N 3/04; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"VAN DEN OORD, Aaron Gerard Antonius; CHEN, Yutian; REZENDE, Danilo Jimenez; VINYALS, Oriol; GOMES DE FREITAS, Joao Ferdinando; REED, Scott Ellison","62/577,114 25.10.2017 US",
WO2019032817,PCT/US2018/045990,09.08.2018,WO/2019/032817,14.02.2019,WO,OBJECT LOCALIZATION USING A SEMANTIC DOMAIN,"Localizing vehicles, via the registration of a map and images of a vehicle's environment, is discussed. Both the map and images are 2D representations of the Earth's surface, both are from an aerial-view of the surface, and both are represented in a semantic-domain, rather than a visual-domain. The map is a semantic map that includes 2D semantic representations of objects located on the surface. The semantic representations of the map indicate semantic labels and absolute positions of the objects. The images are semantic images that include additional 2D semantic representations of the objects. The additional semantic representations of the images indicate semantic labels and relative positions of the objects. Via image registration, the absolute position and orientation of the vehicle are determined based on a spatial and rotational correspondence between the absolute and relative positions of the objects.",G06N 3/02; G06N 3/067; H04B 10/70; H04N 19/169; G05D 1/02; G06K 9/46,"YDRIVE, INC.","STOJANOVIC, Milos; PADMANABHAN, Udiyan","62/543,275 09.08.2017 US; 62/583,284 08.11.2017 US; 16/058,795 08.08.2018 US",
WO2018184204,PCT/CN2017/079719,07.04.2017,WO/2018/184204,11.10.2018,WO,METHODS AND SYSTEMS FOR BUDGETED AND SIMPLIFIED TRAINING OF DEEP NEURAL NETWORKS,"Methods and systems for budgeted and simplified training of deep neural networks (DNNs) are disclosed. In one example， a trainer is to train a DNN using a plurality of training sub-images derived from a down-sampled training image. A tester is to test the trained DNN using a plurality of testing sub-images derived from a down-sampled testing image. In another example， in a recurrent deep Q-network (RDQN) having a local attention mechanism located between a convolutional neural network (CNN) and a long-short time memory (LSTM), a plurality of feature maps are generated by the CNN from an input image. Hard-attention is applied by the local attention mechanism to the generated plurality of feature maps by selecting a subset of the generated feature maps. Soft attention is applied by the local attention mechanism to the selected subset of generated feature maps by providing weights to the selected subset of generated feature maps in obtaining weighted feature maps. The weighted feature maps are stored in the LSTM. A Q value is calculated for different actions based on the weighted feature maps stored in the LSTM.",G06K 9/66; G06N 3/08,"INTEL CORPORATION; GUO, Yiwen; HOU, Yuqing; YAO, Anbang; CAI, Dongqi; WANG, Libin; XU, Lin; HU, Ping; WANG, Shandong; CHENG, Wenhua; CHEN, Yurong","GUO, Yiwen; HOU, Yuqing; YAO, Anbang; CAI, Dongqi; WANG, Libin; XU, Lin; HU, Ping; WANG, Shandong; CHENG, Wenhua; CHEN, Yurong",,CN-201780088119.0; EP-2017904518
WO2004084009,PCT/US2004/006742,05.03.2004,WO/2004/084009,30.09.2004,WO,METHOD AND EXPERT SYSTEM FOR DOCUMENT CONVERSION,"An expert system for more efficiently and accurately deducing document structure from document formatting, the expert system including a conversion engine for converting an unstructured file to a structured file, and a verification engine, responsive to the output of the conversion engine, for generating and displaying a representation of the structured file annotated with a visual depictions of the classified components thereof so that the annotations can be modified and/or classifications can be added and/or classifications can be suggested, and/or rules for classification can be suggested and the structured file reprocessed by the conversion engine.",G06F 15/00,"TEXTERITY, INC.; MCLURE, Petra; SCHOLZ, Carl; WHITNEY, Ronald","MCLURE, Petra; SCHOLZ, Carl; WHITNEY, Ronald","10/388,685 14.03.2003 US",CA-2519216; IN-1600/MUMNP/2005; IN-1006/MUMNP/2005; IL-170854; EP-2004718041; IN-01006/MUMNP/2005
WO2018217863,PCT/US2018/034088,23.05.2018,WO/2018/217863,29.11.2018,WO,METHODS AND APPARATUS FOR ENHANCING A BINARY WEIGHT NEURAL NETWORK USING A DEPENDENCY TREE,"Methods and apparatus are disclosed for enhancing a binary weight neural network using a dependency tree. A method of enhancing a convolutional neural network (CNN) having binary weights includes constructing a tree for obtained binary tensors, the tree having a plurality of nodes beginning with a root node in each layer of the CNN. A convolution is calculated of an input feature map with an input binary tensor at the root node of the tree. A next node is searched from the root node of the tree and a convolution is calculated at the next node using a previous convolution result calculated at the root node of the tree. The searching of a next node from root node is repeated for all nodes from the root node of the tree, and a convolution is calculated at each next node using a previous convolution result.",G06N 3/04; G06N 3/08,INTEL CORPORATION,"GUO, Yiwen; YAO, Anbang; ZHAO, Hao; LU, Ming; CHEN, Yurong","62/510,075 23.05.2017 US",EP-2018806815; CN-201880026996.X
WO2007117980,PCT/US2007/064971,27.03.2007,WO/2007/117980,18.10.2007,WO,METHOD AND SYSTEM FOR COMPUTERIZED SEARCHING AND MATCHING USING EMOTIONAL PREFERENCE,"A method and system for capturing emotional preference of human subjects, generating machine-readable emotional code and using the code to optimize computerized searching and matching operations between entities is disclosed. The entity can be a human user, a product, or a service. The emotional code can thus be a universal language expressing human emotion that communicates among entities. After understanding the sending parties's emotional profile, the receiving party can adapt its operation to achieve more optimum results.",G06F 17/00,"IMAGINI HOLDINGS LIMITED; WILLCOCK, Alex; LUI, Jacqueline, C.","WILLCOCK, Alex","60/787,546 31.03.2006 US; 11/677,055 21.02.2007 US",EP-2007759419; CN-200780019701.8
WO2020069160,PCT/US2019/053200,26.09.2019,WO/2020/069160,02.04.2020,WO,SELF-AWARE VISUAL-TEXTUAL CO-GROUNDED NAVIGATION AGENT,"An agent for navigating a mobile automated system is disclosed herein. The navigation agent receives a navigation instruction and visual information for one or more observed images. The navigation agent is provided or equipped with self-awareness, which provides or supports the following abilities: identifying which direction to go or proceed by determining the part of the instruction that corresponds to the observed images (visual grounding), and identifying which part of the instruction has been completed or ongoing and which part is potentially needed for the next action selection (textual grounding). In some embodiments, the navigation agent applies regularization to ensures that the grounded instruction can correctly be used to estimate the progress made towards the navigation goal (progress monitoring).",G05D 1/00; G10L 15/00,"SALESFORCE.COM, INC.","MA, Chih-Yao; XIONG, Caiming","62/737,684 27.09.2018 US; 16/176,955 31.10.2018 US",
EP215067165,16811440,01.06.2016,3312776,25.04.2018,EP,"EMOTION CONTROL SYSTEM, SYSTEM, AND PROGRAM","It is impossible to change tastes and preferences with a robot or artificial intelligence. Provided is an emotion control system comprising an information acquiring section that acquires network content acquired from a public network; a storage section that stores effect information indicating an effect exerted on an emotion of a control target by the network content; an updating section that updates the effect information stored in the storage section, based on sensor information detected by a sensor of the control target; and an emotion control section that controls the emotion of the control target based on the network content acquired by the information acquiring section and the effect information stored in the storage section.",G06N 3/00; B25J 13/00; G05B 13/02; G06N 3/02; H04L 29/08,COCORO SB CORP,SON MASAYOSHI; TOMONAGA KOSUKE,2015122408 17.06.2015 JP; 2016066312 01.06.2016 JP,
WO2008014826,PCT/EP2006/065054,03.08.2006,WO/2008/014826,07.02.2008,WO,"METHOD AND DEVICE FOR IDENTIFYING AND EXTRACTING IMAGES OF MULTIPLE USERS, AND FOR RECOGNIZING USER GESTURES","The invention relates to a method for identifying and extracting images of one or more users in an interactive environment comprising the steps of : - obtaining a depth map (7) of a scene in the form of an array of depth values, and an image (8) of said scene in the form of a corresponding array of pixel values, said depth map (7) and said image (8) being registered; applying a coordinate transformation to said depth map (7) and said image (8) for obtaining a corresponding array (15) containing the 3D positions in a real- world coordinates system and pixel values points; - grouping said points according to their relative positions, by using a clustering process (18) so that each group contains points that are in the same region of space and correspond to a user location (19); - defining individual volumes of interest (20) each corresponding to one of said user locations (19); - selecting, from said array (15) containing the 3D positions and pixel values, the points located in said volumes of interest for obtaining segmentation masks (35) for each user; - applying said segmentation masks (35) to said image (8) for extracting images of said users. The invention also relates to a method for recognizing gestures of said users.",G06T 7/00; G06K 9/00,"ALTERFACE S.A.; MAISON, Benoît; SOHY, Xavier","MAISON, Benoît; SOHY, Xavier",,US-12309800; EP-2006792688; EP-2013151011; EP-2013151009
WO2014165286,PCT/US2014/025094,12.03.2014,WO/2014/165286,09.10.2014,WO,"SYSTEMS AND METHODS FOR RECOGNIZING, CLASSIFYING, RECALLING AND ANALYZING INFORMATION UTILIZING SSM SEQUENCE MODELS","A biologically-inspired model for sequence representation, method of construction and application of such models, and systems incorporating same are provided. The model captures the statistical nature of sequences and uses that for sequence encoding, recognition, and recall. The model can be trained in real time, has few tunable parameters, and is highly parallelizable, which ensures that it can scale up to very large problems. Applications of the model to word and speech recognition, machine leaning, robotics, computational bioinformatics, genetics datasets, and other sequence processing pipelines are provided.",G06F 19/00,"IOWA STATE UNIVERSITY RESEARCH FOUNDATION, INC.; STOYTCHEV, Alexander; SUKHOY, Volodymyr","STOYTCHEV, Alexander; SUKHOY, Volodymyr","61/777,032 12.03.2013 US",
WO2018148574,PCT/US2018/017666,09.02.2018,WO/2018/148574,16.08.2018,WO,AGENT NAVIGATION USING VISUAL INPUTS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for navigation using visual inputs. One of the systems includes a mapping subsystem configured to, at each time step of a plurality of time steps, generate a characterization of an environment from an image of the environment at the time step, wherein the characterization comprises an environment map identifying locations in the environment having a particular characteristic, and wherein generating the characterization comprises, for each time step: obtaining the image of the environment at the time step, processing the image to generate a first initial characterization for the time step, obtaining a final characterization for a previous time step, processing the characterization for the previous time step to generate a second initial characterization for the time step, and combining the first initial characterization and the second initial characterization to generate a final characterization for the time step.",G06T 7/00; G05B 13/02; G06T 1/40,GOOGLE LLC,"SUKTHANKAR, Rahul; GUPTA, Saurabh; DAVIDSON, James Christopher; LEVINE, Sergey Vladimir; MALIK, Jitendra","62/456,945 09.02.2017 US",EP-2018751319; KR-1020197023399; CN-201880010935.4; JP-2019543104
WO2018204910,PCT/US2018/031356,07.05.2018,WO/2018/204910,08.11.2018,WO,LOSS-SCALING FOR DEEP NEURAL NETWORK TRAINING WITH REDUCED PRECISION,"In training a deep neural network using reduced precision, gradient computation operates on larger values without affecting the rest of the training procedure. One technique trains the deep neural network to develop loss, scales the loss, computes gradients at a reduced precision, and reduces the magnitude of the computed gradients to compensate for scaling of the loss. In one example nonlimiting arrangement, the training forward pass scales a loss value by some factor S and the weight update reduces the weight gradient contribution by 1/S. Several techniques can be used for selecting scaling factor S and adjusting the weight update.",G06N 3/08,NVIDIA CORPORATION,"WU, Hao; ALBEN, Jonah; MICIKEVICIUS, Paulius","62/502,333 05.05.2017 US; 15/971,884 04.05.2018 US; 62/561,499 21.09.2017 US",CN-201880004842.0
EP238739117,16899897,04.05.2016,3451157,06.03.2019,EP,DEVICE AND METHOD FOR PERFORMING FORWARD OPERATION OF CONVOLUTIONAL NEURAL NETWORK,"The present invention provides a device performing a forward operation of convolutional neural network, comprising an instruction storage unit, a controller unit, a data access unit, an interconnection module, a master operation module and a plurality of slave operation modules. The device implement a forward operation of one or more convolution layers of artificial neural network. For each layer, firstly, the input neuron vectors are selected for data according to the convolution window, then conducting a convolution operation with the convolution kernel to calculate an intermediate result of this layer, and then the intermediate result is biased and activated to obtain an output data. The output data is taken as an input data for the next layer.",G06F 9/30; G06F 9/46; G06F 13/362; G06N 3/04; G06N 3/063; G06N 3/08,CAMBRICON TECH CORPORATION LIMITED,CHEN TIANSHI; HAN DONG; CHEN YUNJI; LIU SHAOLI; GUO QI,2016080967 04.05.2016 CN; 201610282534 29.04.2016 CN,
EP232545775,18159837,02.03.2018,3396602,31.10.2018,EP,NEURAL NETWORK TRAINING MECHANISM,An apparatus to facilitate neural network (NN) training is disclosed. The apparatus includes training logic to receive one or more network constraints and train the NN by automatically determining a best network layout and parameters based on the network constraints.,G06N 3/063; G06F 9/30; G06F 9/38,INTEL CORP,CILINGIR GOKCEN; OULD-AHMED-VALL ELMOUSTAPHA; BARIK RAJKISHORE; NEALIS KEVIN; CHEN XIAOMING; GOTTSCHLICH JUSTIN E; SURTI PRASOONKUMAR; SAKTHIVEL CHANDRASEKARAN; APPU ABHISHEK R; WEAST JOHN C; BAGHSORKHI SARA S; DAS BARNAN; BISWAL NARAYAN; BARAN STANLEY J; SHAH NILESH; SHARMA ARCHIE; VARERKAR MAYURESH M,201715494826 24.04.2017 US,
WO2016125148,PCT/IL2016/050108,01.02.2016,WO/2016/125148,11.08.2016,WO,METHODS AND COMPOSITIONS FOR DIAGNOSING BRAIN INJURY OR NEURODEGENERATION,"Methods and compositions for diagnosing brain injury, neurodegeneration; or a predisposition thereto, in a subject are provided. Particularly, the present invention relates to specific antigen antibody reactivities useful in diagnosing brain injury, neurodegeneration or a predisposition thereto, in a subject.",G01N 33/50; G01N 33/53; C07K 14/46,"IMMUNARRAY USA, INC.","SOREK, Rachel; JAKOBI, Keren; EDMONDS, Donna","62/112,189 05.02.2015 US",US-15547252; JP-2017559939; EP-2016746229; IL-253728
WO2019143435,PCT/US2018/066045,17.12.2018,WO/2019/143435,25.07.2019,WO,AUTONOMOUSLY-CONTROLLED INSPECTION PLATFORM WITH MODEL-BASED ACTIVE ADAPTIVE DATA COLLECTION,"Modifying a motion plan for an autonomously-operated inspection platform (AIP) includes obtaining sensor data for an industrial asset area of interest, analyzing the obtained sensor data during execution of an initial motion plan to determine if modification of the initial motion plan is required. If modification is required then performing a pose estimation on a first group of potential targets and a second group of potential targets, optimizing the results of the pose estimation to determine a modification to the initial motion plan, performing reactive planning to the initial motion plan to include the modification, the reactive planning providing a modified motion plan that includes a series of waypoints defining a modified path, and autonomously controlling motion of the AIP along the modified path. The analysis, pose estimation, optimization, and reactive planning occurring during movement of the AIP along a motion plan. A system and computer-readable medium are disclosed.",G05B 19/418; G05B 19/425; G05D 1/02,GENERAL ELECTRIC COMPANY,"TAN, Huan; DASILVA, Ana; GROS, Eric; PATRICK, Romano; THEURER, Charles; CASTILLO-EFFEN, Mauricio; LIZZI, John","15/872,582 16.01.2018 US",
EP14961787,08006012,29.11.2002,1942679,09.07.2008,EP,Automatic detection and tracking of multiple individuals' faces using multiple cues,"Automatic detection and tracking of multiple individuals includes receiving a frame of video and/or audio content and identifying a candidate area for a new face region in the frame. One or more hierarchical verification levels are used to verify whether a human face is in the candidate area, and an indication made that the candidate area includes a face if the one or more hierarchical verification levels verify that a human face is in the candidate area. A plurality of audio and/or video cues are used to track each verified face in the video content from frame to frame.",G06T 1/00; G06T 7/20; G06K 9/00; G06T 1/20; G06T 7/00; H04N 7/15; H04N 7/26,MICROSOFT CORP,RUI YONG; CHEN YUNGJANG,02026684 29.11.2002 EP; 692701 03.12.2001 US,
EP14734826,06124602,22.11.2006,1793318,06.06.2007,EP,Answer determination for natural language questionning,"Open-domain question answering is the task of finding a concise answer to a natural language question using a large domain, such as the Internet. The use of a semantic role labeling approach to the extraction of the answers to an open domain factoid (Who/When/What/Where) natural language question that contains a predicate is described. Semantic role labeling identities predicates and semantic argument phrases in the natural language question and the candidate sentences. When searching for an answer to a natural language question, the missing argument in the question is matched using semantic parses of the candidate answers. Such a technique may improve the accuracy of a question answering system and may decrease the length of answers for enabling voice interface to a question answering system.",G06F 17/27,AT & T CORP,STENCHIKOVA SVETLANA; TUR GOKHAN; TUR DILEK HAKKANI,31918805 28.12.2005 US; 74063205 30.11.2005 US,
WO2009100417,PCT/US2009/033532,09.02.2009,WO/2009/100417,13.08.2009,WO,METHOD FOR TRAINING A LEARNING MACHINE HAVING A DEEP MULTI-LAYERED NETWORK WITH LABELED AND UNLABELED TRAINING DATA,"A method for training a learning machine having a deep network with a plurality of layers, includes applying a regularizer to one or more of the layers of the deep network; training the regularizer with unlabeled data; and training the deep network with labeled data. Also, an apparatus for use in discriminative classification and regression, including an input device for inputting unlabeled and labeled data associated with a phenomenon of interest; a processor; and a memory communicating with the processor. The memory includes instructions executable by the processor for implementing a learning machine having a deep network structure and training the learning machine by applying a regularizer to one or more of the layers of the deep network; training the regularizer with unlabeled data; and training the deep network with labeled data.",G06F 15/18; G06F 9/44,"NEC LABORATORIES AMERICA, INC.","WESTON, Jason; COLLOBERT, Ronan","61/026,860 07.02.2008 US; 12/367,278 06.02.2009 US",EP-2009708540
WO2017035380,PCT/US2016/048748,25.08.2016,WO/2017/035380,02.03.2017,WO,SYSTEMS AND METHODS FOR MACHINE LEARNING,System and methods for machine learning are described. A first input value is obtained. A second input value is also obtained. A decision to use for generating a cycle output is selected based on a randomness factor. The decision is at least one of a random decision or a best decision from a previous cycle. A cycle output for the first and second inputs is generated using the selected decision. The selected decision and the resulting cycle output are stored.,G06N 3/02; G06N 3/08,"RYSKAMP INNOVATIONS, LLC","RYSKAMP, Rix","62/209,799 25.08.2015 US",
WO2019050992,PCT/US2018/049612,05.09.2018,WO/2019/050992,14.03.2019,WO,UNIFIED NEURAL NETWORK FOR DEFECT DETECTION AND CLASSIFICATION,Methods and systems for detecting and classifying defects on a specimen are provided. One system includes one or more components executed by one or more computer subsystems. The one or more components include a neural network configured for detecting defects on a specimen and classifying the defects detected on the specimen. The neural network includes a first portion configured for determining features of images of the specimen generated by an imaging subsystem. The neural network also includes a second portion configured for detecting defects on the specimen based on the determined features of the images and classifying the defects detected on the specimen based on the determined features of the images.,G01N 21/95; G01N 23/2251; G06N 3/04; G06N 3/08,KLA-TENCOR CORPORATION,"HE, Li; MAHADEVAN, Mohan; VENKATARAMAN, Sankar; YING, Huajun; YANG, Hedong","15/697,426 06.09.2017 US",
EP12586715,93480095,09.07.1993,0633536,11.01.1995,EP,Diagnosis method and system for predictive machine maintenance.,"The system has at least one physical parameter the value of which contains information about the operating condition of a machine (1). The system includes :   a) sensor means (2) for monitoring a set of parameters representative of the operation of said physical system and for acquiring a set of analog and/or digital raw data based on said parameters; b) computation means (3) to which said analog and/or digital values are supplied and on which at least one mathematical function is performed, whereby at least one vector of values representative of the processed raw data is generated; c) diagnosis means (4) in the form of a neural network using said vectors of values in order to generate a diagnosis representative of the operative condition of said machine.   <IMAGE>",G06F 17/00; G05B 23/02; G06F 15/18; G06F 17/00; G06F 19/00,IBM,CORRIEU JEAN-MICHEL,93480095 09.07.1993 EP,
WO2002006016,PCT/GB2001/003193,17.07.2001,WO/2002/006016,24.01.2002,WO,CONTROL SYSTEM,A control system implemented preferably using artifical neural networks is described. A controller (20) is arranged to accept an input and generates a control signal for application to a plant (10) and an expected output signal. A comparator (30) compares a plant output signal with the expected output signal in a competitive process and stores the winning signal in a buffer (50). The contents of the buffer (50) are output from the control system as at least a part of the output of the plant (10).,B25J 9/16,"KING'S COLLEGE LONDON; TAYLOR, John, Gerald","TAYLOR, John, Gerald",0017528.1 17.07.2000 GB,
WO2019060125,PCT/US2018/049129,31.08.2018,WO/2019/060125,28.03.2019,WO,THREE-DIMENSIONAL BOUNDING BOX FROM TWO-DIMENSIONAL IMAGE AND POINT CLOUD DATA,A three-dimensional bounding box is determined from a two-dimensional image and a point cloud. A feature vector associated with the image and a feature vector associated with the point cloud may be passed through a neural network to determine parameters of the three- dimensional bounding box. Feature vectors associated with each of the points in the point cloud may also be determined and considered to produce estimates of the three-dimensional bounding box on a per-point basis.,G06K 9/00; G06K 9/46,"ZOOX, INC.","XU, Danfei; ANGUELOV, Dragomir Dimitrov; JAIN, Ashesh","15/797,573 30.10.2017 US; 62/562,193 22.09.2017 US",
WO2006042543,PCT/DK2005/000652,12.10.2005,WO/2006/042543,27.04.2006,WO,A METHOD OF ANALYZING AND SORTING EGGS,"In a method of analyzing and sorting eggs which are advanced and rolled on a conveyor belt, a plurality of images of each egg are recorded by a plurality of cameras, and it is analyzed for each egg whether there are any ar­eas in the image which may be an indication of whether the egg is cracked, contains impurities or the like. The analysis takes place in that each image is subjected to a line scan, and if the line includes an edge defined by two adjacent pixels where the inten­sity value between the two adjacent pixels is numerically greater than a certain value, e.g. 15, a discriminant analysis is provided around the edge in a subarea of the image of 25 X 25 pixels. The analysis establishes a class which defines characteristic features around the edge. When all the edges of the egg have been analyzed, it is determined by a calculation of the classes, including whether the classes define clusters, whether the egg has a crack, an impurity or the like, which means that it is removed by means of a robot. The invention provides a high degree of precision in the sorting-out of eggs which have cracks, impurities or the like, as it is not the total number of pixels with light intensities above a certain value on the entire egg which is used as a criterion, but an evaluation of the position of the edges and characteristic features on the surface of the eggs which is used for the analyses.",G01N 33/08,"IHFOOD A/S; MADSEN, JaKob, Find","MADSEN, JaKob, Find",PA 2004 01622 22.10.2004 DK,JP-2007537114; EP-2005790762; US-11666044
EP282270463,18777880,29.03.2018,3598770,22.01.2020,EP,ELECTRONIC DEVICE FOR DETERMINING EMOTION OF USER AND METHOD FOR CONTROLLING SAME,"The present disclosure relates to an artificial intelligence (AI) system utilizing a machine learning algorithm such as deep learning, and application of the same. In particular, a method for controlling an electronic device of the present disclosure comprises the steps of: obtaining image data and supplementary data including data on a user from an external terminal connected to the electronic device; generating feature data for determining the user's actual emotion by using the image data and the supplementary data; and determining the user's actual emotion by inputting the feature data into an emotion recognition model.",H04N 21/466; G06N 5/04,SAMSUNG ELECTRONICS CO LTD,YUN SO-JUNG; KIM YE-HOON; JANG JUN-IK,20170041774 31.03.2017 KR; 20170162116 29.11.2017 KR; 2018003735 29.03.2018 KR,
WO2013094441,PCT/JP2012/081864,04.12.2012,WO/2013/094441,27.06.2013,WO,METHOD FOR ESTIMATING POSE OF OBJECT,"A pose of an object is estimated by first defining a set of pair features as pairs of geometric primitives, wherein the geometric primitives include oriented surface points, oriented boundary points, and boundary line segments. Model pair features are determined based on the set of pair features for a model of the object. Scene pair features are determined based on the set of pair features from data acquired by a 3D sensor, and then the model pair features are matched with the scene pair features to estimate the pose of the object.",G06T 7/00,"MITSUBISHI ELECTRIC CORPORATION; TAGUCHI, Yuichi; TUZEL, Oncel; RAMALINGAM, Srikumar; CHOI, Changhyun; LIU, Ming-Yu","TAGUCHI, Yuichi; TUZEL, Oncel; RAMALINGAM, Srikumar; CHOI, Changhyun; LIU, Ming-Yu","13/329,493 19.12.2011 US",JP-2014514266; DE-1120120053508; DE-112012005350
WO2018185764,PCT/IL2018/050394,03.04.2018,WO/2018/185764,11.10.2018,WO,CONFIGURABLE AND PROGRAMMABLE SLIDING WINDOW BASED MEMORY ACCESS IN A NEURAL NETWORK PROCESSOR,"A novel and useful neural network (NN) processing core adapted to implement artificial neural networks (ANNs) and incorporating configurable and programmable sliding window based memory access. The memory mapping and allocation scheme trades off random and full access in favor of high parallelism and static mapping to a subset of the overall address space. The NN processor is constructed from self-contained computational units organized in a hierarchical architecture. The homogeneity enables simpler management and control of similar computational units, aggregated in multiple levels of hierarchy. Computational units are designed with minimal overhead as possible, where additional features and capabilities are aggregated at higher levels in the hierarchy. On-chip memory provides storage for content inherently required for basic operation at a particular hierarchy and is coupled with the computational resources in an optimal ratio. Lean control provides just enough signaling to manage only the operations required at a particular hierarchical level. Dynamic resource assignment agility is provided which can be adjusted as required depending on resource availability and capacity of the device.",G06N 3/04; G06F 17/50; G06F 12/0802,HAILO TECHNOLOGIES LTD.,"BAUM, Avi; DANON, Or; ZEITLIN, Hadar; CIUBOTARIU, Daniel; FEIG, Rami","62/481,492 04.04.2017 US; 62/531,372 12.07.2017 US",CN-201880021600.2; JP-2019554894; EP-2018781193
WO2014099740,PCT/US2013/075309,16.12.2013,WO/2014/099740,26.06.2014,WO,HISTOGRAM BASED PRE-PRUNING SCHEME FOR ACTIVE HMMS,"Embodiments of the present invention include an acoustic processing device, a method for acoustic signal processing, and a speech recognition system. The speech processing device can include a processing unit, a histogram pruning unit, and a pre-pruning unit. The processing unit is configured to calculate one or more Hidden Markov Model (HMM) pruning thresholds. The histogram pruning unit is configured to prune one or more HMM states to generate one or more active HMM states. The pruning is based on the one or more pruning thresholds. The pre-pruning unit is configured to prune the one or more active HMM states based on an adjustable pre-pruning threshold. Further, the adjustable pre-pruning threshold is based on the one or more pruning thresholds.",G10L 15/14; G10L 15/28,SPANSION LLC,"BAPAT, Ojas A.","13/725,224 21.12.2012 US",CN-201380073442.2
WO2019016540,PCT/GB2018/052025,17.07.2018,WO/2019/016540,24.01.2019,WO,TARGET RE-IDENTIFICATION,"A computer implemented method and system for training a machine to identify a target within video data, the method comprising the steps of providing a training data set including identified labelled targets within video data having the same target within different video views. Generating, using a learning model, a bounding box action policy for determining required adjustments to a bounding box around a target in the video data by: generating a bounding box around a labelled target within a first view of the video data. Converting the target bounded by the bounding box to a quantitative representation. Determining a matching level between the quantitative representation and a quantitative representation of a further labelled target within the video data from a second view different to the first view. Looping the following steps one or more times, the looped steps comprising: using the bounding box action policy to determine an action to change the bounding box. Applying the determined action to change the bounding box to a new bounding box. Converting the target bounded by the new bounding box to a new quantitative representation. Determining a further matching level between the new quantitative representation and the quantitative representation of the labelled target within the video data from the second view. Applying a reward to the learning model to adjust the bounding box action policy based on an improvement in the matching level.",G06K 9/00; G06K 9/62; G06N 3/08,VISION SEMANTICS LIMITED,"GONG, Shaogang; ZHU, Xiatian; WANG, Hanxiao; LANG, Xu",1711541.1 18.07.2017 GB,EP-2018749061
EP238739213,16899902,05.05.2016,3451241,06.03.2019,EP,DEVICE AND METHOD FOR PERFORMING TRAINING OF CONVOLUTIONAL NEURAL NETWORK,"A device and method for performing a backward training of convolutional neural network, wherein the device comprises an instruction storage unit, a controller unit, a data access unit, an interconnection module, a master operation module and a plurality of slave operation modules. For each layer, firstly, the input neuron vectors are selected for data according to the convolution window, then, based on using the selected data from the previous layer and the data gradient from the next layer as an input to an operation unit of the device, an convolution kernel is calculated and updated. Secondly, based on the convolution kernel, the gradient of the data, and the derivative function of a activation function, a data gradient output by the device is calculated and stored in a memory for outputting to the previous layer for backward propagation calculation. The present invention temporarily stores the data and the weight parameters involved in the calculation on the scratchpad memory, so that the backward training operation of convolutional neural network may be supported flexibly and effectively, and the execution performance of a large number of memory access applications may be improved.",G06N 3/08; G06N 3/063,CAMBRICON TECH CORPORATION LIMITED,CHEN YUNJI; ZHI TIAN; LIU SHAOLI; GUO QI; CHEN TIANSHI,2016081088 05.05.2016 CN; 201610283838 29.04.2016 CN,
WO2004053468,PCT/US2002/039592,10.12.2002,WO/2004/053468,24.06.2004,WO,IMAGE ANALYSIS OF HETEROGENEOUS MIXTURES,"A system for analyzing a plurality of samples (202) containing a dispersion of one or more incompletely miscible components in a continuous fluid phase comprises a vial receptacle located at a first location, an image capturing device (102) directed at the first location, a light source (112) directed at the first location, and a programmable processor (124) operatively coupled to the image capturing device and configured to detect a behavior in a captured image of a sample. The programmable processor defines regions of interest in a captured image, generates an intensity profile for each region of interest, and detects the behavior based on the intensity profile. The programmable processor defines the regions of interest by detecting a sample boundary in a captured image and defining a region within the sample boundary. The programmable processor detects behavior by calculating a Laplacian or a derivative of the intensity profile for the region.",G01N 21/59; G01N 33/18; G01N 33/28,"SYMYX TECHNOLOGIES, INC.; KUEBLER, Sigrid; CARLSON, Eric; CREVIER, Thomas; KOLOSOV, Oleg; LOW, Eric","KUEBLER, Sigrid; CARLSON, Eric; CREVIER, Thomas; KOLOSOV, Oleg; LOW, Eric",,JP-null
WO2013192253,PCT/US2013/046447,19.06.2013,WO/2013/192253,27.12.2013,WO,SELF LEARNING FACE RECOGNITION USING DEPTH BASED TRACKING FOR DATABASE GENERATION AND UPDATE,"Face recognition training database generation technique embodiments are presented that generally involve collecting characterizations of a person's face that are captured over time and as the person moves through an environment, to create a training database of facial characterizations for that person. As the facial characterizations are captured over time, they are will represent the person's face as viewed from various angles and distances, different resolutions, and under different environmental conditions (e.g., lighting and haze conditions). Further, over a long period of time where facial characterizations of a person are collected periodically, these characterizations can represent an evolution in the appearance of the person. This produces a rich training resource for use in face recognition systems. In addition, since a person's face recognition training database can be established before it is needed by a face recognition system, once employed, the training will be quicker.",G06K 9/00,MICROSOFT CORPORATION,"KIKKERI, Harshavardhana Narayana; KOENIG, Michael F.; COLE, Jeffrey","13/530,925 22.06.2012 US",EP-2013731633; JP-2015518531
EP289344324,18906652,03.09.2018,3617959,04.03.2020,EP,COMPUTING DEVICE AND METHOD,"The present disclosure provides a computation device. The computation device is configured to perform a machine learning computation, and includes an operation unit, a controller unit, and a conversion unit. The storage unit is configured to obtain input data and a computation instruction. The controller unit is configured to extract and parse the computation instruction from the storage unit to obtain one or more operation instructions, and to transmit the one or more operation instructions and the input data to the operation unit. The operation unit is configured to perform operations on the input data according to one or more operation instructions to obtain a computation result of the computation instruction. In the examples of the present disclosure, the input data involved in machine learning computations is represented by fixed-point data, thereby improving the processing speed and processing efficiency of training operations.",G06N 3/063,SHANGHAI CAMBRICON INFORMATION TECH CO LTD,ZHANG YAO; WANG BINGRUI,201810149287 13.02.2018 CN; 201810207915 14.03.2018 CN; 2018103850 03.09.2018 CN,
WO2017201487,PCT/US2017/033661,19.05.2017,WO/2017/201487,23.11.2017,WO,METHOD AND SYSTEM FOR PERFORMING CONVOLUTIONAL IMAGE TRANSFORMATION ESTIMATION,"A method for generating inputs for a neural network based on an image includes receiving the image, identifying a position within the image, and identifying a subset of the image at the position. The subset of the image is defined by a first set of corners. The method also includes perturbing at least one of the first set of corners to form a second set of corners. The second set of corners defines a modified subset of the image. The method further includes determining a homography based on a comparison between the subset of the image and the modified subset of the image, generating a transformed image by applying the homography to the image, and identifying a subset of the transformed image at the position.",G06K 7/01; G06K 9/62; G06K 9/40; G06T 3/20; G06N 3/02; G06N 3/06,"MAGIC LEAP, INC.","DETONE, Daniel; MALISIEWICZ, Tomasz Jan; RABINOVICH, Andrew","62/339,799 20.05.2016 US",EP-2017800299; CA-3021085; CN-201780030961.9; IL-262886; AU-2017267983; JP-2018560637; KR-1020187035437
EP254729045,17877417,24.11.2017,3553711,16.10.2019,EP,"INFORMATION PROCESSING DEVICE AND METHOD, AND PROGRAM","The present disclosure relates to an information processing device and method, and program, whereby it is possible to cause a system to efficiently learn a method of controlling a person. A control learning system computes a reward on the basis of an inputted control subject target state and a state of the control subject based on a sensing result of the control subject. By reinforcement learning using the computed reward and the state of the control subject, the control learning system selects a more suitable action for bringing the control subject closer to the target state. The control learning system executes the selected action upon the control subject. The present disclosure may be applied to a control learning system which is formed from a terminal and a cloud system, as an example.",G06N 99/00; G06N 20/00,SONY CORP,KOBAYASHI YOSHIYUKI; TANAKA YASUFUMI; TAKAMATSU SHINGO; NODA ATSUSHI,2016237602 07.12.2016 JP; 2017042153 24.11.2017 JP,
WO2020067633,PCT/KR2019/008652,12.07.2019,WO/2020/067633,02.04.2020,WO,ELECTRONIC DEVICE AND METHOD OF OBTAINING EMOTION INFORMATION,"Emotion information is obtained by an electronic device in order to improve communication between a person and the electronic device. Multimedia data is obtained regarding a person, predicted values for the person are obtained by applying the multimedia data to neural network models, and emotion information of the person is obtained by applying the predicted values to a weight model. Then, feedback information is obtained from the person with respect to the first emotion information of the person. Finally, the weight model is updated by using the feedback information. Subsequently, when multimedia data are again obtained regarding the person, new predicted values for the person are obtained by applying later multimedia data the plurality of neural network models, and emotion information of the person is again obtained, but this time using the weight model updated using the feedback information.",A61B 5/16; A61B 5/00,"SAMSUNG ELECTRONICS CO., LTD.","SEO, Chanwon; ZHANG, Lei; KIM, Yehoon; YUN, Sojung; LEE, Dongwan; KIM, Yongsung; LEE, Juyoung","62/738,656 28.09.2018 US; 10-2018-0140093 14.11.2018 KR",
WO2018129201,PCT/US2018/012407,04.01.2018,WO/2018/129201,12.07.2018,WO,SYSTEMS AND METHODS FOR SHAPE-BASED OBJECT RETRIEVAL,"A method for classifying physical objects includes: controlling, by a processor, one or more depth cameras to capture depth images of a query object; controlling, by the processor, one or more color cameras to capture a color images of the query object; computing, by the processor, a three-dimensional (3D) model of the query object using the depth images; combining, by the processor, the color images with the 3D model; computing, by the processor, a descriptor from the 3D model and the color images, the descriptor including: a multi-dimensional shape descriptor space representation of a 3D shape of the query object; a multi-dimensional color descriptor space representation of a texture of the query object; and a one- dimensional size descriptor space representation of a size of query object; supplying, by the processor, the descriptor to a classifier to compute a classification of the query object; and outputting the classification of the query object.",G06Q 10/08; G06Q 30/06; G06K 9/20; G06N 3/02; G06T 7/55; H04N 21/84,"AQUIFI, INC.","DAL MUTTO, Carlo; MEMO, Alvise","62/442,223 04.01.2017 US",EP-2018736333; CN-201880015857.7
WO2018005701,PCT/US2017/039835,28.06.2017,WO/2018/005701,04.01.2018,WO,VIDEO TO DATA,"A method and system can generate video content from a video, The method and system can include a coordinator, an image detector, and an object recognizer. The coordinator can be communicatively coupled to a splitter and/or to a plurality of demultiplexer nodes. The splitter can be configured to segment the video. The demultiplexer nodes can be configured to extract audio files from the video and/or to extract still frame images from the video. The image detector can be configured to detect images of objects in the still frame images. The object recognizer can be configured to compare an image of an object to a fractal. The recognizer can be further configured to update the fractal with the image. The coordinator can be configured to embed metadata about the object into the video.",G06K 9/00; G06K 9/36; G06T 5/00; G06T 5/50; G06T 7/20; G06T 13/00; G06T 17/00,"CELLULAR SOUTH, INC. DBA C SPIRE WIRELESS","SMITH, Bartlett, Wade; TALLEY, Allison, A.; SHIELDS, John, Carlos","15/197,727 29.06.2016 US",CA-3029411
EP249469726,19151350,11.01.2019,3518141,31.07.2019,EP,SIMILARITY LEARNING AND ASSOCIATION BETWEEN OBSERVATIONS OF MULTIPLE CONNECTED VEHICLES,,G06K 9/00; G06K 9/62,TOYOTA MOTOR CO LTD,GUO RUI; OGUCHI KENTARO,201815870874 13.01.2018 US,
WO2019081208,PCT/EP2018/077589,10.10.2018,WO/2019/081208,02.05.2019,WO,AVOIDING CATASTROPHIC INTERFERENCE WHILE TRAINING AN ARTIFICIAL NEURAL NETWORK ON AN ADDITIONAL TASK.,"Method for training an artificial neural network on an additional untrained segmentation task, while preventing the loss of previously acquired segmentation skills on originally trained segmentation tasks.",G06T 7/10; G06N 3/04,AGFA HEALTHCARE NV; VRVIS ZENTRUM FÜR VIRTUAL REALITY UND VISUALISIERUNG FORSCHUNGS-GMBH,"NOVIKOV, Alexey; BUEHLER, Katja; MAJOR, David; WIMMER, Maria",17197899.2 24.10.2017 EP,
WO2017087406,PCT/US2016/062070,15.11.2016,WO/2017/087406,26.05.2017,WO,AUTOMATICALLY SCANNING AND REPRESENTING AN ENVIRONMENT HAVING A PLURALITY OF FEATURES,"Automatic scanning and representing an environment having a plurality of features, for example, includes scanning the environment along a scanning path, interspersing a plurality of localized scanning of the plurality of features in the environment during the scanning along the scanning path of the environment wherein the interspersed localized scanning of the plurality of features in the environment being different from the scanning the environment along the scanning path, and obtaining a representation of at least a portion of the environment based on the scanning of the environment and the interspersed localized scanning of the plurality of features in the environment.",G06K 9/00,"ABB SCHWEIZ AG; WANG, Jianjun; ZHANG, Biao; MARTINEZ, Carlos; MORATO, Carlos W.; BOCA, Remus","WANG, Jianjun; ZHANG, Biao; MARTINEZ, Carlos; MORATO, Carlos W.; BOCA, Remus","14/941,826 16.11.2015 US",EP-2016866960
WO2018002025,PCT/EP2017/065810,27.06.2017,WO/2018/002025,04.01.2018,WO,EVALUATION OF DECISION TREE USING ONTOLOGY,"A system and method are provided for use in evaluating a clinical guideline which is represented in a machine readable version by a decision tree comprising at least one node and a decision rule associated with the node. The decision rule comprises at least one variable representing a biomedical quantity. The biomedical quantity is extracted from the patient data using an ontology which defines concepts and their relationships in a medical domain of the clinical guideline and which thereby relates the variable of the decision rule to the patient data. If said extraction is not possible, a view of the patient data is presented to the user to enable the user to determine the biomedical quantity from the view. Advantageously, the user is assisted in evaluating the clinical guideline even when it is not possible to automatically extract the biomedical quantity from the patient data.",G06F 19/00,KONINKLIJKE PHILIPS N.V.,"WEKEL, Tilman; GROTH, Alexandra; WEESE, Rolf, Jürgen",16176377.6 27.06.2016 EP,EP-2017739895; CN-201780040137.1; US-16300104
EP76200066,12170557,01.06.2012,2562690,27.02.2013,EP,Assigning a number of reference measurement data sets to an input measurement data set,"The invention concerns a Method and system for assigning a number of reference measurement data sets (A, R2, R3, R4, R5), selected from a plurality of reference measurement data sets (R1, ..., Ri) to an input measurement data set (I) comprising the following steps: 
- determining a query instance (QD) based on the input measurement data set (I) 
- providing a Random Forest (RF1, RF2, RF3) 
- determining query leaves (QL1, ..., QLk) determined by the Random Forest (RF1, RF2, RF3), based on the query instance (QD) 
- assigning the number of reference measurement data sets (A, R2, R3, R4, R5) to the input measurement data set (I), based on the determined query leaves (QL1, ..., QLk) and based on reference leaves (RL111, RL112, ..., RLfik) determined by the Random Forest (RF1, RF2, RF3) for a plurality of reference instances ((RD11, ..., RDfi) based on the plurality of the reference measurement data sets (R1, ...,Ri).",G06K 9/62; G06K 9/00,SIEMENS AG,COSTA MARIA JIMENA; TSYMBAL ALEXEY; SEIFERT SASCHA; SUEHLING MICHAEL,11178290 22.08.2011 EP; 12170557 01.06.2012 EP,
WO2014155131,PCT/GB2014/050996,28.03.2014,WO/2014/155131,02.10.2014,WO,GESTURE TRACKING AND CLASSIFICATION,"A method of tracking the position of a body part, such as a hand, in captured images, the method comprising capturing (10) colour images of a region to form a set of captured images; identifying contiguous skin-colour regions (12) within an initial image of the set of captured images; defining regions of interest (16) containing the skin-coloured regions; extracting (18) image features in the regions of interest, each image feature relating to a point in a region of interest; and then, for successive pairs of images comprising a first image and a second image, the first pair of images having as the first image the initial image and a later image, following pairs of images each including as the first image the second image from the preceding pair and a later image as the second image: extracting (22) image features, each image feature relating to a point in the second image; determining matches (24) between image features relating to the second image and image features relating to in each region of interest in the first image; determining the displacement within the image of the matched image features between the first and second images; disregarding (28) matched features whose displacement is not within a range of displacements; determining regions of interest (30) in the second image containing the matched features which have not been disregarded; and determining the direction of movement (34) of the regions of interest between the first image and the second image.",G06K 9/00; G06K 9/46; G06T 7/20,THE UNIVERSITY OF WARWICK,"LI, Chang-Tsun; YAO, Yi",1305812.8 28.03.2013 GB,EP-2014726185; US-14779835
WO2016145300,PCT/US2016/021988,11.03.2016,WO/2016/145300,15.09.2016,WO,CHEMICAL SENSOR,"The invention provides a chemical sensor system comprising a nanomaterial based chemical sensor chip for detection of chemicals in gas, vapor, liquid and aerosol phase utilizing pattern recognition algorithms. Additionally the invention provides methods of fabricating the chemical sensor chip and sensing with the chip. Additionally the invention provides methods for collecting, storing, sharing and distributing data utilizing automated and predictive algorithms.",G01N 33/50; A61B 5/00; G01N 31/00; G08B 21/12; G08B 21/14,"NANO ENGINEERED APPLICATIONS, INC.","DOSHI, Sundip R.; SU, Heng Chia; CHEN, Albert Chien-En; HUTCHINS, Dale","62/131,586 11.03.2015 US; 62/175,640 15.06.2015 US",
WO2019068236,PCT/CN2017/109552,06.11.2017,WO/2019/068236,11.04.2019,WO,METHOD OF SELECTION OF AN ACTION FOR AN OBJECT USING A NEURAL NETWORK,"A method, device and system of prediction of a state of an object in the environment using an action model of a neural network. In accordance with one aspect, a control system (115) for an object comprises a processor (102), a plurality of sensors (110) coupled to the processor (102) for sensing a current state of the object and an environment in which the object is located, and a first neural network (250) coupled to the processor (102). A plurality of predicted subsequent states of the object in the environment is obtained using an action model, a current state of the object in the environment and a plurality of actions. The action model maps a plurality of states of the object in the environment and a plurality of actions performed by the object for each state to predicted subsequent states of the object in the environment. An action that maximizes a value of a target is determined. The target is based at least on a reward for each of the predicted subsequent states. The determined action is performed.",G06N 3/02; B60W 40/12,"HUAWEI TECHNOLOGIES CO., LTD.","YAO, Hengshuai; CHEN, Hao; NOSRATI, Seyed Masoud; YADMELLAT, Peyman; ZHANG, Yunfei","15/724,939 04.10.2017 US",
WO2020008365,PCT/IB2019/055643,02.07.2019,WO/2020/008365,09.01.2020,WO,TRANSFERRING LEARNING IN CLASSIFIER-BASED SENSING SYSTEMS,"Systems and methods for transferring learning in sensor devices. Historical time-series measurement samples of one or more parameters associated with a biological function being monitored by the sensor device are received and assigned to clusters. Feature data extracted from the historical time-series measurement samples are used to generate cluster-specific source-domain classifiers for each cluster. Unlabeled time-series measurement samples of the one or more parameters associated with the biological function are received. A cluster-identifier is assigned to each unlabeled target-domain sample, the cluster-identifier including information identifying a cluster-specific source-domain classifier associated with the unlabeled target-domain sample. Labeled time-series measurement samples of the one or more parameters associated with the biological function are received, feature data is extracted from the labeled samples and cluster-specific target-domain classifiers are generated for each cluster based on the source-domain classifiers and the feature data extracted from the labeled samples.",G06F 15/18; G06N 5/04,3M INNOVATIVE PROPERTIES COMPANY,"KADKHODAIE ELYADERANI, Mojtaba; GOLNARI, Golshan; TAGHVAEEYAN, Saber; SHANNON, Robert W.; BARTON, Roger W.; PACHAURI, Deepti","62/693,374 02.07.2018 US",
WO2019178548,PCT/US2019/022592,15.03.2019,WO/2019/178548,19.09.2019,WO,DETERMINING DRIVABLE FREE-SPACE FOR AUTONOMOUS VEHICLES,"In various examples, sensor data may be received that represents a field of view of a sensor of a vehicle located in a physical environment. The sensor data may be applied to a machine learning model that computes both a set of boundary points that correspond to a boundary dividing drivable free-space from non-drivable space in the physical environment and class labels for boundary points of the set of boundary points that correspond to the boundary. Locations within the physical environment may be determined from the set of boundary points represented by the sensor data, and the vehicle may be controlled through the physical environment within the drivable free-space using the locations and the class labels.",G06K 9/00; G06K 9/66; G06K 9/62,NVIDIA CORPORATION,"RANKAWAT, Mansi; YAO, Jian; ZHANG, Dong; CHEN, Chia-Chih","62/643,665 15.03.2018 US; 16/355,328 15.03.2019 US",CN-201980000945.4; DE-112019000048
WO2015054240,PCT/US2014/059480,07.10.2014,WO/2015/054240,16.04.2015,WO,"COMPUTER IMPLEMENTED METHOD, COMPUTER SYSTEM AND SOFTWARE FOR REDUCING ERRORS ASSOCIATED WITH A SITUATED INTERACTION","A computer implemented method and computer system for reducing errors associated with a situated interaction performed by at least two agents of a sociotechnical team and for augmenting situation awareness of the at least two agents. Also, a non-transitory computer- readable storage medium used to store instructions relating to the computer method and the computer system. The situated interaction can be surgery and the at least two agents can be members of a surgical team.",G06F 17/28,"PRESIDENT AND FELLOWS OF HARVARD COLLEGE; VETERANS AFFAIRS, THE UNITED STATES GOVERNMENT AS REPRESENTED BY THE DEPARTMENT OF","ZENATI, Marco; MARON, Jason","61/887,559 07.10.2013 US",EP-2014852109
WO2012119191,PCT/AU2012/000211,02.03.2012,WO/2012/119191,13.09.2012,WO,METHOD AND SOFTWARE FOR ANALYSING MICROBIAL GROWTH,"A method for analysing microbial growth on a solid culture medium, the method including obtaining image data of the solid culture medium and any microbial growth, generating an associated feature vector of values obtained by applying one or more filters to the image data, using a classifier to classify each pixel in a plurality of pixels in the image data based on the associated feature vector, analysing results of pixel classifications of each said pixel to derive a microbiological assessment of the solid culture medium and any microbial growth, and outputting the microbiological assessment.",G06T 7/00; G06F 19/00; G06K 9/00,"LBT INNOVATIONS LIMITED; GUTHRIE, Lusia, Halina; GLASSON, John, Hughes; VAN DEN HENGEL, Anton, John; HILL, Rhys, Ernst; WARD, Benjamin, William, Stephen","GUTHRIE, Lusia, Halina; GLASSON, John, Hughes; VAN DEN HENGEL, Anton, John; HILL, Rhys, Ernst; WARD, Benjamin, William, Stephen",2011900786 04.03.2011 AU,EP-2012754708; AU-2012225196; US-14002722; JP-2013555707
WO2019100511,PCT/CN2017/118279,25.12.2017,WO/2019/100511,31.05.2019,WO,AN IMAGE PROCESSING METHOD AND SYSTEM,"A neural network-based image processing method may include receiving, by a trained neural network, a first image including a first object, the first object being partially covered by a second object. The method may also include generating, by the trained neural network, a second image based on the first image. The second image is a representation of the first image with the second object substantially removed, and the first object is a human face.",G06K 9/00; G06N 3/04,"ZHEJIANG DAHUA TECHNOLOGY CO., LTD.","CHENG, Fuyun; HAO, Jingsong; WANG, Gang",201711341825.X 14.12.2017 CN; 201711172696.6 22.11.2017 CN,
WO2017136104,PCT/US2017/012730,09.01.2017,WO/2017/136104,10.08.2017,WO,SPIKING MULTI-LAYER PERCEPTRON,"A method of training a neural network with back propagation includes generating error events representing a gradient of a cost function for the neural network. The error events may be generated based on a forward pass through the neural network resulting from input events, weights of the neural network and events from a target signal. The method further includes updating the weights of the neural network based on the error events.",G06N 3/08; G06N 3/04,QUALCOMM INCORPORATED,"O'CONNOR, Peter; WELLING, Max","62/291,409 04.02.2016 US; 15/252,151 30.08.2016 US",
WO2020069239,PCT/US2019/053325,27.09.2019,WO/2020/069239,02.04.2020,WO,EXPLOITING ACTIVATION SPARSITY IN DEEP NEURAL NETWORKS,"A method of exploiting activation sparsity in deep neural networks is described. The method includes retrieving an activation tensor and a weight tensor where the activation tensor is a sparse activation tensor. The method also includes generating a compressed activation tensor comprising non-zero activations of the activation tensor, where the compressed activation tensor has fewer columns than the activation tensor. The method further includes processing the compressed activation tensor and the weight tensor to generate an output tensor.",G06N 3/063,QUALCOMM INCORPORATED,"HILL, Rexford; LAMB, Aaron; GOLDFARB, Michael; ANSARI, Amin; LOTT, Christopher","16/147,297 28.09.2018 US",
EP12752638,94927965,25.08.1994,0715737,12.06.1996,EP,CNN TOPOGRAPHIC SENSORY ORGANS AND METHOD,"The main design components underlying the implementation of physiologically faithful retina (136-144) and other topographic sensory organ models on CNN universal chips (100) is discussed. If the various retinas (136-144) are implemented on a CNN universal chip (100), in a programmable way, it can be called a 'CNN bionic eye' (174), a device capable of performing a broad range of image processing functions similar to those performed by biological retinas (136-144). The CNN universal machine (100) has the special properties that it is 1) programmable and 2) includes local memory (112). Programming is stored in analog and logical form (the analogic program) generated by an analogic programming and control unit (102), so the functions of the CNN universal machine (100) can be modified as a function of complex internal and external constraints. Further, several CNN bionic eyes (174) and other topographic sensory modalities can be combined on a single CNN universal chip (100), and, for more complex sensory tasks, the necessary physical microsensors (180) to provide the input signals can be implemented on the chip (100), in most instances.",G06F 15/18; G06N 3/00; G06N 3/04; G06N 3/063; G06N 3/067; G06T 1/40,UNIV CALIFORNIA,WERBLIN FRANK S; ROSKA TAMAS; CHUA LEON O,11211593 26.08.1993 US; 9409731 25.08.1994 US,
EP185316809,16172384,01.06.2016,3104309,14.12.2016,EP,SPIKING NEURAL NETWORK WITH REDUCED MEMORY ACCESS AND REDUCED IN-NETWORK BANDWIDTH CONSUMPTION,"A spiking neural network having a plurality layers partitioned into a plurality of frustums using a first partitioning may be implemented, where each frustum includes one tile of each partitioned layer of the spiking neural network. A first tile of a first layer of the spiking neural network may be read. Using a processor, a first tile of a second layer of the spiking neural network may be generated using the first tile of the first layer while storing intermediate data within an internal memory of the processor. The first tile of the first layer and the first tile of the second layer belong to a same frustum.",G06N 3/04; G06N 3/10,SAMSUNG ELECTRONICS CO LTD,BROTHERS JOHN; LEE JOOHOON,20160048957 21.04.2016 KR; 201562173742 10.06.2015 US; 201615062365 07.03.2016 US,
WO2019018860,PCT/US2018/043350,23.07.2018,WO/2019/018860,24.01.2019,WO,METHODS FOR ESTABLISHING AND UTILIZING SENSORIMOTOR PROGRAMS,A method for establishing sensorimotor programs includes specifying a concept relationship that relates a first concept to a second concept and establishes the second concept as higher-order than the first concept; training a first sensorimotor program to accomplish the first concept using a set of primitive actions; and training a second sensorimotor program to accomplish the second concept using the first sensorimotor program and the set of primitive actions.,B25J 9/16; A61B 13/00,"VICARIOUS FPC, INC.","PHOENIX, David, Scott","62/535,703 21.07.2017 US",
WO2009149126,PCT/US2009/046028,02.06.2009,WO/2009/149126,10.12.2009,WO,"METHOD, SYSTEM, AND COMPUTER-ACCESSIBLE MEDIUM FOR CLASSIFICATION OF AT LEAST ONE ICTAL STATE","An exemplary methodology, procedure, system, method and computer- accessible medium can be provided for receiving physiological data for the subject, extracting one or more patterns of features from the physiological data, and classifying the at least one state of the subject using a spatial structure and a temporal structure of the one or more patterns of features, wherein at least one of the at least one state is an ictal state.",G06F 17/00; G06F 7/08,"NEW YORK UNIVERSITY; MIROWSKI, Piotr, W.; MADHAVAN, Deepak; LECUN, Yann; KUZNIECKY, Rubun","MIROWSKI, Piotr, W.; MADHAVAN, Deepak; LECUN, Yann; KUZNIECKY, Rubun","61/058,107 02.06.2008 US",US-12995925
EP275493078,18203236,30.10.2018,3561645,30.10.2019,EP,DEEP NEURAL NETWORK TRAINING FOR APPLICATION PROGRAM GENERATION,,G06F 3/01; G06F 3/03; G06F 3/033; G06F 3/0346; G06F 3/0482; G06F 3/0488; G06F 3/16; G06N 3/04; G06N 3/063; G06N 3/08; H04L 9/32,FUJITSU LTD,MONTANTES JAMES,201815963011 25.04.2018 US,
WO2018118112,PCT/US2017/034160,24.05.2017,WO/2018/118112,28.06.2018,WO,METHOD AND SYSTEM TO PREDICT ONE OR MORE TRAJECTORIES OF A VEHICLE BASED ON CONTEXT SURROUNDING THE VEHICLE,"A surrounding environment of an autonomous vehicle is perceived to identify one or more vehicles nearby. For each of the identified vehicles, based on a current location of the identified vehicle, vehicle-independent information is obtained to determine context surrounding the identified vehicle, where the vehicle-independent information includes vehicle surrounding information that defines physical constraints imposed on the identified vehicle. For each of the identified vehicles, one or more trajectories for the identified vehicle are predicted based at least in part on the vehicle-independent information associated with the identified vehicle. The autonomous vehicle is controlled based on the one or more predicted trajectories of the one or more identified vehicles.",G05D 1/00; G06F 7/00; G08G 1/16,BAIDU USA LLC,"FANG, Shiyuan; YANG, I-Hsuan; MIAO, Jinghao; LI, Liyun; ZHANG, Liangliang; WANG, Jingao","15/387,466 21.12.2016 US",JP-2018517765; EP-2017847775; KR-1020187009732
WO2017091763,PCT/US2016/063661,23.11.2016,WO/2017/091763,01.06.2017,WO,END-TO-END SPEECH RECOGNITION,"Embodiments of end-to-end deep learning systems and methods are disclosed to recognize speech of vastly different languages, such as English or Mandarin Chinese. In embodiments, the entire pipelines of hand-engineered components are replaced with neural networks, and the end-to-end learning allows handling a diverse variety of speech including noisy environments, accents, and different languages. Using a trained embodiment and an embodiment of a batch dispatch technique with GPUs in a data center, an end-to-end deep learning system can be inexpensively deployed in an online setting, delivering low latency when serving users at scale.",G06F 17/28; G10L 15/04; G10L 15/06; G10L 15/08; G10L 15/183; G10L 15/28,BAIDU USA LLC,"CATANZARO, Bryan; CHEN, Jingdong; CHRZANOWSKI, Mike; ELSEN, Erich; ENGEL, Jesse; FOUGNER, Christopher; HAN, Xu; HANNUN, Awni; PRENGER, Ryan; SATHEESH, Sanjeev; SENGUPTA, Shubhabrata; YOGATAMA, Dani; WANG, Chong; ZHAN, Jun; ZHU, Zhenyao; AMODEI, Dario","62/260,206 25.11.2015 US; 15/358,102 21.11.2016 US; 15/358,083 21.11.2016 US",JP-2017544352; KR-1020177023177
WO2019081782,PCT/EP2018/079559,29.10.2018,WO/2019/081782,02.05.2019,WO,MACHINE LEARNING SYSTEMS WITH MEMORY BASED PARAMETER ADAPTATION FOR LEARNING FAST AND SLOWER,"There is described herein a computer-implemented method of processing an input data item. The method comprises processing the input data item using a parametric model to generate output data, wherein the parametric model comprises a first sub-model and a second sub-model. The processing comprises processing, by the first sub-model, the input data to generate a query data item, retrieving, from a memory storing data point-value pairs, at least one data point-value pair based upon the query data item and modifying weights of the second sub-model based upon the retrieved at least one data point-value pair. The output data is then generated based upon the modified second sub-model.",G06N 3/04; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"SPRECHMANN, Pablo; JAYAKUMAR, Siddhant; RAE, Jack William; PRITZEL, Alexander; BADIA, Adrià Puigdomènech; VINYALS, Oriol; PASCANU, Razvan; BLUNDELL, Charles","62/578,319 27.10.2017 US",
EP238739212,16899762,27.04.2016,3451240,06.03.2019,EP,APPARATUS AND METHOD FOR PERFORMING AUTO-LEARNING OPERATION OF ARTIFICIAL NEURAL NETWORK,"The present disclosure provides a device and a method for performing self-learning operations of an artificial neural network. The device includes an instruction storage unit, a controller unit, a data access unit, an interconnection module, a main operation module, and a number of slave operation modules. The present disclosure can perform self-learning pre-training of a multi-layer neural network according to a training mode of layer-by-layer training. For each layer of the network, the self-learning pre-training of the layer of the network is completed when the present disclosure performs many times of operational iterations until the weight is updated to be less than a certain threshold value. Each iteration process can be divided into four stages. Calculation is carried out in the first three stages to respectively generate a first-order hidden layer intermediate value, a first-order visible layer intermediate value and a second-order hidden layer intermediate value. The weight is updated in the last stage with the intermediate values of the first three stages.",G06N 3/08; G06N 3/04; G06N 3/063,CAMBRICON TECH CORPORATION LIMITED,LI ZHEN; GUO QI; CHEN YUNJI; CHEN TIANSHI,2016080320 27.04.2016 CN,
WO2009061390,PCT/US2008/012441,04.11.2008,WO/2009/061390,14.05.2009,WO,MACHINE LEARNING SYSTEMS AND METHODS FOR IMPROVED NATURAL LANGUAGE PROCESSING,"Disclosed is a method to generate at least one new set of concepts to be used to perform natural language processing (NLP) on data. The method includes receiving one or more sources of input data, and determining, based on the one or more sources of input data and on at least one initial set of concepts, at least one attribute representative of a type of information detail to be included in the at least one new set of concepts.",G06F 17/28,"ENHANCED MEDICAL DECISIONS, INC.; BEGGELMAN, Marlene, J.; SMYCHKOVICH, Yuri","BEGGELMAN, Marlene, J.; SMYCHKOVICH, Yuri","60/985,402 05.11.2007 US",
WO2015030606,PCT/NZ2014/000176,26.08.2014,WO/2015/030606,05.03.2015,WO,IMPROVED METHOD AND SYSTEM FOR PREDICTING OUTCOMES BASED ON SPATIO / SPECTRO-TEMPORAL DATA,"The present invention involves the use of temporal or spatio-/spectro temporal data (SSTD) for an early classification of outputs that are results of spatio-temporal patterns of data. Classification models according to preferred embodiments are based on spiking neural networks (SNN), suitable to learn and classify SSTD. The invention can be used to predict early events in many applications, for example engineering, bioinformatics, neuroinformatics, predicting response to treatment of neurological and brain disease, ecology, environment, medicine, and economics, among others. Preferred embodiments of the present invention involve a method and system for personalised modelling of SSTD and early prediction of events. The method and system are based on an evolving spiking neural network reservoir architecture (eSNNr). The system comprises: a spike-time encoding module to encode continuous value input information into spike trains, a recurrent 3D SNNr and an eSNN as an output classification module.",G06N 3/08; G06F 15/18,AUCKLAND UNIVERSITY OF TECHNOLOGY,"KASABOV, Nikola Kirilov; HOU, Zeng-Guang; FEIGIN, Valery; CHEN, Yixiong",614708 26.08.2013 NZ,US-14914326
EP241923902,18202762,26.10.2018,3480740,08.05.2019,EP,METHOD AND APPARATUS WITH NEURAL NETWORK PERFORMING DECONVOLUTION,"A neural network apparatus configured to perform a deconvolution operation includes a memory configured to store a first kernel; and a processor configured to: obtain, from the memory, the first kernel; calculate a second kernel by adjusting an arrangement of matrix elements comprised in the first kernel; generate sub-kernels by dividing the second kernel; perform a convolution operation between an input feature map and the sub-kernels using a convolution operator; and generate an output feature map, as a deconvolution of the input feature map, by merging results of the convolution operation.",G06N 3/04,SAMSUNG ELECTRONICS CO LTD,SONG JOONHO; LEE SEHWAN; JANG JUNWOO,20170147617 07.11.2017 KR,
WO2009120263,PCT/US2009/001513,10.03.2009,WO/2009/120263,01.10.2009,WO,SYSTEM AND METHOD FOR ILLUMINATION INVARIANT IMAGE SEGMENTATION,"In a first exemplary embodiment of the present invention, an automated, computerized method is provided for processing an image. According to a feature of the present invention, the method comprises the steps of providing an image file, identifying a boundary in the image, calculating a representation of the boundary extending to segments of the image at either side of the boundary, performing feature calculations on the representation and classifying the boundary as caused by a material change, as a function of the feature calculations.",G06K 9/48,"TANDENT VISION SCIENCE, INC.; MAXWELL, Bruce, Allen; FRIEDHOFF, Richard, Mark; SMITH, Casey, Arthur","MAXWELL, Bruce, Allen; FRIEDHOFF, Richard, Mark; SMITH, Casey, Arthur","12/079,878 28.03.2008 US",EP-2009724493
WO2019103931,PCT/US2018/061522,16.11.2018,WO/2019/103931,31.05.2019,WO,DYNAMIC ACCURACY-BASED DEPLOYMENT AND MONITORING OF MACHINE LEARNING MODELS IN PROVIDER NETWORKS,Techniques for dynamic accuracy-based experimentation and deployment of machine learning (ML) models are described. Inference traffic flowing to ML models and the accuracy of the models is analyzed and used to ensure that better performing models are executed more often via model selection. A predictive component can evaluate which model is more likely to be accurate for certain input data elements. Ensemble techniques can combine inference results of multiple ML models to aim to achieve a better overall result than any individual model could on its own.,G06N 3/04,"AMAZON TECHNOLOGIES, INC.","FAULHABER, JR., Thomas Albert; LIBERTY, Edo; STEFANI, Stefano; KARNIN, Zohar; WILEY, Craig; LOEPPKY, Steven Andrew; SIVASUBRAMANIAN, Swaminathan; SMOLA, Alexander Johannes; GOODHART, Taylor","62/590,161 22.11.2017 US; 15/919,628 13.03.2018 US",
WO2014147468,PCT/IB2014/000390,19.03.2014,WO/2014/147468,25.09.2014,WO,TOOL COMPILER,"Automatic generation of documentation and software for an equipment or tool, together with an automatic synchronization between the corresponding documentation and software can be preformed with a tool model representation. The tool model can include a textual, graphical, symbolic, and program representation of the tool. Default components, derived components, and standard components can be added to the tool model.",G06F 17/22; G06F 9/44,"DYNAMIC MICRO SYSTEMS; TANGUY, François; DECKER, Andreas","TANGUY, François; DECKER, Andreas","61/803,427 19.03.2013 US",JP-2016504766
WO2016133926,PCT/US2016/018112,16.02.2016,WO/2016/133926,25.08.2016,WO,LOCALITY-BASED DETECTION OF TRAY SLOT TYPES AND TUBE TYPES IN A VISION SYSTEM,"A method for detecting properties of sample tubes is provided that includes extracting image patches substantially centered on a tube slot of a tray or a tube top in a slot. For each image patch, the method may include assigning a first location group defining whether the image patch is an image center, a comer of an image or a middle edge of an image, selecting a trained classifier based on the first location group and determining whether each tube slot contains a tube. The method may also include assigning a second location group defining whether the image patch is from an image center, a left comer of the image, a right comer of the image, a left middle of the image; a center middle of the image or a right middle of the image, selecting a trained classifier based on the second location group and determining a tube property.",G06T 7/60; G01N 1/28,SIEMENS HEALTHCARE DIAGNOSTICS INC.,"WU, Wen; POLLACK, Benjamin; CHANG, Yao-jen; DUMONT, Guillaume; CHEN, Terrence","62/117,916 18.02.2015 US",US-15551571; CA-2976947; JP-2017543749
EP14971405,08000122,04.01.2008,1959393,20.08.2008,EP,Computer implemented method for detecting scene boundaries in videos,A computer implemented method detects scene boundaries in videos by first extracting feature vectors from videos of different genres. The feature vectors are then classified as scene boundaries using a support vector machine. The support vector machine is trained to be independent of the different genres of the videos.,G06T 7/20; G06K 9/00; G06T 7/00; H04N 5/14; H04N 5/76; H04N 5/91,MITSUBISHI ELECTRIC CORP,WILSON KEVIN W; DIVAKARAN AJAY; NIU FENG; GOELA NAVEEN; OTSUKA ISAO,67475007 14.02.2007 US,
EP253957273,16831818,22.11.2016,3545833,02.10.2019,EP,PARETIC LIMB REHABILITATION METHOD AND SYSTEM,"Generator systems are provided for generating a neuromuscular-to-movement decoder from a healthy limb. The generator system is designed to receive neuromuscular signals from neuromuscular sensors associated with predefined muscle/nerve locations on at least one pair of agonist and antagonist muscles/nerves of a healthy limb, obtained during the performance by a person of a predefined exercise (which is defined by predefined exercise data) using the healthy limb; to receive movement signals from movement sensors associated with predefined positions of the healthy limb during the performance by a person of a predefined exercise using the healthy limb; and to generate the neuromuscular-to-movement decoder by mapping the neuromuscular signals to the movement signals over time by means of a mapping process. Also provided are rehabilitation systems for rehabilitating a paretic limb using a neuromuscular-to-movement decoder produced by a generator system. Suitable computer programs and processes are also provided for use in said generator systems and rehabilitation systems.",A61B 5/04; A61B 5/00; A61B 5/0488; A61B 5/11; A61B 5/22; A61B 8/00; A61F 2/50; A61F 2/54; A61F 2/58; A61F 2/68,FUNDACION TECNALIA RES & INNOVATION; UNIV CALIFORNIA; EBERHARD KARLS UNIV TUEBINGEN,RAMOS MURGUIALDAY ANDER; SARASOLA ANDREA; CARMENA RAMON JOSE MIGUEL; MCINTYRE JOSEPH,2016070833 22.11.2016 ES,
WO2015191968,PCT/US2015/035504,12.06.2015,WO/2015/191968,17.12.2015,WO,HYPER-STRUCTURE RECURRENT NEURAL NETWORKS FOR TEXT-TO-SPEECH,"The technology relates to converting text to speech utilizing recurrent neural networks (RNNs). The recurrent neural networks may be implemented as multiple modules for determining properties of the text. In embodiments, a part-of-speech RNN module, letter-to-sound RNN module, a linguistic prosody tagger RNN module, and a context awareness and semantic mining RNN module may all be utilized. The properties from the RNN modules are processed by a hyper-structure RNN module that determine the phonetic properties of the input text based on the outputs of the other RNN modules. The hyper-structure RNN module may generate a generation sequence that is capable of being converting to audible speech by a speech synthesizer. The generation sequence may also be optimized by a global optimization module prior to being synthesized into audible speech.",G10L 13/10,"MICROSOFT TECHNOLOGY LICENSING, LLC","ZHAO, Pei; LEUNG, Max; YAO, Kaisheng; YAN, Bo; ZHAO, Sheng; ALLEVA, Fileno A.","14/303,969 13.06.2014 US",EP-2015738162
WO2018042445,PCT/IL2017/050988,04.09.2017,WO/2018/042445,08.03.2018,WO,A SYSTEM AND METHOD FOR CHARACTERIZATION OF CANNABACEAE PLANTS,"A method and system for characterization of Cannabaceae plants using macro photography images is disclosed. The method comprises the steps of receiving one or more macro photography images of a Cannabaceae plant; performing feature extraction analysis of trichomes using image processing, and performing plant characterization analysis using a neural network which analyzes the macro photography images. The training phase of the neural network comprises using results of chemical composition laboratory tests performed on the plants for which the macro photography images have been used in the training phase. The invention calculates and reports an assessment of maturity of the plant for harvesting, diagnosis of the existence of diseases, insects, or pests, assessment of the presence and concentrations of central ingredients, recommendations for treatment during plants drying, curing or storage production processes, and assessment of the quality and pricing of Cannabaceae plants products.",G06K 9/00,MYCROPS TECHNOLOGIES LTD.,"GAVISH, Assaf; LEVY, Asaf; GAVISH, Yoav","62/383,503 05.09.2016 US",CA-3034626; EP-2017845683; IL-264661
WO2019155054,PCT/EP2019/053300,11.02.2019,WO/2019/155054,15.08.2019,WO,GENERATING OUTPUT EXAMPLES USING RECURRENT NEURAL NETWORKS CONDITIONED ON BIT VALUES,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating output examples using neural networks. One of the methods includes, at each generation time step, processing a first recurrent input comprising an N-bit output value at the preceding generation time step in the sequence using a recurrent neural network and in accordance with a hidden state to generate a first score distribution; selecting, using the first score distribution, values for the first half of the N bits; processing a second recurrent input comprising (i) the N-bit output value at the preceding generation time step and (ii) the values for the first half of the N bits using the recurrent neural network and in accordance with the same hidden state to generate a second score distribution; and selecting, using the second score distribution, values for the second half of the N bits of the output value.",G06N 3/04,DEEPMIND TECHNOLOGIES LIMITED,"KALCHBRENNER, Nal Emmerich; SIMONYAN, Karen; ELSEN, Erich Konrad","62/628,913 09.02.2018 US",
WO2019060283,PCT/US2018/051461,18.09.2018,WO/2019/060283,28.03.2019,WO,PERSONALIZED NEURAL NETWORK FOR EYE TRACKING,"Disclosed herein is a wearable display system for capturing retraining eye images of an eye of a user for retraining a neural network for eye tracking. The system captures retraining eye images using an image capture device when user interface (UI) events occur with respect to UI devices displayed at display locations of a display. The system can generate a retraining set comprising the retraining eye images and eye poses of the eye of the user in the retraining eye images (e.g., related to the display locations of the UI devices) and obtain a retrained neural network that is retrained using the retraining set.",G06K 9/66; G06K 9/62; G06K 9/46; H04N 13/383; G02B 27/01; G06F 3/01,"MAGIC LEAP, INC.","KAEHLER, Adrian; LEE, Douglas; BADRINARAYANAN, Vijay","62/560,898 20.09.2017 US",IL-272289
WO2019180033,PCT/EP2019/056866,19.03.2019,WO/2019/180033,26.09.2019,WO,FAST DETECTION OF SECONDARY OBJECTS THAT MAY INTERSECT THE TRAJECTORY OF A MOVING PRIMARY OBJECT,"A system (1) for detecting dynamic secondary objects (55) that have a potential to intersect the trajectory (51) of a moving primary object (50), comprising a vision sensor (2) with a light-sensitive area (20) that comprises event-based pixels (21), so that a relative change in the light intensity impinging onto an event-based pixel (21) of the vision sensor (2) by at least a predetermined percentage causes the vision sensor (2) to emit an event (21a) associated with this event-based pixel (21), wherein the system (1) further comprises a discriminator module (3) that gets both the stream of events (21a) from the vision sensor (2) and information (52) about the heading and/or speed of the motion of the primary object (50) as inputs, and is configured to identify, from said stream of events (21a), based at least in part on said information (52), events (21b) that are likely to be caused by the motion of a secondary object (55), rather than by the motion of the primary object (50). Vision sensors (2) for use in the system (1). A corresponding computer program.",G06K 9/00,ROBERT BOSCH GMBH; PROPHESEE,"PFEIFFER, Michael; MARX, Jochen; LANGE, Oliver; POSCH, Christoph; LAGORCE, Xavier; NIKOLAIDIS, Spiros",18163096.3 21.03.2018 EP,
WO2019215605,PCT/IB2019/053725,07.05.2019,WO/2019/215605,14.11.2019,WO,SYSTEMS AND METHODS FOR ANALYSIS OF ANATOMICAL IMAGES,"There is provided a method comprising: providing two anatomical images of a target individual, each captured at a unique orientation of the target individual, inputting first and second anatomical images respectively into a first and second convolutional neural network (CNN) of a classifier to respectively output first and second feature vectors, inputting a concatenation of the first and second feature vectors into a fully connected layer of the classifier, and computing an indication of distinct visual finding(s) present in the anatomical images by the fully connected layer, wherein the statistical classifier is trained on a training dataset including two anatomical images of each respective sample individual, each image captured at a respective unique orientation of the target individual, and a tag created based on an analysis that maps respective individual sentences of a text based radiology report to one of multiple indications of visual findings.",G06T 9/00; A61B 5/00,ZEBRA MEDICAL VISION LTD.,"LASERSON, Jonathan","15/972,912 07.05.2018 US; 16/269,619 07.02.2019 US; 16/269,633 07.02.2019 US",
WO1992018946,PCT/CA1992/000162,20.04.1992,WO/1992/018946,29.10.1992,WO,IMPROVEMENTS IN NEURAL NETWORKS,"The present invention relates to adaptive information processing systems, and in particular to associative memories utilizing confidence-mediated associations, and especially neural network systems comprising an auto-organizational apparatus and processes for dynamically mapping an input onto a semantically congruous and contemporaneously-valid, learned response. In particular the present invention relates to such an associative memory system in which provision is made for improving the congruence between an associative memory, by impressing a desired response on an associative memory mapping based on complex polar values.",G06N 3/04,"SUTHERLAND, John","SUTHERLAND, John","2,040,903 22.04.1991 CA",US-08133196; EP-1992909206
WO2019238251,PCT/EP2018/070513,27.07.2018,WO/2019/238251,19.12.2019,WO,AUTHENTICATING AN IDENTITY OF A PERSON,"Methods, systems and computer programs are provided for authenticating an identity of a person, which comprise: obtaining, from a capturing device, one or more captures including image and/or audio captures; detecting, based on spoofing-detection criteria, spoofing indicators in the captures and whether said spoofing indicators correspond to spoofing indicia; detecting, based on liveness-detection criteria, biometric-features in the captures and whether said biometric-features correspond to liveness indicia; detecting, based on identity-biometric criteria, biometric attributes in the captures and whether said biometric attributes correspond to a predefined human identity; extracting, based on time-related criteria, a time-reference hidden or codified in the captures and detecting whether said time-reference satisfies predefined time constraints; and authenticating the identity of the person depending on whether spoofing indicia have been detected, whether liveness indicia have been detected, whether biometric attributes have been detected corresponding to predefined human identity, and whether the time-reference satisfies predefined time constraints.",G06F 21/30; H04L 9/32; H04L 29/06; H04W 12/06; G06N 3/02,"VERIDAS DIGITAL AUTHENTICATION SOLUTIONS, S.L.","ZAMORA MARTÍNEZ, Francisco Julián; GONZÁLEZ DE SUSO MOLINERO, Jose Luis; KOLODA, Jan; SÁNCHEZ YOLDI, Miguel Ángel; AZANZA LADRÓN, Eduardo",18382416.8 13.06.2018 EP,
WO2015127117,PCT/US2015/016677,19.02.2015,WO/2015/127117,27.08.2015,WO,"INVARIANT-BASED DIMENSIONAL REDUCTION OF OBJECT RECOGNITION FEATURES, SYSTEMS AND METHODS","A sensor data processing system and method is described. Contemplated systems and methods derive a first recognition trait of an object from a first data set that represents the object in a first environmental state. A second recognition trait of the object is then derived from a second data set that represents the object in a second environmental state. The sensor data processing systems and methods then identifies a mapping of elements of the first and second recognition traits in a new representation space. The mapping of elements satisfies a variance criterion for corresponding elements, which allows the mapping to be used for object recognition. The sensor data processing systems and methods described herein provide new object recognition techniques that are computationally efficient and can be performed in real-time by the mobile phone technology that is currently available.",G06K 9/62; G06K 9/20,"NANT HOLDINGS IP, LLC","WNUK, Kamil; SUDOL, Jeremi; SONG, Bing; MCKINNON, David; SIDDIQUI, Matheen","61/941,989 19.02.2014 US; 14/626,706 19.02.2015 US",CN-201580020628.0
WO2006073915,PCT/US2005/046957,23.12.2005,WO/2006/073915,13.07.2006,WO,PATIENT TRAINING ROUTINE FOR BIOLOGICAL INTERFACE SYSTEM,Various embodiments of a biological interface system and related methods are disclosed. The system may comprise a sensor comprising a plurality of electrodes for detecting multicellular signals emanating from one or more living cells of a patient and a processing unit configured to receive the multicellular signals from the sensor and process the multicellular signals to produce a processed signal. The processing unit may be configured to transmit the processed signal to a controlled device that is configured to receive the processed signal. The system is configured to perform an integrated patient training routine to generate one or more system configuration parameters that are used by the processing unit to produce the processed signal.,G06F 3/00; A61B 5/0482; A61B 5/04,"CYBERKINETICS NEUROTECHNOLOGY SYSTEMS, INC.; FLAHERTY, Christopher, J.; SERRUYA, Mijail, D.; MORRIS, Daniel, S.; CAPLAN, Abraham, H.; SALEH, Maryam; DONOGHUE, John, P.","FLAHERTY, Christopher, J.; SERRUYA, Mijail, D.; MORRIS, Daniel, S.; CAPLAN, Abraham, H.; SALEH, Maryam; DONOGHUE, John, P.","60/642,021 06.01.2005 US",EP-5855505
WO2020058561,PCT/FI2018/050677,18.09.2018,WO/2020/058561,26.03.2020,WO,APPARATUS AND METHOD FOR AUTHENTICATING A USER,"An apparatus, method and computer program is described comprising: receiving (41) a control signal from a user-operated control apparatus for controlling a remote apparatus, extracting (42) a user noise signal from the received control signal, determining (43) if the user noise signal meets one or more predetermined criteria and authenticating (44) a user of the control apparatus at least partially based on the user noise signal determination.",G06F 21/31; H04W 12/00; H04W 12/06; B25J 9/16; B25J 9/06; A61B 34/35,NOKIA TECHNOLOGIES OY,"MICHE, Yoan Jean Claude; KALLIOLA, Aapo; OLIVER, Ian Justin",,
EP242529333,18206123,14.11.2018,3486845,22.05.2019,EP,CONTROLLER AND MACHINE LEARNING DEVICE,"A machine learning device provided in a controller for controlling a wire electrical discharge machine uses state variables (including data relating to a correction amount, a machining path, machining conditions, and a machining environment) observed by a state observation unit and determination data acquired by a determination data acquisition unit to machine-learn a correction for a machining path. Using the learning result, the machining path can be corrected automatically and accurately on the basis of a partial machining path, the machining conditions and the machining environment of the machining performed by the wire electrical discharge machine.",G06N 3/08,FANUC CORP,OOSAWA TOMOHITO,2017222156 17.11.2017 JP,
EP276032577,16925613,30.12.2016,3564863,06.11.2019,EP,"APPARATUS FOR EXECUTING LSTM NEURAL NETWORK OPERATION, AND OPERATIONAL METHOD","An apparatus for executing an LSTM neural network operation, and an operational method. The apparatus comprises a direct memory access unit (1), an instruction cache unit (2), a controller unit (3), a plurality of data cache units (4) arranged in parallel and a plurality of data processing modules (5) arranged in parallel, the plurality of data processing modules (5) corresponding to the data cache units (4) in a one-to-one manner, for acquiring, from the corresponding data cache units (4), input data and weights and offsets required during operation, so as to perform an LSTM neural network operation; the plurality of data processing modules (5) execute parallel operations. The apparatus runs using special instructions, the number of instructions required for operation is reduced, and decoding overheads are decreased; weights and offsets are cached so that data transmission overheads are decreased; the plurality of data processing modules (5) run in parallel, improving the operation speed of the LSTM network.",G06N 3/06,SHANGHAI CAMBRICON INFORMATION TECH CO LTD,CHEN YUNJI; CHEN XIAOBING; LIU SHAOLI; CHEN TIANSHI,2016113493 30.12.2016 CN,
WO2016134093,PCT/US2016/018379,18.02.2016,WO/2016/134093,25.08.2016,WO,SYSTEM AND METHOD FOR POSITIONAL REGISTRATION OF MEDICAL IMAGE DATA,A system and method of correlating or coregistering medical images is disclosed herein that includes acquiring a surface image of the patient's skin surface using a surface detector assembly comprising a surface frame and a camera system registered to the surface frame. Positional coordinates of one or more surface landmarks in the surface image are determined and a medical image of the patient is acquired having the surface frame depicted therein. A second surface image of the patient's skin surface is acquired that at least partially overlaps the previously acquired surface image. Positional coordinates of one or more surface landmarks in the second surface image are determined and compared with surface landmarks in the previous surface image. Common surface landmarks are determined based on the comparison and the medical images are coregistered based on positional coordinates of the common surface landmarks.,G06K 9/20; G06K 9/46; G06T 7/00,"METRITRACK, INC.","CALUSER, Calin","62/176,411 19.02.2015 US",
WO2009077073,PCT/EP2008/010124,28.11.2008,WO/2009/077073,25.06.2009,WO,ARTIFICIAL COGNITIVE SYSTEM WITH AMARI-TYPE DYNAMICS OF A NEURAL FIELD,"Problem: Efficiently simulating an Amari dynamics of a neural field (a), the Amari dynamics being specified by the equation (1) where (2) is the state of the neural field (a), represented in a spatial domain (SR) using coordinates (3), (4) is a function stating the input to the neural field at time t, f[.] is a bounded monotonic transfer function having values between 0 and 1, (5) is an interaction kernel, (6) specifies the time scale on which the neural field (a) changes and h is a constant specifying the global excitation or inhibition of the neural field (a). Solution: A method for simulating an Amari dynamics of a neural field (a), comprising the step of simulating an application of the transfer function (f) to the neural field (a). According to the invention, the step of simulating an application of the transfer function (f) comprises smoothing the neural field (a) by applying a smoothing operator (S).",G06N 3/10; G06T 7/00,"HONDA RESEARCH INSTITUTE EUROPE GMBH; GEPPERTH, Alexander","GEPPERTH, Alexander",07121770.7 28.11.2007 EP,US-12738937; EP-2008862031
EP20839469,10184190,16.03.2007,2315131,27.04.2011,EP,Method and system to index captioned objects in published literature for information discovery tasks,"The present invention relates to the identification, extraction, linking, storage and provisioning of data that constitute the captioned components of published or ""print ready"" literature for computerized information discovery activities including search, browse and data mining. These components, or objects, include the tabular presentation of data (""tables"") and graphics such as ""figures"", ""images"" and ""illustrations"" typically used to supplement the textual narrative of the publication.",G06F 17/30; G06F 40/00,PROQUEST CSA LLC,DUNIE MATTHEW; EMERSON CRAIG W,07104374 16.03.2007 EP; 78345906 17.03.2006 US,
WO2018110818,PCT/KR2017/011440,17.10.2017,WO/2018/110818,21.06.2018,WO,SPEECH RECOGNITION METHOD AND APPARATUS,"A speech recognition method and apparatus for performing speech recognition in response to an activation word determined based on a situation are provided. The speech recognition method and apparatus include an artificial intelligence (AI) system and its application, which simulates functions such as recognition and judgment of a human brain using a machine learning algorithm such as deep learning.",G10L 15/04; G10L 15/02; G10L 15/22; G10L 15/26,"SAMSUNG ELECTRONICS CO., LTD.","CHOI, Sung-ja; KIM, Eun-kyoung; YU, Ji-sang; HONG, Ji-yeon; RYU, Jong-youb; LEE, Jae-won",10-2016-0171670 15.12.2016 KR; 10-2017-0054513 27.04.2017 KR,EP-2017879966; CN-201780078008.1
WO2002092101,PCT/US2002/015981,15.05.2002,WO/2002/092101,21.11.2002,WO,SYSTEMS AND METHODS FOR MONITORING BEHAVIOR INFORMATICS,"A system and method used to assess animal behavior includes a module having sensors that collects a variety of physical and biological data from a test subject. Interpretation of the data is provided to assess the test subject's behavior, neurology, biochemistry and physiology. The module is useful in observing the effects of a drug on the test animal and providing information on the drug's signature. Another advantage is module's portability that allows it to be used in standard laboratory cages. (NOT SURE ABOUT THIS PORTABILITY) This portability allows the animal to be tested in its own habitat, that can reduce any erroneous data due to stressing the animal when removed to a test cage. Additionally, the module's design allows for parallel data collection and interpretation from several laboratory animals undergoing different experiments. Multi-dimensional modeling of the test subject based the system's interpretation of the data allows pattern recognition of the drug signature, and predictive drug analysis.",G01N 33/50; G01N 33/15; G06F 17/30; G06F 19/00,"PSYCHOGENICS INC.; BRUNNER, Daniela; GONDHALEKAR, Vijay; LEAHY, Emer; LAROSE, David; ROSS, William, P.","BRUNNER, Daniela; GONDHALEKAR, Vijay; LEAHY, Emer; LAROSE, David; ROSS, William, P.","60/291,039 15.05.2001 US; 60/326,271 01.10.2001 US",EP-2002746424; AU-2002316146; CA-2451992; JP-2002589018
WO2014194002,PCT/US2014/039861,28.05.2014,WO/2014/194002,04.12.2014,WO,MACHINE LEARNING GENERATED ACTION PLAN,"Apparatuses, systems, methods, and computer program products are disclosed for a machine learning 222 generated action plan. A machine learning module 202 is configured to process different instances 126 of data using machine learning 222 to produce one or more results. The different instances 126 of data may comprise different values for one or more actionable features 128, 130, 132, 134, 136, 138. A recommended action module 204 is configured to select one or more recommended actions 128, 142 for achieving a goal 150 associated with the machine learning 222. The recommended action module 204 may select the one or more recommended actions 128, 142 based on the one or more results. An action plan interface module 206 is configured to provide an action plan associated with the one or more recommended actions 128, 142.",G06F 15/18,"PUREPREDICTIVE, INC.","PHILLIPPS, Kelly D.; WELLMAN, Richard W.","13/904,963 29.05.2013 US; 14/162,571 23.01.2014 US",EP-2014803583
EP163437345,14747170,23.06.2014,3014522,04.05.2016,EP,STEREOSCOPIC OBJECT DETECTION LEVERAGING ASSUMED DISTANCE,"A method of object detection includes receiving a first image taken by a first stereo camera, receiving a second image taken by a second stereo camera, and offsetting the first image relative to the second image by an offset distance selected such that each corresponding pixel of offset first and second images depict a same object locus if the object locus is at an assumed distance from the first and second stereo cameras. The method further includes locating a target object in the offset first and second images.",G06K 9/00; G06F 3/01; G06K 9/62,MICROSOFT TECHNOLOGY LICENSING LLC,NISTER DAVID; DOLLAR PIOTR; KIENZLE WOLF; RADOJEVIC MLADEN; ASHMAN MATTHEW S; STOJILJKOVIC IVAN; VUKOSAVLJEVIC MAGDALENA,201313926882 25.06.2013 US; 2014043545 23.06.2014 US,
WO2018226247,PCT/US2017/037025,12.06.2017,WO/2018/226247,13.12.2018,WO,MODIFICATION OF AUDIO-BASED COMPUTER PROGRAM OUTPUT,Modifying computer program output in a voice or non-text input activated environment is provided. A system can receive audio signals detected by a microphone of a device. The system can parse the audio signal to identify a computer program to invoke. The computer program can identify a dialog data structure. The system can modify the identified dialog data structure to include a content item. The system can provide the modified dialog data structure to a computing device for presentation.,G10L 15/22,GOOGLE LLC,"EIDEM, Laura; JACOBSON, Alex","15/618,842 09.06.2017 US; 15/618,854 09.06.2017 US; 15/618,871 09.06.2017 US; 15/618,873 09.06.2017 US",CN-201780001058.X; CN-CN201780001058x; EP-2017732673; KR-1020197025033
WO2018145098,PCT/US2018/017083,06.02.2018,WO/2018/145098,09.08.2018,WO,SYSTEMS AND METHODS FOR AUTOMATIC SEMANTIC TOKEN TAGGING,"A computing system can receive a request to apply semantic token tagging on a specified domain, and can retrieve a set of data associated with the specified domain from a data storage facility. Canonical sequences can be formed from strings included in the data set. Each canonical sequence can be permutated to form sequence variations and each sequence variation can be verified against a generalized domain. Semantic token tagging can be applied to the specified domain using a subset of the sequence variations that are successfully verified as training data.",G06F 17/27; G06F 17/28; G06F 19/00; G06N 7/00,"THOMSON REUTERS GLOBAL RESOURCES UNLIMITED COMPANY; SCHILDER, Frank","SCHILDER, Frank; SONG, Dezhao","62/455,082 06.02.2017 US",CA-3052638; EP-2018747399; AU-2018214675
EP14962363,07123583,19.12.2007,1939776,02.07.2008,EP,Intelligent modeling method and system for earmold shell and hearing aid design,"A method and appertaining system are provided for automatically modeling a hearing aid shell design. A 3D geometric description of an undetailed shell model is received, and its features and associated descriptors are automatically extracted. These features are classified, and a database of existing shells and features is queried to determine if a stored shell model matches the received shell model or if stored features match one or more of the extracted features. If matches are found, then specific rules are implemented that have been previously stored and associated with the matched shell model or features on the received shell model. If no matches are found, then generalized binaural modeling rules are utilized based on the classified features.",G06F 17/50; H04R 25/00,SIEMENS AUDIOLOGISCHE TECHNIK,BINDNER JOERG; MCBAGONLURI FRED,61261606 19.12.2006 US,
WO2005036387,PCT/BE2004/000147,18.10.2004,WO/2005/036387,21.04.2005,WO,METHOD OF OPERATING SYSTEMS,,G06F 9/40; G06F 9/44,"DEFOSSÉ, Guillaume","DEFOSSÉ, Guillaume",2003/0543 17.10.2003 BE,
WO2017132168,PCT/US2017/014774,24.01.2017,WO/2017/132168,03.08.2017,WO,METHODS AND APPARATUS FOR MULTI-VIEW CHARACTERIZATION,"A model-based method of classifying a specimen in a specimen container. The method includes capturing images of the specimen and container at multiple different exposures times, at multiple different spectra having different nominal wavelengths, and at different viewpoints by using multiple cameras. From the captured images, 2D data sets are generated. The 2D data sets are based upon selection of optimally-exposed pixels from the multiple different exposure images to generate optimally-exposed image data for each spectra. Based upon these 2D data sets, various components are classified using a multi-class classifier, such as serum or plasma portion, settled blood portion, gel separator (if present), tube, air, or label. From the classification data and 2D data sets, a 3D model can be generated. Specimen testing apparatus and quality check modules adapted to carry out the method are described, as are other aspects.",G01N 1/10; G01N 21/03; G01N 21/95; G01B 11/245; G06T 3/00; G06T 7/00,SIEMENS HEALTHCARE DIAGNOSTICS INC.,"KLUCKNER, Stefan; CHANG, Yao-Jen; CHEN, Terrence; POLLACK, Benjamin, S.","62/288,371 28.01.2016 US",EP-2017744779; JP-2018539280
EP229632801,17200655,08.11.2017,3379531,26.09.2018,EP,TRAINING METHOD AND APPARATUS FOR SPEECH RECOGNITION,"A training method and apparatus for speech recognition is disclosed, where an example of the training method includes determining whether a current iteration for training a neural network is performed by an experience replay iteration using an experience replay set, selecting a sample from at least one of the experience replay set and a training set based on a result of the determining, and training the neural network based on the selected sample.",G10L 15/06; G06K 9/62; G06N 3/08; G10L 15/16,SAMSUNG ELECTRONICS CO LTD,MIN YUNHONG,20170036909 23.03.2017 KR,
WO1992014200,PCT/US1992/000793,30.01.1992,WO/1992/014200,20.08.1992,WO,PREDICTIVE SELF-ORGANIZING NEURAL NETWORK,"An A pattern recognition subsystem responds to an A feature representation input to select an A-category-representation and predict a B-category-representation and its associated B feature representation input. During learning trials, a predicted B-category-representation is compared to that obtained through a B pattern recognition subsystem. With mismatch, a vigilance parameter of the A-pattern-recognition subsystem is increased to cause reset of the first-category-representation selection. Inputs to the pattern recognition subsystems may be preprocessed to complement code the inputs.",G06N 3/04,TRUSTEES OF BOSTON UNIVERSITY,"CARPENTER, Gail, A.; GROSSBERG, Stephen; REYNOLDS, John, H.","648,653 31.01.1991 US",EP-1992907182
WO2020027771,PCT/US2018/044294,30.07.2018,WO/2020/027771,06.02.2020,WO,SYSTEMS AND METHODS FOR IDENTIFYING AND PROVIDING INFORMATION ABOUT SEMANTIC ENTITIES IN AUDIO SIGNALS,"Systems and methods for determining identifying semantic entities in audio signals are provided. A method can include obtaining, by a computing device comprising one or more processors and one or more memory devices, an audio signal concurrently heard by a user. The method can further include analyzing, by a machine-learned model stored on the computing device, at least a portion of the audio signal in a background of the computing device to determine one or more semantic entities. The method can further include displaying the one or more semantic entities on a display screen of the computing device.",G06F 17/30,GOOGLE LLC,"WANTLAND, Tim; BARBELLO, Brandon",,
EP200558441,16207565,30.12.2016,3189779,12.07.2017,EP,ELECTROCARDIOGRAM (ECG) AUTHENTICATION METHOD AND APPARATUS,"Disclosed are an electrocardiogram (ECG) authentication method and apparatus, and a training method and apparatus for training a neural network model used for ECG authentication, the ECG authentication apparatus being configured to acquire an ECG signal of a subject, extract a semantic feature of the ECG signal, and authenticate the subject based on the extracted semantic feature.",A61B 5/0452; A61B 5/117,SAMSUNG ELECTRONICS CO LTD,LIU YANG; FENG XUETAO; ZHANG CHAO; BAE CHISUNG; KIM SANG-JOON,201610007772 06.01.2016 CN; 20160119392 19.09.2016 KR,
WO2018195986,PCT/CN2017/082584,28.04.2017,WO/2018/195986,01.11.2018,WO,CALIBRATION OF LASER SENSORS,"A method for calibrating laser sensors carried by a mobile platform, includes determining an overlapping region of point cloud data generated by laser sensors, comparing surface features of the point clouds within the overlapping region, and generating calibration rules based thereon. A method for automatically detecting a disturbance to an emitter/detector unit carried by a mobile platform, comprising: transforming first and second point cloud information into a first and a second point cloud in a reference system associated with the mobile platform, the first and a second point cloud information obtained from the emitter/detector unit at a first and a second point in time; determining an overlapping region between the first and second point clouds; comparing surface attributes of the first and second point clouds in the overlapping region; detecting a disturbance to the emitter/detector unit based at least in part on comparing the surface attributes.",G06T 7/00; G06T 3/00; G01S 17/02,"SZ DJI TECHNOLOGY CO., LTD.","WU, Kanzhi; MA, Lu",,CN-201780090131.5; EP-2017907356
WO2018048355,PCT/SG2017/050449,07.09.2017,WO/2018/048355,15.03.2018,WO,OBJECT DETECTION FROM VISUAL SEARCH QUERIES,This invention includes a system and method of populating a database with known objects. The database can be populated with off-line data augmentation (e. g. a web crawler) or by aligning known objects and metadata clusters with defined content. A viewer can query images from live or offline media. Objects in the viewers query are linked with similar objects or recommended products in the database.,G06K 9/00; G06F 17/30,AIQ PTE. LTD.,"MOORE, Stephen Maurice; MURRAY, Larry Patrick; SHANMUGAMANI, Rajalingappaa","62/384,855 08.09.2016 US",KR-1020197009533; SG-11201809634T; CN-201780057452.5; EP-2017849212; JP-2019513057; RU-2018142028
WO2006048270,PCT/EP2005/011741,03.11.2005,WO/2006/048270,11.05.2006,WO,METHODS OF DETECTING LEUKEMIA AND ITS SUBTYPES,"The present invention relates to rapid and reliable approaches to detecting, diagnosing, and subtyping leukemia by gene expression profiling. In addition to these methods leukemia, the invention also provides related kits and systems.",G01N 33/574; C12Q 1/68,"ROCHE DIAGNOSTICS GMBH; F.HOFFMANN-LA ROCHE AG; HAFERLACH, Torsten; DUGAS, Martin; KERN, Wolfgang; KOHLMANN, Alexander; SCHNITTGER, Susanne; SCHOCH, Claudia","HAFERLACH, Torsten; DUGAS, Martin; KERN, Wolfgang; KOHLMANN, Alexander; SCHNITTGER, Susanne; SCHOCH, Claudia","60/625,697 04.11.2004 US",
WO2020009778,PCT/US2019/035931,07.06.2019,WO/2020/009778,09.01.2020,WO,METHODS FOR GENERATING A DATASET OF CORRESPONDING IMAGES FOR MACHINE VISION LEARNING,"Machine learning vision systems rely on very large numbers of training images to learn to recognize particular shapes and configurations of shapes. Traditionally, such datasets of training images needed to be selected and tagged (or labelled) manually. To recognize a particular object, such as a dog or vehicle, under realistic settings with an acceptable degree of reliability, may require data sets of thousands of images per object class. To improve this, a method is provided to generate datasets with a multiplicity of corresponding images are generated using a 3D rendering engine using a plurality of lighting arrangements and a plurality of views. Artefacts may also be introduced. In this way, very large data sets become feasible, with a variable degree of correspondence in each data set.",G06K 9/46; G06K 9/62; G06T 19/00,MASTERCARD INTERNATIONAL INCORPORATED,"COLLINS, Robert",18181118.3 02.07.2018 EP,
WO2020019102,PCT/CN2018/096599,23.07.2018,WO/2020/019102,30.01.2020,WO,"METHODS, SYSTEMS, ARTICLES OF MANUFACTURE AND APPARATUS TO TRAIN A NEURAL NETWORK","Methods, systems, apparatus, and articles of manufacture are disclosed to train a neural network. An example apparatus includes an architecture evaluator to determine an architecture type of a neural network, a knowledge branch implementor to select a quantity of knowledge branches based on the architecture type, and a knowledge branch inserter to improve a training metric by appending the quantity of knowledge branches to respective layers of the neural network.",G06N 3/08,"INTEL CORPORATION; YAO, Anbang; SUN, Dawei; ZHOU, Aojun; ZHAO, Hao; CHEN, Yurong","YAO, Anbang; SUN, Dawei; ZHOU, Aojun; ZHAO, Hao; CHEN, Yurong",,
WO2019190618,PCT/US2019/014229,18.01.2019,WO/2019/190618,03.10.2019,WO,EMOTIONAL ADAPTIVE DRIVING POLICIES FOR AUTOMATED DRIVING VEHICLES,"In one example a system for emotional adaptive driving policies for automated driving vehicles, comprising a first plurality of sensors to detect environmental information relating to at least one passenger in a vehicle and a controller communicatively coupled to the plurality of sensors and comprising processing circuitry, to receive the environmental information from the first plurality of sensors, determine, from the environmental information, an emotional state of the at least one passenger, and implement a driving policy based at least in part on the emotional state of the at least one passenger. Other examples may be described.",B60W 30/10; B60W 30/16; B60W 50/00,INTEL CORPORATION,"HEALEY, Jennifer; PALACIOS RIVERA, Victor; ALVAREZ, Ignacio","15/941,303 30.03.2018 US",
WO2018091486,PCT/EP2017/079246,15.11.2017,WO/2018/091486,24.05.2018,WO,CONVOLUTIONAL NEURAL NETWORKS FOR LOCATING OBJECTS OF INTEREST IN IMAGES OF BIOLOGICAL SAMPLES,"Convolutional neural networks for detecting objects of interest within images of biological specimens are disclosed. Also disclosed are systems and methods of training and using such networks, one method including: obtaining a sample image and at least one of a set of positive points and a set of negative points, wherein each positive point identifies a location of one object of interest within the sample image, and each negative point identifies a location of one object of no-interest within the sample image; obtaining one or more predefined characteristics of objects of interest and/or objects of no-interest, and based on the predefined characteristics, generating a boundary map comprising a positive area around each positive point the set of positive points, and/or a negative area around each negative point in the set of negative points; and training the convolutional neural network using the sample image and the boundary map.",G06K 9/00; G06N 3/02; G06K 9/46; G06K 9/62,"VENTANA MEDICAL SYSTEMS, INC.; F. HOFFMANN-LA ROCHE AG","CHUKKA, Srinivas; CHEN, Jianxu","62/423,114 16.11.2016 US",
EP13537490,01200396,25.08.1994,1104911,06.06.2001,EP,CNN bionic eye or other topographic sensory organs or combinations of the same,"The main design components underlying the implementation of physiologically faithful retina and other topographic sensory organ models on CNN universal chips is discussed. If the various retinas are implemented on a CNN universal chip, in a programmable way, it can be called a ""CNN bionic eye"", a device capable of performing a broad range of image processing functions similar to those performed by biological retinas. The CNN universal machine has the special properties that it is 1) programmable and 2) includes local memory. Programming is stored in analog and logical form (the analogic program) generated by an analogic programming and control unit, so the functions of the CNN universal machine can be modified as a function of complex internal and external constraints. Further, several CNN bionic eyes and other topographic sensory modalities can be combined on a single CNN universal chip, and for, more complex sensory tasks, the necessary physical microsensors to provide the input signals can be implemented on the chip, in most instances.",G06F 15/18; G06N 3/063; G06N 3/00; G06N 3/04; G06N 3/067; G06T 1/40,UNIV CALIFORNIA,WERBLIN FRANK S; ROSKA TAMA; CHUA LEON O,94927965 25.08.1994 EP; 11211593 26.08.1993 US,
EP12711847,95908943,20.02.1995,0703094,27.03.1996,EP,"BIOMETRIC SECURITY PROCESS FOR AUTHENTICATING IDENTITY AND CREDIT CARDS, VISAS, PASSPORTS AND FACIAL RECOGNATION","The security processes and products are based on coded topological and/or biometric information. Coded topological data, corresponding to a security document comprising an image, may be printed on the document in order to the used for its authentication. It is thus possible to establish a relationship between an image and certain pattern features contained in a database, said relationship being used for the fabrication and authentication of security documents and for the facial recognition of individuals. <IMAGE>",G06K 9/46; B42D 15/10; B42D 15/10; G06K 9/00; G07C 9/00,I D TEC S L,COBIAN SCHROEDER CARLOS,9400595 21.03.1994 ES; 9401171 26.05.1994 ES; 9401452 05.07.1994 ES; 9500021 20.02.1995 ES,
WO1996012240,PCT/US1995/013574,12.10.1995,WO/1996/012240,25.04.1996,WO,SYSTEM AND METHOD FOR SKIMMING DIGITAL AUDIO/VIDEO DATA,"A system and method for skimming digital audio (18) and video data (20) wherein the video data is partitioned into video segments.The method includes, selecting representative frames (64a, 64b, 64c, 64d) from each of the video segments, combining (235) the representative frames to form an assembled video sequence, identifying (230) keywords contained in a transcription of the audio data,extracting (237) portions of the audio data identified as keywords in the identifying step, assembling (239) an audio track in response to the extraction step, and outputting the video sequence in conjunction with the audio track.",G06F 17/30,CARNEGIE MELLON UNIVERSITY,"MAULDIN, Michael, L.; SMITH, Michael, A.; STEVENS, Scott, M.; WACTLAR, Howard, D.; CHRISTEL, Michael, G.; REDDY, D., Raj","08/324,079 14.10.1994 US",CA-2202540; MX-PA/a/1997/002675; EP-1995938832
WO2006099597,PCT/US2006/009875,17.03.2006,WO/2006/099597,21.09.2006,WO,POSE ESTIMATION BASED ON CRITICAL POINT ANALYSIS,"Methods and systems for estimating a pose of a subject. The subject can be a human, an animal, a robot, or the like. A camera receives depth information associated with a subject (310), a pose estimation module to determine a pose or action of the subject from images, and an interaction module to output a response to the perceived pose or action. The pose estimation module separates portions of the image containing the subject into classified and unclassified portions The portions can be segmented using k-means clustering The classified portions can be known objects, such as a head and a torso, that are tracked across the images The unclassified portions are swept across an x and y axis to identify local minimums and local maximums The critical points are derived from the local minimums and local maximums (320) Potential joint sections are identified by connecting various cπtical points and the joint sections having sufficient probability of corresponding to an object on the subject are selected to generate a skeletal structure based on which a pose of the subject is determined (330).",G06K 9/00; G06K 9/36; G06K 9/46; G06K 9/62,"HONDA MOTOR CO., LTD.; FUJIMURA, Kikuo; ZHU, Youding; THE OHIO STATE UNIVERSITY","FUJIMURA, Kikuo; ZHU, Youding","60/663,020 17.03.2005 US",RU-null; EP-6738875; JP-2008502129
WO2010022351,PCT/US2009/054651,21.08.2009,WO/2010/022351,25.02.2010,WO,SYSTEM AND METHOD FOR LOW BANDWIDTH IMAGE TRANSMISSION,An image transmission method (and related system) for obtaining data of a local subject and processing the data of the local subject to fit a local model of at least a region of the local subject and extract parameters of the local model to capture features of the region of the local subject. The method (and related system) may also include obtaining data of at least one remote subject and processing the data of the remote subject to fit at least one of at least one region of the remote subject and extract parameters the remote model to capture features of the region of the remote subject. The method (and related system) may also include transmitting the extracted parameters of the local region to a remote processor and reconstructing the local image based on the extracted parameters of the local region and the extracted parameters of the remote region.,G06K 9/36,"UNIVERSITY OF VIRGINIA PATENT FOUNDATION; BOKER, Steven, M.; BRICK, Timothy, R.; SPIES, Jeffrey, R.","BOKER, Steven, M.; BRICK, Timothy, R.; SPIES, Jeffrey, R.","61/090,944 22.08.2008 US; 61/235,549 20.08.2009 US",US-13059586
EP13537492,01200397,25.08.1994,1104912,06.06.2001,EP,CNN bionic eye or other topographic sensory organs or combinations of same,"The main design components underlying the implementation of physiologically faithful retina and other topographic sensory organ models on CNN universal chips is discussed. If the various retinas are implemented on a CNN universal chip, in a programmable way, it can be called a ""CNN bionic eye"", a device capable of performing a broad range of image processing functions similar to those performed by biological retinas. The CNN universal machine has the special properties that it is 1) programmable and 2) includes local memory. Programming is stored in analog and logical form (the analogic program) generated by an analogic programmic and control unit, so the functions of the CNN universal machine can be modified as a function of complex internal and external constraints. Further, several CNN bionic eyes and other topographic sensory modalities can be combined on a single CNN universal chip, and for, more complex sensory tasks, the necessary physical microsensors to provide the input signals can be implemented on the chip, in most instances.",G06F 15/18; G06N 3/063; G06N 3/00; G06N 3/04; G06N 3/067; G06T 1/40,UNIV CALIFORNIA,WERBLIN FRANK S; ROSKA TAMA KIKELET-U; CHUA LEON O,94927965 25.08.1994 EP; 11211593 26.08.1993 US,
WO2019203779,PCT/US2018/016017,16.04.2018,WO/2019/203779,24.10.2019,WO,A HUMAN-ARTIFICIAL INTELLIGENCE HYBRID SYSTEM,"A system allowing human intelligence and artificial intelligence to participate in the solving of a problem together, in real time, allowing the human to tag a data set of complex interactions to indicate where the failures are and to develop a system based on this dataset that learns heuristic rules to detect when a failure is likely and to automatically request further human assistance.",G06N 5/02; G06N 5/04; G06N 99/00,"VIIRRE, Erik","VIIRRE, Erik; TAGG, James",,
WO2020055759,PCT/US2019/050236,09.09.2019,WO/2020/055759,19.03.2020,WO,FUTURE OBJECT TRAJECTORY PREDICTIONS FOR AUTONOMOUS MACHINE APPLICATIONS,"In various examples, historical trajectory information of objects in an environment may be tracked by an ego-vehicle and encoded into a state feature. The encoded state features for each of the objects observed by the ego-vehicle may be used – e.g., by a bi-directional long short-term memory (LSTM) network – to encode a spatial feature. The encoded spatial feature and the encoded state feature for an object may be used to predict lateral and/or longitudinal maneuvers for the object, and the combination of this information may be used to determine future locations of the object. The future locations may be used by the ego-vehicle to determine a path through the environment, or may be used by a simulation system to control virtual objects – according to trajectories determined from the future locations – through a simulation environment.",G06N 3/04,NVIDIA CORPORATION,"VILLEGAS, Ruben; TROCCOLI, Alejandro; FROSIO, Iuri; TYREE, Stephen; BYEON, Wonmin; KAUTZ, Jan","62/729,659 11.09.2018 US; 16/564,978 09.09.2019 US",
WO2017158575,PCT/IB2017/051580,17.03.2017,WO/2017/158575,21.09.2017,WO,METHOD AND SYSTEM FOR PROCESSING A TASK WITH ROBUSTNESS TO MISSING INPUT INFORMATION,"A unit is disclosed for generating combined feature maps in accordance with a processing task to be performed, the unit comprising a feature map generating unit for receiving more than one modality and for generating more than one corresponding feature map using more than one corresponding transformation; wherein the generating of each of the more than one corresponding feature map is performed by applying a given corresponding transformation on a given corresponding modality, wherein the more than one corresponding transformation is generated following an initial training performed in accordance with the processing task to be performed and a combining unit for selecting and combining the corresponding more than one feature map generated by the feature map generating unit in accordance with at least one combining operation and for providing at least one corresponding combined feature map; wherein the combining unit is operating in accordance with the processing task to be performed and the combining operation reduces each corresponding numeric value of each of the more than one feature map generated by the feature map generation unit down to one numeric value in the at least one corresponding combined feature map.",G06F 15/00; G06F 15/18; G06F 9/44; G06N 3/04; G06N 3/08; G06T 7/10,IMAGIA CYBERNETICS INC.,"CHAPADOS, Nicolas; GUIZARD, Nicolas; HAVAEI, Mohammad; BENGIO, Yoshua","62/309,682 17.03.2016 US",CN-201780029595.5; SG-11201807914V; CA-3017697; EP-2017765968; JP-2019500044; US-16085339
EP14793823,07104374,16.03.2007,1835423,19.09.2007,EP,Method and system to index captioned objects in published literature for information discovery tasks,"The present invention relates to the identification, extraction, linking, storage and provisioning of data that constitute the captioned components of published or ""print ready"" literature for computerized information discovery activities including search, browse and data mining. These components, or objects, include the tabular presentation of data (""tables"") and graphics such as ""figures"", ""images"" and ""illustrations"" typically used to supplement the textual narrative of the publication.",G06F 17/30; G06F 40/00,PROQUEST CSA LLC,DUNIE MATTHEW; EMERSON CRAIG W,78345906 17.03.2006 US,
WO2019106132,PCT/EP2018/083094,30.11.2018,WO/2019/106132,06.06.2019,WO,GATED LINEAR NETWORKS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for a neural network system comprising one or more gated linear networks. A system includes: one or more gated linear networks, wherein each gated linear network corresponds to a respective data value in an output data sample and is configured to generate a network probability output that defines a probability distribution over possible values for the corresponding data value, wherein each gated linear network comprises a plurality of layers, wherein the plurality of layers comprises a plurality of gated linear layers, wherein each gated linear layer has one or more nodes, and wherein each node is configured to: receive a plurality of inputs, receive side information for the node; combine the plurality of inputs according to a set of weights defined by the side information, and generate and output a node probability output for the corresponding data value.",G06N 3/04; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"GRABSKA-BARWINSKA, Agnieszka; TOTH, Peter; MATTERN, Christopher; BHOOPCHAND, Avishkar; LATTIMORE, Tor; VENESS, Joel William","62/593,219 30.11.2017 US",
EP13537494,01200398,25.08.1994,1104913,06.06.2001,EP,CNN Bionic eye or other topographic sensory organs or combinations of same,"The main design components underlying the implementation of physiologically faithful retina and other topographic sensory organ models on CNN universal chips is discussed. If the various retinas are implemented on a CNN universal chip, in a programmable way, it can be called a ""CNN bionic eye"", a device capable of performing a broad range of image processing functions similar to those performed by biological retinas. The CNN universal machine has the special properties that it is 1) programmable and 2) includes local memory. Programming is stored in analog and logical form (the analogic program) generated by an analogic programming and control unit, so the functions of the CNN universal machine can be modified as a function of complex internal and external constraints. Further, several CNN bionic eyes and other topographic sensory modalities can be combined on a single CNN universal chip, and for, more complex sensory tasks, the necessary physical microsensors to provide the input signals can be implemented on the chip, in most instances.",G06F 15/18; G06N 3/063; G06N 3/00; G06N 3/04; G06N 3/067; G06T 1/40,UNIV CALIFORNIA,WERBLIN FRANK S; ROSKA TAMAS; CHUA LEON O,94927965 25.08.1994 EP; 11211593 26.08.1993 US,
WO2018185766,PCT/IL2018/050396,03.04.2018,WO/2018/185766,11.10.2018,WO,NEURAL NETWORK PROCESSING ELEMENT INCORPORATING COMPUTE AND LOCAL MEMORY ELEMENTS,"A novel and useful neural network (NN) processing core adapted to implement artificial neural networks (ANNs) and incorporating processing circuits having compute and local memory elements. The NN processor is constructed from self-contained computational units organized in a hierarchical architecture. The homogeneity enables simpler management and control of similar computational units, aggregated in multiple levels of hierarchy. Computational units are designed with minimal overhead as possible, where additional features and capabilities are aggregated at higher levels in the hierarchy. On-chip memory provides storage for content inherently required for basic operation at a particular hierarchy and is coupled with the computational resources in an optimal ratio. Lean control provides just enough signaling to manage only the operations required at a particular hierarchical level. Dynamic resource assignment agility is provided which can be adjusted as required depending on resource availability and capacity of the device.",G06N 3/063; G06F 12/0802,HAILO TECHNOLOGIES LTD.,"BAUM, Avi; DANON, Or; ZEITLIN, Hadar; CIUBOTARIU, Daniel; FEIG, Rami","62/481,492 04.04.2017 US; 62/531,372 12.07.2017 US",JP-2019554805; CN-201880020722.X; EP-2018781080
WO2019027992,PCT/US2018/044560,31.07.2018,WO/2019/027992,07.02.2019,WO,"OMNICHANNEL, INTELLIGENT, PROACTIVE VIRTUAL AGENT","An omni-channel, intelligent, proactive virtual agent system and method of use are provided by which a user may engage in a conversation with the agent to interact with structured and unstructured data of an enterprise that is stored in a domain-specific world model for the enterprise.",G06F 17/30; G06F 17/27; G10L 15/02; G06N 3/02,"TELEPATHY LABS, INC.","BROWN, Stephen; REBER, Martin; AVIJEET, Vijeta; BOUDETT, Josselyn","62/540,911 03.08.2017 US; 62/687,870 21.06.2018 US",EP-2018841652; SG-11202000712Y
EP235192173,18176879,08.06.2018,3415416,19.12.2018,EP,AIRCREW AUTOMATION SYSTEM,"An aircrew automation system that provides a pilot with high-fidelity knowledge of the aircraft's physical state, and notifies that pilot of any deviations in expected state based on predictive models. The aircrew automation may be provided as a non-invasive ride-along aircrew automation system that perceives the state of the aircraft through visual techniques, derives the aircraft state vector and other aircraft information, and communicates any deviations from expected aircraft state to the pilot. The aircrew automation may also monitor pilot health and, when needed, function as a robotic co-pilot to perform emergency descent and landing operations.",B64C 13/18; G05D 1/10,AURORA FLIGHT SCIENCES CORP,BOSWORTH WILLIAM; JENSEN DEVIN RICHARD; REAGAN MARGARET,201715624139 15.06.2017 US,
WO2009017483,PCT/US2007/017181,01.08.2007,WO/2009/017483,05.02.2009,WO,MALIGNANCY DIAGNOSIS USING CONTENT-BASED IMAGE RETREIVAL OF TISSUE HISTOPATHOLOGY,"This invention relates to computer-aided diagnostics using content-based retreival of histopathological image features. Specifically, the invention relates to the extraction of image features from a histopathological image based on predetermined criteria and their analysis for malignancy determination.",G06K 9/00; G06K 9/62; G06K 9/34; G06K 9/36; G06K 9/40,"THE TRUSTEES OF THE UNIVERSITY OF PENSSYLVANIA; RUTGERS, THE STATE UNIVERSITY OF NEW JERSEY; MADABHUSHI, Anant; DOYLE, Scott; TOMASZEWSKI, John, E.; FELDMAN, Michael, D.","MADABHUSHI, Anant; DOYLE, Scott; TOMASZEWSKI, John, E.; FELDMAN, Michael, D.",,EP-2007836399; US-12375981; IN-1181/CHENP/2009
WO2019096902,PCT/EP2018/081366,15.11.2018,WO/2019/096902,23.05.2019,WO,SYSTEM AND METHOD FOR REAL-TIME LARGE IMAGE HOMOGRAPHY PROCESSING,"A method for image processing performed by a computing device includes: (a) receiving one or more images and preprocessing the one or more images by extracting one or more features from the one or more images; (b) estimating image homographies (and/or fundamental matrices) based on the one or more features extracted from the one or more images; (c) determining particle trajectories based on composition of the image homographies (and/or fundamental matrices), wherein a particle trajectory comprises image pixel points identified in a subset of the one or more images; and (d) determining a joint estimation of camera pose, camera parameters, and a dense depth map using the particle trajectories.",G06K 9/00; G06T 7/579,NEC LABORATORIES EUROPE GMBH,"ALESIANI, Francesco; SINGH, Ankur","15/814,437 16.11.2017 US",
WO2015191651,PCT/US2015/034993,10.06.2015,WO/2015/191651,17.12.2015,WO,ADVANCED RECURRENT NEURAL NETWORK BASED LETTER-TO-SOUND,"The technology relates to performing letter-to-sound conversion utilizing recurrent neural networks (RNNs). The RNNs may be implemented as RNN modules for letter-to-sound conversion. The RNN modules receive text input and convert the text to corresponding phonemes. In determining the corresponding phonemes, the RNN modules may analyze the letters of the text and the letters surrounding the text being analyzed. The RNN modules may also analyze the letters of the text in reverse order. The RNN modules may also receive contextual information about the input text. The letter-to-sound conversion may then also be based on the contextual information that is received. The determined phonemes may be utilized to generate synthesized speech from the input text.",G10L 13/04,"MICROSOFT TECHNOLOGY LICENSING, LLC","ZHAO, Pei; YAO, Kaisheng; LEUNG, Max; HWANG, Mei-Yuh; ZHAO, Sheng; YAN, Bo; ZWEIG, Geoffrey; ALLEVA, Fileno A.","14/303,934 13.06.2014 US",EP-2015730629
WO2016075274,PCT/EP2015/076522,13.11.2015,WO/2016/075274,19.05.2016,WO,"METHODS, SYSTEMS AND APPARATUS FOR IMAGE RECOGNITION BASED ON RECURSIVELY DETERMINED EXEMPLAR-SUPPORT VECTOR MACHINES (E-SVM) FEATURES",An aspect of present principles relates to methods and apparatus for image searching. The method may include determining at least an RE-SVM feature based on a recursive exemplar support vector machine feature of an order n (RE-SVMn) and performing image searching by applying the determined RE-SVM feature to a plurality of features of search images. The apparatus may include a processor. The processor may be configured to determine at least an RE-SVM feature based on a recursive exemplar support vector machine feature of an order (RE-SVMn). The processor may further be configured to perform image searching by applying the determined RE-SVM feature to a plurality of features of search images. The RE-SVMn feature is determined based on at least an initial positive feature and at least an initial negative feature when n equals one. The RE-SVMn feature is determined based on at least a positive RE-SVMn-1 feature and at least a negative N-1 RE-SVM feature when n is greater than one.,G06F 17/30; G06K 9/00,THOMSON LICENSING,"ZEPEDA SALVATIERRA, Joaquin; PEREZ, Patrick",14306810.4 14.11.2014 EP,
WO2018184187,PCT/CN2017/079663,07.04.2017,WO/2018/184187,11.10.2018,WO,METHODS AND SYSTEMS FOR ADVANCED AND AUGMENTED TRAINING OF DEEP NEURAL NETWORKS USING SYNTHETIC DATA AND INNOVATIVE GENERATIVE NETWORKS,"Methods and systems for advanced and augmented training of deep neural networks (DNNs) using synthetic data and innovative generative networks. A method includes training a DNN using synthetic data, training a plurality of DNNs using context data, associating features of the DNNs trained using context data with features of the DNN trained with synthetic data, and generating an augmented DNN using the associated features.",G06K 9/66,"INTEL CORPORATION; YAO, Anbang; WANG, Shandong; CHENG, Wenhua; CAI, Dongqi; WANG, Libin; XU, Lin; HU, Ping; GUO, Yiwen; YANG, Liu; HOU, Yuqing; SU, Zhou; CHEN, Yurong","YAO, Anbang; WANG, Shandong; CHENG, Wenhua; CAI, Dongqi; WANG, Libin; XU, Lin; HU, Ping; GUO, Yiwen; YANG, Liu; HOU, Yuqing; SU, Zhou; CHEN, Yurong",,EP-2017904421; CN-201780088109.7
WO2017213780,PCT/US2017/031616,08.05.2017,WO/2017/213780,14.12.2017,WO,MOBILE AND WEARABLE VIDEO CAPTURE AND FEEDBACK PLAT-FORMS FOR THERAPY OF MENTAL DISORDERS,"Behavioral and mental health therapy systems in accordance with several embodiments of the invention include a wearable camera and/or a variety of sensors (accelerometer, microphone, among various other) connected to a computing system including a display, audio output, holographic output, and/or vibrotactile output to automatically recognize social cues from images captured by at least one camera and provide this information to the wearer via one or more outputs such as (but not limited to) displaying an image, displaying a holographic overlay, generating an audible signal, and/or generating a vibration.",G06F 19/00; G06T 7/20; G06Q 50/22,"THE BOARD OF TRUSTEES OF THE LELAND STANFORD JUNIOR UNIVERSITY; VOSS, Catalin","VOSS, Catalin; HABER, Nicholas, Joseph; WALL, Dennis, Paul; KLINE, Aaron, Scott; WINOGRAD, Terry, Allen","62/333,108 06.05.2016 US",CA-3023241; EP-2017810680; CN-201780036661.1; JP-2019510585; KR-1020187035497
WO2020036297,PCT/KR2019/006880,07.06.2019,WO/2020/036297,20.02.2020,WO,ELECTRONIC APPARATUS AND CONTROLLING METHOD THEREOF,"An electronic apparatus includes a storage configured to store a liquid-state machine (LSM) model and a recurrent neural networks (RNN) model, and a processor configured to input and process a feature data acquired from an input data using the LSM model, to input and process an output value output by the LSM model using the RNN model, and to identify whether a preset object is included in the input data based on an output value output by the RNN model. The RNN model is trained by a sample data related to the preset object. The LSM model includes a plurality of interlinked neurons. A weight applied to a link between the plurality of interlinked neurons is identified based on a spike at which a neuron value is greater than or equal to a preset threshold in a preset unit time.",G06N 3/08; G06N 3/04,"SAMSUNG ELECTRONICS CO., LTD.","USHAKOV, Yury",10-2018-0096368 17.08.2018 KR,
WO2018222896,PCT/US2018/035431,31.05.2018,WO/2018/222896,06.12.2018,WO,GRADIENT-BASED TRAINING ENGINE FOR QUATERNION-BASED MACHINE-LEARNING SYSTEMS,"A deep neural network (DNN) includes hidden layers arranged along a forward propagation path between an input layer and an output layer. The input layer accepts training data comprising quaternion values, outputs a quaternion-valued signal along the forward path to at least one of the hidden layers. At least some of the hidden layers include quaternion layers to execute consistent quaternion (QT) forward operations based on one or more variable parameters. A loss function engine produces a loss function representing an error between the DNN result and an expected result. QT backpropagation-based training operations include computing layer-wise QT partial derivatives, consistent with an orthogonal basis of quaternion space, of the loss function with respect to a QT conjugate of the one or more variable parameters and of respective inputs to the quaternion layers.",G06N 99/00,INTEL CORPORATION,"MARTINEZ-CANALES, Monica Lucia; SINGH, Sudhir K.; SHARMA, Vinod; BHANDARU, Malini Krishnan","62/513,390 31.05.2017 US",EP-2018809472; CN-201880028671.5
WO2012000650,PCT/EP2011/003177,28.06.2011,WO/2012/000650,05.01.2012,WO,A METHOD FOR CLASSIFYING A MULTITUDE OF IMAGES RECORDED BY A CAMERA OBSERVING A PROCESSING AREA AND LASER MATERIAL PROCESSING HEAD USING THE SAME,"The present invention relates to a method for classifying a multitude of images recorded by a camera observing a processing area of a workpiece processed by a processing beam, comprising the steps of: recording a first pixel image and a multitude of subsequent pixel images by the camera during a processing operation; detecting mismatches of a position and orientation of a keyhole generated by the processing beam in the workpiece within an image plane of the subsequent pixel images in comparison to the first pixel image; compensating the mismatches of the position and orientation of the respective keyholes in the subsequent pixel images with regard to the first pixel image, to produce a set of pixel images having each a normalized keyhole position and orientation; classifying the set of normalized pixel images into at least two classes by means of a classifier.",G06K 9/00; G06T 7/00; B23K 26/00; G05B 19/408,PRECITEC KG; PRECITEC ITM GMBH; INGO STORK GENANNT WERSBORG; MÜLLER-MEERKATZ Stefan,INGO STORK GENANNT WERSBORG; MÜLLER-MEERKATZ Stefan,10006692.7 28.06.2010 EP; 10012614.3 30.09.2010 EP; 10015914.4 21.12.2010 EP; 11000995.8 08.02.2011 EP; 11001371.1 18.02.2011 EP; 11004209.0 20.05.2011 EP,US-13807286; EP-2011728189
WO2015192117,PCT/US2015/035718,13.06.2015,WO/2015/192117,17.12.2015,WO,METHODS AND SYSTEMS FOR CREATING VIRTUAL AND AUGMENTED REALITY,"Configurations are disclosed for presenting virtual reality and augmented reality experiences to users. The system may comprise an image capturing device to capture one or more images, the one or more images corresponding to a field of the view of a user of a head-mounted augmented reality device, and a processor communicatively coupled to the image capturing device to extract a set of map points from the set of images, to identify a set of sparse points and a set of dense points from the extracted set of map points, and to perform a normalization on the set of map points.",G06K 9/00,"MAGIC LEAP, INC.","BRADSKI, Gary R.; MILLER, Samuel A.; ABOVITZ, Rony","62/012,273 14.06.2014 US",JP-2017518040; KR-1020177001117; EP-2015807476; AU-2015274283; CA-2953335; IL-249371
WO2020027454,PCT/KR2019/008353,08.07.2019,WO/2020/027454,06.02.2020,WO,MULTI-LAYERED MACHINE LEARNING SYSTEM TO SUPPORT ENSEMBLE LEARNING,"A method includes providing input data to a plurality of base models to generate a plurality of intermediate outputs. The base models are non-linear in that different base models are specialized differently such that the different base models are complementary to one another. Each of the base models is generated using a different base classification algorithm in a multi-layered machine learning system. The method also includes processing the intermediate outputs using a fusion model to generate a final output associated with the input data. The fusion model is generated using a meta classification algorithm in the multi-layered machine learning system. The method may also include training the classification algorithms, where training data used by each of at least one of the base classification algorithms is selected based on an uncertainty associated with at least one other of the base classification algorithms.",G06N 3/08; G06N 3/04; G06N 20/00,"SAMSUNG ELECTRONICS CO., LTD.","MOAZZAMI, Mohammad M.; YADAV, Anil","62/714,653 03.08.2018 US; 16/217,362 12.12.2018 US",
WO2006010645,PCT/EP2005/008724,26.07.2005,WO/2006/010645,02.02.2006,WO,"AN AUTOMATED ACTION-SELECTION SYSTEM AND METHOD, AND APPLICATION THEREOF TO TRAINING PREDICTION MACHINES AND DRIVING THE DEVELOPMENT OF SELF-DEVELOPING DEVICES","In order to promote efficient learning of relationships inherent in a system or setup S described by system-state and context parameters, the next action to take, affecting the setup, is determined based on the knowledge gain expected to result from this action. Knowledge-gain is assessed 'locally' by comparing the value of a knowledge-indicator parameter after the action with the value of this indicator on one or more previous occasions when the system-state/context parameter(s) and action variable(s) had similar values to the current ones. Preferably the 'level of knowledge' is assessed based on the accuracy of predictions made by a prediction module. This technique can be applied to train a prediction machine by causing it to participate in the selection of a sequence of actions. This technique can also be applied for managing development of a self-developing device or system, the self-developing device or system performing a sequence of actions selected according to the action-selection technique.",G06N 3/00,"SONY FRANCE S.A.; KAPLAN, Frédéric; OUDEYER, Pierre-Yves","KAPLAN, Frédéric; OUDEYER, Pierre-Yves",04291912.6 27.07.2004 EP,JP-2007523042; US-11658683
WO2005006249,PCT/AU2003/000881,09.07.2003,WO/2005/006249,20.01.2005,WO,METHOD AND SYSTEM OF DATA ANALYSIS USING NEURAL NETWORKS,"A system and method of computer data analysis using neural networks. In one embodiment of the invention, the system and method includes generating a data representation using a data set, the data set including a plurality of attributes, wherein generating the data representation includes: modifying the data set using a training algorithm, wherein the training algorithm includes growing the data set; and performing convergence testing, wherein convergence testing checks for convergence of the training algorithm, and wherein the modifying of the data set is repeated until convergence of the training algorithm occurs; and displaying one or more subsets of the data set using the data representation. In one embodiment, the data representation is a knowledge filter that includes a representation of an input data set. The representation may be constructed during a training process. In one exemplary embodiment, the training process uses unsupervised neural networks to create the data representation. In general terms, the data representation may include a number of coupled, or connected, hexagons called nodes. Considering relevant attributes, two nodes that are closer together may be more similar than two nodes that are further apart.",G06N 3/02,"RAPTOR INTERNATIONAL HOLDINGS PTY LTD; WOCKE, Carl; BRITS, Riaan","WOCKE, Carl; BRITS, Riaan",,ZA-200600641; EP-2003735182; ZA-2006/00641; US-10564105
WO2019040196,PCT/US2018/041701,11.07.2018,WO/2019/040196,28.02.2019,WO,CONTINUAL SELECTION OF SCENARIOS BASED ON IDENTIFIED TAGS DESCRIBING CONTEXTUAL ENVIRONMENT OF A USER FOR EXECUTION BY AN ARTIFICIAL INTELLIGENCE MODEL OF THE USER BY AN AUTONOMOUS PERSONAL COMPANION,"An autonomous personal companion executing a method including capturing data related to user behavior. Patterns of user behavior are identified in the data and classified using predefined patterns associated with corresponding predefined tags to generate a collected set of one or more tags. The collected set is compared to sets of predefined tags of a plurality of scenarios, each to one or more predefined patterns of user behavior and a corresponding set of predefined tags. A weight is assigned to each of the sets of predefined tags, wherein each weight defines a corresponding match quality between the collected set of tags and a corresponding set of predefined tags. The sets of predefined tags are sorted by weight in descending order. A matched scenario is selected for the collected set of tags that is associated with a matched set of predefined tags having a corresponding weight having the highest match quality.",G06N 3/00; G06N 99/00; A63H 11/00,"SONY INTERACTIVE ENTERTAINMENT INC.; TAYLOR, Michael","TAYLOR, Michael; FERNANDEZ-RICO, Javier; BASHKIROV, Sergey; YOO, Jaekwon; CHEN, Ruxin","15/684,830 23.08.2017 US",EP-2018749210
WO2019067695,PCT/US2018/053084,27.09.2018,WO/2019/067695,04.04.2019,WO,FLIGHT CONTROL USING COMPUTER VISION,"A flight control operation of a reference aerial vehicle is performed. For example, an image captured by an image sensor of the reference aerial vehicle is received. A target is detected in the image. A three-dimensional relative location of the target with respect to the reference aerial vehicle is determined based on the image. The flight control operation is performed based on the three-dimensional relative location of the target with respect to the reference aerial vehicle.",B64C 39/02; G05D 1/00; G05D 1/02; G05D 1/04; G05D 1/10,"AIRSPACE SYSTEMS, INC.","BAR-NAHUM, Guy; YOON, Hong-Bin,; GOVINDASWAMY, Karthik,; NGUYEN, Hoang, A.","15/729,581 10.10.2017 US; 62/566,449 01.10.2017 US; 16/142,452 26.09.2018 US",
WO2019212501,PCT/US2018/030262,30.04.2018,WO/2019/212501,07.11.2019,WO,TRAINED RECOGNITION MODELS,"A system may include a processing resource, and a computing device comprising instructions executable by the processing resource to: gather digital images of a unique object in a physical environment; utilize a generic model for identifying a type of the object to localize a portion of the unique object in the digital images; and train, form the portion of the unique object localized in the digital images, a new specific model for recognizing the unique object.",G06K 9/60; G06T 1/40,"HEWLETT-PACKARD DEVELOPMENT COMPANY, L.P.","PATEL, Arjun, Angur",,
WO2017155691,PCT/US2017/018839,22.02.2017,WO/2017/155691,14.09.2017,WO,DEEP DEFORMATION NETWORK FOR OBJECT LANDMARK LOCALIZATION,"A system and method are provided. The system includes a processor. The processor is configured to generate a response map for an image, using a four stage convolutional structure. The processor is further configured to generate a plurality of landmark points for the image based on the response map, using a shape basis neural network. The processor is additionally configured to generate an optimal shape for the image based on the plurality of landmark points for the image and the response map, using a point deformation neural network. A recognition system configured to identify the image based on the generated optimal shape to generate a recognition result of the image. The processor is also configured to operate a hardware-based machine based on the recognition result.",G06T 7/70; G06T 3/40; G06T 7/50,"NEC LABORATORIES AMERICA, INC.","YU, Xiang; ZHOU, Feng; CHANDRAKER, Manmohan","62/306,894 11.03.2016 US; 15/436,199 17.02.2017 US",JP-2018548057
WO2004053778,PCT/IB2003/005747,08.12.2003,WO/2004/053778,24.06.2004,WO,COMPUTER VISION SYSTEM AND METHOD EMPLOYING ILLUMINATION INVARIANT NEURAL NETWORKS,"Objects are classified using a normalized cross correlation (NCC) measure to compare two images acquired under non-uniform illumination conditions. An input pattern is classified to assign a tentative classification label and value. The input pattern is assigned to an output node in the radial basis function network having the largest classification value. If the input pattern and an image associated with the node, referred to as a node image, both have uniform illumination, then the node image is accepted and the probability is set above a user specified threshold. If the test image or the node image are not uniform, then the node image is not accepted and the classification value is kept as the value assigned by the classifier. If both the test image and the node image are not uniform, then an NCC measure is used and the classification value is set as the NCC value.",G06K 9/00; G06K 9/66,"KONINKLIJKE PHILIPS ELECTRONICS N.V.; PHILOMIN, Vasanth; GUTTA, Srinivas; TRAJKOVIC, Miroslav","PHILOMIN, Vasanth; GUTTA, Srinivas; TRAJKOVIC, Miroslav","60/432,540 11.12.2002 US",US-10538206; EP-2003812643; CN-200380105643.2; JP-2004558261; KR-1020057010676
WO2008058253,PCT/US2007/084148,08.11.2007,WO/2008/058253,15.05.2008,WO,SYSTEM AND METHOD FOR PARALLEL IMAGE PROCESSING,A system and method for processing images includes a plurality of image providers configured to transmit images. A plurality of destination processors receives the transmitted images and transforms the transmitted images to internally useable image data. A plurality of feature object engines find and identify in the internally useable image data a plurality of objects. A plurality of object classifier engines index and classify the plurality of objects found by the feature object engines.,G06K 9/00; G06K 9/62; H04N 7/18; H04N 9/47,"BERINI, Dario; VAN BEEK, Gary; MOICA, Simion, Adrian; DADRASSAN, Hooman; SRIVASTAVA, Prateek; FEVENS, Bryon; CRYPTOMETRICS, INC.","BERINI, Dario; VAN BEEK, Gary; MOICA, Simion, Adrian; DADRASSAN, Hooman; SRIVASTAVA, Prateek; FEVENS, Bryon","60/864,840 08.11.2006 US",CA-2669269; IN-2158/KOLNP/2009; MX-MX/a/2009/004990; EP-2007854604; NZ-577516; AU-2007317234; GB-0909740.3
WO2018183461,PCT/US2018/024791,28.03.2018,WO/2018/183461,04.10.2018,WO,"SYSTEMS, DEVICES AND METHODS FOR ENHANCING OPERATIVE ACCURACY USING INERTIAL MEASUREMENT UNITS","Accuracy enhancing systems, devices and methods are provided using data obtained from inertial measurement units (IMUs). IMUs are provided on one or more of a patient, surgical table, surgical instruments, imaging devices, navigation systems, and the like. Data from sensors in each IMU is collected and used to calculate absolute and relative positions of the patient, surgical table, surgical instruments, imaging devices, and navigation systems on which the IMUs are provided. The data generated by the IMUs can be coupled with medical images and camera vision, among other information, to generate and/or provide surgical navigation, alignment of imaging systems, pre-operative diagnoses and plans, intra-operative tool guidance and error correction, and post-operative assessments.",A61B 5/06,"DEPUY SYNTHES PRODUCTS, INC.","FRASIER, William; HALL, Mark; CHIEN, Dennis; PULS, Marc","15/475,587 31.03.2017 US",JP-2019553503; EP-2018776313; CN-201880022271.3; AU-2018246254
WO2002019147,PCT/US2001/026841,28.08.2001,WO/2002/019147,07.03.2002,WO,"METHOD AND APPARATUS FOR DIGITAL MEDIA MANAGEMENT, RETRIEVAL, AND COLLABORATION","The software according to the invention incorporates a glossary management tool (fig. 2) that makes it easy for each client to customize terminology (fig. 2) to the needs of a particular business. With this tool, termed a glossary manager (fig. 2), a company can customize a number of feature names (fig. 2) in the system to provide a more familiar context (fig. 2) for their users. A system administrator can also customize the manner in which 'thumbnail' or 'preview' images (fig. 2) are presented. The system performs clustering on search queries, and searches media records multi-modally, using two or more approaches such as image searching and text searching. An administrator can tune search parameters. Two or more streams of metadata may be aligned and correlated with a media file, facilitating later searching. The system evaluates itself. It folds popularity information into rankings of search results.",G06F 17/30,"FLANK, Sharon; SPERER, Ruth; FORBES, David, Ian; KLEIN, Ed; ST. JEAN, Randy; ROMER, Donna; ROTHEY, James; GRIFFIN, Robert; SIMONSEN, Keith; EHLERS, Gerald; EMOTION, INC.","FLANK, Sharon; SPERER, Ruth; FORBES, David, Ian; KLEIN, Ed; ST. JEAN, Randy; ROMER, Donna; ROTHEY, James; GRIFFIN, Robert; SIMONSEN, Keith; EHLERS, Gerald","60/228,837 28.08.2000 US",US-10063411; US-10063410; US-10063412; US-10063413; US-10063414
WO2016142675,PCT/GB2016/050604,07.03.2016,WO/2016/142675,15.09.2016,WO,IMAGING GUIDED AMBIENT IONISATION MASS SPECTROMETRY,"A method is disclosed comprising obtaining or acquiring image or other data from one or more regions of a target (2) using an imaging sensor (20). The image or other data may then be used to determine one or more regions of interest of the target (2). An ambient ionisation ion source (1) may then be used to generate aerosol, smoke or vapour (5) from one or more regions of the target (2).",G01N 33/68; A61B 17/00; G01N 3/00; G01N 9/00; H01J 49/00; A61B 18/00; G01N 27/62,MICROMASS UK LIMITED,"PRINGLE, Steven Derek; MORRIS, Michael Raymond; BALOG, Júlia; JONES, Emrys; RICHARDSON, Keith; LANGRIDGE, James Ian; SIMON, Dániel; GÖDÖRHÁZY, Lajos; SZALAY, Dániel; TAKÁTS, Zoltán",1503876.3 06.03.2015 GB; 1503864.9 06.03.2015 GB; 1503877.1 06.03.2015 GB; 1503867.2 06.03.2015 GB; 1503863.1 06.03.2015 GB; 1503878.9 06.03.2015 GB; 1516003.9 09.09.2015 GB; 1518369.2 16.10.2015 GB; 1503879.7 06.03.2015 GB,EP-2016710785; US-15556037; GB-1715787.6
WO2019202878,PCT/JP2019/009907,12.03.2019,WO/2019/202878,24.10.2019,WO,"RECORDING MEDIUM, INFORMATION PROCESSING APPARATUS, AND INFORMATION PROCESSING METHOD","There is provided a recording medium having a program recorded thereon, the program causing a computer to function as: a learning section configured to learn an action model for deciding an action of an action body on a basis of environment information indicating a first environment, and action cost information indicating a cost when the action body takes an action in the first environment; and a decision section configured to decide the action of the action body in the first environment on a basis of the environment information and the action model.",B25J 9/16,SONY CORPORATION; SONY ELECTRONICS INC.,"OTSUKA, Junji; KOJIMA, Tamaki","62/658,783 17.04.2018 US; 16/046,485 26.07.2018 US",
EP12156652,90119522,11.10.1990,0422654,17.04.1991,EP,Point pattern matching method and system as well as picture recognizing method and system using the same,"A point pattern matching method and system for use in an object recognizing system for deciding pair combinations between a first group of n points pj (n: integer of 2 or more) (j: integer between 1 and n) in a K-dimensional space (K: integer of 2 or more) and a second group of n second points qi (i: integer between 1 and n) in the same space as the K-dimensional space, wherein a total of n<2> of neurons are provided one for each one of point pair combinations between the first group of points and the second group of points, and, when an output of each of the neurons has a value of substantially ""1"", it is determined that the point pair combination associated with the neuron is matched, whereas, when the output of the neuron has a value of substantially ""0"", it is determined that the point pair combination associated with the neuron is not matched.",G06F 15/18; G06K 9/64; G06K 9/66; G06N 3/00; G06N 3/04; G06T 1/00; G06T 7/00,HITACHI LTD,SAKOU HIROSHI; UECKER DARRIN R,26491689 13.10.1989 JP,
EP14295100,03022421,07.10.2003,1522959,13.04.2005,EP,Application of an improved genetic algorithm for fitting X-ray scattering data,"A method of determining parameters of a sample by X-ray scattering comprising the steps of  a) exposing the sample to X-rays and measuring scattered X-ray intensity; b) generating a parameterised model of the sample which is used for numerical simulation of scattered X-ray intensity on the basis of a physical scattering theory; c) comparing the experimental and simulated X-ray scattering data to generate an error value; d) modifying the parameters of the model by means of a genetic algorithm involving an amount of individuals each with an equal number N of encoded parameters forming a generation and applying the genetic operators of ""selection"", ""crossover"" and ""mutation"" used for composing successive generations of evolving individuals,  is characterised in that from one generation to the next a ""movement"" genetic operator is applied which moves at least some of the encoded parameters of at least some of the individuals towards the respective encoded parameters of the individual with the smallest error value. The inventive method improves the genetic algorithm such that it can approximate the true sample parameters faster and with a better reliability. <IMAGE>",G06N 3/12; G01N 23/20,BRUKER AXS GMBH,ULYANENKOV ALEX; SOBOLEWSKI STANISLAW,03022421 07.10.2003 EP,
WO2004063831,PCT/EP2004/000157,13.01.2004,WO/2004/063831,29.07.2004,WO,SYSTEM AND METHOD FOR OPTIMIZATION OF A DATABASE FOR THE TRAINING AND TESTING OF PREDICTION ALGORITHMS,"A system and method are provided for the training and testing of prediction algorithms. According to an exemplary embodiment of the invention the method generates optimum training, testing and/or validation data sets from a common general database by applying a genetic algorithm to populations of testing and training subsets used in connection with a given prediction algorithm. In exemplary embodiments the prediction algorithm operated upon is an artificial neural network. As well, in preferred exemplary embodiments, the most predictive independent variables of the records of the common database are automatically selected in a pre-processing phase. Such preprocessing phase applies a genetic algorithm to populations of prediction algorithms which vary as to number and content of input variables, where the prediction algorithms representing the selections of input variables which have the best testing performances and the minimum input variables are promoted for the processing of the new generations according to a defined selection algorithm.",G06N 3/08,"BRACCO IMAGING S.P.A.; BUSCEMA, Massimo","BUSCEMA, Massimo","60/440,210 15.01.2003 US",US-10542208; JP-2006500551; US-2006230006; EP-2004701600
WO2018102748,PCT/US2017/064309,01.12.2017,WO/2018/102748,07.06.2018,WO,AUTOMATED DETECTION AND REPOSITIONING OF MICRO-OBJECTS IN MICROFLUIDIC DEVICES,"Methods are provided for the automated detection and/or counting of micro-objects in a microfluidic device. In addition, methods are provided for repositioning micro-objects in a microfluidic device. In addition, methods are provided for separating micro-objects in a spatial region of the microfluidic device.",G06T 7/10; G06T 1/20; G06T 1/40; G06T 7/00,"BERKELEY LIGHTS, INC.","KIM, Hansohl E.; TENNEY, John A.; SLOCUM, Joshua F.","62/429,071 01.12.2016 US; 62/579,897 01.11.2017 US",AU-2017368268; CN-201780085461.5; KR-1020197018732; CA-3045333; SG-11201904870T; EP-2017876009; IL-267009
WO2019118737,PCT/US2018/065472,13.12.2018,WO/2019/118737,20.06.2019,WO,EVOLUTION OF ARCHITECTURES FOR MULTITASK NEURAL NETWORKS,"Evolution and coevolution of neural networks via multitask learning is described. The foundation is (1) the original soft ordering, which uses a fixed architecture for the modules and a fixed routing (i.e. network topology) that is shared among all tasks. This architecture is then extended in two ways with CoDeepNEAT: (2) by coevolving the module architectures (CM), and (3) by coevolving both the module architectures and a single shared routing for all tasks using (CMSR). An alternative evolutionary process (4) keeps the module architecture fixed, but evolves a separate routing for each task during training (CTR). Finally, approaches (2) and (4) are combined into (5), where both modules and task routing are coevolved (CMTR).",G06F 17/30; G10L 15/06,COGNIZANT TECHNOLOGY SOLUTIONS U.S. CORPORATION,"LIANG, Jason, Zhi; MEYERSON, Elliot; RISTO, Miikkulainen","16/212,830 07.12.2018 US; 62/627,166 06.02.2018 US; 62/662,082 24.04.2018 US; 62/598,409 13.12.2017 US",
WO2020012475,PCT/IL2019/050770,10.07.2019,WO/2020/012475,16.01.2020,WO,METHOD AND SYSTEM FOR RAILWAY OBSTACLE DETECTION BASED ON RAIL SEGMENTATION,"Systems and methods for rails and obstacles detection based on forward-looking electrooptical imaging, novel system architecture and novel scene analysis and image processing are disclosed. The processing solution utilizes a deep learning semantic scene segmentation approach based on a rails and switches states detection neural network that determines the railway path of the train in the forward- looking imagery, and an objects and obstacles detection and tracking neural network that analyzes the vicinity of the determined railway path and detects impending obstacles.",B61L 23/04; G06N 3/08; G06T 7/10,RAIL VISION LTD,"DOLBERG, Sagi; DAY, Natalie; LEVY, Michael; ALFANDARY, Avishay; GUISSIN, Avraham Ram; BASON, Sharon; SHECHTER, Zohar Zeev; HANIA, Shahar; AZRIEL, Yotam","62/695,901 10.07.2018 US",
WO2019017874,PCT/US2017/042362,17.07.2017,WO/2019/017874,24.01.2019,WO,TECHNIQUES FOR MANAGING COMPUTATIONAL MODEL DATA,"Techniques and apparatus for managing data for computational models are described. In one embodiment, an apparatus may include at least one memory, and logic to enable a data management service operative to receive a data request from a data agent, the data request comprising data request information indicating a requested data set, determine a data status of the requested data set, the data status comprises one of existing data responsive to the requested data set being stored in a service database, or new data responsive to the requested data set not being stored in the service database, and responsive to the requested data set having the data status of new data, the data management service operative to access source data corresponding to the requested data set, and perform at least one preliminary operation on the source data to generate transformed data. Other embodiments are described and claimed.",G06N 3/08; G06N 3/04; G06N 99/00,INTEL CORPORATION,"SRIDHARAN, Srinvas; MUDIGERE, Dheevatsa",,
WO2018084942,PCT/US2017/052252,19.09.2017,WO/2018/084942,11.05.2018,WO,DEEP CROSS-CORRELATION LEARNING FOR OBJECT TRACKING,An artificial neural network for learning to track a target across a sequence of frames includes a representation network configured to extract a target region representation from a first frame and a search region representation from a subsequent frame. The artificial neural network also includes a cross-correlation layer configured to convolve the extracted target region representation with the extracted search region representation to determine a cross-correlation map. The artificial neural network further includes a loss layer configured to compare the cross-correlation map with a ground truth cross-correlation map to determine a loss value and to back propagate the loss value into the artificial neural network to update filter weights of the artificial neural network.,G06N 3/04; G06N 3/08; G06K 9/32,QUALCOMM INCORPORATED,"HABIBIAN, Amirhossein; SNOEK, Cornelis, Gerardus, Maria","62/418,707 07.11.2016 US; 15/708,014 18.09.2017 US",
WO2016033609,PCT/US2015/047820,31.08.2015,WO/2016/033609,03.03.2016,WO,METHOD AND SYSTEM FOR COMBINING PHYSIOLOGICAL AND MACHINE INFORMATION TO ENHANCE FUNCTION,The present invention relates generally and specifically to combining biological sensors with external machines using machine learning to form computerized representations that can control effectors to deliver therapy or enhance performance.,A61B 5/00; A61B 5/04,INCYPHAE INC.,"NARAYAN, Sanjiv, M.; SEHRA, Ruchir","62/043,760 29.08.2014 US; PCT/US2015/046819 25.08.2015 US",JP-2017531456; EP-2015766279
EP213594243,17001334,03.08.2017,3293681,14.03.2018,EP,SPATIO-TEMPORAL SPIKING NEURAL NETWORKS IN NEUROMORPHIC HARDWARE SYSTEMS,"Technologies are provided for implementing temporal and spatio-temporal spiking neural networks (SNNs) using neuromorphic hardware devices. Temporal synapse circuits, with associated weight values, can be used to control spike times of connected neuron circuits. The controlled spike times of multiple neuron circuits can be used to temporally encode information in a neural network in neuromorphic hardware. Neuron circuits in a state space detection layer can be organized into multiple subsets. Neuron circuits in different subsets can be connected to output neuron circuits in an output layer by separate temporal synapse circuits. Spiking signals sent from the neuron circuits in the state space detection layer via separate temporal synapse circuits can cause associated output neuron circuits to generate output spiking signals at different times. The various spike times of the output neuron circuits can be aggregated to produce an output signal for the network.",G06N 3/04; G06N 3/063,SAP SE,GOTTFRIED FRANK; DEISEROTH BJOERN; NEIDECKER LUTZ BURKHARD,201615264316 13.09.2016 US,
WO1990016038,PCT/GB1990/000932,15.06.1990,WO/1990/016038,27.12.1990,WO,CONTINUOUS BAYESIAN ESTIMATION WITH A NEURAL NETWORK ARCHITECTURE,"A neural network includes an observation system (10) which outputs an observation input to a novum (14). The novum (14) provides on an output a suboptimal innovations process related to the received observation and received prediction inputs. The received prediction inputs are received from an input vector (22) and represent a state estimate. The output of the novum (14) is input to an infinitesimal generator (IG) (16) on input vector (20). The IG (16) provides the state estimates on the vector (22). The novum is comprised of an array of processing elements or neurons (28) which each receive the state estimates from the IG (16) on lines (32). In a similar manner, the IG (16) is comprised of a geometrical lattice of neurons (34). Each of the neurons (34) receive synaptic inputs from the novum (14) on lines (36) and also receive a modifying threshold field input. A quantum mechanical wave particle is propagated across the geometrical lattice to provide an output (38) which has an inertia associated therewith. Each of the neurons (34) in the IG (16) has associated therewith a memory for storing the spatial patterns of a timed series of observations and, in a similar manner, the neurons (28) each have a memory associated therewith for storing the temporal patterns of the timed series of observations. The IG (16) is adaptive and learns by the Hebbian law whereby the novum (14) is adaptive and learns by the contraHebbian law.",G06N 3/04,"LAWRENCE, Malcolm, Graham","DAWES, Robert, Leo","367,468 16.06.1989 US",EP-1990909520
WO2011131973,PCT/GB2011/050761,18.04.2011,WO/2011/131973,27.10.2011,WO,CLASSIFICATION OF RANGE PROFILES,"A method and apparatus are provided for classifying range profiles, generated for example by a radar, lidar or sonar. In the method,each in a set of objects of interest is modelled with a probabilistic model. The probabilistic model represents the probabilities of occurrence of different possible sequences of distances between selected features of the object, in different orientations, that are likely to result in peaks of backscatter in a range profile of the object. The probabilistic model is derived from a first probabilistic representation of each selected feature, generated to represent the uncertainty in locating the feature and the uncertainty in observing the feature in a range profile. Classification is achieved by calculating, for each probabilistic model, the probability that the model would generate a given sequence of distances between observed backscatter events in a given range profile. The model generating the given sequence with the greatest probability identifies the object likely to have produced the given range profile. Preferably, the probabilistic models comprise Hidden Markov Models (HMMs).",G06K 9/00; G01S 7/41,"BAE SYSTEMS plc; MILLER, Robert, James","MILLER, Robert, James",1006629.8 21.04.2010 GB; 10250803.3 21.04.2010 EP,AU-2011244813; US-13642386; EP-2011716019; IN-9632/CHENP/2012
WO2019183733,PCT/CA2019/050389,29.03.2019,WO/2019/183733,03.10.2019,WO,METHOD AND SYSTEM FOR MOTION CAPTURE TO ENHANCE PERFORMANCE IN AN ACTIVITY,"A rehabilitation training method based on a predetermined protocol, the method comprising: with an imager, capturing motion of at least one anatomical part of a user during a user activity; and generating captured motion data; with a depth sensor, sensing a location of the at least one anatomical part of the user; with at least one processor, executing instructions to at least: analyze the captured motion data and recognize captured motion of the at least one anatomical part; compare the captured motion to a reference motion pertaining to a predetermined user activity; determine whether the captured motion of the at least one anatomical part matches the reference motion; provide feedback for correcting the motion of the at least one anatomical part of the user such that the motion of the at least one anatomical part of the user is substantially similar to the reference motion.",A61B 5/11; A63B 69/00; A63B 71/06; G06T 13/00,MATR PERFORMANCE INC.,"CAIRES, Thiago; LIPSON, Adam; STARR, Justin","62/650,129 29.03.2018 US",
EP11198623,10008544,19.12.2007,2249271,10.11.2010,EP,Intelligent modeling method and system for earmold shell and hearing aid design,"A method and appertaining system are provided for automatically modeling a hearing aid shell design. A 3D geometric description of an undetailed shell model is received, and its features and associated descriptors are automatically extracted. These features are classified, and a database of existing shells and features is queried to determine if a stored shell model matches the received shell model or if stored features match one or more of the extracted features. If matches are found, then specific rules are implemented that have been previously stored and associated with the matched shell model or features on the received shell model. If no matches are found, then generalized binaural modeling rules are utilized based on the classified features.",G06F 17/50; H04R 25/00,SIEMENS AUDIOLOGISCHE TECHNIK,BINDNER JOERG; MCBAGONLURI FRED,07123583 19.12.2007 EP; 61261606 19.12.2006 US,
WO2018089514,PCT/US2017/060665,08.11.2017,WO/2018/089514,17.05.2018,WO,REAL TIME EFFECTIVE MASS AND MOMENT OF INERTIA MEASUREMENT,"A control system and method for controlling an autonomous or semi-autonomous device. The method includes receiving a command signal representative of a desired acceleration, instructing the device to accelerate according to the desired acceleration, receiving a measurement signal representative of an actual acceleration, determining an initial control response based on the actual acceleration via a prediction model, applying a mathematical transform to the command signal and measurement signal, determining a mathematical model of the device based on the transformed command signal and transformed measurement signal, smoothing parameters of the mathematical model, inverting a transfer function of the mathematical model, updating control responses based on the mathematical model and inverted transfer function, and controlling the device according to the updated control responses. Improved performance of the control system itself and hence improved control of the autonomous or semi-autonomous device is thereby achieved.",G05B 9/03; G05D 1/00; G05D 1/08; G05D 1/10; G05D 3/00; G05D 3/12,"DIGITAL AEROLUS, INC.","MCEWAN, Ian J.","62/419,288 08.11.2016 US",
WO2018194733,PCT/US2018/013592,12.01.2018,WO/2018/194733,25.10.2018,WO,CONNECTING ASSISTANT DEVICE TO DEVICES,"The present disclosure contemplates a variety of improved methods and systems for enabling set up of a variety of disparate IoT devices coupled to the framework and/or ambient operating system of an assistant device. The described solution includes a voice-driven assistant device setup process. An assistant device can determine the IoT devices in its physical environment and provide setup instructions to the user. The setup including determining voice activatable commands, device information and the adapter to allow the assistant device to operate the one or more IoT devices in response to user instructions.",G10L 15/22; G10L 25/63; G10L 15/30; G10L 15/00; G06F 3/01; H04L 29/08,"ESSENTIAL PRODUCTS, INC.","ROMAN, Manuel; SEGAL, Mara Clair; DESAI, Dwipal; RUBIN, Andrew E.","62/486,423 17.04.2017 US; 15/604,325 24.05.2017 US",
WO2020012069,PCT/FI2019/050535,08.07.2019,WO/2020/012069,16.01.2020,WO,VIDEO PROCESSING,"An apparatus, a method and a computer program product are described comprising: obtaining or receiving video data;providing a current frame and/or one or more previous frames of the obtained or received video data to an input of a neural network;generating a predicted output at an output of the neural network, wherein the predicted output comprises at least one of one or more predicted future frames of the video data and predicted properties of one or more future frames of the video data; determining one or more processing decisions based, at least in part, on the predicted output; and processing the current frame of the video data at least partially according to the one or more processing decisions.",G06N 3/02; H04N 19/503; G06T 9/00; H04N 19/172; H04N 19/132,NOKIA TECHNOLOGIES OY,"CRICRI, Francesco; HALLAPURO, Antti; HANNUKSELA, Miska; LAINEMA, Jani; AKSU, Emre; AYTEKIN, Caglar; GHAZNAVI YOUVALARI, Ramin",1811197.1 09.07.2018 GB,
WO2017139927,PCT/CN2016/073943,17.02.2016,WO/2017/139927,24.08.2017,WO,REGION PROPOSAL FOR IMAGE REGIONS THAT INCLUDE OBJECTS OF INTEREST USING FEATURE MAPS FROM MULTIPLE LAYERS OF A CONVOLUTIONAL NEURAL NETWORK MODEL,Region proposal is described for image regions that include objects of interest. Feature maps from multiple layers of a convolutional neural network model are used. In one example a digital image is received and buffered. Layers of convolution are performed on the image to generate feature maps. The feature maps are reshaped to a single size. The reshaped feature maps are grouped by sequential concatenation to form a combined feature map. Region proposals are generated using the combined feature map by scoring bounding box regions of the image. Objects are detected and classified objects in the proposed regions using the feature maps.,G06K 9/00,"INTEL CORPORATION; YAO, Anbang; KONG, Tao; CHEN, Yurong","YAO, Anbang; KONG, Tao; CHEN, Yurong",,US-16070483
WO2014100195,PCT/US2013/076149,18.12.2013,WO/2014/100195,26.06.2014,WO,PHONEME SCORE ACCELERATOR,"Embodiments of the present invention include an acoustic processing device and a method for traversing a Hidden Markov Model (HMM). The acoustic processing device can include a senone scoring unit (SSU), a memory device, a HMM module, and an interface module. The SSU is configured to receive feature vectors from an external computing device and to calculate senones. The memory device is configured to store the senone scores and HMM information, where the HMM information includes HMM IDs and HMM state scores. The HMM module is configured to traverse the HMM based on the senone scores and the HMM information. Further, the interface module is configured to transfer one or more HMM scoring requests from the external computing device to the HMM module and to transfer the HMM state scores to the external computing device.",G10L 15/14; G10L 15/28,SPANSION LLC,"FASTOW, Richard, M.; BAPAT, Ojas, A.; OLSON, Jens","13/725,260 21.12.2012 US",
WO2020043296,PCT/EP2018/073381,30.08.2018,WO/2020/043296,05.03.2020,WO,DEVICE AND METHOD FOR SEPARATING A PICTURE INTO FOREGROUND AND BACKGROUND USING DEEP LEARNING,"Embodiments of the present invention relate to field of separating pictures, particularly pictures of a surveillance video, into foreground and background. A device and method are provided that employ a Convolutional Neural Network (CNN), i.e. are based on deep learning. The CNN is configured to receive as an input the picture and a background model image. The CNN is configured to generate feature maps of different resolution based on the input, wherein the resolution of feature maps is gradually reduced. Based on the feature maps, the CNN is configured to generate activation maps of different resolution, wherein the resolution of activation maps is gradually increased. Further, the CNN is configured to output a 1-channel probability map having the same resolution as the picture, wherein each pixel of the output 1-channel probability map corresponds to a pixel of the picture and indicates a probability that the corresponding pixel of the picture is associated with a foreground object or with a background object.",G06N 3/04; G06N 3/08; G06T 7/11; G06T 7/194,"HUAWEI TECHNOLOGIES CO., LTD.; HOANG, Thai, V","HOANG, Thai, V; BRENNER, Markus; WANG, Hongbin; TANG, Jian",,
WO2020056509,PCT/CA2019/051325,18.09.2019,WO/2020/056509,26.03.2020,WO,REGION PROPOSAL WITH TRACKER FEEDBACK,"Methods, systems, and techniques for object detection and tracking are provided. A system may include a module configured to generate a plurality of region proposals, each region proposal comprising a part of a video frame, a CNN pre-trained for object detection, the plurality of region proposals being input to the CNN; a tracker for tracking one or more targets based on outputs from the CNN across the series of video frames and generating tracking information on the one or more targets; and a module further configured to refine the plurality of region proposals to be input to the CNN, based on the tracking information.",G06K 9/00; G06T 1/40; H04N 19/17; H04N 21/80; G08B 13/196,AVIGILON CORPORATION,"LIPCHIN, Aleksey; WANG, Yin; XIAO, Xiao; ZHANG, Hao; LEE, Chia Ying","62/734,099 20.09.2018 US",
WO2017147552,PCT/US2017/019547,25.02.2017,WO/2017/147552,31.08.2017,WO,"MULTI-FORMAT, MULTI-DOMAIN AND MULTI-ALGORITHM METALEARNER SYSTEM AND METHOD FOR MONITORING HUMAN HEALTH, AND DERIVING HEALTH STATUS AND TRAJECTORY","Real-time and individualized disease monitoring is central to rapidly evolving medical sciences and technologies, but for the vast majority of patients, disease progression and treatment are monitored only in an irregular and discontinuous fashion. Consequently, disease progression and relapse are often allowed to proceed too far before they are detected, compromising the possibility of any effective treatment. For one patient, this can mean becoming refractory to the few early drug treatments that are available; for another, missing early detection may be deadly. This invention provides a method for the detection of early signals of disease and recovery thereof comprising a universal yet personalized healthmonitoring solution using cell phones or other wearable smart device data that generate extensive real-time data. The invention further provides a system and method to provide answers to a variety of questions related to the patient health status and health trajectory.",A61B 5/00; A61B 5/0295; A61N 1/00,"BRUNNER, Daniela","BRUNNER, Daniela","62/300,248 26.02.2016 US",CA-3015838
EP246634867,18164384,27.03.2018,3506150,03.07.2019,EP,METHOD AND DEVICE FOR DETECTING OBJECTS FROM SCENE IMAGES BY USING DYNAMIC KNOWLEDGE BASE,,G06K 9/00,WIPRO LTD,GOVINDARAJ BALAJI; ZAID MOHD; JAGANNATH SUJATHA,201741047409 30.12.2017 IN,
WO2015056024,PCT/GB2014/053116,17.10.2014,WO/2015/056024,23.04.2015,WO,VISUAL DATA MINING,"Method and system for finding targets within visual data, comprising receiving target object information. Generating a set of target object semantic attributes from the target object information. Identifying a plurality of candidate objects within visual data. Generating a set of low-level feature descriptors from the visual data for each candidate object. Generating from the set of low-level feature descriptors a set of candidate semantic attributes for each candidate object within the visual data. Identifying one or more portions of the visual data containing a candidate object, from the plurality of candidate objects, having a set of candidate object semantic attributes that match the set of target object semantic attributes. Providing an output indicating the identified one or more portions of the visual data.",G06K 9/00,VISION SEMANTICS LIMITED,"GONG, Shaogang Sean; HOSPEDALES, Timothy Miguel",1318472.6 18.10.2013 GB,EP-2014787045; US-15028082
WO2017015231,PCT/US2016/042838,18.07.2016,WO/2017/015231,26.01.2017,WO,NATURAL LANGUAGE PROCESSING SYSTEM AND METHOD,"Embodiments of a system and method for natural language processing (NLP) utilize one or more extraction models, and an output of syntactic parser applied to a text to extract information from the text. In an embodiment, an extraction model defines one or more units or combinations of units within a grammar hierarchy (a word, a phase, a clause, or any combination of words, phrases and clauses) as an output of extraction process. An extraction model further comprises a set of rules where each rule sets one or more constraints on: a grammar structure output by extraction process; on the context of the output of extraction process; and on the relations between the output and the context.",G06F 17/20; G06F 17/21; G06F 17/28,"FIDO LABS, INC.","LELIWA, Gniewosz; WROCZYNSKI, Michal","62/193,943 17.07.2015 US",
WO1998040824,PCT/US1998/003385,11.02.1998,WO/1998/040824,17.09.1998,WO,MODULE FOR CONSTRUCTING TRAINABLE MODULAR NETWORK IN WHICH EACH MODULE INPUTS AND OUTPUTS DATA STRUCTURED AS A GRAPH,"A machine learning paradigm called Graph Transformer Networks extends the applicability of gradient-based learning algorithms to systems composed of modules that take graphs as inputs and produce graphs as output. Training is performed by computing gradients of a global objective function with respect to all the parameters in the system using a kind of back-propagation procedure. A complete check reading system based on these concepts is described. The system uses convolutional neural network character recognizers, combined with global training techniques to provide record accuracy on business and personal checks.",G06F 15/18; G06F 17/50; G06K 9/68,AT & T CORP.,"BENGIO, Yoshua; BOTTOU, Leon; LE CUN, Yann, Andre","08/815,504 11.03.1997 US",
EP191879000,16176812,29.06.2016,3125151,01.02.2017,EP,"INVENTORY, GROWTH, AND RISK PREDICTION USING IMAGE PROCESSING","According to examples, inventory, growth, and risk prediction using image processing may include receiving a plurality of images captured by a vehicle during movement of the vehicle along a vehicle path. The images may include a plurality of objects. The images may be pre-processed for feature extraction. A plurality of features of the objects may be extracted from the pre-processed images by using a combination of computer vision techniques. A parameter related to the objects may be determined from the extracted features. A spatial density model may be generated, based on the determined parameter and the extracted features, to provide a visual indication of density of distribution of the objects related to a portion of the images, and/or to provide an alert corresponding to the objects related to the portion of the images.",G06K 9/00,ACCENTURE GLOBAL SERVICES LTD,MANNAR KAMAL; RAMANI SENTHIL; BHANDARI MANIK; WANG ANDREA HUANHUAN; BALASUNDARAM UVARAJ,10201506012S 31.07.2015 SG,
WO2018191155,PCT/US2018/026690,09.04.2018,WO/2018/191155,18.10.2018,WO,SMALL OBJECT DETECTION FROM A LARGE IMAGE,Embodiments include apparatus and methods for training and/or using a convolutional neural network. An image pyramid is calculated from an original image including at least one object of interest. The image pyramid includes a first image under analysis and a second image under analysis. Image patches are calculated at a first predetermined size relative to the first image under analysis and a second plurality of image patches having a second predetermined size relative to the second image under analysis. The convolutional neural network is trained using the image patches and subsequent images are analyzed by the convolutional neural network using similar image patches.,G06K 9/46; G06K 9/00,HERE GLOBAL B.V.,"FAN, Xiaochuan; MENG, Zibo","15/485,704 12.04.2017 US",EP-2018720900
WO2013192433,PCT/US2013/046857,20.06.2013,WO/2013/192433,27.12.2013,WO,METHOD TO PREDICT A COMMUNICATIVE ACTION THAT IS MOST LIKELY TO BE EXECUTED GIVEN A CONTEXT,"Disclosed are apparatus and methods for providing machine-learning services. A context-identification system executing on a mobile platform can receive data comprising context-related data associated with the mobile platform and application-related data received from the mobile platform. The context- identification system can identify a context using the context-related data associated with the mobile platform and/or the application-related data received from the mobile platform. Based on at least one context identified, context- identification system can predict a communicative action associated with the mobile platform by performing a machine-learning operation on the received data. An instruction can be received to execute the communicative action associated with the mobile platform.",H04M 1/725; G06N 99/00; G06F 15/18; H04M 1/60,GOOGLE INC.,"PATTERSON, Anna; ARADHYE, Hrishikesh; HUA, Wei; LEHMANN, Daniel; LIN, Ruei-Sung","13/568,957 07.08.2012 US; 61/663,438 22.06.2012 US",
WO2006020794,PCT/US2005/028609,12.08.2005,WO/2006/020794,23.02.2006,WO,BIOLOGICAL INTERFACE SYSTEMS WITH CONTROLLED DEVICE SELECTOR AND RELATED METHODS,"Various embodiments of a biological interface system and their related methods are disclosed. In one embodiment, a biological interface system may include a sensor including a plurality of electrodes configured to detect multicellular signals emanating from one or more living cells of a patient and a processing unit configured to receive the multicellular signals from the sensor and to process the multicellular signals to produce processed signals. The system may also include a plurality of controlled devices each configured to receive the processed signals. The plurality of controlled devices include at least a first controlled device and a second controlled device. The system may include a selector module usable by an operator and being configured to select which of the first and second controlled devices is to be controlled by the processed signals. In another embodiment, the processing unit may include a processing unit first portion and a processing unit second portion, where the processing unit first portion is implanted under the scalp on the skull of the patient, and the processing unit second portion is placed above the scalp of the patient at a location proximal to the processing unit first portion.",A61B 5/04; G06F 17/00,"CYBERKINETICS NEUROTECHNOLOGY SYSTEMS, INC.; SURGENOR, Timothy R.; DONOGHUE, John P.; SERRUYA, Mijail D.; FLAHERTY, J. Christopher","SURGENOR, Timothy R.; DONOGHUE, John P.; SERRUYA, Mijail D.; FLAHERTY, J. Christopher","60/601,400 13.08.2004 US",
WO2015017259,PCT/US2014/048123,25.07.2014,WO/2015/017259,05.02.2015,WO,CONTEXT-BASED SPEECH RECOGNITION,"A processing system receives an audio signal encoding a portion of an utterance. The processing system receives context information associated with the utterance, wherein the context information is not derived from the audio signal or any other audio signal. The processing system provides, as input to a neural network, data corresponding to the audio signal and the context information, and generates a transcription for the utterance based on at least an output of the neural network.",G10L 15/16,GOOGLE INC.,"WEINSTEIN, Eugene; MENGIBAR, Pedro J. Moreno; SCHALKWYK, Johan","61/860,443 31.07.2013 US; 14/030,265 18.09.2013 US",
EP260717104,17886187,14.12.2017,3557846,23.10.2019,EP,"DATA PROCESSING METHOD, END DEVICE, CLOUD DEVICE, AND END-CLOUD COLLABORATION SYSTEM","Provided is a data processing method, an end device, a cloud device, and an end-cloud collaboration system. The method comprises: the end device sends a request message to the cloud device, wherein the request message is used to request a neural network model for processing a cognitive computing task; the end device receives a second neural network model sent by the cloud device and obtained by means of compressing the first neural network model, wherein the first neural network model is a neural network model for processing the cognitive computing task on the cloud device, and the hardware resources required when the second neural network model runs on the end device are within the available capability range of the hardware resources of the end device; and the end device processes the cognitive computing task based on the second neural network model, thereby improving the performance of processing a neural network-related application of the end device, and aiding enhancement of the expansion of the intelligent application capability of the end device.",H04L 29/08; G06F 9/38; G06N 3/04; G06N 3/063; G06N 3/08,HUAWEI TECH CO LTD,SONG FENGLONG; LIU WULONG; XUE XIJUN; ZHANG HUIMIN,201611215479 26.12.2016 CN; 2017116203 14.12.2017 CN,
WO2015162605,PCT/IL2015/050413,19.04.2015,WO/2015/162605,29.10.2015,WO,SYSTEM AND METHOD FOR CONTROLLING A CAMERA BASED ON PROCESSING AN IMAGE CAPTURED BY OTHER CAMERA,"A device comprises a first digital camera having a first center line of sight and a second digital camera having a second center line of sight that is parallel and opposing the first camera. A method for controlling the first camera based on estimating the angular deviation between a person gaze direction and the line of sight of the first digital camera. A human face is detected in an image captured as an image file by the second digital camera, using a face detection algorithm. An angular deviation a is estimated, defined between the second center line of sight and an imaginary line from the second camera to the detected human face based on the captured image, and an angular deviation β is estimated, defined between the imaginary line from the second camera to the detected face and the human face gaze direction based on the captured image.",G06K 9/36,SNAPAID LTD,"SIVAN, Ishay","61/982,482 22.04.2014 US; 62/060,020 06.10.2014 US; 62/085,284 27.11.2014 US; 62/131,854 12.03.2015 US; 62/143,117 05.04.2015 US",EP-2015782955; US-15028852
WO2019046602,PCT/US2018/048892,30.08.2018,WO/2019/046602,07.03.2019,WO,ARTIFICIAL INTELLIGENCE AND/OR VIRTUAL REALITY FOR ACTIVITY OPTIMIZATION/PERSONALIZATION,Optimizing and/or personalizing activities to a user through artificial intelligence and/or virtual reality.,A61B 5/00; A61B 5/04; A61B 5/05,"P TECH, LLC","BONUTTI, Peter M.; BEYERS, Justin E.; BIERMAN, Tonya M.","62/552,091 30.08.2017 US; 62/552,096 30.08.2017 US",
WO2012059879,PCT/IB2011/054892,03.11.2011,WO/2012/059879,10.05.2012,WO,SYSTEM AND METHOD FOR SEARCHING FUNCTIONS HAVING SYMBOLS,"A system and method for searching through functions and expressions with symbols. Moreover, the system can be used to recognize and further analyze the notations of this nature and use this in order to translate, transform into audio, or solve the mathematical problems. According to at least some embodiments, the functions comprise mathematic equations which are defined by symbols and mathematic notation. The system and method enable a user to enter a mathematical equation in a WYSIWYG environment to a search engine, and to find similar or identical equations, first and foremost according to theoretical similarity, and secondly, according to visual similarity. The engine does this be understanding the meaning behind the visual symbols of the equation using a Dynamic Hidden Markov Model (hereon DHMM). The system enables the user to insert the equation with no prior knowledge of LaTeX, or any computing language, and with no need to follow a predefined generic protocol in order to insert the query.",G06F 17/10; G06F 17/30; G06K 9/68; G06F 17/21; G06F 17/27,"ARNON, Adam; EQSQUEST LTD.","ARNON, Adam","61/409,552 03.11.2010 US",US-13883283
WO2020068624,PCT/US2019/052360,23.09.2019,WO/2020/068624,02.04.2020,WO,SOUND CATEGORIZATION SYSTEM,A system method and computer program product for hierarchical categorization of sound comprising one or more neural networks implemented on one or more processors. The one or more neural networks are configured to categorize a sound into a two or more tiered hierarchical course categorization and a finest level categorization in the hierarchy. The categorization sound may be used to search a database for similar or contextually related sounds.,G06K 9/62; G10L 15/06; G10L 15/183,"SONY INTERACTIVE ENTERTAINMENT INC.; CHEN, Ruxin","JATI, Arindam; KUMAR, Naveen","16/147,331 28.09.2018 US",
WO2011160741,PCT/EP2011/001822,12.04.2011,WO/2011/160741,29.12.2011,WO,A METHOD FOR INDEXING MULTIMEDIA INFORMATION,"It comprises analyzing audio content of multimedia files and performing a speech to text transcription thereof automatically by means of an ASR process, and selecting acoustic and language models adapted for the ASR process at least before the latter processes the multimedia file, i.e. ""a priori"". The method is particularly applicable to the automatic indexing, aggregation and clustering of news from different sources and from different types of files, including text, audio and audiovisual documents without any manual annotation.",G06F 17/30; G10L 15/18,"TELEFONICA, S.A.; CONEJERO, David; DUXANS, Helenca; ESCALADA, Gregorio","CONEJERO, David; DUXANS, Helenca; ESCALADA, Gregorio","61/357,789 23.06.2010 US",EP-2011720980
WO2011062911,PCT/US2010/056869,16.11.2010,WO/2011/062911,26.05.2011,WO,AUTOMATICALLY MINING PERSON MODELS OF CELEBRITIES FOR VISUAL SEARCH APPLICATIONS,"Methods and systems for automated identification of celebrity face images are provided that generate a name list of prominent celebrities, obtain a set of images and corresponding feature vectors for each name, detect faces within the set of images, and remove non-face images. An analysis of the images is performed using an intra-model analysis, an inter-model analysis, and a spectral analysis to return highly accurate biometric models for each of the individuals present in the name list. Recognition is then performed based on precision and recall to identify the face images as belonging to a celebrity or indicate that the face is unknown.",G06K 9/62; G06K 9/00,"GOOGLE INC.; ROSS, David; RABINOVICH, Andrew; PILLAI, Anand; ADAM, Hartwig","ROSS, David; RABINOVICH, Andrew; PILLAI, Anand; ADAM, Hartwig","12/859,721 19.08.2010 US; 61/272,912 18.11.2009 US",AU-2010322173; CN-201080061203.1; KR-1020127015598; EP-2010782762; CA-2781105
WO2018194456,PCT/NL2018/050250,20.04.2018,WO/2018/194456,25.10.2018,WO,OPTICAL MUSIC RECOGNITION OMR : CONVERTING SHEET MUSIC TO A DIGITAL FORMAT,"The invention provides an optical music recognition (OMR) assembly for converting sheet music, representing a music part as a first temporal representation, into a machine-processable representation of said piece of music that represents at least a pitch and duration of notes that are graphically represented in said sheet music and form said music part as a second temporal representation, said assembly comprising a data processor system and software which, when running on said data processor system: - retrieves a machine-processable representation of said sheet music; - generate a series of time slices of said sheet music, by applying a sliding window on said over said machine-processable representation of at least part of said sheet music; - defines a sequence-to-sequence system, said sequence-to-sequence system comprising: provide a convolutional neural network (CNN) for converting said time slices into a sequence of third representations of said sheet music, said CNN comprising an input layer and an output layer; provide a first, encoder recurrent neural network (RNN) as an encoder on said sequence of third representations, for providing a hidden representation of said sheet music, said first RNN having an input layer that is functionally coupled to said output layer of said CNN, and an output layer; * provide a second, decoder recurrent neural network (RNN) as a decoder to said hidden representation, for converting said hidden representation into said machine- processable representation, said second RNN having an input layer that is functionally coupled to said output layer of said first RNN, and an output for providing said machine-processable representation.",G10H 1/00; G06N 3/04; G06N 3/02; G10G 1/04,UNIVERSITEIT VAN AMSTERDAM,"WEL, VAN DER, Eelco Jan; ULLRICH, Karin",2018758 20.04.2017 NL,
WO2019050137,PCT/KR2018/006984,20.06.2018,WO/2019/050137,14.03.2019,WO,SYSTEM AND METHOD OF DETERMINING INPUT CHARACTERS BASED ON SWIPE INPUT,"Provided are an artificial intelligence (AI) system and an application thereof, which simulate functions of a human brain, such as recognition and determination, by using a machine learning algorithm, such as deep-learning. A method of processing, by a device, a keyboard input, based on training, may include: displaying a keyboard on a screen of the device; receiving a swipe input of a user, the swipe input connecting a plurality of keys on a displayed keyboard; extracting a trajectory connecting the plurality of keys; applying, to a trained model for a keyboard input, based on the trajectory, trajectory information indicating a shape of the trajectory and a relative position of the trajectory with respect to the keyboard.",G06F 3/0488; G06N 99/00; G06K 9/32,"SAMSUNG ELECTRONICS CO., LTD.","KIM, Jung-wook; YUN, Hui-won; LEE, Hae-jun; JUNG, Ho-jin",10-2017-0113345 05.09.2017 KR,EP-2018853823
WO2019027258,PCT/KR2018/008756,01.08.2018,WO/2019/027258,07.02.2019,WO,ELECTRONIC DEVICE AND METHOD FOR CONTROLLING THE ELECTRONIC DEVICE,"An artificial intelligence (AI) system utilizing a machine learning algorithm to receive an area in an image provide a first search result by using first text information describing an object in the area by using a trained model, and provide a second search result by using second text information describing an object in the second area using the trained model.",G06F 17/30; G06N 3/08,"SAMSUNG ELECTRONICS CO., LTD.","KIM, Wonsik; CHOI, Yoon-hee","62/539,760 01.08.2017 US; 62/540,221 02.08.2017 US; 10-2018-0007301 19.01.2018 KR",EP-2018840410
WO2019236581,PCT/US2019/035391,04.06.2019,WO/2019/236581,12.12.2019,WO,SYSTEMS AND METHODS FOR OPERATING AN OUTPUT DEVICE,"Systems and methods for operation and control of a smart device, generally a video output device. An aspect is a gesture-based control system that identifies the operative user, regardless of how many potential users are present in the room, and regardless of where each potential user is disposed in the room. Another aspect is controlling and interfacing with a user output device using various types of queries and context cues, and responding to queries by resolving ambiguities in the query. These aspects may be used independently or in combination.",G06F 16/632; G06F 16/68; G10L 15/26,"DISRUPTEL, INC.","QUINN, Alexander, Clifford Hunt; LOWREY, John, F.","62/811,323 27.02.2019 US; 62/692,645 29.06.2018 US; 62/680,372 04.06.2018 US; 62/712,767 31.07.2018 US",
EP198050230,15196557,26.11.2015,3173983,31.05.2017,EP,A METHOD AND APPARATUS FOR PROVIDING AUTOMATICALLY RECOMMENDATIONS CONCERNING AN INDUSTRIAL SYSTEM,"A diagnostic system and method for providing recommendations concerning an industrial system, said diagnostic system (1) comprising an extraction unit (2) adapted to recognize ontology instances of classes within a domain related ontology using a recurrent neural network (RNN) trained with annotations of input data received from distributed data sources and adapted to derive relations between recognized ontology instances using a convolutional neural network (CNN) and to generate triples (T) each comprising a derived relation and the corresponding ontology instances; and a processing unit (3) adapted to retrieve at least one recommendation (R) in response to an inquiry and triples (T) inferred by an inference engine (IE) from a knowledge based database (KB) populated with triples (T) generated by said extraction unit (2). The semantic representation vectors for vocabulary of words used in the received unstructured domain related data are calculated using a neural network language model (NNLM).",G06N 3/10; G06F 17/27; G06F 17/30; G06N 3/04,SIEMENS AG,KUMAR KARN SANJEEV; WALTINGER ULLI,15196557 26.11.2015 EP,
WO2009119272,PCT/JP2009/054116,26.02.2009,WO/2009/119272,01.10.2009,WO,VIDEO PROCESSING APPARATUS AND METHOD,"An apparatus includes unit extracting performer information including a performer name and a first-appearance duration in which the performer appears in a video, unit extracting features of performers, unit determining, of figures who appear in a first sequence included in the video, figures having similarities of the features larger than a threshold as representing one and the same person, unit creating a second-appearance duration of at least one second sequence included in the video in which it is determined that one and the same person appears, and a first cluster identifier of a first cluster including the second sequence, unit determining if the second-appearance duration for each sequence is included in the first-appearance duration, and unit, when the second-appearance duration is included in the first-appearance duration, associating a second cluster identifier of a second cluster including the second sequence corresponding to the second-appearance duration with the performer name.",G06F 17/30,"KABUSHIKI KAISHA TOSHIBA; SHIMOMORI, Taishi; UEHARA, Tatsuya","SHIMOMORI, Taishi; UEHARA, Tatsuya",2008-076575 24.03.2008 JP,JP-2009514284
WO2007090033,PCT/US2007/061061,25.01.2007,WO/2007/090033,09.08.2007,WO,META LEARNING FOR QUESTION CLASSIFICATION,"A system and a method are disclosed for automatic question classification and answering. A multipart artificial neural network (ANN) comprising a main ANN and an auxiliary ANN classifies a received question according to one of a plurality of defined categories. Once the auxiliary ANN has trained, the weights are frozen and transferred to the main ANN. The main ANN can then be trained using labeled questions. The invention makes efficient use of available information, and improves training time and error rate relative to use of single part ANNs.",G05B 13/02,"HONDA MOTOR CO., LTD.; GUPTA, Rakesh; SWARUP, Samarth","GUPTA, Rakesh; SWARUP, Samarth","60/764,412 01.02.2006 US; 11/410,443 24.04.2006 US",DE-null; JP-2008553450
WO2018135833,PCT/KR2018/000738,16.01.2018,WO/2018/135833,26.07.2018,WO,SYSTEM AND METHOD FOR CONTEXTUAL DRIVEN INTELLIGENCE,"A method includes retrieving, by a device, contextual information based on at least one of an image, the device, user context, or a combination thereof. At least one model is identified from multiple models based on the contextual information and at least one object recognized in an image based on at least one model. At least one icon is displayed at the device. The at least one icon being associated with at least one of an application, a service, or a combination thereof providing additional information.",G06F 17/30; G06K 9/20,"SAMSUNG ELECTRONICS CO., LTD.","ANTOL, Stanislaw; BENDALE, Abhijit; GIBBS, Simon J.; JEON, Won J.; KANG, Hyun Jae; KIM, Jihee; LI, Bo; LIOT, Anthony S.; LUO, Lu; MISTRY, Pranav K.; YING, Zhihan","62/448,325 19.01.2017 US; 62/448,339 19.01.2017 US; 62/472,497 16.03.2017 US; 15/841,157 13.12.2017 US",KR-1020197022181; CN-201880007738.7; EP-2018741064
EP13930573,01961347,04.09.2001,1318505,11.06.2003,EP,"EMOTION RECOGNIZING METHOD, SENSIBILITY CREATING METHOD, DEVICE, AND SOFTWARE","An object of the invention is to provide an emotion detecting method capable of detecting emotion of a human accurately, and provide sensibility generating method capable of outputting sensibility akin to that of a human. An intensity, a tempo, and intonation in each word of a voice are detected based on an inputted voice signal, amounts of change are obtained for the detected contents, respectively, and signals expressing each states of emotion of anger, sadness, and pleasure are generated based on the amounts of change. A partner's emotion or situation information is inputted, and thus instinctive motivation information is generated. Moreover, emotion information including basic emotion parameters of pleasure, anger, and sadness is generated, which is controlled based on the individuality information. <IMAGE>",G06F 3/16; G06F 40/00; G06K 9/00; G06N 3/00; G10L 13/033; G10L 13/10; G10L 17/26,AGI INC,MITSUYOSHI SHUNJI,0107646 04.09.2001 JP; 2000278397 13.09.2000 JP; 2001007726 16.01.2001 JP,
WO2017176511,PCT/US2017/024629,28.03.2017,WO/2017/176511,12.10.2017,WO,ON-LINE ACTION DETECTION USING RECURRENT NEURAL NETWORK,"In implementations of the subject matter described herein, an action detection scheme using a recurrent neural network (RNN) is proposed. Representation information of an incoming frame of a video and predefined action label for the frame are obtained to train a learning network including RNN elements and a classification element. The representation information represents an observed entity in the frame. Specifically, parameters for RNN elements are determined based on representation information and the predefined action label. With the determined parameters, the RNN elements are caused to extract features for the frame based on the representation information and features for a preceding frame. Parameters for the classification element are determined based on extracted features and the predefined action label. The classification element with the determined parameters generates a probability of the frame being associated with the predefined action label. The parameters for the RNN elements are updated according to the probability.",G06K 9/00,"MICROSOFT TECHNOLOGY LICENSING, LLC","LAN, Cuiling; ZENG, Wenjun; LI, Yanghao; XING, Junliang",201610218351.9 08.04.2016 CN,US-16082265
WO2010099034,PCT/US2010/024689,19.02.2010,WO/2010/099034,02.09.2010,WO,CAPTURING AND RECOGNIZING HAND POSTURES USING INNER DISTANCE SHAPE CONTEXTS,"A system, method, and computer program product for recognizing hand postures are described. According to one aspect, a set of training images is provided with labels identifying hand states captured in the training images. Inner Distance Shape Context (IDSC) descriptors are determined for the hand regions in the training images, and fed into a Support Vector Machine (SVM) classifier to train it to classify hand shapes into posture classes. An IDSC descriptor is determined for a hand region in a testing image, and classified by the SVM classifier into one of the posture classes the SVM classifier was trained for. The hand posture captured in the testing image is recognized based on the classification.",G06K 9/00,"HONDA MOTOR CO., LTD.; DARIUSH, Behzad; GOPALAN, Raghuraman","DARIUSH, Behzad; GOPALAN, Raghuraman","61/155,439 25.02.2009 US",JP-2011552073
WO2020051776,PCT/CN2018/105107,11.09.2018,WO/2020/051776,19.03.2020,WO,METHOD AND SYSTEM OF DEEP SUPERVISION OBJECT DETECTION FOR REDUCING RESOURCE USAGE,"A system, article, and method of deep supervision object detection for reducing resource usage is provided for image processing and that uses depth-wise dense blocks.",G06K 9/00,"INTEL CORPORATION; LI, Jianguo; LI, Jiuwei; LI, Yuxi","LI, Jianguo; LI, Jiuwei; LI, Yuxi",,
EP275493180,17884701,15.12.2017,3561736,30.10.2019,EP,"MULTIPLICATION AND ADDITION DEVICE FOR MATRICES, NEURAL NETWORK COMPUTING DEVICE, AND METHOD","A multiplication and addition device for matrices, a neural network computing device, and a method. The multiplication and addition device (20) for matrices comprises: a matrix element storage module (210), comprising multiple storage spaces (211), used for receiving, according to a rule, a binary number obtained after a matrix element in a first matrix is converted; a symbolic computing module (220), used for performing exclusive-or computing on a symbol indicated by each bit in a 0<sp>th</sp> storage space and a symbol of a corresponding element in the second matrix, and using the computing result as a symbol position of a corresponding element in the second matrix; a numerical computing module (230), used for extracting a matrix element at a corresponding position in the second matrix according to the position of a matrix element in the matrix corresponding to a position whose bit value is 1 at a j<sp>th</sp> storage space, and adding matrix elements at corresponding positions, shifting the addition results by an i-j position, so as to obtain intermediate computing results; and a summation module (240), used for summating the intermediate computing results from a first to an (i-1)<sp>th</sp> storage space, so as to obtain a multiplication and addition result of the first matrix and the second matrix.",G06N 3/06,SHANGHAI CAMBRICON INFORMATION TECH CO LTD,CHEN TIANSHI; ZHUANG YIMIN; GUO QI; LIU SHAOLI; CHEN YUNJI,201611185917 20.12.2016 CN; 2017116456 15.12.2017 CN,
EP241675016,18202742,26.10.2018,3477589,01.05.2019,EP,"METHOD OF PROCESSING MEDICAL IMAGE, AND MEDICAL IMAGE PROCESSING APPARATUS PERFORMING THE METHOD","A device and a method for medical image processing are provided. The medical image processing method may include: obtaining a plurality of actual medical images corresponding to a plurality of patients and including lesions; training a deep neural network (DNN), based on the plurality of actual medical images, to obtain a first neural network for predicting a variation in a lesion over time, the lesion being included in a first medical image of the plurality of actual medical images, wherein the first medical image is obtained at a first time point; and obtaining, via the first neural network, a second medical image representing a state of the lesion at a second time point different from the first time point.",G06T 7/00; G06T 11/00,SAMSUNG ELECTRONICS CO LTD,LEE DONG-JAE; OH HYUN-HWA; KIM SE-MIN; SONG JEONG-YONG; LEE HYUN-JUNG,20170140317 26.10.2017 KR,
WO2017013494,PCT/IB2016/001148,22.07.2016,WO/2017/013494,26.01.2017,WO,METHODS AND SYSTEMS FOR DYNAMICALLY GENERATING REAL-TIME RECOMMENDATIONS,"Systems and methods are provided herein for generating personalized timeline-based feeds to a user. A computer-implemented method for generating feeds to a user may be provided. The method may include generating a timeline comprising a plurality of milestones and needs associated with an event, and providing the feeds based on community wisdom. The feeds may be provided for each milestone on the time-line specific to the user, and may be configured to address the user's needs at each milestone.",G06N 7/00; H04L 29/08,WISDO LTD.,"GILON, Arik; ENGEL, Ido, Jonathan; GAON, Boaz; GOFER, Arie","62/195,762 22.07.2015 US; 62/196,142 23.07.2015 US",EP-2016827320
WO2020056118,PCT/US2019/050787,12.09.2019,WO/2020/056118,19.03.2020,WO,SYSTEM AND METHOD FOR LABEL-FREE IDENTIFICATION AND CLASSIFICATION OF BIOLOGICAL SAMPLES,"A system and method of analyzing a biological sample using an imaging system are disclosed. An image acquisition module instructs the imaging system to obtain a label free image of a training biological sample and receives a first training image. The imaging system causes the training biological sample to fluoresce, and obtains a second training image. An analysis module analyzes the second training image to generate a plurality of training cell characteristics, wherein each of the plurality of training cell characteristics is associated with one of a plurality of training cells in the training biological sample. A training module trains a machine learning system using the first training image and the plurality of training cell characteristics to develop a trained machine learning system which takes the first training image as an input and generates a plurality of predicted cell characteristics that correspond to the plurality of training cell characteristics.",G01N 33/483; G06N 20/00,"MOLECULAR DEVICES, LLC","COHEN, Avrum, I.; HONG, Dihui; RHEIN, Stephen","16/128,798 12.09.2018 US",
WO2014071330,PCT/US2013/068360,04.11.2013,WO/2014/071330,08.05.2014,WO,NATURAL LANGUAGE PROCESSING SYSTEM AND METHOD,"A natural language processing system is disclosed herein. Embodiments of the NLP system perform hand-written rule-based operations that do not rely on a trained corpus. Rules can be added or modified at any time to improve accuracy of the system, and to allow the same system to operate on unstructured plain text from many disparate contexts (e.g. articles as well as twitter contexts as well as medical articles) without harming accuracy for any one context.",G06F 17/28,FIDO LABS INC.,"WROCZYNSKI, Michal; KRUPA, Tomasz; LELIWA, Gniewosz; WIACEK, Piotr; STANCYK, Michal","61/721,792 02.11.2012 US",EP-2013851449
WO2019182811,PCT/US2019/021846,12.03.2019,WO/2019/182811,26.09.2019,WO,SYSTEM AND METHOD FOR DYNAMICALLY ADJUSTING LEVEL OF DETAILS OF POINT CLOUDS,"Some embodiments of an example method disclosed herein may include receiving point cloud data representing one or more three-dimensional objects; receiving a viewpoint of the point cloud data; selecting a selected object from the one or more three-dimensional objects using the viewpoint; retrieving a neural network model for the selected object; generating a level of detail data for the selected object using the neural network model; and replacing, within the point cloud data, points corresponding to the selected object with the level of detail data.",G06K 9/00; G06T 19/00,"PCMS HOLDINGS, INC.","HARVIAINEN, Tatu V. J.","62/645,618 20.03.2018 US",
EP14284013,04254776,07.08.2004,1508796,23.02.2005,EP,Method and system for analyzing coatings undergoing exposure testing,"A method and system for analyzing a plurality of coatings undergoing exposure testing is disclosed. Included in the system are a data acquisition system and a computer system. The data acquisition system acquires coating identification and attribute data through various input devices, while the computer system automatically receives, stores, analyzes and displays the coating attribute data. The analytical results relate to the durability of a coating composition under test, which may be used for predicting the performance of a coating characteristic and developing improved coating compositions. <IMAGE>",G01J 3/52; G01N 21/88; G01J 3/52; G01N 17/00; G01N 17/00; G01N 21/84; G01N 21/25; G01N 33/32; G01N 21/57; G01N 21/84; G01N 33/32,ROHM & HAAS,LINSER MICHAEL W; SCHMITT EDWARD A; SCHURE MARK RICHARD,49708303 22.08.2003 US,
WO2019170905,PCT/EP2019/055950,11.03.2019,WO/2019/170905,12.09.2019,WO,TRAINING AN UNSUPERVISED MEMORY-BASED PREDICTION SYSTEM TO LEARN COMPRESSED REPRESENTATIONS OF AN ENVIRONMENT,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for training a memory-based prediction system configured to receive an input observation characterizing a state of an environment interacted with by an agent and to process the input observation and data read from a memory to update data stored in the memory and to generate a latent representation of the state of the environment. The method comprises: for each of a plurality of time steps: processing an observation for the time step and data read from the memory to: (i) update the data stored in the memory, and (ii) generate a latent representation of the current state of the environment as of the time step; and generating a predicted return that will be received by the agent as a result of interactions with the environment after the observation for the time step is received.",G06N 3/00; G06N 3/04; G06N 3/08; G06N 7/00,DEEPMIND TECHNOLOGIES LIMITED,"WAYNE, Gregory Duncan; HUNG, Chia-Chun; AMOS, David Antony; MIRZA MOHAMMADI, Mehdi; AHUJA, Arun; LILLICRAP, Timothy Paul","62/640,946 09.03.2018 US",
WO2019246434,PCT/US2019/038301,20.06.2019,WO/2019/246434,26.12.2019,WO,METHODS OF CHEMICAL COMPUTATION,"The invention provides methods for computing with chemicals by encoding digital data into a plurality of chemicals to obtain a dataset; translating the dataset into a chemical form; reading the data set; querying the dataset by performing an operation to obtain a perceptron; and analyzing the perceptron for identifying chemical structure and/or concentration of at least one of the chemicals, thereby developing a chemical computational language. The invention demonstrates a workflow for representing abstract data in synthetic metabolomes. Also presented are several demonstrations of kilobyte-scale image data sets stored in synthetic metabolomes, recovered at >99% accuracy.",G06N 3/00; G06N 3/02,BROWN UNIVERSITY,"RUBENSTEIN, Brenda; ROSENSTEIN, Jacob, Karl; ARCADIA, Christopher; CHEN, Shui, Ling; DOMBROSKI, Amanda, Doris; GEISER, Joseph, D.; KENNEDY, Eamonn; KIM, Eunsuk; OAKLEY, Kady, M.; REDA, Sherief; ROSE, Christopher; SELLO, Jason, Kelby; TANN, Hokchhay; WEBER, Peter","62/791,504 11.01.2019 US; 62/687,366 20.06.2018 US",
WO2015103268,PCT/US2014/072758,30.12.2014,WO/2015/103268,09.07.2015,WO,LEARNING DATA PROCESSOR FOR DISTRIBUTING LEARNING MACHINES ACROSS LARGE-SCALE NETWORK INFRASTRUCTURES,"In one embodiment, a learning data processor determines a plurality of machine learning features in a computer network to collect. Upon receiving data corresponding to the plurality of features, the learning data processor may aggregate the data, and pushes the aggregated data for select features to interested learning machines associated with the computer network.",H04L 12/24; H04L 12/851; H04L 12/753; G06Q 10/06; H04L 29/08,"CISCO TECHNOLOGY, INC.","VASSEUR, Jean-Philippe; MERMOUD, Grégory; DASGUPTA, Sukrit","14/163,638 24.01.2014 US; 61/922,348 31.12.2013 US",EP-2014828644
WO2001074062,PCT/US2001/009223,21.03.2001,WO/2001/074062,04.10.2001,WO,USER INTERFACE WITH MEDIA BAR,"A media bar providing a unified mechanism for user-friendly integrated access to various types (video, audio, and text) of digital multimedia content corresponding to captioned subject matters. In accordance with an embodiment, a user interface to an Internet (102) enabled television system includes such a media bar. The media bar may operate in conjunction with an embedded and/or a pop-up media viewer. The media viewer may provide access to streaming digital video sources (118) and/or streaming digital audio sources. The media bar may also operate in conjunction with a text viewer for presenting text content.",G06Q 30/00; G06T 3/40; H01L 21/336; H04N 5/00; H04N 5/44; H04N 5/445; H04N 7/16; H01L 21/28; H04N 5/45,"DIGEO BROADBAND, INC.","ISTVAN, Anthony, F.; WILKINS, Lisa, M.","60/193,046 29.03.2000 US; 09/591,547 08.06.2000 US; 60/213,811 22.06.2000 US; 09/613,445 11.07.2000 US",
WO2018156991,PCT/US2018/019570,23.02.2018,WO/2018/156991,30.08.2018,WO,CONTROL SYSTEMS FOR UNMANNED AERIAL VEHICLES,"A method for controlling an unmanned aerial vehicle within a flight operating space. The unmanned aerial vehicle includes one or more sensor arrays on each spar. The method includes determining, using a plurality of sensor arrays, a flight path for the unmanned aerial vehicle. The method also includes receiving, by at least one sensor array of the plurality of sensor arrays, sensor data identifying at least one object in the operating space. The sensor data is transmitted over a communications bus connecting components of the UAV. The method further includes determining, by one or more processors onboard the unmanned aerial vehicle, a flight path around the at least one object. The method also includes generating, by the one or more onboard processors, a first signal to cause the unmanned aerial vehicle to navigate within the operating space around the at least one object.",G05D 1/10; G05D 1/08; B64C 39/02,"CYPHY WORKS, INC.","JOHNSON, Samuel, A.; MISTRY, Samir, S.; ALEMAN, John; TSUTSUMI, Erika; THOMSON, Chad","62/463,539 24.02.2017 US; 62/541,637 04.08.2017 US",EP-2018710239; CA-3054313
WO2019092418,PCT/GB2018/053228,07.11.2018,WO/2019/092418,16.05.2019,WO,METHOD OF COMPUTER VISION BASED LOCALISATION AND NAVIGATION AND SYSTEM FOR PERFORMING THE SAME,"In relation to the field of vehicle navigation, we describe a method of determining a position of a subject (such as a vehicle, platform or target), comprising the steps of obtaining and storing an object dataset comprising object data indicative of one or more objects in an environment, including an indication of object parameters associated with the or each object, the object parameters including one or more of location, orientation, one or more dimensions, and a type associated with the object, obtaining environment data indicative of a region of the environment from a sensor associated with the subject, determining the presence of an observed object in the environment data, including determining one or more equivalent observed object parameters associated with the observed object, and determining the position of the subject based on a comparison of the observed object parameters with the equivalent object parameters of the objects in the object dataset.",G01C 21/00; G01C 21/20; G01C 21/32; G01S 5/16; G05D 1/02; G06T 7/70,HORIBA MIRA LIMITED,"MALONEY, Andrew",1718628.9 10.11.2017 GB,
EP242633146,18208155,23.11.2018,3489860,29.05.2019,EP,IMAGE DISPLAY APPARATUS AND METHOD OF OPERATING THE SAME,,G06K 9/62; G06K 9/00,SAMSUNG ELECTRONICS CO LTD,GARG JATIN; KOO JAYOON; AGARWAL VIVEK; SANCHES ERNESTO,20170161002 28.11.2017 KR,
WO2019099144,PCT/US2018/056418,18.10.2018,WO/2019/099144,23.05.2019,WO,LEARNING TO RECONSTRUCT 3D SHAPES BY RENDERING MANY 3D VIEWS,"Methods, systems, and apparatus for obtaining first image features derived from an image of an object, providing the first image features to a three-dimensional estimator neural network, and obtaining, from the neural network, data specifying an estimated three-dimensional shape and texture based on the first image features. The estimated three-dimensional shape and texture are provided to a rendering engine, and a plurality of three-dimensional views of the object are generated by the rendering engine based on the estimated three-dimensional shape and texture. The three-dimensional views are provided to the object recognition engine, and second image features derived from the three-dimensional views are obtained from the object recognition engine. A loss is computed based at least on the first and second image features, and the neural network is trained based at least on the computed loss.",G06K 9/00; G06K 9/46; G06K 9/62,GOOGLE LLC,"COLE, Forrester H.; GENOVA, Kyle","15/813,338 15.11.2017 US",EP-2018799638; CN-201880030823.5
WO2018194940,PCT/US2018/027680,13.04.2018,WO/2018/194940,25.10.2018,WO,POWER-EFFICIENT DEEP NEURAL NETWORK MODULE CONFIGURED FOR PARALLEL KERNEL AND PARALLEL INPUT PROCESSING,"A deep neural network (DNN) module utilizes parallel kernel and input processing to decrease bandwidth utilization, reduce power consumption, improve neuron multiplier stability, and provide other technical benefits. Parallel kernel processing enables the DNN module to load input data once for processing by multiple kernels. Parallel input processing enables the DNN module to load kernel data once for processing with multiple input data. The DNN module can implement other power-saving techniques like clock-gating and power-gating banks of accumulators based upon usage of the accumulators. For example, individual banks of accumulators can be power-gated when all accumulators in a bank are not in use, and do not store data for a future calculation. Banks of accumulators can also be clock-gated when all accumulators in a bank are not in use, but store data for a future calculation.",G06N 3/063,"MICROSOFT TECHNOLOGY LICENSING, LLC","AMBARDEKAR, Amol Ashok; MCBRIDE, Chad Balling; PETRE, George; WALL, Larry Marvin; CEDOLA, Kent D.; BOBROV, Boris","62/486,432 17.04.2017 US; 15/951,690 12.04.2018 US",
WO2012000648,PCT/EP2011/003175,28.06.2011,WO/2012/000648,05.01.2012,WO,METHOD FOR CLOSED-LOOP CONTROLLING A LASER PROCESSING OPERATION AND LASER MATERIAL PROCESSING HEAD USING THE SAME,"The present invention relates to a method for closed-loop controlling a processing operation of a workpiece, comprising the steps of: (a) recording a pixel image at an initial time point of an interaction zone by means of a camera, wherein the workpiece is processed using an actuator having an initial actuator value; (b) converting the pixel image into a pixel vector; (c) representing the pixel vector by a sum of predetermined pixel mappings each multiplied by a corresponding feature value; (d) classifying the set of feature values on the basis of learned feature values into at least two classes of a group of classes comprising a first class of a too high actuator value, a second class of a sufficient actuator value and a third class of a too low actuator value at the initial time point; (e) performing a control step for adapting the actuator value by minimizing the error et between a quality indicator ye and a desired value; and (f) repeating the steps (a) to (e) for further time points to perform a closed-loop controlled processing operation.",B23K 26/00; G06T 7/00; G05B 13/00; G05B 19/408,"PRECITEC KG; PRECITEC ITM GMBH; STORK GENANNT WERSBORG, Ingo; BAUTZE, Thibault","STORK GENANNT WERSBORG, Ingo; BAUTZE, Thibault",10006692.7 28.06.2010 EP; 10012614.3 30.09.2010 EP; 10015914.4 21.12.2010 EP; 11000995.8 08.02.2011 EP; 11001371.1 18.02.2011 EP; 11004209.0 20.05.2011 EP,US-13807289; EP-2011745481
WO2020030903,PCT/GB2019/052206,06.08.2019,WO/2020/030903,13.02.2020,WO,DROPLET PROCESSING METHODS AND SYSTEMS,A method of processing droplets in a microfluidic system. The method may comprise capturing a time sequence of images of a droplet as it passes through a channel in a microfluidic system. The method may further comprise processing each image of the sequence of images using a convolutional neural network to count a number of cells or other entities visible in each image the droplet. The method may further comprise processing the count of the number of cells or other entities visible in each image of the droplet to determine an estimated number of cells or other entities in the droplet. The method/system may further comprise controlling a microfluidic process performed on the droplet responsive to the estimated number of cells or other entities in the droplet. Implementations of the method use the changing orientation and disposition of droplet contents in combination with machine learning to improve monoclonality assurance.,B01L 3/00; G01N 15/14; G01N 35/08; G06K 9/00; G06K 9/46; G06K 9/62,SPHERE FLUIDICS LIMITED,"DAYRELL-ARMES, Nicholas; HOLMES, David; CRAIG, Frank F; REHAK, Marian; JOSEPHIDES, Dimitris; SALTER, Robert; WHITLEY, William; GOKKAYA, Sinan; RUIS, Raphael",1812912.2 08.08.2018 GB,
WO2018179539,PCT/JP2017/037770,12.10.2017,WO/2018/179539,04.10.2018,WO,METHOD FOR CONTROLLING HOST VEHICLE AND CONTROL SYSTEM OF HOST VEHICLE,A method controls a motion of the host vehicle in the environment according to a trajectory and adjusts the trajectory of the vehicle based on the levels of risk posed by the motion of other vehicles. The method determines a set of feasible trajectories of hypothetical vehicles traveling in a driving area of the host vehicle and determines a level of risk of each feasible trajectory as a combination of the probability of the feasible trajectory to intersect with the trajectory of the host vehicle and the probability of the feasible trajectory to be followed by at least one vehicle. The method adjusts the trajectory of the host vehicle in response to assessing the levels of risk of the feasible trajectories.,G08G 1/16; B60W 30/08; G05D 1/02; G06K 9/00,MITSUBISHI ELECTRIC CORPORATION,"BERNTORP, Karl; OKAMOTO, Kazuhide; DI CAIRANO, Stefano","15/471,665 28.03.2017 US",JP-2019534767
WO2020060334,PCT/KR2019/012297,20.09.2019,WO/2020/060334,26.03.2020,WO,METHOD AND APPARATUS FOR PERFORMING QOS PREDICTION IN NR V2X,"Provided are a method for quality of service (QoS) prediction by a first apparatus (100). The method may comprise: receiving a first message for requesting the QoS prediction between the first apparatus (100) and a second apparatus (200), from the second apparatus (200); and performing a UE autonomous QoS prediction or a network assistance QoS prediction, based on QoS prediction configuration.",H04L 12/24; H04L 12/927; H04L 12/911; H04W 4/40,LG ELECTRONICS INC.,"JUNG, Sunghoon; SEO, Hanbyul","62/734,195 20.09.2018 US",
WO2017176112,PCT/NL2017/050206,04.04.2017,WO/2017/176112,12.10.2017,WO,SPATIAL DATA ANALYSIS,"The spatial data analysis system for processing spatial data comprises a statistical analysis module (20) and a convolutional neural network (30). The statistical analysis module (20) calculates a discrete two-dimensional spatial distribution (V(k,l)) of at least one statistical measure derived from said spatial data. The spatial distribution defines a statistical measure value of one or more statistical measure for respective raster elements (R(k,l)) in a two-dimensional raster for the data elements derived from the spatial datain the spatial window associated with the raster element. The convolutional neural network (30) is configured to provide object information of objects based on the statistical data.",G06K 9/00; G06K 9/46,FUGRO N.V.,"GAUDET, Chase; NEPVEAUX, Marcus; NORMAND, Kevin",2016542 04.04.2016 NL,EP-2017718151; US-16091018; AU-2017246938; CA-3020069
WO2018111661,PCT/US2017/064983,07.12.2017,WO/2018/111661,21.06.2018,WO,KERNEL SOFT RESET USING NON-VOLATILE RAM,"Technologies are described which permit kernel updates or firmware fixes, and include re-initialization of kernel data structures, without losing user context information that has been created by services, virtual machines, or user applications. Tailored code in a server or other computing system sets a kernel soft reset (KSR) indicator and saves the user context to non-volatile storage. When a KSR is underway, boot code skips the power on self-test and similar initializations (thereby reducing downtime), loads a kernel image, initializes kernel data structures, restores the user context, and passes control to the initialized kernel to continue computing system operation with the same user context. Device drivers may also be re-initialized. The loaded kernel may use newly fixed firmware, or may have a security patch installed, for instance. The non-volatile storage may operate at RAM speed, e.g., it may include NVDIMM memory. The kernel may be validated before receiving control.",G06F 9/4401; G06F 11/14; G06F 8/656; G06F 9/455,"MICROSOFT TECHNOLOGY LICENSING, LLC","BULUSU, Mallik; KELLY, Bryan; NGUYEN, Tom Long","15/378,406 14.12.2016 US",CN-201780077227.8; EP-2017832601
WO2018222775,PCT/US2018/035217,30.05.2018,WO/2018/222775,06.12.2018,WO,BROAD AREA GEOSPATIAL OBJECT DETECTION,"A system for simplified generation of systems for analysis of satellite images to geolocate one or more objects of interest, A plurality of training images labeled for a study object or objects with irrelevant features loaded into a preexisting feature identification subsystem causes automated generation of models for the study object. This model is used to parameterize pre-engineered machine learning elements that are running a preprogrammed machine learning protocol. Training images with the study are used to train object recognition filters. This filter is used to identify the study object in unanalyzed images. The system reports results in a requestor's preferred format.",G06K 9/62; G06N 3/08,"DIGITALGLOBE, INC.","ESTRADA, Adam; GREEN, Kevin; JENKINS, Andrew","15/608,894 30.05.2017 US",
EP232545705,18163725,23.03.2018,3396544,31.10.2018,EP,EFFICIENT SHARING AND COMPRESSION OF DATA ACROSS PROCESSING SYSTEMS,"A mechanism is described for facilitating sharing of data and compression expansion of models at autonomous machines. A method of embodiments, as described herein, includes detecting a first processor processing information relating to a neural network at a first computing device, where the first processor comprises a first graphics processor and the first computing device comprises a first autonomous machine. The method further includes facilitating the first processor to store one or more portions of the information in a library at a database, where the one or more portions are accessible to a second processor of a computing device.",G06F 9/50; G06N 3/02,INTEL CORP,APPU ABHISHEK R; KOKER ALTUG; WEAST JOHN C; MACPHERSON MIKE B; KIM DUKHWAN; HURD LINDA L; BAGHSORKHI SARA S; GOTTSCHLICH JUSTIN E; SURTI PRASOONKUMAR; SAKTHIVEL CHANDRASEKARAN; RAY JOYDEEP,201715495081 24.04.2017 US,
WO2016075293,PCT/EP2015/076567,13.11.2015,WO/2016/075293,19.05.2016,WO,ACCELERATED SUPPORT VECTOR MACHINE (SVM) LEARNING USING CLUSTERING,An aspect of present principles relate to methods and apparatus for image searching. The method may include determining a classifier based on at least a centroid representing a plurality of negative features and performing image searching based on the classifier. The apparatus may include an apparatus configured to determine a classifier based on centroids representing a plurality of negative features and to perform image searching based on the classifier. The centroids are determined based on a clustering of the plurality of negative features.,G06K 9/62,THOMSON LICENSING,"ZEPEDA SALVATIERRA, Joaquin; PEREZ, Patrick",14306810.4 14.11.2014 EP,
EP276032578,17889129,28.12.2017,3564864,06.11.2019,EP,"DEVICES FOR COMPRESSION/DECOMPRESSION, SYSTEM, CHIP, AND ELECTRONIC DEVICE","Provided in the present disclosure are devices for use in compression/decompression of neural network data, a system, a chip, a chip packaging structure, a card, and an electronic device. The compression device comprises: a model conversion module and a data encoding module connected to the model conversion model. The decompression device comprises: a data decoding module and a model conversion module connected to the data decoding module. The system comprises: the compression device and the decompression device. The present invention achieves an increased compression rate for the compression/decompression of neural network data, and significantly alleviates the pressure on storage space and transmission for a neural network model.",G06N 3/06; H04N 7/24,SHANGHAI CAMBRICON INFORMATION TECH CO LTD,CHEN TIANSHI; LUO YUZHE; GUO QI; LIU SHAOLI; CHEN YUNJI,201611270091 30.12.2016 CN; 2017119364 28.12.2017 CN,
EP238739201,18187277,03.08.2018,3451230,06.03.2019,EP,METHOD AND APPARATUS FOR RECOGNIZING OBJECT,"Methods and apparatus for recognizing an object are provided, including extracting a feature from an input image and generating a feature map in a neural network. In parallel with the generating of the feature map, a region of interest (ROI) corresponding to an object of interest is extracted from the input image, and a number of object candidate regions used to detect the object of interest is determined based on a size of the ROI. The object of interest is recognized from the ROI based on the number of object candidate regions in the neural network.",G06K 9/00; G06K 9/32,SAMSUNG ELECTRONICS CO LTD,JEON PAUL BAROM,20170112429 04.09.2017 KR,
WO2020050508,PCT/KR2019/010039,09.08.2019,WO/2020/050508,12.03.2020,WO,IMAGE DISPLAY APPARATUS AND OPERATION METHOD OF THE SAME,"An image display apparatus includes a display configured to display a plurality of images, a memory storing one or more instructions, and a processor configured to execute the one or more instructions stored in the memory to obtain semantic information corresponding to each of the plurality of images by using a first neural network, obtain emotion information corresponding to each of the plurality of images by using a second neural network, determine at least one piece of audio corresponding to the plurality of images, based on the semantic information and the emotion information, and output the at least one piece of audio.",G06F 3/16; G06F 3/01; G06F 3/0481; G06N 3/04; G06N 3/08,"SAMSUNG ELECTRONICS CO., LTD.","BAIJAL, Anant; HYUN, Daeeun; KWON, Mijeong",10-2018-0106046 05.09.2018 KR,
WO2019203921,PCT/US2019/018119,14.02.2019,WO/2019/203921,24.10.2019,WO,SYSTEM FOR REAL-TIME OBJECT DETECTION AND RECOGNITION USING BOTH IMAGE AND SIZE FEATURES,"Described is an object recognition system. Using an integral channel features (ICF) detector, the system extracts a candidate target region (having an associated original confidence score representing a candidate object) from an input image of a scene surrounding a platform. A modified confidence score is generated based on a location and height of detection of the candidate object. The candidate target regions are classified based on the modified confidence score using a trained convolutional neural network (CNN) classifier, resulting in classified objects. The classified objects are tracked using a multi-target tracker for final classification of each classified object as a target or non-target. If the classified object is a target, a device can be controlled based on the target.",G06K 9/20; G06K 9/00; G06K 9/62; G06N 3/08; G06T 7/11; G06T 7/292,"HRL LABORATORIES, LLC","CHEN, Yang; KHOSLA, Deepak; UHLENBROCK, Ryan, M.","62/659,100 17.04.2018 US",
WO2016137552,PCT/US2015/062951,30.11.2015,WO/2016/137552,01.09.2016,WO,AUTOMATICALLY LEARNING AND CONTROLLING CONNECTED DEVICES,A first input is received from a plurality of sensors. A first state including a first location based on the first input is determined. The first state is associated with a first probability. A second input is received from the plurality of sensors. A second state including a second location is determined based on the second input associated with a second probability. It is determined that the second state corresponds to an actual state based on a transition model and the second probability. The transition model associates the first state with the second state and indicates a likelihood of a transition from the first state to the second state. A rule to change a state of at least one network connected device is triggered based on the second state.,G06F 9/46; G06T 7/20; H04L 29/08,BRAINOFT INC.,"SAXENA, Ashutosh; KOPPULA, Hema Swetha; WU, Chenxia; SENER, Ozan","14/725,989 29.05.2015 US; 62/120,240 24.02.2015 US",
WO2001041064,PCT/EP2000/011434,15.11.2000,WO/2001/041064,07.06.2001,WO,PROGRAM CLASSIFICATION USING OBJECT TRACKING,"A content-based classification system is provided that detects the presence of object images within a frame and determines the path, or trajectory, of each object image through multiple frames of a video segment. In a preferred embodiment, face objects and text objects are used for identifying distinguishing object trajectories. A combination of face, text, and other trajectory information is used in a preferred embodiment of this invention to classify each segment of a video sequence. In one embodiment, a hierarchical information structure is utilized to enhance the classification process. At the upper, video, information layer, the parameters used for the classification process include, for example, the number of object trajectories of each type within the segment, an average duration for each object type trajectory, and so on. At the lowest, model, information layer, the parameters include, for example, the type, color, and size of the object image corresponding to each object trajectory. In an alternative embodiment, a Hidden Markov Model (HMM) technique is used to classify each segment into one of a predefined set of classifications, based on the observed characterization of the object trajectories contained within the segment.",G06F 17/30; G06K 9/00,KONINKLIJKE PHILIPS ELECTRONICS N.V.,"DIMITROVA, Nevenka; AGNIHOTRI, Lalitha; WEI, Gang","09/452,581 01.12.1999 US",EP-2000990604; JP-2001542046
WO2018132718,PCT/US2018/013586,12.01.2018,WO/2018/132718,19.07.2018,WO,METHODS AND APPARATUS FOR MATRIX PROCESSING IN A CONVOLUTIONAL NEURAL NETWORK,"Described examples include an integrated circuit including a vector multiply unit (314) including multiply/accumulate nodes. The vector multiply unit (314) is operable to provide an output from the multiply/accumulate nodes. Also, the integrated circuit includes a first data feeder (312) to provide first data to the vector multiply unit in vector format, and a second data feeder (310) to provide second data to the vector multiply unit in vector format.",G06N 3/02; G06F 17/16; G06T 1/40,TEXAS INSTRUMENTS INCORPORATED; TEXAS INSTRUMENTS JAPAN LIMITED,"MODY, Mihir, Narendra; JAGANNATHAN, Shyam; MATHEW, Manu; JONES, Jason, T.","62/445,493 12.01.2017 US; 15/784,588 16.10.2017 US",CN-201880014717.8
WO2002005135,PCT/US2001/020894,29.06.2001,WO/2002/005135,17.01.2002,WO,METHOD AND SYSTEM FOR INDEXING AND SEARCHING TIMED MEDIA INFORMATION BASED UPON RELEVANCE INTERVALS,"A method and system for searching and retrieving information from timed media files based upon relevance intervals. The method and system for searching and retrieving this information is based upon relevance intervals so that a portion of a timed media file is returned, which is selected specifically to be relevant to the given information representations, thereby eliminating the need for a manual determination of the relevance and avoiding missing relevant portions. The timed media includes streaming audio, streaming video, timed HTML, animations such as vector-based graphics, slide shows, other timed media, and combinations thereof.",G06F 17/30,"STREAMSAGE, INC.","SIBLEY, Tim, V.; MORTON, Michael, Scott","09/611,316 06.07.2000 US",RU-null; EP-2001950739
WO2017155602,PCT/US2017/012726,09.01.2017,WO/2017/155602,14.09.2017,WO,SYSTEMS AND METHODS FOR NORMALIZING AN IMAGE,"A method for normalizing an image by an electronic device is described. The method includes obtaining an image including a target object. The method also includes determining a set of windows of the image. The method further includes, for each window of the set of windows of the image, predicting parameters of an illumination normalization model adapted to the window using a first convolutional neural network (CNN), and applying the illumination normalization model to the window to produce a normalized window.",G06K 9/46; G06T 5/20; G06T 5/00,QUALCOMM INCORPORATED,"RAD, Mahdi; OBERWEGER, Markus; LEPETIT, Vincent","62/307,225 11.03.2016 US; 15/207,239 11.07.2016 US",EP-2017705712
WO2018163786,PCT/JP2018/005819,20.02.2018,WO/2018/163786,13.09.2018,WO,"TARGET SUBJECT ANALYSIS APPARATUS, TARGET SUBJECT ANALYSIS METHOD, LEARNING APPARATUS, AND LEARNING METHOD","A technique is provided that is able to increase recognition accuracy with respect to attributes of a target subject with a simple configuration. A target subject analysis apparatus according to an aspect of the present invention includes: a data acquisition unit configured to acquire image data that represents an image including a figure of a target subject, and range data that represents a value of a distance at each pixel constituting the image; a neural network computing unit configured to obtain an output value from a trained neural network for determining an attribute of the target subject, by performing computation processing with the neural network using the image data and the range data that are acquired as input to the neural network; and an attribute specifying unit configured to specify the attribute of the target subject based on the output value obtained from the neural network.",G06K 9/00; G06K 9/46,OMRON CORPORATION,"ANDO, Tanichi",2017-042661 07.03.2017 JP,
WO2011120211,PCT/CN2010/071378,29.03.2010,WO/2011/120211,06.10.2011,WO,METHOD AND APPARATUS FOR SEEDED USER INTEREST MODELING,"Methods and apparatuses are provided for user interest modeling. A method may include receiving an input from a user for specifying one or more topics from among a predetermined hierarchy of topics and subtopics. The method may additionally include retrieving one or more documents associated with the user and extracting language tokens from the documents based, at least in part, on the specified topics. Corresponding apparatuses are also provided.",G06F 17/30,"NOKIA CORPORATION; SATHISH, Sailesh; TIAN, Jilei; HU, Rile","SATHISH, Sailesh; TIAN, Jilei; HU, Rile",,EP-2010848672; US-13637001; IN-9157/CHENP/2012
WO2018124620,PCT/KR2017/015178,21.12.2017,WO/2018/124620,05.07.2018,WO,METHOD AND DEVICE FOR TRANSMITTING AND RECEIVING AUDIO DATA,"An artificial intelligence (AI) system configured to simulate functions of a human brain, such as recognition, determination, etc., by using a machine learning algorithm, such as deep learning, etc., and an application thereof. The AI system includes a method performed by a device to transmit and receive audio data to and from another device includes obtaining a voice input that is input by a first user of the device, obtaining recognition information indicating a meaning of the obtained voice input, transmitting the obtained voice input to the other device, determining whether an abnormal situation occurs, in which a second user of the other device does not understand the transmitted voice input, and transmitting the obtained recognition information to the other device, based on a result of the determination.",G10L 15/18; G10L 15/26; G10L 15/06; G10L 17/22,"SAMSUNG ELECTRONICS CO., LTD.","KIM, Jae-deok; PARK, Mee-jeong",10-2016-0179317 26.12.2016 KR; 10-2017-0148328 08.11.2017 KR,EP-2017887809; CN-201780084788.0
WO2020047854,PCT/CN2018/104651,07.09.2018,WO/2020/047854,12.03.2020,WO,DETECTING OBJECTS IN VIDEO FRAMES USING SIMILARITY DETECTORS,An example apparatus for detecting objects in video frames includes a receiver to receive a plurality of video frames from a video camera. The apparatus also includes a first still image object detector to receive a first frame of the plurality of video frames and calculate localization information and confidence information for each potential object patch in the first frame. The apparatus further includes a second still image object detector to receive an adjacent frame of the plurality of video frames adjacent to the first frame and calculate localization information and confidence information for each potential object patch in the adjacent frame. The apparatus includes a similarity detector trained to detect paired patches between the first frame and the adjacent frame based on a comparison of the detected potential object patches. The apparatus further includes an enhancer to modify a prediction result for a paired patch in the adjacent frame to a prediction result of a corresponding paired patch in the first frame including a higher confidence score than the prediction result of the paired patch in the adjacent frame.,G06K 9/00,"INTEL CORPORATION; YU, Kun; CHEN, Ciyong; GUO, Xiaotian; HAO, Yan; LI, Hui; LI, Lu; PEI, Jianguo; ZHU, Zhi Yong","YU, Kun; CHEN, Ciyong; GUO, Xiaotian; HAO, Yan; LI, Hui; LI, Lu; PEI, Jianguo; ZHU, Zhi Yong",,
EP249227639,18152378,18.01.2018,3514733,24.07.2019,EP,A DEVICE AND A METHOD FOR IMAGE CLASSIFICATION USING A CONVOLUTIONAL NEURAL NETWORK,"A device for image classification comprising a convolutional neural network, wherein the device is configured to receive an image captured by a camera, the image comprising a plurality of pixels, the convolutional neural network is configured to generate a plurality of probability values, each probability value being linked to a respective one of a plurality of predetermined classes and indicating the probability that the image or a pixel of the image is associated with the respective class, and the convolutional neural network comprises a plurality of convolutional blocks and each of the convolutional blocks comprises: a first convolutional layer configured to perform a pointwise convolution using a first kernel, a second convolutional layer configured to perform a depthwise convolution using a second kernel, wherein the second kernel has one of a single row and a single column, a third convolutional layer configured to perform a depthwise convolution using a third kernel, wherein the third kernel has a single column if the second kernel has a single row, and the third kernel has a single row if the second kernel has a single column, and a fourth convolutional layer configured to perform a convolution using a fourth kernel.",G06N 3/04,APTIV TECH LIMITED,FREEMAN IDO; ROESE-KOERNER LUTZ,18152378 18.01.2018 EP,
WO2017201647,PCT/CN2016/082980,23.05.2016,WO/2017/201647,30.11.2017,WO,RELEVANT PASSAGE RETRIEVAL SYSTEM,"A new architecture is provided to support a precise information retrieval system on a web scale. The architecture provides algorithms to generate candidates and select the top N results via ranking models (e.g., Semantic ranking models, Aggregation ranking models) to capture term relationships between query and result contents at search-time.",G06F 17/30,"MICROSOFT TECHNOLOGY LICENSING, LLC","BAI, Jing; LIU, Yue-Sheng; PEDERSEN, Jan O.; YANG, Mao; LU, Qi",,EP-2016902637; CN-201680086072.X
WO2019183269,PCT/US2019/023241,20.03.2019,WO/2019/183269,26.09.2019,WO,BEST IMAGE GRAB FROM VIDEO WITH DIGITAL GRID ASSISTANCE FOR AVIATION ENGINE BORESCOPE INSPECTION,"Systems, computer-implemented methods and/or computer program products that facilitate aviation engine inspection are provided. In one embodiment, a computer-implemented method comprises: generating, by a system operatively coupled to a processor, a digital grid and visual layer overlay on a raw video feed from borescope inspections; analyzing, by the system, the video feed and identifying frames that capture information of part damage and defects; and classifying, by the system, type of part defect, determining location of defect and learning the digital grid.",G06K 9/62; G01N 21/954; G06K 9/00; G06T 7/00; B64F 5/60; F01D 5/00,GENERAL ELECTRIC COMPANY,"PATHAK, Karunamay; KHAN, Mohsin; BHAKTA, Aditya; ROBIN, Rebinth","15/933,095 22.03.2018 US",
WO2017007742,PCT/US2016/040925,05.07.2016,WO/2017/007742,12.01.2017,WO,TRANSFER LEARNING TECHNIQUES FOR DISPARATE LABEL SETS,"Examples of the present disclosure describe systems and methods of transfer learning techniques for disparate label sets. In aspects, a data set may be accessed on a server device. The data set may comprise labels and word sets associated with the labels. The server device may induce label embedding within the data set. The embedded labels may be represented by multi-dimensional vectors that correspond to particular labels. The vectors may be used to construct label mappings for the data set. The label mappings may be used to train a model to perform domain adaptation or transfer learning techniques. The model may be used to provide results to a statement/query or to train a different model.",G06N 99/00; G10L 15/18,"MICROSOFT TECHNOLOGY LICENSING, LLC","KIM, Young-Bum; SARIKAYA, Ruhi","14/792,269 06.07.2015 US",EP-2016742099
WO2003079287,PCT/US2003/007325,11.03.2003,WO/2003/079287,25.09.2003,WO,A PHYSICAL NEURAL NETWORK DESIGN INCORPORATING NANOTECHNOLOGY,"A physical neural network based on nanotechnology, including methods thereof. Such a physical neural network generally includes one or more neuron-like nodes (1100), which can be formed from a plurality of interconnected nanoconnections (1104) formed from nanoconductors. Each neuron-like node (1100) sums one or more input signals and generates one or more output signals based on a threshold (1112) associated with the input signal. The physical neural network also includes a connection network formed from the interconnected nanoconnections (1104), such that the interconnected nanoconnections (1104) used thereof by one or more of the neuron-like nodes (1100) are strengthened or weakened according to an application of an electric field.",G06N 3/063,"NUGENT, Alex","NUGENT, Alex","10/095,273 12.03.2002 US",EP-2003711511; JP-null
WO2019213297,PCT/US2019/030249,01.05.2019,WO/2019/213297,07.11.2019,WO,METHOD AND SYSTEM FOR AUTOMATED VEHICLE CHARGING,"A method for facilitating automated vehicle charging, which can include one or more of: detecting a charge port cover, determining a cover actuation point, opening the cover, locating a charging connector of the vehicle, locating electrical pins of the charging connector, connecting to the vehicle, and/ or disconnecting from the vehicle. A system for facilitating automated vehicle charging, which can include one or more connectors, sensors, and/or actuators. The system is preferably configured to perform the method (e.g., in the presence of an electric vehicle).",B60L 53/00; B60L 53/10; B60L 53/16; B60L 53/35; B60L 53/37; G06K 9/32; G06K 9/62,STABLE AUTO CORPORATION,"SINHA, Shantanu; SCHIEL, James; PURI, Rohan","62/665,970 02.05.2018 US; 62/666,581 03.05.2018 US",
WO2018042232,PCT/IB2016/055288,02.09.2016,WO/2018/042232,08.03.2018,WO,METHOD AND APPARATUS FOR PROVIDING COGNITIVE FUNCTIONS AND FACILITATING MANAGEMENT IN COGNITIVE NETWORK MANAGEMENT SYSTEMS,"Various methods are provided for enabling the application of machine learning to network management and in particular to enabling cognitive network management in radio access networks. One example method may comprise interpreting one or more operator goals for the CNM or for a specific CF to ensure that the specific CF adjusts its behavior in order to fulfil the operator goals, abstracting an environment into states configured for use in subsequent decision making, wherein the abstracted environment represent are built from one or more of a combination of quantitative KPIs, abstract state labels, and operational contexts, defining legal candidate network configurations for different contexts of the CF based on the abstracted environments and operational contexts as inferred by the EMA engine, and matching a current abstract state, abstracted environment, or operational context as derived by the EMA engine to an appropriate network configuration selected from the set of legal candidate network configurations.",H04L 12/24; H04W 84/18,NOKIA TECHNOLOGIES OY; NOKIA USA INC.,"MWANJE, Stephen; MANNWEILER, Christian; SCHMELZ, Lars Christoph",,EP-2016767022; CN-201680090617.4; JP-2019512206; KR-1020197009522
WO2016139183,PCT/EP2016/054249,29.02.2016,WO/2016/139183,09.09.2016,WO,COMPUTERIZED DEVICE AND METHOD FOR PROCESSING IMAGE DATA,"A computerized device (100) for processing image data (OCT, RID) is proposed. The computerized device (100) comprises a receiving unit (110) which is configured to receive optical coherence tomography data (OCT) of a of a tissue, in particular of a retina, a providing unit (120) which is configured to provide a convolutional neural network (CNN) for processing the optical coherence tomography data (OCT), and a processing unit (130) which is configured to process the received optical coherence tomography data (OCT) using the convolutional neural network (CNN) for identifying at least one certain object (IRC, SRF) in the tissue.",G06K 9/62; G06T 7/00,MEDIZINISCHE UNIVERSITÄT WIEN,"SCHLEGL, Thomas; VOGL, Wolf-Dieter; LANGS, Georg; WALDSTEIN, Sebastian; GERENDAS, Bianca; SCHMIDT-ERFURTH, Ursula",15157253.4 02.03.2015 EP,EP-2016706882; US-15554414
WO2018067613,PCT/US2017/054999,03.10.2017,WO/2018/067613,12.04.2018,WO,TOUCH-SENSING SYSTEM,"A method for a touch sensing system includes generating, by a first pair of electrodes at a first location in a conductive material, an electric field in the conductive material; generating measurement data by measuring, by one or more second pairs of electrodes, the electric field in the conductive material at one or more second locations in the conductive material, with each of the one or more second locations differing from the first location; generating, based on the measurement data, an approximation of the electric field in the conductive material; and classifying, based on the approximation, one or more regions of the interface into a given state.",B25J 9/16; G08B 21/00; H04B 7/00,CARNEGIE MELLON UNIVERSITY,"ZHANG, Yang; LAPUT, Gierad; HARRISON, Christopher","62/496,072 03.10.2016 US",CN-201780074894.0; EP-2017859053
WO2019122953,PCT/IB2017/058086,18.12.2017,WO/2019/122953,27.06.2019,WO,METHOD AND SYSTEM FOR SELF CAPABILITY AWARE ROUTE PLANNING IN AUTONOMOUS DRIVING VEHICLES,"The present teaching relates to method, system, medium, and implementation of route planning for an autonomous driving vehicle. A source location and a destination location are first obtained, where the destination location is where the autonomous driving vehicle is to drive to. One or more available routes between the source location and the destination location are identified. A self-aware capability model is instantiated with respect to the one or more available routes and is predictive of the operational capability of the autonomous driving vehicle with respect to each of the one or more available routes. Based on the self-aware capability model, a planned route to the destination location is then automatically selected for the autonomous driving vehicle.",B60W 40/09; B60W 40/02; B60W 40/06; B60W 40/12; G05D 1/02; B60L 15/38; G06N 5/04; G01C 21/04,PLUSAI CORP,"GANGULI, Anurag; DALY, JR., Timothy Patrick; ZHENG, Hao; LIU, David Wanqian",,
WO2020064990,PCT/EP2019/076148,27.09.2019,WO/2020/064990,02.04.2020,WO,COMMITTED INFORMATION RATE VARIATIONAL AUTOENCODERS,"A variational autoencoder (VAE) neural network system, comprising an encoder neural network to encode an input data item to define a posterior distribution for a set of latent variables, and a decoder neural network to generate an output data item representing values of a set of latent variables sampled from the posterior distribution. The system is configured for training with an objective function including a term dependent on a difference between the posterior distribution and a prior distribution. The prior and posterior distributions are arranged so that they cannot be matched to one another. The VAE system may be used for compressing and decompressing data.",G06N 3/04; G06N 3/00; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"POOLE, Benjamin; VAN DEN OORD, Aäron Gerard Antonius; RAZAVI-NEMATOLLAHI, Ali; VINYALS, Oriol","62/737,845 27.09.2018 US",
WO2019070763,PCT/US2018/054028,02.10.2018,WO/2019/070763,11.04.2019,WO,CAREGIVER MEDIATED MACHINE LEARNING TRAINING SYSTEM,"A system for monitoring people's activity and/or health while at the same time preserving their privacy. Monitoring is accomplished by detecting state of people's electronic devices, e.g., a smart phone. The relationships between users are optionally maintained in a social network. Privacy is protected by reporting only deviations from use according to rules set by the person being monitored. Optionally an activity monitoring system receives data from multiple sources such as a home security system, IoT devices and a smartphone. The use of multiple data sources provides an improved activity monitoring system capable of distinguishing activity that may be indicative of a physical or mental health condition. Variations in the monitored activity are used to identify potential health issues for the user. A human augmented positive feedback loop is used to generate data for training of machine learning systems.",A61B 5/103; G16H 20/10,"NEW SUN TECHNOLOGIES, INC.","VIKLUND, Sophia; SNOWDALL, Clark; COLBY, Steven; KAEHLER, Adrian","62/566,935 02.10.2017 US; 62/629,697 13.02.2018 US; 62/685,872 15.06.2018 US; 62/738,390 28.09.2018 US",
WO2000060539,PCT/EP2000/002585,21.03.2000,WO/2000/060539,12.10.2000,WO,METHOD FOR OPTIMIZING A LINE OF PICK AND PLACE MACHINES,"A genetic algorithm is used to balance a line of pick and place machines. The genetic algorithm uses a modularized chromosome string having at least three parts indicating 1) a division of parts between the pick and place machines, 2) a layout of a first pick and place machine, and 3) a layout of a second pick and place machine, respectively. A heuristic layout generator cycles with the genetic algorithm to create simulated layouts from populations of chromosome strings produced by the genetic algorithm. The heuristic layout generator is also modularized, having separate modules corresponding to the three parts of the chromosome string.",G06N 3/12; H05K 13/08,KONINKLIJKE PHILIPS ELECTRONICS N.V.,"ESHELMAN, Larry, J.; SCHAFFER, James, D.","09/286,026 05.04.1999 US",EP-2000914165
EP14295098,03022420,07.10.2003,1522958,13.04.2005,EP,Determining parameters of a sample by X-ray scattering applying an extended genetic algorithm with truncated use of the mutation operator,"A method of determining parameters of a sample by X-ray scattering comprising the steps of  a) exposing the sample to X-rays and measuring scattered X-ray intensity; b) generating a parameterised model of the sample which is used for numerical simulation of scattered X-ray intensity on the basis of a physical scattering theory; c) comparing the experimental and simulated X-ray scattering data to generate an error value; d) modifying the parameters of the model by means of a genetic algorithm involving an amount of individuals each with an equal number N of encoded parameters forming a generation and applying the genetic operators of ""selection"", ""crossover"" and ""mutation"" used for composing successive generations of evolving individuals,  is characterised in that after a given number k of successive generations the genetic operator of ""mutation"" is no longer applied in evolution of further generations. The inventive method improves the genetic algorithm such that it can approximate the true sample parameters faster and with a higher accuracy. <IMAGE>",G06N 3/12; G01N 23/20,BRUKER AXS GMBH,ULYANENKOV ALEX; SOBOLEWSKI STANISLAW,03022420 07.10.2003 EP,
WO2010045272,PCT/US2009/060567,13.10.2009,WO/2010/045272,22.04.2010,WO,SMOOTHED SARSA: REINFORCEMENT LEARNING FOR ROBOT DELIVERY TASKS,"The present invention provides a method for learning a policy used by a computing system to perform a task, such delivery of one or more objects by the computing system. During a first time interval, the computing system determines a first state, a first action and a first reward value. As the computing system determines different states, actions and reward values during subsequent time intervals, a state description identifying the current sate, the current action, the current reward and a predicted action is stored. Responsive to a variance of a stored state description falling below a threshold value, the stored state description is used to modify one or more weights in the policy associated with the first state.",G06F 15/18,"HONDA MOTOR CO., LTD.; GUPTA, Rakesh; RAMACHANDRAN, Deepak","GUPTA, Rakesh; RAMACHANDRAN, Deepak","61/196,040 14.10.2008 US",
WO1996017307,PCT/US1995/015245,27.11.1995,WO/1996/017307,06.06.1996,WO,NEURAL NETWORK BINARY CODE RECOGNIZER,"A neural network binary code recognizer (100) for decoding n-bit binary code words comprises a device for inputting n signals into recognizer (100), each of the n signals representing a bit value of n-bit binary code word. A number n amplifiers (111a, 111b, 112a and 112b), each having an input for receiving a respective input signal. Additionally connected at each amplifier output is a storage device for storing one or more bit values of one or more corresponding predetermined valid n-bit binary code words. An approximated image product comprising the product of an output signal from each amplifier. Each approximated image product is fedback to an input of each amplifier in accordance with a bit value of one or more predetermined valid n-bit code words.",G06N 3/04,GRUMMAN CORPORATION,"ENGEL, Stephen, J.; JEFFRIES, Clark","08/348,564 02.12.1994 US",EP-1995940813
WO2016075081,PCT/EP2015/076073,09.11.2015,WO/2016/075081,19.05.2016,WO,SYSTEM AND METHOD FOR TOY RECOGNITION,"System and method for automatic computer aided optical recognition of toys, for example, construction toy elements, recognition of those elements on digital images and associating the elements with existing information is presented. The method and system may recognize toy elements of various sizes invariant of toy element distance from the image acquiring device for example camera, invariant of rotation of the toy element, invariant of angle of the camera, invariant of background, invariant of illumination and without the need of predefined region where a toy element should be placed. The system and method may detect more than one toy element on the image and identify them. The system is configured to learn to recognize and detect any number of various toy elements by training a deep convolutional neural network.",A63F 13/65; G06K 9/00,LEGO A/S,"VELIC, Marko; NOE, Karsten Østergaard; MOSEGAARD, Jesper; RIMESTAD, Jens; CHRISTENSEN, Brian Bunch",1419928.5 10.11.2014 GB,US-15524944
WO2019094236,PCT/US2018/058387,31.10.2018,WO/2019/094236,16.05.2019,WO,REDUNDANT POSE GENERATION SYSTEM,"Techniques for performing multiple simultaneous pose generation for an autonomous vehicle. For instance, a system that navigates the autonomous vehicle can include at least a first component that determines first poses for the autonomous vehicle using at least a first portion of sensor data captured by one or more sensors and a second component that determines second poses for the autonomous vehicle using at least a second portion of the sensor data. The first component may have more computational resources than the second component and determine poses at a different frequency than the second component. The system may generate trajectories for the autonomous vehicle using the first poses when the first component is operating correctly. Additionally, the system may generate trajectories for the autonomous vehicle using the second poses when the first component is not operating correctly.",G05D 1/00; B60W 30/00; G01C 21/00,"ZOOX, INC.","HAMMOND, Marcus; KENTLEY-KLAY, Timothy, David","15/806,001 07.11.2017 US",
WO2019226324,PCT/US2019/030988,07.05.2019,WO/2019/226324,28.11.2019,WO,HIGHLY PERFORMANT PIPELINE PARALLEL DEEP NEURAL NETWORK TRAINING,"Layers of a deep neural network (DNN) are partitioned into stages using a profile of the DNN. Each of the stages includes one or more of the layers of the DNN. The partitioning of the layers of the DNN into stages is optimized in various ways including optimizing the partitioning to minimize training time, to minimize data communication between worker computing devices used to train the DNN, or to ensure that the worker computing devices perform an approximately equal amount of the processing for training the DNN. The stages are assigned to the worker computing devices. The worker computing devices process batches of training data using a scheduling policy that causes the workers to alternate between forward processing of the batches of the DNN training data and backward processing of the batches of the DNN training data. The stages can be configured for model parallel processing or data parallel processing.",G06N 3/063; G06N 3/08,"MICROSOFT TECHNOLOGY LICENSING, LLC","SESHADRI, Vivek; PHANISHAYEE, Amar; NARAYANAN, Deepak; HARLAP, Aaron; RANGARAJAN, Nikhil Devanur","62/675,497 23.05.2018 US; 16/024,369 29.06.2018 US",
WO2016139659,PCT/IL2016/050229,29.02.2016,WO/2016/139659,09.09.2016,WO,"DIAGNOSIS OF SYSTEMIC LUPUS ERYTHEMATOSUS USING PROTEIN, PEPTIDE AND OLIGONUCLEOTIDE ANTIGENS","Methods and kits for diagnosing or monitoring systemic lupus erythematosus (SLE) in a subject are provided. Particularly, the present invention relates to a specific antibody reactivity profile useful in diagnosing or monitoring SLE in a subject.",G01N 33/564; G01N 33/68; G06F 19/20; G06F 19/24,IMMUNARRAY LTD.,"SOREK, Rachel; JAKOBI, Keren; SAFER, Pennina; REINER-BENAIM, Anat","62/126,616 01.03.2015 US; 62/181,231 18.06.2015 US; 62/249,284 01.11.2015 US",EP-2016758553; IL-254227; US-15555258
WO2013170129,PCT/US2013/040516,10.05.2013,WO/2013/170129,14.11.2013,WO,"A SYSTEM AND METHOD FOR AUTOMATICALLY DISCOVERING, CHARACTERIZING, CLASSIFYING AND SEMI-AUTOMATICALLY LABELING ANIMAL BEHAVIOR AND QUANTITATIVE PHENOTYPING OF BEHAVIORS IN ANIMALS","A method for studying the behavior of an animal in an experimental area including stimulating the animal using a stimulus device; collecting data from the animal using a data collection device; analyzing the collected data; and developing a quantitative behavioral primitive from the analyzed data. A system for studying the behavior of an animal in an experimental area including a stimulus device for stimulating the animal; a data collection device for collecting data from the animal; a device for analyzing the collected data; and a device for developing a quantitative behavioral primitive from the analyzed data. A computer implemented method, a computer system and a nontransitory computer readable storage medium related to the same. Also, a method and apparatus for automatically discovering, characterizing and classifying the behavior of an animal in an experimental area. Further, use of a depth camera and/or a touch sensitive device related to the same.",A01K 67/027; G06F 19/00; C12N 15/12,PRESIDENT AND FELLOWS OF HARVARD COLLEGE,"DATTA, Sandeep Robert; WILTSCHKO, Alexander B.","61/645,172 10.05.2012 US; 61/791,836 15.03.2013 US",CA-2873218; EP-2013788526
WO2016171534,PCT/KR2016/006366,15.06.2016,WO/2016/171534,27.10.2016,WO,METHOD FOR TRACKING CONTENT AND ELECTRONIC DEVICE USING THE SAME,"An apparatus and method for tracking content are provided. The apparatus is an electronic device that includes a communication circuit and a processor electrically connected to the communication circuit. The processor may be configured to receive information about a tracking target item from an external electronic device, to receive content from a content provider, determine a degree of semantic similarity between the tracking target item and the content, generate at least one update related to the tracking target item, based on the degree of semantic similarity, and send the at least one update to the external electronic device.",G06Q 50/10; G06F 9/445; G06F 9/44,"SAMSUNG ELECTRONICS CO., LTD.","SATHISH, Sailesh Kumar; PRAMANIK, Chandan; SONI, Sandeep Kumar; VENKATARAMANA, Balaji Nerella",2076/CHE/2015 22.04.2015 IN; 2076/CHE/2015 18.01.2016 IN,
WO2015130928,PCT/US2015/017745,26.02.2015,WO/2015/130928,03.09.2015,WO,"REAL ESTATE EVALUATING PLATFORM METHODS, APPARATUSES, AND MEDIA","A unit type selection may be obtained and a training data set may be determined based on the unit type. A plurality of real estate value estimating neural networks may be trained using the training data set. A testing data set may be determined based on the unit type and the plurality of real estate value estimating neural networks may be tested on the testing data set. Based on the testing, a subset of the best performing neural networks may be selected to create a set of real estate value estimating neural networks. Each neural network in the set of real estate value estimating neural networks may be retrained on the worst performing subset of the training data set for the respective neural network.",G06N 3/02; G06Q 50/16,"NANCY PACKES, INC.","PACKES, Nancy; MANVIEU, Emilien, Benoit; TALOS, Florin","61/944,604 26.02.2014 US",
EP161833453,14803624,30.07.2014,3005280,13.04.2016,EP,PORTABLE COMPUTING DEVICE AND ANALYSES OF PERSONAL DATA CAPTURED THEREFROM,"A personal computing device comprising: a processor, an onboard memory, an accelerometer, a gyroscope, and a display; a computer program to create an exercise analysis application comprising: a software module configured to receive data from the accelerometer and the gyroscope that are associated with the bodily motion of a user in three dimensions; a software module configured to place the device in a learning mode, the learning mode comprising recording the data of the user performing a defined exercise to generate a statistical model for the exercise; a software module configured to place the device in a normal mode, the normal mode comprising applying a probabilistic analysis to the bodily motion data to identify an exercise event, classify the exercise by comparison to a recorded model; and a software module configured to apply an analysis to the bodily motion data to score the user's exercise form.",G16H 20/30; A63B 21/06; A63B 71/06; G06K 9/00; G09B 19/00,ATLAS WEARABLES INC,LAKE THOMAS LEE II; KASPARIAN MICHAEL; LI PETER,201361828680 30.05.2013 US; 2014048972 30.07.2014 US,
WO2016118815,PCT/US2016/014445,22.01.2016,WO/2016/118815,28.07.2016,WO,"MACHINE LEARNING HETEROGENEOUS EDGE DEVICE, METHOD, AND SYSTEM","A machine learning heterogeneous edge device, method, and system are disclosed. In an example embodiment, an edge device includes a communication module, a data collection device, a memory, a machine learning module, a group determination module, and a leader election module. The edge device analyzes collected data with a model, outputs a result, and updates the model to create a local model. The edge device communicates with other edge devices in a heterogeneous group. The edge device determines group membership and determines a leader edge device. The edge device receives a request for the local model, transmits the local model to the leader edge device, receives a mixed model created by the leader edge device performing a mix operation of the local model and a different local model, and replaces the local model with the mixed model.",G06F 15/18,"PREFERRED NETWORKS, INC.; CLAYTON, Justin, B.","CLAYTON, Justin, B.; OKANOHARA, Daisuke; NISHIKAWA, Toru; HIDO, Shohei; KUBOTA, Nobuyuki; OTA, Nobuyuki; TOKUI, Seiya","14/602,867 22.01.2015 US",JP-2017538722
EP291472894,18861574,29.09.2018,3627499,25.03.2020,EP,IMAGE PROCESSING APPARATUS AND METHOD,"The present disclosure discloses an image processing device including: a receiving module configured to receive a voice signal and an image to be processed; a conversion module configured to convert the voice signal into an image processing instruction and a target area according to a target voice instruction conversion model, in which the target area is a processing area of the image to be processed; and a processing module configured to process the target area according to the image processing instruction and a target image processing model. The examples may realize a functionality of inputting voice to process images, which may save users' time spent in learning image processing software prior to image processing, and improve user experience.",G10L 15/183; G06N 3/08; G06T 7/11; G10L 15/22,SHANGHAI CAMBRICON INFORMATION TECH CO LTD,CHEN TIANSHI; HU SHUAI; CHEN XIAOBING,201710913131 29.09.2017 CN; 201710913272 29.09.2017 CN; 201711121244 14.11.2017 CN; 2018108696 29.09.2018 CN,
WO2018084948,PCT/US2017/052545,20.09.2017,WO/2018/084948,11.05.2018,WO,ENHANCED SIAMESE TRACKERS,"In one configuration, a visual object tracking apparatus is provided that receives a position of an object in a first frame of a video, and determines a current position of the object in subsequent frames of the video using a Siamese neural network. To facilitate determining the current position of the object, the apparatus may adjust a spatial resolution of an image, adjust a size of a probe region, and/or adjust a scale of a plurality of sampled images. In one configuration, a visual object tracking using a Siamese neural network is provided. The apparatus feeds outputs from a plurality of subnetworks of the Siamese neural network to a comparison layer. In addition, the apparatus compares, at the comparison layer, inputs from the plurality of subnetworks to generate a comparison result. Further, the apparatus combines comparison results based on weights to obtain a final comparison result.",G06N 3/04,QUALCOMM INCORPORATED,"TAO, Ran; GAVVES, Efstratios; SMEULDERS, Arnold Wilhelmus Maria","62/418,704 07.11.2016 US; 15/621,741 13.06.2017 US",
WO2002021423,PCT/US2001/041825,22.08.2001,WO/2002/021423,14.03.2002,WO,METHOD AND SYSTEM FOR OBTAINING KNOWLEDGE BASED RECOMMENDATIONS,"A method and system for obtaining knowledge recommendations. A request with multiple input parameters is received for a desired outcome on a knowledge based decision engine. The knowledge based decision engine includes knowledge derived from one or more input sources processed by a number of pre-determined knowledge creation techniques. An output is generated from the knowledge based decision engine using selected ones from a set of iterative techniques used to process the knowledge into fused knowledge. If the output is appropriate for the desired outcome, a desired outcome with multiple output parameters is created. The method and system are used to select or predict real or virtual drug compounds in a specific domain with the desired features including, absorption, pharmacokinetics, metabolism, toxicity, clinical decision support, etc",G06N 5/02,"CELLOMICS, INC.; COLLINS, Mark, A., D.; SHAW, John, R.; COLASANTI, Ricardo, L.","COLLINS, Mark, A., D.; SHAW, John, R.; COLASANTI, Ricardo, L.","09/655,677 06.09.2000 US",
WO2017105724,PCT/US2016/062028,15.11.2016,WO/2017/105724,22.06.2017,WO,GENERATION OF SYNTHETIC 3-DIMENSIONAL OBJECT IMAGES FOR RECOGNITION SYSTEMS,"Techniques are provided for generation of synthetic 3-dimensional object image variations for training of recognition systems. An example system may include an image synthesizing circuit configured to synthesize a 3D image of the object (including color and depth image pairs) based on a 3D model. The system may also include a background scene generator circuit configured to generate a background for each of the rendered image variations. The system may further include an image pose adjustment circuit configured to adjust the orientation and translation of the object for each of the variations. The system may further include an illumination and visual effect adjustment circuit configured to adjust illumination of the object and the background for each of the variations, and to further adjust visual effects of the object and the background for each of the variations based on application of simulated camera parameters.",G06T 7/00,INTEL CORPORATION,"BLEIWEISS, Amit; PAZ, Chen; LEVY, Ofir; BEN-ARI, Itamar; YANAI, Yaron","14/969,563 15.12.2015 US",
WO2019055555,PCT/US2018/050737,12.09.2018,WO/2019/055555,21.03.2019,WO,FEW-SHOT LEARNING BASED IMAGE RECOGNITION OF WHOLE SLIDE IMAGE AT TISSUE LEVEL,"A computer implemented method of generating at least one shape of a region of interest in a digital image is provided. The method includes obtaining, by an image processing engine, access to a digital tissue image of a biological sample; tiling, by the image processing engine, the digital tissue image into a collection of image patches; obtaining, by the image processing engine, a plurality of features from each patch in the collection of image patches, the plurality of features defining a patch feature vector in a multidimensional feature space including the plurality of features as dimensions; determining, by the image processing engine, a user selection of a user selected subset of patches in the collection of image patches; classifying, by applying a trained classifier to patch vectors of other patches in the collection of patches, the other patches as belonging or not belonging to a same class of interest as the user selected subset of patches; and identifying one or more regions of interest based at least in part on the results of the classifying.",G06T 7/00; G06T 7/11,"NANTOMICS, LLC","SONG, Bing; JABER, Mustafa","62/557,737 12.09.2017 US",IL-272431; AU-2018332879; SG-11202000842S
WO2018194993,PCT/US2018/027834,16.04.2018,WO/2018/194993,25.10.2018,WO,POWER-EFFICIENT DEEP NEURAL NETWORK MODULE CONFIGURED FOR EXECUTING A LAYER DESCRIPTOR LIST,"A deep neural network (DNN) processor is configured to execute descriptors in layer descriptor lists. The descriptors define instructions for performing a pass of a DNN by the DNN processor. Several types of descriptors can be utilized: memory-to-memory move (M2M) descriptors; operation descriptors; host communication descriptors; configuration descriptors; branch descriptors; and synchronization descriptors. A DMA engine uses M2M descriptors to perform multi-dimensional strided DMA operations. Operation descriptors define the type of operation to be performed by neurons in the DNN processor and the activation function to be used by the neurons. M2M descriptors are buffered separately from operation descriptors and can be executed at soon as possible, subject to explicitly set dependencies. As a result, latency can be reduced and, consequently, neurons can complete their processing faster. The DNN module can then be powered down earlier than it otherwise would have, thereby saving power.",G06N 3/063,"MICROSOFT TECHNOLOGY LICENSING, LLC","AMBARDEKAR, Amol Ashok; CEDOLA, Kent D.; WALL, Larry Marvin; BOBROV, Boris; PETRE, George; MCBRIDE, Chad Balling","62/486,432 17.04.2017 US; 15/951,106 11.04.2018 US",CN-201880025508.3; EP-2018721665
WO2020064955,PCT/EP2019/076091,26.09.2019,WO/2020/064955,02.04.2020,WO,STRUCTURE ANNOTATION,"A method of annotating frames of a time sequence of frames captured by at least one travelling vehicle comprises, in a frame processing system: determining a three-dimensional (3D) road model for an area captured in the time sequence of frames; receiving first annotation data denoting a known 3D location of a moving object for a first frame of the time sequence of frames; and automatically generating second annotation data for marking an expected moving object location in at least a second frame of the time sequence of frames, by assuming the moving object moves along an expected path determined from the known 3D location and the 3D road model.",G06K 9/00; G06K 9/62,FIVE AI LIMITED,"WESTMACOTT, Thomas; JAKUBOVIC, Joel; REDFORD, John; CHANDLER, Robert",1815767.7 26.09.2018 GB; 1910382.9 19.07.2019 GB; 1910395.1 19.07.2019 GB; 1910390.2 19.07.2019 GB; 1910392.8 19.07.2019 GB,
WO2018213099,PCT/US2018/032110,10.05.2018,WO/2018/213099,22.11.2018,WO,METHOD AND APPARATUS FOR PROVIDING A MACHINE LEARNING APPROACH FOR A POINT-BASED MAP MATCHER,"An approach is provided for point-based map matchers using machine learning. The approach involves retrieving points collected within proximity to a map feature represented by a link of a geographic database. The probe points are collected from sensors of devices traveling near the map feature. The approach also involves determining a probe feature set for each probe point comprising probe attribute values, and determining a link feature set for the link comprising link attribute values. The apparatus further involves classifying, using a machine learning classifier, each probe point to determine a matching probability based on the probe feature set and the link feature to indicate a probability that each probe point is classified as map- matched to the link. The machine learning classifier is trained using ground truth data comprising reference probe points with known map-matches to respective reference links, and comprising known probe attribute values and known link attribute values.",G06F 15/18,HERE GLOBAL B.V.,"CHEN, Qin; BALLESTEROS, Jaime","15/597,999 17.05.2017 US",EP-2018802356
WO2017024254,PCT/US2016/045853,05.08.2016,WO/2017/024254,09.02.2017,WO,CUSTOMIZED LAND SURFACE MODELING FOR IRRIGATION DECISION SUPPORT IN A CROP AND AGRONOMIC ADVISORY SERVICE IN PRECISION AGRICULTURE,"An irrigation modeling framework in precision agriculture utilizes a combination of weather data, crop data, and other agricultural inputs to create customized agronomic models for diagnosing and predicting a moisture state in a field, and a corresponding need for, and timing of, irrigation activities. Specific combinations of various agricultural inputs can be applied, together with weather information to identify or adjust water-related characteristics of crops and soils, to model optimal irrigation activities and provide advisories, recommendations, and scheduling guidance for targeted application of artificial precipitation to address specific moisture conditions in a soil system of a field",G06N 5/04; G06N 99/00; G05D 7/00; G01N 33/00,"ITERIS, INC.","MEWES, John; HALE, Robert","62/201,117 05.08.2015 US",
WO2002059822,PCT/US2002/002243,24.01.2002,WO/2002/059822,01.08.2002,WO,METHODS OF IDENTIFYING PATTERNS IN BIOLOGICAL SYSTEMS AND USES THEREOF,"The methods, systems and devices of the present invention comprise use of Support Vector Machines and RFE (Recursive Feature Elimination) for the identification of patterns that are useful for medical diagnosis, prognosis and treatment. SVM-RFE can be used with varied data sets.",G06N 3/00; G06F 19/24; G06K 9/62; G06F 19/20,"BIOWULF TECHNOLOGIES, LLC; GUYON, Isabelle; WESTON, Jason","GUYON, Isabelle; WESTON, Jason","60/263,696 24.01.2001 US; 60/275,760 14.03.2001 US; 60/298,757 15.06.2001 US",EP-2002723072; AU-2002253879; CA-2435254; JP-2002560076
EP231575452,16870208,01.12.2016,3385889,10.10.2018,EP,"ABNORMALITY DETECTION SYSTEM, ABNORMALITY DETECTION METHOD, ABNORMALITY DETECTION PROGRAM, AND METHOD FOR GENERATING LEARNED MODEL","It is desired to realize a method or a system that efficiently selects sensors without requiring advanced expertise or extensive experience even in a case of new machines and unknown failures.  An abnormality detection system 1 includes a storage unit 10 for storing a latent variable model and a joint probability model, an acquisition unit 11 for acquiring sensor data that is output by a sensor, a measurement unit 12 for measuring the probability of the sensor data acquired by the acquisition unit 11 based on the latent variable model and the joint probability model stored by the storage unit 10, a determination unit 13 for determining whether the sensor data is normal or abnormal based on the probability of the sensor data measured by the measurement unit 12, and a learning unit 14 for learning the latent variable model and the joint probability model based on the sensor data output by the sensor.",G06N 7/00; G06F 11/07; G06N 3/04; G06N 3/08,PREFERRED NETWORKS INC,OKANOHARA DAISUKE; OONO KENTA,2015234923 01.12.2015 JP; 2016005043 01.12.2016 JP,
WO2000034000,PCT/US1999/027173,16.11.1999,WO/2000/034000,15.06.2000,WO,METHOD AND SYSTEM FOR DETERMINING WELD BEAD QUALITY,"A method for determining the quality of a weld bead (10) includes producing a weld bead (10) along a work surface (12) during a welding process and scanning the weld bead (10) with a scanner (14) to obtain positional data points for defining a weld bead profile (16). The weld bead (10) has a weld toe zone (18) or region, which is formed at the interface between the weld bead (10) and the work surface (12). A curve fit is determined for the weld bead profile (16) based on the positional data points obtained by the scanner (14). The weld toe radius (R) is derived based on the curve fit and is then compared to a first predetermined limit and a second predetermined limit, greater than the first predetermined limit, to determine the quality of the weld bead (10). If the weld toe radius (R) is less than the first predetermined limit or greater than the second predetermined limit, the welding process is modified to produce a weld bead (10) with a weld toe radius (R) that falls within the desired range. In one embodiment the weld toe radius (R) is determined from first and second derivations of a numerical relationship representative of the curve fit. In another embodiment the curve fit is compared to a plurality of curves to find a corresponding match and the weld toe radius (R) is determined from the matching curve.",B23K 9/095; B23K 31/12; B25J 9/16,"CATERPILLAR, INC.","LUDEWIG, Howard, W.; MCCLALLEN, Samuel, L.; VAROL, Ilhan","09/205,564 04.12.1998 US",JP-2000586481; MX-PA/a/2001/005548; EP-1999964995; CA-2348863
WO2019040436,PCT/US2018/047227,21.08.2018,WO/2019/040436,28.02.2019,WO,COMPUTING ARCHITECTURE FOR MULTIPLE SEARCH BOTS AND BEHAVIOR BOTS AND RELATED DEVICES AND METHODS,"The amount and variety of data being generated is becoming too extreme for many computing systems to process, and is even more difficult for information systems to provide relevant data to users. A distributed computing system is provided that includes server machines that form a data enablement platform. The platform includes: a plurality of data collectors that stream data over a message bus to a streaming analytics and machine learning engine; a data lake and a massive indexing repository for respectively storing and indexing data; a behavioral analytics and machine learning module; and multiple application programming interfaces (APIs) to interact with the data lake and the massive indexing repository, and to interact with multiple applications. The multiple applications are command cards, and each command card includes a directive module, a memory module, search bots, and behavior bots that operate at least within the data enablement platform.",G06F 17/30; G10L 15/18,"FACET LABS, LLC","OGAWA, Stuart; SPARKS, Lindsay; NISHIMURA, Koichi; SO, Wilfred P.","62/548,173 21.08.2017 US",
WO1991006911,PCT/US1990/006026,19.10.1990,WO/1991/006911,16.05.1991,WO,AUTOMATED CYTOLOGICAL SPECIMEN CLASSIFICATION SYSTEM AND METHOD,"An automated screening system (10) and method for cytological specimen classification in which plural classifiers (300, 320) in Figure 4 are utilized in performance of the classification function. Also included is an automated microscope (12) and associated image processing circuitry (20b).",G01N 15/14; G06K 9/00; G06N 3/02,"NEUROMEDICAL SYSTEMS, INC.","RUTENBERG, Mark, R.; KNAPP, James; HERRIMAN, James, M.; PORZIO, John; LUCK, Randall, L.; HALL, Thomas, L.; CHABAN, Richard; DULAK, Thomas; DOMES, Robert","425,665 23.10.1989 US",
WO2020012259,PCT/IB2019/053614,02.05.2019,WO/2020/012259,16.01.2020,WO,"SYSTEMS, DEVICES, AND METHODS FOR IN-FIELD DIAGNOSIS OF GROWTH STAGE AND CROP YIELD ESTIMATION IN A PLANT AREA","Methods, devices, and systems may be utilized for detecting one or more properties of a plant area and generating a map of the plant area indicating at least one property of the plant area. The system comprises an inspection system (104) associated with a transport device (106), the inspection system including one or more sensors configured to generate data for a plant area including to: capture at least 3D image data and 2D image data; and generate geolocational data. The datacenter (108) is configured to: receive the 3D image data, 2D image data, and geolocational data from the inspection system; correlate the 3D image data, 2D image data, and geolocational data; and analyze the data for the plant area. A dashboard (110) is configured to display a map (1050) with icons corresponding to the proper geolocation and image data with the analysis.",A01B 79/00; G06K 9/00; G06Q 50/02; G01N 21/00,ADROIT ROBOTICS,"GURZONI, JR., Jose Angelo; CORTEZ, JR., Milton Perez; AQUINO, JR., Plinio Thomas","16/031,801 10.07.2018 US",
EP163439021,15190927,22.10.2015,3016027,04.05.2016,EP,HUMAN BODY PART DETECTION SYSTEM AND HUMAN BODY PART DETECTION METHOD,"A human body part detection system includes: a learning mode storing unit storing a learning model; a depth image acquisition unit acquiring a depth image; a foreground human extraction unit extracting a human area; and a human body part detection unit detecting the human body part based on the human area and the learning model. The detection unit calculates a direction of a geodesic path at a first point based on a shortest geodesic path from a base point to a first point, selects a pixel pair at positions obtained after rotating positions of a pixel pair for calculation of the feature in the learning model in accordance with the direction, calculates a feature at the first point based on depth of the selected pair, and determines a label corresponding to the human body part based on the feature at the first point and learning model.",G06K 9/00; G06K 9/46; G06K 9/62,PANASONIC IP MAN CO LTD,ARATA KOJI; LASANG PONGSAK; SHEN SHENGMEI,2014221586 30.10.2014 JP,
WO2003087983,PCT/US2003/010468,14.04.2003,WO/2003/087983,23.10.2003,WO,MASSIVE TRAINING ARTIFICIAL NEURAL NETWORK (MTANN) FOR DETECTING ABNORMALITIES IN MEDICAL IMAGES,"A method of training an artificial neural network (ANN) involves receiving a likelihood distribution map as a teacher image, receiving a training image, moving a local window across sub-regions of the training image to obtain respective sub-region pixel sets, inputting the sub-region pixel sets to the ANN so that it provides output pixel values that are compared to output pixel values of corresponding teacher image pixel values to determine an error, and training the ANN to reduce the error. A method of detecting a target structure in an image involves scanning a local window across sub-regions of the image by moving the local window for each sub-region so as to obtain respective sub-region pixel sets, inputting the sub-region pixel sets to an ANN so that it provides respective output pixel values that represent likelihoods that respective image pixels are part of a target structure, the output pixel values collectively constituting a likelihood distribution map. Another method for detecting a target structure involves training N parallel ANNs on either (A) a same target structure and N mutually different non-target structures, or (B) a same non-target structure and N mutually different target structures, the ANNs outputting N respective indications of whether the image includes a target structure or a non-target structure, and combining the N indications to form a combined indication of whether the image includes a target structure or a non-target structure. The invention provides related apparatus and computer program products storing executable instructions to perform the methods.",G06T 7/00,"THE UNIVERSITY OF CHICAGO; SUZUKI, Kenji; DOI, Kunio","SUZUKI, Kenji; DOI, Kunio","10/120,420 12.04.2002 US",JP-null
EP249227641,18213652,18.12.2018,3514735,24.07.2019,EP,A DEVICE AND A METHOD FOR IMAGE CLASSIFICATION USING A CONVOLUTIONAL NEURAL NETWORK,"A device for image classification comprising a convolutional neural network, wherein the device is configured to receive an image captured by a camera, the image comprising a plurality of pixels, the convolutional neural network is configured to generate a plurality of probability values, each probability value being linked to a respective one of a plurality of predetermined classes and indicating the probability that the image or a pixel of the image is associated with the respective class, and the convolutional neural network comprises a plurality of convolutional blocks and each of the convolutional blocks comprises: a first convolutional layer configured to perform a pointwise convolution using a first kernel, a second convolutional layer configured to perform a depthwise convolution using a second kernel, wherein the second kernel has one of a single row and a single column, a third convolutional layer configured to perform a depthwise convolution using a third kernel, wherein the third kernel has a single column if the second kernel has a single row, and the third kernel has a single row if the second kernel has a single column, and a fourth convolutional layer configured to perform a convolution using a fourth kernel.",G06N 3/04,APTIV TECH LIMITED,FREEMAN IDO; PETIG CHRISTOF; CREMER PEET; ROESE-KOERNER LUTZ,18152378 18.01.2018 EP,
WO2018089221,PCT/US2017/059139,31.10.2017,WO/2018/089221,17.05.2018,WO,NEURAL NETWORK-BASED ACTION DETECTION,Various implementations of the subject matter described herein relate to a neural network-based action detection. There is provided an action detection scheme using a neural network. The action detection scheme can design and optimize the neural network model based on respective importance of different frames such that frames that are more important or discriminative for action recognition tend to be assigned with higher weights and frames that are less important or discriminative for action recognition tend to be assigned with lower weights.,G06K 9/00; G06K 9/46,"MICROSOFT TECHNOLOGY LICENSING, LLC","LAN, Cuiling; ZENG, Wenjun; SONG, Sijie; XING, Junliang",201610987537.0 09.11.2016 CN,EP-2017805321
EP12885427,97300185,14.01.1997,0786761,30.07.1997,EP,Method of speech recognition using decoded state sequences having constrained state likelihoods,"Embodiments of the invention include a speech recognition method and system for transmitting information including the receipt and decoding of speech information such as that modeled by hidden Markov models (HMMs). The state likelihoods of the modeled state sequences contained within the speech information are assigned penalties based on the difference between those state likelihoods and a maximum possible state likelihood. Once penalties have been assigned, the modified state sequence with the modified state likelihoods having the highest cumulative state likelihoods is used in further speech recognition processing. In this manner, state sequences having no extremely poor state likelihoods are favored over those having both extremely high and extremely poor state likelihoods. <IMAGE>",G10L 5/06; G10L 15/10; G10L 15/14,AT & T CORP,ZELJKOVIC ILIJA,59275196 26.01.1996 US,
EP248884919,17866051,26.10.2017,3511899,17.07.2019,EP,"IMAGE PROCESSING APPARATUS, IMAGE PROCESSING METHOD, AND COMPUTER-READABLE RECORDING MEDIUM",An image processing apparatus is disclosed. The present image processing apparatus comprises: an input unit to which an image is input; and a processor which extracts visual characteristics by reducing an input image and generates a high-definition image by reflecting extracted visual characteristics on the input image. The present disclosure relates to an artificial intelligence (AI) system and application thereof that simulate functions such as cognition and decision-making of a human brain using a machine learning algorithm such as deep learning.,G06T 3/40; G06T 5/50,SAMSUNG ELECTRONICS CO LTD,AHN IL-JUN; NAM WOO-HYUN; CHO KI-HEUM; PARK YONG-SUP; LEE TAMMY; CHEON MIN-SU,20160140237 26.10.2016 KR; 2017011932 26.10.2017 KR,
EP278936826,18787049,17.04.2018,3579152,11.12.2019,EP,COMPUTING APPARATUS AND RELATED PRODUCT,"The present application provides a computing apparatus and a related product. The computing apparatus is used for performing calculation of a network model; the network model comprises a neural network model and/or a non-neural network model; the computing apparatus comprises a computing unit, a controller unit, and a storage unit; the storage unit comprises a data input/output unit, a storage medium, and a scalar data storage unit. The technical solution provided by the present application provides a fast calculation speed and can save energy.",G06N 3/08,SHANGHAI CAMBRICON INFORMATION TECH CO LTD,CHEN TIANSHI; ZHUANG YIMIN; LIU DAOFU; CHEN XIAOBING; WANG ZAI; LIU SHAOLI,201710261742 20.04.2017 CN; 201710279655 25.04.2017 CN; 201710279834 25.04.2017 CN; 2018083379 17.04.2018 CN,
WO2019241145,PCT/US2019/036368,10.06.2019,WO/2019/241145,19.12.2019,WO,ARTIFICIAL INTELLIGENCE APPLICATIONS FOR COMPUTER-AIDED DISPATCH SYSTEMS,"Exemplary embodiments of the present invention provide a virtual dispatch assist system in which various types of Intelligent Agents are deployed (e.g., as part of a new CAD system architecture or as add-ons to existing CAD systems) to analyze vast amounts of historic operational data and provide various types of dispatch assist notifications and recommendations that can be used by a dispatcher or by the CAD system itself (e.g., autonomously) to make dispatch decisions.",G06N 5/04; G06N 3/00; G06N 3/08; G06N 7/00,INTERGRAPH CORPORATION,"WILLIAMS, Jackie, Paul; COLE, Michael, Thomas; DEBONI, Jose Eduardo, Zindel","62/683,754 12.06.2018 US",
WO2018165443,PCT/US2018/021574,08.03.2018,WO/2018/165443,13.09.2018,WO,SENSORS AND A METHOD FOR EVALUATION OF CHARACTERISTICS OF HUMAN JOINTS AND FOR DIAGNOSIS OF JOINT AILMENTS,"A method of conducting a procedure for a diagnosis of a portion of a patient's human musculoskeletal system, the method comprising a remediation recommendation method comprising the steps of: obtaining patient demographics, applying sensors above and below the joint, and then taking an image of the joint using a mobile device. Next, analyzing the image to determine bone centerlines, then instructing patient via a mobile device to perform a task involving assuming certain positions and performing certain movements, then the patient performing the task while the sensors record data about joint location and movement information. Next, using the data, image analysis and patent demographics to make a recommendation regarding joint ailment remediation.",G06F 17/30; G06F 17/50; G06T 7/20,"OBMA, Padraic; FRAENKEL, Visnu; HANSEN, Wayne","OBMA, Padraic; FRAENKEL, Visnu; HANSEN, Wayne","62/468,558 08.03.2017 US; 62/468,565 08.03.2017 US; 62/583,244 08.11.2017 US",
WO2000004493,PCT/US1999/015014,01.07.1999,WO/2000/004493,27.01.2000,WO,PORTABLE IMAGING DEVICE AND METHOD,"The present invention is a multi-purpose portable imaging device. The device is small enough to be hand-held or wearable and has embedded on its surface at least one sensor. These sensors may be active or passive. Analog energy received from the sensors is converted into a digital format and sent to an advanced computer. The computer is constructed on parallel architecture platform. The computer has the capability of taking data from multiple sensors and providing sensor fusion features. The data is processed and displayed in a graphical format in real time which is viewed on the imaging device. A keypad for entering data and commands is available on the device. The device has the capability of using a removable cartridge embedded with read only memory modules containing application software for manipulating data from the sensors. The application cartridge provides the imaging device with its multi-purpose functionality. Methods of utilizing expert systems to match generated images, or dielectric constants is provided.",G06F 15/02,"CIRRUS LOGIC, INC.","COUSINS, Robert, E.; SHAW, Steven, A.","60/092,798 14.07.1998 US; null 01.06.1999 US",
WO2013006489,PCT/US2012/045101,29.06.2012,WO/2013/006489,10.01.2013,WO,LEARNING SPEECH MODELS FOR MOBILE DEVICE USERS,"Techniques are provided to recognize a speaker's voice. In one embodiment, received audio data may be separated into a plurality of signals. For each signal, the signal may be associated with value/s for one or more features (e.g., Mel-Frequency Cepstral coefficients). The received data may be clustered (e.g., by clustering features associated with the signals). A predominate voice cluster may be identified and associated with a user. A speech model (e.g., a Gaussian Mixture Model or Hidden Markov Model) may be trained based on data associated with the predominate cluster. A received audio signal may then be processed using the speech model to, e.g.,: determine who was speaking; determine whether the user was speaking; determining whether anyone was speaking; and/or determine what words were said. A context of the device or the user may then be inferred based at least partly on the processed signal.",G10L 15/06,"QUALCOMM INCORPORATED; GROKOP, Leonard, Henry; NARAYANAN, Vidya","GROKOP, Leonard, Henry; NARAYANAN, Vidya","61/504,080 01.07.2011 US; 13/344,026 05.01.2012 US",
WO2019075276,PCT/US2018/055520,11.10.2018,WO/2019/075276,18.04.2019,WO,SYSTEMS AND METHODS FOR OBJECT IDENTIFICATION,"A method for identifying and tracking objects includes: capturing one or more 3-D models of one or more objects in a scene using a three-dimensional (3-D) scanning system, the one or more 3-D models including color and geometry information of the one or more objects; and computing, by an analysis agent, one or more descriptors of the one or more 3-D models, each descriptor corresponding to a fixed-length feature vector; and retrieving metadata identifying the one or more objects based on the one or more descriptors.",G06F 17/30; G06K 9/46; G06K 9/62; G06K 9/78,"AQUIFI, INC.","DAL MUTTO, Carlo; TIEU, Kinh; ZUCCARINO, Tony; TRACHEWSKY, Jason; RAFII, Abbas","62/571,209 11.10.2017 US",
WO2019000293,PCT/CN2017/090686,29.06.2017,WO/2019/000293,03.01.2019,WO,TECHNIQUES FOR DENSE VIDEO DESCRIPTIONS,"Techniques and apparatus for generating dense natural language descriptions for video content are described. In one embodiment, for example, an apparatus may include at least one memory and logic, at least a portion of the logic comprised in hardware coupled to the at least one memory, the logic to receive a source video comprising a plurality of frames, determine a plurality of regions for each of the plurality of frames, generate at least one region-sequence connecting the determined plurality of regions, apply a language model to the at least one region-sequence to generate description information comprising a description of at least a portion of content of the source video. Other embodiments are described and claimed.",G06K 9/00,"INTEL CORPORATION; CHEN, Yurong; LI, Jianguo; SU, Zhou; SHEN, Zhiqiang","CHEN, Yurong; LI, Jianguo; SU, Zhou; SHEN, Zhiqiang",,EP-2017916116; CN-201780091433.4
WO2019066841,PCT/US2017/053912,28.09.2017,WO/2019/066841,04.04.2019,WO,MULTIMODAL SENSING IN AUTONOMOUS DRIVING VEHICLES WITH SELF-HEALING CAPABILITIES,"An apparatus for autonomous vehicles includes a perception pipeline having independent classification processes operating in parallel to respectively identify objects belonging to a specific object type based on sensor data flows from multiple ones of a plurality of different types of sensors. The apparatus also includes a sensor monitoring stage to operate in parallel with the perception pipeline and to use the sensor data flows to estimate and track a confidence level of each of the plurality of different types of sensors, and nullify a deficient sensor when the confidence level associated with the deficient sensor fails to meet a confidence threshold.",G05D 1/00; G05D 1/02; G05B 23/02,INTEL CORPORATION,"ARDITTI ILITZKY, David; ALVAREZ, Ignacio J.; ZAMORA ESQUIVEL, Julio C.; LOPEZ MEYER, Paulo",,
WO2018154100,PCT/EP2018/054624,26.02.2018,WO/2018/154100,30.08.2018,WO,NEURAL EPISODIC CONTROL,"A method includes maintaining respective episodic memory data for each of multiple actions; receiving a current observation characterizing a current state of an environment being interacted with by an agent; processing the current observation using an embedding neural network in accordance with current values of parameters of the embedding neural network to generate a current key embedding for the current observation; for each action of the plurality of actions: determining the p nearest key embeddings in the episodic memory data for the action to the current key embedding according to a distance measure, and determining a Q value for the action from the return estimates mapped to by the p nearest key embeddings in the episodic memory data for the action; and selecting, using the Q values for the actions, an action from the multiple actions as the action to be performed by the agent.",G06N 3/08; G06N 3/00,DEEPMIND TECHNOLOGIES LIMITED,"URIA-MARTÍNEZ, Benigno; PRITZEL, Alexander; BLUNDELL, Charles; BADIA, Adria Puigdomenech","62/463,558 24.02.2017 US",EP-2018707703; JP-2019546227; CN-201880008758.6
WO2002007164,PCT/US2001/022485,17.07.2001,WO/2002/007164,24.01.2002,WO,METHOD AND SYSTEM FOR INDEXING AND CONTENT-BASED ADAPTIVE STREAMING OF DIGITAL VIDEO CONTENT,"The present invention discloses systems and methods for automatically parsing digital video content into segments corresponding to fundamental semnatic units, events, and camera views, and streaming parsed digital video content to users for display and browsing. The systems and methods effectively use the domain-specific knowledge such as regular structures of fundamental semnatic units, unique views corresponding to the units, and the predictable state transition rules. The systems and methods also include scene change detection, video text recognition, and view recognition. The results of parsing may be used in a personal video browsing/navigation interface system. Furthermore, a novel adaptive streaming method in which quality levels of video segments are varied dynamically according to the user preference of different segments is disclosed. Important segments are transmitted with full-motion audio-video content at a high bit rate, while the rest is transmitted only as low-bandwidth media (text, still frames, audio).",G06F 17/30,"THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK; CHANG, Shih-Fu; ZHONG, Di; KUMAR, Raj; JAIMES, Alejandro","CHANG, Shih-Fu; ZHONG, Di; KUMAR, Raj; JAIMES, Alejandro","60/218,969 17.07.2000 US; 60/260,637 03.01.2001 US",
WO2017200588,PCT/US2016/068737,27.12.2016,WO/2017/200588,23.11.2017,WO,GENERATING NATURAL LANGUAGE OUTPUT BASED ON NATURAL LANGUAGE USER INTERFACE INPUT,"Some implementations are directed to generating a personal database entry for a user based on free-form natural language input formulated by the user via user interface input device(s) of a computing device of the user. The generated personal database entry may include term(s) of the natural language input and descriptive metadata determined based on term(s) of the natural language input and/or based on contextual features associated with receiving the natural language input. Some implementations are directed to generating, based on one or more personal database entries of a user, output that is responsive to further free-form natural language input of the user. For example, one or more entries responsive to further natural language input can be identified based on matching content of those entries to search parameter(s) determined based on the further input. Some implementations are directed to improved automated personal assistants.",G06F 17/30; G06F 17/28,GOOGLE LLC,"GARRETT, Maryam; QUAH, Wan Fen Nicole; HORLING, Bryan; HE, Ruijie","15/157,297 17.05.2016 US",EP-2016826623; JP-2018560513; CN-201680085778.4; KR-1020187036265
EP289050006,19192879,21.08.2019,3614315,26.02.2020,EP,SYSTEMS AND METHODS FOR MODELLING PREDICTION ERRORS IN PATH-LEARNING OF AN AUTONOMOUS LEARNING AGENT,"Systems and methods for modelling prediction errors in path-learning of an autonomous learning agent are provided. The traditional systems and methods provide for machine learning techniques, wherein estimation of errors in prediction is reduced with an increase in the number of path-iterations of the autonomous learning agent. Embodiments of the present disclosure provide for a two-stage modelling technique to model the prediction errors in the path-learning of the autonomous learning agent, wherein the two-stage modelling technique comprises extracting a plurality of fitted error values corresponding to a plurality of predicted actions and actual actions by implementing an Autoregressive moving average (ARMA) technique on a set of prediction error values; and estimating, by implementing a linear regression technique on the plurality of fitted error values, a probable deviation of the autonomous learning agent from each of an actual action amongst a plurality of predicted and actual actions.",G06N 3/04; G06N 3/08,TATA CONSULTANCY SERVICES LTD,DEY SOUNAK; BHATTACHARYA SAKYAJIT; PAL KAUSTAB; MUKHERJEE ARIJIT,201821031249 21.08.2018 IN,
WO2019070790,PCT/US2018/054073,03.10.2018,WO/2019/070790,11.04.2019,WO,"SYSTEMS AND METHODS FOR ENSURING SAFE, NORM-CONFORMING AND ETHICAL BEHAVIOR OF INTELLIGENT SYSTEMS","Systems and methods may ethically evaluate intelligent systems operating in a real-world environment. The systems and methods may generate a clone of the intelligent system, and test the clone in a simulation environment. If the clone passes the testing, the systems and methods may permit the intelligent system to continue operating in the real-world environment. If the clone fails the testing, the systems and methods may override the intelligent system, such as disabling the intelligent system and assuming control in the real-world environment. The systems and methods may be implemented at a hardware level of a data processing device to prevent interference with the systems and methods by the intelligent system.",G06F 17/50; G06F 9/455; G06F 8/40,TRUSTEES OF TUFTS COLLEGE,"SCHEUTZ, Matthias J.; ARNOLD, Thomas H.","62/567,816 04.10.2017 US",
WO2019144287,PCT/CN2018/073864,23.01.2018,WO/2019/144287,01.08.2019,WO,SYSTEMS AND METHODS FOR AUTOMATIC WATER SURFACE AND SKY DETECTION,"Systems and methods for processing images to detect a water surface (404) and/or a sky (402) in one or more of the images. In some embodiments, the systems and methods may obtain image information for an image (902) and determine whether the image information represents a sky (402) based on a classification model (906). In some embodiments, the systems and methods may detect a first edge line (504) in a first image (602), detect a second edge line (504) in a second image (604), and detect a water surface (404) in the images based on comparing a difference between the first and second edge lines (504) with a threshold value (606). According to further embodiments, the systems and methods may detect whether an image includes a water surface (404) or a sky (402), and if so, determine a movement parameter for a movable object (10) based on whether a water surface (404) or sky (402) is detected.",G05D 1/10; G06K 9/46; G06T 7/20,"SZ DJI TECHNOLOGY CO., LTD.","ZHOU, You; CAI, Jianzhao; TANG, Ketan",,
WO2020016869,PCT/IB2019/057339,30.08.2019,WO/2020/016869,23.01.2020,WO,INTEGRATION OF IMAGING DATA,"A surgical visualization system (4000, 4006) is disclosed. The surgical visualization system is configured to identify one or more structure(s) (4001a, 4001b) and/or determine one or more distances with respect to obscuring tissue and/or the identified structure(s). The surgical visualization system can facilitate avoidance of the identified structure(s) by a surgical device. The surgical visualization system (4006) can comprise a first emitter configured to emit a plurality of tissue-penetrating light waves and a second emitter configured to emit structured light (4008) onto the surface (4005) of tissue (4003). The surgical visualization system can also include an image sensor configured to detect reflected visible light, tissue-penetrating light, and/or structured light. The surgical visualization system can convey information to one or more clinicians regarding the position of one or more hidden identified structures (4001a, 4001b) and/or provide one or more proximity indicators. In various instances, imaging data from different sources and/or obtained at different times can be integrated.",A61B 1/00; A61B 1/04; A61B 1/06; A61B 5/00; A61B 5/107; A61B 17/04; A61B 17/062; A61B 34/30; A61B 90/30; A61B 90/00; G01B 11/25; G01N 21/25; G01N 21/31; G01S 17/89,ETHICON LLC,"SCHEIB, Charles J.; RITCHIE, Paul G.; MOORE, Sarah A.; SWAYZE, Jeffrey S.; TALBERT, Joshua D.; YOUNG, Joshua D.; MORENO, Victor C.","62/698,625 16.07.2018 US; 16/128,195 11.09.2018 US",
WO2017218437,PCT/US2017/037081,12.06.2017,WO/2017/218437,21.12.2017,WO,SITUATION FORECAST MECHANISMS FOR INTERNET OF THINGS INTEGRATION PLATFORM,"A method of consolidating Internet of Things (IoT) devices connected via an IoT network is disclosed. An IoT integration platform implemented by a computer system can collect data from one or more of IoT devices, IoT solution specific server systems, third-party server systems, general-purpose user computing devices, or any combination thereof. The IoT integration platform can label the data based on entity-specific context. The entity-specific context can correspond to a user account, a device, a location, or any combination thereof. The IoT integration platform can generate an entity-specific profile based on the labeled data. The IoT integration platform can generate, based on the entity-specific profile, a situation forecast associated with a target entity and with a timeframe yet to occur.",G06F 17/30; H04L 12/26,"NEURA, INC.","SHAASHUA, Triinu Magi; SHAASHUA, Ori","15/181,191 13.06.2016 US",EP-2017813884; CN-201780049737.4
WO2019099198,PCT/US2018/058388,31.10.2018,WO/2019/099198,23.05.2019,WO,PARTITIONING VIDEOS,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for partitioning videos. In one aspect, a method includes obtaining a partition of a video into one or more shots. Features are generated for each shot, including visual features and audio features. The generated features for each shot are provided as input to a partitioning neural network that is configured to process the generated features to generate a partitioning neural network output. The partition of the video into one or more chapters is determined based on the partitioning neural network output, where a chapter is a sequence of consecutive shots that are determined to be taken at one or more locations that are semantically related.",G06N 3/04,GOOGLE LLC,"CHU, Hang; NECHYBA, Michael; GALLAGHER, Andrew C.; PRABHU, Utsav","15/813,978 15.11.2017 US",CN-201880031932.9; EP-2018804194
WO2016124818,PCT/FI2016/050051,28.01.2016,WO/2016/124818,11.08.2016,WO,WELDING SYSTEM WITH ADAPTIVE ALGORITHM,"A welding system comprises a welding actuator (101) operative in accordance with actuator control data, a sensor system (102) for producing sensor data related to a welded seam, and a processing system (103) for determining the actuator control data with an adaptive algorithm on the basis of the sensor data and welding data expressing material to be welded and welding conditions. The welding system comprises a training data interface (104, 105) enabling a user to input the actuator control data for a training welding process. The processing system is configured to train the adaptive algorithm in accordance with the welding data, the actuator control data inputted via the training data interface, and the sensor data measured during the training welding process. Thus, the welding system can be trained so that the user is in the control loop. The adaptive algorithm can be based on for example an artificial neural network.",G05B 13/02,LAPPEENRANNAN TEKNILLINEN YLIOPISTO,"KAH, Paul; PIRINEN, Markku; MARTIKAINEN, Jukka",20155077 06.02.2015 FI,EP-2016703822
WO2015017796,PCT/US2014/049435,01.08.2014,WO/2015/017796,05.02.2015,WO,LEARNING SYSTEMS AND METHODS,"A sequence of images depicting an object is captured, e.g., by a camera at a point-of-sale terminal in a retail store. The object is identified, such as by a barcode or watermark that is detected from one or more of the images. Once the object's identity is known, such information is used in training a classifier (e.g., a machine learning system) to recognize the object from others of the captured images, including images that may be degraded by blur, inferior lighting, etc. In another arrangement, such degraded images are processed to identify feature points useful in fingerprint-based identification of the object. Feature points extracted from such degraded imagery aid in fingerprint-based recognition of objects under real life circumstances, as contrasted with feature points extracted from pristine imagery (e.g., digital files containing label artwork for such objects). A great variety of other features and arrangements - some involving designing classifiers so as to combat classifier copying - are also detailed.",G06K 9/00; G06F 21/16; G06K 9/32; G06T 1/00; G06K 9/62,"DIGIMARC CORPORATION; MEYER, Joel, R.","RODRIGUEZ, Tony, F.; ALATTAR, Osama, M.; BRUNK, Hugh, L.; CONWELL, William, Y.; KAMATH, Ajith, Mulki","61/861,931 02.08.2013 US; 61/880,798 20.09.2013 US",
WO2006041738,PCT/US2005/035334,03.10.2005,WO/2006/041738,20.04.2006,WO,BIOLOGICAL INTERFACE SYSTEM,"A system and method for an improved biological interface system that processes multicellular signals of a patient and controls one or more devices is disclosed. The system includes a sensor that detects the multicellular signals and a processing unit for producing the control signal based on the multicellular signals. The system may include improved communication, self-diagnostics, and surgical insertion tools.",A61B 5/00; A61B 5/04,"CYBERKINETICS NEUROTECHNOLOGY SYSTEMS, INC.; FLAHERTY, J., Christopher; BARRETT, Burke, T.; DONOGHUE, John, Phillip; VAN WAGENEN, Richard, A.; SMITH, Christopher; PUNGOR, Andras; DECARIA, Christine; BRANNER, Almut; HARVEY, Nephi; MISENER, Anthony, K.; GUILLORY, K., Shane; JOSEPH, Jon, P.","FLAHERTY, J., Christopher; BARRETT, Burke, T.; DONOGHUE, John, Phillip; VAN WAGENEN, Richard, A.; SMITH, Christopher; PUNGOR, Andras; DECARIA, Christine; BRANNER, Almut; HARVEY, Nephi; MISENER, Anthony, K.; GUILLORY, K., Shane; JOSEPH, Jon, P.","60/615,629 04.10.2004 US",EP-2005800928
WO2018122858,PCT/IL2017/051405,29.12.2017,WO/2018/122858,05.07.2018,WO,"A SYSTEM AND A METHOD FOR ACOUSTIC MONITORING, ANALYSIS AND MAINTENANCE OF EQUIPMENT IN SWIMMING POOLS","The present invention provides a method for comprehensive monitoring, analysis and maintenance of water and equipment in swimming pools said method implemented by one or more processing devices operatively coupled to a non- transitory storage device, on which are stored modules of instruction code that when executed cause the one or more processing devices to perform: - acquiring continuous data from acoustic sensors; - propagating said data to an online remote server, - applying machine learning algorithms at the online remote server configured to incorporate the acquired data and provide recommendations and control parameters, and - providing an online interface to access said recommendations for at least one of: pool owners, pool servicemen, pool maintenance companies, pool vendors and pool retail dealers, wherein applying said machine learning algorithms comprising applying an acoustic model trained to learn the behavior of said data acquired from said acoustic sensors and to identify at least one of a device failure, location of a failure, type of failure, and the mutual effect between/among devices/instruments undergoing failures and other devices/instruments in said pool system.",E04H 4/00; G06F 11/00; G06N 5/00,MAYTRONICS LTD.,"YIZHACK, Tamir; PERETZ, Shay","62/439,949 29.12.2016 US",EP-2017888834; AU-2017388639; IL-267704
EP250371249,18155944,09.02.2018,3525131,14.08.2019,EP,METHODS AND APPARATUSES FOR OBJECT DETECTION IN A SCENE REPRESENTED BY DEPTH DATA OF A RANGE DETECTION SENSOR AND IMAGE DATA OF A CAMERA,,G06K 9/00; G06K 9/62,BAYERISCHE MOTOREN WERKE AG,BANERJEE KOYEL; GAVARRAJU SUMANTH; HE MINGKANG; NOTZ DOMINIK,18155944 09.02.2018 EP,
EP131260075,13181662,26.08.2013,2843621,04.03.2015,EP,Human pose calculation from optical flow data,"The present invention refers to a method, system and product for estimating human pose based on optical flow data. After providing the image data sequence (1) containing the multipart object, optical flow data are computed (2). Based on the optical flow data a segmentation of the image into object parts is computed. Thereafter, joints between object parts and/or the location of object parts are detected from the segmentation. Finally, the movement of the object parts is tracked.",G06T 7/20; G06K 9/00,MAX PLANCK GES ZUR FÖRDERUNG DER WISSENSCHAFTEN E V,BLACK MICHAEL; LOPER MATTHEW; ROMERO JAVIER; ZUFFI SILVIA,13181662 26.08.2013 EP,
WO2020018392,PCT/US2019/041733,12.07.2019,WO/2020/018392,23.01.2020,WO,MONITORING AND CONTROLLING CONTINUOUS STOCHASTIC PROCESSES BASED ON EVENTS IN TIME SERIES DATA,"Provided is process, including: obtaining interaction-event records; determining, based on at least some of the interaction-event records, sets of event-risk scores, wherein: at least some respective event-risk scores are indicative of an effective of a respective risk ascribed by a first entity to a respective aspect of a second entity; and at least some respective event-risk scores are based on both: respective contributions of respective corresponding events to a subsequent event, and a risk ascribed to a subsequent event; and storing the sets of event-risk scores in memory.",G06N 7/00; G06N 20/00,CEREBRI AI INC.,"BELANGER, Jean; BRIANÇON, Alain; STOJANOV, James; SILBERMAN, Gabriel M.","62/698,769 16.07.2018 US; 16/127,933 11.09.2018 US",
WO2018136875,PCT/US2018/014695,22.01.2018,WO/2018/136875,26.07.2018,WO,ADAPTIVE CYBER-PHYSICAL SYSTEM FOR EFFICIENT MONITORING OF UNSTRUCTURED ENVIRONMENTS,"The present disclosure provides a system for monitoring unstructured environments. A predetermined path can be determined according to an assignment of geolocations to one or more agronomically anomalous target areas, where the one or more agronomically anomalous target areas are determined according to an analysis of a plurality of first images that automatically identifies a target area that deviates from a determination of an average of the plurality of first images that represents an anomalous place within a predetermined area, where the plurality of first images of the predetermined area are captured by a camera during a flight over the predetermined area. A camera of an unmanned vehicle can capture at least one second image of the one or more agronomically anomalous target areas as the unmanned vehicle travels along the predetermined path",G06K 9/46; G06K 9/62; G05D 1/02,THE BOARD OF TRUSTEES OF THE UNIVERSITY OF ILLINOIS,"CHOWDHARY, Girish; SOMAN, Chinmay P.; BARBER, Beau David","62/449,439 23.01.2017 US",EP-2018741140; AU-2018210985; CA-3049681
WO2019098538,PCT/KR2018/012123,15.10.2018,WO/2019/098538,23.05.2019,WO,DEVICE AND METHOD FOR PROCESSING CONVOLUTION OPERATION USING KERNEL,"Provided are a method and apparatus for processing a convolution operation in a neural network. The apparatus may include a memory, and a processor configured to read, from the memory, one of divided blocks of input data stored in a memory; generate an output block by performing the convolution operation on the one of the divided blocks with a kernel; generate a feature map by using the output block, and write the feature map to the memory.",G06N 3/063; G06N 3/04,"SAMSUNG ELECTRONICS CO., LTD.","KIM, Kyoung-hoon; PARK, Young-hwan; SUH, Dong-kwan; PRASAD, Keshava; KIM, Dae-hyun; KIM, Suk-jin; CHO, Han-su; KIM, Hyun-jung",10-2017-0151722 14.11.2017 KR,EP-2018878124
EP13227342,99303197,26.04.1999,0953967,03.11.1999,EP,An automated hotel attendant using speech recognition,"An automated hotel attendant is provided for coordinating room-to-room calling over a telephone switching system that supports multiple telephone extensions. A hotel registration system receives and stores the spelled names of hotel guests as well as assigns each guest an associated telephone extension. A lexicon training system is connected to the hotel registration system for generating pronunciations for each spelled name by converting the characters that spell those names into word-phoneme data. This word-phoneme data is in turn stored in a lexicon that is used by a speech recognition system. In particular, a phoneticizer in conjunction with a Hidden Markov Model (HMM) based model trainer serves as the basis for the lexicon training system, such that one or several HMM models associated with each guest name are stored in the lexicon. An automated attendant is coupled to the speech recognition system for converting a spoken name of a hotel guest entered from one of the telephone extensions into a predefined hotel guest name that can be used to retrieve an assigned telephone extension from the hotel registration system. Next, the automated attendant causes the telephone switching system to call the requested telephone extension in response to the entry of the spoken name from one of the telephone extensions. <IMAGE>",G10L 15/06; G10L 11/00; G10L 15/14; G10L 15/26; H04M 3/42,MATSUSHITA ELECTRIC IND CO LTD,JUNQUA JEAN-CLAUDE; CONTOLINI MATTEO,7039998 30.04.1998 US,
WO2018168521,PCT/JP2018/007987,02.03.2018,WO/2018/168521,20.09.2018,WO,"LEARNING RESULT IDENTIFYING APPARATUS, LEARNING RESULT IDENTIFYING METHOD, AND PROGRAM THEREFOR","In order to provide a technique for identifying a result of performing a learning process by machine learning, and managing the result as appropriate, a management apparatus for an inspection machine includes: an acquiring portion configured to acquire information related to a specification of the inspection machine to which a learning result is to be applied; and a matching portion configured to perform matching, for a learning result that has obtained a predetermined capability through a predetermined learning process by machine learning and has been stored in a learning result database, with identifying information containing first information for distinguishing the predetermined learning process from another learning process and second information for identifying the learning result through the predetermined learning process from another learning result, and specify a learning result that is to be applied to the inspection machine.",G06N 99/00,OMRON CORPORATION,"ANDO, Tanichi",2017-048920 14.03.2017 JP; 2017-049140 14.03.2017 JP; 2017-048924 14.03.2017 JP; 2017-049007 14.03.2017 JP,
WO1997010554,PCT/US1996/015666,13.09.1996,WO/1997/010554,20.03.1997,WO,"ARCHITECTURE FOR PROCESSING SEARCH QUERIES, RETRIEVING DOCUMENTS IDENTIFIED THEREBY, AND METHOD FOR USING SAME","A split-level architecture for processing a search query and identifying and retrieving documents corresponding thereto, comprising a session server (114a) and a query server (116a). The session server includes means for sending the search query to the query server (134), means for receiving the search results information therefrom (134), means for sending a search results list across a communications channel to user (132), means for receiving a document retrieval request transmitted from user (130), means for retrieving a document in response to the retrieval request and transmitting a file representative of the document to user (136), and means for incrementing an accounting record on an accounting database (138), the accounting record representing a number of retrievals of the document by the session server. The query server includes means for receiving a search query from the session server (140), searching means for searching the first database in response thereto (142), and means for sending search results to the session server (140).",G06F 17/30,INFONAUTICS CORPORATION,"BARR, Thomas; BEATTIE, James, T.; HUSICK, Lawrence, A.; KRUPIT, Michael, S.; MORGAN, Howard; SCHULTZ, John, Michael","08/529,249 15.09.1995 US; 08/528,884 15.09.1995 US",
EP248884875,18151489,12.01.2018,3511861,17.07.2019,EP,DATA EXTRACTION PIPELINE,,G06K 9/00,ONFIDO LTD,CALI JACQUES; ROELANTS PETER; SAGONAS CHRISTOS; SABATHE ROMAIN,18151489 12.01.2018 EP,
WO2020009800,PCT/US2019/037952,19.06.2019,WO/2020/009800,09.01.2020,WO,METHODS AND SYSTEMS FOR INTERPOLATION OF DISPARATE INPUTS,"Systems and methods are provided for interpolation of disparate inputs. A radial basis function neural network (RBFNN) may be used to interpolate the pose of a digital character. Input parameters to the RBFNN may be separated by data type (e.g. angular vs. linear) and manipulated within the RBFNN by distance functions specific to the data type (e.g. use an angular distance function for the angular input data). A weight may be applied to each distance to compensate for input data representing different variables (e.g. clavicle vs. shoulder). The output parameters of the RBFNN may be a set of independent values, which may be combined into combination values (e.g. representing x, y, z, w angular value in SO(3) space).",G06F 19/00,"MAGIC LEAP, INC.","WEDIG, Geoffrey","62/693,237 02.07.2018 US",
WO2020031189,PCT/IL2019/050900,08.08.2019,WO/2020/031189,13.02.2020,WO,SYSTEM AND METHOD FOR SEQUENTIAL PROBABILISTIC OBJECT CLASSIFICATION,"Methods and systems are provided for classifying an object appearing in multiple sequential images. The process includes determining a neural network classifier having multiple object classes for classifying objects in images; determining a likelihood classifier model comprising a likelihood vector of class probability vectors; for each image z, running the image multiple respective times through the neural network classifier, applying dropout each time, to generate a point cloud of class probability vector values {ϒt}; calculating a vector of posterior distributions {λt} for each class and for each of the multiple {ϒt}, where calculating each class element of {λt} includes calculating a product of the respective element of the class probability vectors and an element of the posterior distribution of a prior image; randomly selecting a subset of {λt} to form a new subset of {λt}; and repeating the calculation of the subset {λt} for each of the images, to determine a cloud of posterior probability vectors approximating a distribution over posterior class probabilities, given all the multiple sequential images.",G06K 9/62; G06K 9/32,TECHNION RESEARCH & DEVELOPMENT FOUNDATION LIMITED,"TCHUIEV, Vladimir; INDELMAN, Vadim","62/715,863 08.08.2018 US",
WO2017024270,PCT/US2016/045890,05.08.2016,WO/2017/024270,09.02.2017,WO,SYSTEMS AND METHODS FOR LEARNING NEW TRAINED CONCEPTS USED TO RETRIEVE CONTENT RELEVANT TO THE CONCEPTS LEARNED,A system configured for learning new trained concepts used to retrieve content relevant to the concepts learned. The system may comprise one or more hardware processors configured by machine-readable instructions to obtain one or more digital media items. The one or more hardware processors may be further configured to obtain an indication conveying a concept to be learned from the one or more digital media items. The one or more hardware processors may be further configured to receive feedback associated with individual ones of the one or more digital media items. The one or more hardware processors may be configured to obtain individual neural network representations for the individual ones of the one or more digital media items. The one or more hardware processors may be configured to determine a trained concept based on the feedback and the neural network representations of the one or more digital media items.,G06F 15/18,"CLARIFAI, INC.","ZEILER, Matthew D.","14/820,454 06.08.2015 US",EP-2016833968
WO2020023428,PCT/US2019/042898,23.07.2019,WO/2020/023428,30.01.2020,WO,PRE-OPERATIVE ASSESSMENT SYSTEM,"A system of generating a pre-operative assessment of a patient includes one or more client electronic devices, and an assessment system configured to communication with the client electronic devices via a communication network. The assessment system includes one or more computing devices and a computer-readable storage medium. The computer-readable storage medium includes programming instructions that, when executed, cause the computing devices to receive patient information pertaining to a patient one or more of the client electronic devices, use at least a portion of the patient information to access one or more medical images associated with the patient, perform one or more image processing techniques on the medical images to identify, from medical images, a condition associated with the patient, generate a pre-operative assessment for the patient based on the patient information and the condition, and cause the assessment to be displayed on a display device of the client electronic devices.",G16H 30/40; G16H 10/60; G16H 20/40; A61B 5/00; A61B 5/0402; A61B 5/0488; A61B 5/055; A61B 6/03,"WARSAW ORTHOPEDIC, INC.","BENSON, Nicholas M.; BALLARD, Rodney R.; HIGGINS, Ryan","16/043,928 24.07.2018 US",
WO2012009214,PCT/US2011/043319,08.07.2011,WO/2012/009214,19.01.2012,WO,EFFICIENT GESTURE PROCESSING,"Embodiments of the invention describe a system to efficiently execute gesture recognition algorithms. Embodiments of the invention describe a power efficient staged gesture recognition pipeline including multimodal interaction detection, context based optimized recognition, and context based optimized training and continuous learning. Embodiments of the invention further describe a system to accommodate many types of algorithms depending on the type of gesture that is needed in any particular situation. Examples of recognition algorithms include but are not limited to, HMM for complex dynamic gestures (e.g. write a number in the air), Decision Trees (DT) for static poses, peak detection for coarse shake/whack gestures or inertial methods (INS) for pitch/roll detection.",G06F 3/03; G06F 9/44,"INTEL CORPORATION; RAFFA, Giuseppe; NACHMAN, Lama; LEE, Jinwon","RAFFA, Giuseppe; NACHMAN, Lama; LEE, Jinwon","12/835,079 13.07.2010 US",CN-201180034400.9
EP27772988,10185728,27.10.2000,2357582,17.08.2011,EP,Methods and devices for identifying patterns in biological systems,"The methods, systems and devices of the present invention comprise use of support vector machines for the identification of patterns that are important for medical diagnosis, prognosis and treatment. Such patterns may be found in many different datasets. The present invention also comprises methods and compositions for the treatment and diagnosis of medical conditions.",G01N 33/53; G06F 19/24; A61K 45/00; A61P 35/00; C12M 1/00; C12M 1/34; C12N 15/09; C12Q 1/68; G01N 33/566; G06F 15/18; G06F 19/20; G06K 9/62; G06N 99/00,HEALTH DISCOVERY CORP,BARNHILL STEVEN D; GUYON ISABELLE; WESTON JASON,00973988  ; 161806 P  ; 168703 P  ; 184596 P  ; 191219 P  ; 207026 P  ; 568301  ; 578011  ; EP20000973988  ; US19990161806P  ; US19990168703P  ; US20000184596P  ; US20000191219P  ; US20000207026P  ; US20000568301  ; US20000578011  ; 00973988 27.10.2000 EP; 16180699 27.10.1999 US; 16870399 02.12.1999 US; 18459600 24.02.2000 US; 19121900 22.03.2000 US; 20702600 25.05.2000 US; 56830100 09.05.2000 US; 57801100 24.05.2000 US,
WO2014035738,PCT/US2013/055898,21.08.2013,WO/2014/035738,06.03.2014,WO,COMPUTER-IMPLEMENTED DEEP TENSOR NEURAL NETWORK,"A deep tensor neural network (DTNN) is described herein, wherein the DTNN is suitable for employment in a computer-implemented recognition/classification system. Hidden layers in the DTNN comprise at least one projection layer, which includes a first subspace of hidden units and a second subspace of hidden units. The first subspace of hidden units receives a first nonlinear projection of input data to a projection layer and generates the first set of output data based at least in part thereon, and the second subspace of hidden units receives a second nonlinear projection of the input data to the projection layer and generates the second set of output data based at least in part thereon. A tensor layer, which can converted into a conventional layer of a DNN, generates the third set of output data based upon the first set of output data and the second set of output data.",G06N 3/02; G06N 3/04,"MICROSOFT TECHNOLOGY LICENSING, LLC","YU, Dong; DENG, Li; SEIDE, Frank","13/597,268 29.08.2012 US",
WO2007061950,PCT/US2006/044895,20.11.2006,WO/2007/061950,31.05.2007,WO,"SYSTEM, APPARATUS AND METHODS FOR AUGMENTING FILTER WITH ADAPTIVE ELEMENT","A system (10) in accordance with the invention uses an adaptive element (34) to augment a filter (20) for tracking an observed system (50). The adaptive element (34) only requires a single neural network (36) and does not require an error observer. The adaptive element (34) provides robustness to parameter uncertainty and unmodeled dynamics present in the observed system (50) for improved tracking performance over the filter (20) alone. The adaptive element (34) can be implemented with a linearly parameterized neural network (36), whose weights are adapted online using error residuals generated from the filter (20). Boundedness of the signals generated by the system (10) can be proven using Lyapunov s direct method and a backstepping argument. A related apparatus (30) and method (FIGS. 5 A, 5B) are also disclosed.",G05B 13/02,GEORGIA TECH RESEARCH CORPORATION,"CALISE, Anthony, J.; MADYASTHA, Venkatesh, K.","60/738,302 18.11.2005 US",
WO2013138778,PCT/US2013/032546,15.03.2013,WO/2013/138778,19.09.2013,WO,TAG-BASED APPARATUS AND METHODS FOR NEURAL NETWORKS,"Apparatus and methods for high-level neuromorphic network description (HLND) using tags. The framework may be used to define nodes types, define node-to-node connection types, instantiate node instances for different node types, and/or generate instances of connection types between these nodes. The HLND format may be used to define nodes types, define node-to-node connection types, instantiate node instances for different node types, dynamically identify and/or select network subsets using tags, and/or generate instances of one or more connections between these nodes using such subsets. To facilitate the HLND operation and disambiguation, individual elements of the network (e.g., nodes, extensions, connections, I/O ports) may be assigned at least one unique tag. The tags may be used to identify and/or refer to respective network elements. The HLND kernel may comprises an interface to Elementary Network Description.",G06F 15/18; G06N 3/02; G06N 3/04,BRAIN CORPORATION,"SZATMARY, Botond; IZHIKEVICH, Eugene M.","13/385,933 15.03.2012 US",CN-201380025107.5; EP-2013760351
WO2015044851,PCT/IB2014/064712,21.09.2014,WO/2015/044851,02.04.2015,WO,PHYSIOLOGICAL PARAMETER MEASUREMENT AND FEEDBACK SYSTEM,"Electrical activity of the brain (EEG) and position / motion of a body part, e.g. motion of an arm, are measured. A virtual representation of either the moving body part or the intended movement as determined from the brain activity is presented as feedback to the subject on a display which can be implemented as a head-up display. A clock module is operable to time stamp information transferred from a brain electrical activity sensing system and a position / motion detection system for joint processing. This non-invasive EEG-based brain-computer-interface is particularly useful for stroke rehabilitation.",A61B 5/00; A61B 5/0482; A61B 5/0488; A61B 5/11; G06F 3/01; G02B 27/01; A61B 5/01; A61B 5/0402; A61B 5/0496; A61B 5/053,MINDMAZE SA,"TADI, Tej; GARIPELLI, Gangadhar; MANETTI, Davide; BOURDAUD, Nicolas; PEREZ MARCOS, Daniel",13186039.7 25.09.2013 EP,US-15024442; EP-2014787277; CN-201480052887.7
WO2017079529,PCT/US2016/060479,04.11.2016,WO/2017/079529,11.05.2017,WO,UNIVERSAL CORRESPONDENCE NETWORK,"A computer-implemented method for training a convolutional neural network (CNN) is presented. The method includes extracting coordinates of corresponding points in the first and second locations, identifying positive points in the first and second locations, identifying negative points in the first and second locations, training features that correspond to positive points of the first and second locations to move closer to each other, and training features that correspond to negative points in the first and second locations to move away from each other.",G06N 3/08; G06N 3/04,"NEC LABORATORIES AMERICA, INC.","CHANDRAKER, Manmohan; SAVARESE, Silvio; CHOY, Christopher Bongsoo","62/250,877 04.11.2015 US; 15/342,700 03.11.2016 US",DE-112016004535; JP-2018522563
WO2017003756,PCT/US2016/038482,21.06.2016,WO/2017/003756,05.01.2017,WO,METHODS AND SYSTEMS FOR DETECTING AND RECOGNIZING TEXT FROM IMAGES,Images that comprise text are identified and output from the images is generated wherein the output comprises text from the image in textual data format. The portions of an image comprising the text data are initially identified and the text imaged by the pixels of that image portion is extracted in textual data format. The extracted text is stored so that a search for images comprising particular text is enabled.,G06K 9/62; G06K 9/32; G06K 9/46,YAHOO! INC.,"OSINDERO, Simon","14/755,817 30.06.2015 US",
EP254728415,17878608,13.03.2017,3553461,16.10.2019,EP,"CLASSIFICATION DEVICE, CLASSIFICATION METHOD, AND PROGRAM","Provided are a classification device, classification method, and program that make it possible to detect the state of a prescribed space using light such as infrared light while reducing the time and cost necessary for creating a determination program. A classification device according to one embodiment of the present invention is provided with a specification unit incorporating a neural network that has been trained to classify space states using light projection pattern information and light reception pattern information, a light projection information acquisition unit for acquiring information about a light projection pattern projected into a prescribed space and outputting the information to the specification unit, and a light reception unit for acquiring information about a light reception pattern resulting from the reception of light from the prescribed space and outputting the information to the specification unit. The specification unit outputs a classification result classifying the state of the prescribed space on the basis of the information about the light projection pattern acquired by the light projection information acquisition unit and the information about the light reception pattern received by the light reception unit.",G01B 11/00; G06K 9/20; G06K 9/62,OMRON TATEISI ELECTRONICS CO,ANDO TANICHI,2016237056 06.12.2016 JP; 2017010016 13.03.2017 JP,
WO2018160163,PCT/US2017/019890,28.02.2017,WO/2018/160163,07.09.2018,WO,SYSTEM AND METHOD FOR DETERMINING GRASPING POSITIONS FOR TWO-HANDED GRASPS OF INDUSTRIAL OBJECTS,"A system (100) and method (300) is provided for determining grasping positions for two- handed grasps of industrial objects. The system may include a processor configured to determine a three dimensional (3D) voxel grid (136) for a 3D model (150) of a target object (120). In addition, the processor may be configured to determine at least one pair of spaced apart grasping positions (126, 128) on the target object at which the target object is capable of being grasped with two hands at the same time based on processing the 3D voxel grid for the target object with a neural network (138) trained to determine grasping positions for two-handed grasps of target objects using training data (140). Such training data may include 3D voxel grids (142) of a plurality of 3D models (144) of training objects (206) and grasping data (146) including corresponding pairs of spaced-apart grasping positions (208) for two-handed grasps of the training objects. Also, the processor may be configured to provide output data (124) that specifies the determined grasping positions (126, 128) on the target object for two-handed grasps.",B25J 9/16,SIEMENS PRODUCT LIFECYCLE MANAGEMENT SOFTWARE INC.,"ARISOY, Erhan; REN, Guannan; BLUMENFELD, Rafael; RASCHKE, Ulrich; MUSUVATHY, Suraj Ravi",,EP-2017711851; CN-201780081644.X
WO2019071094,PCT/US2018/054556,05.10.2018,WO/2019/071094,11.04.2019,WO,VIDEO ACTION LOCALIZATION FROM PROPOSAL-ATTENTION,A method for processing a sequence of frames includes receiving a sequence of frames and multiple action proposals for the sequence of frames. The method also includes generating a representation of the sequence of frames and pooling the representation around each of the action proposals. The method further includes classifying the action proposals based on the pooled representations and controlling a device based on the classifying.,G06N 3/04; G06N 3/08; G06K 9/00,QUALCOMM INCORPORATED,"ESCORCIA, Victor Augusto; JAIN, Mihir; HABIBIAN, Amirhossein; SNOEK, Cornelis Gerardus Maria","62/569,245 06.10.2017 US; 16/152,301 04.10.2018 US",
WO2016118684,PCT/US2016/014210,21.01.2016,WO/2016/118684,28.07.2016,WO,HARVEST ADVISORY MODELING USING FIELD-LEVEL ANALYSIS OF WEATHER CONDITIONS AND OBSERVATIONS AND USER INPUT OF HARVEST CONDITION STATES AND TOOL FOR SUPPORTING MANAGEMENT OF FARM OPERATIONS IN PRECISION AGRICULTURE,"A modeling framework for evaluating the impact of weather conditions on farming and harvest operations applies real-time, field-level weather data and forecasts of meteorological and climatological conditions together with user-provided and/or observed feedback of a present state of a harvest-related condition to agronomic models and to generate a plurality of harvest advisory outputs for precision agriculture. A harvest advisory model simulates and predicts the impacts of this weather information and user-provided and/or observed feedback in one or more physical, empirical, or artificial intelligence models of precision agriculture to analyze crops, plants, soils, and resulting agricultural commodities, and provides harvest advisory outputs to a diagnostic support tool for users to enhance farming and harvest decision-making, whether by providing pre-, post-, or in situ-harvest operations and crop analyses.",A01G 7/00; A01D 91/00; G06N 99/00,"ITERIS, INC.","MEWES, John, J.; SALENTINY, Dustin, M.","14/603,378 23.01.2015 US; 14/603,380 23.01.2015 US; 14/603,381 23.01.2015 US; 14/603,382 23.01.2015 US; 14/603,383 23.01.2015 US; 14/603,384 23.01.2015 US; 14/603,385 23.01.2015 US; 14/842,852 02.09.2015 US; 14/842,853 02.09.2015 US; 14/842,854 02.09.2015 US",
WO2017037180,PCT/EP2016/070621,01.09.2016,WO/2017/037180,09.03.2017,WO,AUTOMATED ANALYSIS OF CELLULAR SAMPLES HAVING INTERMIXING OF ANALYTICALLY DISTINCT PATTERNS OF ANALYTE STAINING,"Systems and methods discussed herein include, among other things, a method comprising quantifying analyte staining of a biological compartment in a region in which said staining is intermixed with analyte staining of an analytically-distinct distinct biological compartment. Disclosed systems and methods include, for example, a system and method for identifying membrane staining of an analyte of interest in regions where diffuse membrane staining is intermixed with cytoplasmic staining and/or punctate staining is disclosed. Disclosed systems and methods include, for example, a system and method for quantifying membrane staining of an analyte of interest in tissue or cytological samples having regions in which membrane staining is intermixed with cytoplasmic staining and/or punctate staining.",G06K 9/00,"VENTANA MEDICAL SYSTEMS, INC.; F. HOFFMANN-LA ROCHE AG","NGUYEN, Kien; CHEFD'HOTEL, Christophe","62/213,284 02.09.2015 US",AU-2016313775; JP-2018511375; EP-2016767160
WO1993023822,PCT/US1993/004364,13.05.1993,WO/1993/023822,25.11.1993,WO,DYNAMICALLY STABLE ASSOCIATIVE LEARNING NEURAL NETWORK SYSTEM,"A dynamically stable associative learning neural network system includes, in its basic architectural unit, at least one each of a conditioned signal input, an unconditioned signal input and an output. Interposed between input and output elements are 'patches', or storage areas of dynamic interaction between conditioned and unconditioned signals which process information to achieve associative learning locally under rules designed for application-related goals of the system. Patches may be fixed or variable in size. Adjustments to a patch radius may be by 'pruning' or 'budding'. The neural network is taught by successive application of training sets of input signals to the input terminals until a dynamic equilibrium is reached. Enhancements and expansions of the basic unit result in multilayered (multi-subnetworked) systems having increased capabilities for complex pattern classification and feature recognition.",G06N 3/04,"THE UNITED STATES OF AMERICA, as represented by THE SECRETARY, DEPARTMENT OF HEALTH AND HUMAN SERVICES; ENVIRONMENTAL RESEARCH INSTITUTE OF MICHIGAN; ALKON, Daniel, L.; VOGL, Thomas, P.; BLACKWELL, Kim, T.; BARBOUR, Garth, S.","ALKON, Daniel, L.; VOGL, Thomas, P.; BLACKWELL, Kim, T.; BARBOUR, Garth, S.","07/882,646 13.05.1992 US",US-08331554
WO2018145015,PCT/US2018/016882,05.02.2018,WO/2018/145015,09.08.2018,WO,METHOD FOR CREATING AUDIO TRACKS FOR ACCOMPANYING VISUAL IMAGERY,"Methods of creating one or more audio objects to accompany a sequence of multimedia objects are disclosed. According to one embodiment, the method includes using a processor to analyze the multimedia objects and corresponding recorded metadata to generate derived metadata. The method further receives a selection of one or more analysis tools that are configured to analyze the recorded and derived metadata. Next, a selected subset of multimedia objects are identified and sequenced, which will ultimately be coupled to and accompanied by one or more audio objects. Lastly, an embodiment of the present invention generates an audio track to accompany the selected subset of multimedia objects.",G11B 27/031; G11B 27/28; G11B 27/10; G06F 17/30,KODAK ALARIS INC.,"WOOD, Mark D. III; WOOD, Peter D.","62/455,295 06.02.2017 US",CN-201880010311.2; EP-2018706350
WO2019097114,PCT/FI2018/050803,05.11.2018,WO/2019/097114,23.05.2019,WO,A METHOD FOR CLEANING OF A DEVICE,"The present invention relates to methods for cleaning of devices, such as heat exchangers, in particular to methods wherein machine learning systems, such as trained neural networks are used for indicating the fouling status during the cleaning processes.",F28G 7/00; B08B 3/12; B08B 9/032; G05B 13/02; F28G 15/00,ALTUM TECHNOLOGIES OY,"HÆGGSTRÖM, Edward; SALMI, Ari; KLAMI, Arto; MYLLYMÄKI, Petri; RAUHALA, Timo",20176017 14.11.2017 FI,
WO2009009692,PCT/US2008/069694,10.07.2008,WO/2009/009692,15.01.2009,WO,SEMANTIC REPRESENTATION MODULE OF A MACHINE-LEARNING ENGINE IN A VIDEO ANALYSIS SYSTEM,"A machine-learning engine is disclosed that is configured to recognize and learn behaviors, as well as to identify and distinguish between normal and abnormal behavior within a scene, by analyzing movements and/or activities (or absence of such) over time. The machine-learning engine may be configured to evaluate a sequence of primitive events and associated kinematic data generated for an object depicted in a sequence of video frames and a related vector representation. The vector representation is generated from a primitive event symbol stream and a phase space symbol stream, and the streams describe actions of the objects depicted in the sequence of video frames.",G06K 9/62,"BEHAVIORAL RECOGNITION SYSTEMS, INC.; EATON, John, Eric; COBB, Wesley, Kenneth; URECH, Dennis, G.; FRIEDLANDER, David, S.; XU, Gang; SEOW, Ming-jung; RISINGER, Lon, W.; SOLUM, David, M.; YANG, Tao; GOTTUMUKKAL, Rajkiran, K.; SAITWAL, Kishor, Adinath","EATON, John, Eric; COBB, Wesley, Kenneth; URECH, Dennis, G.; FRIEDLANDER, David, S.; XU, Gang; SEOW, Ming-jung; RISINGER, Lon, W.; SOLUM, David, M.; YANG, Tao; GOTTUMUKKAL, Rajkiran, K.; SAITWAL, Kishor, Adinath","60/949,107 11.07.2007 US; 12/170,268 09.07.2008 US; 12/170,283 09.07.2008 US",IN-718/DELNP/2010; EP-2008796147
WO2019136623,PCT/CN2018/072050,10.01.2018,WO/2019/136623,18.07.2019,WO,APPARATUS AND METHOD FOR SEMANTIC SEGMENTATION WITH CONVOLUTIONAL NEURAL NETWORK,"Systems, methods and apparatus are provided for sematic segmentation with convolutional neural networks. A system comprises a first encoder-decoder network, which is configured to perform a plurality of layers of convolution on a raw data material to generate a first set of feature maps. The system further comprises a group of middle encoder-decoder networks cascaded with the first encoder-decoder network. The group of middle encoder-decoder networks is configured to perform a plurality of layers of convolution on the first set of feature maps to generate a second set of feature maps for classifying objects of the raw data material.",G06K 9/00,"NOKIA TECHNOLOGIES OY; NOKIA TECHNOLOGIES (BEIJING) CO., LTD.","ZHANG, Zhijie",,
EP192656525,15828324,26.06.2015,3136305,01.03.2017,EP,LEARNING DEVICE UNIT,[Problem] To provide a learning device for performing more efficient machine learning.  [Solution] A learning device unit according to one embodiment comprises at least one learning device and a connection device for connecting an intermediate learning device having an internal state shared by another learning device unit to the at least one learning device.,G06N 99/00; G06F 3/08; G06N 3/04,PREFERRED NETWORKS INC,OKANOHARA DAISUKE; OKUTA RYOSUKE; MATSUMOTO EIICHI; KAWAAI KEIGO,2015068459 26.06.2015 JP; 2015115532 08.06.2015 JP,
WO2017096396,PCT/US2016/065001,05.12.2016,WO/2017/096396,08.06.2017,WO,RELOCALIZATION SYSTEMS AND METHODS,"A method of determining a pose of an image capture device includes capturing an image using an image capture device. The method also includes generating a data structure corresponding to the captured image. The method further includes comparing the data structure with a plurality of known data structures to identify a most similar known data structure. Moreover, the method includes reading metadata corresponding to the most similar known data structure to determine a pose of the image capture device.",G06T 7/80; G06F 3/03; G06F 15/18; G06F 17/30; G06K 9/20; G06K 9/52; G06K 9/60; G06K 9/70,"MAGIC LEAP, INC.","SCHROEDER, Brigit; MALISIEWICZ, Tomasz, J.; RABINOVICH, Andrew","62/263,529 04.12.2015 US",CA-3007367; EP-2016871733; AU-2016365422; KR-1020187019205; JP-2018528977; IL-259766
WO1991016686,PCT/CA1991/000139,26.04.1991,WO/1991/016686,31.10.1991,WO,ARTIFICIAL NEURAL DEVICE,An artificial neural device comprising a data storage and processing device for encoding data in an abstract form representative of stimulus-response patterns onto said data storage device whereby multiple stimulus-response patterns are superimposed onto said data storage device by said processing device; a device for decoding a previously encoded response associated with a stimulus when said data storage and processing device is stimulated by said stimulus.,G06N 3/04,"SUTHERLAND, John","SUTHERLAND, John","2,575,483 26.04.1990 CA",EP-1991908022
WO2016195912,PCT/US2016/031082,06.05.2016,WO/2016/195912,08.12.2016,WO,CONTEXT-SENSITIVE GENERATION OF CONVERSATIONAL RESPONSES,"Examples are generally directed towards context-sensitive generation of conversational responses. Context-message-response n-tuples are extracted from at least one source of conversational data to generate a set of training context-message-response n-tuples. A response generation engine is trained on the set of training context-message-response n-tuples. The trained response generation engine automatically generates a context-sensitive response based on a user generated input message and conversational context data. A digital assistant utilizes the trained response generation engine to generate context-sensitive, natural language responses that are pertinent to user queries.",G06F 17/28,"MICROSOFT TECHNOLOGY LICENSING, LLC","GALLEY, Michel; SORDONI, Alessandro; BROCKETT, Christopher John; GAO, Jianfeng; DOLAN, William Brennan; JI, Yangfeng; AULI, Michael; MITCHELL, Margaret Ann; NIE, Jian-Yun","14/726,562 31.05.2015 US",EP-2016723226
WO2018169708,PCT/US2018/020863,05.03.2018,WO/2018/169708,20.09.2018,WO,LEARNING EFFICIENT OBJECT DETECTION MODELS WITH KNOWLEDGE DISTILLATION,"A computer-implemented method executed by at least one processor for training fast models for real-time object detection with knowledge transfer is presented. The method includes employing a Faster Region-based Convolutional Neural Network (R-CNN) as an objection detection framework for performing the real-time object detection, inputting a plurality of images into the Faster R-CNN, and training the Faster R-CNN by learning a student model from a teacher model by employing a weighted cross-entropy loss layer for classification accounting for an imbalance between background classes and object classes, employing a boundary loss layer to enable transfer of knowledge of bounding box regression from the teacher model to the student model, and employing a confidence-weighted binary activation loss layer to train intermediate layers of the student model to achieve similar distribution of neurons as achieved by the teacher model.",G06N 3/08; G06N 3/04,"NEC LABORATORIES AMERICA, INC.","CHOI, Wongun; CHANDRAKER, Manmohan; CHEN, Guobin; YU, Xiang","62/472,841 17.03.2017 US; 15/908,870 01.03.2018 US",
WO2012158572,PCT/US2012/037668,11.05.2012,WO/2012/158572,22.11.2012,WO,EXPLOITING QUERY CLICK LOGS FOR DOMAIN DETECTION IN SPOKEN LANGUAGE UNDERSTANDING,"Domain detection training in a spoken language understanding system may be provided. Log data associated with a search engine, each associated with a search query, may be received. A domain label for each search query may be identified and the domain label and link data may be provided to a training set for a spoken language understanding model.",G06F 17/20; G06F 17/30; G10L 15/08,MICROSOFT CORPORATION,"HAKKANI-TUR, Dilek; HECK, Larry Paul; TUR, Gokhan","61/485,664 13.05.2011 US; 61/485,778 13.05.2011 US; 13/234,186 16.09.2011 US; 13/234,202 16.09.2011 US",EP-2012786677
WO2018142022,PCT/FI2018/050044,22.01.2018,WO/2018/142022,09.08.2018,WO,SELF-SHOPPING REFRIGERATOR,"The invention provides a refrigerator system (200), a method and a software program product for controlling and/or advising a diet for a user. The refrigerator system has a refrigerator (225, 226, 227, or 228) including a light (230, 231, 232, or 233) and a camera (235, 236, 237, or 238) that captures an image of contents of the refrigerator. The image is processed by a graphics processing unit (GPU) integrated with the refrigerator and/or a cloud server. The GPU (210 or 240) analyses the image to recognise a quantity, a quality, and/or a kind of food articles and/or food packages such as, vegetables, fruits, beverages, etc. A central processing unit (CPU)/GPU of the refrigerator provides diet plans, recipe recommendations, identifies grocery replenishment requirements, updates and shares shopping lists with food delivery agents, etc., based on the analysis of the refrigerator contents. The invention helps in minimizing food wastage, expanding meal options considering expiry dates, and maximizing benefits of a healthy diet by 20 recommending and controlling the user's diet.",G06Q 30/06; G06Q 10/08; G06Q 10/06; G06K 9/00; G06F 17/20; G06F 17/30; G06T 7/00; F25D 23/00; F25D 29/00,MIKKO VAANANEN,"VAANANEN, Mikko","62/452,403 31.01.2017 US; 15/453,912 09.03.2017 US",EP-2018747302
WO2018067080,PCT/TR2016/050374,10.10.2016,WO/2018/067080,12.04.2018,WO,A MARINE VESSEL IDENTIFICATION METHOD,"The present inversion relates to an identification method developed for identification of marine vessels using at least one silage. This method comprises the steps of obtaining the images of a large number of marine vessels of different classes from at least one source (1) and saving the images to a database; generating at least two superclasses according to the marine vessels in the saved images (2); obtaining models of said superclasses by means of deep learning (4); extracting the descriptors belonging to at least one query image (I) of at least one marine vessel and determining as to which superclass associated with said models said descriptors belong to, such that the marine vessel of said query Image (I) is classified (5).",G06K 9/00,ASELSAN ELEKTRONIK SANAYI VE TICARET ANONIM SIRKETI,"GUNDOGDU, Erhan; KOC, Aykut; SOLMAZ, Berkan; YUCESOY, Veysel",2016/14118 07.10.2016 TR,
WO2019134110,PCT/CN2018/071516,05.01.2018,WO/2019/134110,11.07.2019,WO,AUTONOMOUS DRIVING METHODS AND SYSTEMS,"Methods and systems are described for autonomously driving a vehicle. Sensor data is received from one or more sensors and a graphical representation of the sensor data is generated, which may comprise a driving situation map. The driving situation map may be represented using a logarithmic polar coordinate system comprising an angle dimension and a radius dimension. From the driving situation map, a graphical driving command is determined, which may comprise a graphically depicted arrow, referred to as a cognitive arrow. The vehicle is driven based on the graphical driving command to represent the desired controlling parameters. Pairs of driving situation maps as input with the cognitive arrows as the output may be used for end-to-end deep learning to train the algorithm for generating the cognitive arrow.",G05D 1/02; B60W 10/18,DRIVING BRAIN INTERNATIONAL LTD.,"LI, Deyi",,
WO2017161233,PCT/US2017/022902,17.03.2017,WO/2017/161233,21.09.2017,WO,DEEP MULTI-TASK REPRESENTATION LEARNING,"Technologies for analyzing multi-task multimodal data to detect multi-task multimodal events using a deep multi-task representation learning, are disclosed. A combined model with both generative and discriminative aspects is used to share information during both generative and discriminative processes. The technologies can be used to classify data and also to generate data from classification events. The data can then be used to morph data into a desired classification event.",G06N 5/04,SRI INTERNATIONAL,"AMER, Mohamed R.; SHIELDS, Timothy J.; TAMRAKAR, Amir; EHLRICH, Max; ALMAEV, Timur","62/309,804 17.03.2016 US",US-16085859
WO2001031579,PCT/US2000/029712,27.10.2000,WO/2001/031579,03.05.2001,WO,METHODS AND DEVICES FOR IDENTIFYING PATTERNS IN BIOLOGICAL PATTERNS,"The methods, systems and devices of the present invention comprise use of support vector machines for the identification of patterns that are important for medical diagnosis, prognosis and treatment. Such patterns may be found in many different datasets. The present invention also comprises methods and compositions for the treatment and diagnosis of medical conditions.",G06F 19/00; G06K 9/62,"BARNHILL TECHNOLOGIES, LLC; BARNHILL, Stephen, D.; GUYON, Isabelle; WESTON, Jason","BARNHILL, Stephen, D.; GUYON, Isabelle; WESTON, Jason","60/161,806 27.10.1999 US; 60/168,703 02.12.1999 US; 60/184,596 24.02.2000 US; 60/191,219 22.03.2000 US; 09/568,301 09.05.2000 US; 09/578,011 24.05.2000 US; 60/207,026 25.05.2000 US; 09/633,850 07.08.2000 US",
WO2009009697,PCT/US2008/069700,10.07.2008,WO/2009/009697,15.01.2009,WO,COGNITIVE MODEL FOR A MACHINE-LEARNING ENGINE IN A VIDEO ANALYSIS SYSTEM,"A machine-learning engine is disclosed that is configured to recognize and learn behaviors, as well as to identify and distinguish between normal and abnormal behavior within a scene, by analyzing movements and/or activities (or absence of such) over time. The machine-learning engine may be configured to evaluate a sequence of primitive events and associated kinematic data generated for an object depicted in a sequence of video frames and a related vector representation. The vector representation is generated from a primitive event symbol stream and a phase space symbol stream, and the streams describe actions of the objects depicted in the sequence of video frames.",G06K 9/00,"BEHAVIORAL RECOGNITION SYSTEMS, INC.; EATON, John Eric; COBB, Wesley Kenneth; URECH, Dennis G.; FRIEDLANDER, David S.; XU, Gang; SEOW, Ming-jung; RISINGER, Lon W.; SOLUM, David M.; YANG, Tao; GOTTUMUKKAL, Rajkiran K.; SAITWAL, Kishor Adinath","EATON, John Eric; COBB, Wesley Kenneth; URECH, Dennis G.; FRIEDLANDER, David S.; XU, Gang; SEOW, Ming-jung; RISINGER, Lon W.; SOLUM, David M.; YANG, Tao; GOTTUMUKKAL, Rajkiran K.; SAITWAL, Kishor Adinath","60/949,107 11.07.2007 US; 12/170,268 09.07.2008 US; 12/170,283 09.07.2008 US",IN-719/DELNP/2010; EP-2008781639
WO2017096067,PCT/US2016/064461,01.12.2016,WO/2017/096067,08.06.2017,WO,SPARSE NEURAL NETWORK CONTROL,"Aspects herein describe new methods of determining optimal actions to achieve high-level goals with minimum total future cost. At least one high-level goal is inputted into a user device along with various observational data about the world, and a computational unit determines, though a method comprising backward and forward sweeps, an optimal course of action as well as emotions. In one embodiment a user inputs a high-level goal into a cell phone which senses observational data. The cell phone communicates with a server that provides instructions. The server determines an optimal course of action via the method of backward and forward sweeps, and the cell phone then displays the instructions and emotions to the user.",G06N 99/00,"BURCHARD, Paul","BURCHARD, Paul","14/956,768 02.12.2015 US",
WO2015024002,PCT/US2014/051375,15.08.2014,WO/2015/024002,19.02.2015,WO,EMOTION AND APPEARANCE BASED SPATIOTEMPORAL GRAPHICS SYSTEMS AND METHODS,"A computer-implemented method of mapping. The method includes analyzing images of faces in a plurality of pictures to generate content vectors, obtaining information regarding one or more vector dimensions of interest, at least some of the one or more dimensions of interest corresponding to facial expressions of emotion, and generating a representation of the location. Appearance of regions in the map varies in accordance with values of the content vectors for the one or more vector dimensions of interest. The method also includes using the representation, the step of using comprising at least one of storing, transmitting, and displaying.",G06K 9/46; G09B 29/00,EMOTIENT,"MOVELLAN, Javier; SUSSKIND, Joshua","61/866,344 15.08.2013 US",EP-2014836610; JP-2016534880
EP275493182,19162692,13.03.2019,3561738,30.10.2019,EP,MACHINE LEARNING ACCELERATOR ARCHITECTURE,,G06N 3/063; G06N 3/04; G06N 3/08,INTEL CORP,DAGA BHARAT; JANEDULA PRADEEP; SRINIVASAN ARAVIND BABU; VENGALLUR AMBILI,201815960851 24.04.2018 US,
EP14460371,05253868,22.06.2005,1612719,04.01.2006,EP,"Method, apparatus, system, recording medium and computer program for situation recognition using optical information",A situation recognition apparatus includes: an optical information acquisition unit configured to acquire optical information; a storage configured to store a plurality of pieces of optical information; a processing unit configured to match a plurality of the pieces of optical information stored in the storage and optical information newly acquired by the optical information acquisition unit; and an output unit configured to output a result of the matching. The storage further stores a probabilistic model that numerically represents transitions between the plurality of pieces of optical information.,G06K 9/00; G06K 9/62; G06T 7/00,SONY CORP,CLARKSON BRIAN; MURATA MAKOTO; KOJIMA TAMAKI; ZHAO WENWU,2004191308 29.06.2004 JP; 2005000115 04.01.2005 JP,
WO2016012593,PCT/EP2015/067004,24.07.2015,WO/2016/012593,28.01.2016,WO,METHOD AND SYSTEM FOR OBJECT DETECTION WITH MULTI-SCALE SINGLE PASS SLIDING WINDOW HOG LINEAR SVM CLASSIFIERS,The invention provides methods and systems for reliably detecting objects in a received video stream from a camera. Objects are selected and a bound around selected objects is calculated and displayed. Bounded objects can be tracked. Bounding is performed by using Histogram of Oriented Gradients and linear Support Vector Machine classifiers.,G06K 9/00; G06K 9/46; G06K 9/62,AGT INTERNATIONAL GMBH,"ABAD, Pablo; KRAUSS, Stephan; HIRZEL, Jan; STRICKER, Didier; HAMER, Henning; SCHLATTMANN, Markus","62/028,667 24.07.2014 US",
WO2019045802,PCT/US2018/032538,14.05.2018,WO/2019/045802,07.03.2019,WO,DISTANCE METRIC LEARNING USING PROXIES,"The present disclosure provides systems and methods that enable distance metric learning using proxies. A machine-learned distance model can be trained in a proxy space in which a loss function compares an embedding provided for an anchor data point of a training dataset to a positive proxy and one or more negative proxies, where each of the positive proxy and the one or more negative proxies serve as a proxy for two or more data points included in the training dataset. Thus, each proxy can approximate a number of data points, enabling faster convergence. According to another aspect, the proxies of the proxy space can themselves be learned parameters, such that the proxies and the model are trained jointly. Thus, the present disclosure enables faster convergence (e.g., reduced training time). The present disclosure provides example experiments which demonstrate a new state of the art on several popular training datasets.",G06K 9/46; G06K 9/66; G06K 9/62,GOOGLE LLC,"MOYSHOVITZ-ATTIAS, Yair; LEUNG, King Hong; SINGH, Saurabh; TOSHEV, Alexander; IOFFE, Sergey","15/690,426 30.08.2017 US; 15/710,377 20.09.2017 US",
WO2019138074,PCT/EP2019/050693,11.01.2019,WO/2019/138074,18.07.2019,WO,DATA EXTRACTION PIPELINE,A computer-implemented method for classifying a document type of a document in an image and extracting data from the classified document comprising acquiring image data that comprises data relating to at least a part of the document. Textual classification of the document image is then attempted by machine recognition of textual characters to obtain classification data; and using the classification data to classify the document in the image.,G06K 9/00,ONFIDO LTD,"CALI, Jacques; ROELANTS, Peter; SAGONAS, Christos; SABATHE, Romain",18151489.4 12.01.2018 EP,
WO2018150901,PCT/JP2018/003499,25.01.2018,WO/2018/150901,23.08.2018,WO,SHAPE ESTIMATING APPARATUS,"In order to estimate a three-dimensional shape of a subject from a two-dimensional image, a shape estimating apparatus includes an acquiring unit and an estimating unit. The acquiring unit is configured to acquire a two-dimensional image. The estimating unit has artificial intelligence, and is configured to provide the artificial intelligence with the two-dimensional image and cause the artificial intelligence to estimate a three-dimensional shape of a subject of the two-dimensional image. A learning result of machine learning performed using learning data containing supervisor data expressing a three-dimensional shape of a sample subject and a sample two-dimensional image obtained by capturing an image of the three-dimensional shape of the sample subject is set to the artificial intelligence.",G01B 11/24; G06K 9/00,OMRON CORPORATION,"ANDO, Tanichi",2017-029248 20.02.2017 JP,CN-201880006147.8; EP-2018709087
WO2020041228,PCT/US2019/047134,20.08.2019,WO/2020/041228,27.02.2020,WO,NEUROMUSCULAR ENHANCEMENT SYSTEM,"A neuromuscular enhancement system comprising engineered textile structures is worn by a user to increase strength, preserve energy, and increase motion accuracy. The system can be used in surgery and interface with operating room technology, together providing the surgeon with the ability to perform surgery for longer hours and with increased accuracy. The enhancement system is a flexible structure, worn over the user's body, comprising engineered textile materials that apply forces to different areas of the user's body. The engineered materials can be activated in order to apply a force to a particular region of the body to assist in a desired user output. The engineered materials can be embedded with sensors to detect and monitor motion and other physical properties. The engineered materials can also be embedded with a communication system that conveys information between a computer system and the neuromuscular enhancement system and its various sensors and components. The enhancement system here can be configured for use in applications other than surgery.",A61B 5/11; A41D 1/00; A61B 5/04,"SAFAVI-ABBASI, Sam; HARTMAN, Brent; REYES, Phillip","SAFAVI-ABBASI, Sam; HARTMAN, Brent; REYES, Phillip","62/719,761 20.08.2018 US",
WO2018194939,PCT/US2018/027674,13.04.2018,WO/2018/194939,25.10.2018,WO,POWER-EFFICIENT DEEP NEURAL NETWORK MODULE CONFIGURED FOR LAYER AND OPERATION FENCING AND DEPENDENCY MANAGEMENT,"A deep neural network (DNN) processor is configured to execute layer descriptors in layer descriptor lists. The descriptors define instructions for performing a forward pass of a DNN by the DNN processor. The layer descriptors can also be utilized to manage the flow of descriptors through the DNN module. For example, layer descriptors can define dependencies upon other descriptors. Descriptors defining a dependency will not execute until the descriptors upon which they are dependent have completed. Layer descriptors can also define a ""fence,"" or barrier, function that can be used to prevent the processing of upstream layer descriptors until the processing of all downstream layer descriptors is complete. The fence bit guarantees that there are no other layer descriptors in the DNN processing pipeline before the layer descriptor that has the fence to be asserted is processed.",G06N 3/063; G06F 9/48,"MICROSOFT TECHNOLOGY LICENSING, LLC","MCBRIDE, Chad Balling; AMBARDEKAR, Amol Ashok; CEDOLA, Kent D.; PETRE, George; WALL, Larry Marvin; BOBROV, Boris","62/486,432 17.04.2017 US; 15/950,550 11.04.2018 US",EP-2018721658; CN-201880025488.X
WO2019108846,PCT/US2018/063146,29.11.2018,WO/2019/108846,06.06.2019,WO,ULTRASOUND ANALYTICS FOR ACTIONABLE INFORMATION,"Systems and techniques are described for gathering information on the health of individuals trapped in an accident to provide actionable information to a first responder system. In some implementations, a monitoring system monitors a property that includes sensors located at the property and generate first sensor data. A monitor control unit receives the first sensor data and generates an alarm event for the property based on the first sensor data. Based on generating the alarm event for the property, the monitor control unit dispatches an autonomous drone. The autonomous drone is configured to navigate the property. Using an onboard sensor, the autonomous drone generates second sensor data. Based on the second sensor data, the autonomous drone determines a location within the property where a person is likely located. The autonomous drone provides, for output, data indicating the location within the property where the person is likely located.",G05D 1/00; B64C 39/02; G01S 15/00; A61B 5/00; G08B 25/00,"DJIOFACK, Innocent","DJIOFACK, Innocent","62/591,920 29.11.2017 US",
WO2006015002,PCT/US2005/026564,27.07.2005,WO/2006/015002,09.02.2006,WO,BIOLOGICAL INTERFACE SYSTEM WITH CLINICIAN CONFIRMATION OF PARAMETER CHANGES,A system and method for a biological interface system (100) that processes multicellular signals of a patient (500) and controls an external device (300) is disclosed. The system includes a sensor that detects the multicellular signals and a processing unit for producing the control signal based on the multicellular signals. The system further includes a permission routine that requires an approval of a clinician or other specific operator of the system when specific system parameters are changed. Embedded automatic and semi-automatic calibration and configuration systems are also disclosed.,A61B 5/04,"CYBERKINETICS NEUROTECHNOLOGY SYSTEMS, INC.; FLAHERTY, J. Christopher; CAPLAN, Abraham, H.; GORMAN, William, J.; MCNALLY, Caroline, P.; SERRUYA, Mijail, D.; DONOGHUE, John, P.","FLAHERTY, J. Christopher; CAPLAN, Abraham, H.; GORMAN, William, J.; MCNALLY, Caroline, P.; SERRUYA, Mijail, D.; DONOGHUE, John, P.","60/592,275 29.07.2004 US",EP-2005781250
WO2019082166,PCT/IB2018/058411,26.10.2018,WO/2019/082166,02.05.2019,WO,UNIT-LEVEL UNCERTAINTY AND PROPAGATION,"Neural Networks such as Deep Neural Networks (DNNs) output calibrated probabilities that substantially represent frequencies of occurrences of events. A DNN propagates uncertainty information of a unit of the DNN from an input to an output of the DNN. The uncertain information measures a degree of consistency of the test data with training data used to train a DNN. The uncertainty information of all units of the DNN can be propagated. Based on the uncertainty information, the DNN outputs probability scores that reflect received input data that is substantially different from the training data.",G06N 3/08; G06N 3/04,"UBER TECHNOLOGIES, INC.","GHAHRAMANI, Zoubin","62/577,631 26.10.2017 US",
WO2019236764,PCT/US2019/035669,05.06.2019,WO/2019/236764,12.12.2019,WO,CONFIDENCE-BASED APPLICATION-SPECIFIC USER INTERACTIONS,"This application is directed to a method for controlling user experience (UX) operations on an electronic device that executes an application. A touchless UX operation associated with the application has an initiation condition including at least detection of a presence and a gesture in a required proximity range with a required confidence level. The electronic device then determines from a first sensor signal the proximity of the presence with respect to the electronic device. In accordance with a determination that the determined proximity is in the required proximity range, the electronic device determines from a second sensor signal a gesture associated with the proximity of the presence and an associated confidence level of the determination of the gesture. In accordance with a determination that the determined gesture and associated confidence level satisfy the initiation condition, the electronic device initializes the touchless UX operation associated with the application.",G01V 8/00; G06K 9/00; G06F 3/01,GOOGLE LLC,"UDALL, Ashton; FELCH, Andrew; TOBIN, James","PCT/US2018/064449 07.12.2018 US; 62/680,982 05.06.2018 US; 62/742,892 08.10.2018 US; PCT/US2018/048780 30.08.2018 US; PCT/US2019/028601 23.04.2019 US; 62/844,677 07.05.2019 US",
WO2013050749,PCT/GB2012/052432,02.10.2012,WO/2013/050749,11.04.2013,WO,ASSISTIVE DEVICE FOR CONVERTING AN AUDIO SIGNAL INTO A VISUAL REPRESENTATION,"A device for converting an audio signal into a visual representation, the device comprising at least one receiver for receiving the audio signal; a signal processing unit for processing the received audio signal; a converter for converting the processed audio signal into a visual representation; and projecting means for projecting the visual representation onto a display, wherein the display comprises an embedded grating structure.",G02B 27/01; G10L 21/06; G10L 15/26,"KANEGAONKAR, Rahul Govind","CLARKE, Roger; RIX, Anthony William",1116994.3 03.10.2011 GB,US-14348221; EP-2012790622
WO2006120195,PCT/EP2006/062168,09.05.2006,WO/2006/120195,16.11.2006,WO,METHOD FOR CODING PIXELS OR VOXELS OF A DIGITAL IMAGE AND A METHOD FOR PROCESSING DIGITAL IMAGES,"A method for coding pixels or voxels of a digital or digitalized two dimensional or three dimensional image, comprises the steps of: providing a digital image consisting in a two dimensional array of pixels or in a three dimensional array of voxels, each pixel or voxel being defined by at least one variable as its intensity in a grey scale image or the HSV (Hue, Saturation and Value) or the RGB values in a colour image; each pixel or voxel of the image being considered as a target pixel or voxel and for each target pixel or voxel a neighborhood being formed by a pixel or voxel windows comprising the said target pixel or voxel and a certain number of surrounding pixels or voxels for each target pixel or voxel generating a vector univocally associated to the said target pixel or voxel, the components of the said vectors being generated as a function of the values of the said target pixel or voxel and of each of the pixels or voxels of the said pixel or voxel window. The function of the values of the said target pixel or voxel and of each of the pixels or voxels of the said pixel or voxel window correspond to the characteristic parameters of the numerical matrix representing the pixels or voxels of the said window or of a transformation of the said numerical matrix. The invention relates also to an image processing method in which image data coded according to the above method are processed by means of a predictive algorithm as for example an artificial neural network.",G06T 9/00; G06K 9/00,"BRACCO IMAGING S.P.A.; GORI, Ilaria; MATTIUZZI, Marco","GORI, Ilaria; MATTIUZZI, Marco",05425316.6 12.05.2005 EP,EP-2006755108; DE-null; US-11913554; JP-2008510570; CN-200680016189.7; RU-null
WO2017199088,PCT/IB2017/000665,16.05.2017,WO/2017/199088,23.11.2017,WO,BALE DETECTION AND CLASSIFICATION USING STEREO CAMERAS,"An apparatus comprises a sensor (102) comprising a left camera (102a) and a right camera (102b). A processor (104) is coupled to the sensor. The processor is configured to produce an image and disparity data for the image, and search for a vertical object (122a, 122b) within the image using the disparity data. The processor is also configured to determine whether the vertical object is a bale of material using the image, and compute an orientation of the bale relative to the sensor using the disparity data. The sensor and processor can be mounted for use on an autonomous bale mover comprising an integral power system, a ground-drive system, a bale loading system, and a bale carrying system.",G06K 9/46; A01D 90/02,VERMEER MANUFACTURING COMPANY,"FEVOLD, Jake; DUPONT, Edmond; KROZAK, Kris; DUX, Darin, L.; GRAHAM, Curt; THOMPSON, Kent","62/338,781 19.05.2016 US",CA-3024573; EP-2017730918
WO2016118685,PCT/US2016/014211,21.01.2016,WO/2016/118685,28.07.2016,WO,"DIAGNOSIS AND PREDICTION OF IN-FIELD DRY-DOWN OF A MATURE SMALL GRAIN, COARSE GRAIN, OR OILSEED CROP USING FIELD-LEVEL ANALYSIS AND FORECASTING OF WEATHER CONDITIONS, CROP CHARACTERISTICS, AND OBSERVATIONS AND USER INPUT OF HARVEST CONDITION STATES","A modeling framework for evaluating the impact of weather conditions on farming and harvest operations applies real-time, field-level weather data and forecasts of meteorological and climatological conditions together with user-provided and/or observed feedback of a present state of a harvest-related condition to agronomic models and to generate a plurality of harvest advisory outputs for precision agriculture. A harvest advisory model simulates and predicts the impacts of this weather information and user-provided and/or observed feedback in one or more physical, empirical, or artificial intelligence models of precision agriculture to analyze crops, plants, soils, and resulting agricultural commodities, and provides harvest advisory outputs to a diagnostic support tool for users to enhance farming and harvest decision-making, whether by providing pre-, post-, or in situ-harvest operations and crop analyses.",A01G 7/00; A01D 91/00; G06N 99/00,"ITERIS, INC.","MEWES, John, J.; SALENTINY, Dustin, M.","14/603,378 23.01.2015 US; 14/603,380 23.01.2015 US; 14/603,381 23.01.2015 US; 14/603,382 23.01.2015 US; 14/603,383 23.01.2015 US; 14/603,384 23.01.2015 US; 14/603,385 23.01.2015 US; 14/842,852 02.09.2015 US; 14/842,853 02.09.2015 US; 14/842,854 02.09.2015 US",
EP249469768,18209316,29.11.2018,3518176,31.07.2019,EP,"MACHINE LEARNING SPARSE COMPUTATION MECHANISM FOR ARBITRARY NEURAL NETWORKS, ARITHMETIC COMPUTE MICROARCHITECTURE, AND SPARSITY FOR TRAINING MECHANISM",,G06T 1/20,INTEL CORP,NURVITADHI ERIKO; BLEIWEISS AMIT; MARR DEBORAH; WANG EUGENE; DWARAKAPURAM SARITHA; GANAPATHY SABAREESH,201715859203 29.12.2017 US,
WO2017132169,PCT/US2017/014775,24.01.2017,WO/2017/132169,03.08.2017,WO,METHODS AND APPARATUS FOR DETECTING AN INTERFERENT IN A SPECIMEN,"A model-based method of inspecting a specimen for presence of an interferent (H, I, and/or L). The method includes capturing images of the specimen at multiple different exposures times and at multiple spectra having different nominal wavelengths, selection of optimally-exposed pixels from the captured images to generate optimally-exposed image data for each spectra, identifying a serum or plasma portion of the specimen, and classifying whether an interferent is present or absent within the serum or plasma portion. Testing apparatus and quality check modules adapted to carry out the method are described, as are other aspects.",G01N 21/51; G01N 21/55; G01N 21/59; G01N 27/416; G01N 33/487,SIEMENS HEALTHCARE DIAGNOSTICS INC.,"KLUCKNER, Stefan; CHANG, Yao-jen; CHEN, Terrence; POLLACK, Benjamin, S.; WISSMANN, Patrick","62/288,375 28.01.2016 US",EP-2017744780; JP-2018539287
EP236237970,17827218,26.04.2017,3428878,16.01.2019,EP,IMAGE RECOGNITION SYSTEM,"An image recognition system includes a first computer for detecting a recognition target from image data, and a second computer for identifying the recognition target detected by the first computer. The first computer and the second computer are disposed at positions physically separated from each other. When the first computer sends image data to the second computer, the second computer sends to the first computer a detection parameter group used for detection via a communication path. The detection parameter group is included in a recognition parameter group that is dynamically changed and used for image recognition processing of the image data.",G06K 9/00,PANASONIC IP MAN CO LTD,TAKAHATA ATSUSHI,2016140341 15.07.2016 JP; 2017016516 26.04.2017 JP,
WO2019127108,PCT/CN2017/119027,27.12.2017,WO/2019/127108,04.07.2019,WO,KEY-POINT GUIDED HUMAN ATTRIBUTE RECOGNITION USING STATISTIC CORRELATION MODELS,"Techniques are provided for neural network based, human attribute recognition, guided by anatomical key-points and statistic correlation models. Attributes include characteristics that can be visibly identified or inferred from an image, such as gender, hairstyle, clothing style, etc. A methodology implementing the techniques according to an embodiment includes applying an attribute feature extraction (AFE) convolutional neural network (CNN) to an image of a human to generate attribute feature maps based on the image. The method further includes applying a key-point guided proposal (KPG) CNN to the image of the human to generate proposed hierarchical regions of the image based on associated anatomical key-points. The method further includes generating recognition probabilities for the human attributes using a CNN combination layer that incorporates the attribute feature maps, the proposed hierarchical regions, and statistical correlation models (SCMs) which provide correlations between the features of the attribute feature maps and the proposed hierarchical regions.",G06K 9/00,"INTEL CORPORATION; HU, Ping; YAO, Anbang; WEI, Jia; CAI, Dongqi; CHEN, Yurong","HU, Ping; YAO, Anbang; WEI, Jia; CAI, Dongqi; CHEN, Yurong",,
WO2018154359,PCT/IB2017/051076,24.02.2017,WO/2018/154359,30.08.2018,WO,"LEARNING DATA ACQUIRING APPARATUS AND METHOD, PROGRAM, AND STORING MEDIUM","The present invention relates to a learning data acquiring apparatus and method, program, and storing medium. The learning data acquiring apparatus is configured to acquire learning data about learning objects for machine learning, and comprises: a learning data acquiring portion, acquiring the learning data about the learning objects according to learning condition information, the learning condition information being information generated according to commission information of user commissioned learning; and a modification instructing portion, modifying setting of the learning data acquiring portion for acquiring the learning data according to the learning condition information. By modifying various settings according to the learning condition information, the system resources of the local computer or the server may be saved, and the learning data acquiring efficiency may be improved.",G06K 9/00,OMRON CORPORATION,"ANDO, Tanichi",,EP-2017711007; CN-201780069751.0
WO2011152844,PCT/US2010/044142,02.08.2010,WO/2011/152844,08.12.2011,WO,IMAGE CLUSTERING USING A PERSONAL CLOTHING MODEL,"The disclosure relates to a system and a method for generating clothing feature data representative of at least one clothing feature of a piece of clothing being worn by the person in a set of images, and training a discriminative clothing classifier using the clothing feature data to provide a personal clothing model that corresponds to the piece of clothing. The personal clothing model can be used to identify additional images in which the person appears.",G06K 9/46; G06T 7/40,"HEWLETT-PACKARD DEVELOPMENT COMPANY, L.P.; ZHANG, Tong; ZHANG, Wei; TRETTER, Daniel","ZHANG, Tong; ZHANG, Wei; TRETTER, Daniel","61/350,464 01.06.2010 US",US-13700820
EP289344312,18191826,30.08.2018,3617948,04.03.2020,EP,CAPSULE NETWORKS FOR ANALYZING MEDICAL IMAGE DATA,"A system and method includes acquisition of one or more images of each of a plurality of bodies, each of the images associated with an acquisition time, determination, for each body, of a future health status of the body, the future health status of the body being a health status of the body at a time after the acquisition time of the one or more images of the body, and training of an artificial neural network to output a predicted health status, the training based on the one or more images and determined future health status of each body.",G06K 9/62,SIEMENS HEALTHCARE GMBH,,18191826 30.08.2018 EP,
WO2019010183,PCT/US2018/040721,03.07.2018,WO/2019/010183,10.01.2019,WO,DEEP VISION PROCESSOR,"Disclosed herein is a processor for deep learning. In one embodiment, the processor comprises: a load and store unit configured to load and store image pixel data and stencil data; a register unit, implementing a banked register file, configured to: load and store a subset of the image pixel data from the load and store unit, and concurrently provide access to image pixel values stored in a register file entry of the banked register file, wherein the subset of the image pixel data comprises the image pixel values stored in the register file entry; and a plurality of arithmetic logic units configured to concurrently perform one or more operations on the image pixel values stored in the register file entry and corresponding stencil data of the stencil data.",G06K 9/56; G06T 5/20,"DEEP VISION, INC.","QADEER, Wajahat; HAMEED, Rehan","62/528,796 05.07.2017 US",
WO2017205537,PCT/US2017/034322,24.05.2017,WO/2017/205537,30.11.2017,WO,GENERATING SIMULATED IMAGES FROM INPUT IMAGES FOR SEMICONDUCTOR APPLICATIONS,Methods and systems for generating a simulated image from an input image are provided. One system includes one or more computer subsystems and one or more components executed by the one or more computer subsystems. The one or more components include a neural network that includes two or more encoder layers configured for determining features of an image for a specimen. The neural network also includes two or more decoder layers configured for generating one or more simulated images from the determined features. The neural network does not include a fully connected layer thereby eliminating constraints on size of the image input to the two or more encoder layers.,G01N 21/95; G06T 7/00,KLA-TENCOR CORPORATION,"ZHANG, Jing; BHASKAR, Kris","62/341,548 25.05.2016 US; 15/603,249 23.05.2017 US",IL-262672; JP-2018561506; KR-1020187037530; EP-2017803526
WO2004111934,PCT/CA2004/000891,16.06.2004,WO/2004/111934,23.12.2004,WO,SEGMENTATION AND DATA MINING FOR GEL ELECTROPHORESIS IMAGES,"A segmentation method is provided for the automated segmentation of spot-light structures into D images allowing precise quantification and classification of said structures and said images, based on a plurality of criteria, and further allowing the automated identification of multi-spot based patterns present in one or a plurality of images. In a preferred embodiment, the invention is used for the analysis of 2D gel electrophoresis images, with objective of quantifying protein expressions and for allowing sophisticated multi-protein pattern based image data mining, as well as image matching, registration, and automated classification.",G06T 5/00; G06T 7/00,"DYNAPIX INTELLIGENCE IMAGING INC.; BOUDREAU, Alexandre, J.; DUBE, Patrick; KAUFFMANN, Claude; EL ABIDINE, Khaldoune, Zine","BOUDREAU, Alexandre, J.; DUBE, Patrick; KAUFFMANN, Claude; EL ABIDINE, Khaldoune, Zine","60/478,766 16.06.2003 US",JP-2006517913; US-2006257053; CA-2531126; EP-2004737830; US-10563706; JP-null; CN-200480021630.1
WO2018162933,PCT/GB2018/050622,12.03.2018,WO/2018/162933,13.09.2018,WO,IMPROVED OBJECT RECOGNITION SYSTEM,"According to an aspect of the present invention there is provided a method of identifying a potential obstacle to a moving vehicle, during a vehicle driving period. The method may comprise: receiving a first image of an environment in which the vehicle is located during the driving period from an image capture device, the environment comprising one or more objects physically located within the environment; receiving an optical signal from an optical distance measurement device, the optical signal having been reflected from one or more objects physically located within the environment, the optical signal comprising one or more optical signal data points; determining a distance value associated with one or more of the optical signal data points; selecting the optical signal data points associated with a distance value equal to or less than a predetermined threshold value; selecting a plurality of image pixels comprised within the received image associated with the selected optical signal data points; and identifying the one or more objects associated with the selected plurality of image pixels comprised within the received first image from an analysis of the selected plurality of image pixels. The first image of the environment may comprise a viewpoint of the environment with respect to a reference point. The first image may comprise a point-of-view image from the viewpoint of the vehicle, e.g. an image of the vehicle's field of view (FOV). The viewpoint of the environment may comprise at least a portion of the environment comprised within the vehicle's intended travel path. In this way the first image comprises objects that could potentially pose an obstacle to the vehicle based on its intended travel path.",G06K 9/00,"ARTIFICIAL INTELLIGENCE RESEARCH GROUP LIMITED; ARONSON, Bill","AVNI, Yossi; SUCHARD, Eytan",1703908.2 10.03.2017 GB,
WO1993013487,PCT/US1992/008319,30.09.1992,WO/1993/013487,08.07.1993,WO,RAPIDLY CONVERGING PROJECTIVE NEURAL NETWORK,"A data processing system and method for solving pattern classification problems and function-fitting problems includes a neural network in which N-dimensional input vectors (24) are augmented with at least one element to form an N+j-dimensional projected input vector (26) whose magnitude is normalized to lie on the surface of a hypersphere. Weight vectors of a lowest intermediate layer of network nodes are constrained to lie on the N+j-dimensional surface. To train the network, the system compares network output values with known goal vectors and an error function is minimized. The weight vectors for intermediate nodes are initially set equal to known prototypes for the various classes of input vectors. Furthermore, the invention allows separation of the network into sub-networks, which are trained individually and later recombined. The network is able to use both hyperspheres and hyperplanes to form decision boundaries.",G06N 3/04,R & D ASSOCIATES,"MANUKIAN, Narbik; WILENSKY, Gregg, D.","814,357 27.12.1991 US",EP-1992922053
WO2019122995,PCT/IB2017/058493,28.12.2017,WO/2019/122995,27.06.2019,WO,METHOD AND SYSTEM FOR PERSONALIZED SELF CAPABILITY AWARE ROUTE PLANNING IN AUTONOMOUS DRIVING VEHICLES,"The present teaching relates to method, system, medium, and implementation of route planning for an autonomous driving vehicle. A source location and a destination location are first obtained, where the destination location is where the autonomous driving vehicle is to drive to. One or more available routes between the source location and the destination location are identified. A self-aware capability model is instantiated with respect to the one or more available routes and is predictive of the operational capability of the autonomous driving vehicle with respect to each of the one or more available routes. The preference of a passenger present in the autonomous driving vehicle is determined in terms of a route to take for the autonomous vehicle to drive to the destination location. Based on the self-aware capability model and the preference of the passenger, a planned route to the destination location is then automatically selected for the autonomous driving vehicle.",G01C 21/34; B60W 40/08; G01C 21/36; G05D 1/02,PLUSAI CORP,"GANGULI, Anurag; DALY, JR., Timothy Patrick; ZHENG, Hao; LIU, David Wanqian","15/845,173 18.12.2017 US; 15/856,113 28.12.2017 US",
WO2018194848,PCT/US2018/026355,06.04.2018,WO/2018/194848,25.10.2018,WO,MINIMIZING MEMORY READS AND INCREASING PERFORMANCE OF A NEURAL NETWORK ENVIRONMENT USING A DIRECTED LINE BUFFER,"The performance of a neural network (NN) and/or deep neural network (DNN) can limited by the number of operations being performed as well as management of data among the various memory components of the NN/DNN. Using a directed line buffer that operatively inserts one or more shifting bits in data blocks to be processed, data read/writes to the line buffer can be optimized for processing by the NN/DNN thereby enhancing the overall performance of a NN/DNN. Operatively, an operations controller and/or iterator can generate one or more instructions having a calculated shifting bit(s) for communication to the line buffer. Illustratively, the shifting bit(s) can be calculated using various characteristics of the input data as well as the NN/DNN inclusive of the data dimensions. The line buffer can read data for processing, insert the shifting bits and write the data in the line buffer for subsequent processing by cooperating processing unit(s).",G06F 15/80,"MICROSOFT TECHNOLOGY LICENSING, LLC","PETRE, George; MCBRIDE, Chad, Balling; AMBARDEKAR, Amol, Ashok; CEDOLA, Kent, D.; BOBROV, Boris; WALL, Larry, Marvin","62/486,432 17.04.2017 US; 15/786,514 17.10.2017 US",CN-201880025415.0; EP-2018720861
WO1991017525,PCT/AU1991/000183,30.04.1991,WO/1991/017525,14.11.1991,WO,ELECTRONIC SYSTEM FOR CLASSIFYING OBJECTS,"A frequency-domain pattern-recognition system is provided for the real-time classification of diverse populations of objects where the classification of a sub-set of the population has been predetermined. Adjustment of system parameters is automatically performed during an initial training phase using the sub-set objects to optimise, with respect to classification accuracy and speed, (i) the match between the predetermined and the assessed classifications and (ii) the distinction between the assessed classes. Frequency-domain vectors characteristic of each class are extracted from frequency-domain transforms of time-domain data derived from the objects and are stored for operational use, together with their associated parameter settings. In operation, a microprocessor controller (30) loads parameter settings, for the population of objects to be classified, from a preset memory (34) into a time-domain image capture and preprocessing circuit (18), the transform vector generator (26) and a comparator circuit (28). Time-domain images of objects (10) passing on a production line (12) are captured, digitised and preprocessed (in circuit 18) and fed to a transform vector generator (26), the output of which is compared by a comparator (28) with stored class vectors to identify the class to which the object under inspection should be assigned. Adjustment of system parameters, vector extraction and vector comparison may be placed under the control of artificial neural networks, the parameters of which are, in turn, determined by the microprocessor controller.",G06K 9/66,"IMPACQ TECHNOLOGIES, INC.; GRANT, Paul, Ainsworth; BELILOVE, James, Robert; GLOVER, David, Eugene; HEKKER, Roeland, Michael, Theodorus; WRATHALL, Edward; BUCK, Robert, David","BELILOVE, James, Robert; GLOVER, David, Eugene; HEKKER, Roeland, Michael, Theodorus; WRATHALL, Edward; BUCK, Robert, David",PJ 9913 30.04.1990 AU,
EP289345059,17929793,27.10.2017,3616619,04.03.2020,EP,METHOD OF PREPARING RECOMMENDATIONS FOR TAKING DECISIONS ON THE BASIS OF A COMPUTERIZED ASSESSMENT OF THE CAPABILITIES OF USERS,"The present technical solution in general relates to methods and systems of computer technology, in particular to automated computer methods and systems which help users and companies to take decisions on the basis of a computerized assessment of user capabilities. A method for preparing recommendations for taking decisions on the basis of a computerized assessment of the personality and capabilities of users, in which a user is given access to at least one computerized task for the execution thereof; emotions of the user are identified in real time during the execution of the at least one task by means of at least one video camera; data are obtained about the user's execution of the at least one task; at least one capability of the user is determined on the basis of data obtained after the at least one task is executed and the identified emotions of the user; recommendations for the user are formulated for taking decisions on the basis of the at least one capability determined in the preceding step. The technical effect is to raise the completeness, accuracy and speed of evaluating user capabilities.",A61B 5/16; A61B 5/02,WEHIREAI INC,MIKHAJLOV IGOR' VALENTINOVICH,2017000791 27.10.2017 RU; 2017137534 27.10.2017 RU,
WO2018022597,PCT/US2017/043686,25.07.2017,WO/2018/022597,01.02.2018,WO,METHODS AND APPARATUS FOR INFERRING USER INTENT BASED ON NEUROMUSCULAR SIGNALS,"Methods and system for predicting the onset of a motor action using neuromuscular signals. The system comprises a plurality of sensors configured to continuously record a plurality of neuromuscular signals from a user and at least one computer processor programmed to provide as input to a trained statistical model, the plurality of neuromuscular signals or information based on the plurality of neuromuscular signals, predict, based on an output of the trained statistical model, whether an onset of a motor action will occur within a threshold amount of time; and send a control signal to at least one device based, at least in part, on the output probability, wherein the control signal is sent to the at least one device prior to completion of the motor action by the user.",A61B 5/0488; A61B 5/05; A61B 5/11; A61B 5/22; A61F 2/60; A61F 2/68; A61F 2/72,"CTRL-LABS CORPORATION; KAIFOSH, Patrick; MACHADO, Tim; REARDON, Thomas; SCHOMBURG, Erik","KAIFOSH, Patrick; MACHADO, Tim; REARDON, Thomas; SCHOMBURG, Erik","62/366,419 25.07.2016 US",CN-201780059101.8; EP-2017835111
WO1999026126,PCT/GB1998/003441,16.11.1998,WO/1999/026126,27.05.1999,WO,USER INTERFACE,A gaze tracker for a multimodal user interface uses a standard videoconferencing set on a workstation to determine where a user is looking on a screen. The gaze tracker uses the video camera (100) to make a quantised image of the user's eye. The pupil is detected in the quantised image and a neural net (125) is used in training the gaze tracker to detect gaze direction. A pre-processor (115) may be used to improve the input to the neural net. A Bayesian net (140) is used to learn the relationship between response time and accuracy for the output of the neural net so that a user's externally set preference can be accommodated.,A61B 3/113; G06F 3/00; G06K 9/00,"BRITISH TELECOMMUNICATIONS PUBLIC LIMITED COMPANY; AZVINE, Behnam; DJIAN, David; TSUI, Kwok, Ching; XU, Li-Qun","AZVINE, Behnam; DJIAN, David; TSUI, Kwok, Ching; XU, Li-Qun",9724277.0 17.11.1997 GB; 98306261.3 05.08.1998 EP,EP-1998954602; US-09554556
WO2015190934,PCT/NO2015/050096,29.05.2015,WO/2015/190934,17.12.2015,WO,METHOD AND SYSTEM FOR CONTROLLING WELL OPERATIONS,"A method and system for increasing redundancy and uptime in a SCADA network for managing well operations, wherein control and management systems for well operations are executed in identical virtual environments of at least two servers, and wherein said servers a set up with load balancing.",E21B 47/12; G06F 9/455; G05B 15/02,MHWIRTH AS,"FLADMARK, Jon Rune; KJØLLEBERG, Marius",20140740 13.06.2014 NO,GB-1621926.3; US-15317976
WO2001031580,PCT/US2000/029770,27.10.2000,WO/2001/031580,03.05.2001,WO,METHODS AND DEVICES FOR IDENTIFYING PATTERNS IN BIOLOGICAL SYSTEMS,"The methods, systems and devices of the present invention comprise use of support vector machines for the identification of patterns that are important for medical diagnosis, prognosis and treatment. Such patterns may be found in many different datasets. The present invention also comprises methods and compositions for the treatment and diagnosis of medical conditions.",G01N 33/53; A61K 45/00; A61P 35/00; C12M 1/00; C12M 1/34; C12N 15/09; C12Q 1/68; G01N 33/566; G06F 19/24; G06K 9/62; G06N 99/00,"BIOWULF TECHNOLOGIES, LLC; BARNHILL, Stephen, D.; GUYON, Isabelle; WESTON, Jason","BARNHILL, Stephen, D.; GUYON, Isabelle; WESTON, Jason","60/161,806 27.10.1999 US; 60/168,703 02.12.1999 US; 60/184,596 24.02.2000 US; 60/191,219 22.03.2000 US; 09/568,301 09.05.2000 US; 09/578,011 24.05.2000 US; 60/207,026 25.05.2000 US",JP-2001534088; EP-2000973988; AU-12427/01; CA-2388595
WO2016118686,PCT/US2016/014212,21.01.2016,WO/2016/118686,28.07.2016,WO,MODELING OF CROP GROWTH FOR DESIRED MOISTURE CONTENT OF TARGETED LIVESTOCK FEEDSTUFF FOR DETERMINATION OF HARVEST WINDOWS USING FIELD-LEVEL DIAGNOSIS AND FORECASTING OF WEATHER CONDITIONS AND OBSERVATIONS AND USER INPUT OF HARVEST CONDITION STATES,"A modeling framework for evaluating the impact of weather conditions on farming and harvest operations applies real-time, field-level weather data and forecasts of meteorological and climatological conditions together with user-provided and/or observed feedback of a present state of a harvest-related condition to agronomic models and to generate a plurality of harvest advisory outputs for precision agriculture. A harvest advisory model simulates and predicts the impacts of this weather information and user-provided and/or observed feedback in one or more physical, empirical, or artificial intelligence models of precision agriculture to analyze crops, plants, soils, and resulting agricultural commodities, and provides harvest advisory outputs to a diagnostic support tool for users to enhance farming and harvest decision-making, whether by providing pre-, post-, or in situ-harvest operations and crop analyses.",G06F 19/00; G06F 15/18; G06Q 10/06; G06Q 50/02,"ITERIS, INC.","MEWES, John; SALENTINY, Dustin; KUPER, Dane; BALSLEY, Dustin","14/603,378 23.01.2015 US; 14/603,380 23.01.2015 US; 14/603,381 23.01.2015 US; 14/603,382 23.01.2015 US; 14/603,383 23.01.2015 US; 14/603,384 23.01.2015 US; 14/603,385 23.01.2015 US; 14/842,852 02.09.2015 US; 14/842,853 02.09.2015 US; 14/842,854 02.09.2015 US; 14/952,686 25.11.2015 US; 14/952,698 25.11.2015 US; 14/952,670 25.11.2015 US; 14/952,679 25.11.2015 US",
WO2006048263,PCT/EP2005/011729,03.11.2005,WO/2006/048263,11.05.2006,WO,GENE EXPRESSION PROFILING IN ACUTE PROMYELOCYTIC LEUKEMIA,"The present invention relates to rapid and reliable approaches to leukemia detection and subtyping. In certain aspects, for example, the invention focuses on APL(acute promyelocytic leukemia), which should generally be detected quickly and unquestionably, since in comparison to all other AML as well as to other leukemia, APL typically needs a specific and unique treatment, such as with ATRA instead of chemotherapy as a first treatment. As two subtypes of APL can appear morphologically that both need this treatment, they should also typically be detected both unequivocally and distinguished from all other AML and other leukemia. In addition to methods, the invention also provides related kits and systems.",G01N 33/574; C12Q 1/68,"ROCHE DIAGNOSTICS GMBH; F. HOFFMANN-LA ROCHE AG; HAFERLACH, Torsten; DUGAS, Martin; KERN, Wolfgang; KOHLMANN, Alexander; SCHNITTGER, Susanne; SCHOCH, Claudia","HAFERLACH, Torsten; DUGAS, Martin; KERN, Wolfgang; KOHLMANN, Alexander; SCHNITTGER, Susanne; SCHOCH, Claudia","60/625,685 04.11.2004 US",
WO2018194849,PCT/US2018/026356,06.04.2018,WO/2018/194849,25.10.2018,WO,MINIMIZING MEMORY READS AND INCREASING PERFORMANCE BY LEVERAGING ALIGNED BLOB DATA IN A PROCESSING UNIT OF A NEURAL NETWORK ENVIRONMENT,"The performance of a neural network (NN) and/or deep neural network (DNN) can be limited by the number of operations being performed as well as management of data among the various memory components of the NN/DNN. By inserting a selected padding in the input data to align the input data in memory, data read/writes can be optimized for processing by the NN/DNN thereby enhancing the overall performance of a NN/DNN. Operatively, an operations controller/iterator can generate one or more instructions that inserts the selected padding into the data. The data padding can be calculated using various characteristics of the input data as well as the NN/DNN as well as characteristics of the cooperating memory components. Padding on the output data can be utilized to support the data alignment at the memory components and the cooperating processing units of the NN/DNN.",G06F 15/80,"MICROSOFT TECHNOLOGY LICENSING, LLC","PETRE, George; MCBRIDE, Chad Balling; AMBARDEKAR, Amol Ashok; CEDOLA, Kent D.; BOBROV, Boris; WALL, Larry Marvin","62/486,432 17.04.2017 US; 15/813,952 15.11.2017 US",EP-2018724637; CN-201880024892.5
EP175456970,15305063,22.01.2015,3048563,27.07.2016,EP,Method and system for incremental manifold learning,"A method for incremental manifold learning, comprising: incrementally obtaining a plurality of appearance samples; for each incrementally obtained appearance sample, determining an initial embedding in a manifold, said embedding being a lower-dimensional representation of said incrementally obtained appearance sample; for each last incrementally obtained appearance sample, selecting a proper subset from said incrementally obtained appearance samples, said proper subset comprising at least said last appearance sample and its predecessor appearance sample; computing for that proper subset a transport operator relation between said last appearance sample and its predecessor appearance sample and zero or more auxiliary transport operator relations between respective pairs of appearance samples of said proper subset; iteratively updating said manifold based on said computed transport operator relations.",G06K 9/62,ALCATEL LUCENT,AERTS MAARTEN; MACQ JEAN-FRANÇOIS,15305063 22.01.2015 EP,
WO2019236569,PCT/US2019/035376,04.06.2019,WO/2019/236569,12.12.2019,WO,DEEP LEARNING-ENABLED PORTABLE IMAGING FLOW CYTOMETER FOR LABEL-FREE ANALYSIS OF WATER SAMPLES,An imaging flow cytometer device includes a housing holding a multi-color illumination source configured for pulsed or continuous wave operation. A microfluidic channel is disposed in the housing and is fluidically coupled to a source of fluid containing objects that flow through the microfluidic channel. A color image sensor is disposed adjacent to the microfluidic channel and receives light from the illumination source that passes through the microfluidic channel. The image sensor captures image frames containing raw hologram images of the moving objects passing through the microfluidic channel. The image frames are subject to image processing to reconstruct phase and/or intensity images of the moving objects for each color. The reconstructed phase and/or intensity images are then input to a trained deep neural network that outputs a phase recovered image of the moving objects. The trained deep neural network may also be trained to classify object types.,G01N 33/00; G01N 33/48; G01N 33/52; C12Q 1/00; C12Q 1/02,THE REGENTS OF THE UNIVERSITY OF CALIFORNIA,"OZCAN, Aydogan; GOROCS, Zoltan","62/680,374 04.06.2018 US",
EP260716651,19179828,28.12.2011,3557442,23.10.2019,EP,REAL-TIME NATURAL LANGUAGE PROCESSING OF DATASTREAMS,,G06F 16/783; G06F 3/048; G06F 17/20,INTEL CORP,SMITH ELLIOT; SZILAGYI VICTOR,11878980 28.12.2011 EP; 19179828 28.12.2011 EP; 2011067623 28.12.2011 US,
WO2019083786,PCT/US2018/056211,17.10.2018,WO/2019/083786,02.05.2019,WO,"SECURE MESSAGING SYSTEMS, METHODS, AND AUTOMATION","Systems and methods for secure messaging and automation are disclosed herein. An example method includes providing a user-facing application secured through use of a security token cached on a web browser, establishing a security protocol or security token utilized between the application server layer and the web services layer that is different from the security token cached on the web browser; and performing asynchronous processing based on user interaction with a goal-based planning application that provides queries that are directed to assessing both risk willingness and goal ability, generates a risk willingness score and a goal ability score, selects a goal-based plan, and generating one or more instructions sets that are used to automatically reconfigure the plurality of user accounts to ensure that a goal is met within a specified time frame.",G06F 21/57; G06F 7/04; G06F 15/16,BRIGHTPLAN LLC,"DE BEER, Marthin; SHAH, Krutarth; ROBINSON, Larry","15/796,622 27.10.2017 US",
WO2019197395,PCT/EP2019/058940,09.04.2019,WO/2019/197395,17.10.2019,WO,"METHOD, DEVICE AND SYSTEM FOR MANAGING A FLEET OF INFORMATION CARRIER VEHICLES","The invention relates to a method of managing a fleet of information carrier vehicles (2, 2'; 20, 20""; 100, 101, 102), each of the vehicles being autonomous in energy and arranged to move and roll on a ground of a field (L), each of said information carrier vehicles comprising data communication means for communicating data to a communicating access point (300) common to said fleet of information carrier vehicles and a tool (5; 5') for performing a work, said method comprising the following steps: at vehicle level: generation of data of interest, optional step of local preprocessing of data of interest, step of recording data of interest or pre-processed, transmission of recorded data, movement commands reception and applying the received movement commands, at a remote processing device for the vehicles: processing received data to determine a strategy for controlling the vehicle fleet, communication to the fleet vehicles of movement commands determined from said driving strategy.",G05B 15/02; G05D 1/02; G05D 1/00; G05B 19/042,VITIROVER,"DAVID BEAULIEU, Xavier",PCT/EP2018/058986 09.04.2018 EP,
WO2019050515,PCT/US2017/050338,06.09.2017,WO/2019/050515,14.03.2019,WO,MOVABLE OBJECT APPLICATION FRAMEWORK,"Techniques are disclosed for communicating between a client device and an onboard data manager in a movable object environment. A data manager on a user device can identify an onboard data manager on a movable object. A feature list can be received from the onboard data manager, the feature list identifying at least one feature installed to the movable object. At least one input can be received by the user device, and a user device feature corresponding to the at least one input can be determined. It may be further determined that the user device feature is supported by the onboard data manager based on the feature list. In response to determining that the user device feature is supported, a first instruction corresponding to the at least one input can be sent to the movable object including the onboard data manager.",G05D 1/04; B05B 13/00; B64C 39/02,"DJI TECHNOLOGY, INC.","THIERCELIN, Arnaud; SANT, Rohit",,CN-201780090445.5
EP235192948,16889921,25.11.2016,3416105,19.12.2018,EP,INFORMATION PROCESSING METHOD AND INFORMATION PROCESSING DEVICE,"[Object] To present information for improving development efficiency of a neural network to a user.  [Solution] Provided is an information processing method including: providing, by a processor, a form for creating a program for establishing a neural network on a basis of a disposed component and property set for the component; and presenting statistical information relating to the neural network. In addition, provided is an information processing apparatus including a form control unit configured to provide a form for creating a program for establishing a neural network on a basis of a disposed component and property set for the component. The form control unit presents statistical information relating to the neural network.",G06N 3/02; G06F 8/34; G06F 8/36; G06F 11/34; G06N 3/10,SONY CORP,YOSHIYAMA KAZUKI; KOBAYASHI YOSHIYUKI,2016024545 12.02.2016 JP; 2016085025 25.11.2016 JP,
WO2018070066,PCT/JP2017/010017,13.03.2017,WO/2018/070066,19.04.2018,WO,"IDENTIFYING INFORMATION ASSIGNMENT SYSTEM, IDENTIFYING INFORMATION ASSIGNMENT METHOD, AND PROGRAM THEREFOR","In order to provide a technique for identifying what kind of learning was performed, for each capability acquired as a result of performing a learning process by machine learning, and managing the relationship as appropriate, an identifying information assignment system includes: a generating portion configured to generate, for a learning result obtained by attaining a predetermined capability through a predetermined learning process by machine learning, identifying information for identifying the predetermined learning process; and an assignment portion configured to assign the generated identifying information to the learning result.",G06N 99/00,OMRON CORPORATION,"ANDO, Tanichi",2016-201201 12.10.2016 JP,CN-201780056234.X; EP-2017713476
WO2018194846,PCT/US2018/026353,06.04.2018,WO/2018/194846,25.10.2018,WO,DATA PROCESSING PERFORMANCE ENHANCEMENT FOR NEURAL NETWORKS USING A VIRTUALIZED DATA ITERATOR,"The performance of a neural network (NN) and/or deep neural network (DNN) can limited by the number of operations being performed as well as management of data among the various memory components of the NN/DNN. Using virtualized hardware iterators, data for processing by the NN/DNN can be traversed and configured to optimize the number of operations as well as memory utilization to enhance the overall performance of a NN/DNN. Operatively, an iterator controller can generate instructions for execution by the NN/DNN representative of one more desired iterator operation types and to perform one or more iterator operations. Data can be iterated according to a selected iterator operation and communicated to one or more neuron processors of the NN/DD for processing and output to a destination memory. The iterator operations can be applied to various volumes of data (e.g., blobs) in parallel or multiple slices of the same volume.",G06F 15/80; G06F 9/50,"MICROSOFT TECHNOLOGY LICENSING, LLC","PETRE, George; MCBRIDE, Chad, Balling; AMBARDEKAR, Amol, Ashok; CEDOLA, Kent, D.; BOBROV, Boris; WALL, Larry, Marvin","62/486,432 17.04.2017 US; 15/694,663 01.09.2017 US",EP-2018720860; CN-201880025504.5
WO2020038589,PCT/EP2018/072930,24.08.2018,WO/2020/038589,27.02.2020,WO,METHODS FOR AUTOMATICALLY GENERATING DIVERSE IMAGE DATA,"A method for automated creation of diverse image content by a neural network is provided. The method includes receiving a data input (105), generating a plurality of random vector codes (110), providing a random vector code from the plurality of random vector codes to each channel of a feature map (120), determining, based on the provided random codes, one or more drop-out patterns for application to a feature map of the data input (130), applying the one or more drop-out patterns to the feature map of the input data to drop one or more channels in the input data (140), resulting in a plurality of synthesized outputs and an associated latent code for each synthesized output of the plurality of synthesized outputs, the latent code being based on the applied drop-out pattern, and outputting the plurality of synthesized outputs as images to an image data set (150).",G06K 9/00; G06N 3/04; G06K 9/46; G06K 9/62,TOYOTA MOTOR EUROPE; MAX-PLANCK-INSTITUT FÜR INFORMATIK,"REINO, Daniel, Olmeda; SCHIELE, Bernt; FRITZ, Mario; HE, Yang",,
WO2019212995,PCT/US2019/029742,29.04.2019,WO/2019/212995,07.11.2019,WO,A GAIT CONTROLLED MOBILITY DEVICE,"A mobility device comprising a motorized shoe to be worn by a user to increase the speed of walking. The motorized shoe has a plurality of wheels, with at least one wheel driven by an electric motor through a geartrain. On onboard controller gathers data from at least one of an inertial measurement unit, an ultrasonic sensor, and a vision system to generate a command speed to the electric motor. A user wearing a pair of the mobility devices, one on each foot, is able to walk with a normal gait, but at an increased speed.",A63C 17/12; A43B 3/00; A61B 5/11; A63C 17/00,"NIMBUS ROBOTICS, INC.","ZHANG, Xunjie","62/664,203 29.04.2018 US",
WO2005119589,PCT/JP2005/010535,02.06.2005,WO/2005/119589,15.12.2005,WO,"INFORMATION PROCESSING METHOD AND APPARATUS, AND IMAGE PICKUP DEVICE","An output value of neuron within an objective layer of a hierarchical neural network is computed. The data of the output value of neuron is stored in a memory only if the output value of neuron is greater than or equal to a predetermined value by referring to the computed output value of neuron within the objective layer. When the data of the output value of neuron on a former layer of objective layer is read from the memory, the data having a predetermined value is read, instead of the data of the output value of neuron not stored in the memory.",G06N 3/04; G06N 3/00; G06T 7/00; H04N 5/232,"CANON KABUSHIKI KAISHA; ISHII, Mie; MATSUGU, Masakazu; MORI, Katsuhiko; MITARAI, Yusuke","ISHII, Mie; MATSUGU, Masakazu; MORI, Katsuhiko; MITARAI, Yusuke",2004-166136 03.06.2004 JP,DE-null; US-11579981
EP243363843,18208489,27.11.2018,3496008,12.06.2019,EP,METHOD AND APPARATUS FOR PROCESSING CONVOLUTION OPERATION IN NEURAL NETWORK,,G06N 3/063; G06N 3/04; G06T 1/20,SAMSUNG ELECTRONICS CO LTD,LEE SEHWAN; KIM NAMJOON; SONG JOONHO; JANG JUNWOO,20170166203 05.12.2017 KR,
WO2019054949,PCT/SG2018/050473,14.09.2018,WO/2019/054949,21.03.2019,WO,SYSTEM AND METHOD FOR PREDICTIVE CLEANING,"Embodiments include a system and method for a virtual cleaning supervisor (VCS) for monitoring the cleanliness of a washroom, alerting cleaners and/or stakeholders and predicting cleaning schedules. Sensors are installed within a washroom at various locations that measure its cleanliness in real time. Sensors can measure patterns of use, wetness on floors, indoor air quality by detecting concentrations of gases and receive input from users. The sensor network does not rely on the use of a camera or other image based system. Artificial intelligence (AI) based machine learning algorithms on cloud servers can match the observed values with historical values to detect anomalies and send alerts if cleaning or a check is required. The system can also generate reports for facility managers to track cleaning operations and cleaning companies to evaluate their workforce using a time to service parameter.",G06Q 10/06; G06Q 50/26; G08B 31/00; G06N 3/08,"SMARTCLEAN TECHNOLOGIES, PTE. LTD.","AGARWAL, Lav; AGARWAL, Kush; MISHRA, Abhishek",10201707635W 15.09.2017 SG,EP-2018855257
EP238739153,17188604,30.08.2017,3451189,06.03.2019,EP,A SYSTEM AND METHOD FOR USER QUERY RECOGNITION,"The disclosure relates to a query recognition system (100) for automatically recognizing a current linguistic user query, wherein the current linguistic user query is represented by digital values. The query recognition system (100) comprises: a group of natural language processing entities (131 a-c) for associating computer readable commands with linguistic user queries, the computer readable commands relating to specific computer services which are different for each language processing entity (131a-c); and a dispatcher (101) being configured to select a natural language processing entity (131a) from the group of natural language entities (131a-c) which most recently output a computer readable command, and to pass on the current linguistic user query to the selected natural language processing entity (131a); wherein the selected natural language processing entity (131 a) is configured to determine whether a computer readable command is associated with the current linguistic user query, and to output a computer readable command if the computer readable command is associated with the current linguistic user query.",G06F 9/48; G10L 15/22,DEUTSCHE TELEKOM AG,KORFF GERRIT MATTI; JALALI ADRIN; BACHMANN FLORIAN,17188604 30.08.2017 EP,
WO2019067265,PCT/US2018/051496,18.09.2018,WO/2019/067265,04.04.2019,WO,SPARSE CODING BASED CLASSIFICATION,System and techniques for sparse coding based classification are described herein. A sample of a first type of data may be obtained and encoded to create a sparse coded sample. A dataset may be searched using the sparse coded sample to locate a segment set of a second type of data. An instance of the second type of data may then be created using the segment set.,G06K 9/62; G06K 9/00; G06N 3/02,"INTEL CORPORATION; KUNG, Hsiang Tsung; CHINYA, Gautham N.","KUNG, Hsiang Tsung; CHINYA, Gautham N.; LIN, Chit-Kwan","15/717,478 27.09.2017 US",
WO2016126282,PCT/US2015/039360,07.07.2015,WO/2016/126282,11.08.2016,WO,METHOD AND SYSTEM FOR REAL TIME VISUALIZATION OF INDIVIDUAL HEALTH CONDITION ON A MOBILE DEVICE,"A method and technology to display 3D graphical output for a user using body sensor data, personal medical data in real time is disclosed. A consolidated methodology to bring user meaningful life information based on real-time sensor results, analysis, expert Q&As, ""What if scenarios and future emulation all in one artificial intelligence expert system is described. A unique rendering of 3D image of ones organ, cell or subcellular level display related to one's health condition can be visualized on a graphical user interface of a devices or devices. The change of the display from one level such as from organ to cell or cell to subcellular level or vice versa is enabled is disclosed.",G06F 19/00,"RATH, Matthias, W.","RATH, Matthias, W.; NIEDZWIECKI, Aleksandra; KARNATH, Dirk, Fried","14/613,506 04.02.2015 US",EP-2015881379
WO2019204186,PCT/US2019/027437,15.04.2019,WO/2019/204186,24.10.2019,WO,INTEGRATED UNDERSTANDING OF USER CHARACTERISTICS BY MULTIMODAL PROCESSING,"A system and method for multimodal classification of user characteristics is described. The method comprises receiving audio and other inputs, extracting fundamental frequency information from the audio input, extracting other feature information from the video input, classifying the fundamental frequency information, textual information and video feature information using the multimodal neural network.",G06N 3/02; G06N 3/04; G06N 20/00,"SONY INTERACTIVE ENTERTAINMENT INC.; CHEN, Ruxin","CHEN, Ruxin; OMOTE, Masanori; MENENDEZ-PIDAL, Xavier; YOO, Jaekwon; TASHIRO, Koji; KRISHNAMURTHY, Sudha; KUMAR, Komath Naveen","62/659,657 18.04.2018 US",
WO2020065534,PCT/IB2019/058100,24.09.2019,WO/2020/065534,02.04.2020,WO,SYSTEM AND METHOD OF GENERATING CONTROL COMMANDS BASED ON OPERATOR'S BIOELECTRICAL DATA,"The technical solution relates to control systems, more particularly to systems and methods of generating control commands based on operator's bioelectrical data. One more technical result of the present technical solution is the increase of identification accuracy of the Operator's actions. One more technical result of the present technical solution is the improvement of identification of the Operator's actions due to the elimination of artefacts from the Operator's bioelectrical data.",A61B 5/04; A61B 5/0482; A61B 5/11,"SONKIN, Konstantin","STANKEVICH, Lev; SHEMYAKINA, Natalia; NAGORNOVA, Zhanna; GUNDELAKH, Filipp; CHEVYKALOVA, Aleksandra",2018133658 24.09.2018 RU,
EP225889654,17305247,08.03.2017,3373208,12.09.2018,EP,METHOD AND SYSTEM FOR FACILITATING RELIABLE PATTERN DETECTION,"According to a first aspect of the present disclosure, a method for facilitating detection of one or more time series patterns is conceived, comprising building one or more artificial neural networks, wherein, for at least one time series pattern to be detected, a specific one of said artificial neural networks is built, the specific one of said artificial neural networks being configured to produce a decision output and a reliability output, wherein the reliability output is indicative of the reliability of the decision output. According to a second aspect of the present disclosure, a corresponding computer program is provided. According to a third aspect of the present disclosure, a corresponding system for facilitating the detection of one or more time series patterns is provided.",G06N 3/04; G06N 3/08,NXP BV,DANIEL ADRIEN,17305247 08.03.2017 EP,
WO2009144368,PCT/FI2009/050414,19.05.2009,WO/2009/144368,03.12.2009,WO,"METHOD, APPARATUS AND COMPUTER PROGRAM PRODUCT FOR PROVIDING IMPROVED SPEECH SYNTHESIS","An apparatus for providing improved speech synthesis may include a processor and a memory storing executable instructions. In response to execution of the instructions by the processor, the apparatus may perform at least selecting a real glottal pulse from among one or more stored real glottal pulses based at least in part on a property associated with the real glottal pulse, utilizing the real glottal pulse selected as a basis for generation of an excitation signal, and modifying the excitation signal based on spectral parameters generated by a model to provide synthetic speech.",G10L 13/04; G10L 19/08; G10L 19/14,"NOKIA CORPORATION; NURMINEN, Jani; RAITIO, Tuomo; SUNI, Antti; VAINIO, Martti; ALKU, Paavo","NURMINEN, Jani; RAITIO, Tuomo; SUNI, Antti; VAINIO, Martti; ALKU, Paavo","61/057,542 30.05.2008 US",EP-2009754021; KR-1020107029463; CA-2724753; CN-200980120201.2; IN-8315/CHENP/2010
WO2020050686,PCT/KR2019/011557,06.09.2019,WO/2020/050686,12.03.2020,WO,IMAGE PROCESSING DEVICE AND METHOD,"An image processing method comprises obtaining an input image; converting the input image or a feature map of the input image into a plurality of target input images or target feature maps, wherein a resolution of each of the target input images or the target feature maps is smaller than a resolution of the feature map of the input image or the input image, and pixels at the same position in each of the target input images or the target feature maps are of a neighborhood relationship with the input image or the feature map of the input image; processing at least a part of the plurality of target input images or target feature maps by one or more convolution blocks in a convolutional neural network; and increasing a resolution of a feature map output from the one or more convolution blocks in the convolutional neural network.",G06N 3/04; G06N 3/08,"SAMSUNG ELECTRONICS CO., LTD.","LIU, Zikun; LI, Chunying; QIU, Han; LIU, Yinglu",201811049734.3 07.09.2018 CN,
WO2018212946,PCT/US2018/029180,24.04.2018,WO/2018/212946,22.11.2018,WO,SIGMA-DELTA POSITION DERIVATIVE NETWORKS,"A method for processing temporally redundant data in an artificial neural network (ANN) includes encoding an input signal, received at an initial layer of the ANN, into an encoded signal. The encoded signal comprises the input signal and a rate of change of the input signal. The method also includes quantizing the encoded signal into integer values and computing an activation signal of a neuron in a next layer of the ANN based on the quantized encoded signal. The method further includes computing an activation signal of a neuron at each layer subsequent to the next layer to compute a full forward pass of the ANN. The method also includes back propagating approximated gradients and updating parameters of the ANN based on an approximate derivative of a loss with respect to the activation signal.",G06N 3/04; G06N 3/063; G06N 3/08,QUALCOMM INCORPORATED,"O'CONNOR, Peter; WELLING, Max","62/508,266 18.05.2017 US; 15/705,161 14.09.2017 US",
WO2018142378,PCT/IB2018/050742,06.02.2018,WO/2018/142378,09.08.2018,WO,MEMORY AUGMENTED GENERATIVE TEMPORAL MODELS,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for generating sequences of predicted observations, for example images. In one aspect, a system comprises a controller recurrent neural network, and a decoder neural network to process a set of latent variables to generate an observation. An external memory and a memory interface subsystem is configured to, for each of a plurality of time steps, receive an updated hidden state from the controller, generate a memory context vector by reading data from the external memory using the updated hidden state, determine a set of latent variables from the memory context vector, generate a predicted observation by providing the set of latent variables to the decoder neural network, write data to the external memory using the latent variables, the updated hidden state, or both, and generate a controller input for a subsequent time step from the latent variables.",G06N 3/04,DEEPMIND TECHNOLOGIES LIMITED,"WAYNE, Gregory Duncan; HUNG, Chia-Chun; GEMICI, Mevlana Celaleddin; SANTORO, Adam Anthony","62/455,387 06.02.2017 US",EP-2018708482; CN-201880016434.7
WO2017049188,PCT/US2016/052288,16.09.2016,WO/2017/049188,23.03.2017,WO,AUTOMATED ENVIRONMENT HAZARD DETECTION,"Systems and techniques are provided in which one or more environmental sensors collect data about an environment. An environmental hazard assessment module collects and analyzes data obtained by the environmental sensors to automatically identify, categorize, and/or rate the severity of potential environmental hazards. The hazards are provided to a user for a particular region of the environment or for a larger environment that includes multiple regions.",A61B 5/00; G08B 21/00; G08B 21/02; G08B 21/04; G08B 23/00,LUVOZO PBC,"PIETROCOLA, David; KESSLER, Terrance Jude; CHARIFA, Mohammed Samer; OGUNFEMI, Babatunde O.","62/219,899 17.09.2015 US",
WO2014151035,PCT/US2014/024806,12.03.2014,WO/2014/151035,25.09.2014,WO,COMPUTER-BASED METHOD AND SYSTEM OF DYNAMIC CATEGORY OBJECT RECOGNITION,"A computer-based method/system of dynamic category object recognition for estimating pose and/or positioning of target objects and target object's parts. The method/system may recognize a target object and the target object's parts. The method/system may segment and extract data corresponding to the target object and the target object's parts, and estimate the pose and positioning of the target object and the target object's parts using a plurality of stored object models. The dynamic method/system may supplement or modify the parameters of the plurality of stored object models and/or store learned object models. The learned object models assist in recognizing and estimating pose and/or positioning of newly encountered objects more accurately and with fewer processing steps. The method and system may include a processor, a sensor, an external device, a communications unit, and a database.",G06F 17/00; G06T 7/00,"TOYOTA MOTOR ENGINEERING & MANUFACTURING NORTH AMERICA, INC.","AMMA, Ayako; DJUGASH, Joseph M.A.","13/843,793 15.03.2013 US",
EP238117468,17785587,24.01.2017,3447661,27.02.2019,EP,INFORMATION PROCESSING DEVICE AND INFORMATION PROCESSING METHOD,"[Object] To provide a mechanism that can perform learning of a neural network more efficiently.  [Solution] An information processing apparatus including: an acquisition section configured to acquire a semantic network, identification information of data, and a label; and a learning section configured to learn a classification model that classifies the data into the label, on a basis of the semantic network, the identification information, and the label that have been acquired by the acquisition section.",G06N 3/08; G06F 16/36; G06N 99/00,SONY CORP,NARIHIRA TAKUYA; FUJITA TAKUYA; NAKAMURA AKIRA,2016083606 19.04.2016 JP; 2017002287 24.01.2017 JP,
WO2018125585,PCT/US2017/066237,14.12.2017,WO/2018/125585,05.07.2018,WO,GRAPH LONG SHORT TERM MEMORY FOR SYNTACTIC RELATIONSHIP DISCOVERY,"Long short term memory units that accept a non-predefined number of inputs are used to provide natural language relation extraction over a user-specified range on content. Content written for human consumption is parsed with distant supervision in segments (e.g., sentences, paragraphs, chapters) to determine relationships between various words within and between those segments.",G06F 17/30; G06F 17/20; G06N 3/04; G06N 5/02,"MICROSOFT TECHNOLOGY LICENSING, LLC","QUIRK, Christopher Brian; TOUTANOVA, Kristina Nikolova; YIH, Wen-Tau; POON, Hoifung; PENG, Nanyun","15/395,961 30.12.2016 US",
EP231575400,18159604,01.03.2018,3385844,10.10.2018,EP,NEURAL NETWORK SCHEDULING MECHANISM,"An apparatus to facilitate workload scheduling is disclosed. The apparatus includes one or more clients, one or more processing units to processes workloads received from the one or more clients, including hardware resources and scheduling logic to schedule direct access of the hardware resources to the one or more clients to process the workloads.",G06F 9/50; G06N 3/02,INTEL CORP,MA LIWEI; SATISH NADATHUR RAJAGOPALAN; BOTTLESON JEREMY; AKHBARI FARSHAD; NURVITADHI ERIKO; SAKTHIVEL CHANDRASEKARAN; LAKSHMANAN BARATH; JIN JINGYI; GOTTSCHLICH JUSTIN E; STRICKLAND MICHAEL,201715482793 09.04.2017 US,
WO2019026081,PCT/IL2018/050862,02.08.2018,WO/2019/026081,07.02.2019,WO,SYSTEMS AND METHODS FOR ANALYSIS OF TISSUE IMAGES,"There is provided a method of computing at least one slide-level tissue type for a tissue image of tissue extracted from a patient, comprising: receiving a tissue image of a slide including tissue extracted from the patient, segmenting tissue objects of the tissue image, creating a tissue image patches from the segmented tissue objects of the tissue image, classifying, by a patch-level classifier, each of the plurality of tissue image patches into at least one patch-level tissue type, wherein each of the classified tissue image patches is associated with a relative location within the tissue image, analyzing, by a slide-level analysis code, the classified at least one patch-level tissue type and associated relative location for each of the plurality of tissue image patches outputted by the patch-level classifier, for computing at least one slide-level tissue type for the tissue image, and providing the at least one slide-level tissue type.",G06K 9/00; G06K 9/46; G06T 7/10,NUCLEAI LTD,"VEIDMAN, Avi; CHOREV, Lotan","62/540,652 03.08.2017 US",EP-2018759763; IL-272433
WO2019094729,PCT/US2018/060043,09.11.2018,WO/2019/094729,16.05.2019,WO,METHODS AND SYSTEMS FOR THE INDUSTRIAL INTERNET OF THINGS,"An example data collection system in an industrial environment includes a data collector in communication with a number of input channels for acquiring collected data. The system includes a data storage that stored the collected data as a number of data pools. The system includes a self-organizing data marketplace engine that receives the data pools, and that is organized based on training a marketplace self-organization with a training set, and further based on feedback from measures of marketplace success with respect to the data pools.",G05B 19/418; G06N 99/00; H04L 29/08; G06N 5/04,"STRONG FORCE IOT PORTFOLIO 2016, LLC","CELLA, Charles, Howard; DESAI, Mehul; DUFFY, Gerald, William, Jr.; MCGUCKIN, Jeffrey, P.; HO, Tracey; SEGUI, John; BLUMENTHAL, Steven; MENG, Chun","62/584,103 09.11.2017 US; 15/859,238 29.12.2017 US",
EP250370757,17870527,08.11.2017,3525164,14.08.2019,EP,IMAGE PROCESSING APPARATUS AND IMAGE PROCESSING METHOD,"Disclosed is an image processing apparatus. The present image processing apparatus comprises: an input unit for inputting an image; and a processor for shrinking the inputted image to a predetermined ratio, extracting a visual feature from the shrunken image, performing an image quality enhancement process reflecting the extracted visual feature in the inputted image, repeatedly performing, for a predetermined number of times, the shrinking, the extracting, and the image quality enhancement process on the image that has undergone the image quality enhancement process. The present disclosure relates to an artificial intelligence (AI) system and an application thereof that simulate the functions of a human brain, such as recognition, judgment, etc., by using a machine learning algorithm such as deep learning, etc.",G06T 3/40; G06T 7/33,SAMSUNG ELECTRONICS CO LTD,NAM WOO-HYUN; AHN IL-JUN; LEE TAMMY; CHO KI-HEUM; PARK YONG-SUP; CHEON MIN-SU,20160148510 09.11.2016 KR; 2017012627 08.11.2017 KR,
EP14549603,05257427,02.12.2005,1667107,07.06.2006,EP,"Method and apparatus for learning data, method and apparatus for recognizing data, method and apparatus for generating data and computer program","A learning apparatus for learning time series data, includes a learning unit for updating, in a self-organizing manner based on an observed value of the time series data, a time series pattern storage network including a plurality of nodes, each node having a time series pattern model representing a time series pattern of the time series data.",G10L 15/14,SONY CORP,MINAMINO KATSUKI; AOYAMA KAZUMI; SHIMOMURA HIDEKI,2004353382 06.12.2004 JP,
WO2006076164,PCT/US2005/047218,30.12.2005,WO/2006/076164,20.07.2006,WO,JOINT MOVEMENT SYSTEM,"Systems, methods and devices for restoring or enhancing one or more motor functions of a patient are disclosed. The system comprises a biological interface apparatus and a joint movement device such as an exoskeleton device or FES device. The biological interface apparatus includes a sensor that detects the multicellular signals and a processing unit for producing a control signal based on the multicellular signals. Data from the joint movement device is transmitted to the processing unit for determining a value of a configuration parameter of the system. Also disclosed is a joint movement device including a flexible structure for applying force to one or more patient joints, and controlled cables that produce the forces required.",G06N 3/06; A61B 5/00; G06F 3/00; A61F 2/68,"CYBERKINETICS NEUROTECHNOLOGY SYSTEMS, INC.; FLAHERTY, J., Christopher; FLAHERTY, R., Maxwell; FRIEHS, Gerhard, M.; SERRUYA, Mijail, D.; BARRETT, Burke, T.; DONOGHUE, John, P.","FLAHERTY, J., Christopher; FLAHERTY, R., Maxwell; FRIEHS, Gerhard, M.; SERRUYA, Mijail, D.; BARRETT, Burke, T.; DONOGHUE, John, P.","60/642,810 10.01.2005 US",EP-5855730
WO2019074185,PCT/KR2018/006509,08.06.2018,WO/2019/074185,18.04.2019,WO,ELECTRONIC APPARATUS AND CONTROL METHOD THEREOF,"An electronic apparatus and method thereof are provided for performing deep learning. The electronic apparatus includes a storage configured to store target data and kernel data; and a processor including a plurality of processing elements that are arranged in a matrix shape. The processor is configured to input, to each of the plurality of processing elements, a first non-zero element from among a plurality of first elements included in the target data, and sequentially input, to each of a plurality of first processing elements included in a first row from among the plurality of processing elements, a second non-zero element from among the plurality of elements included in the kernel data. Each of the plurality of first processing elements is configured to perform an operation between the input first non-zero element and the input second non-zero element, based on depth information of the first non-zero element and depth information of the second non-zero element.",G06N 3/08; G06N 3/04; G06N 3/063,"SAMSUNG ELECTRONICS CO., LTD.","KIM, Kyung-hoon; PARK, Young-hwan; SUH, Dong-kwan; PRASADNAGARAJA, Keshava; KIM, Dae-hyun; KIM, Suk-jin; CHO, Han-su; KIM, Hyun-jung","62/571,599 12.10.2017 US; 10-2018-0022960 26.02.2018 KR",EP-2018866233
EP251649946,17873361,23.06.2017,3540611,18.09.2019,EP,ELECTRONIC DEVICE FOR PERFORMING TRANSLATION BY SHARING CONTEXT OF UTTERANCE AND OPERATION METHOD THEREFOR,"The present disclosure relates to an artificial intelligence (AI) system which simulates the functions of a human brain, such as recognition, judgment, etc., by using a machine learning algorithm, such as deep learning; and applications thereof.",G06F 17/28,SAMSUNG ELECTRONICS CO LTD,KIM SANG-HA; KIM EUN-KYOUNG; YU JI-SANG; RYU JONG-YOUB; LEE JAE-WON,20160159416 28.11.2016 KR; 20170048534 14.04.2017 KR; 2017006627 23.06.2017 KR,
EP239447062,17191249,15.09.2017,3456607,20.03.2019,EP,DETERMINING OF AN EMBRAKING/DISEMBARKING DURATION OF AN OBJECT,"The present invention relates to a method for determining a duration (D) of an embarking process and/or a disembarking process of at least one autonomously movable object (10) conveyable by a movable unit (12), wherein the method comprises the step of: Determining the duration (D) of the embarking process and/or the disembarking process of at least one autonomously movable object (10) embarking and/or disembarking the movable unit (12) by using a model describing an embarking process and/or the disembarking process of at least one autonomously movable object (10) embarking and/or disembarking a movable unit (12) spatially discreetly dynamically.  Due to the determination method a flexible, reliable, time and cost saving operation of a travelling network can be provided.",B61L 27/00; G06N 3/00,SIEMENS MOBILITY GMBH,DAVIDICH MARIA,17191249 15.09.2017 EP,
WO2020068056,PCT/US2018/052724,25.09.2018,WO/2020/068056,02.04.2020,WO,SPEAKER DIARIZATION USING SPEAKER EMBEDDING(S) AND TRAINED GENERATIVE MODEL,"Speaker diarization techniques that enable processing of audio data to generate one or more refined versions of the audio data, where each of the refined versions of the audio data isolates one or more utterances of a single respective human speaker. Various implementations generate a refined version of audio data that isolates utterance(s) of a single human speaker by generating a speaker embedding for the single human speaker, and processing the audio data using a trained generative model - and using the speaker embedding in determining activations for hidden layers of the trained generative model during the processing. Output is generated over the trained generative model based on the processing, and the output is the refined version of the audio data.",G10L 15/16; G10L 15/20; G10L 15/30,GOOGLE LLC,"MORENO, Ignacio Lopez; COBO RUS, Luis Carlos",,
WO2018013495,PCT/US2017/041408,10.07.2017,WO/2018/013495,18.01.2018,WO,AUGMENTED REALITY METHODS AND DEVICES,"Augmented reality methods and systems are described. According to one aspect, an augmented reality computer system includes processing circuitry configured to access an image of the real world, wherein the image includes a real world object, and evaluate the image using a neural network to determine a plurality of augmented reality estimands which are indicative of a pose of the real world object and which are useable to generate augmented content regarding the real world object. Other methods and systems are disclosed including additional aspects directed towards training and using neural networks.",G06F 17/00; G06K 9/00; G06K 9/62,"GRAVITY JACK, INC.","RICHEY, Aaron, Luke; RIDGWAY, Randall, Sewell; POINDEXTER, Shawn, David; ROLLINS, Marc, Andrew; ABEL, Joshua, Adam","62/360,889 11.07.2016 US",
WO2003019475,PCT/JP2002/008433,21.08.2002,WO/2003/019475,06.03.2003,WO,"ROBOT APPARATUS, FACE RECOGNITION METHOD, AND FACE RECOGNITION APPARATUS","A robot includes a face extraction unit for extracting a feature of a face contained in an image picked up by a CCD camera and a face recognition unit for recognizing a face according to the face extraction result obtained by the face extraction unit. The face extraction unit is composed of a Gabor filter for filtering an image by using a plurality of filters having direction selectivity and different frequency components. The face recognition unit is composed of a support vector machine for mapping the face extraction result onto a non-linear space and obtaining a hyperplane for separation in the space, thereby distinguishing face from non-face. The robot can recognize a user face in a dynamically changing environment within a predetermined time.",G06K 9/00,"SONY CORPORATION; ; YOKONO, Jun; ; SABE, Kohtaro; ; KAWAMOTO, Kenta;","YOKONO, Jun; ; SABE, Kohtaro; ; KAWAMOTO, Kenta;",2001-253700 23.08.2001 JP,US-10399740; JP-2003523462; EP-2002762820; KR-1020037005576; CN-02803094.X
WO2018069791,PCT/IB2017/056069,02.10.2017,WO/2018/069791,19.04.2018,WO,DETECTING PHYSIOLOGICAL RESPONSES USING THERMAL AND VISIBLE-LIGHT HEAD-MOUNTED CAMERAS,"Some aspects of this disclosure involve head-mounted systems that are utilized to take thermal measurements of a user's face to detect various physiological responses, such as an allergic reaction, stress, a headache, a stroke, to name a few. Typically, these systems involve one or more head-mounted thermal cameras that may be physically coupled to a frame worn on the user's head and are utilized to take thermal measurements of one or more regions of interest (ROIs). Some of the systems described in this disclosure are intended for ""real world"", uncontrolled day-to-day use, in which detection of the physiological response may be hampered by ""confounding factors"". A confounding factor can be a cause of warming and/or cooling of certain ROIs the face, which is unrelated to a physiological response being detected, and as such, can reduce the accuracy of the detection of the physiological response.",A61B 5/00; A61B 5/01,FACENSE LTD.,"TZVIELI, Arie; THIEBERGER, Gil; FRANK, Ari M","62/408,677 14.10.2016 US; 62/456,105 07.02.2017 US; 62/480,496 02.04.2017 US",CN-201780077226.3; GB-1906592.9
WO2019143940,PCT/US2019/014199,18.01.2019,WO/2019/143940,25.07.2019,WO,ENHANCED REALITY REHABILITATION SYSTEM AND METHOD OF USING THE SAME,"A network-based rehabilitation system for treating ailments of a user utilizing an enhanced reality environment is provided. The system has an enhanced reality device wearable by the user, the device being in communication with a network and configured to enable a user to interact with the enhanced reality environment to execute a rehabilitation routine; at least one sensor configured to capture biometrics of the user, a condition of the user, or both, wherein the at least one sensor is in communication with the enhanced reality device and the network; a progress analysis module configured to analyze a rehabilitation routine performance of the user, and a routine modification module configured to adjust the rehabilitation routine based on the performance of the user, wherein the routine modification module executes a machine learning algorithm and recommends a routine adjustment based on the machine.",G06F 19/00,"PATEL, Amish; DENISON, Timothy","PATEL, Amish; DENISON, Timothy","62/619,086 18.01.2018 US",
WO2019180255,PCT/EP2019/057336,22.03.2019,WO/2019/180255,26.09.2019,WO,WARE IDENTIFICATION AND HANDLING APPARATUS,"A warewasher system for identifying and handling wares is disclosed. The system comprises a first apparatus for identifying and locating a ware to be transported from a first location to a second location in the warewasher system, and a second apparatus for transporting the ware. The first apparatus comprises means for identifying a region of an image that contains an image part corresponding to at least a part of the ware. The identified region has a perimeter that does not coincide with the perimeter of the image part. The first apparatus also comprises means for determining a location of the region, within the image, and for generating information representing a corresponding spatial location in a receiving area. The second apparatus comprises means for receiving the generated information, and a resilient handling tool for transporting the ware, even when the estimated spatial location is not coincident with the actual spatial location.",B25J 9/16; A47L 15/24; B25J 11/00; G06K 9/00,ELIOR GROUP,"YOUNG, Douglas, Geoffrey; BUCKLEY, James, Edward; FLETCHER, Henry, Matthew, Lawrence; ROBERTS, Christopher, John",1804637.5 22.03.2018 GB,
WO2019143536,PCT/US2019/013372,11.01.2019,WO/2019/143536,25.07.2019,WO,FAILURE DETECTION FOR A NEURAL NETWORK OBJECT TRACKER,"A method of detecting failure of an object tracking network with a failure detection network includes receiving an activation from an intermediate layer of the object tracking network and classifying the activation as a failure or success. The method also includes determining whether to initiate a recovery mode of the object tracking network or to remain in a tracking mode of the object tracking network, based on the classifying.",G06N 3/04; G06N 3/08,QUALCOMM INCORPORATED,"HABIBIAN, Amirhossein; SNOEK, Cornelis Gerardus Maria","15/877,226 22.01.2018 US",
WO2014165304,PCT/US2014/025979,13.03.2014,WO/2014/165304,09.10.2014,WO,"ACQUISITION, RECOVERY, AND MATCHING OF UNIQUE INFORMATION FROM FILE-BASED MEDIA FOR AUTOMATED FILE DETECTION","A media fingerprint archive system generates and archives media fingerprints from second media content portions such as commercials. A downstream media measurement system can extract/derive query fingerprints from an incoming signal, and query the media fingerprint archive system whether any of the query fingerprints matches any archived fingerprints. If so, the media measurement system can perform media measurements on a specific secondary media content portion from which the matched query fingerprint is derived. If not, the media measurement system can analyze media characteristics of a media content portion to determine whether the media content portion is a secondary media content portion and perform media measurement if needed to. The media measurement system may send fingerprints from an identified secondary media content portion to the media fingerprint archive system for storage.",G06F 17/30,DOLBY LABORATORIES LICENSING CORPORATION,"GRANT, Michael; RADHAKRISHNAN, Regunathan; CHANDLER, Jeff Edwin; MURRIE, Stewart; BABBITT, Michael G.","61/809,001 05.04.2013 US",EP-2014717015; US-14781549; CN-201480020129.7
EP290834905,19196839,12.09.2019,3623961,18.03.2020,EP,PREDICTIVE MODELING WITH MACHINE LEARNING IN DATA MANAGEMENT PLATFORMS,"Techniques are described for integrating prediction capabilities from data management platforms into applications. Implementations employ a data science platform (DSP) that operates in conjunction with a data management solution (e.g., a data hub). The DSP can be used to orchestrate data pipelines using various machine learning (ML) algorithms and/or data preparation functions. The data hub can also provide various orchestration and data pipelining capabilities to receive and handle data from various types of data sources, such as databases, data warehouses, other data storage solutions, internet-of-things (IoT) platforms, social networks, and/or other data sources. In some examples, users such as data engineers and/or others may use the implementations described herein to handle the orchestration of data into a data management platform.",G06F 16/28; G06N 3/06,BUSINESS OBJECTS SOFTWARE LTD,MCSHANE ALAN; KUMAR APOORVA,201816218743 13.12.2018 US; 201862730091 12.09.2018 US,
WO2018158578,PCT/GB2018/050529,01.03.2018,WO/2018/158578,07.09.2018,WO,CLASSIFICATION METHOD AND DEVICE,"A classification method comprises positioning an object and a radar unit in proximity to each other; receiving by the radar unit radar signals reflected from the object; and classifying the object, wherein the classifying is based on the radar signals and/or at least one feature extracted from the radar signals, and the classifying of the object comprises determining classification data for the object.",G01S 7/41,UNIVERSITY COURT OF THE UNIVERSITY OF ST ANDREWS,"YEO, Hui Shyong; QUIGLEY, Aaron; FLAMICH, Gergely; SCHREMPF, Patrick; HARRIS-BIRTILL, David","62/465,325 01.03.2017 US; 62/552,833 31.08.2017 US",EP-2018715902
WO2006055413,PCT/US2005/040905,10.11.2005,WO/2006/055413,26.05.2006,WO,METHODS AND SYSTEMS FOR IDENTIFYING AND LOCALIZING OBJECTS BASED ON FEATURES OF THE OBJECTS THAT ARE MAPPED TO A VECTOR,"A method of identifying and localizing objects belonging to one of three or more classes, includes deriving vectors, each being mapped to one of the objects, where each of the vectors is an element of an N-dimensional space. The method includes training an ensemble of binary classifiers with a CISS technique, using training sets generated with an ECOC technique. For each object corresponding to a class, the method includes calculating a probability that the associated vector belongs to a particular class, using an ECOC probability estimation technique. The method includes generating a confidence map for each object type using the probability calculated for the vector as a confidence value, comparing peaks in the map for the object type with corresponding peaks in maps for other classes, using a highest peak to assign class membership, and localizing the object corresponding to the highest peak.",G06K 9/62; G06K 9/00,"THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK; LONG, Xi; CLEVELAND, W. Louis; YAO, Y. Lawrence","LONG, Xi; CLEVELAND, W. Louis; YAO, Y. Lawrence","60/627,465 11.11.2004 US",
WO2019231516,PCT/US2019/022246,14.03.2019,WO/2019/231516,05.12.2019,WO,"SYSTEM AND METHOD FOR COMPACT, FAST, AND ACCURATE LSTMS","According to various embodiments, a method for generating an optimal hidden-layer long short-term memory (H-LSTM) architecture is disclosed. The H-LSTM architecture includes a memory cell and a plurality of deep neural network (DNN) control gates enhanced with hidden layers. The method includes providing an initial seed H-LSTM architecture, training the initial seed H-LSTM architecture by growing one or more connections based on gradient information and iteratively pruning one or more connections based on magnitude information, and terminating the iterative pruning when training cannot achieve a predefined accuracy threshold.",G10L 15/16; G06F 7/483; G06N 3/04; G06N 3/063; G10L 21/0224,THE TRUSTEES OF PRINCETON UNIVERSITY,"DAI, Xiaoliang; YIN, Hongxu; JHA, Niraj K.","62/677,232 29.05.2018 US",
WO2019099625,PCT/US2018/061219,15.11.2018,WO/2019/099625,23.05.2019,WO,LIGHTWEIGHT VEHICLE LOCALIZATION SYSTEMS AND METHODS,"Systems and methods for autonomous vehicle localization are provided. In one example embodiment, a computer-implemented method includes obtaining, by a computing system that includes one or more computing devices onboard an autonomous vehicle, sensor data indicative of one or more geographic cues within the surrounding environment of the autonomous vehicle. The method includes obtaining, by the computing system, sparse geographic data associated with the surrounding environment of the autonomous vehicle. The sparse geographic data is indicative of the one or more geographic cues. The method includes determining, by the computing system, a location of the autonomous vehicle within the surrounding environment based at least in part on the sensor data indicative of the one or more geographic cues and the sparse geographic data. The method includes outputting, by the computing system, data indicative of the location of the autonomous vehicle within the surrounding environment.",G01C 21/32; G01C 21/00; G01C 21/26; G06K 9/00; G08G 1/0968,"UATC, LLC","MA, Wei-Chiu; WANG, Shenlong; HOMAYOUNFAR, Namdar; LAKSHMIKANTH, Shrinidhi Kowshika; URTASUN, Raquel","62/586,759 15.11.2017 US; 16/123,289 06.09.2018 US",
WO2017161128,PCT/US2017/022724,16.03.2017,WO/2017/161128,21.09.2017,WO,OPTICAL IMPLEMENTATION OF MACHINE LEARNING FOR REAL TIME INCREASED CONTRAST VIA MULTIPLE WAVELENGTH lLLUMINATION WITH TUNABLE POWER,"An imaging system (e.g., hyperspectral imaging system) receives an indication to compare a first object and a second object (e.g., two anatomical structures or organs in a medical environment). The imaging system accesses a classification vector for the first object and the second object, the classification vector having been extracted by separating a plurality of collected reflectance values for the first object from a plurality of collected reflectance values for the second object. A set of optimal illumination intensities for one or more spectral illumination sources of the imaging system is determined based on the extracted classification vector. The first and second objects are illuminated with the determined illumination intensities. A high-contrast image of the first and second objects is provided for display, such that the two objects can be readily distinguished in the image. The intensity of pixels in the image is determined by the illumination intensities.",G06K 9/20; G06K 9/62,VERILY LIFE SCIENCES LLC,"REPHAELI, Eden; GANAPATI, Vidya; PIPONI, Daniele; TEISSEYRE, Thomas","62/310,539 18.03.2016 US",EP-2017717924
WO2020048620,PCT/EP2018/074215,07.09.2018,WO/2020/048620,12.03.2020,WO,METHOD AND SYSTEM FOR PROCESSING AN IMAGE BY DETERMINING ROTATION HYPOTHESES,"A system and a method for processing an image comprising inputting the image to a neural network configured to: obtain (2) a plurality of feature maps, each feature map having a respective resolution and a respective depth, perform (3) a classification on each feature map to deliver, for each feature map: - the type of at least one object visible on the image, - the position and shape in the image of at least one two-dimensional bounding box surrounding the at least one object, - a plurality of rotation hypotheses for the at least one object.",G06K 9/00; G06T 7/70,TOYOTA MOTOR EUROPE; TECHNICAL UNIVERSITY OF MUNICH,"MEIER, Sven; KOBORI, Norimasa; MANHARDT, Fabian; ARROYO, Diego, Martin; TOMBARI, Federico; RUPPRECHT, Christian",,
WO2008103412,PCT/US2008/002293,21.02.2008,WO/2008/103412,28.08.2008,WO,REPRESENTATIVE IMAGE SELECTION BASED ON HIERARCHICAL CLUSTERING,"In a computer-mediated method for providing representative images, image records are classified spatio-temporally into groups. In each group, image records are partitioned into clusters and the hierarchically highest cluster is ascertained. The partitioning is between a hierarchy of feature clusters and a remainder cluster, based on a predetermined plurality of saliency features. Feature clusters each have one or more of the saliency features. The remainder cluster lacks the saliency features. Feature clusters are each exclusive of the saliency features of any higher clusters in the hierarchy and non-exclusive of the saliency features of any lower feature clusters in the hierarchy. A representative image of each group is designated from respective image records based on: the respective saliency feature of the highest cluster when the highest cluster is a feature cluster and independent of the saliency features when the highest cluster is the remainder cluster.",G06F 17/30,"EASTMAN KODAK COMPANY; BLOSE, Andrew, C.; LOUI, Alexander, C.","BLOSE, Andrew, C.; LOUI, Alexander, C.","11/677,617 22.02.2007 US",EP-2008725883; JP-2009550913
EP12798924,96302120,27.03.1996,0737938,16.10.1996,EP,Method and apparatus for processing visual information,"A 2D image supplied from an image input unit including a wide view lens is sampled into a discrete form by an array sensor, and then mapped to a multi-resolution space by a 2D filter. The feature of the supplied image is detected, and then the mapped image is transformed to a local pattern about the detected feature, and then the coordinates of the position of the feature and the code word of the local pattern are formed into a set which is then encoded. The code is supplied to each cell of a stochastic automaton. The quantity of visual information is calculated in accordance with the quantity of mutual information between different cells of the stochastic automaton consisting of cells in blocks, the coordinates of the position of the feature and the distance from the feature to the optical axis so as to control the optical axis of the image input unit in such a manner that the quantity of visual information is maximized. <IMAGE>",G06T 7/00; G06T 7/20; G06T 5/20,CANON KK,WASHIZAWA TERUYOSHI,7658395 31.03.1995 JP,
WO2019145098,PCT/EP2018/085804,19.12.2018,WO/2019/145098,01.08.2019,WO,NON-INVASIVE ELECTROPHYSIOLOGY MAPPING BASED ON AFFORDABLE ELECTROCARDIOGRAM HARDWARE AND IMAGING,"For non-invasive EP mapping, a sparse number of electrodes (e.g., 10 in a typical 12-lead ECG exam setting) are used to generate an EP map without requiring preoperative 3D image data (e.g. MR or CT). An imager (e.g., a depth camera) captures the surface of the patient and may be used to localize electrodes in any positioning on the patient. Two-dimensional (2D) x-rays, which are commonly available, and the surface of the patient are used to segment the heart of the patient. The EP map is then generated from the surface, heart segmentation, and measurements from the electrodes.",G06T 7/00; A61B 6/02; A61B 5/04; A61B 5/107; A61B 6/00; A61B 5/0402; A61B 5/00; A61B 5/0408; A61B 5/044,SIEMENS HEALTHCARE GMBH,"BROST, Alexander; CHEN, Terrence; MANSI, Tommaso; MIAO, Shun; PASSERINI, Tiziano; SHARMA, Puneet; TUYSUZOGLU, Ahmet","15/878,557 24.01.2018 US",
WO2020008272,PCT/IB2019/051087,11.02.2019,WO/2020/008272,09.01.2020,WO,ZERO-SHOT SKETCH-BASED IMAGE RETRIEVAL TECHNIQUES USING NEURAL NETWORKS FOR SKETCH-IMAGE RECOGNITION AND RETRIEVAL,"This disclosure relates to improved sketch-based image retrieval (SBIR) techniques. The SBIR techniques utilize an architecture comprising three interconnected neural networks to enable zero-shot image recognition and retrieval based on free-hand sketches. Zero-shot learning may be implemented to retrieve one or more images corresponding to the sketches without prior training on all categories of the sketches. The neural network architecture may do so, at least in part, by training encoder hashing functions to mitigate heterogeneity of sketches and images, and by applying semantic knowledge that is learned during a limited training phase to unknown categories.",G06F 16/583; G06K 9/62; G06K 9/66,"INCEPTION INSTITUTE OF ARTIFICIAL INTELLIGENCE, LTD.","SHEN, Yuming; LIU, Li; SHEN, Fumin; SHAO, Ling","16/025,082 02.07.2018 US",
WO2014140541,PCT/GB2014/050695,10.03.2014,WO/2014/140541,18.09.2014,WO,SIGNAL PROCESSING SYSTEMS,"We describe a signal processor, the signal processor comprising: a probability vector generation system, wherein said probability vector generation system has an input to receive a category vector for a category of output example and an output to provide a probability vector for said category of output example, wherein said output example comprises a set of data points, and wherein said probability vector defines a probability of each of said set of data points for said category of output example; a memory storing a plurality of said category vectors, one for each of a plurality of said categories of output example; and a stochastic selector to select a said stored category of output example for presentation of the corresponding category vector to said probability vector generation system; wherein said signal processor is configured to output data for an output example corresponding to said selected stored category.",G06N 3/04; G06N 3/08,GOOGLE INC.,"CORNEBISE, Julien Robert Michel; REZENDE, Danilo Jimenez; WIERSTRA, Daniël Pieter","1304795.6 15.03.2013 GB; 13/925,637 24.06.2013 US",EP-2014715977; CN-201480016209.5
WO2009076203,PCT/US2008/085678,05.12.2008,WO/2009/076203,18.06.2009,WO,SYSTEM AND METHODS FOR FACILITATING COLLABORATION OF A GROUP,A system and method for facilitating collaboration of a group. The system and method provide a ubiquitous anytime/everywhere environment realized through fixed and mobile technologies and scaffolded by group support software. The system includes a collaboration engine having an architecture that supports both generic collaborative processes along with task specific team processes instantiated through a sophisticated suite of advanced modular technologies. The collaboration engine drives dynamic and real time collaborative problem solving and decision making by integrating sensor and human data from the field with group support software that efficiently and effectively manages team interaction.,G06F 17/00; G06Q 50/00; G06F 15/16,"FLORIDA GULF COAST UNIVERSITY; RODRIGUEZ, Walter; OPDENBOSCH, Augusto; CARSTENS, Deborah S.; GOLDIEZ, Brian; FIORE, Stephen M.; KEPUSKA, Veton","RODRIGUEZ, Walter; OPDENBOSCH, Augusto; CARSTENS, Deborah S.; GOLDIEZ, Brian; KEPUSKA, Veton","60/992,513 05.12.2007 US; 61/079,969 11.07.2008 US",
WO2015006632,PCT/US2014/046258,11.07.2014,WO/2015/006632,15.01.2015,WO,FEATURE COMPLETION IN COMPUTER-HUMAN INTERACTIVE LEARNING,"A collection of data that is extremely large can be difficult to search and/or analyze. Relevance may be dramatically improved by automatically classifying queries and web pages in useful categories, and using these classification scores as relevance features. A thorough approach may require building a large number of classifiers, corresponding to the various types of information, activities, and products. Creation of classifiers and schematizers is provided on large data sets. Exercising the classifiers and schematizers on hundreds of millions of items may expose value that is inherent to the data by adding usable meta-data. Some aspects include active labeling exploration, automatic regularization and cold start, scaling with the number of items and the number of classifiers, active featuring, and segmentation and schematization.",G06N 99/00; G06F 17/27,"MICROSOFT TECHNOLOGY LICENSING, LLC","SIMARD, Patrice Y.; CHICKERING, David Max; GRANGIER, David G.; CHARLES, Denis X.; BOTTOU, Leon; GARCIA JURADO SUAREZ, Carlos","61/845,844 12.07.2013 US; 14/075,701 08.11.2013 US",CN-201480039790.2; EP-2014745314
EP14939433,05795653,18.10.2005,1936545,25.06.2008,EP,ACTION GUIDELINE DECISION DEVICE,"An action agenda determining apparatus for determining an agenda of action to be taken with reference to surrounding situation is provided. An action agenda determining apparatus 42 includes a matching model storage unit 78 for storing an action agenda determining model that has learned in advance relation between time-sequence of prescribed feature information related to human motion extracted from surrounding images and action agenda to be taken, and a model reference unit 76 for forming the time-sequence of prescribed feature information from the surrounding motion images and referring to the action agenda determining model stored in the matching model storage unit, for determining the action agenda to be taken. Sound may be included as part of the feature information.",G06N 5/04,ATR ADVANCED TELECOMM RES INST,CAMPBELL NICK,2005019080 18.10.2005 JP; 2005243656 25.08.2005 JP,
EP78638600,11798097,20.06.2011,2586873,01.05.2013,EP,METHODS AND DEVICES FOR DETECTING A MICROBIAL COLONY,"A method for detecting microorganisms, which comprises: a training step for forming, by a classifier, feature vectors based on color data on individual points within a subject region of training in a culture medium, mapping the points in the culture medium, that are specified by the feature vectors, on a high-dimensional feature space, and linearly separating a set of the points È (x1), that are specified by the high-dimensional feature vectors thus obtained, to thereby color-classify the class (C1) of the culture medium; and a identifying step for forming, by a classifier, feature vectors based on color data on individual inspection points within a region in the culture medium using image data obtained by capturing an image of the culture medium under cultivation, mapping the inspection points (xj), that are specified by the feature vectors, on a high-dimensional feature space, and determining whether or not the mapped points È (xj), that are specified by the high-dimensional feature vectors thus obtained, belong to the class (C1) of the culture medium, thereby identifying a colony based on inspection points not belonging to the class (C1) of the culture medium.",C12Q 1/04; C12M 1/34; C12Q 1/02; G06K 9/00; G06T 7/00,N TECH KK; YAKULT HONSHA KK; TOHOSHOJI KABUSHIKI KAISHA,LI SHENGLAN; NISHIDA TAKASHI; KAI CHIZUKA; TOYOSHIMA KUNIMITSU,2010143161 23.06.2010 JP; 2011064078 20.06.2011 JP,
EP13481251,00307370,29.08.2000,1083536,14.03.2001,EP,A method and apparatus for interactive language instruction,"A method and apparatus for interactive language instruction is provided that displays text files for processing, provide key features and functions for interactive learning, displays facial animation, and provides a workspace for language building functions. The system includes a stored set of language rules as part of the text-to-speech sub-system, as well as another stored set of rules as applied to the process of learning a language. The method implemented by the system includes digitally converting text to audible speech, providing the audible speech to a user or student (with the aid of an animated image in selected circumstances), prompting the student to replicate the audible speech, comparing the student's replication with the audible speech provided by the system, and providing feedback and reinforcement to the student by, for example, selectively recording or playing back the audible speech and the student's replication.",G09B 5/06; G09B 19/04; G06F 3/048; G06F 3/16; G06Q 50/00; G06T 13/00; G09B 5/04; G09B 5/14; G09B 15/00; G09B 19/06; G10L 13/00; G10L 13/04; G10L 15/06; G10L 15/22,,ZHOU QIRU; ZHONG JIALIN; AUGUST KATHERINE G; BLACKWOOD NADINE; LI QI P; MCNERNEY MICHELLE; SHIH CHI-LIN; CHANDRASEKARAN SURENDRAN ARUN,39284499 09.09.1999 US,
WO2019133297,PCT/US2018/065732,14.12.2018,WO/2019/133297,04.07.2019,WO,METHODS AND SYSTEMS FOR TRAINING A MACHINE LEARNING SYSTEM USING A REDUCED DATA SET,"Methods and systems are disclosed herein for accurately training a machine learning model with a reduced training data set. A large number of data records may be parsed. Each record may be reduced to a set of symbols representing the composition of each record. A user may assign a classification to each symbol within each record. Records with identical arrangements and classifications of symbols may be grouped together, and a representative sample of data records from each group may be fed into the model as the reduced training data set.",G06K 9/62,"ROVI GUIDES, INC.","ARDHANARI, Sankar; PULIKUNTA, Sai, Rahul Reddy; VENKATARAMAN, Sashikumar; SIDDIQ, Abubakkar; RAMAMOORTHY, Ganesh","15/854,167 26.12.2017 US",
WO2018168908,PCT/JP2018/009903,14.03.2018,WO/2018/168908,20.09.2018,WO,"NOTIFICATION APPARATUS, NOTIFICATION METHOD AND COMPUTER PROGRAM THEREFOR","Provided is a technology for detecting that a new capability has been procured as a result of having performed learning by machine learning, and notifying a user who requires the capability. A notification apparatus is provided with an acceptance unit that accepts a condition designated by a requester, an acquisition unit that acquires a learning result obtained due to predetermined learning being performed by machine learning, a determination unit that determines whether a procured capability of the learning result acquired by the acquisition unit satisfies the condition accepted by the acceptance unit, and a notification unit that notifies the requester if necessary, based on a result of the determination.",G06F 17/30,OMRON CORPORATION,"ANDO, Tanichi",2017-049141 14.03.2017 JP,
WO2012019163,PCT/US2011/046855,05.08.2011,WO/2012/019163,09.02.2012,WO,IDENTIFYING VISUAL MEDIA CONTENT CAPTURED BY CAMERA-ENABLED MOBILE DEVICE,"Automatic identification of media content is at least partially based upon visually capturing a still or video image of media content being presented to a user via another device. The media content can be further refined by determining location of the user, capturing an audio portion of the media content, date and time of the capture, or profile/behavioral characteristics of the user. Identifying the media content can require (1) distinguishing a rectangular illumination the corresponds to a video display; (2) decoding a watermark presented within the displayed image/video; (3) characterizing the presentation sufficiently for determining a particular time stamp or portion of a program; and (4) determining user setting preferences for viewing the program (e.g., close captioning, aspect ratio, language). Thus identified, the media content appropriately formatted can be received for continued presentation on a user interface of the mobile device.",G06K 9/22; G06F 17/30,"QUALCOMM Incorporated; MOMEYER, Brian; SALAZAR, Selena Melissa; FORUTANPOUR, Babak","MOMEYER, Brian; SALAZAR, Selena Melissa; FORUTANPOUR, Babak","12/850,732 05.08.2010 US",EP-2011748527; JP-2013523379; CN-201180038237.3
WO2016139576,PCT/IB2016/051125,01.03.2016,WO/2016/139576,09.09.2016,WO,BRAIN ACTIVITY MEASUREMENT AND FEEDBACK SYSTEM,"A head set (2) comprises a brain electrical activity (EEG) sensing device (3) comprising EEG sensors (22) configured to be mounted on a head of a wearer so as to position the EEG sensors (22) at selected positions of interest over the wearers scalp, the EEG sensing device comprising a sensor support (4) and a flexible circuit (6) assembled to the sensor support. The sensor support and flexible circuit comprise a central stem (4a, 6a) configured to extend along a center plane of the top of the head in a direction from a nose to a centre of the back of a wearers head, a front lateral branch (4b, 6b) configured to extend across a front portion of a wearer's head extending laterally from the central stem, a center lateral branch (4c, 6c) configured to extend across a top portion of a wearer's head essentially between the wearer's ears, and a rear lateral branch (4d, 6d) configured to extend across a back portion of a wearer's head. The sensor support (4) comprises a base wall (401) and side walls (402) extending along edges of the base wall to form an essentially flat ""U"" shaped channel (403) in which the flexible circuit (6) is inserted and the base wall comprise EEG sensor orifices (404) to allow access to the EEG sensor contacts or electrodes on the flexible circuit.",A61B 5/0478; A61B 5/00; A61B 5/01; A61B 5/04; A61B 5/0402; A61B 5/0482; A61B 5/0488; A61B 5/0496; A61B 5/053; A61B 5/11; G02B 27/01; G06F 3/01,MINDMAZE SA,"TADI, Tej; GARIPELLI, Gangadhar; PEREZ MARCOS, Daniel; BOURDAUD, Nicolas; CHAVEZ CASTANEDA, Gerardo de Jesus; BOLOMEY, Leandre",15157206.2 02.03.2015 EP,EP-2016710815; US-15555561
WO2019137912,PCT/EP2019/050340,08.01.2019,WO/2019/137912,18.07.2019,WO,COMPUTER VISION PRE-FUSION AND SPATIO-TEMPORAL TRACKING,The present invention relates to a new image processing method of several images (IMG). At first a plurality of predetermined image features is defined. On the basis of this plurality of predetermined image features image feature information of each of the several images (IMG) is determined. The so determined image feature information is fused into a new image. This process is also called an image fusion (IF). A spatio-temporal tracking of an object of the new image is enabled by using a probabilistic graphical model (PGM). The probabilistic graphical model (PGM) can be modified by a hierarchical modelling or order decoupling. Furthermore specific boundary conditions can be defined to adapt the probabilistic graphical model (PGM). The new fused image comprises an increased information density thanks to the image fusion (IF). This preferably leads to a new image with increased information density. It usually allows for an improved modelling within the probabilistic graphical model (PGM) and improved spatio-temporal tracking of objects.,G06T 7/20; G06T 7/277,CONNAUGHT ELECTRONICS LTD.,"YOGAMANI, Senthil",10 2018 100 667.5 12.01.2018 DE,
WO2006017497,PCT/US2005/027410,01.08.2005,WO/2006/017497,16.02.2006,WO,TIME-LAPSING DATA METHODS AND SYSTEMS,"A system includes an image storage device (Fig. 5, 202, 204, 206) configurable to store at least one historical image of at least a part of a patient, an image playback device (Fig. 5, 106) (i) configurable to present responsive to a medical expert specification related to at least a part of an image of the patient and (ii) operably couplable to the image storage device and an image sequencing engine (Fig. 5, 404) (i) operably couplable to the image playback device and (ii) configurable to present at least a part of the at least one historical image in a time-lapse context.",G06K 9/54,"SEARETE LLC; ALLEN, Paul G.; JUNG, Edward K. Y.; LEVIEN, Royce A.; MALAMUD, Mark A.; RINALDO, John D., Jr.","ALLEN, Paul G.; JUNG, Edward K. Y.; LEVIEN, Royce A.; MALAMUD, Mark A.; RINALDO, John D., Jr.","10/910,421 02.08.2004 US; 10/912,271 05.08.2004 US; 10/941,803 15.09.2004 US; 10/951,002 27.09.2004 US; 10/972,319 22.10.2004 US",EP-2005777515; KR-1020077005006
EP252257025,18163096,21.03.2018,3543898,25.09.2019,EP,FAST DETECTION OF SECONDARY OBJECTS THAT MAY INTERSECT THE TRAJECTORY OF A MOVING PRIMARY OBJECT,,G06K 9/00,BOSCH GMBH ROBERT; CHRONOCAM SA,PFEIFFER MICHAEL; MARX JOCHEN; LANGE OLIVER; POSCH CHRISTOPH; LAGORCE XAVIER; NIKOLAIDIS SPIROS,18163096 21.03.2018 EP,
WO2003071410,PCT/US2003/004979,18.02.2003,WO/2003/071410,28.08.2003,WO,GESTURE RECOGNITION SYSTEM USING DEPTH PERCEPTIVE SENSORS,"Three-dimensional position information is used to identify the gesture created by a body part of interest. At one or more instances of an interval, the posture of a body part is recognized, based on the shape of the body part and its position and orientation. The posture of the body part over each of the one or more instances in the interval are recognized as a combined gesture. The gesture is classified for determining an input into a related electronic device.",G06F 3/00; G06K 9/00,"CANESTA, INC.","GOKTURK, Salih, Burak; TOMASI, Carlo; SÜRÜCÜ, Fahri; RAFII, Abbas","60/357,730 15.02.2002 US; 60/394,068 02.07.2002 US; 60/410,415 13.09.2002 US",JP-null
EP281666901,19182892,26.03.2018,3594813,15.01.2020,EP,COMPUTE OPTIMIZATIONS FOR LOW PRECISION MACHINE LEARNING OPERATIONS,,G06F 9/50; G06F 9/30; G06F 9/38; G06N 3/04; G06N 3/063; G06N 3/08; G06T 1/20; G06T 15/00,INTEL CORP,OULD-AHMED-VALL ELMOUSTAPHA; BAGHSORKHI SARA S; YAO ANBANG; NEALIS KEVIN; CHEN XIAOMING; KOKER ALTUG; APPU ABHISHEK R; WEAST JOHN C; MACPHERSON MIKE B; KIM DUKHWAN; HURD LINDA L; ASHBAUGH BEN J; LAKSHMANAN BARATH; MA LIWEI; RAY JOYDEEP; TANG PING T; STRICKLAND MICHAEL S,18164092 26.03.2018 EP; 201715581167 28.04.2017 US,
EP160060121,15181884,20.08.2015,2993618,09.03.2016,EP,DOMAIN ADAPTATION FOR IMAGE CLASSIFICATION WITH CLASS PRIORS,"In camera-based object labeling, boost classifier      f  T    x   =      ˆ‘   r  =  1   M      ²  r     h  r    x       is trained to classify an image represented by feature vector x using a target domain training set  D T   of labeled feature vectors representing images acquired by the same camera and a plurality of source domain training sets  D S 1  ,...,D S N    acquired by other cameras. The training applies an adaptive boosting (AdaBoost) algorithm to generate base classifiers  h r  (x) and weights  ²  r . The  r th   iteration of the AdaBoost algorithm trains candidate base classifiers      h  r  k    x       each trained on a training set  D T UD S k  ,  and selects  h r  (x) from previously trained candidate base classifiers. The target domain training set  D T   may be expanded based on a prior estimate of the labels distribution for the target domain. The object labeling system may be a vehicle identification system, a machine vision article inspection system, or so forth.",G06K 9/00; G06K 9/62,XEROX CORP,CHIDLOVSKII BORIS; CSURKA GABRIELA,201414477215 04.09.2014 US,
WO2019217107,PCT/US2019/029526,27.04.2019,WO/2019/217107,14.11.2019,WO,BLOCK FLOATING POINT COMPUTATIONS USING SHARED EXPONENTS,"A system for block floating point computation in a neural network receives a plurality of floating point numbers. An exponent value for an exponent portion of each floating point number of the plurality of floating point numbers is identified and mantissa portions of the floating point numbers are grouped. A shared exponent value of the grouped mantissa portions is selected according to the identified exponent values and then removed from the grouped mantissa portions to define multi-tiered shared exponent block floating point numbers. One or more dot product operations are performed on the grouped mantissa portions of the multi-tiered shared exponent block floating point numbers to obtain individual results. The individual results are shifted to generate a final dot product value, which is used to implement the neural network. The shared exponent block floating point computations reduce processing time with less reduction in system accuracy.",G06F 7/487; G06F 17/16,"MICROSOFT TECHNOLOGY LICENSING, LLC","LO, Daniel; CHUNG, Eric Sen","15/974,643 08.05.2018 US",
EP12683837,95201518,09.06.1995,0689154,27.12.1995,EP,An evidential confidence measure and rejection technique for use in a neural network based optical character recognition system,"Apparatus, and an accompanying method, for use in, e.g., a neural network-based optical character recognition (OCR) system (5) for accurately classifying each individual character extracted from a string of characters, and specifically for generating a highly reliable confidence measure that would be used in deciding whether to accept or reject each classified character. Specifically, a confidence measure, associated with each output of, e.g., a neural classifier (165), is generated through use of all the neural activation output values. Each individual neural activation output provides information for a corresponding atomic hypothesis of an evidence function. This hypothesis is that a pattern belongs to a particular class. Each neural output is transformed (1650) through a pre-defined monotonic function into a degree of support in its associated evidence function. These degrees of support are then combined (1680, 1690) through an orthogonal sum to yield a single confidence measure associated with the specific classification then being produced by the neural classifier. <IMAGE>",G06K 9/66; G06K 9/34; G06K 9/66,EASTMAN KODAK CO,SHUSTOROVICH ALEXANDER; TRASHER CHRISTOPHER WILLIAM C,26330494 21.06.1994 US; 36139194 21.12.1994 US,
WO2018007968,PCT/IB2017/054069,06.07.2017,WO/2018/007968,11.01.2018,WO,METHOD OF AND APPARATUS FOR DIAGNOSING LEG PATHOLOGIES IN QUADRUPEDS,"An automatic method of diagnosing pathologies of the distal parts of the limbs of a quadruped is based on the processing (101 - 109) of thermographic images of such limbs. The processing includes the following steps: identifying (103, 104), in each thermographic image and for each limb concerned by the diagnosis, an area containing the distal part, and extracting an identified image of the distal part from said area; validating (104) identified images complying with predetermined criteria as images utilisable for diagnostic purposes; extracting (105) features that are significant for the detection of the presence and the kind of pathology from the validated images; and classifying (106) the distal part of a limb as unaffected by pathologies or as affected by a specific pathology on the basis of such features. There are also provided an apparatus implementing the method and an information technology product containing program codes for implementing the method when the product is loaded into a processing device.",A61B 5/01,COWMATIX S.R.L.,"MIODINI, Marzio; SALA, Leonardo",16178313.9 07.07.2016 EP,RU-2018143985; EP-2017737883
WO2019177181,PCT/KR2018/002868,12.03.2018,WO/2019/177181,19.09.2019,WO,"AUGMENTED REALITY PROVISION APPARATUS AND PROVISION METHOD RECOGNIZING CONTEXT BY USING NEURAL NETWORK, AND COMPUTER PROGRAM, STORED IN MEDIUM, FOR EXECUTING SAME METHOD","An augmented reality provision method, which recognizes a context by using a neural network, according to the present embodiment, comprises the steps of: acquiring an image by a processor; analyzing, by the processor, the image and rendering the image to arrange a virtual object on a plane included in the image; determining whether there is a change of scene in the current frame included in the image by comparing the current frame with the previous frame, and determining whether to process context recognition for the image by taking into account whether there is a change of scene in the current frame; if it is determined that the context recognition process is to take place, analyzing the image and/or a sensing value received from a sensor unit by using a neural network, so as to calculate one or more items of context information; and generating additional content to which the context information is applied, and providing the additional content.",G06K 9/00; G06K 9/46; G06K 9/62; H04N 21/81; H04N 5/14; G06N 3/04,LINE PLUS CORPORATION; 라인플러스(주),"CHOI, Sang Jo; 최상조; PARK, Hee Cheol; 박희철; NOH, Hyoung Jun; 노형준",,
WO2018089158,PCT/US2017/056195,11.10.2017,WO/2018/089158,17.05.2018,WO,NATURAL LANGUAGE OBJECT TRACKING,"A method of tracking an object across a sequence of video frames using a natural language query includes receiving the natural language query and identifying an initial target in an initial frame of the sequence of video frames based on the natural language query. The method also includes adjusting the natural language query, for a subsequent frame, based on content of the subsequent frame and/or a likelihood of a semantic property of the initial target appearing in the subsequent frame. The method further includes identifying a text driven target and a visual driven target in the subsequent frame. The method still further includes combining the visual driven target with the text driven target to obtain a final target in the subsequent frame.",G06K 9/00; G06N 3/04; G06F 17/30,QUALCOMM INCORPORATED,"LI, Zhenyang; TAO, Ran; GAVVES, Efstratios; SNOEK, Cornelis Gerardus Maria; SMEULDERS, Arnold Wilhelmus Maria","62/420,510 10.11.2016 US; 15/587,196 04.05.2017 US",
WO2007011976,PCT/US2006/027960,19.07.2006,WO/2007/011976,25.01.2007,WO,CRASH PREDICTION NETWORK WITH VISUAL INPUT FOR VEHICLE,"A method for facilitating the avoidance of a vehicle collision with an object includes the following steps: a) providing an environment for generating training examples, b) evolving a good driver using a visual input, c) evolving a crash predictor using a visual input, and d) outputting a warning signal.",G06F 15/18,"TOYOTA ENGINEERING & MANUFACTURING NORTH AMERICA, INC.; THE BOARD OF REGENTS, THE UNIVERSITY OF TEXAS SYSTEM; SHERONY, Rini; MIIKKULAINEN, Risto, P.; STANLEY, Kenneth, O.; KOH, Nathaniel, F.","SHERONY, Rini; MIIKKULAINEN, Risto, P.; STANLEY, Kenneth, O.; KOH, Nathaniel, F.","60/700,610 19.07.2005 US; 11/458,261 18.07.2006 US",DE-null
WO2019059579,PCT/KR2018/010748,13.09.2018,WO/2019/059579,28.03.2019,WO,DEVICE AND METHOD FOR PROVIDING RESPONSE TO DEVICE USAGE INQUIRY,"Provided are a device for providing a response operation corresponding to a device usage inquiry and a method of controlling the device. The method of controlling a device for providing a response operation corresponding to a device usage inquiry may include: receiving a user input corresponding to the device usage inquiry; classifying the device usage inquiry by analyzing the received user input corresponding to the device usage inquiry; extracting operation scenario information corresponding to a result of the classifying the device usage inquiry; and executing preset response operations of the device based on the operation scenario information, wherein the classifying includes classifying the device usage inquiry by inputting the user input of the device usage inquiry to a learning model that is a pre-generated.",G06F 9/451; G06N 3/08,"SAMSUNG ELECTRONICS CO., LTD.","JEONG, Man-un; JO, Seo-young; CHOI, Chang-hwan",10-2017-0120511 19.09.2017 KR,EP-2018859583
WO2019086760,PCT/FI2018/050791,31.10.2018,WO/2019/086760,09.05.2019,WO,GENERATION OF A CONTROL SYSTEM FOR A TARGET SYSTEM,"The invention relates to a method for generating a control system (120) for a target system (1 10), wherein: operational data (210) is received; a first neural model component (310) is trained with the received operational data for generating a prediction on a state of the target system (1 10) based on the received operational data; a second neural model component (320) is trained with the operational data for generating a regularizer for use in inverting the first neural model component; and the control system (120) is generated (330) by inverting the first neural model component by optimization and arranging to apply the regularizer generated with the second neural model component in the optimization. The invention relates also to a system and a computer program product.",G05B 13/02; G05B 13/04,CURIOUS AI OY,"VALPOLA, Harri; KOPPALI, Eva",20175970 01.11.2017 FI,
WO2018071403,PCT/US2017/055909,10.10.2017,WO/2018/071403,19.04.2018,WO,SYSTEMS AND METHODS FOR OPTICAL CHARATER RECOGNITION FOR LOW-RESOLUTION DUCUMENTS,"Systems and methods for optical character resolution (OCR) at low resolutions are provided. The system receives a dataset and extracts document images from the dataset. The system then segments and extracts a plurality of text lines from the document images. The system then processes the plurality of text lines using a Recurrent Neural Network (RNN) with Long Short Term Memory (LSTM) module to perform line OCR. Finally, the system generates a plurality of text strings corresponding to the plurality of text lines.",G06F 9/45,"INSURANCE SERVICES OFFICE, INC.","WANG, Shuai; SIGH, Maneesh Kumar","62/406,665 11.10.2016 US; 62/406,272 10.10.2016 US",
WO2019191002,PCT/US2019/023924,25.03.2019,WO/2019/191002,03.10.2019,WO,OBJECT MOVEMENT BEHAVIOR LEARNING,"In various examples, a set of object trajectories may be determined based at least in part on sensor data representative of a field of view of a sensor. The set of object trajectories may be applied to a long short-term memory (LSTM) network to train the LSTM network. An expected object trajectory for an object in the field of view of the sensor may be computed by the LSTM network based at least in part an observed object trajectory. By comparing the observed object trajectory to the expected object trajectory, a determination may be made that the observed object trajectory is indicative of an anomaly.",G06K 9/00,NVIDIA CORPORATION,"NAPHADE, Milind; WANG, Shuo","62/648,339 26.03.2018 US; 16/363,869 25.03.2019 US",
WO2018152093,PCT/US2018/017962,13.02.2018,WO/2018/152093,23.08.2018,WO,METHOD OF DIAGNOSING CANCER USING MITOCHONDRIAL DNA HETEROGENEITY,The present invention relates to diagnosing cancer based on measurements of sequence heterogeneity in mitochondrial genomic DNA.,G06F 19/10; G16H 50/20; G16H 50/00,"THE UNITED STATES OF AMERICA, AS REPRESENTED BY THE SECRETARY, DEPARTMENT OF HEALTH AND HUMAN SERVICES","CAMPO, Davis S.","62/459,406 15.02.2017 US",
WO2006113394,PCT/US2006/013985,14.04.2006,WO/2006/113394,26.10.2006,WO,"SURGICAL INSTRUMENTS WITH SENSORS FOR DETECTING TISSUE PROPERTIES, AND SYSTEMS USING SUCH INSTRUMENTS","A system is provided that furnishes expert procedural guidance based upon patient-specific data gained from surgical instruments incorporating sensors on the instrument's working surface, one or more reference sensors placed about the patient, sensors implanted before, during or after the procedure, the patient's personal medical history, and patient status monitoring equipment. Embodiments include a system having a surgical instrument with a sensor for generating a signal indicative of a property of a subject tissue of the patient, which signal is converted into a current dataset and stored. A processor compares the current dataset with other previously stored datasets, and uses the comparison to assess a physical condition of the subject tissue and/or to guide a procedure being performed on the tissue.",A61B 5/00; A61B 17/00; A61M 25/00,"SURGISENSE CORPORATION; ZAND, Jason, Matthew; FISCHER, Gregory, Scott","ZAND, Jason, Matthew; FISCHER, Gregory, Scott","60/671,872 15.04.2005 US; 60/766,359 12.01.2006 US",EP-2006758332; EP-2016001279; CA-2604563; CN-200680021505.X; US-11918456; RU-null; DE-null
WO2016022108,PCT/US2014/049839,06.08.2014,WO/2016/022108,11.02.2016,WO,SYSTEMS AND METHODS INVOLVING FEATURES OF ADAPTIVE AND/OR AUTONOMOUS TRAFFIC CONTROL,"Systems and method are disclosed for adaptive and/or autonomous traffic control. In one illustrative implementation, there is provided a method for processing traffic information. Moreover, the method may include receiving data regarding travel of vehicles associated with an intersection, using neural network technology to recognize types and/or states of traffic, and using the neural network technology to process/determine/memorize optimal traffic flow decisions as a function of experience information. Exemplary implementations may also include using the neural network technology to achieve efficient traffic flow via recognition of the optima! traffic flow decisions.",G06F 19/00,"ROBINSON, Kurt, B.","ROBINSON, Kurt, B.",,
EP210574526,15889219,17.04.2015,3276542,31.01.2018,EP,PROCESSING SYSTEM AND PROGRAM,"A processing system that processes parameters of a plurality of artificial neurons and artificial synapses constituting a neural network, the processing system including: a storing unit storing definition information defining a state of a control target for each artificial neuron of the plurality of artificial neurons; a processing unit processing parameter values of each artificial neuron of the plurality of artificial neurons and parameter values of one or more artificial synapses connected to inputs of each artificial neuron using a data access structure accessible data unit by data unit, the data unit being collective for each artificial neuron; and an operation determining unit determining operation of the control target based on: an activation state of at least some artificial neurons of the plurality of artificial neurons specified by parameter values of the at least some artificial neurons; and a state defined by the at least some artificial neurons.",G06N 3/10; G06N 3/04,COCORO SB CORP,TSUTSUI TAKASHI; TOMONAGA KOSUKE; MIHIRA YUMA,2015061840 17.04.2015 JP,
WO2018197019,PCT/EP2017/060273,28.04.2017,WO/2018/197019,01.11.2018,WO,"SYSTEM AND METHOD FOR DETECTING OBJECTS IN A DIGITAL IMAGE, AND SYSTEM AND METHOD FOR RESCORING OBJECT DETECTIONS.","The invention relates to a system for detecting objects in a digital image. The system comprises a neural network which is configured to generate candidate windows indicating object locations, and to generate for each candidate window a score representing the confidence of detection. Generating the scores comprises: - generating a latent representation for each candidate window, - updating the latent representation of each candidate window based on the latent representation of neighboring candidate windows, and - generating the score for each candidate window based on its updated latent representation The invention further relates to a system for rescoring object detections in a digital image and to methods of detecting objects and rescoring objects.",G06K 9/32,TOYOTA MOTOR EUROPE; MAX-PLANCK-GESELLSCHAFT ZUR FÖRDERUNG DER WISSENSCHAFTEN E.V.,"OLMEDA REINO, Daniel; SCHIELE, Bernt; HOSANG, Jan Hendrik; BENENSON, Rodrigo",,DE-112017007492; JP-2019558478
WO2018094360,PCT/US2017/062626,20.11.2017,WO/2018/094360,24.05.2018,WO,METHODS AND SYSTEMS FOR PREDICTING DNA ACCESSIBILITY IN THE PAN-CANCER GENOME,"Techniques are provided for predicting DNA accessibility. DNase-seq data files and RNA-seq data files for a plurality of cell types are paired by assigning DNase-seq data files to RNA-seq data files that are at least within a same biotype. A neural network is configured to be trained using batches of the paired data files, where configuring the neural network comprises configuring convolutional layers to process a first input comprising DNA sequence data from a paired data file to generate a convolved output, and fully connected layers following the convolutional layers to concatenate the convolved output with a second input comprising gene expression levels derived from RNA-seq data from the paired data file and process the concatenation to generate a DNA accessibility prediction output. The trained neural network is used to predict DNA accessibility in a genomic sample input comprising RNA-seq data and whole genome sequencing for a new cell type.",G06F 19/24; G06F 19/12; G06F 19/26; C12Q 1/68,"NANTOMICS, LLC; NANT HOLDINGS IP, LLC","WNUK, Kamil; SUDOL, Jeremi; RABIZADEH, Shahrooz; SOON-SHIONG, Patrick; SZETO, Christopher; VASKE, Charles","62/540,523 02.08.2017 US; 62/481,574 04.04.2017 US; 62/424,370 18.11.2016 US",AU-2017362569; IL-266692; EP-2017870742; CA-3044254; KR-1020197016912
EP14249268,03291714,09.07.2003,1496446,12.01.2005,EP,Regulating the growth of complexity in developmental systems,"Developmental systems (1/11) are provided with an autotelic mechanism for driving their development. An autotelic component (1) in the system uses a mapping mechanism (2) to produce an output based on a set of inputs. The mapping mechanism (2) implements a mapping that is dependent upon a state associated therewith. The content of the state is changed by a learning/repair module (3) based on interactions between the system and the environment, and so reflects knowledge gained by this component as a result of its experience. The autotelic component (1) monitors its own performance with reference to the level of a set of one or more challenge parameters whose levels quantify the complexity of different parameters relating to the autotelic component (1). The state associated with the mapping mechanism 2 is altered depending upon the component's performance as evaluated during the monitoring. A controller (5) controls the levels of the challenge parameters. <IMAGE>",G06N 3/08; G06F 15/18; G06N 3/00; G06N 3/08,SONY FRANCE SA,STEELS LUC,03291714 09.07.2003 EP,
WO2017206066,PCT/CN2016/084128,31.05.2016,WO/2017/206066,07.12.2017,WO,METHOD AND APPARATUS FOR DETECTING SMALL OBJECTS WITH AN ENHANCED DEEP NEURAL NETWORK,"Various methods are provided for training and subsequently utilizing a convolutional neural network (CNN) to detect small pedestrians (e.g., pedestrians located away a large distance). One example method may comprise performing a first training stage in which a first CNN is trained to detect objects of a first size, the first CNN trained using a first set of images comprised of objects of the first size, and configured to output a first set of parameters, performing a second training stage in which a second CNN is trained using a second set of images, the second set of images comprising objects of a second size, and the first CNN is initialized with the first set of parameters and is re-trained using the second set of images, and determining parameters of the first CNN by minimizing error between the first CNN and the second CNN.",G06K 9/66,"NOKIA TECHNOLOGIES OY; CAO, Jiale","CAO, Jiale",,
EP248884878,19151349,11.01.2019,3511863,17.07.2019,EP,DISTRIBUTABLE REPRESENTATION LEARNING FOR ASSOCIATING OBSERVATIONS FROM MULTIPLE VEHICLES,,G06K 9/00; G06K 9/62,TOYOTA MOTOR CO LTD,GUO RUI; OGUCHI KENTARO,201815870875 13.01.2018 US,
WO2014018793,PCT/US2013/052127,25.07.2013,WO/2014/018793,30.01.2014,WO,APPARATUS AND METHODS FOR EFFICIENT UPDATES IN SPIKING NEURON NETWORKS,"Efficient updates of connections in artificial neuron networks may be implemented. A framework may be used to describe the connections using a linear synaptic dynamic process, characterized by stable equilibrium. The state of neurons and synapses within the network may be updated, based on inputs and outputs to/from neurons. In some implementations, the updates may be implemented at regular time intervals. In one or more implementations, the updates may be implemented on- demand, based on the network activity (e.g., neuron output and/or input) so as to further reduce computational load associated with the synaptic updates. The connection updates may be decomposed into multiple event-dependent connection change components that may be used to describe connection plasticity change due to neuron input. Using event-dependent connection change components, connection updates may be executed on per neuron basis, as opposed to per- connection basis.",G06F 15/18; G10L 25/30,"QUALCOMM TECHNOLOGIES, INC.","SINYAVSKIY, Oleg; POLONICHKO, Vadim; IZHIKEVICH, Eugene","13/560,891 27.07.2012 US",KR-1020157004869
WO2009015008,PCT/US2008/070439,18.07.2008,WO/2009/015008,29.01.2009,WO,METHOD AND APPARATUS FOR AUTOMATED DIFFERENTIATED DIAGNOSIS OF ILLNESS,"This method and apparatus for automated differential diagnosis of illness utilizes neural network technology to analyze information that has been collected and assimilated from multiple sources, including information concerning lifestyle and travel habits, occupational and environmental risks and other contributory factors, and compares this information to, and incorporates it into, databases, to render diagnoses as well as alerts regarding anomalous concentrations of illnesses. The invention has similar application in the area of mechanical maintenance and repair.",G01N 33/48,"NAGY, David, S.","KOZUCH, Michael, J.; SMITH, James, E. III; FATE, Timothy, A.","60/951,418 23.07.2007 US; 12/172,419 14.07.2008 US",
WO2019190391,PCT/SG2018/050481,20.09.2018,WO/2019/190391,03.10.2019,WO,EMBEDDING MEDIA CONTENT ITEMS IN TEXT OF ELECTRONIC DOCUMENTS,"A playable media content item is received. An electronic document that includes text is accessed, and a portion of text of the electronic document is analyzed by natural language processing to extract a keyword associated with the portion of text. The media content item is associated with the portion of text based on a determined match the media content item and the keyword associated with the portion of text. The association is sent over a computer network to a publisher of the electronic document for linking the media content item to the portion of text.",G06F 17/27; G06F 16/00; G06F 3/048; G06Q 30/02,SPAYCE ASIA PTE LTD,"COLANGELO, Patrick M.","15/942,247 30.03.2018 US",
WO1993019431,PCT/GB1993/000580,22.03.1993,WO/1993/019431,30.09.1993,WO,PARALLEL VECTOR PROCESSOR ARCHITECTURE,"A parallel vector processor (PVP) is described which can be implemented on a single silicon die or multiple dies using single-instruction multiple data (SIMD) or multiple-instruction multiple data (MIMD) architecture containing at leat one data processor with at least one data stream coupled thereto for inputting data and removing results. The PVP apparatus can be incorporated in any suitable communication network topology. In one arrangement this is achieved most readily by providing the parallel vector processor on a single a chip using single-instruction, multiple data (SIMD architecture) containing a plurality of data processors organised into a pipeline with an input/output stream for supplying the processors with data and to remove the results. Although a single input/output stream can be used it is desirable to use at least two streams to facilitate optimum performance. The PVP has applications in neural networks, pattern recognition and a variety of signal processing applications.",F02B 75/02; G06F 15/80; G06T 1/20,"MAXYS CIRCUIT TECHNOLOGY LTD.; MACKIE, Stuart; MACKAY, Stuart","MACKIE, Stuart; MACKAY, Stuart",9206126.6 20.03.1992 GB,
WO2018124309,PCT/JP2017/047417,25.12.2017,WO/2018/124309,05.07.2018,WO,METHOD AND SYSTEM FOR MULTI-MODAL FUSION MODEL,"A system for generating a word sequence includes one or more processors in connection with a memory and one or more storage devices storing instructions causing operations that include receiving first and second input vectors, extracting first and second feature vectors, estimating a first set of weights and a second set of weights, calculating a first content vector from the first set of weights and the first feature vectors, and calculating a second content vector, tranforming the first content vector into a first modal content vector having a predetermined dimension and tranforming the second content vector into a second modal content vector having the predetermined dimension, estimating a set of modal attention weights, generating a weighted content vector having the predetermined dimension from the set of modal attention weights and the first and second modal content vectors, and generating a predicted word using the sequence generator.",H04N 21/2343; H04N 21/439; H04N 21/8549; G06N 3/04; G10L 25/30; G10L 25/57; G06F 17/30,MITSUBISHI ELECTRIC CORPORATION,"HORI, Chiori; HORI, Takaaki; HERSHEY, John; MARKS, Tim","62/440,433 30.12.2016 US; 15/472,797 29.03.2017 US",DE-112017006685; CN-201780079516.1; JP-2019513858
WO2020020472,PCT/EP2018/072857,24.08.2018,WO/2020/020472,30.01.2020,WO,A COMPUTER-IMPLEMENTED METHOD AND SYSTEM FOR DETECTING SMALL OBJECTS ON AN IMAGE USING CONVOLUTIONAL NEURAL NETWORKS,"A computer-implemented method and system for detecting small objects on an image using convolutional neural networks. The method comprises: applying convolution operations (210) to an input image (102) to obtain a first set of convolutional layers (212) and an input feature map (302); analyzing the input feature map (302) to determine a first set of candidate regions (222) containing candidate objects; arranging the first set of candidate regions (222) to form a reduced feature map (228); applying convolution operations (230) to the reduced feature map (228) to obtain a second set of convolutional layers (232) and an output feature map (502); applying a Region Proposal Network (240) to the output feature map (502) to obtain a second set of candidate regions (242) containing candidate objects; classifying and applying bounding box regression (250) to each candidate region of the second set (242) to obtain, for each candidate region, a class score as a candidate object and a bounding box in the input image (102).",G06K 9/62; G06K 9/00; G06K 9/32; G06K 9/46,FUNDACIÓN CENTRO TECNOLOXICO DE TELECOMUNICACIÓNS DE GALICIA; UNIVERSIDADE DE SANTIAGO DE COMPOSTELA,"BREA SÁNCHEZ, Victor Manuel; MUCIENTES MOLINA, Manuel Felipe; BOSQUET MERA, Brais",P201830753 24.07.2018 ES,
EP14191173,04250943,20.02.2004,1455284,08.09.2004,EP,Image processing method and image processing system,"This invention provides an image processing method which allows easy re-use of image information that is stored to minimize deterioration of image quality and the storage capacity. Storage means is searched for original digital data corresponding to each input image. If no original digital data is found, the input image is converted into vector data, and is stored as digital data in the storage means. A sheet including at least one of information associated with the found original digital data when the original digital data is found in the search step and information associated with digital data which is obtained by converting the image into the vector data in the vectorization step and is stored in the storage step when no original digital data is found in the search step is generated, thus providing a sheet that allows easy re-use. <IMAGE>",G06K 9/20; G06T 1/00; G06F 17/30,CANON KK,KANEDA KITAHIRO; TANIOKA HIROSHI; USAMI AKIHIRO; OHTA KEN-ICHI; ITO HIROHIKO; KATO SHINICHI; AKIBA TOMOHIRO; KANATSU TOMOTOSHI; MISAWA REIJI; TERAO YOSHIHIDE; UZAWA MITSURU,2003044299 21.02.2003 JP,
EP209999738,16305847,05.07.2016,3267438,10.01.2018,EP,METHOD AND SYSTEM FOR FACILITATING THE DETECTION OF TIME SERIES PATTERNS,"According to a first aspect of the present disclosure, a method for facilitating the detection of one or more time series patterns is conceived, comprising building one or more artificial neural networks, wherein, for at least one time series pattern to be detected, a specific one of said artificial neural networks is built. According to a second aspect of the present disclosure, a corresponding computer program is provided. According to a third aspect of the present disclosure, a non-transitory computer-readable medium is provided that comprises a computer program of the kind set forth. According to a fourth aspect of the present disclosure, a corresponding system for facilitating the detection of one or more time series patterns is provided.",G10L 15/16; G10L 15/07,NXP BV,DANIEL ADRIEN,16305847 05.07.2016 EP,
WO2018164435,PCT/KR2018/002593,05.03.2018,WO/2018/164435,13.09.2018,WO,"ELECTRONIC APPARATUS, METHOD FOR CONTROLLING THE SAME, AND NON-TRANSITORY COMPUTER READABLE RECORDING MEDIUM","An electronic apparatus is provided. The electronic apparatus includes an input interface configured to receive a user command, a memory, a display configured to display a content, and a processor configured, in response to a predetermined command with respect to the content being received through the input interface, to acquire context information of the content by analyzing the content, to store the context information together with the information relating to the content in the memory, and in response to a context corresponding to the context information being detected, to control the display to provide a content corresponding to the detected context. At least some of a method for controlling the electronic apparatus may use a rules-based model or an artificial intelligence model which is trained according to at least one of a machine learning, a neural network, and a deep learning algorithm. For example, the artificial intelligence model may provide context information, which is a result of determination using a content as an input value, to the electronic apparatus.",G06F 17/30,"SAMSUNG ELECTRONICS CO., LTD.","AHN, Hyoung-joo",10-2017-0029490 08.03.2017 KR; 10-2017-0145925 03.11.2017 KR,EP-2018764090
WO2016200887,PCT/US2016/036368,08.06.2016,WO/2016/200887,15.12.2016,WO,VIDEO CONTENT SEARCHES IN A MEDICAL CONTEXT,"A method of searching video content for specific subject matter of interest augments traditional image data analysis methods with analysis of contemporaneously gathered non-image data. One application involves video recordings of medical procedures performed using a medical device. When a user desires to locate portions of video recordings showing a medical event of interest, one or more medical device system events likely to correspond to the occurrence of the medical event of interest are identified from one or more procedure event logs. Timestamps associated with these system events are used to identify candidate video clips from the procedure video recordings. Image data analysis is performed on the candidate video clips to determine whether each candidate video clip contains the medical event of interest.",G06F 17/30; G06F 19/00; G06F 15/18,"INTUITIVE SURGICAL OPERATIONS, INC.","MOHR, Catherine J.; MILLER, Brian E.","62/173,187 09.06.2015 US",US-15735073; EP-2016808157; JP-2017563923; KR-1020177037645
WO2016155844,PCT/EP2015/067850,03.08.2015,WO/2016/155844,06.10.2016,WO,METHOD AND SYSTEM FOR OBSERVING A PREDETERMINED MONITORING AREA,"A method for observing a predetermined monitoring area, wherein one or more sensing platform nodes are employed to observe a predetermined number of sub-areas of said monitoring area, comprises observing sub-areas of said monitoring area using the sensing platform nodes in order to collect measuring data for said sub-areas, providing at least one prediction model for analyzing predictability of measuring data for said sub-areas on the basis of collected measuring data, calculating future measuring data for said sub-areas and calculating uncertainty of said future measuring data over time by the use of the prediction model, and scheduling the sensing platform nodes for observation of said sub-areas according to a scheduling mechanism, wherein the scheduling of the sensing platform nodes is dependent on the calculated uncertainty of said future measuring data predicted for said sub-areas. Furthermore, a corresponding system is disclosed.",G06N 99/00,NEC EUROPE LTD.,"HILDMANN, Hanno; MARTIN LOPEZ, Miquel",15162087.9 31.03.2015 EP,DE-112015006398; US-15562429
WO2018045400,PCT/ZA2017/050053,05.09.2017,WO/2018/045400,08.03.2018,WO,INCIDENT MANAGEMENT & INFORMATION CAPTURING SYSTEM,"Incident management and information capturing system. The system has a communication infrastructure which includes a mobile client loadable with an application which is executable to provide a user with a hierarchical, menu- based decision tree configured (a) to prompt user input relating to information elements associated with an incident; and (b) for capturing, storing and transmitting the information elements. The system further comprises a data storage means and a remotely located processing means. The information elements comprise information relating to characteristics of persons, vehicles and/or other factors connected with the incident. In preferred embodiments the information elements relate to categories selected from the group consisting of: suspicious persons; suspicious vehicles; crime; medical incidents; fire and rescue incidents; traffic accidents; traffic alerts; roadside assistance; animal welfare; animal removal; municipal support; crisis centres; alarm monitoring; alarm technical support; administration and application support; and estate security.",G08B 25/01; G06Q 50/26; G06F 17/30,TRACKBOX TECHNOLOGIES (PROPRIETARY) LIMITED,"RIGGS, Brian",2016/06119 05.09.2016 ZA,
WO2019001346,PCT/CN2018/092298,22.06.2018,WO/2019/001346,03.01.2019,WO,SYSTEM AND METHODS FOR OBJECT FILTERING AND UNIFORM REPRESENTATION FOR AUTONOMOUS SYSTEMS,"A computer-implemented method of controlling an autonomous system comprises: accessing, by one or more processors, sensor data that includes information regarding an area; disregarding, by the one or more processors, a portion of the sensor data that corresponds to objects outside of a region of interest; identifying, by the one or more processors, a plurality of objects from the sensor data; assigning, by the one or more processors, a priority to each of the plurality of objects; based on the priorities of the objects, selecting, by the one or more processors, a subset of the plurality of objects; generating, by the one or more processors, a representation of the selected objects; providing, by the one or more processors, the representation to a machine learning system as an input; and based on an output from the machine learning system resulting from the input, controlling the autonomous system.",G06K 9/00,"HUAWEI TECHNOLOGIES CO., LTD.","YIN, Xiaotian; LIU, Lifeng; ZHU, Yingxuan; ZHANG, Jun; LI, Jian","15/633,470 26.06.2017 US",EP-2018823510; CN-201880043257.1
WO2009052277,PCT/US2008/080149,16.10.2008,WO/2009/052277,23.04.2009,WO,NLP-BASED ENTITY RECOGNITION AND DISAMBIGUATION,"Methods and systems for entity recognition and disambiguation using natural language processing techniques are provided. Example embodiments provide an entity recognition and disambiguation system (ERDS) and process that, based upon input of a text segment, automatically determines which entities are being referred to by the text using both natural language processing techniques and analysis of information gleaned from contextual data in the surrounding text. In at least some embodiments, supplemental or related information that can be used to assist in the recognition and/or disambiguation process can be retrieved from knowledge repositories such as an ontology knowledge base. In one embodiment, the ERDS comprises a linguistic analysis engine, a knowledge analysis engine, and a disambiguation engine that cooperate to identify candidate entities from a knowledge repository and determine which of the candidates best matches the one or more detected entities in a text segment using context information.",G06F 17/20,"EVRI, INC.; LIANG, Jisheng; KOPERSKI, Krzysztof; DHILLON, Navdeep, S.; TUSK, Carston; BHATTI, Satish","LIANG, Jisheng; KOPERSKI, Krzysztof; DHILLON, Navdeep, S.; TUSK, Carston; BHATTI, Satish","60/980,747 17.10.2007 US",EP-2008839965; AU-2008312487; CA-2703007
WO2016043659,PCT/SG2015/050317,15.09.2015,WO/2016/043659,24.03.2016,WO,IMAGE RECOGNITION SYSTEM AND METHOD,"An improved system and method for digital image classification is provided. A host computer having a processor is coupled to a memory storing thereon reference feature data. A graphics processing unit (GPU) having a processor is coupled to the host computer and is configured to obtain, from the host computer, feature data corresponding to the digital image; to access, from the memory, the one or more reference feature data; and to determine a semi-metric distance based on a Poisson-Binomial distribution between the feature data and the one or more reference feature data. The host computer is configured to classify the digital image using the determined semi-metric distance.",G06T 7/00; G06K 9/78; G06F 19/24,TEMASEK LIFE SCIENCES LABORATORY LIMITED,"SWAMINATHAN, Muthukaruppan; SJÖBLOM, Tobias; CHEONG, Ian; PILOTO, Obdulio","62/050,414 15.09.2014 US",JP-2017534514; CA-2960964; CO-NC2017/0003311; EP-2015842878; AU-2015318702; US-15511089; IL-251022
WO2006078432,PCT/US2005/047389,30.12.2005,WO/2006/078432,27.07.2006,WO,BIOLOGICAL INTERFACE SYSTEM WITH AUTOMATED CONFIGURATION,A system and method for a biological interface system that processes multicellular signals of a patient and controls one or more devices is disclosed. The system includes a sensor that detects the multicellular signals and a processing unit for producing the control signal based on the multicellular signals. The system further includes an automated configuration routine that is used to set or modify the value of one or more system configuration parameters.,G06N 3/06; A61F 4/00; G06F 3/00,"CYBERKINETICS NEUROTECHNOLOGY SYSTEMS, INC.; FLAHERTY, Christopher, J.","FLAHERTY, Christopher, J.","60/644,686 18.01.2005 US",EP-5855880
WO2018022657,PCT/US2017/043791,25.07.2017,WO/2018/022657,01.02.2018,WO,SYSTEM AND METHOD FOR MEASURING THE MOVEMENTS OF ARTICULATED RIGID BODIES,"A method for determining spatial information for a multi-segment articulated rigid body system having at least an anchored segment and a non-anchored segment coupled to the anchored segment, each segment in the multi-segment articulated rigid body system representing a respective body part of a user, the method comprising: obtaining signals recorded by a first autonomous movement sensor coupled to a body part of the user represented by the non-anchored segment; providing the obtained signals as input to a trained statistical model and obtaining corresponding output of the trained statistical model; and determining, based on the corresponding output of the trained statistical model, spatial information for at least the non-anchored segment of the multi-segment articulated rigid body system. Determining the spatial information may include determining the position and/or orientation of the non-anchored segment relative to the anchor point and/or determining a spatial relationship between the anchored and non-anchored segments.",A63F 13/00; A63F 13/40; G06K 9/62; G06K 9/64; G06T 7/20; G06T 13/40,"CTRL-LABS CORPORATION; KAIFOSH, Patrick; MACHADO, Timothy; REARDON, Thomas; SCHOMBURG, Erik; TONG, Calvin","KAIFOSH, Patrick; MACHADO, Timothy; REARDON, Thomas; SCHOMBURG, Erik; TONG, Calvin","62/366,426 25.07.2016 US",EP-2017835140
EP279871522,19178692,06.06.2019,3586973,01.01.2020,EP,SYSTEM CONTROL BASED ON ACOUSTIC AND IMAGE SIGNALS,,B05B 1/00; B05B 12/08; G05B 13/02,ROLLS ROYCE CORP; COMMONWEALTH CENTER FOR ADVANCED MFG,CYBULSKY MICHAEL; BLAIR TAYLOR K; ZIMMERMAN BENJAMIN; SWEET MARSHALL LOUIS; MARCON ANDREA,201862686390 18.06.2018 US,
WO2007018501,PCT/US2005/026498,27.07.2005,WO/2007/018501,15.02.2007,WO,A METHOD FOR FINDING TEXT READING ORDER IN A DOCUMENT,"A method for finding text reading order in a document such as a scanned newspaper or magazine includes the steps of pruning unnecessary text zones using semantic analysis (40), using text correlation measures to cluster zones (41), and then finding a reading order within each of the clusters (42).",G06F 17/27; G06K 9/20,"HEWLETT-PACKARD DEVELOPMENT COMPANY, L.P.; YACOUB, Sherif; ORTEGA, Daniel; FARABOSCHI, Paolo; PEIRO, Jose, Abad","YACOUB, Sherif; ORTEGA, Daniel; FARABOSCHI, Paolo; PEIRO, Jose, Abad",,EP-2005778313; DE-null; US-11995650
WO1993015475,PCT/GB1993/000179,28.01.1993,WO/1993/015475,05.08.1993,WO,METHOD OF FORMING A TEMPLATE,"A method of forming a template of an image of an object includes the steps of: detecting occurrences of at least one feature type within the image which meet a respective criterion; for each such occurrence, determining a feature position which is a point within the image at which the occurrence of the feature type is to be considered as being located; and constructing a structural mesh of links between the feature positions. A method is also disclosed of forming a template derived from a plurality of templates formed from respective images of different members of the class of objects and combining the templates to form a generalised template. In particular the templates are combined using a genetic algorithm. The invention provides a method of forming a template from one or more images which does not rely on a priori assumptions about the salient features of the object for which a template is to be obtained.",G06K 9/62,"BRITISH TELECOMMUNICATIONS PUBLIC LIMITED COMPANY; SHACKLETON, Mark, Andrew; WELSH, William, John","SHACKLETON, Mark, Andrew; WELSH, William, John",9201856.3 29.01.1992 GB,US-08256835; EP-1993902475; CA-2128885
WO2019005257,PCT/US2018/026432,06.04.2018,WO/2019/005257,03.01.2019,WO,A NEUROMORPHIC SYSTEM FOR REAL-TIME VISUAL ACTIVITY RECOGNITION,"Described is a system for visual activity recognition that includes one or more processors and a memory, the memory being a non-transitory computer-readable medium having executable instructions encoded thereon, such that upon execution of the instructions, the one or more processors perform operations including detecting a set of objects of interest in video data and determining an object classification for each object in the set of objects of interest, the set including at least one object of interest. The one or more processors further perform operations including forming a corresponding activity track for each object in the set of objects of interest by tracking each object across frames. The one or more processors further perform operations including, for each object of interest and using a feature extractor, determining a corresponding feature in the video data. The system may provide a report to a user's cell phone or central monitoring facility.",G06K 9/32; G06K 9/62; G06N 3/02,"HRL LABORATORIES, LLC","KHOSLA, Deepak; UHLENBROCK, Ryan, M.; CHEN, Yang","15/883,822 30.01.2018 US; 62/516,217 07.06.2017 US",EP-2018823688; CN-201880030086.9
WO2018204833,PCT/US2018/031166,04.05.2018,WO/2018/204833,08.11.2018,WO,SYSTEM AND METHOD FOR AUTOMATICALLY RESTOCKING ITEMS ON SHELVES,"Systems, methods and computer-readable media for automating the restocking of shelves process by sending a notification when a product on a shelf has reached, or will reach, an undesired level of emptiness. This is determined using imaging sensors, such as cameras, which can calculate how full or empty a respective shelf is and predict when the shelf will need to be restocked. When the restocking time arrives, the notification can be sent to automated systems, which automatically cause new products to be stocked on the shelf, or can be sent to human beings (such as store associates) who can then perform the restocking.",G06Q 10/08; G06K 9/62; G06K 9/78; G06T 7/73; H04N 7/18,"WALMART APOLLO, LLC","NEMATI, Behzad; NAZARIAN, Ehsan","62/502,201 05.05.2017 US",
EP14295022,04001994,29.01.2004,1522918,13.04.2005,EP,Proactive user interface,"A proactive user interface, which could optionally be installed in (or otherwise control and/or be associated with) any type of computational device. The proactive user interface actively makes suggestions to the user, based upon prior experience with a particular user and/or various preprogrammed patterns from which the computational device could select, depending upon user behavior. These suggestions could optionally be made by altering the appearance of at least a portion of the display, for example by changing a menu or a portion thereof; providing different menus for display; and/or altering touch screen functionality. The suggestions could also optionally be made audibly.",G06F 3/048; G06F 9/44; G06F 3/00; G06F 3/01; G06F 3/033; G06F 3/14; G06F 15/00; G06F 15/18; G06F 17/00; G06N 3/00; H04M 1/247; H04M 1/2745; H04M 1/725; H04M 3/00,SAMSUNG ELECTRONICS CO LTD,LEE JONG-GOO; TOLEDANO EYAL; LINDER NATAN; EISENBERG YARIV; BEN-YAIR RAN,50066903 05.09.2003 US; 74347603 23.12.2003 US,
WO2013056315,PCT/AU2012/001277,19.10.2012,WO/2013/056315,25.04.2013,WO,IMAGE PROCESSING AND OBJECT CLASSIFICATION,"A method for classifying objects from one or more images comprising the steps of: generating a trained classification process wherein the generation comprises the steps of extracting features from one or more training images and clustering said features into one or more groups of features termed visual words; storing data for each of said visual words, including colour and texture information, as descriptor vectors; and generating a vocabulary tree to store clusters of visual words with common characteristics; and using the trained classification process to classify objects in said one or more images wherein the usage comprises the steps of extracting features from said one or more images and clustering said features into groups of features termed visual words; searching the vocabulary tree to determine the closest matching clusters of visual words; and classifying objects based on the closest matching clusters of visual words in the vocabulary tree.",G06K 9/00,"THE UNIVERSITY OF SYDNEY; VIDAL CALLEJA, Teresa Alejandra; RAMAKRISHNAN, Rishi","VIDAL CALLEJA, Teresa Alejandra; RAMAKRISHNAN, Rishi",2011904325 19.10.2011 AU,AU-2012318250; US-14352879; EP-2012842625; CA-2852614
WO2017197213,PCT/US2017/032317,12.05.2017,WO/2017/197213,16.11.2017,WO,FACILITATING TARGETED ANALYSIS VIA GRAPH GENERATION BASED ON AN INFLUENCING PARAMETER,"Provided is a process including: obtaining a graph comprising nodes and edges, each of the edges having a value indicating an amount of similarity between objects corresponding to the two linked nodes; selecting a parameter for influencing the graph; assessing each of the nodes based on the selected influencing parameter, wherein assessing comprises, with respect to each adjacent node in the graph sharing an edge with the node: determining the value indicating the amount of similarity between the object corresponding to the node and the object corresponding to the adjacent node; and determining a score related to the edge shared with the node, the score determined based on the similarity-amount value and a value of the selected influencing parameter for the node, such that edges are removed, weakened, added, or strengthened; and preparing, based on the graph, instructions to display at least part of the graph.",G06F 17/30; G06N 5/04,"QUID, INC.","TACCHI, Ruggero, Altair; CIULLA, Fabio","15/153,001 12.05.2016 US",
EP278936824,18780474,04.04.2018,3579150,11.12.2019,EP,OPERATION APPARATUS AND METHOD,"An operation method and apparatus, the operation apparatus comprising: an operation module (1-1), which is used for executing a neural network operation, and a power conversion module (1-2), which is connected to said operation module (1-1) and which is used for converting input neuron data and/or export neuron data of the neural network operation into power neuron data. Said operation method and apparatus reduce the overhead of storage resources and computing resources, and increase operation speed.",G06N 3/06,SHANGHAI CAMBRICON INFORMATION TECH CO LTD,,201710222232 06.04.2017 CN; 201710227493 07.04.2017 CN; 201710256444 19.04.2017 CN; 201710266052 21.04.2017 CN; 201710312415 05.05.2017 CN; 2018081929 04.04.2018 CN,
WO2016077834,PCT/US2015/060922,16.11.2015,WO/2016/077834,19.05.2016,WO,SYSTEMS AND METHODS OF BUILDING AND USING AN IMAGE CATALOG,"A method of managing an image catalog is performed by one or more servers. The process receives from a first user identification of one or more images in an image database. The image database is distinct from the servers. For each of the images, the process analyzes the image to extract keywords that describe the image and creates an index entry in the image catalog. The index entry includes the keywords. The process receives a query from a second user and matches the query to an index entry in the image catalog. The index entry corresponds to a first image in the image database. The process determines whether the second user is authorized to view the first image. When the second user is authorized to view the first image, the process retrieves the first image from the image database and transmits the first image to the second user.",G06F 17/30,ZORROA CORPORATION,"WEXLER, Daniel, Elliott; BUHLER, Juan, Jose","62/080,198 14.11.2014 US; 14/941,502 13.11.2015 US",
EP20634808,10008295,09.08.2010,2309492,13.04.2011,EP,System and method for activating plurality of functions based on speech input,"A method and a system for activating multiple functions based on a speech input are disclosed. The system includes, a memory storing multiple states, wherein each state is associated with at least one function from the multiple of functions; an automatic speech recognition (ASR) engine operatively connected to a set of data models, wherein there is one data model for each state, wherein the ASR engine is configured to interpret the speech input into a functional input using a data model associated with a state while the system is in the state, such that the function is activated according to the functional input; multiple controls, wherein there is one control for each state, and wherein each control is configured to generate a signal associated with the state; and a state transition module configured to transition the system to the state based on the signal.",G10L 15/26; G01C 21/36; H04L 29/06,MITSUBISHI ELECTRIC CORP,WEINBERG GARRETT L,55703509 10.09.2009 US,
WO2005017825,PCT/GB2004/003160,22.07.2004,WO/2005/017825,24.02.2005,WO,THREE-DIMENSIONAL MODELLING,"Apparatus for representing the spatial structure of subject’s three- dimensional spatial environment using a continuous attractor neural network. Information in multiple spatial dimensions can be represented simultaneously in a single continuous attractor network, for example permitting the representation of the full 3D spatial structure of an agent’s environment, where each space represented by the network would correspond to the egocentric location space of a particular type of spatial feature in the agent’s environment. The different spaces can be encoded and represented within a single network.",G06N 3/02,"ISIS INNOVATION LIMITED; STRINGER, Simon, Maitland","STRINGER, Simon, Maitland",0319285.3 15.08.2003 GB,
WO2020073316,PCT/CN2018/110064,12.10.2018,WO/2020/073316,16.04.2020,WO,"METHOD, APPARATUS AND COMPUTER READABLE MEDIA FOR OBJECT DETECTION","Methods, apparatuses and computer program products for object detection. A method comprises extracting a generic feature of an image characterizing one or more general properties of the image(310); identifying one or more regions of interest (ROIs) (320); generating scale information on one or more objects in the image based on the generic feature and one or more candidate scales(330); generating one or more scale-specific features of the image based on the scale information(340); and detecting the one or more objects in the image based on the identified one or more ROIs and the one or more scale-specific features(350).",G06K 9/00,"NOKIA TECHNOLOGIES OY; NOKIA TECHNOLOGIES (BEIJING) CO., LTD.","LI, Yazhao",,
WO2017139895,PCT/CA2017/050207,17.02.2017,WO/2017/139895,24.08.2017,WO,SYSTEM AND METHOD FOR DETECTING PHYSIOLOGICAL STATE,A system and method for health diagnostics and more specifically to an image-capture based system and method for detecting physiological state for a subject. The system provides a remote and non-invasive approach by which to detect physiological state with a high confidence. The system enables monitoring of hemoglobin concentration changes by optical imaging and related detection systems.,A61B 5/145; A61B 5/00; A61B 5/024; A61B 5/0476; A61B 5/055,NURALOGIX CORPORATION,"LEE, Kang; ZHENG, Pu","62/296,163 17.02.2016 US",CA-3013959; EP-2017752609; US-16076522
WO2020014680,PCT/US2019/041716,12.07.2019,WO/2020/014680,16.01.2020,WO,OBJECT IDENTIFICATION AND COLLECTION SYSTEM AND METHOD,"An object identification and collection method is disclosed. The method includes employing an image-collection vehicle to capture first images of a target geographical area, identifying one or more objects in the first images, and guiding an object-collection system over the target geographical area toward the one or more identified objects. The method further includes determining object information for each of the identified objects and guiding the object-collection system based on the object information. The method may further include capturing second images of the ground relative to the object-collection system as the object-collection system is guided toward the one or more identified objects, identifying a target object in the second images, and instructing the object-collection system to pick up the target object.",G05D 1/00; H04N 5/232; A63B 47/02,TERRACLEAR INC.,"FREI, Brent Ronald; MCMASTER, Dwight Galen; RACINE, Michael; DU PREEZ, Jacobus; DIMMIT, William David; BUTTERFIELD, Isabelle; HOLMGREN, Clifford; RHYS-JONES, Dafydd Daniel; KOLLMORGEN, Thayne; NAYAK, Vivek Ullal","62/697,057 12.07.2018 US",
WO2020044180,PCT/IB2019/057068,22.08.2019,WO/2020/044180,05.03.2020,WO,METHOD AND SYSTEM FOR GAZE ESTIMATION,The invention concerns a method for estimating a gaze at which a user is looking at. The method comprises a step of retrieving an input image and a reference image of an eye of the user and/or an individual.The method comprises then a step of processing the input image and the reference image so as to estimate a gaze difference between the gaze of the eye within the input image and the gaze of the eye within the reference image. The gaze of the user is the retrieved using the estimated gaze difference and the known gaze of the reference image.The invention also concerns a system for enabling this method.,G02B 27/00; G02B 27/01; G06F 3/01; G06K 9/00,EYEWARE TECH SA,"ODOBEZ, Jean-Marc; LIU, Gang; FUNES MORA, Kenneth Alberto",01046/2018 31.08.2018 CH,
WO2017079474,PCT/US2016/060384,03.11.2016,WO/2017/079474,11.05.2017,WO,MACHINE-LEARNING SYSTEMS AND TECHNIQUES TO OPTIMIZE TELEOPERATION AND/OR PLANNER DECISIONS,"A system, an apparatus or a process may be configured to implement an application that applies artificial intelligence and/or machine-learning techniques to predict an optimal course of action (or a subset of courses of action) for an autonomous vehicle system (e.g., one or more of a planner of an autonomous vehicle, a simulator, or a teleoperator) to undertake based on suboptimal autonomous vehicle performance and/or changes in detected sensor data (e.g., new buildings, landmarks, potholes, etc.). The application may determine a subset of trajectories based on a number of decisions and interactions when resolving an anomaly due to an event or condition. The application may use aggregated sensor data from multiple autonomous vehicles to assist in identifying events or conditions that might affect travel (e.g., using semantic scene classification). An optimal subset of trajectories may be formed based on recommendations responsive to semantic changes (e.g., road construction).",G05B 17/00; G06F 15/18; B60W 30/08,"ZOOX, INC.","LEVINSON, Jesse Sol; SIBLEY, Gabriel Thurston; REGE, Ashutosh Gajanan","14/932,963 04.11.2015 US; 14/933,602 05.11.2015 US; 14/932,959 04.11.2015 US; 14/932,966 04.11.2015 US; 14/932,940 04.11.2015 US",JP-2018543271; EP-2016862996
WO2019241016,PCT/US2019/035729,06.06.2019,WO/2019/241016,19.12.2019,WO,VECTOR BASED OBJECT RECOGNITION IN HYBRID CLOUD,"Disclosed are systems, methods, and computer-readable media for a hybrid cloud structure for machine-learning based object recognition. In one aspect, a system includes one or more video-capable access points; and one or more processors configured to receive image data from the one or more video-capable access points; perform, at a first processor of the one or more processors, a first process to detect one or more objects of interest in the image data; generate vector IDs for one or more objects detected in the image data; perform, at a second processor of the one or more processors, a second process to identify the one or more objects in the vector IDs; and generate at least one offline trail for the one or more objects based on statistics associated with the one or more objects identified.",G06K 9/00,"CISCO TECHNOLOGY, INC.","MALEGAONKAR, Ashutosh Arwind; XIAO, Haihua; CHEN, Rizhi; KANG, Li; LING, Siqi; ZHENG, Mingen","62/683,202 11.06.2018 US; 16/193,238 16.11.2018 US",
WO2019051658,PCT/CN2017/101502,13.09.2017,WO/2019/051658,21.03.2019,WO,INCREMENTAL NETWORK QUANTIZATION,"Methods and apparatus relating to techniques for incremental network quantization. In an example, an apparatus comprises logic, at least partially comprising hardware logic to partition a plurality of model weights in a deep neural network (DNN) model into a first group of weights and a second group of weights, convert each weight in the first group of weights to a power of two, and repeatedly retrain the DNN model while converting a subset of weights in the second group to a power of two or zero. Other embodiments are also disclosed and claimed.",G06N 3/04,"INTEL CORPORATION; CHEN, Yurong; YAO, Anbang; XU, Lin; GUO, Yiwen; ZHOU, Aojun","CHEN, Yurong; YAO, Anbang; XU, Lin; GUO, Yiwen; ZHOU, Aojun",,
WO2019209569,PCT/US2019/027519,15.04.2019,WO/2019/209569,31.10.2019,WO,SPEAKER DIARIZATION USING AN END-TO-END MODEL,"Techniques are described for training and/or utilizing an end-to-end speaker diarization model. In various implementations, the model is a recurrent neural network (RNN) model, such as an RNN model that includes at least one memory layer, such as a long short-term memory (LSTM) layer. Audio features of audio data can be applied as input to an end-to-end speaker diarization model trained according to implementations disclosed herein, and the model utilized to process the audio features to generate, as direct output over the model, speaker diarization results. Further, the end-to-end speaker diarization model can be a sequence-to-sequence model, where the sequence can have variable length. Accordingly, the model can be utilized to generate speaker diarization results for any of various length audio segments.",G10L 17/04; G10L 17/18,GOOGLE LLC,"WANG, Quan; SHETH, Yash; MORENO, Ignacio Lopez; WAN, Li","62/661,498 23.04.2018 US",EP-2019720314
WO2003065294,PCT/US2003/003060,03.02.2003,WO/2003/065294,07.08.2003,WO,RECOVERING OBJECTS BY USING SHAPE PRIORS FOR LEVEL SET REPRESENTATIONS,"This invention relates to shape priors for level set representations. An embodiment of the invention comprises a first stage and a second stage. In the first stage, a shape model can be built directly on level set space using a collection of samples. The shape model can be constructed using a variational framework to create a non-stationary pixel-wise model that accounts for variabilities. Then, in the second stage, the shape model can be used as basis to introduce the shape prior in an energetic form. In terms of level set representations, the shape prior aims at minimizing non-stationary distance between the evolving interface and the shape model. An embodiment according to the present invention can be integrated with an existing, data-driven variational method to perform image segmentation for physically corrupted and incomplete data.",G06K 9/48; G06K 9/64,"SIEMENS CORPORATE RESEARCH, INC.","PARAGIOS, Nikolaos; ROUSSON, Mikael","60/354,005 01.02.2002 US; 10/356,093 31.01.2003 US",EP-2003706033
WO2019190312,PCT/NL2019/050182,25.03.2019,WO/2019/190312,03.10.2019,WO,ADAPTIVE ARTIFICIAL INTELLIGENCE SYSTEM FOR EVENT CATEGORIZING BY SWITCHING BETWEEN DIFFERENT STATES,"The invention provides an artificial intelligence (AI) system for categorizing events, said AI system comprising a first state and a second state, wherein: - said AI system is in a first state for categorizing events in a first category type; - upon categorizing of a first event in a predefined category of said first category type, said AI system is set to said second state, in said second state said AI system is set for categorizing subsequent events in a second category type.",G06N 3/04,KEPLER VISION TECHNOLOGIES BV,"STOKMAN, Henricus Meinardus Gerardus; VAN OLDENBORGH, Marc Jean Baptist",2020685 29.03.2018 NL,
WO2018089685,PCT/US2017/060933,09.11.2017,WO/2018/089685,17.05.2018,WO,GENERATING PRESENTATION SLIDES WITH DISTILLED CONTENT,"A method for generating presentation slides with distilled content including receiving one or more data files as source material for slide generation, obtaining content from the one or more data files for a slide of a slide presentation, identifying a layout template for the slide based on the content, and distilling the content into distilled content to generate a presentation visualization item based on the distilled content. The distilled content may include a subset of the content. The method may also include generating the slide based on the presentation visualization item and the layout template.",G06F 17/21; G06F 17/22; G06F 17/24; G06F 17/30,GOOGLE LLC,"SIVAJI, Vishnu; SAVIANO, Steven Joseph; DULKO, Andrea","62/420,263 10.11.2016 US; 15/807,431 08.11.2017 US",
WO2017070656,PCT/US2016/058440,24.10.2016,WO/2017/070656,27.04.2017,WO,VIDEO CONTENT RETRIEVAL SYSTEM,"This document describes a search retrieval system for automatically indexing data representing audio-visual recordings and for querying, responsive to a search query, that indexed data representing the audio-visual recordings. The search retrieval system defines weights for semantic features of an audio-visual recording and extracts, based on execution of a first set of rules, one or more semantic features. The system determines a weight for each of the one or more semantic features. A search engine searches nodes in the graph of the semantic features to identify one or more logical relationships for the one or more semantic features extracted. The weights for each of the one or more semantic features are adjusted based on the graph. The data is indexed in association with the one or more adjusted weights for the one or more semantic features, respectively.",G06F 17/30,CARNEGIE MELLON UNIVERSITY,"JIANG, Lu; HUANG, Po-yao; HAUPTMANN, Alexander G.","62/285,256 23.10.2015 US",US-15769233
WO2019226308,PCT/US2019/030972,07.05.2019,WO/2019/226308,28.11.2019,WO,MOBILE REMOTE DIRECT MEMORY ACCESS,"A mobile local computing device is configured to access memories or storage devices associated with a remote computing device using remote direct memory access (RDMA) over a wireless fifth generation (5G) network link that provides high bandwidth and low latency relative to previous wireless network protocols. The mobile local computing device utilizes a local compute context that is unique to the local environment and which may be facilitated by devices, components, or functionalities that are local to the mobile local computing device, but which are not available with the same context to the remote computing device. The 5G network link supports high bandwidth and low latency so that the mobile local computing device accesses and utilizes the remote data in large datasets in a similar manner to how it would for locally stored data, while still being able to leverage the local I/O and maintain its unique local compute context.",G06F 13/28; G06F 15/173,"MICROSOFT TECHNOLOGY LICENSING, LLC","BRUNER, John David; THALER, David Garfield, III","62/674,555 21.05.2018 US; 15/992,248 30.05.2018 US",
WO2019246562,PCT/US2019/038546,21.06.2019,WO/2019/246562,26.12.2019,WO,WEARABLE SYSTEM SPEECH PROCESSING,"A method of processing an acoustic signal is disclosed. According to one or more embodiments, a first acoustic signal is received via a first microphone. The first acoustic signal is associated with a first speech of a user of a wearable headgear unit. A first sensor input is received via a sensor, a control parameter is determined based on the sensor input. The control parameter is applied to one or more of the first acoustic signal, the wearable headgear unit, and the first microphone. Determining the control parameter comprises determining, based on the first sensor input, a relationship between the first speech and the first acoustic signal.",G10L 21/02; G10L 17/22; H04R 3/00,"MAGIC LEAP, INC.","LEIDER, Colby Nelson","62/687,987 21.06.2018 US",
WO2008045233,PCT/US2007/021130,02.10.2007,WO/2008/045233,17.04.2008,WO,SUPPLYING DIGITAL IMAGES FROM A COLLECTION,"In a computer-mediated method and a system for supplying image records from a collection, an output request is received from a user. An output is generated responsive to the request by locating a set of image records in the collection corresponding to the request, determining one or more constraints on the output, ascertaining a respective value index of each of the image records in the set, calculating a statistical measure of the value indexes of the set, reducing in number the image records in the set responsive to the constraints while optimizing the statistical measure to provide a reduced set of image records, and providing the output using the reduced set of image records.",G06F 17/30,"EASTMAN KODAK COMPANY; CEROSALETTI, Cathleen, Daniels; LOUI, Alexander, C.","CEROSALETTI, Cathleen, Daniels; LOUI, Alexander, C.","60/828,494 06.10.2006 US; 11/747,933 14.05.2007 US",JP-2009531412; EP-2007852490
WO2018194998,PCT/US2018/027840,16.04.2018,WO/2018/194998,25.10.2018,WO,NEURAL NETWORK PROCESSOR USING COMPRESSION AND DECOMPRESSION OF ACTIVATION DATA TO REDUCE MEMORY BANDWIDTH UTILIZATION,"A deep neural network (""DNN"") module can compress and decompress neuron-generated activation data to reduce the utilization of memory bus bandwidth. The compression unit can receive an uncompressed chunk of data generated by a neuron in the DNN module. The compression unit generates a mask portion and a data portion of a compressed output chunk. The mask portion encodes the presence and location of the zero and non-zero bytes in the uncompressed chunk of data. The data portion stores truncated non-zero bytes from the uncompressed chunk of data. A decompression unit can receive a compressed chunk of data from memory in the DNN processor or memory of an application host. The decompression unit decompresses the compressed chunk of data using the mask portion and the data portion. This can reduce memory bus utilization, allow a DNN module to complete processing operations more quickly, and reduce power consumption.",G08B 13/196; G06N 3/063; H03M 7/30; H03M 7/46,"MICROSOFT TECHNOLOGY LICENSING, LLC","CORKERY, Joseph Leon; LUNDELL, Benjamin Eliot; WALL, Larry Marvin; MCBRIDE, Chad Balling; AMBARDEKAR, Amol Ashok; PETRE, George; CEDOLA, Kent D.; BOBROV, Boris","62/486,432 17.04.2017 US; 15/953,356 13.04.2018 US",MX-MX/a/2019/012388; EP-2018721932; RU-2019136750; JP-2019555659; CN-201880025420.1; CA-3056660; AU-2018256212; SG-11201909175X; IL-269888; KR-1020197033456
WO2017220788,PCT/EP2017/065560,23.06.2017,WO/2017/220788,28.12.2017,WO,SYSTEM AND METHOD FOR ARTIFICIAL AGENT BASED COGNITIVE OPERATING ROOMS,"An artificial agent based cognitive operating room system and a method thereof providing automated assistance for a surgical procedure are disclosed. Data related to the surgical procedure from multiple data sources is fused based on a current context. The data includes medical images of a patient acquired using one or more medical imaging modalities. Real-time quantification of patient measurements based on the data from the multiple data sources is performed based on the current context. Short-term predictions in the surgical procedure are forecasted based on the current context, the fused data, and the real-time quantification of the patient measurements. Suggestions for next steps in the surgical procedure and relevant information in the fused data are determined based on the current context and the short-term predictions. The suggestions for the next steps and the relevant information in the fused data are presented to an operator.",G06F 19/00,SIEMENS HEALTHCARE GMBH,"COMANICIU, Dorin; KAPOOR, Ankur; MANSI, Tommaso; ORDY, Vincent; PHEIFFER, Thomas","62/353,907 23.06.2016 US",
WO2019084308,PCT/US2018/057573,25.10.2018,WO/2019/084308,02.05.2019,WO,DEEP REINFORCEMENT LEARNING FRAMEWORK FOR CHARACTERIZING VIDEO CONTENT,"Video information in a video scene is represented as a sequence of features depicted each frame. An environment state for each time step t corresponding to each frame is represented by the video information for time step t and predicted affective information from a previous time step t-1. An action A(t) as taken with an agent controlled by a machine learning algorithm for the frame at step t, wherein an output of the action A(t) represents affective label prediction for the frame at the time step t. A pool of predicted actions is transformed to a predicted affective history at a next time step t+1. The predictive affective history is included as part of the environment state for the next time step t+1. A reward R is generated on predicted actions up to the current time step t, by comparing them against corresponding annotated movie scene affective labels.",G06N 3/08,SONY INTERACTIVE ENTERTAINMENT INC.,"CHEN, Ruxin; KUMAR, Naveen; LI, Haoqi","62/577,970 27.10.2017 US",
WO2017158586,PCT/IL2017/050258,01.03.2017,WO/2017/158586,21.09.2017,WO,LASER-BASED SYSTEM AND OPTICAL MICROPHONE HAVING INCREASED BANDWIDTH,"Laser-based system and optical microphone having increased bandwidth. The system includes a laser microphone to transmit a laser beam towards a human speaker; to receive an optical feedback signal reflected back from the human speaker; and to perform self-mixing interferometry. An optical feedback signal bandwidth enhancer improves the bandwidth of the optical feedback signal, to improve the quality of remote speech detection that is based on the optical feedback signal. The bandwidth enhancement utilizes takes into account one or more of: the identity of the face-region hit by the laser beam; the skin color or shade; obstruction of the skin by hair or by accessories; ability to allocate increased processing resources for processing of the optical feedback signal; ability to modify modulation frequency of the optical feedback signal; Signal to Noise Ratio (SNR) estimation; bandwidth estimation; acoustic-optical transmission channel estimation; or other suitable parameters.",H04R 23/00; G01H 9/00; G10L 15/20,VOCALZOOM SYSTEMS LTD.,"BAKISH, Tal","15/072,382 17.03.2016 US",
WO2019027735,PCT/US2018/043478,24.07.2018,WO/2019/027735,07.02.2019,WO,MODEL FOR DETERMINING DROP-OFF SPOT AT DELIVERY LOCATION,"An example system includes a delivery vehicle, a sensor connected to the delivery vehicle, and a control system that determines a delivery destination for an object. The control system receives sensor data representing a physical environment of at least a portion of the delivery destination and determines a drop-off spot for the object within the delivery destination by way of an artificial neural network (ANN). The ANN is trained to determine the drop-off spot based on previously-designated drop-off spots within corresponding delivery destinations and includes an input node that receives the sensor data, hidden nodes connected to the input node, and an output node connected to the hidden nodes that provides data indicative of a location of the drop-off spot. The control system additionally causes the delivery vehicle to move to and place the object at the drop-off spot.",G05D 1/00; G05D 1/10; G06Q 50/28; B64C 39/02,WING AVIATION LLC,"SCHUBERT, Martin Friedrich; WATSON, Philip Edwin; GRUNDMANN, Michael Jason; LEVINE, Gabriella","15/667,180 02.08.2017 US",EP-2018840420; SG-11201914015W
WO2018204837,PCT/US2018/031173,04.05.2018,WO/2018/204837,08.11.2018,WO,SYSTEM AND METHOD FOR AUTOMATICALLY RESTOCKING ITEMS ON SHELVES USING A CONVEYOR SYSTEM,"Systems, methods and computer-readable media for automating the restocking of shelves process by sending a notification when a product on a shelf has reached, or will reach, an undesired level of emptiness. This is determined using imaging sensors, such as cameras, which can calculate how full or empty a respective shelf is and predict when the shelf will need to be restocked. When the restocking time arrives, the notification can be sent to automated systems, which automatically cause new products to be stocked on the shelf via a conveyor system.",G06Q 10/08; B65G 15/00; G06K 9/62; G06K 9/78; G06T 7/73; H04N 7/18,"WALMART APOLLO, LLC","NEMATI, Behzad; NAZARIAN, Ehsan","62/502,193 05.05.2017 US",
WO2017066378,PCT/US2016/056734,13.10.2016,WO/2017/066378,20.04.2017,WO,METHOD AND SYSTEM FOR CALCULATING RESECTED TISSUE VOLUME FROM 2D/2.5D INTRAOPERATIVE IMAGE DATA,A method and system for calculating a volume of resected tissue from a stream of intraoperative images is disclosed. A stream of 2D/2.5D intraoperative images of resected tissue of a patient is received. The 2D/2.5D intraoperative images in the stream are acquired at different angles with respect to the resected tissue. A resected tissue surface is segmented in each of the 2D/2.5D intraoperative images. The segmented resected tissue surfaces are stitched to generate a 3D point cloud representation of the resected tissue surface. A 3D mesh representation of the resected tissue surface is generated from the 3D point cloud representation of the resected tissue surface. The volume of the resected tissue is calculated from the 3D mesh representation of the resected tissue surface.,G06T 7/60; G06T 7/00,SIEMENS AKTIENGESELLSCHAFT,"KAMEN, Ali; KLUCKNER, Stefan; PHEIFFER, Thomas","14/882,485 14.10.2015 US",EP-2016787978
WO1998015825,PCT/US1997/015754,07.10.1997,WO/1998/015825,16.04.1998,WO,MATRICES WITH MEMORIES IN AUTOMATED DRUG DISCOVERY AND UNITS THEREFOR,"Automated drug discovery protocols, or partially automated protocols, in which matrices-with-memories serve as the platform on which all manipulations are performed or serve as the repository of information that is transferred to other memories as the synthesized compounds are processed and screened. Also provided are automated drug discovery units for use in the protocols. The units provide a means for seamless data tracking and include instrumentation and vials with memories for information transfer to other memories in a unit. The units, which are provided herein, include some or all of the following: an automated or manual sorter, microreactors and microvessels, which contain memories, an automated or semi-automated synthesizer, a microreactor washer/dryer, a manual or automated cleaver for removing compounds from the matrix-with-memory microreactors, and associated software. The memories may be any of any type, including electromagnetically encodable memories and optical memories, or combinations thereof. The memories may be pre-encoded or may be encodable during, after or before processing. Also provided are manual and automated methods for sorting matrices with memories.",B01J 19/00; C07K 1/04; C08J 7/16; G01N 15/14; G01N 33/542; G01N 33/543; G11C 13/02,IRORI,"NOVA, Michael, Phillip; LILLIG, John, E.; KARUNARATNE, Kanchana, Sanjaya, Gunesekera; O'NEIL, Donald; EWING, William; SATODA, Yozo","08/726,703 07.10.1996 US; 08/743,984 28.10.1996 US; 08/741,685 31.10.1996 US; 08/788,594 22.01.1997 US; 08/857,800 22.01.1997 US; 08/826,253 27.03.1997 US; 08/912,998 11.08.1997 US",CA-2267769; EP-1997912649
WO2015200120,PCT/US2015/036637,19.06.2015,WO/2015/200120,30.12.2015,WO,"SYSTEM, METHOD AND APPARATUS FOR ORGANIZING PHOTOGRAPHS STORED ON A MOBILE COMPUTING DEVICE","An image organizing system for organizing and retrieving images from an image repository residing on a mobile device is disclosed. The image organizing system includes a mobile computing device including an image repository. The mobile computing device is adapted to produce a small-scale model from an image in the image repository including an indicia of the image from which the small-scale model was produced. In one embodiment the small-scale model is then transmitted from the mobile computing device to a cloud computing platform including recognition software that produces a list of tags describing the image, which are then transmitted back to the mobile computing device. The tags then form an organization system. Alternatively, the image recognition software can reside on the mobile computing device, so that no cloud computing platform is required.",G06F 15/16,"AMAZON TECHNOLOGIES, INC.","WANG, Meng; CHEN, Yushan","14/316,905 27.06.2014 US",JP-2016575531; CA-2952974; EP-2015812729; KR-1020177002492; AU-2015280393
WO2018119200,PCT/US2017/067837,21.12.2017,WO/2018/119200,28.06.2018,WO,SEARCH ENGINE FOR PROCESSING IMAGE SEARCH QUERIES IN MULTIPLE LANGUAGES,"A method for receiving an input user query from a user in any of multiple languages and creating an input user query vector for the input user query is provided. The input user query vector has a length equal to a pre-selected length determined by a dimension of a multimodal space. The method includes associating an image vector to the input user query vector in the multimodal space, the image vector having the pre-selected length, identifying, from an image database, an image associated with the image vector, and providing the image for display to the user in a results panel of a user interface. A system configured to perform the above method is also provided.",G06F 17/30,"SHUTTERSTOCK, INC.","LEV-TOV, Manor; LINEBACK, Nicholas Alexander; HOHWALD, Heath","62/438,168 22.12.2016 US; 15/448,081 02.03.2017 US",
EP12398861,92116751,30.09.1992,0539749,05.05.1993,EP,A STATISTICAL MIXTURE APPROACH TO AUTOMATIC HANDWRITING RECOGNITION,"Method and apparatus for automatic recognition of handwritten text based on a suitable representation of handwriting in one or several feature vector spaces(s), Gaussian modeling in each space, and mixture decoding to take into account the contribution of all relevant prototypes in all spaces. The feature vector space(s) is selected to encompass both a local and a global description of each appropriate point on a pen trajectory. Windowing is performed to capture broad trends in the handwriting, after which a linear transformation is applied to suitably eliminate redundancy. The resulting feature vector space(s) is called chirographic space(s). Gaussian modeling is performed to isolate adequate chirographic prototype distributions in each space, and the mixture coefficients weighting these distributions are trained using a maximum likelihood framework. Decoding can be performed simply and effectively by accumulating the contribution of all relevant prototype distributions. Post-processing using a language model may be included. <IMAGE>",G06K 9/22; G06K 9/46; G06K 9/62,IBM,BELLEGARDA EVELINE JEANNINE; BELLEGARDA JEROME RENE; NAHAMOO DAVID; NATHAN KRISHNA SUNDARAM,78564291 31.10.1991 US,
WO2019046663,PCT/US2018/048984,30.08.2018,WO/2019/046663,07.03.2019,WO,DECISION MAKING BASED ON PLASTICITY RULES OF A NEURAL NETWORK,"Systems, devices, and methods are disclosed for decision making based on spike time dependent plasticity of a neural network. A method may include obtaining a multilayered model. The multilayered model may include an input layer including one or more input units. The multilayered model may include one or more hidden layers including one or more hidden units. Each input unit may have a first connection with at least one hidden unit. The multilayered model may include an output layer including one or more output units. The method may also include receiving an input at a first input unit. The method may include sending a first signal from the first input unit to at least one hidden unit via a first connection comprising a first strength. The method may also include making a decision based on the model receiving the input.",G06N 3/04; G06N 3/063; G06N 3/08,"THE REGENTS OF THE UNIVERSITY OF CALIFORNIA; SKORHEIM, Steven","SKORHEIM, Steven; BAZHENOV, Maksim; SANDA, Pavel","62/552,279 30.08.2017 US",
WO2018125685,PCT/US2017/067447,19.12.2017,WO/2018/125685,05.07.2018,WO,ZERO-SHOT LEARNING USING MULTI-SCALE MANIFOLD ALIGNMENT,"Described is a system for recognition of unseen and untrained patterns. A graph is generated based on visual features from input data, the input data including labeled instances and unseen instances. Semantic representations of the input data are assigned as graph signals based on the visual features. The semantic representations are aligned with visual representations of the input data using a reguiarizalicm method, applied, directly in a spectral graph wavelets (SOW) domain. The semantic representations are then used to generate labels for the unseen instances. The unseen instances may represent unknown conditions tor an autonomous vehicle.",G06K 9/68; G06K 9/72,"HRL LABORATORIES, LLC","DEUTSCH, Shay; KIM, Kyungnam; OWECHKO, Yuri","62/440,898 30.12.2016 US",CN-201780071989.7; EP-2017888421
EP14555812,06100063,04.01.2006,1679694,12.07.2006,EP,Confidence score for a spoken dialog system,"A spoken dialog system configured to use a combined confidence score. A first confidence score, indicating a confidence level in a speech recognition result of recognizing an utterance, is provided. A second confidence level, indicating a confidence level of mapping the speech recognition result to an intent, is provided. The first confidence score and the second confidence score are combined to form a combined confidence score. A determination is made, with respect to whether to accept the intent, based on the combined confidence score.",G10L 15/22,AT & T CORP,HAKKANI-TUR DILEK Z; RICCARDI GIUSEPPE; TUR GOKHAN,2927805 05.01.2005 US,
WO2019090264,PCT/US2018/059273,05.11.2018,WO/2019/090264,09.05.2019,WO,REAL TIME ANOMALY DETECTION SYSTEMS AND METHODS,"The systems and methods provide an action recognition and analytics tool for use in manufacturing, health care services, shipping, retailing and other similar contexts. Machine learning action recognition can be utilized to determine cycles, processes, actions, sequences, objects and or the like in one or more sensor streams. The sensor streams can include, but are not limited to, one or more video sensor frames, thermal sensor frames, infrared sensor frames, and or three-dimensional depth frames. The analytics tool can provide for process validation, anomaly detection and in-process quality assurance.",G05B 19/418; G06Q 10/06; G06T 7/00; G06N 99/00; G06Q 50/04; G06K 17/00,"DRISHTI TECHNOLOGIES, INC.","AKELLA, Prasad Narasimha; ASHOK, Ananya Honnedevasthana; CHAUDHURY, Krishnendu; GUPTA, Ashish; NARUMANCHI, Sujay Venkata Krishna; PRAGER, David Scott; SHANKAR, Devashish; UGGIRALA, Ananth; CHHABRA, Yash Raj; ASSOUL, Zakaria Ibrahim; GUPTA, Sameer","62/581,541 03.11.2017 US",
EP215067164,16811439,01.06.2016,3312775,25.04.2018,EP,"CONTROL SYSTEM, SYSTEM, AND PROGRAM",It is in some cases not possible to record data appropriately according to increase in the intensity of an emotion. A control system provided includes: a recording information generating unit that processes at least part of information detected continuously by a sensor and generates information in a first recording format or information in a second recording format having a larger amount of information than that of the information in the first recording format; a recording control unit that causes information generated by the recording information generating unit to be recorded; an emotion determining unit that determines intensity of an emotion at the control system based on at least part of information detected by the sensor; and a switching control unit that switches a recording format of information which the recording control unit causes to be recorded from the first recording format to the second recording format in response to increase in intensity of an emotion determined by the emotion determining unit if the recording information generating unit is being caused to generate the information in the first recording format.,G06N 3/00; G06N 3/02,COCORO SB CORP,SON MASAYOSHI; TOMONAGA KOSUKE,2015122406 17.06.2015 JP; 2016066311 01.06.2016 JP,
WO2019112516,PCT/SG2018/050590,03.12.2018,WO/2019/112516,13.06.2019,WO,"SENSOR-BASED COMMUNICATION APPARATUS AND METHOD, AND COMMUNICATION MEDIUM","In a described embodiment, a sensor-based communication apparatus (100) is disclosed. The communication apparatus (100) comprises a plurality of sensor nodes (112) associated with respective unique pulse signatures (200) and adapted to communicate with respective sensors (113) with each sensor (113) configured to generate a sensory signal (113a) in response to a respective stimulus (113b). Each sensor node (112) is triggered, upon receipt of the corresponding sensory signal (113a), to transmit the associated unique pulse signature (200) independently and asynchronously through a transmission medium (110) shared by the sensor nodes (112), and the unique pulse signatures (200) transmitted by the sensor nodes (112) being a representation (300) of a stimulus event associated with the stimuli detected by the corresponding sensors (113). A method and a communication medium are also disclosed.",G06F 3/01; B25J 13/08; G06N 3/04,NATIONAL UNIVERSITY OF SINGAPORE,"TEE, Chee Keong; LEE, Wang Wei; NG, Kian Ann; HO, John",10201710041S 04.12.2017 SG,
WO2018211144,PCT/EP2018/063304,22.05.2018,WO/2018/211144,22.11.2018,WO,MAKING OBJECT-LEVEL PREDICTIONS OF THE FUTURE STATE OF A PHYSICAL SYSTEM,"A system implemented by one or more computers comprises a visual encoder component configured to receive as input data representing a sequence of image frames, in particular representing objects in a scene of the sequence, and to output a sequence of corresponding state codes, each state code comprising vectors, one for each of the objects. Each vector represents a respective position and velocity of its corresponding object. The system also comprises a dynamic predictor component configured to take as input a sequence of state codes, for example from the visual encoder, and predict a state code for a next unobserved frame. The system further comprises a state decoder component configured to convert the predicted state code, to a state, the state comprising a respective position and velocity vector for each object in the scene. This state may represent a predicted position and velocity vector for each of the objects.",G06N 3/04; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"WATTERS, Nicholas; PASCANU, Razvan; BATTAGLIA, Peter William; ZORN, Daniel; WEBER, Theophane Guillaume","62/509,049 19.05.2017 US",CN-201880027163.5; EP-2018726785
WO2018194850,PCT/US2018/026357,06.04.2018,WO/2018/194850,25.10.2018,WO,PROCESSING DISCONTIGUOUS MEMORY AS CONTIGUOUS MEMORY TO IMPROVE PERFORMANCE OF A NEURAL NETWORK ENVIRONMENT,"The performance of a neural network (NN) can be limited by the number of operations being performed. Using a line buffer that is directed to shift a memory block by a selected shift stride for cooperating neurons, data that is operatively residing memory and which would require multiple write cycles into a cooperating line buffer can be processed as in a single line buffer write cycle thereby enhancing the performance of a NN/DNN. A controller and/or iterator can generate one or more instructions having the memory block shifting values for communication to the line buffer. The shifting values can be calculated using various characteristics of the input data as well as the NN/DNN inclusive of the data dimensions. The line buffer can read data for processing, shift the data of the memory block and write the data in the line buffer for subsequent processing.",G06F 15/80; G06F 12/0862; G06F 9/50,"MICROSOFT TECHNOLOGY LICENSING, LLC","PETRE, George; MCBRIDE, Chad Balling; AMBARDEKAR, Amol Ashok; CEDOLA, Kent D.; BOBROV, Boris; WALL, Larry Marvin","62/486,432 17.04.2017 US; 15/829,832 01.12.2017 US",EP-2018720862; CN-201880025244.1
WO2018155018,PCT/JP2018/001305,18.01.2018,WO/2018/155018,30.08.2018,WO,ENVIRONMENT RECOGNITION SYSTEM AND LEARNING APPARATUS,"A technique that makes it possible to respond to complex conditions in a surrounding environment is provided. An environment recognition system according to one aspect of the present invention includes: a sensor apparatus configured to detect brightness information pertaining to a brightness of the surrounding environment; and an information processing apparatus configured to calculate, by inputting the brightness information obtained by the sensor apparatus into a trained learning device that has been trained for identifying a brightness level of the surrounding environment and a factor determining the brightness, an environment information set including information of the brightness level of the surrounding environment and the factor determining the brightness.",G06K 9/00,OMRON CORPORATION,"ANDO, Tanichi",2017-031089 22.02.2017 JP,CN-201880005685.5; EP-2018702827
WO2019173860,PCT/AU2019/000037,14.03.2019,WO/2019/173860,19.09.2019,WO,METHOD AND SYSTEM FOR DATA CURATION,"A computer implemented method and system for curating an electronic data stream consisting of a plurality of electronic data items into a category is described. The method includes processing each of the electronic data items in accordance with a feature schema applicable to the electronic data stream to determine values of the features defined by the feature schema for each of the individual electronic data items and adopting an initial curation rule that is operative on a selection of the features defined by the feature schema and their determined feature values for each of the individual electronic data items to determine whether an individual electronic item is in the category. The initial curation rule is then automatically processed to generate an enriched curation rule, wherein the enriched curation rule is operative on an expanded selection of the determined values of the features defined by the feature schema for each of the individual electronic data items as compared to the initial curation rule. The enriched curation rule is then applied to the electronic data stream to curate electronic data items into the category based on determination by the enriched curation rule.",G06F 16/30; G06N 5/02; G06F 17/27,NQRY PTY LTD,"BENATALLAH, Boualem; BARUKH, Moshe; BEHESHTI, Amin; ZAMANI, Shayan",2018900840 14.03.2018 AU,
WO2018204836,PCT/US2018/031172,04.05.2018,WO/2018/204836,08.11.2018,WO,SYSTEM AND METHOD FOR AUTOMATICALLY RESTOCKING ITEMS ON SHELVES USING A PNEUMATIC PIPE SYSTEM,"Systems, methods and computer-readable media for automating the restocking of shelves process by sending a notification when a product on a shelf has reached, or will reach, an undesired level of emptiness. This is determined using imaging sensors, such as cameras, which can calculate how full or empty a respective shelf is and predict when the shelf will need to be restocked. When the restocking time arrives, the notification can be sent to automated systems, which automatically cause new products to be stocked on the shelf via a pneumatic pipe system.",G06Q 10/08; B65G 1/04; G06K 9/78; G06T 7/73; H04N 7/18,"WALMART APOLLO, LLC","NEMATI, Behzad; NAZARIAN, Ehsan","62/502,204 05.05.2017 US",
WO2017135757,PCT/KR2017/001223,03.02.2017,WO/2017/135757,10.08.2017,WO,"ELECTRONIC DEVICE AND METHOD FOR CONTROLLING DISPLAYING, AND SERVER AND METHOD THEREFOR","A method for controlling displaying, an electronic device therefor, and a server and method therefor are provided. The method includes transmitting information including at least one input keyword to a server, receiving, from the server, a recognition model for filtering out an object included in a received webpage, installing the recognition model, determining whether a first object corresponding to the at least one input keyword exists in the webpage, when the first object corresponding to the input keyword exists in the webpage, processing the first object to become a second object, and displaying the webpage including the processed object.",G06Q 50/10; H04N 21/258; H04M 1/725; G06N 3/02; G06N 99/00,"SAMSUNG ELECTRONICS CO., LTD.","BAE, Ki-Bum",10-2016-0013510 03.02.2016 KR,EP-2017747802
WO2012094422,PCT/US2012/020226,04.01.2012,WO/2012/094422,12.07.2012,WO,A VOICE BASED SYSTEM AND METHOD FOR DATA INPUT,"Described herein are systems and methods for transforming a speech input into machine-interpretable structured data. In some embodiments, a system may include an automated speech recognition (ASR) engine configured to receive a live speech input and to continuously generate a text of the live speech input, a natural language processing (NLP) engine configured to transform the text into machine-interpretable structured data, and a user interface device configured to display the live speech input and a corresponding portion of the structured data in a predetermined order with respect to the structured data. In some embodiments, the method may include the steps of receiving a speech input with a speech capture component of a user interface device, generating a text from the speech input, identifying textual cues in the text, modifying the text based on the textual cues, and transforming the modified text into machine-interpretable structured data.",G10L 17/00,"HEALTH FIDELITY, INC.; RISKIN, Daniel, J.; SHROFF, Anand; CHOW, Yan; DUMMETT, Brian, A.; TIWARI, Ritu, Raj","RISKIN, Daniel, J.; SHROFF, Anand; CHOW, Yan; DUMMETT, Brian, A.; TIWARI, Ritu, Raj","61/429,923 05.01.2011 US",GB-1312361.7
WO2019161237,PCT/US2019/018264,15.02.2019,WO/2019/161237,22.08.2019,WO,SYSTEM AND METHOD FOR INFERRING SCENES BASED ON VISUAL CONTEXT-FREE GRAMMAR MODEL,"The present teaching relates to method, system, medium, and implementations for determining a type of a scene. Image data acquired by a camera with respect to a scene are received and one or more objects present in the scene are detected therefrom. The detected objects are recognized based on object recognition models. The spatial relationships among the detected objects are then determined based on the image data. The recognized objects and their spatial relationships are then used to infer a type of the scene in accordance with at least one scene context-free grammar model.",G06K 9/00; G06K 9/20; H04N 21/84; H04N 21/845,"DMAI, INC.","SHUKLA, Nishant; DHARNE, Ashwin","62/630,998 15.02.2018 US",
WO2018224847,PCT/GB2018/051578,08.06.2018,WO/2018/224847,13.12.2018,WO,MIXED REALITY GAMING SYSTEM,"An interactive mixed reality system for one or more users, in which both real-world entities and virtual world entities are capable of being interacted with by one or more users, or by objects (47, 91) for use by users, and the system arranged to computationally maintain game state and the evolution of events in the real-world and the virtual world, and the system arranged to generate a response (such as visual or tactile/haptic, or by way of cause and effect) which is experienced or perceived by the one or more users.",A63F 13/65; A63F 13/21; A63F 13/25; G06T 19/00; G01B 11/25; G06F 3/01; G06F 3/042; G06K 9/00; G06T 15/50; G02B 27/01; A63F 13/50,"DELAMONT, Dean Lindsay","DELAMONT, Dean Lindsay",1709199.2 09.06.2017 GB,
EP13052381,98301978,17.03.1998,0867831,30.09.1998,EP,Incorporating invariances by preprocessing for kernel-based methods,"A kernel-based method and apparatus includes a preprocessor, which operates on an input data in such a way as to provide invariance under some symmetry transformation. <IMAGE>",G06K 9/36; G06F 15/18; G06F 17/10; G06K 9/52; G06K 9/62; G06N 3/00; G06T 7/00,LUCENT TECHNOLOGIES INC,BURGES CHRISTOPHER JOHN,82528797 27.03.1997 US,
WO2019217323,PCT/US2019/030934,06.05.2019,WO/2019/217323,14.11.2019,WO,"METHODS AND SYSTEMS FOR IMPROVING MACHINES AND SYSTEMS THAT AUTOMATE EXECUTION OF DISTRIBUTED LEDGER AND OTHER TRANSACTIONS IN SPOT AND FORWARD MARKETS FOR ENERGY, COMPUTE, STORAGE AND OTHER RESOURCES","A transaction-enabling system includes a production facility having a core task that is a production task. The system includes a controller having a facility description circuit that interprets a number of historical facility parameter values and a corresponding number of historical facility outcome values, and a facility prediction circuit that operates an adaptive learning system, where the adaptive learning system is configured to train a facility production predictor in response to the plurality of facility parameter values and the corresponding plurality of facility outcome values. The facility description circuit further interprets a number of present state facility parameter values, and the facility prediction circuit further operates the adaptive learning system to predict a present state facility outcome value in response to the number of present state facility parameter values.",G06Q 10/10; G06Q 30/06; G06Q 50/18; G06N 3/08; G06Q 10/04; G06Q 10/06; G06Q 50/04,"STRONG FORCE TX PORTFOLIO 2018, LLC","CELLA, Charles Howard","62/667,550 06.05.2018 US; 62/751,713 29.10.2018 US; 62/787,206 31.12.2018 US",
EP13736448,01308965,22.10.2001,1207465,22.05.2002,EP,Apparatus and a method for facilitating searching,A receiver (2b) receives from a search engine (3) search results consisting of at least one search item associated with at least one context item relating to the search item;  a modifier (2b) modifies the search results by associating at least one context item with data for enabling the user to cause the search results to be filtered in accordance with that context item by selecting that context item; and a supplier (2b) supplies the modified search results to the user.  <IMAGE>,G06F 17/30,CANON KK,KOTCHEFF AARON WILLIAM CHRISTO; ROSE ANTHONY GERARD,0026353 27.10.2000 GB,
WO2014194161,PCT/US2014/040141,30.05.2014,WO/2014/194161,04.12.2014,WO,SYSTEMS AND METHODS FOR PERFORMING BAYESIAN OPTIMIZATION,"Techniques for use in connection with performing optimization using a plurality of objective functions associated with a respective plurality of tasks. The techniques include using at least one computer hardware processor to perform: identifying, based at least in part on a joint probabilistic model of the plurality of objective functions, a first point at which to evaluate an objective function in the plurality of objective functions; selecting, based at least in part on the joint probabilistic model, a first objective function in the plurality of objective functions to evaluate at the identified first point; evaluating the first objective function at the identified first point; and updating the joint probabilistic model based on results of the evaluation to obtain an updated joint probabilistic model.",G06F 15/18,PRESIDENT AND FELLOWS OF HARVARD COLLEGE; THE GOVERNING COUNCIL OF THE UNIVERSITY OF TORONTO; UNIVERSITE DE SHERBROOKE,"ADAMS, Ryan, P.; SNOEK, Roland, Jasper; LAROCHELLE, Hugo; SWERSKY, Kevin; ZEMEL, Richard","61/829,090 30.05.2013 US; 61/829,604 31.05.2013 US; 61/910,837 02.12.2013 US",EP-2014804134; CA-2913743
EP239838887,18192349,04.09.2018,3460720,27.03.2019,EP,MACHINE LEARNING SYSTEM FOR IN-SITU RECOGNITION OF COMMON LOCATIONS IN A ROTATABLE BODY WITH REPEATING SEGMENTS,"A system (100) includes one or more processors (102) configured to automatically identify different distressed portions (206, 208, 210, 306, 308, 310) in repeating segments (200) of a rotating body (106). At least one of a size and/or a shape of one or more of the distressed portions (206, 208, 210, 306, 308, 310) changes with respect to time. The one or more processors (102) also are configured to determine a pattern of the different distressed portions (206, 208, 210, 306, 308, 310) in the repeating segments (200) of the rotating body (106) during rotation of the rotating body (106) based on identifying the different distressed portions (206, 208, 210, 306, 308, 310). The one or more processors (102) also are configured to subsequently automatically identify locations of individual segments (200) of the repeating segments (200) in the rotating body (106) using the pattern of the distressed portions (206, 208, 210, 306, 308, 310) that is determined.",G06K 9/68; G01N 21/954; G06T 7/00,GEN ELECTRIC,LIM SER NAM; DIWINSKY DAVID SCOTT,201715714208 25.09.2017 US,
EP14229050,04076159,15.04.2004,1477116,17.11.2004,EP,Probe position measurement to facilitate image registration and image manipulation in a medical application,A method utilizing an imaging probe for registering images associated with a medical image processing application comprises the steps of: (a) providing a local tracking system that generates a field in a local area within which the imaging probe is used; (b) capturing first and second images representing substantially the same object; (c) sensing field emissions from the local tracking system to establish positional coordinates of the imaging probe during image capture; (d) using the positional coordinates to register the first and second images; and (e) utilizing the registered images to determine a characteristic of the object. <IMAGE>,A61B 5/107; A61B 5/06; A61C 19/04; A61B 5/00; A61B 5/06; A61B 5/107; A61B 6/14; G06T 1/00,EASTMAN KODAK CO,SPOONHOWER JOHN P; SQUILLA JOHN R; BOLAND JOHN T; STEPHANY THOMAS M,42524903 29.04.2003 US,
WO2018178863,PCT/IB2018/052084,27.03.2018,WO/2018/178863,04.10.2018,WO,GAZE BASED CLASSROOM NOTES GENERATOR,"Techniques are provided for creating presentation notes based upon gaze tracking information associated with observers of a presentation. In one example, a computer-implemented method comprises: obtaining, by a system operatively coupled to a processor, gaze information associated with observers of a presentation; determining, by the system, respective content clarity scores for content elements of the presentation based on a content clarity function; selecting, by the system, respective content from one or more content sources for the content elements based on the respective content clarity scores; and generating, by the system, presentation notes based on the presentation and the selected respective content for the content elements of the presentation.",G06F 17/30; G06F 3/01,INTERNATIONAL BUSINESS MACHINES CORPORATION; IBM UNITED KINGDOM LIMITED; IBM (CHINA) INVESTMENT COMPANY LIMITED,"VACULIN, Roman; DWIVEDI, Utkarsh; AHUJA, Karan; NAGAR, Seema; DEY, Kuntal","15/474,475 30.03.2017 US",GB-1914876.6; JP-2019552881; DE-112018001711; CN-201880021811.6
WO2008039480,PCT/US2007/020746,26.09.2007,WO/2008/039480,03.04.2008,WO,METHOD AND SYSTEM FOR LEARNING SPATIO-SPECTRAL FEATURES IN AN IMAGE,"In a first exemplary embodiment of the present invention, an automated, computerized method is provided for determining illumination flux in an image. According to a feature of the present invention, the method comprises the steps of performing a computer learning technique to determine spatio-spectral information for the images, and utilizing the spatio-spectral information to identify illumination flux.",G06K 9/62,"TANDENT VISION SCIENCE, INC.; DANA, Kristin, Jean; FRIEDHOFF, Richard, Mark; MAXWELL, Bruce, Allen; SMITH, Casey, Arthur","DANA, Kristin, Jean; FRIEDHOFF, Richard, Mark; MAXWELL, Bruce, Allen; SMITH, Casey, Arthur","11/528,128 27.09.2006 US",EP-2007838860
WO2014179389,PCT/US2014/036016,30.04.2014,WO/2014/179389,06.11.2014,WO,INTERACTIVE CONTENT AND PLAYER,A tool is provided that may allow a user to create unique content for a media item such as a movie. A movie may be received. An indication of an object in the movie may be received from an author. Supplemental content for the object in the movie may be received as may be an interactivity data. The interactivity data may specify a manner by which a user may interact with the movie using a device such as a camera and/or a microphone. The movie may be encoded to include the interactivity data and/or supplemental content.,G06F 17/30,GOOGLE INC.,"PAGLIA, Marco; SIPE, Michael Andrew; SCHNEIDERMAN, Henry Will; KOSER, Mikkel Crone","13/874,544 01.05.2013 US",
WO2003008963,PCT/US2002/022445,16.07.2002,WO/2003/008963,30.01.2003,WO,E-GENECHIP ONLINE WEB SERVICE FOR DATA MINING BIOINFORMATICS,"A method for data analysis of microarrays. The method includes accessing a software program that performs a multistage analysis of the biological image, through an internet webserver. The analysis includes at least a step of comparing the digitized quantitative data for each sample. The method may further include digitizing the data for each sample and quantitating the data for each sample. Further, the method may include using a software program which quantitates the intensity and size of each sample; compares the quantitative value for each sample with the quantitative value of one or more controls; captures data, quantitates data, analyses data, or stores data; removes the background based on negative controls; averages or adjusts intensities as a function of the number of the biological images; generates reports; and stores data. The microarray can be processed to display the samples using an assay such as chromogenic assay or fluorescent assay, using a radioactive label imaged on radiographic film or using any other means in the art. The samples can be oligonucleotides such as DNA or mRNA or proteomics. The biological images can be in any form, preferably in the form of immunoassays, dot blots, Northern assays, Southern assay, Western assay, and electrophoretic gels.",G01N 27/447; G06F 19/20; G06T 9/00; G06F 19/28,"UNIVERSITY OF LOUISVILLE RESEARCH FOUNDATION, INC.","WANG, Eugenia; HALL, William, Christopher; ZHAO, XueChun","60/306,234 18.07.2001 US",JP-null
EP282270370,18801300,08.05.2018,3598342,22.01.2020,EP,METHOD AND DEVICE FOR IDENTIFYING OBJECT,"The present disclosure relates to an artificial intelligence (AI) system which copies functions of the human brain such as cognition and judgment by utilizing a machine learning algorithm such as deep learning, and to an application of the system. The present disclosure provides a method for a device to identify an object by: acquiring an image including an object; extracting attribute information of the object from the image by using a plurality of layers included in a network for determining a category of the object; acquiring feature information representing the object by combining attribute information of the object extracted from at least some of the plurality of layers by using at least one feature extraction layer; and identifying the object on the basis of the result of a comparison between the acquired feature information and feature information of each of a plurality of pre-stored object images, wherein at least one parameter of the feature extraction layer is set up based on a learning result based on a database including a plurality of images.",G06K 9/20; G06K 9/62,SAMSUNG ELECTRONICS CO LTD,KIM DEOK-HO; LEE WON-WOO; LEE JAE-WOONG; PARK BONG-HOON; LEE GUN-ILL; JEONG JI-WON; NG TERESA KA KI,20170060961 17.05.2017 KR; 2018005257 08.05.2018 KR,
WO2020024185,PCT/CN2018/098131,01.08.2018,WO/2020/024185,06.02.2020,WO,TECHNIQUES FOR MOTION-BASED AUTOMATIC IMAGE CAPTURE,Techniques are disclosed for motion-based automatic image capture in a movable object environment. Image data including a plurality of frames can be obtained and a region of interest in the plurality of frames can be identified. The region of interest may include a representation of one or more objects. Depth information for the one or more objects can be determined in a first coordinate system. A movement characteristic of the one or more objects may then be determined in the second coordinate system based at least on the depth information. One or more frames from the plurality of frames may then be identified based at least on the movement characteristic of the one or more objects.,G05D 1/00,"SZ DJI TECHNOLOGY CO., LTD.","ZHOU, You; LIU, Jie; HUANG, Jinzhu",,
EP74866088,11169962,15.06.2011,2518661,31.10.2012,EP,"System and method for human detection and counting using background modeling, hog and haar features","A system for adaptive learning based human detection for channel input of captured human image signals, the said system comprises of: a sensor for tracking real time images of environment of interest; a feature extraction and classifiers generation means for extracting a plurality of the features and classifying the features associated with time-space descriptors of image comprising background modeling, Histogram of Oriented Gradients (HOG) and Haar like wavelet; a processor configured to process extracted feature classifiers associated with plurality of real-time images; a means for combining plurality of feature classifiers of time-space descriptors; a means for evaluating linear probability of human detection based on predetermined threshold value of feature classifier in a time window having at least one image frame; a counter for counting the number of human in the image; and a transmission means adapted to send the final human detection decision and number thereof to storage means.",G06K 9/00,TATA CONSULTANCY SERVICES LTD,SINHA ANIRUDDHA; GUPTA ROHIT; CHAKI AYAN; PAL ARPAN,1359MU2011 29.04.2011 IN,
WO2018213108,PCT/US2018/032197,11.05.2018,WO/2018/213108,22.11.2018,WO,DOMAIN ADAPTATION AND FUSION USING WEAKLY SUPERVISED TARGET IRRELEVANT DATA,Aspects include receiving a request to perform an image classification task in a target domain. The image classification task includes identifying a feature in images in the target domain. Classification information related to the feature is transferred from a source domain to the target domain. The transferring includes receiving a plurality of pairs of task-irrelevant images that each includes a task-irrelevant image in the source domain and in the target domain. The task-irrelevant image in the source domain has a fixed correspondence to the task-irrelevant image in the target domain. A target neural network is trained to perform the image classification task in the target domain. The training is based on the plurality of pairs of task-irrelevant images. The image classification task is performed in the target domain and includes applying the target neural network to an image in the target domain and outputting an identified feature.,G06K 9/62; G06K 9/46,SIEMENS MOBILITY GMBH,"WU, Ziyan; PENG, Kuan-Chuan; ERNST, Jan","62/506,128 15.05.2017 US; 62/528,690 05.07.2017 US; 15/720,424 29.09.2017 US",EP-2018732984
WO2019010428,PCT/US2018/041105,06.07.2018,WO/2019/010428,10.01.2019,WO,NAVIGATION SYSTEM FOR A DRONE,"This document describes an unmanned aerial vehicle (UAV) configured to navigate an unmanned aerial vehicle highway. The UAV includes a navigation system that includes a sensor, configured to gather environmental data, and a computing system configured to navigate the UAV. The computing system compares the environmental data to a specified data signature in the one or more spectra and determines a position of the unmanned aerial vehicle in the unmanned aerial vehicle highway. The UAV includes a hybrid generator system including an engine configured to generate mechanical energy and a generator motor coupled to the engine and configured to generate electrical energy from the mechanical energy generated by the engine. The UAV includes a rotor motor configured to drive a propeller to rotate. The navigation system is powered by the electrical energy generated by the generator motor.",G05D 1/00; G05D 3/00,"TOP FLIGHT TECHNOLOGIES, INC.","RASMUSSEN, Scott; SARMA, Sanjay; DEBITETTO, Paul, A.; PHAN, Long, N.","62/529,081 06.07.2017 US",JP-2019542365
WO2020051168,PCT/US2019/049418,04.09.2019,WO/2020/051168,12.03.2020,WO,SYSTEMS AND METHODS FOR CLASSIFYING DRIVER BEHAVIOR,"Data processing techniques and systems for processing telematics data associated with a vehicle, such as an automobile, to classify how the vehicle is being operated by a driver. The telematics data can include the use of image data captured by a camera of the vehicle. The image data is processed in conjunction with vehicular telematics data such as position, speed, and acceleration data of the vehicle obtained from, for example, smartphone sensors. The image data is processed and used by a processing system to provide a context for the telematics data. The image data and the telematics data are classified by the processing system to identify driving behavior of the driver, determine driving maneuvers that have occurred, scoring driving quality of the driver, or a combination of them.",B60W 40/09; B60W 30/08; B60W 50/14; G06K 9/00; G06N 20/00,CAMBRIDGE MOBILE TELEMATICS INC.,"BALAKRISHNAN, Hari; MADDEN, Samuel Ross","62/726,916 04.09.2018 US",
WO2015167975,PCT/US2015/027689,27.04.2015,WO/2015/167975,05.11.2015,WO,RATING PHOTOS FOR TASKS BASED ON CONTENT AND ADJACENT SIGNALS,"Method and system for selecting a representative subset of images from a set, the selecting based on rating the images in the set based on task, image, and/or adjacent information. An indication of the task may be embodied in a query provided by a user. The task may indicate the user's intended use of the subset of images. The set may be grouped into cluster(s) based on technical attributes of the images in the set, and/or technical attributes indicated by the task. Adjacent information may be obtained from sources that are generally unrelated or indirectly related to the images in the set.",G06F 17/30,"MICROSOFT TECHNOLOGY LICENSING, LLC","LEE, David; CHAN, Chunkit Jacky; RICARD, Doug; SCOTT, Stacia; LIGHT, Allison; SPROULE, William David; MCNEIL, Meghan; MABREY, Christopher; AVERY, Adam; WEISBERG, Joshua; BRODIE, Alexander","14/266,795 30.04.2014 US",
WO2015032585,PCT/EP2014/067056,08.08.2014,WO/2015/032585,12.03.2015,WO,CONTENT BASED IMAGE RETRIEVAL,"A method and non-transitory computer readable medium for content based image retrieval. The method includes selecting a query image, segmenting the selected query image by applying a segmentation technique, extracting features from the segmented query image by determining at least two feature descriptors, including color feature descriptors and texture feature descriptors, and determining a similarity of the query image to a plurality of images included in a database using the determined at least two feature descriptors of the segmented query image, features being extracted from each of the plurality of images included in the database by determining the at least two feature descriptors, the color feature descriptors and the texture feature descriptors including a simultaneous combination of different color spaces, and global and local statistical measurements being carried out on the simultaneous combination of the different color spaces.",G06F 17/30,"SHAZURA, INC.","PÉREZ DE LA COBA, Sira",P201300816 04.09.2013 ES,RU-2016112126; JP-2016539453; EP-2014755341; US-14785045; IL-244381; AU-2014317351; CA-2921127; MX-MX/a/2016/002854
WO2012126008,PCT/US2012/029692,19.03.2012,WO/2012/126008,20.09.2012,WO,"SYSTEMS, METHODS AND COMPUTER-ACCESSIBLE MEDIUMS FOR AUTHENTICATION AND VERIFICATION OF PHYSICAL OBJECTS","[00139] Exemplary methodology, procedure, system, method and computer-accessible medium can be provided for authenticating a non-digital medium of a physical object, by receiving at least one image of video of at least one marked or unmarked region, and comparing the first microscopic image or video of at least one marked or unmarked region with at least one second microscopic image or video relating to the non-digital medium to determine if a similarity between the first and second microscopic images or videos matches or exceeds a predetermined amount.",G01N 33/36,NEW YORK UNIVERSITY,"SHARMA, Ashlesh; SUBRAMANIAN, Lakshminarayanan; BREWER, Eric","61/453,916 17.03.2011 US",EP-2012757221; JP-2013558240
WO2012078114,PCT/SG2011/000429,08.12.2011,WO/2012/078114,14.06.2012,WO,METHOD AND AN APPARATUS FOR DETERMINING VEIN PATTERNS FROM A COLOUR IMAGE,"The present invention is directed to a method of determining vein patterns from a colour image for personal identification, the method comprising forming a counterpart of the colour image by applying a functional relationship obtained from optimization on the colour image, wherein the counterpart of the colour image comprises the vein patterns. An apparatus for determining vein patterns from a colour image is also disclosed.",G06K 9/20; A61B 5/05,"NANYANG TECHNOLOGICAL UNIVERSITY; LOS ANGELES BIOMEDICAL RESEARCH INSTITUTE; KONG, Wai Kin Adams; TANG, Chaoying; ZHANG, Hengyi; CRAFT, Noah Ames","KONG, Wai Kin Adams; TANG, Chaoying; ZHANG, Hengyi; CRAFT, Noah Ames","61/421,450 09.12.2010 US",US-13992634; EP-2011847188
EP14242020,03291359,06.06.2003,1484716,08.12.2004,EP,An architecture for self-developing devices,"A self-developing device (1) capable of open-ended development makes use of a special motivational system for selecting which action should be taken on the environment by an associated sensory-motor apparatus (2). For a given candidate action, a motivational module (11) calculates a reward associated with the corresponding values that would be taken by one or more motivational variables that are independent of the nature of the associated sensory-motor apparatus. Preferred motivational variables are dependent on the developmental history of the device (1), and include variables quantifying the predictability, familiarity and stability of sensory-motor variables serving as the inputs to the device (1). The sensory-motor variables represent the status of the external environment and/or the internal resources (3) of the sensory-motor apparatus (2) whose behaviour is controlled by the self-developing device (1). Open-ended development is enabled by attributing a reward which is proportional to the rate of change of the history-dependent motivational variables. <IMAGE>",G06N 3/00; B25J 13/00; G06N 3/00,SONY FRANCE SA,KAPLAN FREDERIC; OUDEYER PIERRE-YVES,03291359 06.06.2003 EP,
EP14747473,05028259,22.12.2005,1801731,27.06.2007,EP,Adaptive scene dependent filters in online learning environments,,G06K 9/68,HONDA RES INST EUROPE GMBH,WERSING HEIKO; GOETTING MICHAEL; STEIL JOCHEN J,05028259 22.12.2005 EP,
WO2017116881,PCT/US2016/067896,21.12.2016,WO/2017/116881,06.07.2017,WO,STRUCTURE AND TRAINING FOR IMAGE CLASSIFICATION,"A computer implemented method of training an image classifier, comprising: receiving training images data labeled according to image classes; selecting reference points of the images; and constructing a set of voting convolutional tables and binary features on a patch surrounding each reference point by performing, for each calculation stage: creating a voting table by: creating first candidate binary features; calculating a global loss reduction for each first candidate binary feature; selecting one first candidate binary feature having minimal global loss reduction; and repeating to select stage-size binary features; and performing a tree split using the voting table by: creating second candidate binary features; calculating a combined loss reduction for each stage-split size group of the second candidate binary features; selecting one of the groups having a maximal combined loss reduction; and creating a child-directing table using the selected binary features.",G06F 17/30,"MICROSOFT TECHNOLOGY LICENSING, LLC","KRUPKA, Eyal; BAR HILLEL, Aharon","14/985,803 31.12.2015 US",
WO2011088497,PCT/AU2011/000028,12.01.2011,WO/2011/088497,28.07.2011,WO,OBJECT RECOGNITION METHOD AND COMPUTER SYSTEM,"A method of recognising an object is described, which is to be performed on or with the aid of one or more computers, the method comprising the generation of one or more sets of characterising data as training data during an initial training data generation stage, the generation of one or more sets of characterising data as test data during a later test data generation stage, and comparison of the training data and test data using a comparison algorithm, wherein, during each of the training data generation and the test data generation stages, the generation of the one or more sets of characterising data comprises, for a scene containing the object in a 3-dimensional space defined by an axis system, deriving a set of 3-dimensional object data points for the object, each object data point defined by 3- dimensional coordinates and one or more light intensity values and, based on a first data-processing of the coordinates of the object data points, deriving a set of feature data points corresponding to object features of the object, each feature data point also defined by 3-dimensional coordinates, and grouping one or more sets of three feature data points; and for each set of three feature data points, applying a 3- dimensional transformation function to the coordinates of one or more object data points to generate respective transformed object data points with respective new coordinates, each transformed object data point having the same associated one or more light intensity values as the object data point from which it was generated, wherein the 3-dimensional transformation function is a function of the set of three feature data points, and carrying out a second data processing of the transformed object data points to generate one of the one or more sets of characterising data.",G06K 9/00; G06T 17/00,"BAXTER, Richard, Bruce","BAXTER, Richard, Bruce",2010900180 19.01.2010 AU; 2010903967 05.09.2010 AU; 2010904309 24.09.2010 AU,
EP249227634,19152571,18.01.2019,3514728,24.07.2019,EP,"MACHINE-IN-THE-LOOP, IMAGE-TO-VIDEO COMPUTER VISION BOOTSTRAPPING","Disclosed are systems and methods for improving interactions with and between computers in content searching, hosting and/or providing systems supported by or configured with devices, servers and/or platforms. The disclosed systems and methods provide a novel machine-in-the-loop, image-to-video bootstrapping framework that harnesses a training set built upon an image dataset and a video dataset in order to efficiently produce an accurate training set to be applied to frames of videos. The disclosed systems and methods reduce the amount of time required to build the training dataset, and also provide mechanisms to apply the training dataset to any type of content and for any type of recognition task.",G06K 9/00; G06K 9/62,OATH INC,SONG YALE; DASSA GUY; LEE MINHO; SCHOLZ JEFFREY; SOARES JOAO VITOR BALDINI,201815941437 30.03.2018 US; 201862619045 18.01.2018 US,
WO1993023814,PCT/US1993/004713,17.05.1993,WO/1993/023814,25.11.1993,WO,ASYNCHRONOUS TEMPORAL NEURAL PROCESSING ELEMENT,The processing element is useful in solving problems from the class of temporal signal processing problems and is modeled closely on the sub-cellular biology and electrophysiology of neurons having chemical synapses.,G06N 3/04; G06N 3/063; G06N 3/067; H03H 17/02,NEW MEXICO STATE UNIVERSITY TECHNOLOGY TRANSFER CORPORATION,"DeYONG, Mark, R.; FINDLEY, Randall, L.; ESKRIDGE, Thomas, C.; FIELDS, Christopher, A.","07/885,423 18.05.1992 US",EP-1993913970
WO2017001495,PCT/EP2016/065170,29.06.2016,WO/2017/001495,05.01.2017,WO,OPTIMAL DRUG DOSING BASED ON CURRENT ANESTHESIA PRACTICE,"Prior to initiating sedation of a subject (10), current values (30) of physiological parameters are measured for the subject using a sedation monitoring device (14, 16), including at least heart rate, a blood pressure, and a capnography parameter. A sedation dosing recommendation to achieve a desired level of sedation (36) is computed using the current values of the physiological parameters and past sedation subject data retrieve from a storage medium (24). The sedation dosing recommendation may be displayed on a display component (26, 28) or used as a default sedation dosing of an anesthesia machine (16). The past sedation subject data may comprise trained neural network parameters and the computing uses the trained neural network (22NN). The past sedation subject data may comprise trained Bayesian inference model parameters and the computing uses the trained Bayesian inference model (22BC).",G06F 19/00,KONINKLIJKE PHILIPS N.V.,"CHENG, Limei; CHBAT, Nicolas, Wadih",62/185880 29.06.2015 US,
WO2008051240,PCT/US2006/044863,17.11.2006,WO/2008/051240,02.05.2008,WO,"SYSTEM, APPARATUS AND METHODS FOR AUGMENTING FILTER WITH ADAPTIVE ELEMENT","A system in accordance with the invention uses an adaptive element to augment a filter for tracking an observed system. The adaptive element only requires a single neural network and does not require an error observer. The adaptive element provides robustness to parameter uncertainty and unmodeled dynamics present in the observed system for improved tracking performance over the filter alone. The adaptive element can be implemented with a linearly parameterized neural network, whose weights are adapted online using error residuals generated from the Filter. Boundedness of the signals generated by the system can be proven using Lyapunov's direct method and a backstepping argument. A related apparatus and method are also disclosed.",G06F 17/13,GEORGIA TECH RESEARCH CORPORATION,"CALISE, Anthony, J.; MADYASTHA, Venkatesh, K.","60/738,302 18.11.2005 US",
WO2018227169,PCT/US2018/036779,08.06.2018,WO/2018/227169,13.12.2018,WO,OPTIMAL HUMAN-MACHINE CONVERSATIONS USING EMOTION-ENHANCED NATURAL SPEECH,"A system and method for emotion-enhanced natural speech using dilated convolutional neural networks, wherein an audio processing server receives a raw audio waveform from a dilated convolutional artificial neural network, associates text-based emotion content markers with portions of the raw audio waveform to produce an emotion-enhanced audio waveform, and provides the emotion-enhanced audio waveform to the dilated convolutional artificial neural network for use as a new input data set.",G10L 25/63; G10L 25/30; G10L 21/0332,NEWVOICEMEDIA US INC.,"MCCORD, Alan; UNITT, Ashley; GALVIN, Brian","15/661,341 27.07.2017 US; 62/516,672 08.06.2017 US",
WO2015094112,PCT/SE2014/051546,19.12.2014,WO/2015/094112,25.06.2015,WO,SYSTEM AND METHOD FOR NEUROMUSCULAR REHABILITATION COMPRISING PREDICTING AGGREGATED MOTIONS,"The present invention relates to a system (100, 200) for neuromuscular rehabilitation of a patient (102, 202) having an affected limb (104, 204) comprising: a feedback member arranged to give real-time visual feedback; a plurality of electrodes (110, 210) arranged to acquire an electric signal corresponding to an intent to move said affected limb (104, 204); a control unit (108, 208) configured to: perform pattern recognition of said electric signals, wherein at least one feature in said electric signal is used to predict motion intent of said affected limb (104, 204) adjacent to at least one joint, such aggregated motions of said affected limb (104, 204) are predicted; based on output signals from said performed pattern recognition, control said feedback member to perform actions corresponding to said motions, whereby said actions of said feedback member are individually and simultaneously controlled by said patient (102, 202) via said intended motions.",A61B 5/0488; A61B 5/11; A61F 2/72,INTEGRUM AB,"ORTIZ CATALAN, Max Jair",1351570-5 20.12.2013 SE,CA-2933053; AU-2014367277; US-15039558; EP-2014873074
EP196378431,15306762,06.11.2015,3166020,10.05.2017,EP,METHOD AND APPARATUS FOR IMAGE CLASSIFICATION BASED ON DICTIONARY LEARNING,"An efficient technique for multimedia content classification is provided which generates sparse classifiers based on sparse coding and dictionary learning. Learning may be performed on the entire training set of multimedia content or jointly on classes of the training set. Methods (300, 400), apparatuses (500), computer-readable storage mediums and non-transitory computer-readable program products are provided for generating a sparse classifier for multimedia content classification (300, 500) and for multimedia content classification utilizing the sparse classifier (400, 500).",G06F 17/30,THOMSON LICENSING,LYU XINRUI; ZEPEDA SALVATIERRA JOAQUIN; PEREZ PATRICK,15306762 06.11.2015 EP,
WO2007041429,PCT/US2006/038309,02.10.2006,WO/2007/041429,12.04.2007,WO,METHOD AND SYSTEM FOR GENERATING DISPLAY DATA,"A method of aiding in the evaluation of lesions in a bodv using a plurality of sets of image data of sections of the body region in mutually parallel planes. Processing of the data requires several steps, including pixel intensity pattern recognition, contouring of the regions of probable pathology, thresholding and 3-dimensional clustering, providing each pixel with a color representative of a selected opacity level and displaying an image of the region of interest where areas of probable pathological conditions are highligted.",A61B 5/05,"ALAN PENN & ASSOCIATES, INC.; PENN, Alan; THOMPSON, Scott, F.","PENN, Alan; THOMPSON, Scott, F.","60/722,005 30.09.2005 US",EP-6804281; EP-06804281; US-12088301
WO2017058643,PCT/US2016/053217,23.09.2016,WO/2017/058643,06.04.2017,WO,SELECTING CONTENT ITEMS BASED ON RECEIVED TERM USING TOPIC MODEL,"Lyrics associated with songs are processed to generate a probabilistic topic model that includes probabilities for terms of the lyrics with respect to one or more predetermined topics. At a later time, a user may desire to hear songs that are associated with a particular term, and may submit the term using a user interface. When the term is received, the probabilities of the probabilistic model are used to identify a topic of the predetermined topics that is most likely associated with the received term. The probabilistic model is used to identify songs that are associated with the identified topic, and some or all of the identified songs are presented as being related to the received term in the user interface.",G06F 17/30,"MICROSOFT TECHNOLOGY LICENSING, LLC","AGRAWAL, Varun","14/870,245 30.09.2015 US",EP-2016777860
WO2011133812,PCT/US2011/033490,21.04.2011,WO/2011/133812,27.10.2011,WO,DATA MINING SYSTEM,A data mining system and method retrieve data related to an item from a database. A survey is generated for presentation in a game. The survey includes the retrieved item data and solicits from a user input data pertaining to the retrieved item data. The input data is received from the survey and stored in a database with the item data. The input data is transmitted to the game and incorporated into the game such that the user interacts with the input data as part of playing the game.,G06F 17/30,"EBAY INC.; LANCIANI, Kirk; STEWART, Nicole; WASHINGTON, Steve; SUNDARESAN, Neelakantan","LANCIANI, Kirk; STEWART, Nicole; WASHINGTON, Steve; SUNDARESAN, Neelakantan","61/327,044 22.04.2010 US",
WO2004070648,PCT/US2003/032740,06.11.2003,WO/2004/070648,19.08.2004,WO,"A METHOD, SYSTEM, AND COMPUTER PROGRAM PRODUCT FOR COMPUTER-AIDED DETECTION OF NODULES WITH THREE DIMENSIONAL SHAPE ENHANCEMENT FILTERS","A method, system, and computer program product for evaluating an image including an object (S2) including filtering (S3) image data derived from the image with a first geometric enhancement filter (S6) having magnitude and likelihood filter components so as to produce first filtered image data in which a first geometric pattern is enhanced.",G06F 9/40; G06K 9/00,"THE UNIVERSITY OF CHICAGO; LI, Qiang; DOI, Kunio","LI, Qiang; DOI, Kunio","10/355,147 31.01.2003 US",JP-2004567996; EP-2003777621
EP189907351,16177346,30.06.2016,3113079,04.01.2017,EP,A CONTROLLER FOR A WORKING VEHICLE,"A controller (100) configured to receive image data (102) representative of the surroundings of a working vehicle. The image data (102) comprises a plurality of portion data. The controller (100) determines (104) one or more features associated with each of the plurality of portion data. For each of the plurality of portion data, the controller (100) applies (106) a label-attribution-algorithm to attribute one of a plurality of predefined labels to the portion data in question based on: (i) features determined for the portion data in question; and (ii) features determined for proximate portion data, which is portion data that is proximate to the portion data in question. The labels are representative of objects. The controller (100) provides a representation (110) of the attributed labels and their position in the received image data (102).",G06K 9/46; G06K 9/00; G08G 1/0962,CNH IND BELGIUM NV,HOUTHOOFT REIN; VERSTICHEL STIJN; DEBILDE BENOIT; FOSTER CHRISTOPHER A,201505423 03.07.2015 BE,
WO2019210275,PCT/US2019/029497,26.04.2019,WO/2019/210275,31.10.2019,WO,EVENT DRIVEN MATHEMATICAL ENGINE AND METHOD,"An event driven device has a network collecting data, A device is coupled to the network for determining changes in the data collected, wherein the device signals the network to process the data collected when the device determines desired changes in the data collected. In a second embodiment a level shift adjusts the band diagram of a spill and fill circuit to allow processing only if a change in input value occurs. This is extended to teach a means by which the subset of an image or incoming audio data might he used to trigger an event. It could also be used for always on operation at lower power than alternative solutions.",G06N 3/02; G06N 3/04; G06N 3/06; G06N 7/02,"SCHIE, David; GAITUKEVICH, Sergey; DRABOS, Peter; SIBRAI, Andreas","SCHIE, David; GAITUKEVICH, Sergey; DRABOS, Peter; SIBRAI, Andreas","16/396,570 26.04.2019 US; 62/663,121 26.04.2018 US",
WO2008057648,PCT/US2007/077105,29.08.2007,WO/2008/057648,15.05.2008,WO,METHOD OF DETECTION OF PATHOGEN MICROORGANISMS OR CHEMICALS,A method of determining the presence and level of microorganisms and/or chemicals in samples taken from generally any non-laboratory substance or environment. The method preferably comprises one or a combination of the steps of (a) prescreening for threshold levels of targeted microorganisms and/or (b) confirming the presence of targeted microorganisms or chemicals by mass spectrometry fingerprint analysis.,C12Q 1/06; G01N 33/569,"LITMUS, L.L.C.; WILKES, Jon, G.; BUZATU, Dan, A.; MILLER, Dwight, W.; CURTIS, Daniel, L.; DIGGS, Mark; NAYAK, Rajesh; RAFII, Fatemeh; SUTHERLAND, John, B.; TUCKER, Randal","WILKES, Jon, G.; BUZATU, Dan, A.; MILLER, Dwight, W.; CURTIS, Daniel, L.; DIGGS, Mark; NAYAK, Rajesh; RAFII, Fatemeh; SUTHERLAND, John, B.; TUCKER, Randal","11/558,586 10.11.2006 US",
WO2002093318,PCT/US2002/015700,15.05.2002,WO/2002/093318,21.11.2002,WO,SYSTEMS AND METHODS FOR MONITORING BEHAVIOR INFORMATICS,"A system and method used to assess animal behavior includes a module (1510) having sensors (1505) that collects a variety of physical and biological data from a test subject. Interpretation of the data is provided to assess the test subject's behavior, neurology, biochemistry and physiology. The module is useful in observing the effects of a drug on the test animal and providing information on the drug's signature. Another advantage is module's portability that allows it to be used in standard laboratory cages. (NOT SURE ABOUT THIS PORTABILITY) This portability allows the animal to be tested in its own habitat, that can reduce any erroneous data due to stressing the animal when removed to a test cage. Additionally, the module's design allows for parallel data collection and interpretation from several laboratory animals undergoing different experiments. Multi-dimensional modeling of the test subject based the system's interpretation of the data allows pattern recognition of the drug signature, and predictive drug analysis.",G01N 33/50; G01N 33/15; G06F 17/30; G06F 19/00,"PSYCHOGENICS INC.; BRUNNER, Daniela; GONDHALEKAR, Vijay; LEAHY, Emer","BRUNNER, Daniela; GONDHALEKAR, Vijay; LEAHY, Emer","60/291,039 15.05.2001 US; 60/326,271 01.10.2001 US",EP-2002731842; CA-2446853; AU-2002303783; EP-2010172439; JP-2002589931
WO2012047532,PCT/US2011/052739,22.09.2011,WO/2012/047532,12.04.2012,WO,PROVIDING ANSWERS TO QUESTIONS USING HYPOTHESIS PRUNING,"A method, system and computer program product for generating answers to questions. In one embodiment, the method comprises receiving a query, conducting a search through one or more data sources to identify candidate answers to the query, and providing each of the candidate answers with a preliminary score. The method further comprises filtering out any of the candidate answers with a preliminary score that does not satisfy a defined condition. The candidate answers having preliminary scores that satisfy this condition form a subset of the candidate answers. Each of the candidate answers in this subset is processed to produce further scores. A ranking function is applied to these further scores to determine a ranking for each of the candidate answers in the subset; and after this ranking function is applied, one or more of the candidate answers are selected as one or more final answers to the query.",G06E 1/00; G06F 15/18; G06G 7/00,"INTERNATIONAL BUSINESS MACHINES CORPORATION; CHU-CARROLL, Jennifer; FERRUCCI, David A.; GONDEK, David C.; LALLY, Adam P.; MURDOCK IV, James W.","CHU-CARROLL, Jennifer; FERRUCCI, David A.; GONDEK, David C.; LALLY, Adam P.; MURDOCK IV, James W.","61/387,157 28.09.2010 US",EP-2011831210
WO2018101671,PCT/KR2017/013328,22.11.2017,WO/2018/101671,07.06.2018,WO,APPARATUS AND METHOD FOR PROVIDING SENTENCE BASED ON USER INPUT,"Disclosed are an apparatus and/or method for providing a sentence based on a user input. When a sentence corresponding to a shorthand word input from a user is generated and provided to the user, a sentence most suitable for a current context is provided to the user by further considering context information. At least a portion of the method for providing a sentence based on a user input may be performed using a rule-based model and/or an artificial intelligence model learned according to at least one of neural network or deep learning algorithms. The rule-based model and/or artificial intelligence model may provide a sentence most suitable for a current context to the user by using the input shorthand word and the context information as input values.",G06F 3/023; G06F 3/0484; G06N 3/08; G06F 17/27,"SAMSUNG ELECTRONICS CO., LTD.","LEE, Ji-yeon; RHO, Ji-hyun; RYU, Won-ho",10-2016-0160783 29.11.2016 KR; 10-2017-0144234 31.10.2017 KR,EP-2017875469; CN-201780073446.9
EP236976251,16897086,14.12.2016,3438972,06.02.2019,EP,INFORMATION PROCESSING DEVICE AND INFORMATION PROCESSING METHOD,"[Object]  To provide a mechanism capable of characterizing data appropriately.  [Solution]  An information processing apparatus includes: an acquisition section that acquires first feature information, to which meaning is assigned, and second feature information, to which meaning is not assigned; and a generation section that generates time-series data having features indicated by the first feature information and the second feature information acquired by the acquisition section.",G06N 3/04; B25J 9/16; G10H 7/00; G10L 13/02; G10L 13/033; G10L 13/10,SONY CORP,IDE NAOKI; FUJITA TAKUYA; NAKAMURA AKIRA; NARIHIRA TAKUYA; NAKAHASHI RYO,2016063784 28.03.2016 JP; 2016087316 14.12.2016 JP,
EP154186579,14862597,18.07.2014,2918222,16.09.2015,EP,"LIFE MAINTENANCE MODE, BRAIN INHIBITION METHOD AND PERSONAL HEALTH INFORMATION PLATFORM","The present invention provides a novel life maintenance mode named as the third type of life maintenance mode, comprising the steps of decomposing inspection items of clinical diagnosis which is usually carried out after a disease has occurred into a series of individual automatically measured and computed indicators of life condition data, which is popularized into people's daily life and work to be practiced continuously so as to produce continuous diagnosis and inspection analysis report and trend; performing active control of the change of the life condition data by means of senior independent consciousness of cerebral cortex with the automatically measured and computed life condition data as a tool to serve as a quantitative traction means for treatment, rehabilitation, and health and longevity; predict and prevent the occurrence and development of diseases on the basis of the produced inspection analysis report and trend; automatically sending messages to remind a patient at home to check the treatment behaviors on the basis of doctor's advices and prescriptions in the track record of medical treatment, and providing an automatic no-response alarming service.",A61B 5/00; G06F 19/00,WU YIBING,WU YIBING,201310566688 15.11.2013 CN; 2014082449 18.07.2014 CN,
EP195255127,15812291,23.06.2015,3159118,26.04.2017,EP,MOVEMENT REPRODUCTION SYSTEM AND MOVEMENT REPRODUCTION DEVICE,"There is provided a motion reproducing system and a motion reproducing apparatus that store human motions and reproduce them. The motion reproducing system includes a data acquiring apparatus acquiring body motion data representing a motion of a subject during the motion, and transmitting the body motion data, a data managing apparatus receiving the body motion data from the data acquiring apparatus, the data managing apparatus including a memory storing the body motion data, and a motion reproducing apparatus receiving the body motion data stored in the memory from the data managing apparatus, and allowing a reproducer to reproduce the motion of the subject using the body motion data, the motion being performed at the time of acquisition of the body motion data.",B25J 9/22; A61B 5/0488; A61B 5/11; A61F 2/38; A61F 2/62; A61F 2/72; B25J 11/00,CYBERDYNE INC; UNIV TSUKUBA,SANKAI YOSHIYUKI,2014128330 23.06.2014 JP; 2015068077 23.06.2015 JP,
WO2017103676,PCT/IB2016/001890,15.12.2016,WO/2017/103676,22.06.2017,WO,SYSTEMS AND METHODS FOR PROVIDING AN IMAGE CLASSIFIER,"Systems and methods are provided for image classification using histograms of oriented gradients (HoG) in conjunction with a trainer. The efficiency of the process is greatly increased by first establishing a bitmap which identifies a subset of the pixels in the HoG window as including relevant foreground information, and limiting the HoG calculation and comparison process to only the pixels included in the bitmap.",G06K 9/46; G06K 9/62,LINEAR ALGEBRA TECHNOLOGIES LIMITED,"MOLONEY, David; DEHGHANI, Alireza","14/973,272 17.12.2015 US",EP-2016840331; DE-112016005776
EP12999800,97307401,23.09.1997,0834862,08.04.1998,EP,Method of key-phrase detection and verification for flexible speech understanding,"A key-phrase detection and verification method that can be advantageously used to realize understanding of flexible (i.e., unconstrained) speech. A ""multiple pass"" procedure is applied to a spoken utterance comprising a sequence of words (i.e., a ""sentence""). First, a plurality of key-phrases are detected (i.e., recognized) based on a set of phrase sub-grammars which may, for example, be specific to the state of the dialogue. These key-phrases are then verified by assigning confidence measures thereto and comparing these confidence measures to a threshold, resulting in a set of verified key-phrase candidates. Next, the verified key-phrase candidates are connected into sentence hypotheses based upon the confidence measures and predetermined (e.g., task-specific) semantic information. And, finally, one or more of these sentence hypotheses are verified to produce a verified sentence hypothesis and, from that, a resultant understanding of the spoken utterance. <IMAGE>",G10L 5/06; G10L 15/10; G10L 15/00; G10L 15/08; G10L 15/18; G10L 15/28,LUCENT TECHNOLOGIES INC,JUANG BIING-HWANG; LEE CHIN-HUI; KAWAHARA TATSUYA,72441396 01.10.1996 US; 77173296 20.12.1996 US,
WO2020041517,PCT/US2019/047570,21.08.2019,WO/2020/041517,27.02.2020,WO,SYSTEMS AND METHODS FOR ENHANCED IMAGING AND ANALYSIS,"A method to, is provided for collecting an image from a sample. The method includes selecting a radiation level for a first probe to meet a desired radiation dosage, and providing, with the first probe, a radiation at a selected point within a region of the sample. The method includes identifying a second selected point within the region of the sample based on a down sampling scheme, and providing a second radiation amount at the second selected point within the region of the sample. The method also includes interpolating a first datum and a second datum based on an up sampling scheme to obtain a plurality of data, and forming an image of the region of the sample with the plurality of data. A system to perform the above method and including the first probe is also provided.",A61B 5/00; G16H 30/40,THE SALK INSTITUTE FOR BIOLOGICAL STUDIES,"MANOR, Uri; FANG, Linjing","62/720,762 21.08.2018 US",
WO2006078255,PCT/US2005/002789,01.02.2005,WO/2006/078255,27.07.2006,WO,METHOD AND APPARATUS FOR DETECTING HUMANS AND HUMAN REMAINS,"The present invention includes a method and apparatus for detecting humans or human remains by analyzing air, fluid, or soil using electronic sensor technology, including surface acoustic-wave gas sensor technology. The method determines the presence and concentration of the target compound (or a class of compounds) associated with humans or human decomposition. Diagnostic software is used to identify target compounds where a stored library of signatures is compared to the signature obtained from the system. Signal processing and neural networks are preferably utilized in the analysis.",G01N 33/00,"UNIVERSITY OF FLORIDA RESEARCH FOUNDATION, INC.; MELKER, Richard, J.; GOLDBERGER, Bruce","MELKER, Richard, J.; GOLDBERGER, Bruce","11/039,111 19.01.2005 US",EP-5712288
WO2014102568,PCT/IB2012/057773,27.12.2012,WO/2014/102568,03.07.2014,WO,METHOD AND APPARATUS FOR MOTION DETECTION,"Image analysis techniques may be employed to identify moving and/or static object within a sequence of spatial data frames (102, 300). Attributes of interest may be identified within a sequence of spatial data frames (102, 300). The attributes of interest may be clustered and examined across frames of the spatial data to detect motion vectors. A system (200) may derive information about these attributes of interest and their motion over time and identify moving and/or static objects, and the moving and/or static objects may be used to generate natural language messages describing the motion of the attributes of interest. Example uses include description of moving and/or static objects in data such as weather data, oil spills, cellular growth (e.g., tumor progression), atmospheric conditions (e.g., the size of a hole in the ozone layer), or any other implementation where it may be desirable to detect motion vectors in a sequence of spatial data frames.",G06T 7/20; G06K 9/00; G06K 9/62,ARRIA DATA2TEXT LIMITED,"SRIPADA, Gowri, Somayajulu",,US-14650763
WO2014210334,PCT/US2014/044376,26.06.2014,WO/2014/210334,31.12.2014,WO,MACHINE LEARNING ENCHANCED BY HUMAN MEASUREMENTS,"In various embodiments, training objects are classified by human annotators, psychometric data characterizing the annotation of the training objects is acquired, a human-weighted loss function based at least in part on the classification data and the psychometric data is computationally derived, and one or more features of a query object are computationally classified based at least in part on the human- weighted loss function.",G06F 19/24,PRESIDENT AND FELLOWS OF HARVARD COLLEGE,"COX, David; SCHEIRER, Walter; ANTHONY, Samuel; NAKAYAMA, Ken","61/840,871 28.06.2013 US",US-14900397
WO2015149009,PCT/US2015/023146,27.03.2015,WO/2015/149009,01.10.2015,WO,SYSTEMS AND METHODS FOR IDENTIFYING TRAFFIC CONTROL DEVICES AND TESTING THE RETROREFLECTIVITY OF THE SAME,"The disclosed technology includes systems and methods for identifying traffic control devices from images, and systems and methods for assessing the retro reflectivity of traffic control devices. In some embodiments, the identification of traffic control devices is accomplished using a lighting-dependent statistical color model. In some embodiments, the identification of traffic control devices is accomplished using an active contour or active polygon method.",G06K 9/00,GEORGIA TECH RESEARCH CORPORATION,"AI, Chengbo; TSAI, Yichang; WANG, Zhaohua","61/971,126 27.03.2014 US",US-15129655; EP-2015769673
WO2007028166,PCT/US2006/034618,05.09.2006,WO/2007/028166,08.03.2007,WO,A SYSTEM AND METHOD FOR DETECTING TEXT IN REAL-WORLD COLOR IMAGES,"A method and apparatus for detecting text in real-world images comprises calculating a cascade of classifiers, the cascade comprising a plurality of stages, each stage including one or more weak classifiers, the plurality of stages organized to start out with classifiers that are most useful for ruling out non-text regions, and removing regions classified as non-text regions from the cascade prior to completion of the cascade, to further speed up processing.",G06K 9/34,"BLINDSIGHT, INC.; YUILLE, Alan; CHEN, Xiangrong; LAGERSTROM, Stellan; TERRY, Daniel; NITZBERG, Mark","YUILLE, Alan; CHEN, Xiangrong; LAGERSTROM, Stellan; TERRY, Daniel; NITZBERG, Mark","60/711,100 02.09.2005 US",EP-2006790181; DE-null
EP160970432,15187618,30.09.2015,3002686,06.04.2016,EP,LANGUAGE IDENTIFICATION,A plurality of documents in each of a plurality of languages can be received. A Latent Semantic Indexing (LSI) index can be created from the plurality of documents. A language classification model can be trained from the LSI index. A document to be identified by language can be received. A vector in the LSI index can be generated for the document to be identified by language. The vector can be evaluated against the language classification model.,G06F 17/27,ACCENTURE GLOBAL SERVICES LTD,BITTMAN MARK,201414502465 30.09.2014 US,
WO1999005621,PCT/US1998/014883,17.07.1998,WO/1999/005621,04.02.1999,WO,SYSTEM FOR PROCESSING TEXTUAL INPUTS USING NATURAL LANGUAGE PROCESSING TECHNIQUES,"A system (1480) filters documents in a document set retrieved from a document store in response to a query. The system (1480) obtains (1830) a first set of logical forms based on a selected one of the query and the documents in the document set. The system (1480) obtains a second set of logical forms based on another of the query and the documents in the document set. The system (1480) then uses natural language processing techniques to modify (1832, 1834) the first logical forms to obtain a modified set of logical forms. The system (1480) filters (1836) documents in the document set based on a predetermined relationship betwwen the modified set of logical forms and the second set of logical forms.",G06F 17/30,MICROSOFT CORPORATION,"CORSTON, Simon, H.; DOLAN, William, B.; VANDERWENDE, Lucy, H.; BRADEN-HARDER, Lisa","08/898,652 22.07.1997 US; 09/097,979 16.06.1998 US",EP-1998936899; CN-98807504.0
WO2020037492,PCT/CN2018/101510,21.08.2018,WO/2020/037492,27.02.2020,WO,DISTANCE MEASURING METHOD AND DEVICE,A method for measuring distance using an unmanned aerial vehicle (UAV) (102) includes: identifying a target object (106) to be measured (S502); receiving a plurality of images captured by a camera (1022) of the UAV (102) when the UAV (102) is moving and the camera (1022) is tracking the target object (106) (S504); collecting movement information of the UAV (106) corresponding to capturing moments of the plurality of images (S506); and calculating a distance between the target object (106) and the UAV (102) based on the movement information and the plurality of images (S508).,G01C 11/08; G05D 1/10,"SZ DJI TECHNOLOGY CO., LTD.","ZHOU, You; LIU, Jie; YAN, Jiaqi",,
WO2002073526,PCT/IL2002/000204,13.03.2002,WO/2002/073526,19.09.2002,WO,CEREBRAL PROGRAMMING,"A method of training a biological neural network using a controller includes the steps of applying a cycle comprising stimulating a neural network using the controller by applying at least an input signal to the network (204), detecting an output response of the network by the controller (206), modifying the stimulation of the neural network for at least a period of time if the response matches a desired at least approximate response (208), and repeating the cycle of stimulation, detection, and modification at least one more time (212) until the neural network is trained to generate a desired output response for said input signal.",A61N 1/08; A61N 1/34; A61N 1/36; G06N 3/06,"WIDE HORIZON HOLDINGS INC.; MAROM, Shimon; SHAHAF, Goded; ROUSSO, Benny; BEN HAIM, Shlomo","MAROM, Shimon; SHAHAF, Goded; ROUSSO, Benny; BEN HAIM, Shlomo","60/275,396 13.03.2001 US; 60/337,846 08.11.2001 US",JP-null; US-10662987
WO2019239367,PCT/IB2019/054948,13.06.2019,WO/2019/239367,19.12.2019,WO,VIRTUAL USER INTERFACE SYSTEM AND METHODS FOR USE THEREOF,"A system including a power source, one or more stimulating devices for stimulating the visual cortex of a user to present a perceived virtual image responsive to the stimulating, one or more sensing devices for sensing electrical signals in the motor and/or pre-motor cortex of the user and a processor/controller connected to the stimulating and sensing devices and programmed to sense signals from the motor and/or pre-motor cortex of the user. The sensed signals result from the user performing a movement and/or intending to perform a movement and/or imagining the performing of a movement and are used to interact with the presented virtual image. The processor/controller processes the sensed signals to obtain computed data indicative of a user's interaction with the virtual image, and performs a general computing task responsive to the computed data.",A61B 5/0476; A61B 5/0478; A61N 1/04,"GRIBETZ, Meron","GRIBETZ, Meron","62/684,756 14.06.2018 US",
WO2015126162,PCT/KR2015/001636,17.02.2015,WO/2015/126162,27.08.2015,WO,CREATING EPISODIC MEMORY BASED ON UNSTRUCTURED DATA IN ELECTRONIC DEVICES,"A method and system for identifying episodic events in a user's life using an electronic device are provided. The method includes receiving, by the electronic device, unstructured data from at least one data source associated with a user, and identifying at least one episodic event from the unstructured data based on at least one parameter, wherein the at least one parameter is at least one of a casual reasoning, a spatial reasoning, or a temporal reasoning.",G06F 17/00; G06N 5/04; G06F 17/20,"SAMSUNG ELECTRONICS CO., LTD.","SHASTRI, Lokendra; NOOKALA, Rohini; SENGUPTA, Sohini; KHATKE, Kapil; ATAL, Kailash; BANSAL, Nishu; TANDON, Rajat; KUMAR, Udaya",817/CHE/2014  20.02.2014 IN; 817/CHE/2014  13.11.2014 IN,EP-2015752089
WO2015187247,PCT/US2015/025803,14.04.2015,WO/2015/187247,10.12.2015,WO,BIOMIMETIC MULTICHANNEL NEUROSTIMULATION,"Sensory information can be delivered to a subject mammal, for example, for restoring a sense of cutaneous touch and limb motion to the subject mammal. A biomimetic electrical signal is generated based on (a) a stimulation reference signal applied to a somatosensory region of a nervous system of a reference mammal, (b) a stimulated-response signal acquired from a sensory cortex of the reference mammal in response to application of the stimulation reference signal to the thalamic nucleus, and (c) a natural-response signal acquired from the sensory cortex in response to peripheral touch stimuli and/or peripheral nerve stimulation of the reference mammal. The biomimetic electrical signal is applied to a somatosensory region of a nervous system of the subject mammal to induce an activation response, in a sensory cortex of the subject mammal.",A61B 5/04,RESEARCH FOUNDATION FOR THE STATE UNIVERSITY OF NEW YORK,"CHOI, John S.; FRANCIS, Joseph T.","61/979,425 14.04.2014 US",US-15304305; CN-201580027321.3
WO2018014109,PCT/CA2017/000176,24.07.2017,WO/2018/014109,25.01.2018,WO,SYSTEM AND METHOD FOR ANALYZING AND SEARCHING FOR FEATURES ASSOCIATED WITH OBJECTS,"There is provided a system and method for analyzing features associated with objects. The method comprises obtaining one or more images associated with corresponding one or more objects; passing each image through a plurality of models to generate feature vectors for each object; combining feature vectors for each object when multiple feature vectors are produced; generating similarity measures for the feature vectors; and storing the feature vectors to enable the features to be searched, filtered and/or retrieved.",G06Q 30/02; G06F 15/18; G06F 17/30; G06N 3/02; G06Q 30/06,9206868 CANADA INC.,"BESSEGA, Maria Carolina; CAMACARO, Jaime Rafael","62/365,436 22.07.2016 US",CA-3031548
WO2020010517,PCT/CN2018/095144,10.07.2018,WO/2020/010517,16.01.2020,WO,TRAJECTORY PREDICTION METHOD AND APPARATUS,"A trajectory prediction method and apparatus, relating to the field of local navigation for robots and intelligent vehicles, and applied to a vehicle provided with a vehicle-mounted camera. The method comprises: photographing a surrounding environment by means of a vehicle-mounted camera to acquire a video sequence comprising a surrounding vehicle and a vehicle background (101); positioning the surrounding vehicle in the video sequence and extracting historical trajectory information of the surrounding vehicle, and taking, as auxiliary information, scene semantic information obtained through performing image segmentation on the video sequence (102); and inputting the historical trajectory information and the auxiliary information into a neural network model to obtain a predicted trajectory of the surrounding vehicle (103). By means of the trajectory prediction method, the accuracy of predicting a vehicle trajectory can be improved.",G05D 1/02,SHENZHEN UNIVERSITY; 深圳大学,"ZOU, Wenbin; 邹文斌; ZHOU, Changyuan; 周长源; WU, Di; 吴迪; WANG, Zhennan; 王振楠; TANG, Yi; 唐毅; LI, Xia; 李霞",,
WO2016071718,PCT/GB2015/053385,09.11.2015,WO/2016/071718,12.05.2016,WO,INFLUENCING CONTENT OR ACCESS TO CONTENT,"A method of influencing access to website, social media or mobile application content is described. The method comprises identifying the occurrence of an item of live or previously broadcast media content, identifying consumer Internet activity at the time of the occurrence of the item of media content, and identifying, from said detected consumer internet activity, a strategy to influence an Internet search function, social media site or mobile application to display selected information. Then, a subsequent broadcast of the item of media content is identified, and the identified strategy is triggered at the point the item occurs during the time of the identified subsequent broadcast.",H04N 21/25; H04N 21/258; H04N 21/262; H04N 21/2668; H04N 21/435; H04N 21/44; H04N 21/45; H04N 21/478; H04N 21/4788; H04N 21/8352; H04N 21/858; H04N 21/4402; H04N 21/43; H04N 21/4782; G06F 17/30,MPORIUM GROUP PLC,"HACKETT, Christopher; SMITH, Tom; CARLSON, David; WARFORD, Ian; DEGROOT, Nelius",1419834.5 07.11.2014 GB; 1516944.4 24.09.2015 GB; 1516946.9 24.09.2015 GB; 1516947.7 24.09.2015 GB,US-15524787
EP14596797,05101353,23.02.2005,1696237,30.08.2006,EP,Diagnosis of dry-eye syndrome by SELDI analysis of proteins in tears,"The invention relates to a method for the diagnosis of dry-eye, related ocular surface diseases and diabetes mellitus based on the protein composition of tears of an individual, using SELDI-TOF-MS (surface-enhanced laser desorption/ionization in time-of-flight mass spectrometry) as a method to profile human tear proteins. Protein or peptide biomarkers for dry-eye disease are selected by comparing the protein profiles of tears from dry-eye patients and healthy controls and analyzing those, using univariate analysis, multivariate statistical techniques and/or artificial neural networks. A multivariate panel of markers is described that classifies the two (or more) groups as accurately as possible.",G01N 33/68,RESCOM GMBH,GRUS FRANZ; PFEIFFER NORBERT,05101353 23.02.2005 EP,
EP198313403,16201016,29.11.2016,3176751,07.06.2017,EP,"INFORMATION PROCESSING DEVICE, INFORMATION PROCESSING METHOD, COMPUTER-READABLE RECORDING MEDIUM, AND INSPECTION SYSTEM","An information processing device inspects a target image that contains an image of an inspection target. The device includes a pre-processor (702), a first calculator (703), a second calculator (703), and a determiner (704). The pre-processor (702) is configured to perform preprocessing for comparing the target image with a reference image or a plurality of reference images. The first calculator (703) is configured to define, in the target image, a region of interest (ROI) and surrounding regions that are adjacent to the ROI, and calculate a feature value of the ROI. The second calculator (703) is configured to calculate an outlier from comparison with feature values of images corresponding to the ROI and the surrounding regions in the reference images. The outlier numerically indicates singularity of an image at the ROI. The determiner (704) is configured to provide, based on the outlier, an indicator to be used for the inspection.",G06T 7/00; G06K 9/46,RICOH CO LTD,TANAKA TAKUYA; KASAHARA RYOSUKE,2015234843 01.12.2015 JP; 2016185440 23.09.2016 JP,
WO2017132228,PCT/US2017/014885,25.01.2017,WO/2017/132228,03.08.2017,WO,DIGITAL MEDIA CONTENT EXTRACTION NATURAL LANGUAGE PROCESSING SYSTEM,"An automated lesson generation learning system extracts text-based content from a digital programming file. The system parses the extracted content to identify one or more topics, parts of speech, named entities and/or other material in the content. The system then automatically generates and outputs a lesson containing content that is relevant to the content that was extracted from the digital programming file.",G06F 17/30,"WESPEKE, INC.","ELCHIK, Michael, E.; CARBONELL, Jaime, G.; WILSON, Cathy; PAWLOWSKI, Robert, J., Jr.; JONES, Dafyd","62/286,661 25.01.2016 US; 62/428,260 30.11.2016 US; 62/331,490 04.05.2016 US",KR-1020187024507; MX-MX/a/2018/008994; AU-2017212396; EP-2017744817; IL-260768; CA-3012471
WO2019214799,PCT/EP2018/061667,07.05.2018,WO/2019/214799,14.11.2019,WO,SMART DIALOGUE SYSTEM AND METHOD OF INTEGRATING ENRICHED SEMANTICS FROM PERSONAL AND CONTEXTUAL LEARNING,"A smart dialogue system improved with a context and machine learning system for enabling enhanced semantics for query understanding. A spoken dialogue system interacts with a user via voice. A context and machine learning system is configured to collect telemetry and interaction data from a user and a vehicle and learns a user profile comprising at least one of user's preference, interest, or habit based on the collected data. The context and machine learning system is configured to identify a behavior pattern of the user from the user profile, identify a current context associated with a current situation, determine a recommended action based on the behavior pattern and the current context, and send the recommended action to a target system for executing the recommended action. The recommended action may be generated in response to a voice request from a user or may be generated autonomously by the system without a request from the user.",G10L 15/22; B60R 16/037; G10L 15/18; G10L 15/30,BAYERISCHE MOTOREN WERKE AKTIENGESELLSCHAFT,"CHIN, Alvin; TIAN, Jilei",,
WO2011067463,PCT/FI2010/050975,29.11.2010,WO/2011/067463,09.06.2011,WO,WEIGHT-ORDERED ENUMERATION OF REFERENTS AND CUTTING OFF LENGTHY ENUMERATIONS,"In many reference resolution problems there are many candidate referents, and the overhead of enumerating them can be considerable. The overhead is reduced by stopping enumeration be- fore all candidate referents have been enumerated, utilizing the properties of ordered and semi-ordered enumerators. Converting semi-ordered enumerators into ordered enumerators and combining several ordered enumerators into a single using dynamic weightings for handling determiner interpretations are dis- closed.",G06F 17/27; G06F 17/28,"TATU YLÖNEN OY; YLÖNEN, Tatu","YLÖNEN, Tatu","12/629,606 02.12.2009 US",EP-2010834276
WO2019064158,PCT/IB2018/057353,24.09.2018,WO/2019/064158,04.04.2019,WO,CONVERSION BETWEEN GRAPHEMES AND PHONEMES ACROSS DIFFERENT LANGUAGES,"A technique for estimating phonemes for a word written in a different language is disclosed. A sequence of graphemes of a given word in a source language is received. The sequence of the graphemes in the source language is converted into a sequence of phonemes in the source language. One or more sequences of phonemes in a target language are generated from the sequence of the phonemes in the source language by using a neural network model. One sequence of phonemes in the target language is determined for the given word. Also, technique for estimating graphemes of a word from phonemes in a different language is disclosed.",G10L 13/08,INTERNATIONAL BUSINESS MACHINES CORPORATION; IBM UNITED KINGDOM LIMITED; IBM (CHINA) INVESTMENT COMPANY LIMITED,"NAGANO, Toru; KURATA, Gakuto; TSUBOI, Yuta","15/717,194 27.09.2017 US; 15/801,820 02.11.2017 US",
EP289840098,19196237,09.09.2019,3620972,11.03.2020,EP,METHOD AND APPARATUS FOR PROVIDING A USER REACTION USER INTERFACE FOR GENERATING A PASSENGER-BASED DRIVING PROFILE,"An approach is provided for presenting a user reaction user interface for providing a user interface on a device to present vehicle sensor data, user sensor data, or a combination thereof collected from one or more sensors of vehicle carrying a user as a passenger. The vehicle sensor data indicates at least one driving behavior of the vehicle and the user sensor data indicates a reaction of the user to the least one driving behavior. The approach also involves presenting a user interface element associated with the user interface to receive a user input for providing, modifying, interacting with, or a combination thereof the vehicle sensor data, the user sensor data, or a combination thereof. The approach further involves generating a passenger profile for the user based on the vehicle sensor data, the user sensor, or a combination thereof after the providing, the modifying, the interacting with, or a combination of the vehicle sensor data, the user sensor data, or a combination thereof via the user interface element.",G06K 9/00; B60W 40/09,HERE GLOBAL BV,BEAUREPAIRE JEROME,201816126837 10.09.2018 US,
WO2006093507,PCT/US2005/017988,19.05.2005,WO/2006/093507,08.09.2006,WO,METHODS AND SYSTEMS FOR PREDICTING CANCER OUTCOME,The invention provides a molecular marker set that can be used for prognosis of colorectal cancer in a colorectal cancer patient. The invention also provides methods and computer systems for evaluating prognosis of colorectal cancer in a colorectal cancer patient based on the molecular marker set. The invention also provides methods and computer systems for determining chemotherapy for a colorectal cancer patient and for enrolling patients in clinical trials.,G06F 17/50; G06F 19/00; G01N 33/48; G01N 33/50,"H. LEE MOFFITT CANCER CENTER AND RESEARCH INSTITUTE, INC.; UNIVERSITY OF SOUTH FLORIDA; YEATMAN, Timothy, J.; ESCHRICH, Steven; BLOOM, Gregory, C.","YEATMAN, Timothy, J.; ESCHRICH, Steven; BLOOM, Gregory, C.","11/065,794 25.02.2005 US",EP-2005754399
WO2019016685,PCT/IB2018/055264,16.07.2018,WO/2019/016685,24.01.2019,WO,METHODS AND SYSTEMS FOR CONTINUOUS RISK MONITORING AND DYNAMIC UNDERWRITING PRICING,"A system that includes a calculation unit configured to receive an input derived from data measured from a sensor located in a first location, the calculation unit is configured to determine a value for a risk premium. The system includes a storage unit to store the input; and an output unit configured to receive information based on the value determined by the calculation unit and outputs a graphical representation to a display device. The system is at a second location different from the first location.",G06Q 40/08; G06Q 30/02; G06T 7/00; B64C 39/02,"GEYLANI, Veysel Sinan","GEYLANI, Veysel Sinan","62/534,125 18.07.2017 US",EP-2018834425
WO1996035982,PCT/EP1996/001789,29.04.1996,WO/1996/035982,14.11.1996,WO,AUTONOMOUS COMMAND AND CONTROL UNIT FOR MOBILE PLATFORM,"In a vehicle designed for the execution of a mission, a programmable decision unit capable of managing and controlling the execution of the mission by utilizing a plurality of subsystems and database capable of holding and managing data including pre-stored data and data acquired by and received from the plurality of subsystems. The programmable decision unit includes a mission plan (MP) for accomplishing the execution of the mission which MP may be described as a graph that utilizes the database. The operation of managing and controlling the execution of the mission includes a succession of iterations that include each: (i) assignment of a mission segment associated with a current mission state to at least one of the subsystems; (ii) receipt from the subsystems of report data which include data indicative of the execution status of said mission segment by the at least one subsystem; (iii) evaluation of the report data for determining either of normal behavior and exceptional event. The programmable decision unit is capable of managing and controlling the execution of the mission in essentially autonomous fashion whereby the vehicle becomes an autonomous vehicle.",G05D 1/02,"THE STATE OF ISRAEL, MINISTRY OF DEFENCE, ARMAMENT DEVELOPMENT AUTHORITY, RAFAEL; YAVNAI, Arie; COHN, Michael","YAVNAI, Arie",113647 08.05.1995 IL; 117792 02.04.1996 IL,US-08952145
EP14355724,04029602,14.12.2004,1550869,06.07.2005,EP,Cell motility assay,"An electrooptical method is disclosed for quantifying the motility response of cells to external stimuli, wherein a target cell population (formed as a function of said response) is subsequently optically differentiated by the addition of an optical differentiation solution, and whereby the targeted cell population becomes more or less detectable to an electrooptical reading device. The method can be used to perform chemotactic assays. For such and other purposes, the method can be performed utilizing high throughput robotic automation.",G01N 33/48; G01N 33/50; B01L 3/00; C12M 1/34; C12Q 1/02; G01N 33/483,MILLIPORE CORP,KAMATH LAKSHMI,74602903 23.12.2003 US,
WO2018226960,PCT/US2018/036467,07.06.2018,WO/2018/226960,13.12.2018,WO,KEY-VALUE MEMORY NETWORKS,"In one embodiment, a computing system may generate a query vector representation of an input (e.g., a question). The system may generate relevance measures associated with a set of key-value memories based on comparisons between the query vector representation and key vector representations of the keys in the memories. The system may generate an aggregated result based on the relevance measures and value vector representations of the values in the memories. Through an iterative process that iteratively updates the query vector representation used in each iteration, the system may generate a final aggregated result using a final query vector representation. A combined feature representation may be generated based on the final aggregated result and the final query vector representation. The system may select an output (e.g., an answer to the question) in response to the input based on comparisons between the combined feature representation and a set of candidate outputs.",G06F 17/30,"FACEBOOK, INC.","MILLER, Alexander Holden; FISCH, Adam Joshua; DODGE, Jesse Dean; KARIMI, Amir-Hossein; BORDES, Antoine; WESTON, Jason E.","62/517,097 08.06.2017 US; 16/002,463 07.06.2018 US",
EP13027224,97309261,18.11.1997,0848371,17.06.1998,EP,Automated directory assistance system utilizing a heuristics model for predicting the most likely requested number,The invention relates to an automated directory assistance system that utilizes a heuristics model for predicting the most likely requested number. Each orthography link in the speech recognition dictionary pointing toward an entry in the white pages is associated with a data structure that provides a probability value of that link pointing toward the telephone number intended by the user on the basis of locality information specified by the user of the automated directory assistance system. <IMAGE>,G10L 15/00; G06F 17/30; G10L 15/26; H04M 1/27,NORTEL NETWORKS LTD,GUPTA VISHWA,76750396 16.12.1996 US,
WO2018097889,PCT/US2017/053495,26.09.2017,WO/2018/097889,31.05.2018,WO,CAMERA OPERABLE USING NATURAL LANGUAGE COMMANDS,"In general, techniques of this disclosure may enable a computing device to capture one or more images based on a natural language user input. The computing device, while operating in an image capture mode, receive an indication of a natural language user input associated with an image capture command. The computing device determines, based on the image capture command, a visual token to be included in one or more images to be captured by the camera. The computing device locates the visual token within an image preview output by the computing device while operating in the image capture mode. The computing device captures one or more images of the visual token.",G10L 15/18; G06K 9/00; G10L 15/22; H04N 5/232,GOOGLE LLC.,"CARCERONI, Rodrigo","15/358,770 22.11.2016 US",
WO2016167947,PCT/US2016/024596,29.03.2016,WO/2016/167947,20.10.2016,WO,TWO-DIMENSIONAL INFRARED DEPTH SENSING,"A signal encoding an infrared (IR) image including a plurality of IR pixels is received from an IR camera. Each IR pixel specifies one or more IR parameters of that IR pixel. IR-skin pixels that image a human hand are identified in the IR image. For each IR-skin pixel, a depth of a human hand portion imaged by that IR-skin pixel is estimated based on the IR parameters of that IR-skin pixel. A skeletal hand model including a plurality of hand joints is derived. Each hand joint is defined with three independent position coordinates inferred from the estimated depths of each human hand portion.",G06K 9/00,"MICROSOFT TECHNOLOGY LICENSING, LLC","BUTLER, Ben; TANKOVICH, Vladimir; KESKIN, Cem; FANELLO, Sean Ryan Francesco; IZADI, Shahram; BARSOUM, Emad; STACHNIAK, Simon P.; WEI, Yichen","14/686,528 14.04.2015 US",EP-2016715956
WO2019027733,PCT/US2018/043458,24.07.2018,WO/2019/027733,07.02.2019,WO,SYSTEMS AND METHODS FOR DETERMINING PATH CONFIDENCE FOR UNMANNED VEHICLES,"Examples implementations relate to determining path confidence for a vehicle. An example method includes receiving a request for a vehicle to navigate a target location. The method further includes determining a navigation path for the vehicle to traverse a first segment of the target location based on a plurality of prior navigation paths previously determined for traversal of segments similar to the first segment of the target location. The method also includes determining a confidence level associated with the navigation path. Based on the determined confidence level, the method additionally includes selecting a navigation mode for the vehicle from a plurality of navigation modes corresponding to a plurality of levels of remote assistance. The method further includes causing the vehicle to traverse the first segment of the target location using a level of remote assistance corresponding to the selected navigation mode for the vehicle.",G05D 1/00; G05D 1/12; G06N 3/08; G06N 3/04,WING AVIATION LLC,"SCHUBERT, Martin Friedrich; WATSON, Philip Edwin; GRUNDMANN, Michael Jason; LEVINE, Gabriella","15/667,391 02.08.2017 US",SG-11201913991U; EP-2018842338
WO2018125428,PCT/US2017/062365,17.11.2017,WO/2018/125428,05.07.2018,WO,AUTOMATIC CONTROL OF WEARABLE DISPLAY DEVICE BASED ON EXTERNAL CONDITIONS,"Embodiments of a wearable device can include a head-mounted display (HMD) which can be configured to display virtual content. While the user is interacting with visual or audible virtual content, the user of the wearable may encounter a triggering event such as, for example, an emergency condition or an unsafe condition, detecting one or more triggering objects in an environment, or determining characteristics of the user's environment (e.g., home or office). Embodiments of the wearable device can automatically detect the triggering event and automatically control the HMD to deemphasize, block, or stop displaying the virtual content. The HMD may include a button that can be actuated by the user to manually deemphasize, block, or stop displaying the virtual content.",G06F 3/00; G06F 19/00; G06T 11/00; G06T 19/00,"MAGIC LEAP, INC.","POWDERLY, James, M.; NILES, Savannah; SAMEC, Nicole, Elizabeth; AMIRHOOSHMAND, Ali; ROBAINA, Nastasja, U.; HARRISES, Christopher, M.; BAERENRODT, Mark; CINTRON, Carlos, A.rivera; SMITH, Brian, Keith","62/440,099 29.12.2016 US",IL-267683; CA-3051060; KR-1020197021805; EP-2017888654; AU-2017387781; JP-2019535899; CN-201780087609.9
WO2016077026,PCT/US2015/055932,16.10.2015,WO/2016/077026,19.05.2016,WO,NEAR-ONLINE MULTI-TARGET TRACKING WITH AGGREGATED LOCAL FLOW DESCRIPTOR (ALFD),"Systems and methods are disclosed to track targets in a video by capturing a video sequence, detecting data association between detections and targets, where detections are generated using one or more image-based detectors (tracking-by-detections); identifying one or more target of interests and estimating a motion of each individual; and applying an Aggregated Local Flow Descriptor to accurately measure an affinity between a pair of detections and a Near Online Muti-target Tracking to perform multiple target tracking given a video sequence.",G06T 7/20,"NEC LABORATORIES AMERICA, INC.","CHOI, Wongun","62/078,765 12.11.2014 US; 62/151,094 22.04.2015 US; 14/872,551 01.10.2015 US",EP-2015858498; JP-2017525879
WO2013155619,PCT/CA2013/000391,22.04.2013,WO/2013/155619,24.10.2013,WO,CONVERSATIONAL AGENT,"A method, system, and computer program product provide a conversation agent to process natural language queries expressed by a user and perform commands according to the derived intention of the user. A natural language processing (NLP) engine derives intent using conditional random fields to identify a domain and at least one task embodied in the query. The NLP may further identify one or more subdomains, and one or more entities related to the identified command. A template system creates a data structure for information relevant to the derived intent and passes a template to a services manager for interfacing with one or more services capable of accomplishing the task. A dialogue manager may elicit more entities from the user if required by the services manager and otherwise engage in conversation with the user. In one embodiment, the conversational agent allows a user to engage in multiple conversations simultaneously.",G06F 17/27; G06F 17/30; G10L 15/22,"PASUPALAK, Sam; PANTONY, Joshua R.; HSU, Wilson; WU, Zhiyuan; TREGENZA, Phil; SULEMAN, Kaheer; SIMPSON, James; McNAMARA, Andrew; ISMAIL, Tareq","PASUPALAK, Sam; PANTONY, Joshua R.; HSU, Wilson; WU, Zhiyuan; TREGENZA, Phil; SULEMAN, Kaheer; SIMPSON, James; McNAMARA, Andrew; ISMAIL, Tareq","61/636,444 20.04.2012 US",US-14394824; EP-2013777880
EP236801782,17789261,11.04.2017,3435292,30.01.2019,EP,"FEELING SPECIFICATION SYSTEM, SYSTEM, AND PROGRAM","An emotion identifying system includes: an information acquiring unit that acquires information for deciding an emotion of a target object; a judging unit that, based on the information, judges whether or not judgement factors associated respectively with a plurality of emotions are each met; an adjusting unit that, if the information matches a predetermined condition about a predetermined type of emotion among the plurality of emotions, expands a range occupied by the predetermined type of emotion in a space in which the plurality of emotions is mapped; an emotion identifying unit that identifies, among the plurality of emotions, an emotion for which the judging unit judges that the associated judgement factor is met; and an output control unit that causes information indicating an emotion identified by the emotion identifying unit and ranges occupied respectively by the plurality of emotions in the space to be output.",G06N 3/00,COCORO SB CORP,SON MASAYOSHI; TSUTSUI TAKASHI; TOMONAGA KOSUKE; OURA KIYOSHI,2016091998 28.04.2016 JP; 2017014876 11.04.2017 JP,
WO2020069534,PCT/US2019/053915,30.09.2019,WO/2020/069534,02.04.2020,WO,"DATA REPRESENTATIONS AND ARCHITECTURES, SYSTEMS, AND METHODS FOR MULTI-SENSORY FUSION, COMPUTING, AND CROSS-DOMAIN GENERALIZATION","A computer-implemented method, computer system and machine readable medium. The method includes performing a set of parameterizations of a plurality of semantic concepts, each parameterization of the set including: receiving existing data at a computer system on the plurality of semantic concepts, the existing data including processed output data from a plurality of neural network-based computing systems (NNBCSs), the processed output data corresponding to a plurality of distinct data domains associated with respective ones of the NNBCSs; generating a data structure to define a continuous vector space of a digital knowledge graph (DKG) based on the existing data; and storing the data structure in the memory circuitry; and in response to a determination that error rates from a processing of data sets by the plurality of NNBCSs are below respective predetermined thresholds, generating a training model.",G06N 3/02; G06N 3/08; G06F 16/901,"BRAINWORKS; ALVELDA, Philip","ALVELDA, Philip","62/739,207 29.09.2018 US; 62/739,208 29.09.2018 US; 62/739,210 29.09.2018 US; 62/739,287 30.09.2018 US; 62/739,297 30.09.2018 US; 62/739,301 30.09.2018 US; 62/739,364 01.10.2018 US; 62/739,864 02.10.2018 US; 62/739,895 02.10.2018 US",
WO2019183758,PCT/CN2018/080507,26.03.2018,WO/2019/183758,03.10.2019,WO,METHODS AND APPARATUS FOR MULTI-TASK RECOGNITION USING NEURAL NETWORKS,"Methods and apparatus for multi-task recognition using neural networks are disclosed. An example apparatus includes a filter engine (108) to generate a facial identifier feature map based on image data, the facial identifier feature map to identify a face within the image data. The example apparatus also includes a sibling semantic engine (110) to process the facial identifier feature map to generate an attribute feature map associated with a facial attribute. The example apparatus also includes a task loss engine (112) to calculate a probability factor for the attribute, the probability factor identifying the facial attribute. The example apparatus also includes a report generator (116) to generate a report indicative of a classification of the facial attribute.",G06K 9/00,"INTEL CORPORATION; HU, Ping; YAO, Anbang; CHEN, Yurong; CAI, Dongqi; WANG, Shandong","HU, Ping; YAO, Anbang; CHEN, Yurong; CAI, Dongqi; WANG, Shandong",,
EP14028205,02724190,01.03.2002,1364069,26.11.2003,EP,METHOD FOR THE DEVELOPMENT OF GENE PANELS FOR DIAGNOSTIC AND THERAPEUTIC PURPOSES BASED ON THE EXPRESSION AND METHYLATOIN STATUS OF THE GENES,The invention concerns a method for the development of gene panels for diagnostic and therapeutic pusposes based on the expession and methylation status of secific genes. The invention further concerns gene panels developed using the method of the present invention and their uses.,C12Q 1/68; G01N 27/62; A61K 45/00; A61P 1/00; A61P 1/04; A61P 3/00; A61P 9/00; A61P 9/12; A61P 11/00; A61P 15/10; A61P 17/00; A61P 19/00; A61P 25/00; A61P 25/06; A61P 25/28; A61P 35/00; A61P 35/02; C12M 1/00; C12N 15/09; C12Q 1/02; C12Q 1/6809; C12Q 1/6827; C12Q 1/6837; C12Q 1/6883; C12Q 1/6886; G01N 27/447; G01N 33/53; G01N 33/566,EPIGENOMICS AG,OLEK ALEXANDER; BERLIN KURT,0202255 01.03.2002 EP; 27254901 01.03.2001 US,
EP252257035,19164558,22.03.2019,3543907,25.09.2019,EP,"METHOD, APPARATUS, AND SYSTEM FOR DYNAMIC ADAPTATION OF AN IN-VEHICLE FEATURE DETECTOR",,G06K 9/00,HERE GLOBAL BV,SHESTAK VLADIMIR; O'HARA STEPHEN; DRONEN NICHOLAS,201815933063 22.03.2018 US,
EP222886313,16465563,29.12.2016,3343432,04.07.2018,EP,GENERATING TRAINING IMAGES FOR MACHINE LEARNING-BASED OBJECT RECOGNITION SYSTEMS,"A method, performed by a computing device, for generating training image data for a machine learning-based object recognition system is described. The method comprises receiving generic image data of an object type, receiving recorded image data related to the object type, and modifying the generic image data with respect to at least one imaging-related parameter. The method further comprises determining a degree of similarity between the modified generic image data and the recorded image data, and, when the determined degree of similarity fulfills a similarity condition, storing the modified generic image data as generated training image data of the object type. Further described are a computing device, a computer program product, a system and a motor vehicle.",G06K 9/00; G06K 9/62,ELEKTROBIT AUTOMOTIVE GMBH,GRIGORESCU SORIN; MACESANU GIGEL; COCIAS TIBERIU; TRASNEA BOGDAN; GINERICA COSMIN,16465563 29.12.2016 EP,
WO2018155019,PCT/JP2018/001306,18.01.2018,WO/2018/155019,30.08.2018,WO,"OPTICAL SENSOR, LEARNING APPARATUS, AND IMAGE PROCESSING SYSTEM","An identification process suited to the attributes of a subject can be carried out. An optical sensor according to one aspect of the present invention is an optical sensor including an optical member having a plurality of focusing units, each focusing unit focusing light from a subject, and a plurality of image capturing devices, each image capturing device having a plurality of light-receiving elements, each image capturing device being provided corresponding to one of the focusing units, and each image capturing device configured to receive light focused by the corresponding focusing unit and form a captured image of the subject. The light-receiving elements, of the plurality of light-receiving elements, that are to be used to form the captured image are set for each of the image capturing devices.",G06K 9/20,OMRON CORPORATION,"ANDO, Tanichi",2017-031088 22.02.2017 JP,CN-201880005689.3; EP-2018703378
EP234740428,18176725,08.06.2018,3413218,12.12.2018,EP,KEY-VALUE MEMORY NETWORKS,"In one embodiment, a computing system may generate a query vector representation of an input (e.g., a question). The system may generate relevance measures associated with a set of key-value memories based on comparisons between the query vector representation and key vector representations of the keys in the memories. The system may generate an aggregated result based on the relevance measures and value vector representations of the values in the memories. Through an iterative process that iteratively updates the query vector representation used in each iteration, the system may generate a final aggregated result using a final query vector representation. A combined feature representation may be generated based on the final aggregated result and the final query vector representation. The system may select an output (e.g., an answer to the question) in response to the input based on comparisons between the combined feature representation and a set of candidate outputs.",G06F 17/30,FACEBOOK INC,MILLER ALEXANDER HOLDEN; FISCH ADAM JOSHUA; DODGE JESSE DEAN; KARIMI AMIR-HOSSEIN; BORDES ANTOINE; WESTON JASON E,201762517097 08.06.2017 US; 2018036467 07.06.2018 US,
WO2015073019,PCT/US2013/070284,15.11.2013,WO/2015/073019,21.05.2015,WO,SYSTEM AND METHOD FOR MAINTAINING SPEACH RECOGNITION DYNAMIC DICTIONARY,"A computer-implemented method for speech recognition comprising: performing a content mark-up, via a natural language processing engine, of output text associated with an active application associated with one or more contexts; maintaining a history of communication interactions, via a content tracker, based at least in part on the content mark-up of the output text associated with the active application; updating a dynamic dictionary, via a dynamic dictionary manager, based at least in part on the maintained history of communication interactions; receiving a voice input from a user; and performing speech recognition, via a speech recognition engine, on the voice input to output subsequent text associated with the voice input for display and/or text-to-speech output to the user based at least in part on use of the dynamic dictionary.",G10L 15/26; G10L 15/18; G06F 17/20,"INTEL CORPORATION; SUKHOMLINOV, Vadim","SUKHOMLINOV, Vadim",,US-14359494; KR-1020167009388
WO2015053711,PCT/SG2014/000472,08.10.2014,WO/2015/053711,16.04.2015,WO,METHOD AND SYSTEM FOR INTELLIGENT CRANE LIFTING,"A method is proposed for automatically generating a crane lifting path describing the motion of a crane. The method includes: laser scanning a plant to generate one or more point clouds; using the point clouds to identify objects to be lifted by the crane; rasterizing the laser scanned point clouds to generate ditigal data describing the plant and in a format for input to a Graphics Processing Unit (GPU); and iteratively optimizing a crane lifting path, including using the GPU and the digital data to detect collisions between one or more cranes and the plant if the crane follows the crane lifting path.",G06G 7/122; G06F 19/26; G06F 17/50,NANYANG TECHNOLOGICAL UNIVERSITY; PEC LIMITED,"CAI, Yiyu; CAI, Panpan; INDHUMATHI, Chandrasekara; ZHENG, Jianmin; THALMANN, Nadia M; WONG, Peng; LIM, Teng Sam; GONG, Yi","61/888,293 08.10.2013 US",DE-1120140046418; US-15027373; DE-112014004641; CN-201480055801.6
WO2008148211,PCT/CA2008/001088,06.06.2008,WO/2008/148211,11.12.2008,WO,TIME-ORDERED TEMPLATES FOR TEXT-TO-ANIMATION SYSTEM,"There is described a method for converting an input text into an input for an animation generator, the method comprising: receiving the input text; extracting from the text a first set of data representing information related to actions identified in the input text and completing a semantically annotated action template using the first set of data; extracting from the input text a second set of data representing information related to a description of every participant involved in the actions and completing a semantically annotated description template using the second set of data; and transmitting the semantically annotated action template and the semantically annotated description template to the animation generator.",G06F 17/27; G06F 19/00; G06T 13/00; G06T 15/70,"XTRANORMAL TECHNOLOGIE INC.; BHERER, Hans","BHERER, Hans","60/924,945 06.06.2007 US",JP-2010510625; EP-2008757220
WO2004090752,PCT/IB2004/001068,02.04.2004,WO/2004/090752,21.10.2004,WO,METHOD AND APPARATUS FOR SUMMARIZING A MUSIC VIDEO USING CONTENT ANALYSIS,"A method and apparatus are provided for segmenting and summarizing a music video (507) in a multimedia stream (505) using content analysis. A music video (507) is segmented in a multimedia stream (505) by evaluating a plurality of content features that are related to the multimedia stream. The plurality of content features includes at least two of a face presence feature; a videotext presence feature; a color histogram feature; an audio feature, a camera cut feature; and an analysis of key words obtained from a transcript of the at least one music video. The plurality of content features are processed using a pattern recognition engine (1000), such as a Bayesian Belief Network, or one or more video segmentation rules (1115) to identify the music video (507) in the multimedia stream (505). A chorus is detected in at least one music video (507) using a transcript (T) of the music video (507) based upon a repetition of words in the transcript. The extracted chorus may be employed for the automatic generation of a summary of the music video (507).",G06F 17/30,"KONINKLIJKE PHILIPS ELECTRONICS N.V.; AGNIHOTRI, Lalitha; DIMITROVA, Nevenka; KENDER, John","AGNIHOTRI, Lalitha; DIMITROVA, Nevenka; KENDER, John","60/462,777 14.04.2003 US; 60/509,800 08.10.2003 US",JP-2006506452; IN-2633/CHENP/2005; CN-200480009909.8; KR-1020057019649; US-10552829; EP-2004725441
WO2019203795,PCT/US2018/027812,16.04.2018,WO/2019/203795,24.10.2019,WO,AUTOMATICALLY DETERMINING LANGUAGE FOR SPEECH RECOGNITION OF SPOKEN UTTERANCE RECEIVED VIA AN AUTOMATED ASSISTANT INTERFACE,"Implementations relate to determining a language for speech recognition of a spoken utterance, received via an automated assistant interface, for interacting with an automated assistant. Implementations can enable multilingual interaction with the automated assistant, without necessitating a user explicitly designate a language to be utilized for each interaction. Selection of a speech recognition model for a particular language can based on one or more interaction characteristics exhibited during a dialog session between a user and an automated assistant. Such interaction characteristics can include anticipated user input types, anticipated user input durations, a duration for monitoring for a user response, and/or an actual duration of a provided user response.",G10L 15/22; G10L 15/00; G10L 15/26; G10L 15/183,GOOGLE LLC,"CHAO, Pu-sen; CASADO, Diego Melendo; MORENO, Ignacio Lopez",,SG-11201912053X; EP-2018722336
WO2019045750,PCT/US2017/049860,01.09.2017,WO/2019/045750,07.03.2019,WO,DETAILED EYE SHAPE MODEL FOR ROBUST BIOMETRIC APPLICATIONS,"Systems and methods for robust biometric applications using a detailed eye shape model are described. In one aspect, after receiving an eye image of an eye (e.g., from an eye- tracking camera on an augmented reality display device), an eye shape (e.g., upper or lower eyelids, an iris, or a pupil) of the eye in the eye image is calculated using cascaded shape regression methods. Eye features related to the estimated eye shape can then be determined and used in biometric applications, such as gaze estimation or biometric identification or authentication.",G06F 3/01; G06F 21/32; G06K 9/52; G06K 9/46; G06T 3/40,"MAGIC LEAP, INC.","AMAYEH, Gholamreza; CHEN, Jixu",,IL-272360; AU-2017430168
WO2017070127,PCT/US2016/057562,19.10.2016,WO/2017/070127,27.04.2017,WO,METHODS AND SYSTEMS FOR CLEARING SENSOR OCCLUSIONS,A method is provided that involves identifying a target region of an environment of an autonomous vehicle to be monitored for presence of moving objects. The method also involves operating a first sensor to obtain a scan of a portion of the environment that includes at least a portion of the target region and an intermediate region between the autonomous vehicle and the target region. The method also involves determining whether a second sensor has a sufficiently clear view of the target region based on at least the scan obtained by the first sensor. The method also involves operating the second sensor to monitor the target region for presence of moving objects based on at least a determination that the second sensor has a sufficiently clear view of the target region. Also provided is an autonomous vehicle configured to perform the method.,G05D 1/00; G05D 1/02; G05D 1/12,WAYMO LLC,"LUDERS, Brandon, Douglas; CAMPBELL, Tim; FAIRFIELD, Nathaniel","14/919,667 21.10.2015 US",KR-1020197038945; SG-11201802882T; CA-3002537; KR-1020187013901; EP-2016858081; AU-2016341202; JP-2018518604
WO2019104109,PCT/US2018/062167,21.11.2018,WO/2019/104109,31.05.2019,WO,COMPUTER IMAGING PRE-PROCESSING FOR AUTOMATED MEDICATION DISPENSING ANALYSIS,"A method includes capturing a first image of medication held by a receptacle. The method includes creating a second image based on the first image. The method includes determining a first subset of pixels of the second image that are more likely to correspond to the receptacle. The method includes processing the second image along a first axis by, for each point: defining a line perpendicularly intersecting the first axis at the point and counting how many of the pixels located along the line are in the first subset. The method includes determining first and second local maxima of the counts. The method includes estimating positions of first and second edges of the receptacle based on positions of the local maxima. The method includes defining an ellipse based on the first and second edges and excluding areas of the first image outside the defined ellipse from further processing.",A61J 7/02; A61J 3/06; A61J 1/03; G06K 9/20; G06K 9/62; G06T 5/50; G06T 7/10; G06T 7/12; G06T 7/136,"EXPRESS SCRIPTS STRATEGIC DEVELOPMENT, INC.","MARKSON, Christopher, R.; SHAH, Pritesh, J.; LEHMUTH, Christopher, G.","16/190,548 14.11.2018 US; 62/590,255 22.11.2017 US",
WO2019048922,PCT/IB2018/000994,07.09.2018,WO/2019/048922,14.03.2019,WO,PARALLEL NEURAL PROCESSOR FOR ARTIFICIAL INTELLIGENCE,"Systems and/or devices for efficient and intuitive methods for implementing artificial neural networks specifically designed for parallel AI processing are provided herein. In various implementations, the disclosed systems, devices, and methods complement or replace conventional systems, devices, and methods for parallel neural processing that (a) greatly reduce neural processing time necessary to process more complex problem sets; (b) implement neuroplasticity necessary for self-learning; and (c) introduce the concept and application of implicit memory, in addition to explicit memory, necessary to imbue an element of intuition. With these properties, implementations of the disclosed invention make it possible to emulate human consciousness or awareness.",G06K 9/62; G06N 3/04,"SETH, Rohit","SETH, Rohit","62/556,312 08.09.2017 US; 16/124,104 06.09.2018 US",AU-2018330840
WO2019175534,PCT/GB2019/050515,25.02.2019,WO/2019/175534,19.09.2019,WO,ENHANCED VEHICLE TRACKING,"The present invention relates to a method and system for accurately predicting future trajectories of observed objects in dense and ever-changing city environments. More particularly, the present invention relates to substantially continuously tracking and estimating the future movements of an observed object. As an example, an observed object may be a moving vehicle, for example along a path or road. Aspects and/or embodiments seek to provide an end to end method and system for substantially continuously tracking and predicting future movements of a newly observed object, such as a vehicle, using motion prior data extracted from map data.",G06K 9/00,BLUE VISION LABS UK LIMITED,"ONDRUSKA, Peter; PLATINSKY, Lukas; SURENDRAN, Suraj Mannakunnel",1804195.4 15.03.2018 GB; 1810797.9 29.06.2018 GB,
EP236491134,17766637,13.03.2017,3432229,23.01.2019,EP,ABILITY IMPARTING DATA GENERATION DEVICE,"Provided is a mechanism for increasing the efficiency of development work for adding a new ability to an apparatus. In addition, a mechanism that makes it possible to easily add a new ability to another apparatus is provided. A target apparatus has an architecture that is modeled as an ability acquisition model including an ability unit that executes an ability, a data input unit that is an interface for input of the ability unit, and a data output unit that is an interface for output of the ability unit. an ability-providing-data generation apparatus generates ability providing data including ability setting data for setting a function in the ability unit in the ability acquisition model of the target apparatus, input setting data for setting a function in the data input unit in the ability acquisition model of the target apparatus, and output 
setting data for setting a function in the data output unit in the ability acquisition model of the target apparatus.",G06N 99/00; G06F 8/71; G06F 9/445; G06N 3/063; G06N 3/08; G06N 3/10,OMRON TATEISI ELECTRONICS CO,ANDO TANICHI,2016049329 14.03.2016 JP; 2017010041 13.03.2017 JP,
WO2019005100,PCT/US2017/040264,30.06.2017,WO/2019/005100,03.01.2019,WO,METHOD AND SYSTEM TO DISPLAY CONTENT FROM A PDF DOCUMENT ON A SMALL SCREEN,"Roughly described, a viewer application is provided for viewing a PDF document on a screen of a device such as a mobile phone or tablet. The viewer application may operate in page mode or in text mode. In page mode the original layout is maintained, and navigation assistance is provided by use of a navigation pane indicating the contents of the screen with a superimposed frame. Display of the navigation pane is controllable by the user. In page mode a selected text column is scrolled and zoomed to optimize reading. In text mode, text is extracted from the document and reformatted in text view to be continuous and complete in correct reading order, and images and advertising may be excluded. The user may toggle between page mode and text mode. The viewer application is implemented in software to by executed by a processor on the device.",G09G 5/373; G06F 17/21; G06F 3/0481; G06F 3/0482,"ISSUU, INC.","THOMSEN, Søren, D.; MADSEN, Anders, H.; VIND, Søren; SEJERSEN, Mads; ASSENTORP, Peter",,
EP206658831,16172863,03.06.2016,3252769,06.12.2017,EP,ADDING BACKGROUND SOUND TO SPEECH-CONTAINING AUDIO DATA,"An editing method (40) facilitates the task of adding background sound to speech-containing audio data so as to augment the listening experience. The editing method (40) is executed by a processor in a computing device and comprises obtaining (41) characterization data that characterizes time segments in the audio data by at least one of topic and sentiment; deriving (43), for a respective time segment in the audio data and based on the characterization data, a desired property of a background sound to be added to the audio data in the respective time segment, and providing (44) the desired property for the respective time segment so as to enable the audio data to be combined, within the respective time segment, with background sound having the desired property. The background sound may be selected and added automatically or by manual user intervention.",G10L 25/48; G09B 5/06; G10L 15/18; G10L 15/26; G10L 17/26; G10L 25/87; G11B 27/031,SONY MOBILE COMMUNICATIONS INC,THÖRN OLA,16172863 03.06.2016 EP,
EP281666231,18763609,20.02.2018,3594858,15.01.2020,EP,INFORMATION PROCESSING DEVICE,"The present feature relates to an information processing device with which it is possible to reduce the computational load and the number of parameters of a neural network. A binary computation layer constitutes a layer of the neural network, performs binary computation using two values out of layer input data, and outputs the computation result of the two values as layer output data. The present feature can be applied to a neural network.",G06N 3/04,SONY CORP,FUKUI AKIRA,2017041812 06.03.2017 JP; 2018005828 20.02.2018 JP,
WO2014194160,PCT/US2014/040140,30.05.2014,WO/2014/194160,04.12.2014,WO,AUTOMATED PERCENTAGE OF BREAST DENSITY MEASUREMENTS FOR FULL FIELD DIGITAL MAMMOGRAPHY,"An automated percentage of breast density measure (PDa ) that analyzes signal dependent noise (SDN) based on a wavelet expansion using full field digital mammography (FFDM). A matched case-control dataset is used with images acquired from a specific direct x-ray capture FFDM system. PDa is applied to the raw and clinical display representation images. Transforming (pixel mapping) of the raw image to another representation (raw-transformed) is performed using differential evolution optimization and investigated the influence of lowering the native spatial resolution of the image by a one-half. When controlling for body mass index, the quartile specific ORs for the associations of PDa with breast cancer varied with representation and resolution. PDa is a valid automated breast density measurement for a specific FFDM technology and compares well against PD (operator-assisted or the standard) when applied to either the raw-transformed or clinical display images from this FFDM technology.",G06K 9/00,"H. LEE MOFFITT CANCER CENTER AND RESEARCH INSTITUTE, INC.; MAYO FOUNDATION FOR MEDICAL EDUCATION AND RESEARCH","HEINE, John, J.; SELLERS, Thomas, A.; VACHON, Celine, M.; FOWLER, Erin, E.","61/828,780 30.05.2013 US; 61/828,971 30.05.2013 US",US-14893603
WO1996036935,PCT/US1996/007207,17.05.1996,WO/1996/036935,21.11.1996,WO,COMPRESSION EMBEDDING,"A method of embedding auxiliary information into the digital representation of host data created by a lossy compression technique. The method applies to data comnpressed with algorithms based on series expansion, quantization to a finite number of symbols, and entropy coding, such as a photograph, television signal, personal information, medical imaging data, and digital audio. Lossy compression methods represent the original data as sequences of integer indices having redundancy and uncertainty of value by one unit, allowing indices which are adjacent in value to be manipulated to encode auxiliary data.",G06T 9/00; H04N 1/32; H04N 7/26; H04N 7/30; H04N 7/50; H04N 7/52,"THE REGENTS OF THE UNIVERSITY OF CALIFORNIA; SANDFORD, Maxwell, T., II; HANDEl, Theodore, G.; BRADLEY, Jonathan, N.","SANDFORD, Maxwell, T., II; HANDEl, Theodore, G.; BRADLEY, Jonathan, N.","08/442,592 17.05.1995 US",
WO2012113732,PCT/EP2012/052798,17.02.2012,WO/2012/113732,30.08.2012,WO,DETERMINING MODEL PARAMETERS BASED ON TRANSFORMING A MODEL OF AN OBJECT,"Apparatus for determining model parameters, the apparatus comprising an object model transformer, a region comparator, and a model parameter determiner. The object model transformer is configured to receive an object model of a known object and to transform the object model based on a set of model parameters from a first frame of reference to a second frame of reference. The object model transformer is further configured to determine as result of this transformation a transformed object model comprising at least one region, the at least one region being associated to an object region of the object. The region comparator is configured to receive the transformed object model and an image depicting the object, to determine for a selected region of the transformed object model a region-related similarity measure representative of a similarity between the selected region and an image section of the image associated to the selected region via a transformation-dependent mapping. The model parameter determiner is configured to determine an updated set of model parameters on the basis of the region-related similarity measure and an optimization scheme.",G06T 7/00,"FRAUNHOFER-GESELLSCHAFT ZUR FOERDERUNG DER ANGEWANDTEN FORSCHUNG E.V.; ERNST, Andreas; RUF, Tobias; LAUTENSCHLAGER, Felix; PAPST, Anton; THIELECKE, Jörn; KÜBLBECK, Christian","ERNST, Andreas; RUF, Tobias; LAUTENSCHLAGER, Felix; PAPST, Anton; THIELECKE, Jörn; KÜBLBECK, Christian","61/446,668 25.02.2011 US",EP-2012704804; JP-2013554855
WO2011116514,PCT/CN2010/071205,23.03.2010,WO/2011/116514,29.09.2011,WO,METHOD AND APPARATUS FOR DETERMINING A USER AGE RANGE,"An approach is provided for determining a user age range. An age estimator causes, at least in part, acquisition of voice data. Next, the age estimator calculates a first set of probability values, wherein each of the probability values represents a probability that the voice data is in a respective one of a plurality of predefined age ranges, and the predefined age ranges are segments of a lifespan. Then, the age estimator derives a second set of probability values by applying a correlation matrix to the first set of probability values, wherein the correlation matrix associates the first set of probability values with probabilities of the voice data matching individual ages over the lifespan. Then, the age estimator, for each of the predefined age ranges, calculates a sum of the probabilities in the second set of probability values corresponding to the individual ages within the respective predefined age ranges. Further, the age estimator determines the predefined age range to associate with the voice data based, at least in part, on the calculated sums of the probabilities.",G06F 19/00,"NOKIA CORPORATION; CAO, Yang; DING, Feng; TIAN, Jilei","CAO, Yang; DING, Feng; TIAN, Jilei",,IN-8873/CHENP/2012; CN-201080065696.6; US-13634811; EP-2010848176
WO2017213814,PCT/US2017/033152,17.05.2017,WO/2017/213814,14.12.2017,WO,SENSOR TRAJECTORY PLANNING FOR A VEHICLE,"An example system includes a vehicle and a sensor connected to the vehicle. The system, may receive a predetermined path for the vehicle to follow. The system may also receive a plurality of objectives, associated with a corresponding set of sensor data, for which to collect sensor data. The system may determine, for each of the plurality of objectives, a portion of the environment for the sensor to scan to acquire the corresponding set of sensor data. The system may determine, based on the portion of the environment determined for each of the plurality of objectives, a sensor trajectory through which to move the sensor. The system may cause the sensor to move through the determined sensor trajectory and scan portions of the environment corresponding to the determined sensor trajectory as the vehicle moves along the predetermined path.",G05D 1/02,X DEVELOPMENT LLC,"RUSSELL, Jared","15/178,120 09.06.2016 US",JP-2018555285; EP-2017810687; KR-1020187032217
EP276895893,19169386,16.04.2019,3570219,20.11.2019,EP,"CONTROL SYSTEM, LEARNING DATA CREATION APPARATUS, LEARNING APPARATUS, AND JUDGMENT APPARATUS",,G06N 3/00; G06N 3/04; G06N 3/08,OMRON TATEISI ELECTRONICS CO,ANDO TANICHI,2018092840 14.05.2018 JP,
WO2019140091,PCT/US2019/013054,10.01.2019,WO/2019/140091,18.07.2019,WO,AUTOMATICALLY MONITORING RETAIL PRODUCTS BASED ON CAPTURED IMAGES,"A system for acquiring images of products in a retail store is disclosed. The system may include at least one first housing configured for location on a retail shelving unit, and at least one image capture device included in the at least one first housing and configured relative to the at least one first housing such that an optical axis of the at least one image capture device is directed toward an opposing retail shelving unit when the at least one first housing is fixedly mounted on the retail shelving unit. The system may further include a second housing configured for location on the retail shelving unit separate from the at least one first housing, the second housing may contain at least one processor configured to control the at least one image capture device and also to control a network interface for communicating with a remote server. The system may also include at least one data conduit extending between the at least one first housing and the second housing, the at least one data conduit being configured to enable transfer of control signals from the at least one processor to the at least one image capture device and to enable collection of image data acquired by the at least one image capture device for transmission by the network interface.",G06K 9/00; G06K 9/46; G06K 9/62; G06K 9/68; G06Q 10/08,TRAX TECHNOLOGY SOLUTIONS PTE LTD.,"ADATO, Yair; LISHNER, Itai; COHEN, Daniel, Shimon; EISENSCHTAT, Aviv; POMERANZ, Dolev; MHABARY, Ziv; YANUSHEVSKY, Osnat; MICHAEL, Yotam; ADAR, Yonatan; KUSHNIR, Maria; YASHPE, Dror; DEVIR, Yohai; YUDKIN, Paul; BRONICKI, Youval; DAYAN, Shlomi; PELED, Galit; GOTTLIEB, David, M.; GRUBSHTEIN, Alon; HEMED, Nir","62/615,512 10.01.2018 US; 62/681,718 07.06.2018 US; 62/695,469 09.07.2018 US",
WO2013105108,PCT/IN2012/000733,07.11.2012,WO/2013/105108,18.07.2013,WO,A SYSTEM AND METHOD FOR ENHANCING HUMAN COUNTING BY FUSING RESULTS OF HUMAN DETECTION MODALITIES,The present invention discloses a method and a system for enhancing accuracy of human counting in at least one frame of a captured image in a real-time in a predefined area. The present invention detects human in one or more frames by using at least one human detection modality for obtaining the characteristic result of the captured image. The invention further calculates an activity probability associated with each human detection modality. The characteristic results and the activity probability are selectively integrated by using a fusion technique for enhancing the accuracy of the human count and for selecting the most accurate human detection modality. The human is then performed based on the selection of the most accurate human detection modality.,G06K 9/60,TATA CONSULTANCY SERVICES LIMITED,"GUPTA, Rohit; SINHA, Aniruddha; PAL, Arpan; CHAKRAVORTY, Aritra",3167/MUM/2011  09.11.2011 IN,JP-2014540637; US-14357272; EP-2012865389
WO1996012239,PCT/US1995/013573,12.10.1995,WO/1996/012239,25.04.1996,WO,METHOD AND APPARATUS FOR CREATING A SEARCHABLE DIGITAL VIDEO LIBRARY AND A SYSTEM AND METHOD OF USING SUCH A LIBRARY,An apparatus and method of creating a digital library (36) from audio data (18) and video images (20). The method includes the steps of transcribing the audio data and marking the transcribed audio data with a first set of time-stamps (27) and indexing (38) the transcribed audio data. The method also includes the steps of digitizing the video data and marking the digitized video data with a second set of time-stamps (31) related to the first set of time-stamps and segmenting the digitized video data into paragraphs (33) according to a set of rules (37). The steps of storing the indexed audio data and the digitized video data with their respective sets of time-stamps is also provided. The method also includes the step of passing the transcribed audio data through a natural language interpreter (29) before indexing the transcribed audio data (30). A method and apparatus for searching the digital library is disclosed.,G06F 17/30,CARNEGIE MELLON UNIVERSITY,"MAULDIN, Michael, L.; SMITH, Michael, A.; STEVENS, Scott, M.; WACTLAR, Howard, D.; CHRISTEL, Michael, G.; REDDY, D., Raj; KANADE, Takeo","08/324,076 14.10.1994 US",CA-2202539; MX-PA/a/1997/002705; EP-1995937573
EP12435426,92104502,16.03.1992,0565738,20.10.1993,EP,System for encoding and decoding data in machine readable graphic form,"A system for representing and recognizing data in machine readable graphic image form in which data to be encoded is entered into the system and a processor encodes the data into a two-dimensional bar code symbol and generates transfer drive signals representative of the symbol. A transferring device such as a printer transfers an image of the two-dimensional bar code symbol onto a carrier such as a card or paper document in response to the transfer drive signals. A recognition device converts the image on the carrier into electrical signals representative of the symbol by scanning the image. A low-level decoder decodes the signals by decoding each scan line into a vector of codeword values corresponding to the codewords in the two-dimensional bar code symbol, assigning a row number to each of the codeword yalues, and then filling in a two-dimensional matrix with the codeword values. A high-level decoder further decodes the codeword values into data which can then be output for processing or use. <IMAGE>",G06K 17/00; G06F 3/00; G06K 19/06; G06K 1/12; H04N 1/32; G06K 7/14; G06K 17/00; G06K 19/06; G09C 5/00; H04N 1/00; H04N 1/32,SYMBOL TECHNOLOGIES INC,PAVLIDIS THEODOSIOS; WANG YAJIUM P; SWARTZ JEROME,46188190 05.01.1990 US; 55002390 09.07.1990 US; 65382291 11.02.1991 US; 85150592 16.03.1992 US,
WO2019012520,PCT/IL2018/050732,05.07.2018,WO/2019/012520,17.01.2019,WO,APPARATUS AND METHODS FOR USE WITH IMAGE-GUIDED SKELETAL PROCEDURES,"Apparatus and methods are described including acquiring 3D image data of a skeletal portion. A computer processor (22) is used to designate a skin-level incision point (235) or a skeletal-portion level entry point within the body of the subject and associate the designated point with the 3D image data. A radiopaque element (258) is positioned on the body of the subject with respect to the skeletal portion and an intraoperative 2D radiographic image is acquired of the skeletal portion, such that the radiopaque element appears in the 2D radiographic image. The computer processor (i) registers the 2D radiographic image to the 3D image data such that the designated point appears in the 2D radiographic image, and (ii) displays a location of the designated point with respect to the radiopaque element on the 2D radiographic image. Other applications are also described.",A61B 34/00; A61B 17/56; A61B 6/00; G06T 7/00; G06T 7/30,VUZE MEDICAL LTD.,"TOLKOWSKY, David; STEINBERG, Alexander; COHEN, Ran","62/530,123 08.07.2017 US; 62/556,436 10.09.2017 US; 62/599,802 18.12.2017 US; 62/641,359 11.03.2018 US",EP-2018831854
WO2019064294,PCT/IL2018/051039,17.09.2018,WO/2019/064294,04.04.2019,WO,SLE DISEASE MANAGEMENT,"Assays, kits and methods useful in the field of systemic lupus erythematosus (SLE) diagnosis and management for determining and providing SLE treatment adjustment include methods for detecting SLE resolution and for adjusting treatment in a subject hitherto diagnosed as having SLE.",G01N 33/564; G01N 33/68; G16B 25/30; G16B 40/20,IMMUNARRAY LTD.; YEDA RESEARCH AND DEVELOPMENT CO. LTD.,"SOREK, Rachel; JAKOBI-BROOK, Keren; SAFER, Pennina; COHEN, Irun R.","62/564,330 28.09.2017 US",
WO2018164378,PCT/KR2018/001611,06.02.2018,WO/2018/164378,13.09.2018,WO,"ELECTRONIC APPARATUS FOR COMPRESSING LANGUAGE MODEL, ELECTRONIC APPARATUS FOR PROVIDING RECOMMENDATION WORD AND OPERATION METHODS THEREOF","An electronic apparatus for compressing a language model is provided, the electronic apparatus including a storage configured to store a language model which includes an embedding matrix and a softmax matrix generated by a recurrent neural network (RNN) training based on basic data including a plurality of sentences, and a processor configured to convert the embedding matrix into a product of a first projection matrix and a shared matrix, the product of the first projection matrix and the shared matrix having a same size as a size of the embedding matrix, and to convert a transposed matrix of the softmax matrix into a product of a second projection matrix and the shared matrix, the product of the second projection matrix and the shared matrix having a same size as a size of the transposed matrix of the softmax matrix, and to update elements of the first projection matrix, the second projection matrix and the shared matrix by performing the RNN training with respect to the first projection matrix, the second projection matrix and the shared matrix based on the basic data.",G06F 17/16; G06F 17/30; G06N 3/08,"SAMSUNG ELECTRONICS CO., LTD.","YU, Seung-hak; KULKARNI, Nilesh; SONG, Hee-jun; LEE, Hae-jun","62/469,089 09.03.2017 US; 10-2017-0147922 08.11.2017 KR",EP-2018763492; CN-201880005774.X
WO2020058570,PCT/FI2019/050658,13.09.2019,WO/2020/058570,26.03.2020,WO,AN APPARATUS AND A METHOD FOR ARTIFICIAL INTELLIGENCE,The embodiments relate to a method comprising receiving visual data in a file format compatible with ISO base media file format; processing the visual data to detect one or more content elements; storing the detected one or more content elements and information on the used process as a metadata; and including the metadata to the media file in association with the visual data. The embodiments also relate to a technical equipment for implementing the method.,H04N 21/84; H04N 21/2343; G06F 16/783; G06N 3/02; G06K 9/00,NOKIA TECHNOLOGIES OY,"AKSU, Emre; HANNUKSELA, Miska; MÄKINEN, Jonne Juhani; HIPPELÄINEN, Juha-Pekka",20185781 20.09.2018 FI,
WO2017213932,PCT/US2017/035261,31.05.2017,WO/2017/213932,14.12.2017,WO,SYSTEM AND METHOD FOR DISTRIBUTED INTELLIGENT PATTERN RECOGNITION,"Embodiments include a system, method, and computer program product for distributed intelligent pattern recognition. Embodiments include a cooperative multi-agent detection system that enables an array of disjunctive devices (e.g., cameras, sensors) to selectively cooperate to identify objects of interest over time and space, and to contribute an object of interest to a shared deep learning pattern recognition system based on a bidirectional feedback mechanism. Embodiments provide updated information and/or algorithms to one or more agencies for local system learning and pattern updating recognition models. Each of the multiple agencies may in turn, update devices (e.g., cameras, sensors) coupled to the local machine learning and pattern recognition models.",G06K 9/00,"MUTUALINK, INC.","MAZZARELLA, Joseph, R.; WENGROVITZ, Michael, S.","62/346,062 06.06.2016 US; 15/491,257 19.04.2017 US",EP-2017739728; CA-3026712; KR-1020197000313; AU-2017277846
WO2007056532,PCT/US2006/043680,08.11.2006,WO/2007/056532,18.05.2007,WO,METHODS AND APPARATUS FOR MERGING MEDIA CONTENT,"A computerized method and apparatus is disclosed for merging content segments from a number of discrete media content (e.g., audio/video podcasts) in preparation for playback. The method and apparatus obtain metadata corresponding to a plurality of discrete media content. The metadata identifies the content segments and their corresponding timing information, such that the metadata of at least one of the plurality of discrete media content is derived using one or more media processing techniques. A number of the content segments are selected to be merged for playback using the timing information from the metadata. The merged media content can be implemented as a playlist identifying the content segments to be merged for playback. The merged media content can also be generated by extracting the content segments to be merged for playback from each of the media files/streams and then merging the extracted segments into one or more merged media files/streams.",G06F 17/30,"EVERYZING, INC.; HOUH, Henry; STERN, Jeffrey, Nathan","HOUH, Henry; STERN, Jeffrey, Nathan","60/736,124 09.11.2005 US; 11/395,732 31.03.2006 US; 11/446,543 02.06.2006 US",EP-6837263
WO2019183202,PCT/US2019/023133,20.03.2019,WO/2019/183202,26.09.2019,WO,ACCELERATED QUANTIZED MULTIPLY-AND-ADD OPERATIONS,"Disclosed herein are techniques for accelerating convolution operations or other matrix multiplications in applications such as neural network. A computer-implemented method includes receiving low-precision inputs for a convolution operation from a storage device, and subtracting a low-precision value representing a high-precision zero value from the low-precision inputs to generate difference values, where the low-precision inputs are asymmetrically quantized from high-precision inputs. The method also includes performing multiplication and summation operations on the difference values to generate a sum of products, and generating a high-precision output by scaling the sum of products with a scaling factor.",G06N 3/063; G06N 3/04,"AMAZON TECHNOLOGIES, INC.","VANTREASE, Dana Michelle; HUANG, Randy; DIAMANT, Ron; ELMER, Thomas; AMIRINENI, Sundeep","15/934,681 23.03.2018 US",
WO2016195890,PCT/US2016/030589,03.05.2016,WO/2016/195890,08.12.2016,WO,DIALOGUE SYSTEM WITH AUDIO WATERMARK,"Described is an apparatus which comprises: first logic to generate a first audio data and to embed the first audio data with a watermark to generate an embedded data; a speaker to output the embedded data as a first audible audio; a microphone to receive a second audible audio; and second logic to check the second audible audio for the watermark, and if the second audible audio has the watermark embedded in the first audio data, generate a first message, else generate a second message.",G10L 19/018; G10L 15/26; G10L 21/02,INTEL CORPORATION,"PHIELIPP, Mariano J.","14/731,315 04.06.2015 US",
WO2019067204,PCT/US2018/050458,11.09.2018,WO/2019/067204,04.04.2019,WO,SYSTEM AND METHOD FOR IDENTIFYING PHYSICAL OBJECTS,"One embodiment can provide a system for authenticating an object. During operation, the system configures an environment surrounding the object according to one or more target environmental factors, captures at least a first image of the object while the object is exposed to the target environmental factors, and determines Fan authenticity of the object based on the captured first image and the target environmental factors.",G06F 21/00; G06K 9/00; G06T 1/00,ALIBABA GROUP HOLDING LIMITED,"WANG, Yan; FENG, Xuetao","201710911613.4 29.09.2017 CN; 16/126,597 10.09.2018 US",
WO2016036623,PCT/US2015/047629,31.08.2015,WO/2016/036623,10.03.2016,WO,FACET RECOMMENDATIONS FROM SENTIMENT-BEARING CONTENT,"A ""Facet Recommender"" creates conversational recommendations for facets of particular conversational topics, and optionally for things associated with those facets, from consumer reviews or other social media content. The Facet Recommender applies a machine-learned facet model and optional sentiment-model, to identify facets associated with spans or segments of the content and to determine neutral, positive, or negative consumer sentiment associated with those facets and, optionally, things associated with those facets. These facets are selected by the facet model from a list or set of manually defined or machine-learned facets for particular conversational topic types. The Facet Recommender then generates new conversational utterances (i.e., short neutral, positive or negative suggestions) about particular facets based on the sentiments associated with those facets. In various implementations, utterances are fit to one or more predefined conversational frameworks. Further, responses or suggestions provided as utterances may be personalized to individual users.",G06F 17/27; G06F 17/28; G06Q 30/00; G06F 3/048; H04M 1/72; G06F 17/30,"MICROSOFT TECHNOLOGY LICENSING, LLC","DOLAN, Bill; MITCHELL, Margaret; BANERJEE, Jay; CHOUDHURY, Pallavi; HENDRICH, Susan; MASON, Rebecca; OWENS, Ron; REDDY, Mouni; SONG, Yaxiao; TOUTANOVA, Kristina; XU, Liang; YIN, Xuetao","14/475,450 02.09.2014 US",EP-2015760050; CN-201580047303.1
WO2014181331,PCT/IL2014/050409,07.05.2014,WO/2014/181331,13.11.2014,WO,EFFICIENT IMAGE MATCHING FOR LARGE SETS OF IMAGES,"A system and methods to detect similarities between images is disclosed herein. The system and methods allow comparisons between a query image and one or more catalog images in a manner that is resilient to scanning, scaling, rotating, cropping and other distortions of the query image. The system includes an image processing module that identifies principle features of a catalog image and constructs a feature vector using one or more of the principle features. For each principle feature, a vector made up of measures of the surrounding features is added as patch information to the principle feature. The resulting vector is multi-dimensional. For example, the system may construct a k-dimensional vector that describes intensities of points in a region adjacent to each principle feature that is identified in a catalog image.",G06K 9/62,PICSCOUT (ISRAEL) LTD.,"LAVI, Uri; GOZ, Eli; BEGELMAN, Gregory","226219 07.05.2013 IL; 14/141,295 26.12.2013 US",CN-201480038965.8; EP-2014794756
WO2014028855,PCT/US2013/055381,16.08.2013,WO/2014/028855,20.02.2014,WO,APPARATUS AND METHODS FOR SPIKING NEURON NETWORK LEARNING,"Event-based updates in artificial neuron networks may be implemented. An internal event may be defined in order to update incoming connections of a neuron. The internal event may be triggered by an external signal and/or internally by the neuron. A reinforcement signal may be used to trigger an internal event of a neuron in order to perform synaptic updates without necessitating post-synaptic response. An external event may be defined in order to deliver response of the neuron to desired targets. The external and internal events may be combined into a composite event configured to effectuate connection update and spike delivery to post-synaptic target. The scope of the internal event may comprise the respective neuron and does not extend to other neurons of the network. Conversely, the scope of the external event may extend to other neurons of the network via, for example, post-synaptic spike delivery.",G06N 3/02,QUALCOMM TECHNOLOGIES INC.,"SINYAVSKIY, Oleg; IZHIKEVICH, Eugene","13/588,774 17.08.2012 US",JP-2015527661; EP-2013829473
WO2020039198,PCT/GB2019/052354,21.08.2019,WO/2020/039198,27.02.2020,WO,MACHINE LEARNING OPTIMISATION METHOD,"Embodiments provide a computer implemented method for use in self-optimising a complex time varying system, the method being performed in relation to a first model of the system. The first model is a weighted graph based model of the system. The graph may,optionally, be fully connected but constrained.The model comprises: a plurality of nodes, each node representing an element of the system and being associated with one or more data records indicative of the properties of the element of the system; a plurality of links connecting pairs of nodes, each link indicating the relationship between a pair of nodes. The method comprises: performing a query to determine at least one property of the system by performing a traversal along a path from a start node to an end node of the first graph via one or more intermediate nodes according to the links, which are stored in a common data storage structure, the traversal comprising collecting one or more data records associated with each of at least the start and end node and determining the property of the system based on the collected data records.",G06N 3/12; G06N 5/02,SHAPECAST LIMITED,"BARNETT, William",1813561.6 21.08.2018 GB,
WO2010075311,PCT/US2009/069061,21.12.2009,WO/2010/075311,01.07.2010,WO,MULTI-STAGE IMAGE PATTERN RECOGNIZER,"An image-based pattern recognizer and a method and apparatus for making such a pattern recognizer are disclosed. By employing positional coding, the meaning of any feature present in an image can be defined implicitly in space. The pattern recognizer can be a neural network including a plurality of stages of observers. The observers are configured to cooperate to identify the presence of features in the input image and to recognize a pattern in the input image based on the features. Each of the observers includes a plurality of neurons. The input image includes a plurality of units, and each of the observers is configured to generate a separate output set that includes zero or more coordinates of such units.",G06K 9/20; G06T 7/60; G06K 9/48; G06K 9/52,"FIVE APES, INC.; PAQUIER, Williams J. F.","PAQUIER, Williams J. F.","12/344,346 26.12.2008 US",
WO2019152062,PCT/US2018/023132,19.03.2018,WO/2019/152062,08.08.2019,WO,FEEDBACK LOOP FOR IMAGE-BASED RECOGNITION,"Methods, systems, and computer programs are presented for providing a feedback loop to improve object image-based recognition based on transaction data. In one method, instructions are received defining items to be visually recognized by a terminal. For each item, a check is made to determine if item image information is in a global database or if it is a new item. The global database includes item images captured during transactions performed at several terminals. For each item in the global database, item image information is downloaded from the global database. For new items, terminal cameras capture pose images for several poses of the new items, each camera taking an image for each pose. A machine-learning program is trained with the downloaded image information and the pose images, where the machine-learning program performs image-based recognition of the items that are presented at the terminal, based on images captured by the cameras.",G06K 9/00,MASHGIN INC.,"SRIVASTAVA, Abhinai; DHANKHAR, Mukul; LI, Yong; OLSON, Maxwell William","15/883,355 30.01.2018 US",
WO2019225961,PCT/KR2019/006111,22.05.2019,WO/2019/225961,28.11.2019,WO,ELECTRONIC DEVICE FOR OUTPUTTING RESPONSE TO SPEECH INPUT BY USING APPLICATION AND OPERATION METHOD THEREOF,"An artificial intelligence (AI) system is provided. The AI system simulates functions of human brain such as recognition and judgment by utilizing a machine learning algorithm such as deep learning, etc. and an application of the AI system. A method, performed by an electronic device, of outputting a response to a speech input by using an application, includes receiving the speech input, obtaining text corresponding to the speech input by performing speech recognition on the speech input, obtaining metadata for the speech input based on the obtained text, selecting at least one application from among a plurality of applications for outputting the response to the speech input based on the metadata, and outputting the response to the speech input by using the selected at least one application.",G10L 15/22; G10L 15/26,"SAMSUNG ELECTRONICS CO., LTD.","BHARGAVA, Cheenepalli Srirama Krishna; GUPTA, Ankush",201841019106 22.05.2018 IN; 201841019106 30.11.2018 IN; 10-2019-0054521 09.05.2019 KR,
WO2017211814,PCT/EP2017/063694,06.06.2017,WO/2017/211814,14.12.2017,WO,SYSTEM AND METHODS FOR PHOTOPLETHYSMOGRAPHY-BASED PULSE DETECTION SUPPORT DURING INTERRUPTIONS IN CHEST COMPRESSIONS,"An apparatus and method relating to the field of cardiopulmonary resuscitation (CPR) including the processing of a photoplethysmography signal during the CPR protocol procedure to quickly make a determination as to whether or not a spontaneous pulse is present. The user thus obtains rapid information as to whether or not to continue CPR compressions, whether to withold administraton of vasopressors, and optionally, whether or not to continue a defibrillation protocol.",A61B 5/00; A61B 5/024,KONINKLIJKE PHILIPS N.V.,"WIJSHOFF, Ralph, Wilhelm, Christianus, Gemma, Rosa; MÜHLSTEFF, Jens; HAARBURGER, Christoph","62/345,950 06.06.2016 US",
WO2019197021,PCT/EP2018/059130,10.04.2018,WO/2019/197021,17.10.2019,WO,DEVICE AND METHOD FOR INSTANCE-LEVEL SEGMENTATION OF AN IMAGE,"A device and method for performing instance-level semantic segmentation of an image are proposed. Thereby, a class-level semantic segmentation is combined with an instance-level boundary detection, and a modified SLIC algorithm calculates a plurality of superpixels as instance-level segments. The device performs the class-level semantic segmentation of the image to obtain one or more class-level segments, each class-level segment having an object class associated with it, and it performs an instance-level semantic boundary detection on the image to obtain one or more instance-level boundaries and for each instance-level boundary an instance-level center point. The device estimates, for each class-level segment, a number of object instances in the class-level segment based on the number of instance-level center points located in the class-level segment. For each class- level segment having an estimated number of object instances greater than one, the device performs the modified SLIC algorithm based on the one or more instance-level boundaries to obtain a plurality of superpixels as instance-level segments.",G06K 9/46; G06K 9/62,"HUAWEI TECHNOLOGIES CO., LTD.; HALFAOUI, Ibrahim","HALFAOUI, Ibrahim; URFALIOGLU, Onay; BOUZARAA, Fahd",,
EP246633711,18275201,28.12.2018,3505115,03.07.2019,EP,POWERED SURGICAL TOOL WITH PREDEFINED ADJUSTABLE CONTROL ALGORITHM FOR CONTROLLING END EFFECTOR PARAMETER,,A61B 18/00; A61B 17/068; A61B 18/12; A61B 18/14; A61B 34/30; G06F 11/00; G06K 9/00; G06N 3/02; G06N 20/00; G16H 40/00; G16H 40/60; H02H 11/00,ETHICON LLC,SHELTON IV FREDERICK E; HARRIS JASON L,201762611339 28.12.2017 US; 201762611340 28.12.2017 US; 201762611341 28.12.2017 US; 201816182249 06.11.2018 US; 201862640415 08.03.2018 US; 201862640417 08.03.2018 US; 201862650877 30.03.2018 US; 201862650882 30.03.2018 US; 201862650887 30.03.2018 US; 201862650898 30.03.2018 US; 201862659900 19.04.2018 US; 201862692747 30.06.2018 US; 201862692748 30.06.2018 US; 201862692768 30.06.2018 US; 201862729184 10.09.2018 US,
WO2018129850,PCT/CN2017/086530,31.05.2017,WO/2018/129850,19.07.2018,WO,METHOD AND SYSTEM FOR ESTIMATING TIME OF ARRIVAL,"A method and system are provided for determining an estimated time of arrival relating to a target trip. The method includes extracting, by a processor, sample characteristic data relating to a target trip, wherein the sample characteristic data comprises first feature data corresponding to a route relating to the target trip and second feature data corresponding to a link of the route; obtaining a prediction model for estimating time of arrival; and determining, by the processor, an estimated time of arrival (ETA) relating to the target trip based on the prediction model and the sample characteristic data.",G06N 99/00,"BEIJING DIDI INFINITY TECHNOLOGY AND DEVELOPMENT CO., LTD.","WANG, Zheng; FU, Kun",201710016048.5 10.01.2017 CN,CN-201780083059.3; AU-2017317611; GB-1803663.2; JP-2018512392
EP13092330,98108621,12.05.1998,0880126,25.11.1998,EP,Speech-silence discrimination based on unsupervised HMM adaptation,"An unsupervised, discriminative, sentence level, HMM adaptation based on speech-silence classification is presented. Silence and speech regions are determined either using a speech end-pointer or the segmentation obtained from the recognizer in a first pass. The discriminative training procedure using a GPD or any other discriminative training algorithm, employed in conjunction with the HMM-based recognizer, is then used to increase the discrimination between silence and speech. <IMAGE>",G10L 15/06; G10L 11/02; G10L 15/06; G10L 15/14,AT & T CORP,NARAYANAN SHRIKANTH SAMBASIVAN; POTAMIANOS ALEXANDROS; ZELJKOVIC ILIJA,86141397 21.05.1997 US,
WO2019133148,PCT/US2018/060996,14.11.2018,WO/2019/133148,04.07.2019,WO,POWERED SURGICAL TOOL WITH PREDEFINED ADJUSTABLE CONTROL ALGORITHM FOR CONTROLLING END EFFECTOR PARAMETER,"A surgical system is disclosed. The surgical system comprises a surgical instrument comprising an end effector, wherein the end effector is configured to perform an end effector function, and a control circuit configured to control the end effector function and automatically adapt the control of the end effector function over time, and limit the automatic adaptation of the control of the end effector function.",A61B 18/00; G16H 40/60; G06F 11/00; H02H 11/00; G16H 40/00; A61B 17/068; A61B 34/30; G06K 9/00; G06N 3/02; G06N 20/00; A61B 18/14; A61B 18/12,ETHICON LLC,"SHELTON, Frederick, E., IV; HARRIS, Jason, L.","62/650,882 30.03.2018 US; 62/611,341 28.12.2017 US; 62/611,340 28.12.2017 US; 62/640,415 08.03.2018 US; 62/650,898 30.03.2018 US; 62/640,417 08.03.2018 US; 62/650,887 30.03.2018 US; 62/692,747 30.06.2018 US; 62/650,877 30.03.2018 US; 62/659,900 19.04.2018 US; 62/729,184 10.09.2018 US; 16/182,249 06.11.2018 US; 62/692,748 30.06.2018 US; 62/692,768 30.06.2018 US; 62/611,339 28.12.2017 US",
WO2017120551,PCT/US2017/012642,06.01.2017,WO/2017/120551,13.07.2017,WO,CONVEX RELAXION REGRESSION SYSTEMS AND RELATED METHODS,"A computer implemented method for optimizing a function is disclosed. The method may comprise identifying an empirical convex envelope, on the basis of a hyperparameter, that estimates the convex envelope of the function; optimizing the empirical convex envelope; and providing the result of optimizing the empirical convex envelope as an estimate of the optimization of the first function.",G06K 9/18,"REHABILITATION INSTITUTE OF CHICAGO; AZAR, Mohammad G.; DYER, Eva; KORDING, Konrad","AZAR, Mohammad G.; DYER, Eva; KORDING, Konrad","62/276,679 08.01.2016 US",
EP204138067,17162462,23.03.2017,3223195,27.09.2017,EP,"DEVICE, METHOD, AND PROGRAM FOR DETECTING OBJECT","A device that detects an object includes a receiver that receives information about the object detected by a sensor, multiple circuits that detect the object by performing different detection processes, and a control circuit that controls the circuits. The control circuit detects whether the detection circuits are in an abnormal state, based on a change in a state of the circuits, when the control circuit detects that a first circuit of the circuits is in an abnormal state, the control circuit causes the first circuit to stop a detection process being performed by the first circuit and causes one or more circuits, other than the first circuit, to detect the object by causing the one or more circuits to stop performing detection processes performed by the one or more circuits, and to perform detection processes different from the detection processes being performed by the one or more circuits.",G06K 9/00; G06F 11/07,PANASONIC IP CORP AMERICA,TAKAHASHI MASAKI; ISHII YASUNORI; KOZUKA KAZUKI,2016059547 24.03.2016 JP; 2016219460 10.11.2016 JP,
EP250876658,19155341,04.02.2019,3528243,21.08.2019,EP,SYSTEM FOR PROCESSING USER UTTERANCE AND CONTROLLING METHOD THEREOF,,G10L 15/22; G06F 17/27; H04L 12/58,SAMSUNG ELECTRONICS CO LTD,BYUN DOOHO; KIM WOONSOO; UM TAEKWANG; LEE DASOM,20180019610 20.02.2018 KR,
EP205290132,16165420,14.04.2016,3232368,18.10.2017,EP,DETERMINING FACIAL PARAMETERS,"There is provided a device (200, 500) comprising: an input (210, 510) to sequential data (220, 230, 520, 530) associated to a face; a predictor (240, 540) configured to predict facial parameters (241, 541); and a corrector (250, 550) configured to correct the predicted facial parameters (241, 541) on the basis of input data (220, 230, 520, 530), the input data containing geometric measurements (220, 520) and other information (230, 530). A related method and a related computer program are also disclosed.",G06K 9/00,FRAUNHOFER-GESELLSCHAFT ZUR FÖRDERUNG DER ANGEWANDTEN FORSCHUNG E V,SEUSS DOMINIK; HASSAN TEENA CHAKKALAYIL; WOLLENBERG JOHANNES; ERNST ANDREAS; GARBAS JENS-UWE,16165420 14.04.2016 EP,
WO2011023828,PCT/EP2010/062739,31.08.2010,WO/2011/023828,03.03.2011,WO,VEHICLE OR TRAFFIC CONTROL METHOD AND SYSTEM,"The invention relates to a vehicle or traffic control method and to a vehicle or traffic control system. The vehicle or traffic control method comprises the steps: a) estimating actual and/or future behavior of a first traffic participant and of a second traffic participant, respectively, the second traffic participant being different from the first traffic participant, b) estimating a trajectory to be taken by the first traffic participant and/or a trajectory to be taken by the second traffic participant, c) determining risk of collision of the first traffic participant relative to the second traffic participant by calculating information adapted for risk assessment of collision of the first traffic participant relative to the second traffic participant, and d) controlling the behavior of the first traffic participant based on the information provided after step a), step b) and/or step c). In this way a probability value is determined which indicates the plausibility that a vehicle or traffic participant might enter into collision within a certain time horizon in the future.",B60T 7/22; B60W 30/08; G06K 9/00; G08G 1/16,"TOYOTA MOTOR EUROPE NV/SA; INRIA Institut National de Recherche en Informatique et en Automatique; OTHMEZOURI, Gabriel; YANAGIHARA, Hiromichi; SAKAI, Katsuhiro; MAZER, Emmanuel; MEKHNACHA, Kamel; LAUGIER, Christian; TAY MENG KEAT, Christopher","OTHMEZOURI, Gabriel; YANAGIHARA, Hiromichi; SAKAI, Katsuhiro; MAZER, Emmanuel; MEKHNACHA, Kamel; LAUGIER, Christian; TAY MENG KEAT, Christopher",09169060.2 31.08.2009 EP,EP-2010757579; JP-2012527303; US-13390567
WO2010040143,PCT/US2009/059592,05.10.2009,WO/2010/040143,08.04.2010,WO,"SYSTEMS, METHODS, AND MEDIA FOR PERFORMING CLASSIFICATION","Systems, methods, and media that implement a boosted classifier having a plurality of weak hypotheses that produce a classification, each of the plurality of weak hypotheses having at least one weight; receive testing data; receive at least one piece of training data subsequently to receiving the testing data, calculate corrective terms for correcting a sum of weights of correctly classified training data and a sum of weights of incorrectly classified training data, calculate the sum of weights of correctly classified training data and the sum of weights of incorrectly classified training data based on the corrective terms; modify the at least one weight of at least one of the plurality of weak hypotheses in response to the at least one piece of training data based on the sum of weights to produce modified weights, and classify the testing data based on the modified weights to produce a classification.",G06F 15/18,"THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK; PELOSSOF, Raphael, A.; JONES, Michael","PELOSSOF, Raphael, A.; JONES, Michael","61/102,766 03.10.2008 US",
WO2008015571,PCT/IB2007/003047,21.05.2007,WO/2008/015571,07.02.2008,WO,SIMULATION-ASSISTED SEARCH,"A visually-oriented search system guides a search with non-verbal inputs. Instead of specifying discrete attributes (words) as input to a search engine, a user may create a visual model of a desired end result and apply the model as a generalized input from which discrete attributes are extracted for submission to conventional search engines. The search may be enhanced with a simulation of the visually-created query, and the simulation may be transformed into a query suitable for distribution to one or more search engines. The query may be refined using domain-specific rules, vocabulary, expert systems, and the like. Search results may be browsed by a user, or employed to further refine subsequent searches.",G06F 17/30; G06F 17/00; G06F 17/20; G06F 19/00; G06F 3/048; G06Q 30/00; G06T 7/00,"MY VIRTUAL MODEL INC.; GUAY, LOUISE; FARIBAULT, CLAUDE; SAUMIER-FINCH, GREGORY; HAYDOCK, ELIZABETH; ST-ARNAUD, Jean","GUAY, LOUISE; FARIBAULT, CLAUDE; SAUMIER-FINCH, GREGORY; HAYDOCK, ELIZABETH; ST-ARNAUD, Jean","60/747,758 19.05.2006 US; 60/804,952 16.06.2006 US",EP-2007825352; AU-2007280092; CA-2652762; JP-2009511609; KR-1020087030675
WO2018194851,PCT/US2018/026358,06.04.2018,WO/2018/194851,25.10.2018,WO,FLEXIBLE HARDWARE FOR HIGH THROUGHPUT VECTOR DEQUANTIZATION WITH DYNAMIC VECTOR LENGTH AND CODEBOOK SIZE,"The performance of a neural network (NN) and/or deep neural network (DNN) can limited by the number of operations being performed as well as memory data management of a NN/DNN. Using vector quantization of neuron weight values, the processing of data by neurons can be optimize the number of operations as well as memory utilization to enhance the overall performance of a NN/DNN. Operatively, one or more contiguous segments of weight values can be converted into one or more vectors of arbitrary length and each of the one or more vectors can be assigned an index. The generated indexes can be stored in an exemplary vector quantization lookup table and retrieved by exemplary fast weight lookup hardware at run time on the flyas part of an exemplary data processing function of the NN as part of an inline de-quantization operation to obtain needed one or more neuron weight values.",G06N 3/06; G06F 9/50,"MICROSOFT TECHNOLOGY LICENSING, LLC","AMBARDEKAR, Amol Ashok; TOMIC, Aleksandar; MCBRIDE, Chad Balling; PETRE, George; CEDOLA, Kent D.; WALL, Larry Marvin; BOBROV, Boris","62/486,432 17.04.2017 US; 15/881,519 26.01.2018 US",CN-201880025227.8; EP-2018720863
WO2017040520,PCT/US2016/049483,30.08.2016,WO/2017/040520,09.03.2017,WO,MOLECULAR METHODS FOR ASSESSING UROTHELIAL DISEASE,"The present disclosure relates to methods of collecting exosomes and microvesicles (EMV) from urine, isolating corresponding mRNA, and analyzing expression patterns in order to diagnose and treat various urothelial cancers. In particular, various expression patterns are analyzed through a unique diagnostic formula.",C12N 15/10; C12Q 1/68; G01N 33/48,"HITACHI CHEMICAL CO., LTD.; HITACHI CHEMICAL CO. AMERICA, LTD.; CITY OF SAPPORO","MURAKAMI, Taku; YAMAMOTO, Cindy; MITSUHASHI, Masato; HARADA, Hiroshi","62/252,257 06.11.2015 US; 62/212,501 31.08.2015 US; 62/331,241 03.05.2016 US",DE-112016003948; JP-2018530656
EP13035447,96936310,10.10.1996,0852004,08.07.1998,EP,MULTIPLEXED ANALYSIS OF CLINICAL SPECIMENS,"A method for the multiplexed diagnostic and genetic analysis of enzymes, DNA fragments, antibodies, and other biomolecules comprises the steps of constructing an appropriately labeled beadset, exposing the beadset to a clinical sample, and analyzing the combined sample/beadset by flow cytometry is disclosed. Flow cytometric measurements are used to classify, in real-time, beads within an exposed beadset and textual explanations, based on the accumulated data obtained during real-time analysis, are generated for the user. The inventive technology enables the simultaneous, and automated, detection and interpretation of multiple biomolecules or DNA sequences in real-time while also reducing the cost of performing diagnostic and genetic assays.",G01N 15/10; G01N 15/14; G01N 33/50; G01N 33/543,LUMINEX CORP,CHANDLER VAN S; FULTON R JERROLD; CHANDLER MARK B,54081495 11.10.1995 US; 54240195 11.10.1995 US; 9616198 10.10.1996 US,
WO2016170005,PCT/EP2016/058789,20.04.2016,WO/2016/170005,27.10.2016,WO,DETECTION AND IDENTIFICATION OF A HUMAN FROM CHARACTERISTIC SIGNALS,"One or more sensors are configured for detection of characteristics of moving objects and living subjects for human identification or authentication. One or more processors, such as in a system of sensors or that control a sensor, may be configured to process signals from the one or more sensors to identify a person. The processing may include evaluating features from the signals such as breathing rate, respiration depth, degree of movement and heart rate etc. The sensors may be radio frequency non-contact sensors with automated detection control to change detection control parameters based on the identification of living beings, such as to avoid sensor interference.",G01S 7/41; G01S 13/56; G01S 13/88; G01S 13/87; A61B 5/05,RESMED SENSOR TECHNOLOGIES LIMITED,"SHOULDICE, Redmond; DOHENY, Emer; ZAFFARONI, Alberto","62/149,839 20.04.2015 US; 62/207,687 20.08.2015 US",US-15562751; JP-2017554455
WO2019237068,PCT/US2019/036159,07.06.2019,WO/2019/237068,12.12.2019,WO,PROTECTING VEHICLE BUSES FROM CYBER-ATTACKS,"Various approaches are disclosed for protecting vehicle buses from cyber-attacks. Disclosed approaches provide for an embedded system having a hypervisor that provides a virtualized environment supporting any number of guest OSes. The virtualized environment may include a security engine on an internal communication channel between the guest OS and an external vehicle bus of a vehicle to analyze network traffic to protect the guest OS from other guest OSes or other network components, and to protect those network components from the guest OS. Each guest OS may have its own security engine customized for the guest OS to account for what is typical or expected traffic for the guest OS (e.g., using machine learning, anomaly detection, etc.). Also disclosed are approaches for corrupting a message being transmitted on a vehicle bus to prevent devices from acting on the message",H04L 9/00; H04L 29/06; G06F 9/455; G06F 21/53; H04L 12/40; H04L 29/08,NVIDIA CORPORATION,"OVERBY, Mark; DINGLE, Rick; DI MISCIO, Nicola; KANNAN, Varadharajan; ZHANG, Yong; SARACINO, Francesco","62/682,803 08.06.2018 US; 16/435,337 07.06.2019 US",
WO2012015919,PCT/US2011/045532,27.07.2011,WO/2012/015919,02.02.2012,WO,AUTOMATIC MEDIA SHARING VIA SHUTTER CLICK,"A computer-implemented method for automatically sharing media between users is provided. Collections of images are received from different users, where each collection is associated with a particular user and the users may be associated with each other. The collections are grouped into one or more albums based on the content of the images in the collection, where each album is associated with a particular user. The albums from the different users are grouped into one or more event groups based on the content of the albums. The event groups are then shared automatically, without user intervention, between the different users based on their associations with each other and their individual sharing preferences.",G06F 17/30; G06Q 30/00,"GOOGLE INC.; KIYOHARA, Keith, Shoji; BENJAMIN, Henry; DELAYE, Darren; CHEN, Ping, Hsin; HAN, Simon; SMILAK, Kevin; AXE, Brian; NOSHADI, Hyduke; KANITKAR, Kedar; TSANG, Evan","KIYOHARA, Keith, Shoji; BENJAMIN, Henry; DELAYE, Darren; CHEN, Ping, Hsin; HAN, Simon; SMILAK, Kevin; AXE, Brian; NOSHADI, Hyduke; KANITKAR, Kedar; TSANG, Evan","61/368,166 27.07.2010 US; 13/188,879 22.07.2011 US",CN-201180046353.X; JP-2013521938; EP-2011741726; KR-1020137004789
WO2019116099,PCT/IB2018/001557,13.12.2018,WO/2019/116099,20.06.2019,WO,SYSTEMS AND METHODS FOR PREDICTING PEDESTRIAN INTENT,"A system and a method are disclosed for determining intent of a human based on human pose. In some embodiments, a processor obtains a plurality of sequential images from a video feed, and determines respective keypoints corresponding a human in each respective image of the plurality of sequential images. The processor aggregates the respective keypoints for each respective image into a pose of the human and transmits a query to a database to find a template that matches the pose by comparing the pose to a plurality of templates poses that translate candidate poses to intent, each template corresponding to an associated intent. The processor receives a reply message from the database that either indicates an intent of the human based on a matching template, or an inability to locate the matching template, and, in response to the reply message indicating the intent of the human, outputs the intent.",G06K 9/00; G06K 9/62,"HUMANISING AUTONOMY LIMITED; PINDEUS, Maya Audrey Lara; BOSE, Raunaq; NOOTEBOOM, Leslie Cees; BERNSTEIN, Adam Joshua","PINDEUS, Maya Audrey Lara; BOSE, Raunaq; NOOTEBOOM, Leslie Cees; BERNSTEIN, Adam Joshua","62/598,359 13.12.2017 US",
WO2019012719,PCT/JP2018/001695,16.01.2018,WO/2019/012719,17.01.2019,WO,BINARY DESCRIPTOR USING VERTICAL LINES IN THE IMAGE,"Systems and methods for an imaging system having a memory with a historical localization dictionary database having geo-located driving image sequences, such that each reference image is applied to a threshold to produce a binary representation. A sensor to acquire a sequence of input images of a dynamic scene. An encoder to determine, for each input image in the sequence, a histogram of each input image indicating a number of vertical edges at each bin of the input image and to threshold the histogram to produce a binary representation of the input image. A visual odometer to compare the binary representations of each input image and each reference image, by matching an input image against a reference image. Wherein the visual odometer determines a location of the input image based on a match between the input image and the reference image.",G06K 9/00; G06K 9/46,MITSUBISHI ELECTRIC CORPORATION,"LEE, Teng-Yok; RAMALINGAM, Srikumar; TAGUCHI, Yuichi; PATIL, Sonali","15/647,428 12.07.2017 US",JP-2019546267
WO2016130294,PCT/US2016/014144,20.01.2016,WO/2016/130294,18.08.2016,WO,ENVIRONMENTAL SCENE CONDITION DETECTION,"A method of processing data includes receiving, at a computing device, data representative of an image captured by an image sensor. The method also includes determining a first scene clarity score. The method further includes determining whether the first scene clarity score satisfies a threshold, and if the first scene clarity score satisfies the threshold, determining a second scene clarity score based on second data extracted from the data.",G06K 9/00,QUALCOMM INCORPORATED,"ZHONG, Xin; GUO, Feng; XU, Shili; REN, Jianfeng; YANG, Yang; GAO, Dashan; YANG, Ruiduo; BISWAS, Mainak","14/619,354 11.02.2015 US",CA-2973212; KR-1020177022101; JP-2017541922
EP236801783,17795880,11.04.2017,3435293,30.01.2019,EP,"STORAGE CONTROL SYSTEM, SYSTEM, AND PROGRAM","A memory control system includes: an information acquiring unit that acquires information for deciding an emotion of a target object; a secretion information generating unit that generates secretion information indicating a secretion amount of an endocrine substance to influence decision of the emotion of the target object, based on the information acquired by the information acquiring unit; a memory control unit that associates and stores the secretion information and memory information based on the information acquired by the information acquiring unit, when an intensity of the emotion of the target object decided based on the information acquired by the information acquiring unit exceeds a predetermined value; and an information selecting unit that selects memory information to be retrieved by the target object from the memory information that has been stored in association with the secretion information, based on the secretion information.",G06N 3/00; G06N 3/04,COCORO SB CORP,SON MASAYOSHI; TSUTSUI TAKASHI; TOMONAGA KOSUKE; OURA KIYOSHI,2016096836 13.05.2016 JP; 2017014875 11.04.2017 JP,
WO2019068200,PCT/CA2018/051260,05.10.2018,WO/2019/068200,11.04.2019,WO,BRAIN-COMPUTER INTERFACE PLATFORM AND PROCESS FOR CLASSIFICATION OF COVERT SPEECH,"A device and method are provided for real-time classification of covert speech. The device comprises a plurality of sensors for capturing real-time bio-signal data for brain monitoring in response to mental tasks delivered to a user, and a brain computer interface with memory storing instructions to configure a processor to perform a method of real-time classification of covert speech. The method comprises capturing real-time bio-signal data for brain monitoring in response to mental tasks delivered to a user, pre-processing the raw bio-signal data, extracting a vector of features from the raw bio-signal data, selecting features from the vector of features, building classification model to generate classified covert speech data using the selected features, and controlling a display device with visual elements based on the classified covert speech data.",G06K 9/62; A61B 5/04; A61B 5/0476; G06F 3/01; G06F 3/14,HOLLAND BLOORVIEW KIDS REHABILITATION HOSPITAL,"SERESHKEH, Alborz Rezazadeh; CHAU, Thomas Tak Kin","62/569,184 06.10.2017 US; 62/642,180 13.03.2018 US",
WO2005060392,PCT/US2004/024964,30.07.2004,WO/2005/060392,07.07.2005,WO,SYSTEM AND METHOD FOR MEDIA-ENABLED MESSAGING HAVING PUBLISH-AND-SEND FEATURE,"A system and related techniques manage the adding of digital images or other media to email messages using a comparatively straightforward insert-and-send scheme. A user may choose to insert or embed comparatively low-resolution versions of images or other media automatically published to a media server into an email message. The recipient of that media-enabled message may receive and view the email text message along with the lowresolution images in typical fashion using an email or other client. The recipient may choose to view one or more of the embedded images in greater resolution by linking or activating those images, for instance by moving a cursor and clicking into the selected image or other object. Activating the image or other media object from within the email pane may seamlessly transport the user to the media server's Web page to view a larger-resolution version of that image, for instance using a media player. Video, audio and other media may likewise be inserted into messages. The sender may therefore share a variety of images, audio, video or other media with selected recipients without loading the recipient's email or other client with increased download times or storage requirements.",G06F 13/00; G06F 17/00; G06F 19/00; G09G 5/00,MICROSOFT CORPORATION,"KIRN, Kevin, Neil; FRANK, Steven, Gary; NIKIEL, Mark, A.; JOSHI, Tanuja; CODY, Brian, Robert; WEBER, Kurt, Alan","10/728,086 05.12.2003 US",KR-1020057007614; CN-200480001349.1; ZA-200503155; MX-PA/a/2005/007166; JP-2006542554; ZA-2005/03155; EP-2004779891; IN-1848/DELNP/2005; CA-2501853; AU-2004279167
EP279871154,19182560,26.06.2019,3588382,01.01.2020,EP,A DEEP LEARNING METHOD FOR TUMOR CELL SCORING ON CANCER BIOPSIES,,G06K 9/62,DEFINIENS GMBH,KAPIL ANSH; BRIEU NICOLAS,201862690329 26.06.2018 US,
WO2001046842,PCT/US2000/035024,21.12.2000,WO/2001/046842,28.06.2001,WO,COMPUTATIONAL METHOD AND SYSTEM TO PERFORM EMPIRICAL INDUCTION,"The present invention is an improved computational method and system of empirical induction that can be used to arrive at generalized conclusions and make predictions involving longitudinal associations between and among variables and events. Empirical induction is used to gain scientific knowledge, to develop and evaluate treatments and other interventions, and to help make predictions and decisions. The invention, which is distinct from and often complementary to the statistical method, is applied to repeated measures and multiple time-series data and can be used to quantify, discover, analyze, and describe longitudinal associations for individual real and conceptual entities. Major improvements include provisions to define Boolean independent events and Boolean dependent events and to apply analysis parameters such as episode length and episode criterion for both independent and dependent variables, persistence after independent events, and delay and persistence after Boolean independent events.",G06F 19/00; G06N 5/02,"BAGNE, Curtis, A.","BAGNE, Curtis, A.","09/470,956 22.12.1999 US",EP-2000988292; CA-2395743
WO2001014910,PCT/US2000/014903,30.05.2000,WO/2001/014910,01.03.2001,WO,METHOD FOR DEVELOPING A SYSTEM FOR IDENTIFYING THE PRESENCE AND ORIENTATION OF AN OBJECT IN A VEHICLE,"Method for developing a system for determining the occupancy of a seat (1) in a vehicle using a variety of transducers and pattern recognition technologies and techniques that applies to any combination of transducers that provide information about seat occupancy. These include weight sensors (6,7) capacitive sensors, inductive sensors, ultrasonic (12), optical (12), electromagnetic, motion, infrared, and radar among others. A processor coupled to the transducers for receiving the data from the transducers and processing the data to obtain an output indicative of the current occupancy state of the seat. An algorithm is resident in the processor and is created from a plurality of data sets, each representing a different occupancy state of the seat and being formed from data from the transducers while the seat is in that occupancy state. The algorithm produces the output indicative of the current occupancy state of the seat upon inputting a data set representing the current occupancy state of the seat and being formed from data from the transducers. The algorithm may be a neural network (25) or neural fuzzy algorithm generated by an appropriate algorithmgenerating program.",B60R 21/01; G06K 9/00,"AUTOMOTIVE TECHNOLOGIES INTERNATIONAL, INC.","BREED, David, S.; JOHNSON, Wendell, C.; DUVALL, Wilbur, E.; MORIN, Jeffrey, L.; XU, Kunhong; VARGA, Andrew, J.","60/136,163 27.05.1999 US; 09/382,406 24.08.1999 US; 09/474,147 29.12.1999 US",JP-2001519213; SE-01001866; DE-10084638
WO2019018509,PCT/US2018/042661,18.07.2018,WO/2019/018509,24.01.2019,WO,PROCESSING SYSTEM HAVING MACHINE LEARNING ENGINE FOR PROVIDING CUSTOMIZED USER FUNCTIONS,"Systems and apparatuses for generating customized user output are provided. The system may collect sensor data, associated with the user, from a variety of sources. The system may use the sensor data to generate a customized user output. The system may analyze the sensor data, and determine, based on the sensor data and the customized user output, one or more user recommendation outputs. The system may update the customized user output based on additional or subsequent sensor data, and/or based on whether or not the user recommendation output was completed, as determined from subsequent sensor data.",A61B 5/00; G06F 19/00; G06Q 40/08; G06Q 50/00; H04W 4/00,ALLSTATE INSURANCE COMPANY,"SANKOVSKY, Jenny","15/653,641 19.07.2017 US",EP-2018835210
WO2020037308,PCT/US2019/046995,19.08.2019,WO/2020/037308,20.02.2020,WO,PATIENT-SPECIFIC SURGICAL METHOD AND SYSTEM,A method of determining patient-specific implant parameters for an implant used in a surgical procedure is described. A surgical system receives one or more initial transfer functions and one or more preoperative input factors for a patient and generates a surgical plan comprising one or more patient-specific implant parameters based on the one or more initial transfer functions and the one or more preoperative input factors for the patient. The surgical system further receives one or more intraoperative input factors for the patient and updates the one or more patient-specific implant parameters based on the one or more intraoperative input factors for the patient. An implant for the patient is selected based on the one or more updated patient-specific implant parameters.,A61B 5/00; A61B 34/10; A61B 34/30; A61F 2/02; A61F 2/30; G06F 17/50,"SMITH & NEPHEW, INC.; SMITH & NEPHEW PTE. LIMITED; SMITH & NEPHEW ORTHOPAEDICS AG","FARLEY, Daniel; MCGUAN, Shawn; JARAMAZ, Branislav; MCKINNON, Brian W.; NIKOU, Constantinos; DUXBURY, Elizabeth; MARINESCU TANASOCA, Ruxandra C.; LANDON, Ryan; WINEBARGER, Randy C.; BOWERS, William L.","62/719,415 17.08.2018 US",
WO2017147731,PCT/CN2016/074783,29.02.2016,WO/2017/147731,08.09.2017,WO,UAV HARDWARE ARCHITECTURE,"Systems, methods, and devices are provided herein for improving efficiency and operational capabilities of UAVs. In some instances, different types of processing modules may be provided. The different processing modules may be configured to process data differently and/or implement different features for the UAV. In addition, the different processing modules may be coupled to different types of devices and/or sensors. The division of the processing modules may enable improved UAV operations.",G05D 1/10,"SZ DJI TECHNOLOGY CO., LTD.","LIU, Huaiyu; QIU, Hualiang; WU, Jun; ZHOU, Guyue; HUANG, Jinzhu",,
WO2016011433,PCT/US2015/041037,17.07.2015,WO/2016/011433,21.01.2016,WO,WIRELESS POSITIONING SYSTEMS,A time-reversal positioning system includes a storage storing first data representing channel impulse responses derived from probe signals sent from a plurality of positions and second data representing coordinates of the positions. A data processor determines a position of a terminal device based on the stored channel impulse responses and a time-reversed signal determined based on a time-reversed version of a channel impulse response that is estimated based on a channel probing signal sent from the terminal device.,H04L 25/02,"ORIGIN WIRELESS, INC.","CHEN, Yan; LAI, Hung-Quoc Duc; HAN, Yi; CHEN, Chen; WU, Zhung-Han; LIU, K.J. Ray","62/025,795 17.07.2014 US; 62/069,090 27.10.2014 US; 14/605,611 26.01.2015 US; 62/148,019 15.04.2015 US",US-15326112; JP-2017523197; EP-2015821676
WO2019239243,PCT/IB2019/054493,30.05.2019,WO/2019/239243,19.12.2019,WO,TOOL HANDEDNESS DETERMINATION FOR SURGICAL VIDEOS,"Implementations generally relate to determining tool handedness for surgical videos. In some implementations, a method includes receiving at least one image frame of a plurality of image frames. The method further includes detecting one or more objects in the at least one image frame. The method further includes classifying the one or more objects into one or more tool classifications, where the one or more objects are tools. The method further includes determining, for each tool, if the tool is assistive or non-assistive. The method further includes determining, for each tool, a handedness of the tool.",G06K 9/00,SONY CORPORATION,"CHEN, Xiaojing; HUANG, Ko-Kai Albert; LIU, Ming-Chang","16/008,784 14.06.2018 US",
EP13369233,98924477,29.05.1998,1015909,05.07.2000,EP,POSITION DETERMINATION,"In the preferred implementation, the position of an object, for example a studio camera is determined by means of a camera which views several markers disposed about a studio ceiling, the markers being patterned as a series of light and dark rings to encode information in binary form enabling the markers to be identified as the camera moves about the studio. Methods and apparatus of more general applicability are also disclosed.",G01S 17/87; G01S 5/16; G06T 1/00; H04N 5/272; G01S 5/16; G01S 17/42; G01S 17/87; G06T 7/60; H04N 5/222; H04N 5/272,BRITISH BROADCASTING CORP,RUSSELL RICHARD THOMAS; THOMAS GRAHAM ALEXANDER,9711316 30.05.1997 GB; 9711373 02.06.1997 GB; 9801576 29.05.1998 GB,
EP13833941,01111737,15.05.2001,1259069,20.11.2002,EP,"Method for modifying a user interface of a consumer electronic apparatus, corresponding consumer electronic apparatus","According to the invention a user interface (5) of a consumer electronic apparatus is modified, which can be used for example to update a given basic UI functionality or to temporarily implement isolated, dedicated UI sub-domains. For this purpose side information is received comprising side information components for controlling the user interface and validity information defining the validity start and/or end time of the side information components. The side information components and validity information is stored (9) and the user interface is modified (10) by using said stored side information components. The start time and/or end time of the user interface modification is controlled (11) by means of said stored validity information. <IMAGE>",H04N 5/445; G06F 3/048; G10L 15/22; H04N 5/00; H04N 5/445; H04N 7/08; H04N 7/088; H04N 7/16; H04N 7/24,THOMSON BRANDT GMBH,SCHILLER HARALD,01111737 15.05.2001 EP,
WO2019060583,PCT/US2018/052010,20.09.2018,WO/2019/060583,28.03.2019,WO,SYSTEM AND METHOD FOR DETECTING TAILLIGHT SIGNALS OF A VEHICLE,"A system and method for detecting taillight signals of a vehicle using a convolutional neural network. A method includes: receiving images from one or more image-generating devices; generating a frame for each of the images; generating a ground truth including a labeled image with one of the following taillight status conditions for a right or left taillight signal of the vehicle: (1) an invisible right or left taillight signal, (2) a visible but not illuminated right or left taillight signal, and (3) a visible and illuminated right or left taillight signal; creating a first dataset including the labeled images corresponding to the images, the labeled images including one or more of the taillight status conditions of the right or left taillight signal; and creating a second dataset including at least one pair of portions of the images, wherein the at least one pair of portions of the images are in temporal succession.",G06K 9/00; G06K 9/46; B60W 40/02; B60W 30/14,TUSIMPLE,"WANG, Yijie; ZHU, Ligeng; WANG, Panqu; CHEN, Pengfei","15/709,832 20.09.2017 US",
WO2005058018,PCT/US2004/042621,16.12.2004,WO/2005/058018,30.06.2005,WO,SYSTEM AND METHOD FOR PLANT IDENTIFICATION,Methods of compiling a database of images of plant species and the use of the database to identify unknown plant species are described. Images of the apical complexes of the plant are obtained and stored in a database to allow a comparison of the apical complexes with unknown plant species. The invention provides a facile method for the identification of unknown or unidentified plant species.,G06K 9/20; G06F 19/00; C12N 5/02,"AERULEAN PLANT IDENTIFICATION SYSTEMS, INC.; DUNLAP, Susan, C.","DUNLAP, Susan, C.","60/530,359 16.12.2003 US",EP-2004814764; DE-null
EP234474828,17743930,11.01.2017,3410102,05.12.2018,EP,"CRACK INFORMATION DETECTION DEVICE, CRACK INFORMATION DETECTION METHOD, AND CRACK INFORMATION DETECTION PROGRAM","Provided are a crack information detection device, a method of detecting crack information, and a crack information detection program capable of accumulating a manual editing history with respect to an automatically detected damage to improve detection accuracy of a crack. It is assumed that a delete flag ""1"" of a damage vector (C5-2) is recorded in hierarchical structure information by completion of a delete operation with respect to the damage vector (C5-2). In the case, in a case where the number of operations or an operation time required for the completion of the delete operation is equal to or larger than a predetermined threshold value (for example, click ten times or more, drag and drop five times or more, or ten minutes or more from the start to the end of the editing operation), threshold values of an angle ±1 and an angle ±2 are reduced by a predetermined amount (for example, 5°).",G01N 21/88; G06T 7/00,FUJIFILM CORP,KARUBE MIKIHIKO,2016012538 26.01.2016 JP; 2017000671 11.01.2017 JP,
WO2019222833,PCT/CA2019/000078,24.05.2019,WO/2019/222833,28.11.2019,WO,QUANTIFYING MOTOR FUNCTION USING BEG SIGNALS,"A motor control score is automatically generated for a subject based on electroencephalography (EEG) data represented as a plurality of EEG waveforms obtained from a plurality of EEG electrodes. Each waveform is separated into at least one window, containing a portion of the EEG waveform representative of neural activity corresponding to a movement performed by the subject. At least one or more frequency components and/or signal components are determined from the EEG data in the window, and a motor control score is determined based on these components. The frequency components may correspond to event-related desynchronization (ERD) response frequency band and event-related synchronization (ERS) response frequency band. In other embodiments, the frequency components correspond to a phase response and the signal components correspond to a signal power spectrum density of the window, which are provided to a primary neural network model to determine the motor control score.",A61B 5/0476; A61B 5/00; A61B 5/16,HEALTHTECH CONNEX INC.,"D'ARCY, Ryan, Clarke, Newell; ZHANG, Xin; MENON, Carlo; FREHLICK, Zachary; TANNOURI, Pamela","62/675,866 24.05.2018 US; 62/700,416 19.07.2018 US",
WO2019164146,PCT/KR2019/001190,29.01.2019,WO/2019/164146,29.08.2019,WO,SYSTEM FOR PROCESSING USER UTTERANCE AND CONTROLLING METHOD THEREOF,"A system is provided. The system may include a communication interface, at least one processor, and at least one memory. The memory may store instructions that, when executed, cause the processor to provide an ASR module and a plurality of NLU modules, and further cause the processor to receive first voice data including a first user utterance, to process the first voice data using the ASR module to generate first text data, based on the first user utterance, to process the first text data using a first NLU module to provide a first intent and one or more items associated with the first intent, to provide a first response based on the first intent and the one or more items, and to provide at least part of the first intent and the one or more items to at least part of one other NLU module.",G10L 15/04; G10L 15/18; G10L 15/26; G10L 13/08,"SAMSUNG ELECTRONICS CO., LTD.","BYUN, Dooho; KIM, Woonsoo; UM, Taekwang; KIM, Hyunkyung; PARK, Joohee; YEO, Jaeyung",10-2018-0021845 23.02.2018 KR,
EP96169781,12797126,12.03.2012,2689576,29.01.2014,EP,AUTONOMOUS DETECTION OF CHEMICAL PLUMES,"Systems and methods for autonomously detecting a chemical plume are described. In a method for autonomously detecting a chemical plume, a plurality of images are obtained from a detection camera at least at a wavelength of light selected to be absorbed or emitted by a chemical species. The plurality of images is analyzed to identify changes in a deterministic feature, changes in a statistical feature, or both, between sequential images. A chemical plume is recognized based, at least in part, on the changes.",G08B 21/14; G06T 7/20,EXXONMOBIL UPSTREAM RES CO,CHEBEN JOSEPH M; ZENG YOUSHENG; MORRIS JON; RUAN YANHUA,201161467816 25.03.2011 US; 201161509909 20.07.2011 US; 2012028788 12.03.2012 US,
WO2009143133,PCT/US2009/044489,19.05.2009,WO/2009/143133,26.11.2009,WO,COMPOSITIONS AND METHODS TO PROTECT CELLS BY BLOCKING ENTRY OF PATHOGEN PROTEINS,"Pathogenic effector proteins which include one or more RxLR, dEER, Pexel or analogous motifs are blocked from entry into plant or animal cells by binding one or more of the motifs with a blocking compound which prevents binding of phosphoinositides or other polar lipids to the motifs which is a prerequisite for translocation of the pathogenic effector proteins into the plant or animal cell. The blocking compounds can take a variety of forms including synthetic peptides or the hydrophilic head-groups of phosphoinositides, phosphatidic acids, phospholipids, or sphingolipids. Suitable blocking compounds can be identified by assays demonstrating binding to RxLR, dEER, Pexel or analogous motifs. In addition, pathogenic effector proteins can be identified by analyzing whether they contain structural RxLR motifs using hidden markov modeling.",A61K 31/6615; A61K 38/02; C07K 14/44; G01N 33/68; A61P 31/00,"VIRGINIA TECH INTELLECTUAL PROPERTIES, INC.; KALE, Shiv; TYLER, Brett; DOU, Daolong","KALE, Shiv; TYLER, Brett; DOU, Daolong","61/160,059 13.03.2009 US; 61/128,080 19.05.2008 US",CA-2724569; EP-2009751361
WO2019094721,PCT/US2018/060034,09.11.2018,WO/2019/094721,16.05.2019,WO,METHODS AND SYSTEMS FOR THE INDUSTRIAL INTERNET OF THINGS,"A monitoring system for data collection in an industrial environment includes a data acquisition circuit that determines detection values received from input sensors, a multiplexor (MUX) having a number of inputs corresponding to a subset of the detection values, and a MUX control circuit that provides logical control of the MUX based on the subset of the detection values, including control of a correspondence of MUX inputs to detection values, and adaptive scheduling of select lines. The system includes a data analysis circuit that receives an output from the MUX and determines a component health status, and an analysis response circuit that responds to the component health status.",G05B 19/418; G06N 99/00; H04L 29/08; G06N 5/04,"STRONG FORCE IOT PORTFOLIO 2016, LLC","CELLA, Charles, Howard; DESAI, Mehul; DUFFY, Gerald, William, Jr.; MCGUCKIN, Jeffrey, P.","62/584,099 09.11.2017 US; 15/859,238 29.12.2017 US",
EP45087554,11192213,04.02.2008,2428950,14.03.2012,EP,Presenting supplemental content for digital media using a multimodal application,"The invention relates to a method of rendering to a user data describing where to purchase an item depicted in a portion of digital media being rendered to the user, the method comprising rendering, by a multimodal application, operating on a multimodal device and implemented with a grammar, the portion of the digital media; receiving, by the multimodal application, as a user request a voice utterance from a user; determining, by the multimodal application using an automatic speech recognition (ASR) engine, a recognition result in dependence upon the voice utterance and the grammar, querying a content repository for supplemental content associated with at least a portion of the recognition result, comprising data describing where to purchase the item; and rendering, by the multimodal application, the supplemental content.",G10L 15/26; H04N 5/445; H04N 5/45; H04N 7/173; H04N 21/00; H04N 21/436,NUANCE COMMUNICATIONS INC,CROSS JR CHARLES WILLARD; GOODMAN BRIAN; JANIA FRANK LAWRENCE; SHAW DARREN MARK,08708662 04.02.2008 EP; 67922507 27.02.2007 US,
WO2006107670,PCT/US2006/011402,28.03.2006,WO/2006/107670,12.10.2006,WO,IN VITRO ASSOCIATION STUDIES,Cell and tissue autonomous phenotypes are correlated with genotype information. Correlated genotype information is used to screen individual traits. Methods and systems for correlating cell and tissue autonomous phenotypes to genotype information are provided.,C12Q 1/68; G01N 33/53,"PERLEGEN SCIENCES, INC.; COX, David, R.; MARGUS, Brad, A.","COX, David, R.; MARGUS, Brad, A.","60/667,903 01.04.2005 US; 11/373,837 09.03.2006 US",DE-null; EP-6748852; RU-null
EP276409852,19168869,12.04.2019,3567695,13.11.2019,EP,"AUTONOMOUS MOVING SYSTEM, AUTONOMOUS MOVING BODY, CHARGING DOCK, CONTROL METHOD, AND PROGRAM",,H02J 7/00; B60L 53/30; G05D 1/02,TOYOTA MOTOR CO LTD,ITOZAWA YUTA,2018092141 11.05.2018 JP,
WO2018022301,PCT/US2017/041794,12.07.2017,WO/2018/022301,01.02.2018,WO,"SYSTEMS, METHODS, AND APPARATUSES FOR AGRICULTURAL DATA COLLECTION, ANALYSIS, AND MANAGEMENT VIA A MOBILE DEVICE","A voice-interaction system enables mobile workers to capture measurements, observations and complete inspections using their voice as they move about, leaving one or both hands and eyes free to safely and effectively focus on work tasks. The system has the flexibility to recognize highly specialized vocabulary, prompting for and error-checking utterances that are unique to an industry, company, government agency, user or specific task. This data is saved and formatted to be viewed, listened to, or input into a structured database for further use.",G06F 17/22; G06F 17/30; G06F 17/40; G06F 19/00; G10L 15/06; G10L 15/26,"TEKWEAR, LLC","SWANSEY, John, David; RASA, Bruce, Wayne; BALENTINE, Bruce; KOBRES, Erick, Christian","62/361,311 12.07.2016 US",
WO2018089163,PCT/US2017/056276,12.10.2017,WO/2018/089163,17.05.2018,WO,METHODS AND SYSTEMS OF PERFORMING OBJECT POSE ESTIMATION,"Techniques are provided for estimating a three-dimensional pose of an object. An image including the object can be obtained, and a plurality of two-dimensional (2D) projections of a three-dimensional bounding (3D) box of the object in the image can be determined. The plurality of 2D projections of the 3D bounding box can be determined by applying a trained regressor to the image. The trained regressor is trained to predict twodimensional projections of the 3D bounding box of the object in a plurality of poses, based on a plurality of training images. The three-dimensional pose of the object is estimated using the plurality of 2D projections of the 3D bounding box.",G06T 7/73; G06K 9/46; G06K 9/32,QUALCOMM INCORPORATED,"RAD, Mahdi; OBERWEGER, Markus; LEPETIT, Vincent","62/420,944 11.11.2016 US; 15/495,665 24.04.2017 US",
WO2017034860,PCT/US2016/047177,16.08.2016,WO/2017/034860,02.03.2017,WO,EYELID SHAPE ESTIMATION USING EYE POSE MEASUREMENT,"Systems and methods for eyelid shape estimation are disclosed. In one aspect, after receiving an eye image of an eye (e.g., from an image capture device), an eye pose of the eye in the eye image is determined. From the eye pose, an eyelid shape (of an upper eyelid or a lower eyelid) can be estimated using an eyelid shape mapping model. The eyelid shape mapping model relates the eye pose and the eyelid shape. In another aspect, the eyelid shape mapping model is learned (e.g., using a neural network).",A61B 3/14; G06K 9/00,"MAGIC LEAP, INC.","KAEHLER, Adrian","62/208,519 21.08.2015 US",JP-2018509551; EP-2016839825; AU-2016310451; IL-257485; KR-1020187007935
WO2018212538,PCT/KR2018/005524,15.05.2018,WO/2018/212538,22.11.2018,WO,ELECTRONIC DEVICE AND METHOD OF DETECTING DRIVING EVENT OF VEHICLE,"Provided are a method and an electronic device for determining whether a driving event of a vehicle occurs, based on a location of an object in a plurality of frames, using a plurality of trained models.",G06T 7/70; G06T 5/30; G06N 3/08; G06N 99/00; B60W 30/08; B60W 50/14,"SAMSUNG ELECTRONICS CO., LTD.","JANG, Seo-woo; BAN, Dae-hyun; PARK, Un-kyu","62/506,712 16.05.2017 US; 10-2018-0049405 27.04.2018 KR",EP-2018801907
WO2016140795,PCT/US2016/018193,17.02.2016,WO/2016/140795,09.09.2016,WO,METHOD AND SYSTEM FOR CONTENT MANAGEMENT OF VIDEO IMAGES OF ANATOMICAL REGIONS,"Various aspects of a method and system for content management of video images of anatomical regions are disclosed herein. In accordance with an embodiment of the disclosure, the method is implementable in a content processing device, which is communicatively coupled to an image-capturing device. The method includes identification of one or more non-tissue regions in a video image of an anatomical region. The video image is generated by the image-capturing device. Thereafter, one or more content identifiers are determined for the identified one or more non-tissue regions. Further, each of the determined one or more content identifiers are associated with a corresponding non-tissue region that corresponds to the identified one or more non-tissue regions.",A61B 5/00,SONY CORPORATION,"LIU, Ming-Chang; CHOU, Chen-Rui; HUANG, Ko-Kai Albert","62/126,758 02.03.2015 US; 14/816,250 03.08.2015 US",KR-1020177024654; JP-2017546126; KR-1020197025761
EP15084994,07766873,05.07.2007,2044591,08.04.2009,EP,AUTOMATIC GENERATION OF VIDEO FROM STRUCTURED CONTENT,"Apparatus for generation of playable media from structured data, comprises a structured data reading unit for reading in of content of a first structure, a transformation unit for transforming said content into a second structure, said transformation comprising incorporating media play instructions, and a rendering unit for rendering content from the second structure using said media play instructions to generate playable media from the content.",G11B 27/031; G06F 17/30; G11B 27/32; H04N 7/173; H04N 7/24,SUNDAYSKY LTD,AXEN YANIV; WELLER SHMUEL,2007000843 05.07.2007 IL; 80662606 06.07.2006 US,
EP290833377,19803375,07.05.2019,3624020,18.03.2020,EP,COMPUTING METHOD AND RELATED PRODUCT,The present disclosure provides a computation method and product thereof. The computation method adopts a fusion method to perform machine learning computations. Technical effects of the present disclosure include fewer computations and less power consumption.,G06N 3/063,SHANGHAI CAMBRICON INFORMATION TECH CO LTD,LIU SHAOLI; LUO YUZHE; MENG XIAOFU; ZHANG XISHAN; SONG XINKAI,201810479540 18.05.2018 CN; 201811040961 06.09.2018 CN; 201811041573 06.09.2018 CN; 201811592249 25.12.2018 CN; 2019085844 07.05.2019 CN,
WO2005050485,PCT/US2004/036317,29.10.2004,WO/2005/050485,02.06.2005,WO,USING TEMPORAL CONTEXT FOR IMAGE CLASSIFICATIONS,A method improving scene classification of a sequence of digital images comprising the steps of: (a) providing a sequence of images captured in temporal succession; (b) classifying each of the images individually based on information contained in the image alone to generate a first image classification; and (c) imposing a pre-determined temporal context model on the sequence of images to generate a final image classification for each image in the sequence.,G06F 17/30,"EASTMAN KODAK COMPANY; LUO, Jiebo; BOUTELL, Matthew Richard","LUO, Jiebo; BOUTELL, Matthew Richard","10/712,181 13.11.2003 US",AU-2004292166
EP13473417,99917409,12.04.1999,1072014,31.01.2001,EP,FACE RECOGNITION FROM VIDEO IMAGES,"The present invention is embodied in an apparatus, and related method, for detecting and recognizing an object in an image frame. The object may be, for example, a head having particular facial characteristics. The object detection process uses robust and computationally efficient techniques. The object identification and recognition process uses an image processing technique based on model graphs and bunch graphs that efficiently represent image features as jets. The jets are composed of wavelet transforms and are processed at nodes or landmark locations on an image corresponding to readily identifiable features. The system of the invention is particularly advantageous for recognizing a person over a wide variety of pose angles.",G06T 1/00; G06K 9/00; G06T 7/00; G06T 7/20; H04N 13/00,NEVENGINEERING INC,MAURER THOMAS; ELAGIN EGOR VALERIEVICH; NOCERA LUCIANO PASQUALE AGOSTI; STEFFENS JOHANNES BERNHARD; NEVEN HARTMUT,20619598 04.12.1998 US; 8161598 13.04.1998 US; 9907935 12.04.1999 US,
WO2020023429,PCT/US2019/042899,23.07.2019,WO/2020/023429,30.01.2020,WO,PRE-OPERATIVE ASSESSMENT AND INVENTORY MANAGEMENT SYSTEM,"A system of generating a pre-operative assessment of a patient includes an assessment system configured to communicate with client electronic devices. The system receives patient information pertaining to a patient, uses the patient information to access one or more medical images associated with the patient, performs one or more image processing techniques on the one or more medical images to identify measurements pertaining to an internal bodily structure of the patient, identifies one or more implant components for the patient, determines whether the one or more implant components are currently stocked, in response to determining that the one or more implant components are not currently stocked, automatically generates and placing an order for the one or more implant components that are not stocked, generates a pre operative assessment for the patient, and causes the assessment to be displayed on a display device of a client electronic device.",G16H 30/40; G16H 10/60; G16H 20/40; A61B 5/00; A61B 5/0402; A61B 5/0488; A61B 5/055; A61B 6/03,"WARSAW ORTHOPEDIC, INC.","BENSON, Nicholas M.; BALLARD, Rodney R.","16/043,986 24.07.2018 US",
EP289840097,19196127,09.09.2019,3620971,11.03.2020,EP,METHOD AND APPARATUS FOR GENERATING A PASSENGER-BASED DRIVING PROFILE,"An approach is provided for generating a passenger-based driving profile. The approach involves collecting vehicle sensor data of a vehicle carrying a user as a passenger. The vehicle sensor data indicates at least one driving behavior of the vehicle. The approach also involves collecting user sensor data, user input data, or a combination thereof indicating a reaction of the user to the at least one driving behavior. The approach further involves including or excluding the at least one driving behavior in a passenger profile for the user based on the reaction of the user.",G06K 9/00; B60W 40/09,HERE GLOBAL BV,BEAUREPAIRE JEROME; RINCOVER AARON,201816126871 10.09.2018 US,
WO2004044823,PCT/US2003/035554,06.11.2003,WO/2004/044823,27.05.2004,WO,CLUSTERING APPEARANCES OF OBJECTS UNDER VARYING ILLUMINATION CONDITIONS,"[0060] Taking a set of unlabeled images of a collection of objects acquired under différent imaging conditions, and decomposing the set into disjoint subsets corresponding to individual objects requires clustering. Appearance-based methods for clustering a set of images (101c) of 3-D objects acquired under varying illumination conditions (100a) can be based on the concept of illumination cones. A clustering problem is equivalent to fmding convex polyhedral eones (301c) in the high-dimensional image space. To efficiently determine the conic structures hidden in the image data, the concept of conic affinity can be used which measures the likelihood of a pair of images belonging to the saine underlying polyhedral cone. Other algorithme can be based on affinity measure based on image gradient comparisons operating directly on die image gradients by comparing the magnitudes and orientations of the image gradient.",G06K 9/62,"HONDA MOTOR CO., LTD.; YANG, Ming-Hsuan; HO, Jeffrey","YANG, Ming-Hsuan; HO, Jeffrey","60/425,213 07.11.2002 US; 60/478,219 12.06.2003 US",JP-2005507111; EP-2003811253
EP131694690,14185449,18.09.2014,2851808,25.03.2015,EP,Hybrid natural language processor,"Methods and a natural language processor for processing a natural language query are provided. The processor includes a classifier, a rule-based pre-processor, a rule-based post-processor, a named entity recognizer, and an output module. The method involves receiving a text representation of the natural language query, pre-processing the text representation, applying a classification statistical model to the text representation when pre-processing fails, applying a post-processing rule, and performing name entity recognition.",G06F 17/27; G06F 17/30; G06N 99/00,MALUUBA INC,SULEMAN KAHEER; PETRESCU ADRIAN; PANTONY JOSHUA; HSU WILSON; BROOKE JULIAN,201361879831 19.09.2013 US,
EP232545692,18162628,19.03.2018,3396532,31.10.2018,EP,DYNAMIC PRECISION FOR NEURAL NETWORK COMPUTE OPERATIONS,"In an example, an apparatus comprises a compute engine comprising a high precision component and a low precision component; and logic, at least partially including hardware logic, to receive instructions in the compute engine; select at least one of the high precision component or the low precision component to execute the instructions; and apply a gate to at least one of the high precision component or the low precision component to execute the instructions. Other embodiments are also disclosed and claimed.",G06F 9/30; G06F 1/32; G06F 15/78; G06T 15/00,INTEL CORP,SINHA KAMAL; VEMBU BALAJI; NURVITADHI ERIKO; GALOPPO VON BORRIES NICOLAS C; BARIK RAJKISHORE; LIN TSUNG-HAN; RAY JOYDEEP; TANG PING T; STRICKLAND MICHAEL S; CHEN XIAOMING; YAO ANBANG; SHPEISMAN TATIANA; APPU ABHISHEK R; KOKER ALTUG; AKHBARI FARSHAD; SRINIVASA NARAYAN; CHEN FENG; KIM DUKHWAN; SATISH NADATHUR RAJAGOPALAN; WEAST JOHN C; MACPHERSON MIKE B; HURD LINDA L; RANGANATHAN VASANTH; JAHAGIRDAR SANJEEV S,201715495020 24.04.2017 US,
WO2005098725,PCT/EP2005/003682,07.04.2005,WO/2005/098725,20.10.2005,WO,USE OF EXPERT SYSTEM DRIVEN CLINICAL ALGORITHMS IN CNS CLINICAL TRIALS,,G06F 19/00,"B & B BEHEER NV; BUNTINX, Erik","BUNTINX, Erik","60/560,290 07.04.2004 US",DE-null
WO2017030915,PCT/US2016/046636,11.08.2016,WO/2017/030915,23.02.2017,WO,SYSTEMS AND METHODS OF REGISTRATION FOR IMAGE-GUIDED SURGERY,"A method of registering sets of anatomical data for use during a surgical procedure is provided herein. The method may include segmenting a set of first modality image data representing a model of one or more passageways within a patient and generating a first set of points based on the segmented set of first modality image data representing the model of the one or more passageways. The method may further include determining a set of matches between a second set of points and the first set of points, wherein the second set of points is obtained by a second modality and discarding a subset of the set of matches based on a first heuristic to generate a modified set of matches. The second set of points may then be moved relative to the first set of points based on the modified set of matches.",A61B 1/005; A61B 1/04; A61B 1/00; A61B 5/00,"INTUITIVE SURGICAL OPERATIONS, INC.","DONHOWE, Caitlin Q.; ZHAO, Tao; DUINDAM, Vincent; SOPER, Timothy D.","62/205,433 14.08.2015 US",US-15752166; EP-2016837556
WO2007137047,PCT/US2007/068992,15.05.2007,WO/2007/137047,29.11.2007,WO,MODELING THE NEOCORTEX,"A processor architecture for a learning machine is presented which uses a massive array of processing elements having local, recurrent connections to form global associations between functions defined on manifolds. Associations between these functions provide the basis for learning cause-and-effect relationships involving vision, audition, tactile sensation and kinetic motion. Two arbitrary images hold each other in place in a manifold association processor and form the basis of short-term memory.",G06F 17/00; G06N 5/02,"GREER, Douglas, S.","GREER, Douglas, S.","60/801,026 16.05.2006 US; 60/862,038 18.10.2006 US",GB-0818549.8
WO2011017393,PCT/US2010/044343,04.08.2010,WO/2011/017393,10.02.2011,WO,SYSTEM AND METHOD FOR OBJECT EXTRACTION,"Systems and methods for extracting an image of a physical object constructed of for example bricks are presented. The method and system may detect boundaries and edges of a background using an edge detection operator, perform a perspective transformation calculation to compute a corrected virtual grid that is substantially aligned with the physical object's image, locate a color calibration palette in the digital image and extract color value information for pixels of the color calibration palette, and discern bricks as part of the physical object's image, the discernment being based in part on a determination of the brick's color compared to the color palette and the background color, the discerned bricks forming the extracted image. A computer readable medium may include instructions causing a system to extract an image of a physical object constructed of bricks according to the method.",G06K 9/00,"EYECUE VISION TECHNOLOGIES LTD.; HOROVITZ, Ronen; KAFTORY, Ran","HOROVITZ, Ronen; KAFTORY, Ran","61/231,216 04.08.2009 US",KR-1020127005725; US-13201512; JP-2012523722; CN-201080044689.8; EP-2010807071
WO2019040213,PCT/US2018/043128,20.07.2018,WO/2019/040213,28.02.2019,WO,ADAPTIVE REAL-TIME DETECTION AND EXAMINATION NETWORK (ARDEN),"An adaptive real-time detection and examination network that employs deep learning to detect and recognize objects in a stream of pixilated two- dimensional digital images. The network provides the images from an image source as pixilated image frames to a CNN having an input layer and output layer, where the CNN identifies and classifies the objects in the image. The network also provides metadata relating to the image source and its location, and provides the object classification data and the metadata to an RNN that identifies motion and relative velocity of the classified objects in the images. The network combines the object classification data from the CNN and the motion data from the RNN, and correlates the combined data to define boundary boxes around each of the classified objects and an indicator of relative velocity and direction of movement of the classified objects, which can be displayed on the display device.",G06K 9/62; G06K 9/46; G06K 9/00,NORTHROP GRUMMAN SYSTEMS CORPORATION,"WANG, Victor, Y.; CALCOTE, Kevin, A.","15/683,483 22.08.2017 US",
WO1987003411,PCT/US1986/002552,26.11.1986,WO/1987/003411,04.06.1987,WO,PATTERN ENCODING SYSTEM,"A massively parallel neural network architecture, called a masking field, is characterized through systematic computer simulations. A masking field is a multiple scale, self-similar, automatically gain-controlled cooperative-competitive feedback network F2. Network F2 receives input patterns from an adaptive filter F1 ← F2 that is activated by a prior processing level F1 and behaves like a content-addressable memory. It activates compressed recognition codes that are predictive with respect to the activation patterns flickering across, and competitively inhibits, or masks, codes which are unpredictive with respect to the F1 patterns. In particular, a masking field can simultaneously detect multiple groupings within its input patterns and assign activation weights to the codes for these groupings which are predictive with respect to the contextual information embedded within the patterns and the prior learning of the system. A masking field automatically rescales its sensitivity as the overall size of an input pattern changes, yet also remains sensitive to the microstructure within each input pattern. In this way, masking field more strongly activates a code for the whole F1 pattern than for its salient parts, yet amplifies the code for a pattern part when it becomes a pattern whole in a new input context. A masking field can also be primed by inputs from F1: it can activate codes which represent predictions of how the F1 pattern may envolve in the subsequent time interval. Network F2 also exhibits an adaptive sharpening property: repetition of a familiar F1 pattern can tune the adaptive filter to elicit a more focal spatial activation of its F2 recognition code than does an unfamiliar input pattern. The F2 recognition code also becomes less distributed when an input pattern contains more contextual information on which to base an unambiguous prediction of which F1 pattern is being processed. Thus a masking field suggests a solution of the credit assignment problem by embodying a real-time code for the predictive evidence contained within its input patterns. Such capabilities are useful in speech recognition, visual object recognition, and cognitive information processing. An absolutely stable design for a masking field is disclosed through an analysis of the computer simulations. This design suggests how associative mechanisms, cooperative-competitive interactions, and modulatory gating signals can be joined together to regulate the learning of compressed recognition codes.",G06K 9/66; G10L 15/16,THE TRUSTEES OF BOSTON UNIVERSITY,"GROSSBERG, Stephen; COHEN, Michael","802,479 27.11.1985 US; 934,412 24.11.1986 US",EP-1986907225
EP14651172,06011895,09.06.2006,1731097,13.12.2006,EP,"Activity recognition apparatus, method and program","There is provided an activity recognition apparatus for detecting an activity of a subject. The apparatus includes: a sensor unit (10) including a plurality of linear motion sensors configured to detect linear motions and a plurality of rotational motion sensors, the linear motions being orthogonal to each other, the rotational motions being orthogonal to each other; and a computational unit (20) configured to receive and process signals from the sensors included in the sensor unit so as to detect an activity of the subject. The sensor unit (10) is directly or indirectly supported by the subject with an arbitrary orientation with respect to the subject. The computational unit (20) performs a calculation that uses the signals from both linear motion sensors and rotational motion sensors to determine the activity of the subject independent of the orientation of the sensor unit.",A61B 5/11; A61B 5/103,SONY CORP,CLARKSON BRIAN,2005169507 09.06.2005 JP,
WO2008143941,PCT/US2008/006245,14.05.2008,WO/2008/143941,27.11.2008,WO,COMPUTATIONAL USER-HEALTH TESTING,"Methods, apparatuses, computer program products, devices and systems are described that carry out obtaining user-health data; selecting at least one user-health test function at least partly based on the user-health data; and applying the at least one user-health test function to at least one interaction between at least one user and at least one device-implemented application whose primary function is different from symptom detection.",G06Q 50/00; A61B 5/22,"SEARETE LLC; JUNG, Edward K.Y.; LEUTHARDT, Eric C.; LEVIEN, Royce A.; LORD, Robert W.; MALAMUD, Mark A.","JUNG, Edward K.Y.; LEUTHARDT, Eric C.; LEVIEN, Royce A.; LORD, Robert W.; MALAMUD, Mark A.","11/804,304 15.05.2007 US; 11/807,220 24.05.2007 US; 11/811,865 11.06.2007 US",
WO2018143669,PCT/KR2018/001340,31.01.2018,WO/2018/143669,09.08.2018,WO,METHOD AND ELECTRONIC DEVICE FOR PROVIDING HEALTH CONTENT,"An electronic device includes a display, a processor, a communication circuit establishing communication with a server, and a memory storing a specified application. The memory stores an instruction that, when executed, causes the processor to output an execution screen of the specified application to the display, in response to a launching of the specified application, to analyze a correlation between a specified health parameter and content included in the execution screen, to generate a specified query message depending on the analysis result, to transmit the query message to the server, to receive a response content of the query message from the server, and to output the response content to at least part of the execution screen.",G06Q 50/22; G06Q 50/10; G06F 17/30,"SAMSUNG ELECTRONICS CO., LTD.","LEE, Mi Sun; KANG, Jae Hyeon; ROH, Byoung Tack; PANG, Jeong Hyun; JEON, Yong Joon; CHOI, Bo Kun",10-2017-0014363 01.02.2017 KR,EP-2018748649; CN-201880009713.0
WO2019059906,PCT/US2017/052525,20.09.2017,WO/2019/059906,28.03.2019,WO,"APPARATUSES, METHODS, AND SYSTEMS FOR THERMO-MECHANICAL PROTECTION OF ELECTRONICS INCLUDING COMPUTER COMPONENTS AND SENSORS","Embodiments include apparatuses, systems and methods for a computer device with a casing and a substance in the casing substantially surrounding a computer component in the casing. In embodiments, the computer device may be a command and control computer, such as for example, an autonomous or semi-autonomous vehicle. In embodiments, the substance may be an electrically isolative and shear-thickening fluid to provide thermo-mechanical protection to a computer component. In the described embodiments, the substance may dampen mechanical shock or vibrational impact on the processor and the memory. The shear-thickening gel may further be thermally conductive in embodiments. In the embodiments, the casing may be substantially filled with the substance and the substance is to conduct heat away from the processor and the memory toward an outer edge of the casing. Other embodiments may also be described and claimed.",G06F 1/20; H05K 7/20; G05D 1/02,INTEL CORPORATION,"MORADI, Ali; PETRINI, Joseph B.; SCHROEDER, Michael A.; DEVANSENATHIPATHY, Shankar; HATALKAR, Atul N.",,
WO2019033838,PCT/CN2018/090386,08.06.2018,WO/2019/033838,21.02.2019,WO,METHOD AND SYSTEM FOR HEADING DETERMINATION,"A method and system for determining a heading of a vehicle. The method may include receiving, from a mobile computing device, a request for determining the heading of the vehicle. The method may also include retrieving, at least in response to the request, sensor data generated by a magnetometer of the mobile computing device within one or more first time slots, and obtaining a classifier trained to determine a predicted heading of the vehicle. The method may further include, for the sensor data of each of the one or more first time slots, obtaining a feature vector by extracting features from the sensor data, and determining, based on the obtained feature vector, a predicted heading by inputting the feature vector into the classifier. The method may also include determining the heading of the vehicle based on the obtained one or more predicted headings.",G06K 9/62,"BEIJING DIDI INFINITY TECHNOLOGY AND DEVELOPMENT CO., LTD.","XU, Hailiang; ZHAO, Renyu",201710707761.4 17.08.2017 CN,
WO2017212486,PCT/IL2017/050635,06.06.2017,WO/2017/212486,14.12.2017,WO,A SYSTEM AND METHOD OF ANALYZING AND AUTHENTICATING SCENARIOS AND ACTIONS THAT ARE TAKING PLACE IN A PLANT OR A FACTORY,"The present invention discloses a system and a method for analyzing and authenticating scenarios and actions that are taking place in a plant or a factory. Said analysis comprising the steps of: monitoring a plurality of data streams, originating from a plurality of independent sources within the plant. Said sources including at least part of production machines, machine sub-units, and independent indicators and sensors within the plant. • correlating between two or more monitored data streams, each relating to a specific action occurring within the plant, but originating from different data sources, or are of different data types; • analyzing said data stream correlations; and • obtaining specific characteristics that indicate the occurrence of specific actions within the plant.",G05B 19/048; G05B 23/00; G05B 23/02; H04L 12/24; H04L 12/26; G06Q 50/00; G06F 13/00,HALO DIGITAL LTD,"KRAUZ, Achiel","62/346,681 07.06.2016 US",EP-2017809845; JP-2019516741
WO2019217430,PCT/US2019/031131,07.05.2019,WO/2019/217430,14.11.2019,WO,CARDIAC INFORMATION PROCESSING SYSTEM,"Provided herein are cardiac information processing systems comprising multiple subsystems for performing a procedure and producing procedure data, and a processing module. The multiple subsystems comprise: a mapping subsystem comprising at least one mapping catheter; an imaging subsystem comprising at least one imaging device; and a treatment subsystem comprising at least one treatment device. The processing module receives the procedure data, the processing module comprising at least one processor and at least one algorithm. The at least one algorithm is configured to perform an assessment of the procedure data and produce evaluation data based on the assessment. Methods of processing cardiac information are also provided.",A61B 8/12; A61B 5/042; A61B 18/12; A61B 18/14; A61B 34/20,"ACUTUS MEDICAL, INC.","CHOU, Derrick Ren-yu; CORVI, Timothy J.; BURGESS, Vince; PARIKH, Paras; WERNETH, Randell L.; BEATTY, Graydon Ernest; ANGEL, Nathan; SCHARF, Christoph; DANG, Lam; FLAHERTY, R. Maxwell; FLAHERTY, J. Christopher","62/668,659 08.05.2018 US; 62/811,735 28.02.2019 US",
WO2020010526,PCT/CN2018/095181,10.07.2018,WO/2020/010526,16.01.2020,WO,SYSTEMS AND METHODS FOR DETERMINING A MARKETING STRATEGY FOR AN ONLINE TO OFFLINE SERVICE,"Systems and methods for determining a marketing strategy for an online to offline service are provided. A method may include: obtaining a plurality of historical vectors, determining a first value function according to a first reinforcement learning algorithm based on the plurality of historical vectors, determining a first value under a state of a driver to provide the online to offline service based on the first value function and the plurality of historical vectors, and obtaining a first regression model by training an initial model, wherein the plurality of historical vectors are inputs of the initial model, and the first value under the state is a label of the initial model.",G06Q 30/02; G06F 17/50,"BEIJING DIDI INFINITY TECHNOLOGY AND DEVELOPMENT CO., LTD.","LUO, Wenjuan",,
WO2014018799,PCT/US2013/052135,25.07.2013,WO/2014/018799,30.01.2014,WO,SYSTEMS AND METHODS FOR ARTIFICIAL INTELLIGENCE SCRIPT MODIFICATION,"Systems and methods for modifying content for interactive synthetic characters are provided. In some embodiments, a traversable script for an interactive synthetic character may be modified based on a set of analytics relating to the use of the interactive synthetic character. These uses may include words spoken by the user, language spoken, user demographics, length of interactions, visually detected objects, current environmental conditions, or location. The traversable script may include a set of conversation rules that include actions to be performed by the interactive synthetic character. The actions can include, for example, producing audible or textual speech, performing one or more animations, playing one or more sound effects, retrieving data from one or more data sources, and the like. The traversable script can be modified, customized, or improved based on the feedback from the use of the character by a plurality of users. The modifications may happen automatically or be reviewed by a content creator using a graphical user interface.",G06F 17/00,"TOYTALK, INC.","REDDY, Martin; JACOB, Oren, M.; PODESTA, Robert, G.","13/558,239 25.07.2012 US",
WO2019133715,PCT/US2018/067680,27.12.2018,WO/2019/133715,04.07.2019,WO,SYSTEM AND METHOD FOR ARTIFICIAL INTELLIGENCE DRIVEN AUTOMATED COMPANION,"The present teaching relates to method, system, medium, and implementations for an automated dialogue companion. Multimodal input data associated with a user engaged in a dialogue of a certain topic in a dialogue scene are first received and used to extract features representing a state of the user and relevant information associated with the dialogue scene. A current state of the dialogue characterizing the context of the dialogue is generated based on the state of the user and the relevant information associated with the dialogue scene. A response communication for the user is determined based on a dialogue tree corresponding to the dialogue of the certain topic, the current state of the dialogue, and utilities learned based on historic dialogue data and the current state of the dialogue.",G10L 15/22; G06T 13/40; G06F 17/28,"DMAI, INC.","SHUKLA, Nishant; FANG, Rui; LIU, Changsong","62/612,145 29.12.2017 US",
WO2002086864,PCT/US2002/011987,15.04.2002,WO/2002/086864,31.10.2002,WO,SYSTEM AND METHOD FOR ADAPTIVE LANGUAGE UNDERSTANDING BY COMPUTERS,"A system and method are described for adaptive language understanding multimodal language acquisition in human-computer interaction. Words, phrases, sentences, production rules (syntactic information) as well as their corresponding meanings (semantic information) are stored. New words, phrases, sentences, production rules and their corresponding meanings can be acquired through interaction with users, using different input modalities, such as, speech, taping, pointing, drawing and image capturing. This system therefore acquires language through a natural language and multimodal interaction with users. New language knowledge is acquired in two ways. First, by acquiring new linguistic units, i.e. words or phrases and their corresponding semantics, and second by aquiring new sentences or language rules and their corresponding computer actions. The system represents an adaptive spoken interface capable of interpeting the user's spoken commands and sensory inputs and of learning new linguistic concepts and production rules. Such a system and the underlying method can not only be used to build adptive interactive compputer interfaces and operating systems, expert systems and computer games.",G06F 17/27; G10L 15/18; G10L 15/22,"RUTGERS, THE STATE UNIVERSITY OF NEW JERSEY","DUSAN, Sorin, V.; FLANAGAN, James, L.","60/284,188 18.04.2001 US; 60/295,878 05.06.2001 US",JP-null
WO2019177373,PCT/KR2019/002913,13.03.2019,WO/2019/177373,19.09.2019,WO,"ELECTRONIC DEVICE FOR CONTROLLING PREDEFINED FUNCTION BASED ON RESPONSE TIME OF EXTERNAL ELECTRONIC DEVICE ON USER INPUT, AND METHOD THEREOF","An electronic device is configured to: receive an input; generate first control data for controlling at least one application among one or more applications using a first recognition method based at least on the input; transmit at least part of the input to external electronic device through a communication module, wherein the external electronic device is configured to generate second control data for controlling the at least one application using a second recognition method based at least on the input; identify a time that passes until the second control data is received after the at least part of the input is transmitted to the external electronic device; control the at least one application using the first control data based on the passing time satisfying a first predefined condition; and control the at least one application using the second control data based on the passing time satisfying a second predefined condition.",G06F 9/44; G06N 3/08,"SAMSUNG ELECTRONICS CO., LTD.","LEE, Dongyul",10-2018-0029786 14.03.2018 KR,
WO1997010587,PCT/US1996/014649,12.09.1996,WO/1997/010587,20.03.1997,WO,SIGNAL CONDITIONED MINIMUM ERROR RATE TRAINING FOR CONTINUOUS SPEECH RECOGNITION,Hierarchical signal bias removal (HSBR) signal conditioning (26) uses a codebook (28) constructed from the set of recognition models (34). HSBR signal conditioning and recognition model training may be based on the same set of recognition model parameters and provides a reduction in recognition errors.,G10L 15/02; G10L 15/14; G10L 15/20,AT & T CORP.,"BUHRKE, Eric, Rolfe; CHOU, Wu; RAHIM, Mazin, G.","08/528,821 15.09.1995 US",CA-2204866; EP-1996930853
EP13748218,01111720,15.05.2001,1213660,12.06.2002,EP,Meaning understanding by means of local pervasive intelligence,"Scheme for enriching an input network (18) with knowledge from a fractal semantic knowledge network (11). The input network (18) comprises objects and pointers between these objects, and the knowledge network (11) comprises semantic units, and a plurality of Jani, whereby any of these Jani is associated with one or more of the semantic units such that the respective Janus is able to operate on one or more of the semantic units. The following steps are carried out: 
  finding a counterpart element for an object or a pointer by looking for a semantic unit that is related to the object or the pointer; 
  establishing a classification connection between the object or the pointer and its counterpart element; 
  assigning the module that is associated with the counterpart element, if any, to the object or the pointer; 
  examining the objects' or the pointers' neighborhoods in the input network (18) by comparing them with the counterpart elements' neighborhoods in knowledge network (11) to verify the classification connection.",G06F 17/27; G06F 17/28; G06N 3/08; G06N 5/02,IBM,BERGAN ELIAS; BINNIG GERD K; KLENK JUERGEN A,00113438 24.06.2000 EP; 01111720 15.05.2001 EP,
WO2010027933,PCT/US2009/055496,31.08.2009,WO/2010/027933,11.03.2010,WO,TEXT LOCALIZATION FOR IMAGE AND VIDEO OCR,"In accord with embodiments consistent with the present invention, a first action in recognizing text from image and video is to locate accurately the position of the text in image and video. After that, the located and possibly low resolution text can be extracted, enhanced and binarized. Finally existing OCR technology can be applied to the binarized text for recognition. This abstract is not to be considered limiting, since other embodiments may deviate from the features described in this abstract.",G06K 9/34,"SONY CORPORATION; SONY ELECTRONICS INC.; GUILLOU, Jean-pierre; YU, Yang","GUILLOU, Jean-pierre; YU, Yang","12/380,394 26.02.2009 US; 61/190,992 03.09.2008 US",JP-2011526127; CN-200980134487.X; MX-MX/a/2011/002293; CA-2735824; KR-1020117005003; EP-2009812088
WO1999028859,PCT/US1998/023522,03.11.1998,WO/1999/028859,10.06.1999,WO,PATTERN RECOGNIZER WITH INDEPENDENT FEATURE LEARNING,"A pattern recognition device having modifiable feature detectors (28) which respond to a transduced input signal (26) and communicate a feature activity signal (30) to allow classification and an appropriate output action (70). A memory (40) stores a set of comparison patterns, and is used by an assigner (66) to find likely features, or parts, in the current input signal (26). Each part is assigned to a feature detector (28[m]) judged to be responsible for it. An updater (42) modifies each responsible feature detector (28[m]) so as to make its preferred feature more similar to its assigned part. The modification embodies a strong constraint on the feature learning process, in particular an assumption that the ideal features for describing the pattern domain occur independently. This constraint allows improved learning speed and potentially improved scaling properties. A first preferred embodiment uses a group of noisy-OR type neural networks (50) to implement the feature detectors (28) and memory (40), and to obtain the parts by a soft segmentation of the current input signal (26). A second preferred embodiment maintains a lossless memory (40) separate from the feature detectors (28), and the parts consist of differences between the current input signal (26) and comparison patterns stored in the memory (40).",G06K 9/66; G06N 3/04,"KORTGE, Chris, Alan","KORTGE, Chris, Alan","08/980,838 01.12.1997 US",MX-PA/a/2000/005089; JP-2000523634; CA-2311752; EP-1998955244
WO2017011075,PCT/US2016/033764,23.05.2016,WO/2017/011075,19.01.2017,WO,CONTROL NORMALIZATION FOR UNMANNED AUTONOMOUS SYSTEMS,"Methods, systems, and process-readable media include an autonomous vehicle override control system that receives override commands from a pilot qualified on a first type of unmanned autonomous vehicle (UAV) and translates the inputs into suitable commands transmitted to a target UAV of a second UAV type. A pilot's certification for a first UAV type may be determined from the pilot's login credentials. The system may obtain a first control model for the first UAV type and a second control model for the target UAV. Pilot input commands processed through the first control model may be used to calculate movements of a virtual UAV of the type. The system may estimate physical movement of the target UAV similar to the first physical movement, and generate an override command for the target UAV using the second control model and the second physical movement. Control models may accommodate current conditions and pilot experience.",G05D 1/00,QUALCOMM INCORPORATED,"CHAU, Kiet Tuan; CANOY, Michael-David Nakayoshi; DEVICO, Michael Orlando; SPRIGG, Stephen Alton","14/798,715 14.07.2015 US",JP-2018501367; KR-1020187001047; EP-2016729673
WO2003046171,PCT/SE2002/002193,27.11.2002,WO/2003/046171,05.06.2003,WO,A METHOD FOR COMBINED SEQUENTIAL AGENT DELIVERY AND ELECTROPORATION FOR CELL STRUCTURES AND USE THEREOF,"Disclosed is a method for sequential delivery of agents to and/or into a cell structure, wherein an electrolyte-filled tube is provided together with a counter electrode, said tube is connected to a voltage or current generator, at least two agents are introduced in a discrete mode into the electrolyte solution contained in the tube, which is placed close to the cell structure, one agent at the time being transported through the tube to and/or into said cell structure in which a pore has been formed by application of an electric field focused on the cell structure, resulting in electroporation of the cell structure. Also different applications of the method is disclosed, e.g. us of the method in order to transfer cell-impermeant solutes, such as drugs or genes, into the cell structure or out of the cell structure.",A61N 1/30; C12N 15/87; G01N 33/487; G01N 35/10,"CELLECTRICON AB; ORWAR, Owe; KARLSSON, Mattias; NOLKRANTZ, Kerstin; FARRE, Cecilia","ORWAR, Owe; KARLSSON, Mattias; NOLKRANTZ, Kerstin; FARRE, Cecilia",0103957-7 27.11.2001 SE,US-10496227; CA-2468511; JP-2003547603; EP-2002789118; AU-2002353741
WO1991000591,PCT/GB1990/001002,29.06.1990,WO/1991/000591,10.01.1991,WO,PATTERN RECOGNITION,"A neural net is trained on training data, and the weight values are increased up to a predetermined maximum value M; any weight values which would otherwise exceed M are set equal to M. Useful for training multi-layer perceptrons for speech recognition; results in weight values which are more easily quantised hence give a more robust performance.",G06K 9/66; G06N 3/04; G06N 3/08; G10L 15/16,"BRITISH TELECOMMUNICATIONS PUBLIC LIMITED COMPANY; WOODLAND, Philip, Charles","WOODLAND, Philip, Charles",8915085.8 30.06.1989 GB,CA-2063426; EP-1990909478; FI-916155
WO2020060311,PCT/KR2019/012272,20.09.2019,WO/2020/060311,26.03.2020,WO,ELECTRONIC DEVICE AND METHOD FOR PROVIDING OR OBTAINING DATA FOR TRAINING THEREOF,"Methods for providing and obtaining data for training and electronic devices thereof are provided. The method for providing data for training includes obtaining first voice data for a voice uttered by a user at a specific time through a microphone of the electronic device and transmitting the voice recognition result to a second electronic device which obtained second voice data for the voice uttered by the user at the specific time, for use as data for training a voice recognition model. In this case, the voice recognition model may be trained using the data for training and an artificial intelligence algorithm such as deep learning.",G10L 15/06; G10L 15/04; G06F 3/16; G10L 15/22,"SAMSUNG ELECTRONICS CO., LTD.","KIM, Sangha; KIM, Sungchan; LEE, Yongchan",10-2018-0113234 20.09.2018 KR; 10-2019-0013855 01.02.2019 KR,
WO2012167164,PCT/US2012/040567,01.06.2012,WO/2012/167164,06.12.2012,WO,APPARATUS AND METHODS FOR TEMPORALLY PROXIMATE OBJECT RECOGNITION,"Object recognition apparatus and methods useful for extracting information from an input signal. In one embodiment, the input signal is representative of an element of an image, and the extracted information is encoded into patterns of pulses. The patterns of pulses are directed via transmission channels to a plurality of detector nodes configured to generate an output pulse upon detecting an object of interest. Upon detecting a particular object, a given detector node elevates its sensitivity to that particular object when processing subsequent inputs. In one implementation, one or more of the detector nodes are also configured to prevent adjacent detector nodes from generating detection signals in response to the same object representation. The object recognition apparatus modulates properties of the transmission channels by promoting contributions from channels carrying information used in object recognition.",G06K 9/00,"BRAIN CORPORATION; PIEKNIEWSKI, Filip, Lukasz; PETRE, Csaba; SOKOL, Sach, Hansen; SZATMARY, Botond; NAGESWARAN, Jayram, Moorkanikara; IZHIKEVICH, Eugene, M.","PIEKNIEWSKI, Filip, Lukasz; PETRE, Csaba; SOKOL, Sach, Hansen; SZATMARY, Botond; NAGESWARAN, Jayram, Moorkanikara; IZHIKEVICH, Eugene, M.","13/152,105 02.06.2011 US",
WO2020036958,PCT/US2019/046351,13.08.2019,WO/2020/036958,20.02.2020,WO,REAL-TIME SPIKE DETECTION AND IDENTIFICATION,"Methods and apparatus for substantially real-time detection of spike events in neuromuscular data. The method comprises receiving a plurality of neuromuscular signals from a plurality of neuromuscular sensors arranged on one or more wearable devices worn by a user, detecting, based on the plurality of neuromuscular signals or information derived from the plurality of neuromuscular signals, at least one spike event corresponding to firing of an action potential in at least one motor unit, determining, based on the plurality of neuromuscular signals or the information derived from the plurality of neuromuscular signals, a biological source of the detected at least one spike event, and generating at least one output based, at least in part, on the detected at least one spike event and/or the determined biological source of the detected at least one spike event.",A61B 5/0492; G06F 3/01; G06F 19/00,CTRL-LABS CORPORATION,"KAIFOSH, Patrick; BARACHANT, Alexandre; MANDEL, Michael, Isaac; WETMORE, Daniel","62/718,337 13.08.2018 US",
WO2018064660,PCT/US2017/054728,02.10.2017,WO/2018/064660,05.04.2018,WO,LENSLESS IMAGING DEVICE,Technology is described for methods and systems for imaging an object (110). The method can include an image sensor (116) exposed to light (114) from an object (110) without passing the light through an image modification element. Light intensity of the light (114) can be stored as data in a medium. The image data can be analyzed at a processor (902) as a reconstructed image of the object (110).,G06T 5/00; G06T 1/00; G06T 7/60; H04N 5/232,UNIVERSITY OF UTAH RESEARCH FOUNDATION,"MENON, Rajesh; KIM, Ganghun; ISAACSON, Kyle","62/402,579 30.09.2016 US",
WO2014149510,PCT/US2014/019134,27.02.2014,WO/2014/149510,25.09.2014,WO,NETWORK OF INTELLIGENT MACHINES,"A network of apparatuses that characterizes items is presented. A self-updating apparatus includes a processing unit that has a memory storing parameters that are useful for characterizing different items, and a processing module configured to automatically select sources from which to receive data, modify the parameters based on the data that is received, and to select recipients of modified parameters. Selection of sources and recipients is based on comparison of parameters between the processing module and the sources, and between the processing module and the recipients, respectively. The processing unit may include an artificial intelligence program (e.g., a neural network such as a machine learning program). When used in a network, the processing units may ""train"" other processing units in the network such that the characterization accuracy and range of each processing unit improves over time.",G06N 3/00,"SAGI-DOLEV, Alysia; CHECHIK, Gal; ZWEIG, Alon","SAGI-DOLEV, Alysia; CHECHIK, Gal; ZWEIG, Alon","13/843,784 15.03.2013 US",CN-201480021265.8; RU-2015139090; IL-241056; EP-2014711367; CA-2903041
WO2016103026,PCT/IB2015/002506,18.12.2015,WO/2016/103026,30.06.2016,WO,EXTRACTING FEATURE GEOMETRIES FOR LOCALIZATION OF A DEVICE,"Systems, apparatuses, and methods are provided for developing a fingerprint database and extracting feature geometries for determining the geographic location of an end-user device. A device collects, or a processor receives, a depth map of a location in a path network (S101). A physical structure is identified within the depth map (S103). The depth map is divided, at the physical structure, into a horizontal plane at an elevation from the road level (S105). A two- dimensional feature geometry is extracted from the horizontal plane of the depth map using a linear regression algorithm, a curvilinear regression algorithm, or a machine learning algorithm (S107).",G01S 5/02; G01S 5/16; G01S 17/06; G01C 21/30; G06T 7/00,HERE GLOBAL B.V.,"MODICA, Leo; STENNETH, Leon","14/583,523 26.12.2014 US",
WO2014117544,PCT/CN2013/085738,21.11.2013,WO/2014/117544,07.08.2014,WO,METHOD AND SYSTEM FOR RECOGNIZING SPEECH COMMANDS,"A method of recognizing speech commands includes generating a background acoustic model for a sound using a first sound sample, the background acoustic model characterized by a first precision metric. A foreground acoustic model is generated for the sound using a second sound sample, the foreground acoustic model characterized by a second precision metric. A third sound sample is received and decoded by assigning a weight to the third sound sample corresponding to a probability that the sound sample originated in a foreground using the foreground acoustic model and the background acoustic model. The method further includes determining if the weight meets predefined criteria for assigning the third sound sample to the foreground and, when the weight meets the predefined criteria, interpreting the third sound sample as a portion of a speech command. Otherwise, recognition of the third sound sample as a portion of a speech command is forgone.",G10L 15/20,TENCENT TECHNOLOGY (SHENZHEN) COMPANY LIMITED,"YUE, Shuai; LU, Li; ZHANG, Xiang; XIE, Dadong; LIU, Haibo; CHEN, Bo; LIU, Jian",201310035979.1 30.01.2013 CN,MX-MX/a/2015/009812; CA-2897365
WO2000014668,PCT/US1999/020390,08.09.1999,WO/2000/014668,16.03.2000,WO,METHOD AND SYSTEM FOR IMPROVED DETECTION OF PROSTATE CANCER,"A computerized method for analyzing data from a tissue biopsy, which includes creating a plurality of three-dimensional graphic, electronic models of tumorous and non-tumorous individual patient tissue specimens from corresponding digitized cross-sectional sequences, where each of the sequences represents an actual patient tissue specimen. The digitized cross-sectional sequences consist of two-dimensional cross-sectional slides. The slides represent slices of the tissue specimen at spaced intervals. A three-dimensional graphic, electronic master model of a tissue specimen is then formed by mapping all of the graphic models of tumorous and non-tumorous individual patient tissue specimens. A three-dimensional statistical probability distribution is then incorporated into the master model, that designates positions of potential tumors to be found during the tissue biopsy, based on locations of actual tumors in the tumorous individual patient tissue specimens. The master model with the statistical probability distribution is then superimposed on a graphic, electronic patient's biopsy display during the tissue biopsy.",G06K 9/62; G06T 7/00,"CATHOLIC UNIVERSITY OF AMERICA; WANG, T., Joseph","WANG, T., Joseph","60/099,329 08.09.1998 US; 60/100,622 17.09.1998 US",
WO2019217468,PCT/US2019/031185,07.05.2019,WO/2019/217468,14.11.2019,WO,METHODS AND SYSTEMS FOR GENERATING AND PROVIDING PROGRAM GUIDES AND CONTENT,"Systems and methods for identifying, assembling, and transmitting content are described in the illustrative context of electronic program guides and program channels. Data is received over a network from a first user terminal that enables identification of the first user. Program information for a digital program is accessed. A determination is made as to how many interstitials are to be presented during a playback of the digital program. A prediction model is selected and executed to generate predictions of user responses to one or more placements of program interstitials. The user response predictions are used to determine positioning of interstitials with respect to the program. The interstitials are enabled to be displayed on the first user terminal in accordance with the determined positioning.",H04N 21/466; H04N 21/45; H04N 21/475; H04N 21/458; H04N 21/482,PLUTO INC.,"HOU, Chan V.","62/669,182 09.05.2018 US",
WO2002013067,PCT/US2001/024719,04.08.2001,WO/2002/013067,14.02.2002,WO,SYSTEM FOR ONLINE RULE-BASED VIDEO CLASSIFICATION,"A rule based video based classification system, which initiates classification with offline training 500. Sample video clips 502 of different categories are identified. Thereafter, an entropy-based inductive tree-learning algorithm is utilized to establish the trained knowledge base. A classifier 504 then accepts video of data 506 to be classified, and utilizes rules in conjunction with extracted video features to classify the input video or data 506. The classifier 504 then provides the classification results 508.",G06F 17/30; G06N 5/02,"HRL LABORATORIES, LLC; VELLIAKAL, Asha; ZHOU, Wensheng","VELLIAKAL, Asha; ZHOU, Wensheng","60/223,555 05.08.2000 US; 09/708,272 07.11.2000 US",
WO2007120456,PCT/US2007/008002,30.03.2007,WO/2007/120456,25.10.2007,WO,CAMERA USER INPUT BASED IMAGE VALUE INDEX,"In an imaging evaluation method, camera, and system, a scene is imaged with a camera. User inputs to the camera are received concurrent with the imaging. The inputs each define a setting of one of a plurality of operational functions of the camera. The inputs are valued to provide a set of input values. An image value index is calculated using the input values.",G06F 17/30,"EASTMAN KODAK COMPANY; MANICO, Joseph Anthony; FREDLUND, John Randall; FEDOROVSKAYA, Elena A.; BEAUDET, Douglas Barrett","MANICO, Joseph Anthony; FREDLUND, John Randall; FEDOROVSKAYA, Elena A.; BEAUDET, Douglas Barrett","11/403,583 13.04.2006 US",EP-2007754515; JP-2009505385; CN-200780013129.4
WO2019000445,PCT/CN2017/091300,30.06.2017,WO/2019/000445,03.01.2019,WO,SYSTEMS AND METHODS FOR VERIFYING AUTHENTICITY OF ID PHOTO,"A system and method for verifying authenticity of a target ID photo are provided. The method may include: receiving, by at least one computer, a target identification (ID) photo; accessing, by the at least one computer, a database of one or more reference ID photos; determining, by the at least one computer, a difference value between a predetermined area on the target ID photo and a predetermined area of one or more target reference ID photos in the database; upon determining that the difference value is less than a threshold value, generating, by the at least one computer, a warning code to indicate that the target ID photo is a fake ID photo.",G06K 9/00,"BEIJING DIDI INFINITY TECHNOLOGY AND DEVELOPMENT CO., LTD.","ZHANG, Tianming",,CN-201780041307.8; EP-2017914122; SG-11201811691R; JP-2018568402; CA-3034688; AU-2017421316
WO2007056535,PCT/US2006/043683,08.11.2006,WO/2007/056535,18.05.2007,WO,METHOD AND APPARATUS FOR TIMED TAGGING OF MEDIA CONTENT,"A method and apparatus for timed tagging of content is featured. The method and apparatus can include the steps of, or structure for, obtaining at least one keyword tag associated with discrete media content; generating a timed segment index of discrete media content, the timed segment index identifying content segments of the discrete media content and corresponding timing boundaries of the content segments; searching the timed segment index for a match to the at least one keyword tag, the match corresponding to at least one of the content segments identified in the segment index; and generating a timed tag index that includes the at least one keyword tag and the timing boundaries corresponding to the least one content segment of the discrete media content containing the match.",G06F 17/30,"EVERYZING. INC.; HOUH, Henry; STERN, Jeffrey, Nathan","HOUH, Henry; STERN, Jeffrey, Nathan","60/736,124 09.11.2005 US; 11/395,732 31.03.2006 US; 11/444,989 01.06.2006 US",EP-6837265
WO2019106566,PCT/IB2018/059411,28.11.2018,WO/2019/106566,06.06.2019,WO,SYSTEM AND METHOD FOR THE GENERATION AND EDITING OF TEXT CONTENT IN WEBSITE BUILDING SYSTEMS,"A tool for a website building system (WBS) includes a database storing text options formed of a hierarchical data structure (HDS) associated with a field role, based on information gathered internally and externally to the WBS, each HDS having nodes and sub-trees representing field content, text paragraphs and sentences; a role determiner to determine a field role for an editable text field of a website edited or generated with said WBS; an analysis engine to make at least one text option recommendation from the database for the field role; an HDS editor to enable a user to select one recommended text option and to edit a local instance of an HDS of the text option including editing nodes and sub-trees of a local instance of the HDS and a text generator to linearize the local instance and to generate the text for site generation or an editor of the WBS.",G06F 17/00; G06F 17/24,WIX.COM LTD.,"KOREN, Dan; SHASHA, Erez; SADEH, Eyal; ROWLAND, Rachel","62/591,297 28.11.2017 US",
EP221780070,17207568,15.12.2017,3336648,20.06.2018,EP,MOVABLE OBJECT AND CONTROL METHOD THEREOF,"Disclosed herein are a movable object and a movable object control method. The movable object control method may include acquiring an image of a movable object's surroundings, acquiring a signal having strength changing depending on a location of the movable object, generating a map on the basis of the signal and the image of the surroundings of the movable object, and applying the map to an algorithm to acquire a learned algorithm.",G05D 1/02; G01C 21/00; G01S 1/00; H04W 4/00,SAMSUNG ELECTRONICS CO LTD,YOON SUK JUNE; KWAK NO SAN; ROH KYUNG SHIK; PARK SOON YONG; AHN SUNG HWAN,20160173535 19.12.2016 KR,
WO2013090910,PCT/US2012/070149,17.12.2012,WO/2013/090910,20.06.2013,WO,REAL-TIME ANOMALY DETECTION OF CROWD BEHAVIOR USING MULTI-SENSOR INFORMATION,"The present disclosure includes systems and methods for detecting an anomaly in crowd behavior. The method includes receiving sensor data representing a crowd, and partitioning the sensor data into local areas forming neighborhoods. The method further includes, for each local area, characterizing motion in the local area to determine real-time estimates of motion of sub-populations based on the sensor data, providing a crowd model for each local area, representing continuous functions describing expected motion near each local area, and determining parametric values of the crowd model based on the real-time estimates of the motion of the sub-populations. The method further includes learning and adapting auxiliary stochastic models characterizing normal evolution of the parametric values of the crowd model over time associated with each local area, and identifying a potential anomaly associated with the local area by comparing predictions from an auxiliary stochastic model with parametric values of the crowd model.",G06F 17/10,NORTHEASTERN UNIVERSITY,"LEHMANN, Oliver; TADMOR, Gilead","61/576,198 15.12.2011 US",US-14365494
EP204138114,17161797,20.03.2017,3223237,27.09.2017,EP,SYSTEMS AND METHODS FOR DETECTING AND TRACKING A MARKER,"Systems and methods for detecting and tracking a marker in real time are disclosed. Shape based segmentation of at least one object detected in a first frame from a sequence of frames is performed to define a region of interest (ROI) surrounding an object of interest corresponding to the marker. A marker detection model is dynamically trained based on sampling points from a plurality of pixels in and around the ROI. The marker is then tracked in real-time based on projected ROI in subsequent frames and the trained marker detection model. To optimize computation time required in classifying the pixels as marker pixels or non-marker pixels, the ROI is reduced to half its size, classification is performed on the reduced ROI and to improve accuracy, blob detection and classifying pixels along the boundary of the reduced ROI is performed by processing the ROI in original resolution.",G06T 7/11; G06K 9/32; G06K 9/62; G06T 7/12; G06T 7/246,TATA CONSULTANCY SERVICES LTD,HASSAN EHTESHAM; GUPTA GAURAV,201621010035 22.03.2016 IN,
WO2019169396,PCT/US2019/020577,04.03.2019,WO/2019/169396,06.09.2019,WO,CHARGE DOMAIN MATHEMATICAL ENGINE AND METHOD,"A multiplier has a pair of charge reservoirs. The pair of charge reservoirs are connected in series, A first charge movement device induces charge movement to or from the pair of charge reservoirs at a same rate. A second charge movement device induces charge movement to or from one of the pair of reservoirs, the rate of charge movement programmed to one of add or remove charges at a rate proportional to the first charge movement device. The first charge movement device loads a first charge into a first of the pair of charge reservoirs daring a first cycle, The first charge movement device and the second charge movement device remove charges at a proportional rate from the pair of charge reservoirs during a second cycle until the first of the pair of charge reservoirs is depleted of the first charge. The second charge reservoir thereafter holding the multiplied result.",G06N 3/063; G06N 3/08; H03M 1/10; H03M 1/40; H04L 12/56,"SCHIE, David; GAITUKEVICH, Sergey; DRABOS, Peter; SIBRAI, Andreas; SIBRAI, Erik","SCHIE, David; GAITUKEVICH, Sergey; DRABOS, Peter; SIBRAI, Andreas; SIBRAI, Erik","16/291,864 04.03.2019 US; 62/637,496 02.03.2018 US",
WO2019178372,PCT/US2019/022292,14.03.2019,WO/2019/178372,19.09.2019,WO,RECIPE CONVERSION SYSTEM,"A system for performing recipe conversion is disclosed. The recipe resulting from the conversion may produce superior and more consistent results for less experienced cooks, particularly when instructions are ported to a cooking system that provides step-by-step guidance with a high level of thermal and time control for critical recipe steps. Further, a converted recipe may optionally include more precise instructions and/or graphic content to assist less experienced cooks. The system analyzes, via natural language processing, an original recipe to identify recipe stages and to determine cooking stages corresponding to the recipe stages. The system correlates the cooking stages to machine instructions, and modifies recipe stages to include enhanced content by using the machine instructions. The system reformats the recipe into a digital file that includes a machine instruction set, which is provided to a device to facilitate the performance of recipe stages when preparing a food item.",G06F 17/30,"HESTAN SMART COOKING, INC.","BAUMBACK, Mark; JENKINS, Jonathan","62/642,850 14.03.2018 US",
WO2019042738,PCT/EP2018/071727,10.08.2018,WO/2019/042738,07.03.2019,WO,GENERATING CHAT BOTS FROM WEB API SPECIFICATIONS,"Automatic generation of a chat bot from an API specification to carry out a dialogue with a user and invoke an API call described in the API specification. Based on input API specification, a conversational bot specification representing a dialog flow is constructed. A natural language expression is received and transformed into instructions based on the conversational bot specification. Based on the instructions, a natural language prompt to the user and executable computer code for invoking the API call may be generated.",G06F 8/35; H04L 12/58; G06N 3/04; G06F 17/27; G06F 17/30,INTERNATIONAL BUSINESS MACHINES CORPORATION; IBM UNITED KINGDOM LIMITED,"HIRZEL, Martin; MANDEL, Louis; SHINNAR, Avraham; SIMEON, Jerome; VAZIRI, Mandana; WIECHA, Charles","15/692,410 31.08.2017 US",
WO2020014294,PCT/US2019/041103,10.07.2019,WO/2020/014294,16.01.2020,WO,LEARNING TO SEGMENT VIA CUT-AND-PASTE,"Example aspects of the present disclosure are directed to systems and methods that enable weakly-supervised learning of instance segmentation by applying a cut-and-paste technique to training of a generator model included in a generative adversarial network. In particular, the present disclosure provides a weakly-supervised approach to object instance segmentation. In some implementations, starting with known or predicted object bounding boxes, a generator model can learn to generate object masks by playing a game of cut-and-paste in an adversarial learning setup.",G06K 9/62,GOOGLE LLC,"BROWN, Matthew, Alun; HUANG, Jonathan, Chung-Kuan; REMEZ, Tal","62/696,447 11.07.2018 US",
WO2019060645,PCT/US2018/052095,20.09.2018,WO/2019/060645,28.03.2019,WO,PHOTONIC NEURAL NETWORK SYSTEM,"A system (10) for convolving and adding frames of data comprises a first sensor-display device (14) and a second sensor display device (26). Each sensor display device (14, 26) comprises an array (80) of transmit-receive modules (82). Each transmit-receive module (82) comprises a light sensor element (86), a light transmitter element (84), and a memory bank (90). A radial modulator device (20) is positioned where transmission of light fields comprising frames of data are Fourier transformed. Filters implemented by modulator elements of the radial modulator device (20) convolve the fields of light comprising the frames of data, which are then sensed on a pixel-by-pixel basis by the light sensor elements (86), which accumulate charges, thus sum pixel values of sequential convolved frames of data.",G06N 3/067; G06N 3/08,"LOOK DYNAMICS, INC.","BRUCE, David A.; BAIARDO, Jonathan C.; CRILL, Rikki J.","62/561,061 20.09.2017 US; 62/625,711 02.02.2018 US",IL-273370
WO2020048358,PCT/CN2019/102880,27.08.2019,WO/2020/048358,12.03.2020,WO,"METHOD, SYSTEM, AND COMPUTER-READABLE MEDIUM FOR RECOGNIZING SPEECH USING DEPTH INFORMATION","In an embodiment, a method includes receiving a plurality of first images including at least a mouth-related portion of a human speaking an utterance, wherein each first image has depth information; extracting a plurality of viseme features using the first images, wherein one of the viseme features is obtained using depth information of a tongue of the human in the depth information of a first image of the first images; determining a sequence of words corresponding to the utterance using the viseme features, wherein the sequence of words comprises at least one word; and outputting, by a human-machine interface (HMI) outputting module, a response using the sequence of words.",G10L 15/25,"GUANGDONG OPPO MOBILE TELECOMMUNICATIONS CORP., LTD.","LIN, Yuan; HO, Chiuman","62/726,595 04.09.2018 US",
EP233540691,18169500,26.04.2018,3404578,21.11.2018,EP,SENSOR TRANSFORMATION ATTENTION NETWORK (STAN) MODEL,"A sensor transformation attention network (STAN) model including sensors configured to collect input signals, attention modules configured to calculate attention scores of feature vectors corresponding to the input signals, a merge module configured to calculate attention values of the attention scores, and generate a merged transformation vector based on the attention values and the feature vectors, and a task-specific module configured to classify the merged transformation vector is provided.",G06K 9/00; G06K 9/46; G06K 9/62; G10L 15/16; G10L 15/20,SAMSUNG ELECTRONICS CO LTD; UNIV ZUERICH,BRAUN STEFAN; NEIL DANIEL; CEOLINI ENEA; ANUMULA JITHENDAR; LIU SHIH-CHII,20170117021 13.09.2017 KR; 201762507385 17.05.2017 US; 201762508631 19.05.2017 US,
WO2019081375,PCT/EP2018/078758,19.10.2018,WO/2019/081375,02.05.2019,WO,APPARATUS FOR PLANT MANAGEMENT,The present invention relates to an apparatus for plant management. It is described to provide (210) a processing unit with at least one image of a field. The processing unit analyses (220) the at least one image to determine information relating to a plant that is present. The processing unit determines (230) if the plant is to be controlled or is not to be controlled by a plant control technology based on the information relating to the plant. An output unit outputs (240) information that is useable to activate at least one plant control technology if the determination is made that the plant is to be controlled by the plant control technology.,A01N 25/00; A01M 7/00; G06F 17/00; G06Q 10/04; G06Q 50/02; A01M 1/02,BASF SE,"PETERS, Ole",17198814.0 27.10.2017 EP; 17198812.4 27.10.2017 EP,
WO2018184746,PCT/EP2018/051704,24.01.2018,WO/2018/184746,11.10.2018,WO,A METHOD AND APPARATUS FOR PERFORMING HIERARCHICAL ENTITY CLASSIFICATION,"A method for performing hierarchical entity classification of an entity mention within a context, wherein ontological classes are computed for the entity mention levelwise using a contextual representation of the con- text and a state representation obtained by running an end-to-end trained decoding recurrent neural network on a mention representation (m) of said entity mention.",G06F 17/27,SIEMENS AKTIENGESELLSCHAFT,"KUMAR KARN, Sanjeev",17164615.1 03.04.2017 EP,EP-2018704442
WO2015022689,PCT/IL2014/050727,13.08.2014,WO/2015/022689,19.02.2015,WO,MEDIA OBJECT SELECTION,"A computerized method selecting a group of media objects. The method comprises analyzing a plurality of profiling media objects, each one of the plurality of visual media objects associated with a target user, identifying, using a processor, a prevalence of each of a plurality of characterizing properties in each one of the plurality of visual media objects, selecting at least one of the plurality of characterizing properties based on the respective prevalence, identifying automatically a group of a plurality of matching media objects from a plurality of additional media objects, each member of the group having the at least one characterizing property, and outputting an indication of the group.",G06F 17/30,PIC DJ LTD.,"ECKHOUSE BARZILAI, Adi","61/865,231 13.08.2013 US",
WO2020073272,PCT/CN2018/109802,11.10.2018,WO/2020/073272,16.04.2020,WO,SNAPSHOT IMAGE TO TRAIN AN EVENT DETECTOR,"A method and an apparatus for training an event detector with snapshot images is set forth.The method comprises: obtaining at least two frames of sensor data from at least one sensor installed on a vehicle, the at least two frames of sensor data are sequentially collected at different time(702); obtaining results of events that are occurring while the sensor data are obtained(704); for each of the at least two frames, creating a snapshot image with the obtained sensor data(706); associating the obtained results of events with corresponding snapshot images as training data(708); and training an event detector using the training data(710).",G06K 9/00,"BAYERISCHE MOTOREN WERKE AKTIENGESELLSCHAFT; JIANG, Wanli","JIANG, Wanli; DOMLING, Maximilian; LI, Qianshan",,
WO2020073268,PCT/CN2018/109796,11.10.2018,WO/2020/073268,16.04.2020,WO,SNAPSHOT IMAGE TO TRAIN ROADMODEL,"Examples of the present disclosure describe a method and a system for training a road model with snapshot images. The method comprises: obtaining an existing road model of a road scene; obtaining at least two frames of sensor data of the road scene from at least two sensors installed on a vehicle, the at least two frames of sensor data are sequentially collected at different time; for each of the at least two frames, creating a snapshot image with the obtained sensor data; associating the existing road model with each of the snapshot image as training data; and training a new road model using the training data.",G06K 9/62; G01S 13/86,"BAYERISCHE MOTOREN WERKE AKTIENGESELLSCHAFT; LI, Qianshan","LI, Qianshan; DOMLING, Maximilian; JIANG, Wanli",,
WO2019055278,PCT/US2018/049706,06.09.2018,WO/2019/055278,21.03.2019,WO,SEMANTIC SIGNATURES,"In various embodiments, methods and systems for implementing a semantic signature system are provided. A semantic signature system provides a machine trained semantic representation (i.e., a semantic signature) of the context of a word, synonyms of the word, and weak and strong relationship of the word with other words. The semantic signature can be utilized to facilitate labeling a word that is ambiguous or previously unknown. In practice, the label can be used to more accurately categorize the word for later retrieval by a search or to more accurately provide search results for a search query that includes the word.",G06N 3/08,EBAY INC.,"DA SILVEIRA KUHN, Amanda; JOHAL, Era; XIN, Yingwei; LI, Shuo; MEHTA, Kunal Nitin; LIAO, Siyu","62/558,180 13.09.2017 US; 16/109,280 22.08.2018 US",
WO2019136894,PCT/CN2018/086557,11.05.2018,WO/2019/136894,18.07.2019,WO,METHODS AND SYSTEMS FOR FACE ALIGNMENT,"A method and system for face alignment. The method may include obtaining an image processing model set including M (M ≥ 2) candidate models, and obtaining a test image including a target face. The method may also include conducting T (T ≥ 1) stages of model set updating operation. Each stage of the T stages of model set updating operation may include conducting a performance evaluation to each candidate model of the image processing model set with respect to the test image, and updating the image processing model set by excluding at least one model from the image processing model set based on the performance evaluation. The method may further include designating, after completing the T stages of model set updating operation, at least one candidate model of the image processing model set as a target model, and determining, based on the target model, a result shape as a shape of the target face.",G06K 9/00,"ZHEJIANG DAHUA TECHNOLOGY CO., LTD.","WANG, Bin; WANG, Gang",201810021987.3 10.01.2018 CN,
WO2015134244,PCT/US2015/017454,25.02.2015,WO/2015/134244,11.09.2015,WO,NEURAL NETWORK ADAPTATION TO CURRENT COMPUTATIONAL RESOURCES,"Methods and apparatus are provided for processing in an artificial nervous system. According to certain aspects, resolution of one or more functions performed by processing units of a neuron model may be reduced, based at least in part on availability of computational resources or a power target or budget. The reduction in resolution may be compensated for by adjusting one or more network weights.",G06N 3/08; G06N 3/04,QUALCOMM INCORPORATED,"JULIAN, David, Jonathan; CHANG, Ilwoo","61/947,149 03.03.2014 US; 14/268,372 02.05.2014 US",EP-2015710343; JP-2016555302
EP12769711,95309005,12.12.1995,0720147,03.07.1996,EP,"Systems, methods and articles of manufacture for performing high resolution N-best string hypothesization","Disclosed are systems, methods and articles of manufacture for performing high resolution N-best string hypothesization during speech recognition. A received input signal, representing a speech utterance, is processed utilizing a plurality of recognition models to generate one or more string hypotheses of the received input signal. The plurality of recognition models preferably include one or more inter-word context dependent models and one or more language models. A forward partial path map is produced according to the allophonic specifications of at least one of the inter-word context dependent models and the language models. The forward partial path map is traversed in the backward direction as a function of the allophonic specifications to generate the one or more string hypotheses. One or more of the recognition models may represent one phone words.",G10L 5/00; G10L 5/06; G10L 15/02; G10L 7/08; G10L 15/08; G10L 9/00; G10L 15/18; G10L 9/06; G10L 9/18,AT & T CORP,CHOU WU; LEE CHIN-HUI; JUANG BIING-HWANG; MATSUOKA TATSUO,36684394 30.12.1994 US,
WO2019228654,PCT/EP2018/064534,01.06.2018,WO/2019/228654,05.12.2019,WO,METHOD FOR TRAINING A PREDICTION SYSTEM AND SYSTEM FOR SEQUENCE PREDICTION,"The invention relates to a method for training a prediction system. The prediction system comprises a hidden variable model using a hidden random variable for sequence prediction. The method comprises the steps of: * multiple input of a sequence input (x) into the hidden variable model which outputs in response multiple distinct samples (y) conditioned by the random variable, * use of the best of multiple samples to train the model, the best sample being the closest to the ground truth. The invention further relates to a system for sequence prediction.",G06N 3/04; G06N 3/08,TOYOTA MOTOR EUROPE; MAX-PLANCK-INSTITUT FÜR INFORMATIK,"BHATTACHARYYA, Apratim; FRITZ, Mario; SCHIELE, Bernt; OLMEDA REINO, Daniel",,
WO2018005069,PCT/US2017/037104,13.06.2017,WO/2018/005069,04.01.2018,WO,AUGMENTING A MOVEABLE ENTITY WITH A HOLOGRAM,"In embodiments of augmenting a moveable entity with a hologram, an alternate reality device (100) includes a tracking system (108) that can recognize an entity in an environment and track movement of the entity in the environment. The alternate reality device can also include a detection algorithm (128) implemented to identify the entity recognized by the tracking system based on identifiable characteristics of the entity. A hologram positioning application (124) is implemented to receive motion data from the tracking system, receive entity characteristic data from the detection algorithm, and determine a position and an orientation of the entity in the environment based on the motion data and the entity characteristic data. The hologram positioning application can then generate a hologram that appears associated with the entity as the entity moves in the environment.",G06F 3/01; G06K 9/00; G06T 7/20; G02B 27/01; G06F 3/0481; G06K 9/20,"MICROSOFT TECHNOLOGY LICENSING, LLC","MCCULLOCH, Daniel Joseph; FAJT, Nicholas Gervase; POULOS, Adam G.; EDMONDS, Christopher Douglas; CHERKASHIN, Lev; ALLEN, Brent Charles; DULU, Constantin; KAPASI, Muhammad Jabir; GRABNER, Michael; SAMPLES, Michael Edward; BONG, Cecilia; SUSFFALICH, Miguel Angel; MANI, Varun Ramesh; AMBRUS, Anthony James; TOMLIN, Arthur C.; DACK, James Gerard; KOHLER, Jeffrey Alan; REHMEYER, Eric S.; PARKER, Edward D.","15/199,831 30.06.2016 US",
WO2009058164,PCT/US2008/006243,14.05.2008,WO/2009/058164,07.05.2009,WO,COMPUTATIONAL USER-HEALTH TESTING RESPONSIVE TO A USER INTERACTION WITH ADVERTISER-CONFIGURED CONTENT,"Methods, apparatuses, computer program products, devices and systems are described that carry out specifying at least one of a plurality of user-health test functions responsive to an interaction between a user and at least one advertiser-specified attribute; and transmitting at least one output of the at least one user-health test function related to the at least one advertiser-specified attribute.",A61B 5/00; G06Q 50/00,"SEARETE LLC; JUNG, Edward K.Y.; LEUTHARDT, Eric C.; LEVIEN, Royce A.; LORD, Robert W.; MALAMUD, Mark A.","JUNG, Edward K.Y.; LEUTHARDT, Eric C.; LEVIEN, Royce A.; LORD, Robert W.; MALAMUD, Mark A.","11/982,333 31.10.2007 US",GB-1008893.8
EP290833376,18894430,29.12.2018,3624019,18.03.2020,EP,INTEGRATED CIRCUIT CHIP DEVICE AND RELATED PRODUCT,The present disclosure provides an integrated circuit chip device and a related product. The integrated circuit chip device includes: a primary processing circuit and a plurality of basic processing circuits. The primary processing circuit or at least one of the plurality of basic processing circuits includes a compression mapping circuit configured to perform compression on each data of a neural network operation. The technical solution provided by the present disclosure has the advantages of a small amount of computations and low power consumption.,G06N 3/063,CAMBRICON TECH CORPORATION LIMITED,CHEN TIANSHI; LIU SHAOLI; WANG BINGRUI; ZHANG YAO; HU SHUAI; SONG XINKAI,201711499265 30.12.2017 CN; 201711499266 30.12.2017 CN; 201711499267 30.12.2017 CN; 201711499268 30.12.2017 CN; 2018125801 29.12.2018 CN,
EP151489057,13844281,01.10.2013,2904561,12.08.2015,EP,SYSTEM AND METHOD FOR OPTIMIZING VIDEOS,"A computing device executing an optimizer analyzes a video. The computing device identifies one or more optimizations for the video based on the analysis. The computing device suggests the one or more optimizations to an entity associated with the video. In response to the entity accepting the one or more optimizations, the computing device implements the one or more optimizations for the video.",G06F 16/00; G06F 16/48; G06K 9/00; G06K 9/62; G11B 27/031; H04N 5/262; H04N 7/12; H04N 21/234; H04N 21/2343; H04N 21/258; H04N 21/2668; H04N 21/2743; H04N 21/431; H04N 21/435; H04N 21/44; H04N 21/4722; H04N 21/475; H04N 21/81; H04N 21/84; H04N 21/854,GOOGLE LLC,VUSKOVIC VLADIMIR; BAKSHI DHRUV; D'ARC AMAURY FORGEOT; POROPATITS CHRISTOPH,201213632998 01.10.2012 US; 2013062930 01.10.2013 US,
WO2014168898,PCT/US2014/033241,08.04.2014,WO/2014/168898,16.10.2014,WO,IMAGE LABELING USING GEODESIC FEATURES,"Image labeling is described, for example, to recognize body organs in a medical image, to label body parts in a depth image of a game player, to label objects in a video of a scene. In various embodiments an automated classifier uses geodesic features of an image, and optionally other types of features, to semantically segment an image. For example, the geodesic features relate to a distance between image elements, the distance taking into account information about image content between the image elements. In some examples the automated classifier is an entangled random decision forest in which data accumulated at earlier tree levels is used to make decisions at later tree levels. In some examples the automated classifier has auto-context by comprising two or more random decision forests. In various examples parallel processing and look up procedures are used.",G06K 9/62; G06T 7/00,"MICROSOFT TECHNOLOGY LICENSING, LLC","CRIMINISI, Antonio; SHOTTON, Jamie Daniel Joseph; KONTSCHIEDER, Peter; KOHLI, Pushmeet","13/860,515 10.04.2013 US",EP-2014724259
WO1990014631,PCT/US1990/002718,17.05.1990,WO/1990/014631,29.11.1990,WO,DYNAMICALLY STABLE ASSOCIATIVE LEARNING NEURAL SYSTEM,"A dynamically stable associative learning neural network system includes a plurality of synapses (122, 22-28), a non-linear function circuit (30) and an adaptive weight circuit (150) for adjusting the weight of each synapse based upon the present signal and the prior history of signals applied to the input of the particular synapse and the present signal and the prior history of signals applied to the input of a predetermined set of other collateral synapses. A flow-through neuron circuit (1110) embodiment includes a flow-through synapse (122) having a predetermined fixed weight. A neural network is formed by a set of low-through neuron circuits connected by flow-through synapses to form separate paths between each input (215) and a corresponding output (245). In one embodiment (200), the neuron network is initialized by setting the adjustable synapses at some value near the minimum weight and setting the flow-through neuron circuits at some arbitrarily high weight. The neural network embodiments are taught by successively application of sets of input signals to the input terminals until a dynamic equilibrium is reached.",G06N 3/04,"THE UNITED STATES OF AMERICA, represented by THE SECRETARY, UNITED STATES DEPARTMENT OF COMMERCE; ENVIRONMENTAL RESEARCH INSTITUTE OF MICHIGAN","ALKON, Daniel, L.; VOGL, Thomas, P.; BLACKWELL, Kim, L.","353,107 17.05.1989 US; 448,090 12.12.1989 US",
WO1999053287,PCT/US1999/007344,07.04.1999,WO/1999/053287,21.10.1999,WO,ELECTRONIC TECHNIQUES FOR ANALYTE DETECTION,"Techniques are used to detect and identify analytes. Techniques are used to fabricate and manufacture sensors to detect analytes. An analyte (1810) is sensed by sensors (1820) that output electrical signals in response to the analyte. The electrical signals are preprocessed (1830) by filtering and amplification. In an embodiment, this preprocessing includes adapting the sensor and electronics to the environment in which the analyte exists. The electrical signals are further processed (1840) to classify and identify the analyte, which may be by a neural network.",G01N 33/00,"CALIFORNIA INSTITUTE OF TECHNOLOGY; GOODMAN, Rodney, M.; LEWIS, Nathan, S.; GRUBBS, Robert, H.; DICKSON, Jeffery; KOOSH, Vincent","GOODMAN, Rodney, M.; LEWIS, Nathan, S.; GRUBBS, Robert, H.; DICKSON, Jeffery; KOOSH, Vincent","60/081,182 09.04.1998 US; 60/092,707 14.07.1998 US",JP-2000543804; EP-1999919780; AU-37427/99; CA-2325886
WO2003046170,PCT/SE2002/002192,27.11.2002,WO/2003/046170,05.06.2003,WO,A METHOD FOR COMBINED PARALLEL AGENT DELIVERY AND ELECTROPORATION FOR CELL STRUCTURES AND USE THEREOF,"Disclosed is a method for parallel delivery of agents to and/or into a cell structure, wherein at least two electrolyte-filled tubes are provided together with a counter electrode, the tubes being connected to a voltage or current generator, said agents being introduced into the electrolyte solution contained in the tubes, which are placed close to the cell structure, whereupon the agents are transported through the tubes to said cell structure and into the said structure through pores which have been formed by application of an electric field focused on the cell structure, resulting in electroporation of the cell structure. Also different applications of the method is disclosed, e.g. use of the method in order to transfer cell-impermeant solutes, such as drugs or genes, into the cell structure or out of the cell structure.",A61N 1/30; C12N 15/87; G01N 33/487; G01N 35/10,"CELLECTRICON AB; ORWAR, Owe; KARLSSON, Mattias; NOLKRANTZ, Kerstin; FARRE, Cecilia","ORWAR, Owe; KARLSSON, Mattias; NOLKRANTZ, Kerstin; FARRE, Cecilia",0103957-7 27.11.2001 SE,JP-2003547602; EP-2002791153; CA-2468424; AU-2002365542; US-10496214
WO2006019993,PCT/US2005/025114,14.07.2005,WO/2006/019993,23.02.2006,WO,DISTRIBUTED PATTERN RECOGNITION TRAINING METHOD AND SYSTEM,A distributed pattern recognition training method includes providing data communication between at least one central pattern analysis node and a plurality of peripheral data analysis sites. The method also includes communicating from the at least one central pattern analysis node to the plurality of peripheral data analysis a plurality of kernel­based pattern elements. The method further includes performing a plurality of iterations of pattern template training at each of the plurality of peripheral data analysis sites.,G10L 15/00,"AURILAB, LLC; BAKER, James, K.","BAKER, James, K.","60/587,874 15.07.2004 US",DE-null
WO2019068835,PCT/EP2018/077060,04.10.2018,WO/2019/068835,11.04.2019,WO,METHOD AND SYSTEM FOR PERFORMING DATA ANALYSIS FOR PLANT PHENOTYPING,"The invention relates to a method for performing data analysis for plant phenotyping of single plants in a field and a data acquisition and evaluation system for performing data analysis for plant phenotyping of single plants in a field. Further, the invention relates to a mobile platform for use in said method and/or in said data acquisition and evaluation system and a use of the mobile platform for said method and/or said data acquisition and evaluation system. The method comprises the steps of capturing spectral data via a hyperspectral imaging sensor, capturing image data via an image sensor, capturing georeference data via an inertial measurement unit, spatializing the image data to generate georeferenced image data and a digital surface model, spatializing the spectral data, generating georeferenced spectral data based on the spatialized spectral data and the digital surface model and overlaying the georeferenced image data and georeferenced spectral data with field plan information to generate a high-resolution analysis data set.",G06K 9/00; G06K 9/62; A01B 79/00,KWS SAAT SE & Co. KGaA,"BAUER, Christoph; JEBSEN, Christian; GUBATZ, Sabine; DAHL, Ludmilla",17194841.7 04.10.2017 EP,
WO2015026902,PCT/US2014/051817,20.08.2014,WO/2015/026902,26.02.2015,WO,MULTI-TRACKER OBJECT TRACKING,"Systems and approaches are provided for tracking an object using multiple tracking processes. By combining multiple lightweight tracking processes, object tracking can be robust, use a limited amount of power, and enable a computing device to respond to input corresponding to the motion of the object in real time. The multiple tracking processes can be run in parallel to determine the position of the object by selecting the results of the best performing tracker under certain heuristics or combining the results of multiple tracking processes in various ways. Further, other sensor data of a computing device can be used to improve the results provided by one or more of the tracking processes.",G06K 9/00,"AMAZON TECHNOLOGIES, INC.","FOTLAND, David, Allen","13/973,913 22.08.2013 US",
EP14854527,06253562,07.07.2006,1876553,09.01.2008,EP,Method and system for engineering process graphics using sketch recognition,"The present invention concerns a method for generating process graphics for an industrial process, comprising the following steps: recording a digital image of a graphic in the form of a sketch drawn free-hand by a user, said sketch representing an engineering process element into a computing device, processing the digital image to provide an enhanced process graphic element, and identifying said sketch as at least one process graphic element by using at least a library providing information helping to interpret said sketch and geometrical sketch elements. A system for generating process graphics for an industrial process is also disclosed.",G06K 9/00,ABB RESEARCH LTD,TORGEIR ENKERUD,06253562 07.07.2006 EP,
WO2011014168,PCT/US2009/052164,29.07.2009,WO/2011/014168,03.02.2011,WO,SYSTEM AND METHOD FOR PRODUCING A MEDIA COMPILATION,A system and method for producing a media compilation is described.,G06Q 50/00; G06F 17/00,"HEWLETT-PACKARD DEVELOPMENT COMPANY, L.P.; ATKINS, Clayton, Brian; BHATTI, Nina; TRETTER, Daniel","ATKINS, Clayton, Brian; BHATTI, Nina; TRETTER, Daniel",,US-13260324; IN-656/DELNP/2012; CN-200980160694.2; EP-2009847911
WO2019112235,PCT/KR2018/014836,28.11.2018,WO/2019/112235,13.06.2019,WO,"ELECTRONIC APPARATUS, CONTROL METHOD THEREOF, AND COMPUTER READABLE RECORDING MEDIUM",An electronic apparatus is provided. The electronic apparatus includes a communicator comprising communication circuitry configured to receive a control signal from a remote controller; and a processor configured to determine at least one recommendation key based on a screen corresponding to an image signal and key input history information and to generate a keypad image including a button object in which the at least one recommendation key is arranged to be selectable by a plurality of buttons included in the remote controller.,G06F 3/023; G06F 3/0488; G06N 99/00; H04N 21/422,"SAMSUNG ELECTRONICS CO., LTD.","KIM, Hyungrae",10-2017-0165220 04.12.2017 KR,
WO2019137137,PCT/CN2018/120397,11.12.2018,WO/2019/137137,18.07.2019,WO,ACTIVITY RECOGNITION METHOD USING VIDEOTUBES,"An activity recognition device comprises a port configured to receive a video stream from a video source for a first object and a second object; a memory configured to store instructions and image frames of the video stream; and one or more processors, wherein the one or more processors execute the instructions stored in the memory, the one or more processors configured to: select portions of the image frames based on presence of the first object; determine areas within the portions of image frames, wherein locations of the first object in the video frames are bounded by the determined areas; determine motion of the first object and locations of a second object within the areas of the image frames; and identify an activity according to the determined motion and locations of the second object, and generate an alert according to the identified activity.",G06K 9/46,"HUAWEI TECHNOLOGIES CO., LTD.","PORIKLI, Fatih; XU, Qijie; BILL, Luis; WEI, Huang","15/867,932 11.01.2018 US",
WO2020032661,PCT/KR2019/010034,09.08.2019,WO/2020/032661,13.02.2020,WO,"ELECTRONIC APPARATUS, METHOD FOR CONTROLLING THEREOF, AND METHOD FOR CONTROLLING A SERVER",The disclosure relates to an artificial intelligence (AI) system that uses a machine learning algorithm and an application thereof. A method for controlling an electronic apparatus according to the disclosure includes receiving image data and information associated with a filter set that is applied to an artificial intelligence model for upscaling the image data from an external server; decoding the image data; upscaling the decoded image data using a first artificial intelligence model that is obtained based on the information associated with the filter set; and providing the upscaled image data for output.,H04N 21/4402; H04N 7/01; G06N 3/04,"SAMSUNG ELECTRONICS CO., LTD.","PARK, Taejun; LEE, Sangjo; NA, Sangkwon",10-2018-0093511 10.08.2018 KR,EP-2019762283
WO2003014732,PCT/US2002/016962,24.05.2002,WO/2003/014732,20.02.2003,WO,APPARATUSES AND METHODS FOR CREATING AND TESTING PRE-FORMULATIONS AND SYSTEMS FOR SAME,"The invention provides methods, apparatus, and systems for performing high-throughput preparation and screening of salts and polymporphs of drug candidates. The invention is directed towards enhancing the pre-formulation discovery process used for drug development. In particular, processes that determine suitable salts and processes that discover substantially every polymorph that can form from a particular drug candidate are provided. The processes are performed using several apparatuses that are specifically configured to carry-out various steps in a high-throughput characterization process. One such apparatus is configured for synthesizing a plurality of library members based on, for example, a library model generated by a computer system.",B01J 19/00; B01L 3/00; B01L 3/06; B01L 7/00; C07B 61/00; G01N 5/04; G01N 13/00; G01N 21/65; G01N 33/15; G01N 33/543; G01N 35/02,"SYMYX TECHNOLOGIES, INC.; CARLSON, Eric, D.; CONG, Peijun; CHANDLER, William, H., Jr.; CHAU, Henry, K.; DANIELSON, Earl; DESROSIERS, Peter, J.; DOOLAN, Robert, D.; WU, Luping","CARLSON, Eric, D.; CONG, Peijun; CHANDLER, William, H., Jr.; CHAU, Henry, K.; DANIELSON, Earl; DESROSIERS, Peter, J.; DOOLAN, Robert, D.; WU, Luping","60/311,332 10.08.2001 US",JP-2003519413; EP-2004016266; EP-2002731970; EP-2004016270
WO2014170919,PCT/IT2013/000109,15.04.2013,WO/2014/170919,23.10.2014,WO,METHOD OF CONTROLLING A FORGING SYSTEM AND RELATIVE SYSTEM,"The present invention concerns a method of controlling an open-die forging system (1) comprising at least one actuator (2, 3) for forging a blank (4), to define a workpiece with the required dimensions by an operation sequence (OS) of operation steps for processing said blank (4), the method comprising the steps of: - generating, for each operation step, respective intermediate end dimensions that the blank (4) is required to have at the end of each operation step; - iteratively repeating, for each operation step of said operation sequence (OS), the following steps: - detecting said blank (4) using at least one electromagnetic infrared radiation detection means (8), and generating a dimensional map (Ml) of the blank (4), by analyzing said electromagnetic radiation received by said detection means (8); - estimating the dimensions of said blank (4), using an artificial intelligence system (10), as a function of parameters included in said dimensional map (Ml) and further preset parameters (PGI) in said artificial intelligence system (10), to define estimated dimensions of said blank (4); - determining a reference deviation map (E), as a difference between the estimated dimensions of the blank (4) and the intermediate end dimensions required by the operation step; - adapting said artificial intelligence system (10) as an error function that is designed to reduce said deviation map (E) and determine at least one control signal (Inl, In2) to control said at least one actuator (2, 3).",B21J 5/02; G05B 13/02,VEA S.R.L.,"ROSI, Fabio",,
WO2001024114,PCT/EP2000/009205,19.09.2000,WO/2001/024114,05.04.2001,WO,IMAGE PROCESSING METHOD AND SYSTEM FOR FOLLOWING A MOVING OBJECT IN AN IMAGE SEQUENCE,"An image processing method for processing the images of an image sequence (S) comprising steps (200, 300) of determining image data related to first points of an Object of Interest observed in a first image, said Object of Interest having possible movements, and image data related to correlated points found in a second image of the sequence, and based on said image data, of estimating parameters of sets of transformation functions (400), which transformation functions transform said first points into said correlated points and, from said parameters, of determining one Warping Law (500) that automatically transforms said given Object of Interest of the first image into the same object in the second image of the sequence for following and locating (600) said Object of Interest in said second image of the sequence. Application: Medical imaging, X-ray examination apparatus.",G06T 7/20,KONINKLIJKE PHILIPS ELECTRONICS N.V.,"MAKRAM-EBEID, Shérif",99402392.7 30.09.1999 EP,JP-2001526808; EP-2000964213
WO2016167779,PCT/US2015/026217,16.04.2015,WO/2016/167779,20.10.2016,WO,SPEECH RECOGNITION DEVICE AND RESCORING DEVICE,"A speech recognition device and a rescoring device are constructed that reduce recognition errors, that allow consideration for contexts longer than a discriminative language model and that are robust to unknown contexts to some extent. In the speech recognition device and the rescoring device utilizing a discriminatively trained language model, the discriminatively trained language model is trained based on alignment between a correct sequence and a hypothesis sequence and the discriminatively trained language model is constructed based on a recurrent neural network.",G10L 15/00,"MITSUBISHI ELECTRIC CORPORATION; MITSUBISHI ELECTRIC RESEARCH LABORATORIES, INC.","TACHIOKA, Yuki; WATANABE, Shinji",,JP-2017507782
WO2016150750,PCT/EP2016/055483,15.03.2016,WO/2016/150750,29.09.2016,WO,RESTRAINT MANAGEMENT,"There is provided a restraint management apparatus. The restraint management apparatus comprises a processing unit arranged to: receive one or more types of sensor data; determine a status of a subject based on the received sensor data; determine, based on the determined subject status, a restraint parameter for a restraint device configured to restrain a body part of the subject; and output a signal based on the determined restraint parameter.",G06F 19/00; A61G 7/00; A61B 5/00,KONINKLIJKE PHILIPS N.V.,"VAN DEN HEUVEL, Teun; XIE, Yingrong; HEINRICH, Adrienne; FALCK, Thomas; VAN DER HEIDE, Esther Marjan; GREINER, Harald",15160212.5 23.03.2015 EP,JP-2017549428; EP-2016711556
WO2018078413,PCT/IB2016/001737,31.10.2016,WO/2018/078413,03.05.2018,WO,DRIVING ASSISTANCE METHOD AND SYSTEM,"The present invention concerns a driving assistance method and system (100) for a road vehicle (1). The driving assistance system (100) comprises a sensor set (101), a data storage device (102) and an an output device (104,105). The sensor set (101) detects, within a traffic scene including the road vehicle (1), a set of road users and, for each road user of said set of road users, a current state including a current speed and a current position. The data storage device (102) comprises a finite plurality of behavioral models. The data processor (103), which is connected to the sensor set (101) and to the data storage device (102), assigns a behavioral model, from among the finite plurality of behavioral models, to each road user, probabilistically estimates, for each road user, a belief state comprising a set of alternative subsequent states and corresponding probabilities, each alternative subsequent state including a speed and a position, according to the behavioral model assigned to each road user, and determines a risk of collision of the road vehicle (1) with a road user, based on the probabilistically estimated future state of each road user. The output device (104,105) is connected to the data processor (103) and outputs a driver warning signal and/or executing an avoidance action if the risk of collision exceeds a predetermined threshold.",G08G 1/0962; B62D 15/02; B60W 30/09; B60W 30/095; G06F 3/00; G06K 9/00; G08G 1/16,TOYOTA MOTOR EUROPE; INSTITUT NATIONAL DE RECHERCHE EN INFORMATIQUE ET EN AUTOMATIQUE; INSTITUT NATIONAL DES SCIENCES APPLIQUEES DE LYON,"SIERRA GONZALEZ, David; LAUGIER, Christian; DIBANGOYE, Jilles Steeve; VASQUEZ GOVEA, Alejandro Dizan; VIGNARD, Nicolas",,EP-2016826153
WO2019145756,PCT/IB2018/050508,28.01.2018,WO/2019/145756,01.08.2019,WO,A DATA COMMUNICATION SYSTEM AND METHOD FOR USE OF THE DATA COMMUNICATION SYSTEM,"A data communication system (1) for creating and / or experiencing an internet- based augmented reality content comprising a creator data communication device (10) to be used by a creator, a user data communication device (11) to be used by a user and an internet-based data processing device (12), a method for creating an internet-based augmented reality content using the inventive data communication system (1), and a method for experiencing an internet-based augmented rea!ity content using the inventive data communication system (1).",G06F 17/30,AUGMANIA GmbH i.G.,"REDA, Rania",,
WO2016065487,PCT/CA2015/051117,30.10.2015,WO/2016/065487,06.05.2016,WO,"SYSTEM, METHOD AND APPARATUS FOR PATHOGEN DETECTION","Systems and methods for pathogen detection are described. A method for pathogen detection comprises collecting a sample from a subject, combining the sample with amplification substances, performing detection operations on the combined sample, analyzing the detection signals, and disposing of the combined sample. Embodiments of an apparatus for pathogen detection comprise a microfluidic disk having a plurality of reaction chambers for combining a sample and amplification substances. Further described apparatuses for pathogen detection comprise a storage unit, a sensor unit and a disposal unit.",G01N 33/569; C12M 1/34; C12Q 1/04; C12Q 1/70; C40B 60/12; G01N 1/00; G01N 1/28; G01N 33/577; G06F 19/10; G01N 21/39; G01N 21/47; G01N 21/65,SIGHTLINE INNOVATION INC.,"TRENHOLM, Wallace; CASSIDY, Jason","62/072,590 30.10.2014 US; 62/081,152 18.11.2014 US; 62/157,041 05.05.2015 US",EP-2015854148; CA-2966215
WO2013126711,PCT/US2013/027334,22.02.2013,WO/2013/126711,29.08.2013,WO,VISUALLY ADAPTIVE SURFACES,"A display system can include an optionally removable display that at least partially conforms to a surface of an article. The article and display can be non-flat, having a curved or complex conforming shape. A processing module can automatically create images based on a set of rules operating on at least one of stored user settings, input from a user, local sensor data including but not limited to images captured by a user, or social or other network derived data. An intermediate image can be created for approval by a user, and the image can be modified to conform to display surface for enhanced visual appearance, fashion coordination, advertising, and/or branding of the article supporting the display.",G09G 5/08; G06F 17/24,"BURTZLAFF, Robert; FALCONE, Carmen","BURTZLAFF, Robert; FALCONE, Carmen","61/602,499 23.02.2012 US",
WO2020051704,PCT/CA2019/051289,11.09.2019,WO/2020/051704,19.03.2020,WO,SYSTEM AND METHOD FOR IMPROVING SPEED OF SIMILARITY BASED SEARCHES,"A method and system for processing images for a search is provided, including: receiving a plurality of images selected from search results; for each image in the plurality of images, retrieving a feature vector associated with the image; selecting a subset of the feature vectors based on similarity of feature vectors associated with the images in the plurality of images; and performing a search for feature vectors in a database similar to the feature vectors in the subset of feature vectors.",G06F 16/53; G06K 9/78; H04N 21/80; G06N 20/00; G08B 13/196,AVIGILON CORPORATION,"ALCOCK, Nicholas John; KEDARISETTI, Dharanish; VENETIANER, Peter L.","62/730,215 12.09.2018 US",
WO2007120455,PCT/US2007/008001,30.03.2007,WO/2007/120455,25.10.2007,WO,VALUE INDEX FROM INCOMPLETE DATA,"In a digital image administration method and system, a database of image records is maintained. Data sets are provided. The data sets are each associated with a respective image record. The data sets each include data in a plurality of the categories: capture related data, intrinsic image data, image usage data, and user reaction data. A plurality of the data sets have missing data in different combinations of the categories. A value index of each of the image records is generated from the respective data set. The image records are managed responsive to respective value indexes.",G06F 17/30,"EASTMAN KODAK COMPANY; FEDOROVSKAYA, Elena A.; ENDRIKHOVSKI, Serguei; FREDLUND, John Randall; MANICO, Joseph Anthony","FEDOROVSKAYA, Elena A.; ENDRIKHOVSKI, Serguei; FREDLUND, John Randall; MANICO, Joseph Anthony","11/403,686 13.04.2006 US",EP-2007754514; JP-2009505384
WO2016018258,PCT/US2014/048642,29.07.2014,WO/2016/018258,04.02.2016,WO,SIMILARITY IN A STRUCTURED DATASET,"Detecting similarity in a structured dataset is disclosed. One example is a system including a converter, and an evaluator. A structured dataset is received via a processing system, the dataset including a plurality of objects, each object of the plurality of objects associated with a category, and each category associated with an object label. The converter converts, for each object of the plurality of objects, the object label into a semantic term. The evaluator determines, via the processing system, a term similarity for a pair of object labels in a given category, the term similarity indicative of a correlation between the respective semantic terms in the given category.",G06F 17/00; G06F 17/30,HEWLETT PACKARD ENTERPRISE DEVELOPMENT LP,"LEE, Wei-Nchih; ROLIA, Jerome",,US-15325630
WO2011147925,PCT/EP2011/058652,26.05.2011,WO/2011/147925,01.12.2011,WO,"MULTISCALE MODULUS FILTER BANK AND APPLICATIONS TO PATTERN DETECTION, CLUSTERING, CLASSIFICATION AND REGISTRATION","A digital filter bank having a number J ≥ 1 of stages is disclosed. For each integer j such that 1 ≤ j ≤ J, the j-th stage comprises a plurality of filtering units (20, 21 ) each receiving an input signal of the j-th stage. These filtering units include a low-pass filtering unit (20) using real filtering coefficients and at least one band-pass filtering unit (21) using complex filtering coefficients. Following each band-pass filtering unit of the j-th stage, a respective modulus processing unit (25) generates a processed real signal as a function of squared moduli of complex output values of said band-pass filtering unit. The input signal of the first stage is a digital signal supplied to the digital filter bank, while for 1 < j ≤ J, the input signal of the j-th stage includes the processed real signal generated by at least one modulus processing unit of the (j— 1 )-th stage.",G06K 9/46; G06K 9/52,"ECOLE POLYTECHNIQUE; MALLAT, Stéphane","MALLAT, Stéphane",10305565.3 28.05.2010 EP,US-13698169; EP-2011721545
EP235560716,17209090,20.12.2017,3422200,02.01.2019,EP,METHOD AND SYSTEM FOR HANDLING ONE OR MORE ISSUES IN A COMPUTING ENVIRONMENT,"Disclosed herein is method and system for handling issues in a computing environment. An issue template is generated by mapping problem statements of the issues with system log information of the computing environment. Critical features in the issue templates are determined based on natural language analysis of the issue templates and predetermined parameters associated with the issues. Further, one or more clusters of issues are created based on semantic similarity analysis of the critical features, and finally, a correlation map of various clusters is created to dynamically identify issue resolution scripts required for handling the issues. The present method facilitates automated mapping of an issue to corresponding problem statements and action scripts, thereby eliminating manual intervention associated with classifying and handling of the issues in the computing environment.",G06F 17/27; G06F 11/07; H04L 12/24,WIPRO LTD,VENKATARAMAN ARTHI; ANANTHA AJAY,201741023145 30.06.2017 IN,
WO2015009624,PCT/US2014/046533,14.07.2014,WO/2015/009624,22.01.2015,WO,HEAD-POSE INVARIANT RECOGNITION OF FACIAL EXPRESSIONS,"A system facilitates automatic recognition of facial expressions. The system includes a data access module and an expression engine. The expression engine further includes a set of specialized expression engines, a pose detection module, and a combiner module. The data access module accesses a facial image of a head. The set of specialized expression engines generates a set of specialized expression metrics, where each specialized expression metric is an indication of a facial expression of the facial image assuming a specific orientation of the head. The pose detection module determines the orientation of the head from the facial image. Based on the determined orientation of the head and the assumed orientations of each of the specialized expression metrics, the combiner module combines the set of specialized expression metrics to determine a facial expression metric for the facial image that is substantially invariant to the head orientation.",G06K 9/62,"EMOTIENT, INC.","WHITEHILL, Jacob; MOVELLAN, Javier, R.; FASEL, Ian","13/944,018 17.07.2013 US",
WO2007141809,PCT/IS2007/000014,06.06.2007,WO/2007/141809,13.12.2007,WO,DATA MINING USING AN INDEX TREE CREATED BY RECURSIVE PROJECTION OF DATA POINTS ON RANDOM LINES,"The present invention relates to a method computer program product for datamining with constant search time, the method and computer program product comprises the steps of: traversing a search tree to a leave, retrieving a one or more data store identifier from said leave, read data pointed to by said data store identifier, locating one or more value in said data, referencing one or more data descriptor, retrieve the n-nearest data descriptor neighbors, terminate said search.",G06F 17/30,"HASKOLINN I REYKJAVIK; ASMUNDSSON, Fridrik Heidar; LEJSEK, Herwig; JONSSON, Bjorn Thor","ASMUNDSSON, Fridrik Heidar; LEJSEK, Herwig; JONSSON, Bjorn Thor",8499 06.06.2006 IS,EP-2007736624; US-12303598
WO2018146279,PCT/EP2018/053352,09.02.2018,WO/2018/146279,16.08.2018,WO,DEVICE AND METHOD FOR ANALYZING OBJECTS,"A device and a method for analyzing objects, including buildings, build environments and/or environment areas is proposed. Image data points of an object are gathered and geo-referenced in order to generate object data points. Properties of the object such as material composition, material state or material properties are determined based spectral characteristics evaluation. Three-dimensional object models are generated in accordance with the evaluation of spectral characteristics.",G01N 21/31; G01N 21/35; G01N 21/94; G01S 17/89; G06T 1/00; G06T 7/20; G06T 17/05,VOXELGRID GMBH,"WETZEL, Karl Christian; ANDREOU, Charoula",17000215.8 10.02.2017 EP,CN-201880024022.8; EP-2018706670; JP-2019543811
WO2004042493,PCT/SG2002/000249,24.10.2002,WO/2004/042493,21.05.2004,WO,METHOD AND SYSTEM FOR DISCOVERING KNOWLEDGE FROM TEXT DOCUMENTS,"A method and a system for discovering knowledge from text documents are disclosed, which involve extracting from text documents semi-structured meta-data, wherein the semi-structured meta-data includes a plurality of entities and a plurality of relations between the entities; identifying from the semi-structured meta-data a plurality of key entities and a corresponding plurality of key relations; deriving from a domain knowledge base a plurality of attributes relating to each of the plurality of entities relating to one of the plurality of key entities for forming a plurality of pairs of key entity and a plurality of attributes related thereto; formulating a plurality of patterns, each of the plurality of patterns relating to one of the plurality of pairs of key entity and a plurality of attributes related thereto; analyzing the plurality of patterns using an associative discoverer; and interpreting the output of the associative discoverer for discovering knowledge.",G06F 17/30,"AGENCY FOR SCIENCE, TECHNOLOGY AND RESEARCH; TAN, Ah, Hwee; KANAGASABAI, Rajaraman","TAN, Ah, Hwee; KANAGASABAI, Rajaraman",,JP-null; US-10532163
EP280245512,19184646,05.07.2019,3591582,08.01.2020,EP,METHOD AND SYSTEM FOR AUTOMATIC OBJECT ANNOTATION USING DEEP NETWORK,,G06K 9/62,TATA CONSULTANCY SERVICES LTD,SINGH CHANDAN KUMAR; MAJUMDER ANIMA; KUMAR SWAGAT; BEHERA LAXMIDHAR,201821025354 06.07.2018 IN,
WO2013074092,PCT/US2011/060876,15.11.2011,WO/2013/074092,23.05.2013,WO,MODELING OPERATION OF A TOOL IN A WELLBORE,"In modeling operation of a well tool in applying a force to a device in a well, a computing system receives inputs representing a plurality of geometric characteristics of the well tool. The computing system also receives inputs representing a plurality of geometric characteristics of the well. The computing system determines based on the geometric characteristics of the well tool and the well, a predicted reaction force on a portion of the well tool that affects operation of the well tool in applying force to the device. The predicted reaction force is due to contact between a surface associated with the well tool and a surface of the well.",E21B 44/00; G06F 19/00,"CLEMENS, Jack Gammill; LARIMORE, David Russ; RUBIN, Heru; TRAN, Dominic Anh; WOOD, Josiah; FOX, Philip Edmund; KENNEDY, Ronnie; GARY, Ben","CLEMENS, Jack Gammill; LARIMORE, David Russ; RUBIN, Heru; TRAN, Dominic Anh; WOOD, Josiah; FOX, Philip Edmund; KENNEDY, Ronnie; GARY, Ben",,
WO2016018487,PCT/US2015/030050,09.05.2015,WO/2016/018487,04.02.2016,WO,SYSTEMS AND METHODS FOR BIOMECHANICALLY-BASED EYE SIGNALS FOR INTERACTING WITH REAL AND VIRTUAL OBJECTS,"Systems and methods are provided for discerning the intent of a device wearer primarily based on movements of the eyes. The system can be included within unobtrusive headwear that performs eye tracking and controls screen display. The system can also utilize remote eye tracking camera(s), remote displays and/or other ancillary inputs. Screen layout is optimized to facilitate the formation and reliable detection of rapid eye signals. The detection of eye signals is based on tracking physiological movements of the eye that are under voluntary control by the device wearer. The detection of eye signals results in actions that are compatible with wearable computing and a wide range of display devices.",G06F 3/01; G06K 9/00,"EYEFLUENCE, INC.; CONNAUGHTON, Spencer, James","CONNAUGHTON, Spencer, James; PUBLICOVER, Nelson, George; MARGGRAFF, Lewis, James; DRAKE, Eliot","62/023,940 13.07.2014 US; 62/027,774 22.07.2014 US; 61/991,435 09.05.2014 US; 62/038,984 19.08.2014 US; 62/074,920 04.11.2014 US; 62/074,927 04.11.2014 US; 62/046,072 04.09.2014 US; 62/039,001 19.08.2014 US; 62/027,777 22.07.2014 US",KR-1020167034649; JP-2017511568; EP-2015826370; CN-201580035714.9; AU-2015297035
WO2015017632,PCT/US2014/049081,31.07.2014,WO/2015/017632,05.02.2015,WO,ADVANCED TREATMENT RESPONSE PREDICTION USING CLINICAL PARAMETERS AND ADVANCED UNSUPERVISED MACHINE LEARNING: THE CONTRIBUTION SCATTERGRAM,"The present invention provides a method for detection of different ontologies using advanced unsupervised machine learning which will be used to visualize factors not visible to the human observer, such as unknown characteristics between imaging datasets and other factors to provide insights into the structure of the data. This methodology is referred to herein as Contribution Scattergram. An example includes using radiological images to determine a relationship in dimension, structure, and distance between each parameter. This information can be used to determine if changes in the images have occurred and for treatment response.",G06T 7/00; A61B 5/055; A61B 6/03,THE JOHNS HOPKINS UNIVERSITY,"JACOBS, Michael A.; AKHBARDEH, Alireza","61/860,426 31.07.2013 US",US-14909154
WO2019245578,PCT/US2018/038961,22.06.2018,WO/2019/245578,26.12.2019,WO,MULTI-MODAL VIRTUAL EXPERIENCES OF DISTRIBUTED CONTENT,"Systems and techniques are described herein for providing a beholder, via a user interface on a user experience device, with a multi-faceted and flexibly-dimensional virtual experience of one or more target identities placed in a subject matter context. A systems aspects include selecting, finding, and interpreting digital content pertaining to a subject matter context indicated by the beholder; deconstructing digital content into discrete content elements containing content segments that are classified according to a schema of element facets, and then constructing a facet-segmented repository of discrete content elements pertaining to a target identity; supplementing existing digital content with supplemental information and content to support the presentation of expanded information content, dimensions, or sensory capabilities; and creating and presenting a virtual experience container that is adapted to the beholder and the capabilities of the beholders user experience device.",G06F 17/30; G06F 3/01,VIRTUAL ALBUM TECHNOLOGIES LLC,"HOWARD, Todd",,
WO2015080558,PCT/MY2014/000153,29.05.2014,WO/2015/080558,04.06.2015,WO,A METHOD AND SYSTEM FOR AUTOMATED ENTITY RECOGNITION,"The present invention provides a system for extracting concept and named-entities from a text-containing document. An entity recognition eagine (102) is provided to process an entity with a Rule-based Named-Entity Recognition (NER) (122), a Natural-Language-Processing (NLP) based NER (124), and a knowledge-based NER (126). The NERs are further scored and weighted, wherein the highest weighted score will be taken. A method thereof is also provided.",G06F 17/27,MIMOS Berhad,"CHU MIN XIAN, Benjamin; BAHLS, Daniel; LUKOSE, Dickson",PI 2013004281 27.11.2013 MY,
EP249989443,19154865,31.01.2019,3522079,07.08.2019,EP,DATA ENCODING AND CLASSIFICATION,,G06N 10/00; G06N 3/04; G06N 3/08,SIEMENS HEALTHCARE LTD,MOUNTNEY PETER; PIAT SEBASTIEN; HERBSTER MARK; SEVERINI SIMONE,201801627 01.02.2018 GB,
WO2019036652,PCT/US2018/046950,17.08.2018,WO/2019/036652,21.02.2019,WO,"SYSTEMS, MEDIA, AND METHODS FOR CONDUCTING INTELLIGENT WEB PRESENCE REDESIGN","Disclosed are systems, media, and methods for automatically and intelligently redesigning a web presence by: ingesting files of an existing web site; extracting content from the ingested files; surveying a user for user preferences; determining a style package based on the user preferences; selecting a web site skeleton from a plurality of preconfigured web site skeletons based on the user preferences, the web site skeleton having a plurality of hierarchical blocks; applying a machine learning system to rank the extracted content; populating the content into the hierarchy of blocks based on the rank; automatically generating a redesigned web site by applying the style package to the populated web site skeleton; and providing an interface allowing the user to edit the style package, the content, and the web site skeleton.",G06F 17/22,CML MEDIA CORP.,"BERNAL, Eric, George; BERNAL, Scott, Eric; LEVINE, Cary, Michael; RICH, Thomas, William; PATEL, Shanket, Rajendra","62/547,593 18.08.2017 US",
WO2017025860,PCT/IB2016/054653,02.08.2016,WO/2017/025860,16.02.2017,WO,ANNOTATION OF VIDEOS WITH TAG CORRECTNESS PROBABILITIES,"A system and methodology provide for annotating videos with entities and associated probabilities of existence of the entities within video frames. A computer-implemented method identifies an entity from a plurality of entities identifying characteristics of video items. The computer-implemented method selects a set of features correlated with the entity based on a value of a feature of a plurality of features, determines a classifier for the entity using the set of features, and determines an aggregation calibration function for the entity based on the set of features. The computer-implemented method selects a video frame from a video item, where the video frame having associated features, and determines a probability of existence of the entity based on the associated features using the classifier and the aggregation calibration function.",G06F 17/30,GOOGLE INC.,"VARADARAJAN, Balakrishnan; TODERICI, George; NATSEV, Apostol; KHANDELWAL, Nitin; VIJAYANARASIMHAN, Sudheendra; YANG, Weilong; SHETTY, Sanketh","14/823,946 11.08.2015 US",EP-2016754561
WO2019060889,PCT/US2018/052641,25.09.2018,WO/2019/060889,28.03.2019,WO,ARTIFICIAL INTELLIGENCE (AI) CHARACTER SYSTEM CAPABLE OF NATURAL VERBAL AND VISUAL INTERACTIONS WITH A HUMAN,"Systems and methods herein are directed to an artificial intelligence (AI) character capable of natural verbal and visual interactions with a human. In one embodiment, an AI character system receives, in real-time, one or both of an audio user input and a visual user input of a user interacting with the AI character system. The AI character systems determines one or more avatar characteristics based on the one or both of the audio user input and the visual user input of the user. The AI character system manages interaction of an avatar with the user based on the one or more avatar characteristics.",G06N 5/00,"VENTANA 3D, LLC","LEMBERSKY, Roman; BORKE, Michael, James; BEZIRGANYAN, Hayk; CROWDER, Ashley; CONWAY, Benjamin; VU, Hoang, Son; BEHMKE, James, M.","62/562,592 25.09.2017 US; 62/620,682 23.01.2018 US",
EP13833944,02291145,06.05.2002,1259071,20.11.2002,EP,"Method for modifying a user interface of a consumer electronic apparatus, corresponding consumer electronic apparatus","According to the invention a user interface UI (5) of a consumer electronic apparatus is modified, which can be used for example to update a given basic UI functionality or to temporarily implement isolated, dedicated UI sub-domains. For this purpose side information is received comprising side information components for controlling the user interface and validity information defining the validity start and/or end time of the side information components. The side information components and validity information is stored (9) and the user interface is modified (10) by using said stored side information components. The start time and/or end time of the user interface modification is controlled (11) by means of said stored validity information. <IMAGE>",G06F 3/048; H04N 5/445; G10L 15/22; H04N 5/00; H04N 7/08; H04N 7/088; H04N 7/16; H04N 7/24,THOMSON LICENSING,SCHILLER HARALD,01111737 15.05.2001 EP; 02291145 06.05.2002 EP,
WO2016142696,PCT/GB2016/050626,07.03.2016,WO/2016/142696,15.09.2016,WO,AMBIENT IONIZATION MASS SPECTROMETRY IMAGING PLATFORM FOR DIRECT MAPPING FROM BULK TISSUE,"A method of ion imaging is disclosed that includes automatically sampling a plurality of different locations on a sample (20) using a first device (21) which is arranged and adapted to generate aerosol, smoke or vapour from the sample (20). Mass spectral data and/or ion mobility data corresponding to each location is obtained and the obtained mass spectral data and/or ion mobility data is used to construct, train or improve a sample classification model.",G01N 33/68,MICROMASS UK LIMITED,"JONES, Emrys; PRINGLE, Steven Derek; TAKÁTS, Zoltán",1503876.3 06.03.2015 GB; 1503879.7 06.03.2015 GB; 1503864.9 06.03.2015 GB; 1503877.1 06.03.2015 GB; 1516003.9 09.09.2015 GB; 1503867.2 06.03.2015 GB; 1503863.1 06.03.2015 GB; 1503878.9 06.03.2015 GB; 1518369.2 16.10.2015 GB,GB-1713942.9; US-15555818; EP-2016710793
WO2014128610,PCT/IB2014/059066,18.02.2014,WO/2014/128610,28.08.2014,WO,NATURAL LANGUAGE UNDERSTANDING AND SEMANTIC CONTENT DISCOVERY,"Disclosed are systems, apparatuses, circuits and methods for extrapolating meaning from vocalized speech or otherwise obtained text. Speech of a speaking user is sampled and digitized, the digitized speech is converted into a text stream, the text stream derived from speech or otherwise obtained is analyzed syntactically and semantically, a knowledgebase in the specific context domain of the text stream is utilized to construct one or more semantic/syntactic domain specific query analysis constrains/rule-sets, and a ""Domain Specific Knowledgebase Query"" (DSKQ) or set of queries is built at least partially based on the domain specific query analysis constrains/rule-sets.",G10L 15/183,JINNI MEDIA LTD.,"MESHULAM, Ram; RIMON, Mordechai Mori; BEN-ZAKEN, Izhak","13/771,705 20.02.2013 US",
WO2018142228,PCT/IB2018/000524,19.01.2018,WO/2018/142228,09.08.2018,WO,"SYSTEMS, METHODS, APPARATUSES AND DEVICES FOR DETECTING FACIAL EXPRESSION AND FOR TRACKING MOVEMENT AND LOCATION INCLUDING FOR AT LEAST ONE OF A VIRTUAL AND AUGMENTED REALITY SYSTEM","Systems, methods, apparatuses and devices for detecting facial expressions according to EMG signals for a virtual and/or augmented reality (VR/AR) environment, in combination with a system for simultaneous location and mapping (SLAM), are presented herein.",G06K 9/00,MINDMAZE HOLDING SA,"TADI, Tej; LEEB, Robert; BOURDAUD, Nicolas; BOLOMEY, Leandre; GARIPELLI, Gangadhar; MENSI, Skander; PILET, Julien; NGO, Dal; LEBRUN, Yann; GIROUX, Arthur; CARDIN, Sylvain; MERLINI, Nicolas","62/448,373 19.01.2017 US; 62/481,760 05.04.2017 US",EP-2018733666
WO2019217129,PCT/US2019/029762,30.04.2019,WO/2019/217129,14.11.2019,WO,EFFICIENT DATA ENCODING FOR DEEP NEURAL NETWORK TRAINING,"Functions are added to a deep neural network (""DNN"") computation graph for encoding data structures during a forward training pass of the DNN and decoding previously-encoded data structures during a backward training pass of the DNN. The functions added to the DNN computation graph can be selected based upon on the specific layer pairs specified in the DNN computation graph. Once a modified DNN computation graph has been generated, the DNN can be trained using the modified DNN computation graph. The functions added to the modified DNN computation graph can reduce the utilization of memory during training of the DNN.",G06N 3/08; G06N 3/04; G06F 9/50,"MICROSOFT TECHNOLOGY LICENSING, LLC","PHANISHAYEE, Amar; PEKHIMENKO, Gennady; JAIN, Animesh","62/669,696 10.05.2018 US; 16/024,311 29.06.2018 US",
EP26571729,10180591,10.06.2005,2336770,22.06.2011,EP,Methods for identifying conditions affecting a cell state,"The present invention is directed to methods of identifying agents which affect cell state. The instant invention provides rapid and efficient methods for identifying agents which affect cell state. Methods are directed toward the screening of complex combinations of agents for their ability to affect cell state. In one embodiment, cells are incubated under suitable conditions and subjected to different agents. After an appropriate amount of time, the cells are assayed to determine what, if ant characteristics they possess. Cell characteristics can be organised in a manner such that different and novel cell states can be identified.",G01N 33/50; G01N 33/48; G06F 19/00,TRANSFORM PHARMACEUTICALS INC,LEVINSON DOUGLAS; KITSOS CHRISTINE; MELNIKOVA IRENA; MCNULTY CHRISTOPHER,05760335  ; 600964 P  ; EP20050760335  ; US20040600964P  ; 05760335 10.06.2005 EP; 60096404 12.08.2004 US,
WO2018132187,PCT/US2017/063438,28.11.2017,WO/2018/132187,19.07.2018,WO,CHARACTERISTIC-BASED SPEECH CODEBOOK SELECTION,"An apparatus includes a speech processing engine configured to receive data corresponding to speech and to determine whether a first characteristic associated with the speech differs from a reference characteristic by at least a threshold amount. The apparatus further includes a selection circuit responsive to the speech processing engine. The selection circuit is configured to select a particular speech codebook from among a plurality of speech codebooks based on the first characteristic differing from the reference characteristic by at least the threshold amount. The particular speech codebook is associated with the first characteristic. This first characteristic is based on an emotion of the user, an environement of the user, and estimated age of the user or an estimated distance of the user from a microphone.",G10L 19/00; G10L 25/51; G10L 25/30; G10L 25/63,QUALCOMM INCORPORATED,"GUO, Yinyi; VISSER, Erik","15/405,159 12.01.2017 US",CN-201780079428.1
EP206611067,17173150,26.05.2017,3249581,29.11.2017,EP,CONTROLLED AUTHENTICATION OF PHYSICAL OBJECTS,"A physical object is scanned and a digital image of the object is generated from the scan. At least one subset of the image, known as an ""authentication region"" is selected. A plurality of feature vectors, arising from the physical structure of the object, are extracted from certain locations of interest within an authentication region and combined to generate a unique identifier or ""digital fingerprint"" for that object. Preferably, authentication regions for feature vector extraction are automatically selected by a software process. To identify or authenticate an object, a system may compare a digital fingerprint of an object to digital fingerprints previously stored in a database. Digital fingerprint data may specify a set of features (also termed ""locations of interest"") which may be referenced in the creation of a ""fingerprint template"" which is a template of certain locations of interest and/or attributes selected for authenticating a particular class of objects.",G06K 9/00,ALITHEON INC,WITHROW JUSTIN LYNN; ROSS DAVID JUSTIN,201662342147 26.05.2016 US; 201715600566 19.05.2017 US,
WO1995003526,PCT/AU1994/000409,20.07.1994,WO/1995/003526,02.02.1995,WO,AN INSPECTION SYSTEM FOR A CONDUIT,"An inspection system for a conduit comprising measurement means for travelling in the conduit and obtaining data on the conduit, and processing means for processing the data to identify regions of the conduit corresponding to defects in the conduit. The measurement means may be laser scanning means and sonar scanning means.",F16L 55/26; G01C 7/06; G01M 3/00; G01N 29/265; G01N 29/44; H04N 7/18,"COMMONWEALTH SCIENTIFIC AND INDUSTRIAL RESEARCH ORGANISATION; MELBOURNE WATER CORPORATION; MACINTYRE, Ian, Barry; KEARNEY, Patrick, Dale; FONG, Jensen, Lok, Chueng; ROBERTS, Michael, Vaughan; ROGERS, Kevin, John; SHARPE, Ron; GIBERT, Jacek; MASHFORD, John, Sebastian; PARKER, Robert, Andrew; RAHILLY, Michael, Albert; JENSEN, Murray, John","MACINTYRE, Ian, Barry; KEARNEY, Patrick, Dale; FONG, Jensen, Lok, Chueng; ROBERTS, Michael, Vaughan; ROGERS, Kevin, John; SHARPE, Ron; GIBERT, Jacek; MASHFORD, John, Sebastian; PARKER, Robert, Andrew; RAHILLY, Michael, Albert; JENSEN, Murray, John",PM 0024 20.07.1993 AU,EP-1994922792
EP249469736,18161856,14.03.2018,3518149,31.07.2019,EP,FEEDBACK LOOP FOR IMAGE-BASED RECOGNITION,,G06K 9/62; G06K 9/00; G06N 3/02,MASHGIN INC,SRIVASTAVA ABHINAI; DHANKHAR MUKUL; LI YONG; OLSON MAXWELL WILLIAM,201815883355 30.01.2018 US,
WO2019133098,PCT/US2018/056790,19.10.2018,WO/2019/133098,04.07.2019,WO,MICROFLUIDIC PLATFORM FOR TIME-RESOLVED TISSUE AND ORGANISM ANALYSIS,A microfluidic system includes an automated platform for culturing embryos with hyperspectral imaging. The microfluidic system further includes a plurality of static chips on the automated platform for providing a fresh medium exchange with minimal embryo motion. The plurality of static chips is compatible with traditional benchtop tools.,B01L 3/00; C12Q 1/04; G01N 1/18; G01N 1/36; G01N 33/50; G01N 33/53,PRESIDENT AND FELLOWS OF HARVARD COLLEGE,"NOVAK, Richard; CHOE, Youngjae; NESTOR, Bret","62/575,265 20.10.2017 US",
WO2002056254,PCT/GB2002/000093,10.01.2002,WO/2002/056254,18.07.2002,WO,MONITORING SYSTEM,"A method for obtaining a record of the playing and performance characteristics of one or more players of a game is by video recording the game with spaced apart cameras, processing the images obtained using a visual recognition system to obtain a record of one or more playing or performance characteristic of any player or group of players. The record can be used as a coaching aid, to program a virtual player in a computer game or can be retransmitted.",G06T 7/20,"SOUTH BANK UNIVERSITY ENTERPRISES LTD.; ORWELL, James, Matthew; SEELEY, Philip, John","ORWELL, James, Matthew; SEELEY, Philip, John",0100579.2 10.01.2001 GB,JP-null
WO2019179496,PCT/CN2019/079054,21.03.2019,WO/2019/179496,26.09.2019,WO,METHOD AND SYSTEM FOR RETRIEVING VIDEO TEMPORAL SEGMENTS,"A method and a system for retrieving video temporal segments are provided. In the method, a video is analyzed to obtain frame feature information of the video; the frame feature information is input into an encoder to output first data relating to temporal information of the video; the first data and a retrieval description for retrieving video temporal segments of the video are input into a decoder to output second data; attention computation training is conducted according to the first data and the second data; video temporal segments of the video corresponding to the retrieval description are determined according to the attention computation training.",G06K 9/00; G06K 9/62; G06N 3/04; G06N 3/08,"GUANGDONG OPPO MOBILE TELECOMMUNICATIONS CORP., LTD.","HSIAO, Jenhao; HO, Chiuman","62/646,834 22.03.2018 US",
WO2020006154,PCT/US2019/039356,26.06.2019,WO/2020/006154,02.01.2020,WO,CONTEXTUAL DRIVER MONITORING SYSTEM,"Systems and methods are disclosed for contextual driver monitoring. In one implementation, one or more first inputs are received and processed to determine a state of a driver present within a vehicle. One or more second inputs are receiving and processed to determine navigation condition(s) associated with the vehicle, the navigation condition(s) including a temporal road condition received from a cloud resource or a behavior of the driver. Based on the navigation condition(s), a driver attentiveness threshold is computed. One or more actions are initiated in correlation with the state of the driver and the driver attentiveness threshold.",B60Q 9/00; G06K 9/00,"KATZ, Itay; ANAVI, Tamir; STEINBERG, Erez","KATZ, Itay; ANAVI, Tamir; STEINBERG, Erez","62/690,309 26.06.2018 US; 62/757,298 08.11.2018 US; 62/834,471 16.04.2019 US",
WO2019113308,PCT/US2018/064240,06.12.2018,WO/2019/113308,13.06.2019,WO,ACTIVE ADAPTATION OF NETWORKED COMPUTE DEVICES USING VETTED REUSABLE SOFTWARE COMPONENTS,"A method includes receiving a text description of a system capability request, and converting the text description into a normalized description of the system capability request. A repository is then queried, based on the normalized description and using a search algorithm, to identify multiple candidate application software units (ASUs). The candidate ASUs are displayed to a user for selection. The user-selected ASU is then deployed, either locally or to at least one remote compute device, in response to receiving the user selection. Deployment can include the user-selected candidate ASU being integrated into a local or remote software package, thus defining a modified software package that is configured to provide the system capability.",G06F 9/06; G06F 9/44; G06F 9/45; G06F 15/16; G06F 17/30; G06F 17/50,"FRANCHITTI, Jean-Claude","FRANCHITTI, Jean-Claude","62/594,922 05.12.2017 US",
WO1994020952,PCT/US1994/002542,08.03.1994,WO/1994/020952,15.09.1994,WO,METHOD AND APPARATUS FOR VOICE-INTERACTIVE LANGUAGE INSTRUCTION,Spoken-language instruction method and apparatus employ context-based speech recognition for instruction and evaluation. A finite state grammar set (113) corresponding to the range of word sequence patterns in the lesson is employed as a constraint on a hidden Markov model (HMM) search apparatus in an HMM speech recognizer (112). The invention includes a system with an interactive decision mechanism which employs at least three levels of error tolerance to simulate a natural level of patience in human-based interactive instruction. A linguistically-sensitive utterance endpoint detector is provided for judging termination of a spoken utterance to simulate human turn-taking in conversational speech.,G09B 19/04; G09B 19/06; G09B 7/04; G10L 15/14; G10L 15/193; G10L 15/22; G10L 15/183,SRI INTERNATIONAL,"RTISCHEV, Dimitry; BERNSTEIN, Jared, C.; CHEN, George, T.; BUTZBERGER, John, W.","08/032,850 12.03.1993 US",CA-2158062; EP-1994910890
WO2011044322,PCT/US2010/051763,07.10.2010,WO/2011/044322,14.04.2011,WO,NON-INVASIVE OCULAR ANALYTE SENSING SYSTEM,"A noninvasive method and apparatus for determining analyte concentration (e.g., glucose) in a subject that includes measuring light refraction from at least a portion one or more structures. One example of such structure is the subject's iris.",A61B 5/00,"THE UNIVERSITY OF TOLEDO; CAMERON, Brent, D.; WEBB, Anthony","CAMERON, Brent, D.; WEBB, Anthony","61/249,551 07.10.2009 US",US-13500706
EP251065501,19155788,06.02.2019,3531416,28.08.2019,EP,SYSTEM FOR PROCESSING USER UTTERANCE AND CONTROLLING METHOD THEREOF,,G10L 15/18; G06F 17/27; G10L 15/22; G10L 15/30,SAMSUNG ELECTRONICS CO LTD,BYUN DOOHO; KIM WOONSOO; UM TAEKWANG; KIM HYUNKYUNG; PARK JOOHEE; YEO JAEYUNG,20180021845 23.02.2018 KR,
EP14036878,02254425,25.06.2002,1376484,02.01.2004,EP,Method and apparatus for processing signals in testing currency items,A method of testing a document comprises deriving a plurality of measurements from the document at a resolution R and processing the measurements to derive values at a different resolution. <IMAGE>,G06T 3/40; G07D 7/20; G07D 7/12; G06T 3/40; G07D 7/00; G07D 7/20,MARS INC,ANOUAR FATIHA; BAUDAT GASTON,02254425 25.06.2002 EP,
WO2008085857,PCT/US2008/000071,04.01.2008,WO/2008/085857,17.07.2008,WO,PROCESSING TEXT WITH DOMAIN-SPECIFIC SPREADING ACTIVATION METHODS,"A method for performing natural language processing of free text using domain- specific spreading activation. Embodiments of the present invention ontologize free text using an algorithm based on neurocognitive theory by simulating human recognition, semantic, and episodic memory approaches. Embodiments of the invention may be used to process clinical text for assignment of billing codes, analyze suicide notes or legal discovery materials, and for processing other collections of text. Further, embodiments of the invention may be used to more effectively search large databases, such as a database containing a large number of medical publications.",G06F 17/27,"CHILDREN'S HOSPITAL MEDICAL CENTER; PESTIAN, John","PESTIAN, John","60/878,718 04.01.2007 US",
WO2019007524,PCT/EP2017/067037,06.07.2017,WO/2019/007524,10.01.2019,WO,TRACKING OBJECTS IN SEQUENCES OF DIGITAL IMAGES,"The invention relates to a system for tracking objects in a temporal sequence of digital images. The system is configured to: - detect potential objects in the images, the detected potential objects being indicated as nodes, identify pairs of neighboring nodes, such that for each pair the nodes of said pair potentially represent an identical object and their spatial and/or temporal relationship with each other is within a predetermined range, - connect each pair of neighboring nodes with a first type edge, - identify at least one supplementary pair of distant nodes whose spatial and/or temporal relationship with each other exceeds the predetermined range, connect the pair of distant nodes with a supplementary second type edge, each of the first and second type edges being assigned a cost value representing a probability whether the connected nodes represent an identical object or not, and determine a track of an object in the temporal sequence of digital images based on a set of connected first type edges and at least one second type edge additionally connecting at least one of the nodes connected by the set of connected first type edges. The invention further relates to a system of tracking objects in a temporal sequence of digital images.",G06K 9/00; G06K 9/62,TOYOTA MOTOR EUROPE; MAX-PLANCK-GESELLSCHAFT ZUR FÖRDERUNG DER WISSENSCHAFTEN E.V.,"OLMEDA REINO, Daniel; SCHIELE, Bernt; ANDRES, Björn; ANDRILUKA, Mykhaylo; TANG, Siyu",,DE-112017007724
WO1995034045,PCT/US1995/007006,02.06.1995,WO/1995/034045,14.12.1995,WO,INTENSITY TEXTURE BASED CLASSIFICATION SYSTEM AND METHOD,"A method for classifying objects within a specimen as likely to be premalignant or malignant cells includes the steps of forming an intensity image (20) of a specimen, calculating and storing the maximum and minimum grey scale values at a plural number of distances from a pixel in the intensity image, finding the difference between the maximum and the minimum grey scale values at like distances from the pixel, determining the slope of the log of the differences as a function of the log of the distances, storing the slope at the pixel location in a resultant image (24), and identifying objects in the intensity image as likely to be malignant or premalignant based on the value of the slope (22).",G06T 7/00; G06T 7/40,"NEUROMEDICAL SYSTEMS, INC.","RECHT, Joel, M.","08/253,713 03.06.1994 US",CA-2191599; EP-1995923692; CN-95193865.7
WO2013088353,PCT/IB2012/057213,12.12.2012,WO/2013/088353,20.06.2013,WO,MEDICAL IMAGING RECONSTRUCTION OPTIMIZED FOR RECIPIENT,A database (52)stores image recipient reconstruction profiles each comprising image reconstruction parameter values. An image reconstruction module (30)is configured to reconstruct medical imaging data to generate a reconstructed image. An image reconstruction setup module (50)is configured to retrieve an image recipient reconstruction profile from the database (52) for an intended image recipient associated with a set of medical imaging data and to invoke the image reconstruction module (30) to reconstruct the set of medical imaging data using image reconstruction parameter values of the retrieved image recipient reconstruction profile to generate a reconstructed image for the intended image recipient. A feedback acquisition module (54)is configured to acquire feedback from the intended image recipient pertaining to the reconstructed image for the intended image recipient. A profile updating module (56)is configured to update the image recipient reconstruction profile of the intended image recipient based on the acquired feedback.,G06F 19/00,KONINKLIJKE PHILIPS N.V.,"COLLINS, John, Patrick; TUNG, Chi-Hua; ZHANG, Bin","61/576,063 15.12.2011 US",JP-2014546708; EP-2012821185; US-14363917
EP195090232,15306661,16.10.2015,3156942,19.04.2017,EP,SCENE LABELING OF RGB-D DATA WITH INTERACTIVE OPTION,A method (2000) for establishing category labels for an image commences by preprocessing a captured data to map it to a 3-D point cloud (2002). The pre-processed multi-modality data is segmented into super voxels and image patches (2004). Features are learned from the segmented image and the 3-D point cloud (2006) and are fused (2008). Pre-trained classifiers are applied (2010) and thereafter scene labels are generated based on the application of the classifiers (2012).,G06K 9/62; G06K 9/00,THOMSON LICENSING,LUO TAO,15306661 16.10.2015 EP,
WO1991019248,PCT/US1990/003067,30.05.1990,WO/1991/019248,12.12.1991,WO,NEURAL NETWORK USING VIRTUAL-ZERO,"A virtual-zero architecture is intended for use in a single instruction stream, multiple data stream (SIMD) processor which includes an input bus, an input unit, manipulation units, an output unit and an output bus. The virtual-zero architecture includes a memory unit (40) for storing data, an arithmetic unit (42) for mathematically operating on the data, a memory address generation unit (32) and an adder for computing a next memory address. The memory address generation unit (32) includes an address register (34) in the memory unit for identifying the address of a particular data block, a counter (38) for counting the number of memory addresses in a particular data block, and a rotation register (36) for providing a data-void address in the memory unit if and only if all of the entries in the data block are zero. The memory (40) and the address (32) units provide zero-value data blocks to the arithmetic unit (44) to simulate the data block having the data-void address during processing. The architecture may also be used to selectively handle input to a system.",G06N 3/04,"ADAPTIVE SOLUTIONS, INC.; HAMMERSTROM, Daniel, W.","HAMMERSTROM, Daniel, W.",,EP-1990913599
EP137965679,14198105,16.12.2014,2889806,01.07.2015,EP,"Image processing device, image processing system, mobile object control apparatus, image recognition method, and carrier means","An image processing device (20, 30) and carrier means are provided, The image processing device (20, 30) recognizes an object in a specified imaging area, and includes a first feature obtaining unit (31) configured to obtain a feature from a polarized image obtained by capturing the imaging area based on a difference in polarization data between local areas of an area indicating the shape of an object to be recognized, and an object recognition unit (32, 34, 35) configured to recognize the object to be recognized using the feature obtained by the first feature obtaining unit (31). The carrier means carries computer readable code for controlling a computer system (200) to carry out the method performed by the image processing device (20, 30).",G06K 9/00; G06K 9/20,RICOH CO LTD,KASAHARA RYOSUKE,2013273083 27.12.2013 JP,
WO2013108073,PCT/IB2012/003120,06.12.2012,WO/2013/108073,25.07.2013,WO,TEXT MINING ANALYSIS AND OUTPUT SYSTEM,"A natural language authoring system that organizes technical, financial, legal and market information into Point of View specific analytical, visual and narrative decision-support content. The expert system transforms a user's point of view into a tailored narrative and/or visualization report. Expert rules embed interactive advertising, such as affiliate URL links, into analytical, visual and narrative and statistical content. The rules may be modified by one or more users, thereby capturing knowledge as the rules are utilized by users of the system.",G06F 17/30,"PERCEPTION PARTNERS, INC.",,"61/567,359 06.12.2011 US",EP-2012866278
WO1991006908,PCT/BR1990/000019,30.10.1990,WO/1991/006908,16.05.1991,WO,CIRCUITRY AND MICROPROGRAMMING OF A NON-VON NEUMANN COMPUTER FOR ACQUISITION OF AN AUTOMATIC PROGRAMMING (SOFTWARE),"The invention refers basically to a new computational architecture, ''Non Von Neumann'' type, which allows the insertion in memory devices of RAM, ROM family and others, from any microprogramming (firmware), by using a machine mathematical language, being represented by bits ''strings'' (0/1) of the Boolean Mathematics, or by means of numerical transformed of the functions correspondent to these microprogramming, originate from the Boolean Algebra, and/or isomorphic technical Linguistics. We could create a new computational architecture, represented by the ''ESÇAO (n,m,p)'' machine where the present microprocessor is no more a basic subsystem, passing to be a peripheral, sometimes convocated to perform certain tasks, in accordance with an established microprogramming, mathematically and automatically, by programmes aided by conventional computers.",G06F 7/00; G06F 9/22; G06F 15/78,"UNIVERSIDADE DE SÃO PAULO - USP; WERNECK MARTINS, Wagner; DOMINGUES DA SILVA, Edison, Gilberto","WERNECK MARTINS, Wagner; DOMINGUES DA SILVA, Edison, Gilberto",PI 8905536 30.10.1989 BR,
EP195090234,16193212,11.10.2016,3156944,19.04.2017,EP,SCENE LABELING OF RGB-D DATA WITH INTERACTIVE OPTION,"It is provided a method for generating labels for an image; comprising: mapping image data and depth information of said image to a 3D point cloud; segmenting the 3-D point cloud and the image into super voxels and image patches; fusing features obtained from the super voxels and image patches, by using a fusion model; applying classifiers to fused features, wherein the fusion model and the classifiers are generated from a dataset including image data of selected quality and quantity, corresponding point cloud and image labels; and generating scene labels based on applied classifiers.",G06K 9/62; G06K 9/00,THOMSON LICENSING,LUO TAO,15306661 16.10.2015 EP,
EP192502576,16157638,26.02.2016,3133539,22.02.2017,EP,METHOD ANS SYSTEM FOR PROCESS AUTOMATION IN COMPUTING,"The embodiments herein disclose a method and system for process automation in computing by implementing a Robotic Process Automation software arm component used for automation of tasks that involves transactional activities like reading from a document ,application ,writing into a system or application and so on. The process automation allows workflow generation for automation of business user activities on numerous operating systems and works with multiple platforms, environments and applications. Further, a process automation system also supports handling of runtime environment exceptions and audit log. A separate interface is not required by user for (easy) maintenance, as the interface supports admin configuration and run mode access. Internal/embedded documentation of process and unit level control on automation is supported while also supporting automating keyboard activities, mouse operations, wait/smart wait time feature, visual interaction and so on.",G06Q 10/06; G06F 9/44; G06Q 10/10,TATA CONSULTANCY SERVICES LTD,SHARMA SUJATA; DIXIT SEJAL DEEPAK; PATEL VANDANA; KAMALI ZUBER; AGRAWAL PARIDHI,3154MU2015 19.08.2015 IN,
WO2018230832,PCT/KR2018/004610,20.04.2018,WO/2018/230832,20.12.2018,WO,IMAGE PROCESSING APPARATUS AND METHOD USING MULTI-CHANNEL FEATURE MAP,"A convolution neural network (CNN)-based image processing method and apparatus are provided. The CNN-based image processing method includes identifying whether values of pixels of each of feature maps having a plurality of channels at a first layer are zero, and storing information regarding a result of identifying whether the values of the pixels are zero; writing image feature information of the feature maps at the first layer to an external memory; reading information regarding pixels having values which are not zero among the written image feature information from the external memory based on the information regarding the result of identifying whether the values of the pixels are zero; and performing a feature map operation at a second layer using the read image feature information of the feature maps.",G06T 1/20; G06T 1/60; G06T 5/40; G06T 5/00; G06N 3/02,"SAMSUNG ELECTRONICS CO., LTD.","LEE, Won-jae; CHOI, Yong-seok; KIM, Min-soo",10-2017-0075818 15.06.2017 KR,EP-2018818948; CN-201880030783.4
WO2018203951,PCT/US2018/017592,09.02.2018,WO/2018/203951,08.11.2018,WO,CLASSIFYING FACIAL EXPRESSIONS USING EYE-TRACKING CAMERAS,Images of a plurality of users are captured concurrently with the plurality of users evincing a plurality of expressions. The images are captured using one or more eye tracking sensors implemented in one or more head mounted devices (HMDs) worn by the plurality of first users. A machine learnt algorithm is trained to infer labels indicative of expressions of the users in the images. A live image of a user is captured using an eye tracking sensor implemented in an HMD worn by the user. A label of an expression evinced by the user in the live image is inferred using the machine learnt algorithm that has been trained to predict labels indicative of expressions. The images of the users and the live image can be personalized by combining the images with personalization images of the users evincing a subset of the expressions.,G06K 9/00; G06K 9/46; G06K 9/62,GOOGLE LLC,"SUD, Avneesh; HICKSON, Steven; KWATRA, Vivek; DUFOUR, Nicholas","62/492,861 01.05.2017 US; 15/831,823 05.12.2017 US",CN-201880009128.0; EP-2018707479
WO2019211178,PCT/EP2019/060704,26.04.2019,WO/2019/211178,07.11.2019,WO,METHODS AND SYSTEMS FOR AUTOMATIC OBJECT RECOGNITION AND AUTHENTICATION,"The present invention relates to the field of tracing and anti-counterfeit protection of objects, e.g. products,and particularly to an automatic recognition and authentication of such objects.Specifically, the invention relates to a system and a method of receiving object data representing one or more discriminating characteristics of a physical object or group of physical objects. The method comprises: processing the object data by means of a machine-learning-based object recognition process to obtain discriminating data representing one or more collision resistant virtual representations of the physical object or group of physical objects; comparing at least one of the discriminating data and an original hash value derived therefrom by application of a pre-determined cryptographic hash function thereto with corresponding reference data stored in one or more data repositories with restricted access; and, if said comparison with the reference data results in a match, outputting digitally signed identification data comprising said hash value. Potential applications of the invention comprise particularly object authenticity checks for track & trace and anti- counterfeiting purposes, for example without limitation in the fields of automotive/aerospace spare parts, 3D-printed objects,pharmaceutical products or other health-related products, such health-care products, lab disposables, and clinical test disposables.",G06K 9/00; H04L 9/32; G06K 9/62,MERCK PATENT GMBH,"ENDRESS, Thomas; SZABO, Daniel; BERKERMANN, Frederic",18170047.7 30.04.2018 EP,
WO1998028963,PCT/IB1997/001358,30.10.1997,WO/1998/028963,02.07.1998,WO,METHOD AND APPARATUS FOR OPTIMIZING THE LAYOUT AND CHARGE MAPS OF A FLOWLINE OF PICK AND PLACE MACHINES,"An apparatus uses a computer-controlled algorithm that enables production of high-quality layouts and charge maps or set-ups for arbitrary printed circuit boards for electronic components placement machines alone or as one of many in a production line. A class of algorithms known as genetic algorithms employing an initial population of chromosomes are used. Each chromosome represents a set of parameters that control how a layout and charge maps are generated. Problem descriptors, based on one time code are generated. An adaptive searcher searches parameters and generates trial solutions as chromosomes and a heuristic layout generator interprets these chromosomes to generate the layout and charge maps using the problem descriptors.",G06N 3/12; H05K 13/04,KONINKLIJKE PHILIPS ELECTRONICS N.V.; PHILIPS NORDEN AB,"SCHAFFER, James, David; MANI, Murali","08/772,392 23.12.1996 US",KR-1019980706525; EP-1997945041
WO2014005609,PCT/EP2012/002865,06.07.2012,WO/2014/005609,09.01.2014,WO,PARAGRAPH ALIGNMENT DETECTION AND REGION-BASED SECTION RECONSTRUCTION,"A paragraph alignment detection engine and a section reconstruction engine. The paragraph alignment detection engine determines the paragraph alignment of a paragraph and updates the paragraph alignment property of the paragraph in the data store for single line and multi-line paragraphs. The paragraph alignment detection engine employs per paragraph comparisons and relative comparisons to other paragraphs to determine the paragraph alignment of a single line paragraph. The paragraph alignment detection engine employs per paragraph comparisons and relative comparisons of the lines of a paragraph to determine the paragraph alignment of a multiline paragraph. The section reconstruction engine minimizes the number of sections created in the flow format document by identifying the columns on each page, combining contiguous pages with the same column layout into a single section, and creating alternative objects to contain regions associated special cases in lieu of creating additional sections.",G06K 9/00,"MICROSOFT CORPORATION; SESUM, Milan; LAZAREVIC, Milos; RASKOVIC, Milos; OBULJEN, Aljosa; PANJEVIC, Filip; TANKOVIC, Vanja Petrovic","SESUM, Milan; LAZAREVIC, Milos; RASKOVIC, Milos; OBULJEN, Aljosa; PANJEVIC, Filip; TANKOVIC, Vanja Petrovic",,US-13704172
WO2018100244,PCT/FI2017/050838,29.11.2017,WO/2018/100244,07.06.2018,WO,AUDIO PROCESSING,A method comprising: causing analysis of a portion of a visual scene; causing modification of a first sound object to modify a spatial extent of the first sound object in dependence upon the analysis of the portion of the visual scene corresponding to the first sound object; and causing rendering of the visual scene and the corresponding sound scene including of the modified first sound object with modified spatial extent.,H04S 3/00; G06K 9/00; G11B 27/28; G11B 27/031; H04S 7/00,NOKIA TECHNOLOGIES OY,"ERONEN, Antti; LEPPÄNEN, Jussi; CRICRI, Francesco; LEHTINIEMI, Arto",1620422.4 01.12.2016 GB,EP-2017876577
WO2017011713,PCT/US2016/042382,15.07.2016,WO/2017/011713,19.01.2017,WO,"MEDICATION IDENTIFICATION, TRACKING, AND ADHERENCE MANAGEMENT","A method and a wellness adherence tracking system (WATS) for tracking wellness adherence of a healthcare recipient are provided. An identifier code or an existing code is positioned on a medical implement, for example, a medication bin, a parenteral device, a fitness device, etc. The WATS accessible on a user device scans, decodes, and validates the identifier code, and obtains medical information associated with the medical implement and/or an activity, for example, an exercise activity, a diet activity, etc., associated with the medical implement from the decoded and validated identifier code. The WATS renders the medical information and multiple wellness adherence options on a graphical user interface and receives inputs for the wellness adherence options from the user device. The WATS logs the received inputs in association with the wellness adherence criteria in the user device and/or one or more databases to track the wellness adherence of the healthcare recipient.",G06F 19/00,RXADVANCE CORPORATION,"JAIN, Yogendra, K.; DUCEY, Paul; IKA, Ravi, V; TATI, Anand, M; GOPALADASU, Srinivas, Venkata Naga; TALLABATTULA, Prakash, Surya","14/800,689 15.07.2015 US",CA-2992465; EP-2016825222
WO1998026368,PCT/EP1997/006974,11.12.1997,WO/1998/026368,18.06.1998,WO,"METHOD AND APPARATUS FOR EXTRACTING FEATURES CHARACTERISING OBJECTS, AND USE THEREOF","A method of extracting features characterising objects consists in discriminating an object from a context, the discriminating step comprising, determining the context consisting of at least two objects, choosing a topic object from the context, deriving feature sets of the topic object and the other objects in the context, judging whether there is at least one distinctive feature set in the feature sets, deriving a new feature set if there is not a distinctive feature set amongst the feature sets, and registering one of the distinctive feature sets as an outcome; and restarting the discriminating step when there exists an object which is not discriminated from the other objects. This method represents a selectionist approach to the characterisation of objects, driven by a discrimination task. There is also an apparatus putting this method into practice and a system for autonomous development of a common vocabulary by a plurality of agents incorporating the method and/or apparatus.",G06K 9/62,"SONY CORPORATION; STEELS, Luc","STEELS, Luc",96402700.7 11.12.1996 EP,EP-1997952932; US-09117824
WO2015119674,PCT/US2014/061283,19.10.2014,WO/2015/119674,13.08.2015,WO,WIDE AREA AUGMENTED REALITY LOCATION-BASED SERVICES,"Apparatus, methods and systems of providing AR content are disclosed. Embodiments of the inventive subject matter can obtain an initial map of an area, derive views of interest, obtain AR content objects associated with the views of interest, establish experience clusters and generate a tile map tessellated based on the experience clusters. A user device could be configured to obtain and instantiate at least some of the AR content objects based on at least one of a location and a recognition.",G06T 19/00; G06F 17/30,"NANT HOLDINGS IP, LLC","MCKINNON, David; WNUK, Kamil; SUDOL, Jeremi; SIDDIQUI, Matheen; WIACEK, John; SONG, Bing; WITCHEY, Nicholas J.","61/892,238 17.10.2013 US; 14/517,728 17.10.2014 US",
WO2016145480,PCT/AU2016/000096,21.03.2016,WO/2016/145480,22.09.2016,WO,SEMANTIC KNOWLEDGE BASE,"A system for categorising and referencing a document using an electronic processing device, wherein: the electronic processing device reviews the content of the document to identify structures within the document; wherein the identified structures are referenced against a library of structures stored in a database; wherein the document is categorised according to the conformance of the identified structures with those of the stored library of structures; and wherein the categorised structure is added to the stored library.",G06N 5/00; G06F 17/30; G06F 17/27,SEMANTIC TECHNOLOGIES PTY LTD,"TONKIN, Albert Donald; LE, Dung Xuan Thi","62/135,560 19.03.2015 US",
WO2012101093,PCT/EP2012/050994,23.01.2012,WO/2012/101093,02.08.2012,WO,SYSTEMS AND METHODS FOR MEDICAL USE OF MOTION IMAGING AND CAPTURE,"A motion sensing and capture system to provide to a patient and/or healthcare provider, patient motion data and/or motion impairment data, which can be used as a diagnostic, predictive or therapeutic tool. Such method comprises the steps of: (a) selecting one or more patient motions; (b) using a sensing and capture system to image an initial set comprising the one or more motions to provide an initial set of motion data; and (c) conveying such initial set of motion data to a patient and/or healthcare provider.",A61B 5/11; A61H 5/00; G06T 7/20,"NOVARTIS AG; VARAKLIS, John; SMITH, Craig","VARAKLIS, John; SMITH, Craig","61/436,074 25.01.2011 US",JP-2013550849; US-13981557; CA-2825009; RU-2013139172; AU-2012210593; EP-2012700514; KR-1020137022293; MX-MX/a/2013/008610
WO2004019187,PCT/US2003/026990,26.08.2003,WO/2004/019187,04.03.2004,WO,RELATING MEDIA TO INFORMATION IN A WORKFLOW SYSTEM,"A method for relating media to information in a workflow system provides pre-processed Natural Language Processing (NLP) tables of a database of informational content such as text documents, Web pages, images, video, music, etc., that provide information pertaining to a statistical and heuristic analysis of the informational content and description of the content. The tables are used for algorithmic comparison to other documents and media. The invention can be used in workflow applications and media applications, e.g., television set top boxes. The invention performs real time analysis of incoming media content or workflow content and algorithmically matches informational content that pertain to the media or workflow content and algorithmically matches informational content that pertain to the media or workflow content using the pre-processed tables. This is through algorithmic analysis of the text in, and/or associated with, the informational content and the text in or associated with the incoming media content or workflow content. Referrals to any related informational documents and/or media are sent to the appropriate workflow or media application and are displayed to a user. The user can select any of the related documents for display or use in the workflow or media application.",G06F 17/22,"SIFTOLOGY, INC.","SHORT, Gordon; MYSERSDORF, Doron","60/406,010 26.08.2002 US",JP-null
WO2019006381,PCT/US2018/040417,29.06.2018,WO/2019/006381,03.01.2019,WO,INTELLIGENT ENDPOINT SYSTEMS FOR MANAGING EXTREME DATA,"A system and methods are provided that can make distributed and autonomous decision science based recommendations, decisions, and actions that increasingly become smarter and faster over time. The system can comprise intelligent computing devices and components (i.e., Intelligent Endpoint Systems) at the edge or endpoints of the network (e.g., user devices or IoT devices). Each of these Intelligent Endpoint Systems can optionally have the ability to transmit and receive new data or decision science, software, data, and metadata to other intelligent devices and third party components and devices so that data or decision science, whether real-time or near real-time, batch, or manual processing, can be updated and data or decision science driven queries, recommendations and autonomous actions can be broadcasted to other Intelligent Endpoint Systems and third party systems in real-time or near real-time.",G06F 15/16; G06Q 20/38; H04L 9/32,"FACET LABS, LLC","OGAWA, Stuart; SPARKS, Lindsay; NISHIMURA, Koichi; SO, Wilfred P.","62/528,014 30.06.2017 US; 62/540,499 02.08.2017 US",
WO2013150286,PCT/GB2013/050858,02.04.2013,WO/2013/150286,10.10.2013,WO,METHOD FOR LOCALIZING A VEHICLE EQUIPPED WITH TWO LIDAR SYSTEMS,"A method of localising transportable apparatus (200) within an environment includes receiving (402) data obtained from a first ranging sensor device (202) that is configured to collect information relating to a 2D representation of an environment (301) through which the transportable device is moving. Further data is received (404), that data being obtained from a second ranging sensor device (204) of the transportable apparatus configured to collect information relating to at least a surface (218) over which the transportable apparatus is moving. The ranging sensor device data is used (406) to estimate linear and rotational velocities of the transportable apparatus and the estimates are used (408) to generate a new 3D point cloud (212) of the environment. The method seeks to match (412) the new 3D point cloud with, or within, existing 3D point cloud (216) in order to localise the transportable apparatus with respect to the existing point cloud.",G01S 17/87; G01S 17/58; G01S 7/48; G01S 17/89; G06T 7/00; G01C 21/00,THE CHANCELLOR MASTERS AND SCHOLARS OF THE UNIVERSITY OF OXFORD,"NEWMAN, Paul, Michael; BALDWIN, Ian, Alan",1205895.4 02.04.2012 GB,EP-2013715420; US-14389723
EP12949716,97301810,18.03.1997,0810807,03.12.1997,EP,Method and apparatus for analysing network data,"A network monitoring and diagnosis apparatus comprises a processor (500), data storage device (501, 504), graphical user interface (401), data mining means (505), data visualization means (506), data correlation means (507), and problem solving means. Performance data signals generated periodically by a communications network are collected by a network controller (400). The collected performance data is continuously mined, examining the data for performance parameters which are outside preset limits. Performance data outside preset limits is displayed on a graphical user interface, in a format determined by the visualization means. Performance parameters which are out of limits are correlated with other related parameters, information on which is available from the performance data signals, and patterns of parameter changes are identified by the correlation means. For performance parameters which are outside limits, a problem solving means (508) examines the out of limit performance data and generates suggested solutions to underlying problems resulting in out of limit performance parameters. <IMAGE>",H04L 12/70; H04Q 3/00; H04Q 11/04,NORTHERN TELECOM LTD,BURN-THORNTON KATHRYN ELIZABET,9611403 31.05.1996 GB,
EP209579810,16191608,29.09.2016,3264225,03.01.2018,EP,A METHOD AND A SYSTEM FOR OPTIMIZING BATTERY USAGE OF AN ELECTRONIC DEVICE,"A method and a system are provided for optimizing battery usage of an electronic device. The method comprises determining, by a battery optimization unit, a degree of criticality of environment in which one or more sensors are operating based on one or more pre-defined conditions. The method further comprises determining, by the battery optimization unit, a plurality of parameters comprising an energy level of the electronic device, an available processing power, and an available communication network bandwidth associated with the electronic device. The method further comprises processing, by the battery optimization unit, a first portion of sensor data locally based on the degree of criticality of environment and a priority based rule engine, wherein the priority based rule engine is configured to optimize battery usage of the electronic device based on the plurality of parameters.",G06F 1/32; G08B 13/196; G08B 29/18; H04N 19/132; H04N 19/156; H04N 19/164,WIPRO LTD,RAMACHANDRA MANJUNATH,201641022131 28.06.2016 IN,
EP203793796,17150982,11.01.2017,3217324,13.09.2017,EP,HYBRID DETECTION RECOGNITION SYSTEM,"A system and method for determining an object or product represented in an image is disclosed. The system receives a first image, determines a region of interest in the first image, determines a classification score for the region of interest using a convolutional neural network that assigns the region of interest the classification score corresponding to a class, and identifies a first product in the first image based on the classification score.",G06K 9/32; G06K 9/46; G06K 9/62,RICOH CO LTD,KWON JUNGHYUN; NARASIMHA RAMYA; SCHWARTZ EDWARD L; MCFARLAND MAX; SAVARESE SILVIO; BERKNER KATHRIN,201615199553 30.06.2016 US; 201662304713 07.03.2016 US,
EP231575465,18160825,08.03.2018,3385901,10.10.2018,EP,MACHINE LEARNING SPARSE COMPUTATION MECHANISM,"An apparatus to facilitate processing of a sparse matrix is disclosed. The apparatus includes a plurality of processing units each comprising one or more processing elements, including logic to read operands, a multiplication unit to multiply two or more operands and a scheduler to identify operands having a zero value and prevent scheduling of the operands having the zero value at the multiplication unit.",G06T 1/20,INTEL CORP,NURVITADHI ERIKO; VEMBU BALAJI; LIN TSUNG-HAN; SINHA KAMAL; BARIK RAJKISHORE; GALOPPO VON BORRIES NICOLAS C,201715482791 09.04.2017 US,
WO2016153690,PCT/US2016/019263,24.02.2016,WO/2016/153690,29.09.2016,WO,3D MODEL RECOGNITION APPARATUS AND METHOD,"In embodiments, apparatuses, methods and storage media (transitory and non-transitory) are described that receive a first 3D model of a 3D object, and determine a second 3D model to replace the first 3D model, wherein the second 3D model is a fuller representation of the 3D object than the first 3D model. In embodiments, the second 3D model may be manipulated, metadata corresponding to a material property of the 3D object may be provided, 3D models of component parts of the 3D object may be provided, or the second 3D model may be used to construct an object with a 3D printer. Other embodiments may be described and/or claimed.",G06K 9/00; G06T 17/00,INTEL CORPORATION,"TATOURIAN, Igor; CHAHAL, Sudip S.; YEE, Norman; YELLAREDDY, Greeshma","14/670,000 26.03.2015 US",
EP12948473,97303358,16.05.1997,0817028,07.01.1998,EP,Mechanism for dispatching requests in a distributed object system,"Data structures, methods and devices for reducing computing overhead associated with dispatching a distributed object invocation and improving the flexibility of the dispatch framework in a distributed client/server based computing system are disclosed. In one aspect of the invention, a request received on an end point in a transport layer is dispatched from the transport layer to a subcontract in a subcontract layer where the request is partially unmarshaled and dispatched from the subcontract to a skeleton function in a skeleton layer where a servant is invoked.",G06F 9/44; G06F 9/46; G06F 13/00; G06F 9/46,SUN MICROSYSTEMS INC,LIM SWEE BOON; RADIA SANJAY R; CAVANAUGH III KEN M; CALLSEN CHRISTIAN J,670700  ; US19960670700  ; 67070096 26.06.1996 US,
WO2006134388,PCT/GB2006/002225,19.06.2006,WO/2006/134388,21.12.2006,WO,"A METHOD OF ANALYSING AUDIO, MUSIC ORVIDEO DATA","Meta-data or tags are generated by analysing audio, music or video data; a database stores audio, music or video data; and a processing unit analyses the data to generate the meta-data in conformance with an ontology. Ontology-based approaches are new in this context. A logical processing unit infers knowledge from the meta-data.",G06F 17/30,"QUEEN MARY AND WESTFIELD COLLEGE; SANDLER, Mark; RAIMOND, Yves; ABDALLAH, Samer","SANDLER, Mark; RAIMOND, Yves; ABDALLAH, Samer",0512435.9 17.06.2005 GB,DE-null; US-11917601; EP-2006744249
WO2017131975,PCT/US2017/013517,13.01.2017,WO/2017/131975,03.08.2017,WO,DETECTING SECURITY THREATS BY COMBINING DECEPTION MECHANISMS AND DATA SCIENCE,"Provided are systems, methods, and computer-program products for a network device, configured to use data science techniques to manage the deployment of deception mechanisms in a network, where the deception mechanisms can attract and detect threats to the network. In various implementations, the network device can receive network data. The network data can include data produced by an interaction with a deception mechanism. The deception mechanism can be part of the security of the network. An interaction can include a potential threat to the network. The network device can further be configured to analyze the network data using a data science engine, including identifying a pattern of network behavior. The network device can further generate an attack pattern that includes the behavior of the potential threat. The network device can further use the attack pattern to modify deception mechanisms on the network.",H04L 29/06; H04L 12/24,"ACALVIO TECHNOLOGIES, INC.","GUKAL, Sreenivas; VARADARAJAN, Rammohan","62/286,564 25.01.2016 US; 62/344,267 01.06.2016 US",
WO2001040522,PCT/US2000/032787,04.12.2000,WO/2001/040522,07.06.2001,WO,SHORT SHARED NUCLEOTIDE SEQUENCES,"A method of selecting sets of short shared nucleotide sequences from amongst members of nucleic acid populations and identifying subsets of those selected short shared nucleotide sequences that differentiate those members from one another. Probes corresponding to the sets of short shared nucleotide sequences can be synthesized and utilized, inter alia, to detect target nucleic acids in a sample population, to provide expression profiles, or to identify polymorphisms of a gene. The invention also includes integrated systems for performing various steps involved in the method and certain probe compositions.",G06F 17/30,"PIONEER HI-BRED INTERNATIONAL, INC.; ANANIEV, Evgueni, V.","ANANIEV, Evgueni, V.","60/169,157 06.12.1999 US",
WO2017078886,PCT/US2016/055735,06.10.2016,WO/2017/078886,11.05.2017,WO,GENERIC MAPPING FOR TRACKING TARGET OBJECT IN VIDEO SEQUENCE,A method of tracking a position of a target object in a video sequence includes identifying the target object in a reference frame. A generic mapping is applied to the target object being tracked. The generic mapping is generated by learning possible appearance variations of a generic object. The method also includes tracking the position of the target object in subsequent frames of the video sequence by determining whether an output of the generic mapping of the target object matches an output of the generic mapping of a candidate object.,G06K 9/46; G06K 9/66; G06N 3/04; G06T 7/20; G06K 9/62,QUALCOMM INCORPORATED,"TAO, Ran; GAVVES, Efstratios; SMEULDERS, Arnold Wilhelmus Maria","62/251,544 05.11.2015 US; 15/192,935 24.06.2016 US",
EP209989354,16752902,16.02.2016,3259578,27.12.2017,EP,MODEL-BASED METHODS AND TESTING APPARATUS FOR CLASSIFYING AN INTERFERENT IN SPECIMENS,,G01N 21/25; G01J 3/46; G01J 3/50; G01N 21/59; G01N 21/94; G06T 7/00,SIEMENS HEALTHCARE DIAGNOSTICS INC,PARK JINHYEONG; CHANG YAO-JEN; WU WEN; CHEN TERRENCE; POLLACK BENJAMIN,201562117263 17.02.2015 US; 2016018062 16.02.2016 US,
WO2020005922,PCT/US2019/038958,25.06.2019,WO/2020/005922,02.01.2020,WO,SYSTEM AND METHOD FOR A DYNAMIC RESOURCE ALLOCATION ENGINE,"A dynamic resource allocation engine which can assist in automating activities and processes within an organization. More specifically, the concepts disclosed herein can reduce operational costs by eliminating unnecessary devices, processes, and/or personnel, while also providing an efficient mechanism for testing the effects of new resources on the entire system. This is done by first combining data associated with devices, processes, and personnel, in a common (normalized) data format. This combination represents a simulation of the business or enterprise associated with the data, and can be referred to as a ""resource allocation engine."" The resource allocation engine provides information about how resources are being used within the organization.",G06F 15/02,"WALMART APOLLO, LLC","O'BRIEN, John J.; MCHALE, Brian; HIGH, Donald R.; ABDULSAHIB, Muhenned","62/689,638 25.06.2018 US",
WO2017163230,PCT/IL2017/050230,23.02.2017,WO/2017/163230,28.09.2017,WO,METHOD AND SYSTEM FOR CONVERTING AN IMAGE TO TEXT,"In a method of converting an input image patch to a text output, a convolutional neural network (CNN) is applied to the input image patch to estimate an n-gram frequency profile of the input image patch. A computer-readable database containing a lexicon of textual entries and associated n-gram frequency profiles is accessed and searched for an entry matching the estimated frequency profile. A text output is generated responsively to the matched entries.",G06K 9/46; G06K 9/62,RAMOT AT TEL-AVIV UNIVERSITY LTD.,"WOLF, Lior; POZNANSKI, Arik","62/312,560 24.03.2016 US",US-16086646; EP-2017769556
EP231425365,18164657,28.03.2018,3382697,03.10.2018,EP,"VOICE SERVER, VOICE RECOGNITION SERVER SYSTEM, AND METHOD OF OPERATING THE SAME","A method of operating a voice server is disclosed. The method includes receiving voice data from a home appliance, converting the received voice data into text data, analyzing the text data to determine a voice command, transmitting a signal corresponding to the determined voice command to a predetermined server, receiving a response signal based on the determined voice command from the predetermined server, and converting a response signal based on the voice command into voice data and transmitting the response signal to the home appliance, thereby effectively recognizing and processing a voice command.",G10L 15/22,LG ELECTRONICS INC,YIM TAEHYEONG; KWON MINGU; KIM SUNGHAK; SHIN KYUYEOL; OH JEONGKYU; HAN DONGWOO,20170041050 30.03.2017 KR,
WO2016044920,PCT/CA2015/000504,23.09.2015,WO/2016/044920,31.03.2016,WO,"OPERATING ROOM BLACK-BOX DEVICE, SYSTEM, METHOD AND COMPUTER READABLE MEDIUM","A multi-channel recorder/encoder for collecting, integrating, synchronizing and recording medical or surgical data received as independent live or real-time data streams from a plurality of hardware units. The medical or surgical data relating to a live or real-time medical procedure. Example hardware units include a control interface, cameras, sensors, audio devices, and patient monitoring hardware. Further example systems may include a cloud based platform incorporating the encoder.",A61B 19/00; A61G 99/00; G06F 19/00; H04L 12/16; H04L 29/14; H04L 7/00,SURGICAL SAFETY TECHNOLOGIES INC.,"GRANTCHAROV, Teodor Pantchev","62/054,057 23.09.2014 US; 62/138,647 26.03.2015 US",CA-2961970; EP-2015843858; US-15512992
WO2019148315,PCT/CN2018/074548,30.01.2018,WO/2019/148315,08.08.2019,WO,VISUAL QUESTION ANSWERING USING VISUAL KNOWLEDGE BASES,An example apparatus for visual question answering includes a receiver to receive an input image and a question. The apparatus also includes an encoder to encode the input image and the question into a query representation including visual attention features. The apparatus includes a knowledge spotter to retrieve a knowledge entry from a visual knowledge base pre-built on a set of question-answer pairs. The apparatus further includes a joint embedder to jointly embed the visual attention features and the knowledge entry to generate visual-knowledge features. The apparatus also further includes an answer generator to generate an answer based on the query representation and the visual-knowledge features.,G06F 17/30,"INTEL CORPORATION; SU, Zhou; LI, Jianguo; DONG, Yinpeng; CHEN, Yurong","SU, Zhou; LI, Jianguo; DONG, Yinpeng; CHEN, Yurong",,
WO2020072972,PCT/US2019/054819,04.10.2019,WO/2020/072972,09.04.2020,WO,A CROSS REALITY SYSTEM,"A cross reality system that provides an immersive user experience by storing persistent spatial information about the physical world that one or multiple user devices can access to determine position within the physical world and that applications can access to specify the position of virtual objects within the physical world. Persistent spatial information enables users to have a shared virtual, as well as physical, experience when interacting with the cross reality system. Further, persistent spatial information may be used in maps of the physical world, enabling one or multiple devices to access and localize into previously stored maps, reducing the need to map a physical space before using the cross reality system in it. Persistent spatial information may be stored as persistent coordinate frames, which may include a transformation relative to a reference orientation and information derived from images in a location corresponding to the persistent coordinate frame.",G06T 19/00; G06F 3/0482; G06F 3/0486; G06K 9/46; G06K 9/52,"MAGIC LEAP, INC.; MOHAN, Anush; TAYLOR, Robert, Blake; MIRANDA, Jeremy, Dwayne; TORRES, Rafael, Domingos; OLSHANSKY, Daniel; SHAROKNI, Ali; GUENDELMAN, Eran; KRAMER, Nick; TOSSELL, Ken; MILLER, Samuel A.; TAJIK, Jehangir; SWAMINATHAN, Ashwin; AGARWAL, Lomesh; SINGHAL, Prateek; HOLDER, Joel, David; ZHAO, Xuan; CHOUDHARY, Siddharth; SUZUKI, Helder, Toshiro; BAROT, Hiral, Honar","MOHAN, Anush; TAYLOR, Robert, Blake; MIRANDA, Jeremy, Dwayne; TORRES, Rafael, Domingos; OLSHANSKY, Daniel; SHAROKNI, Ali; GUENDELMAN, Eran; KRAMER, Nick; TOSSELL, Ken; MILLER, Samuel A.; TAJIK, Jehangir; SWAMINATHAN, Ashwin; AGARWAL, Lomesh; SINGHAL, Prateek; HOLDER, Joel, David; ZHAO, Xuan; CHOUDHARY, Siddharth; SUZUKI, Helder, Toshiro; BAROT, Hiral, Honar","62/812,935 01.03.2019 US; 62/742,237 05.10.2018 US; 62/868,786 28.06.2019 US; 62/815,955 08.03.2019 US; 62/870,954 05.07.2019 US; 62/884,109 07.08.2019 US",
WO2018187170,PCT/US2018/025307,30.03.2018,WO/2018/187170,11.10.2018,WO,CONTOUR BASED DEFECT DETECTION,"Methods and systems for detecting defects in patterns formed on a specimen are provided. One system includes one or more components executed by one or more computer subsystems, and the component(s) include first and second learning based models. The first learning based model generates simulated contours for the patterns based on a design for the specimen, and the simulated contours are expected contours of a defect free version of the patterns in images of the specimen generated by an imaging subsystem. The second learning based model is configured for generating actual contours for the patterns in at least one acquired image of the patterns formed on the specimen. The computer subsystem(s) are configured for comparing the actual contours to the simulated contours and detecting defects in the patterns formed on the specimen based on results of the comparing.",G06T 7/00; G06K 9/46; G06T 7/13,KLA-TENCOR CORPORATION,"GUPTA, Ajay; MAHADEVAN, Mohan; VENKATARAMAN, Sankar; YANG, Hedong; KARSENTI, Laurent; CARMON, Yair; BULLKICH, Noga; DANINO, Udy","62/483,223 07.04.2017 US; 15/896,060 14.02.2018 US",KR-1020197033064; CN-201880023809.2
WO2012145273,PCT/US2012/033833,16.04.2012,WO/2012/145273,26.10.2012,WO,SYSTEMS AND METHODS FOR AUTOMATICALLY DETERMINING AN IMPROVED VIEW FOR A VISUAL QUERY IN A MOBILE SEARCH,"Systems and methods for automatically determining an improved view for a visual query in a mobile location or object search are provided. In some embodiments, methods for automatically determining an improved view for a visual query in a mobile location or object search system include obtaining at least one data set based on a prior visual query, wherein the at least one data set includes at least a top location or object and one or more other locations or objects; retrieving at least one distinctiveness measurement for one or more locations or objects in the at least one data set; and determining the improved view based on the retrieved at least one distinctiveness measurement.",G06K 9/62,"THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK; CHANG, Shih-fu; YU, Xinnan; JI, Rong-rong; ZHANG, Tongtao","CHANG, Shih-fu; YU, Xinnan; JI, Rong-rong; ZHANG, Tongtao","61/477,844 21.04.2011 US",US-13983265
EP231425366,18164658,28.03.2018,3382698,03.10.2018,EP,"VOICE SERVER, VOICE RECOGNITION SERVER SYSTEM, AND METHOD OF OPERATING THE SAME","A method of operating a voice server is disclosed. The method includes receiving voice data from a home appliance, converting the received voice data into text data, analyzing the text data to determine a voice command, and transmitting a signal corresponding to the determined voice command to a predetermined server, thereby effectively recognizing and processing a voice command.",G10L 15/22,LG ELECTRONICS INC,KIM SUNGHAK; KWON MINGU; SHIN KYUYEOL; OH JEONGKYU; YIM TAEHYEONG; HAN DONGWOO,20170041055 30.03.2017 KR,
WO2007008583,PCT/US2006/026328,07.07.2006,WO/2007/008583,18.01.2007,WO,IMPROVED PROTEIN EXPRESSION COMPARISON ASSAY RESULTS AND APPLICATIONS,The invention proves a method and means to produce protein expression comparison assay results and for using the improved protein expression comparison results for producing improved results for any other application which utilizes said improved protein expression results.,G01N 33/48; C12Q 1/00,"KOHNE, David, E.","KOHNE, David, E.","60/697,118 07.07.2005 US",EP-2006786471; DE-null
WO2003079276,PCT/US2002/020423,28.06.2002,WO/2003/079276,25.09.2003,WO,PORTABLE OBJECT IDENTIFICATION AND TRANSLATION SYSTEM AND METHOD,"A portable information system is comprised of an input device for capturing an image having a user-selected object or text, and a background. A hand-held computer is responsive to the input device and is programmed to: distinguish the user-selected object/text from the background; compare the user-selected object to a database of objects/characters; and output a translation of, information about, or interpretation of, the user-selected object or text in response to the step of comparing. The invention is particularly useful as a portable aid for translating or remembering text messages foreign to the user that are found in visual scenes. A second important use is to provide mobile information and guidance to the mobile user in connection with surrounding objects (such as, identifying landmarks, people, and/or acting as a navigational aid). Methods of operating the present invention are also disclosed.",G06F 1/16; G06K 9/22,"MOBILE TECHNOLOGIES, INC.","WAIBEL, Alex","10/090,559 04.03.2002 US",JP-null
WO2020047420,PCT/US2019/049082,30.08.2019,WO/2020/047420,05.03.2020,WO,METHOD AND SYSTEM FOR FACILITATING RECOGNITION OF VEHICLE PARTS BASED ON A NEURAL NETWORK,"One embodiment facilitates recognizing parts of a vehicle. A convolution module is configured to generate a convolution feature map of a vehicle image. A region proposal module is configured to determine, based on the convolution feature map, one or more proposed regions, wherein a respective proposed region corresponds to a target of a respective vehicle part. A classification module is configured to determine a class and a bounding box of a vehicle part corresponding to a proposed region based on a feature of the proposed region. A conditional random field module is configured to optimize classes and bounding boxes of the vehicle parts based on correlated features of the corresponding proposed regions. A reporting module is configured to generate a result which indicates a list including an insurance claim item and corresponding damages based on the optimized classes and bounding boxes of the vehicle parts.",G06K 9/00; G06K 9/62,ALIBABA GROUP HOLDING LIMITED,"QUO, Qingpei","201811014381.3 31.08.2018 CN; 16/555,790 29.08.2019 US",
EP243305306,18207882,22.11.2018,3493119,05.06.2019,EP,LANGUAGE PROCESSING METHOD AND APPARATUS,,G06N 3/04; G06F 17/27; G06F 17/28; G06N 3/08,SAMSUNG ELECTRONICS CO LTD,LEE MIN-JOONG; LEE HODONG,20170165397 04.12.2017 KR,
WO2019067641,PCT/US2018/052988,26.09.2018,WO/2019/067641,04.04.2019,WO,SYSTEMS AND METHODS FOR VISUAL INSPECTION BASED ON AUGMENTED REALITY,"A system for visual inspection includes: a scanning system configured to capture images of an object and to compute a three-dimensional (3-D) model of the object based on the captured images; an inspection system configured to: compute a descriptor of the object based on the 3-D model of the object; retrieve metadata corresponding to the object based on the descriptor; and compute a plurality of inspection results based on the retrieved metadata and the 3-D model of the object; and a display device system including: a display; a processor; and a memory storing instructions that, when executed by the processor, cause the processor to: generate overlay data from the inspection results; and show the overlay data on the display, the overlay data being aligned with a view of the object through the display.",G06F 3/01; G06F 17/30; G06F 17/50; H04N 13/117; G01N 21/95; G01N 23/02; G01N 27/90,"AQUIFI, INC.","DAL MUTTO, Carlo; TRACHEWSKY, Jason; ZUCCARINO, Tony","62/563,560 26.09.2017 US",
WO1999005851,PCT/US1998/015962,27.07.1998,WO/1999/005851,04.02.1999,WO,METHOD OF ISOMORPHIC SINGULAR MANIFOLD PROJECTION STILL/VIDEO IMAGERY COMPRESSION,"The method of still image compression uses isomorphic singular manifold projection (1) whereby surfaces of objects having singular manifold representations are represented by best match canonical polynomials to arrive at a model representation (2). The model representation (3) is compared with the original representation (4) to arrive at a difference (5). If the difference exceeds a predetermined threshold, the difference data are saved and compressed using standard lossy compression (6). The coefficients from the best match polynomial together with the difference data, if any, are then compressed using lossless compression (6).",G06T 9/00,PHYSICAL OPTICS CORPORATION,"KOSTRZEWSKI, Andrew; TERNOVSKIY, Igor; JANNSON, Tomasz, P.","08/901,832 28.07.1997 US",EP-1998938212; KR-1020007000979
WO2019195191,PCT/US2019/025232,01.04.2019,WO/2019/195191,10.10.2019,WO,DYNAMIC IMAGE REGION SELECTION FOR VISUAL INFERENCE,"A region (e.g., a portion) of a full-size image is selected for analysis by a vision inference model. The region of the image may be dynamically selected for the image based on environmental characteristics of the image. These environmental characteristics may include semantic information about the environment that may be determined from a previous image of the environment, road structure information, control information, and motion information. These environmental characteristics may thus describe expected areas of interest in the image. The selected region of the full-size image is resized to a size compatible with a vision inference model which identifies semantic information about the current image. This semantic information may then be used to select a region of a subsequent image.",H04N 7/18; G06T 7/00,"PHANTOM AI, INC.","HWANGBO, Myung; CHO, Hyunggi; HUANG, Gordon; DZIWULSKI, Filip; CHOI, Jaehyung","62/651,654 02.04.2018 US",
WO2011152893,PCT/US2011/024414,10.02.2011,WO/2011/152893,08.12.2011,WO,METHODS AND SYSTEMS FOR GENERATING SALIENCY MODELS THROUGH LINEAR AND/OR NONLINEAR INTEGRATION,Methods and systems for generating saliency models are discussed. Saliency models can be applied to visual scenes to generate predictions on which locations in the visual scenes are fixation locations and which locations are nonfixation locations. Saliency models are learned from fixation data on the visual scenes obtained from one or more subjects.,G06T 7/00; G06T 7/40,"CALIFORNIA INSTITUTE OF TECHNOLOGY; ZHAO, Qi; KOCH, Christof","ZHAO, Qi; KOCH, Christof","61/303,225 10.02.2010 US",
WO2010006087,PCT/US2009/049987,09.07.2009,WO/2010/006087,14.01.2010,WO,"PROCESS FOR PROVIDING AND EDITING INSTRUCTIONS, DATA, DATA STRUCTURES, AND ALGORITHMS IN A COMPUTER SYSTEM","A method and system for computer programming using speech and one or two hand gesture input is described. The system generally uses a plurality of microphones and cameras as input devices. A configurable event recognition system is described allowing various software objects in a system to respond to speech and hand gesture and other input. From this input program code is produced that can be compiled at any time. Various speech and hand gesture events invoke functions within programs to modify programs, move text and punctuation in a word processor, manipulate mathematical objects, perform data mining, perform natural language internet search, modify project management tasks and visualizations, perform 3D modeling, web page design and web page data entry, and television and DVR programming.",G10L 15/00,"SEABERG, David","SEABERG, David","61/134,196 08.07.2008 US",US-13003009
WO2017182225,PCT/EP2017/056933,23.03.2017,WO/2017/182225,26.10.2017,WO,TRAINING METHOD AND DETECTION METHOD FOR OBJECT RECOGNITION,The present invention relates to the technical field of object recognition. A training method for object recognition from top-view images uses a step of labelling at least one training object from at least one training image using a pre-defined labelling scheme. A detection method for object recognition uses a step of applying a test window on a test image. An object recognition method comprises the training method and the detection method. A surveillance system performs the detection method. The present invention is particularly useful for object recognition in optic-distorted videos based on a machine training method. The invention is further particularly useful for person detection from top-view visible imagery and surveillance and presence monitoring in a region of interest (ROI).,G06T 3/00; G06K 9/00,OSRAM GMBH,"KAESTLE, Herbert; BRANDLMAIER, Meltem Demirkus; ESCHEY, Michael; GALASSO, Fabio; WANG, Ling",10 2016 206 817.2 21.04.2016 DE,US-16094503; EP-2017714407
WO2014153651,PCT/CA2014/000304,28.03.2014,WO/2014/153651,02.10.2014,WO,MICROFLUIDIC DEVICES AND METHODS FOR USE THEREOF IN MULTICELLULAR ASSAYS OF SECRETION,"Methods and devices are provided herein for identifying a cell population comprising an effector cell that exerts an extracellular effect. In one embodiment the method comprises retaining in a microreactor a cell population comprising one or more effector cells, wherein the contents of the microreactor further comprise a readout particle population comprising one or more readout particles, incubating the cell population and the readout particle population within the microreactor, assaying the cell population for the presence of the extracellular effect, wherein the readout particle population or subpopulation thereof provides a direct or indirect readout of the extracellular effect, and determining, based on the results of the assaying step, whether one or more effector cells within the cell population exerts the extracellular effect on the readout particle. If an extracellular effect is measured, the cell population is recovered for further analysis to determine the cell or cells responsible for the effect.",C12Q 1/02; C12M 1/34; C12Q 1/68; G01N 33/48; G01N 33/567,THE UNIVERSITY OF BRITISH COLUMBIA,"RICICOVA, Marketa; HEYRIES, Kevin Albert; ZAHN, Hans; PETRIV, Oleh; LECAULT, Veronique; SINGHAL, Anupam; DA COSTA, Daniel J.; HANSEN, Carl, L., G.; NELSON, Brad; NIELSEN, Julie; LISAINGO, Kathleen","61/806,329 28.03.2013 US",KR-1020157031147; EP-2014775104; CA-2906231; CN-201480031128.2; JP-2016504429; US-14773244; AU-2014245806
WO2014068567,PCT/IL2013/050892,31.10.2013,WO/2014/068567,08.05.2014,WO,"METHOD AND SYSTEM FOR PREDICTING PERSONALITY TRAITS, CAPABILITIES AND SUGGESTED INTERACTIONS FROM IMAGES OF A PERSON","The present invention relates to a method of predicting personality characteristic from at least one image of a subject person, in particular images of the person's face, comprising: a) collecting training images of multiple persons for training propose, wherein each of said training images is associated with metadata characteristics of human personality; b) grouping said collected training images into training groups according to said associated metadata, either according to same metadata or similar metadata; c) training at least one image-based classifier to predict at least one characteristics of human personality from at least one image of a second person; and d) applying said at least one image-based classifier to at least one image of said subject person for outputting a prediction of at least one human personality characteristic of said subject person.",G06K 9/46,"WILF, Itzhak; SHOR, Yael; GILBOA, Shai; GAVRIEL, David; BECHAR, Gilad","WILF, Itzhak; SHOR, Yael; GILBOA, Shai; GAVRIEL, David; BECHAR, Gilad","61/721,571 02.11.2012 US; 61/858,686 26.07.2013 US",IL-238574; EP-2013850336
WO2017112067,PCT/US2016/058078,21.10.2016,WO/2017/112067,29.06.2017,WO,VIDEO SUMMARIZATION USING SEMANTIC INFORMATION,"An apparatus for video summarization using sematic information is described herein. The apparatus includes a controller, a scoring mechanism, and a summarizer. The controller is to segment an incoming video stream into a plurality of activity segments, wherein each frame is associated with an activity. The scoring mechanism is to calculate a score for each frame of each activity, wherein the score is based on a plurality of objects in each frame. The summarizer is to summarize the activity segments based on the score for each frame.",G11B 27/19; G11B 20/10; G06N 3/02,INTEL CORPORATION,"HWANGBO, Myung; SINGH, Krishna Kumar; LEE, Teahyung; TICKOO, Omesh","14/998,322 24.12.2015 US",
WO2017027429,PCT/US2016/045935,07.08.2016,WO/2017/027429,16.02.2017,WO,MEDIA CONTENT ANALYSIS SYSTEM AND METHOD,"Disclosed herein is an intelligent agent to analyze a media object. The agent comprises a trained model comprising a number of state layers for storing a history of actions taken by the agent in each of a number of previous iterations performed by the agent in analyzing a media object. The stored state may be used by the agent in a current iteration to determine whether or not to make, or abstain from making, a prediction from output generated by the model, identify another portion of the media object to analyze, end analysis. Output from the agent's model may comprise a semantic vector that can be mapped to a semantic vector space to identify a number of labels for a media object.",G06F 17/30; G06N 3/02,YAHOO! INC.,"OSINDERO, Simon","14/824,561 12.08.2015 US",
WO2020072676,PCT/US2019/054338,02.10.2019,WO/2020/072676,09.04.2020,WO,EFFICIENT HIGH BANDWIDTH SHARED MEMORY ARCHITECTURES FOR PARALLEL MACHINE LEARNING AND AI PROCESSING OF LARGE DATA SETS AND STREAMS,The present disclosure relates to systems and methods to implement efficient high-bandwidth shared memory systems particularly suited for parallelizing and operating large scale machine learning and AI computing systems necessary to efficiently process high volume data sets and streams.,G06K 9/62; G06F 9/50; G06F 13/14,"BRAINWORKS FOUNDRY, INC.","ALVELDA VII, Phillip; KRAUSE, Markus; STIERS, Todd Allen","62/739,901 02.10.2018 US",
WO2019217419,PCT/US2019/031114,07.05.2019,WO/2019/217419,14.11.2019,WO,SYSTEMS AND METHODS FOR IMPROVED SPEECH RECOGNITION USING NEUROMUSCULAR INFORMATION,"Systems and methods for using neuromuscular information to improve speech recognition. The system includes a plurality of neuromuscular sensors arranged on one or more wearable devices and configured to continuously record a plurality of neuromuscular signals from a user, at least one storage device configured to store one or more trained inference models for determining text based on audio input and the plurality of neuromuscular signals, at least one input interface configured to receive the audio input, and at least one computer processor programmed to obtain the audio input and the plurality of neuromuscular signals, provide as input to the one or more trained inference models, the audio input and the plurality of neuromuscular signals or signals derived from the plurality of neuromuscular signals, and determine based, at least in part, on an output of the one or more trained inference models, the text.",G10L 15/22; G10L 15/06; G06F 1/16; G10L 15/26; G10L 25/75; G06F 3/01; G06F 3/16,CTRL-LABS CORPORATION,"BERENZWEIG, Adam; KAIFOSH, Patrick; DU, Alan, Huan; SEELY, Jeffrey, Scott; WETMORE, Daniel","15/974,454 08.05.2018 US; 15/974,384 08.05.2018 US; 15/974,430 08.05.2018 US",
EP206520225,16869294,23.11.2016,3245652,22.11.2017,EP,DEPLOYED END-TO-END SPEECH RECOGNITION,,G10L 15/16; G10L 15/06; G10L 15/08; G10L 15/183,BAIDU USA LLC,CATANZARO BRYAN; CHEN JINGDONG; CHRZANOWSKI MIKE; ELSEN ERICH; ENGEL JESSE; FOUGNER CHRISTOPHER; HAN XU; HANNUN AWNI; PRENGER RYAN; SATHEESH SANJEEV; SENGUPTA SHUBHABRATA; YOGATAMA DANI; WANG CHONG; ZHAN JUN; ZHU ZHENYAO; AMODEI DARIO,201562260206 25.11.2015 US; 2016063641 23.11.2016 US; 201615358083 21.11.2016 US; 201615358102 21.11.2016 US,
WO2019206032,PCT/CN2019/083398,19.04.2019,WO/2019/206032,31.10.2019,WO,METHOD AND SYSTEM FOR ADAPTIVELY CONTROLLING OBJECT SPACING,"A method or system for adaptive vehicle spacing, including determining a current state of a vehicle based on sensor data captured by sensors of the vehicle; for each possible action in a set of possible actions: (i) predicting based on the current vehicle state a future state for the vehicle, and (ii) predicting, based on the current vehicle state a first zone future safety value corresponding to a first safety zone of the vehicle; and selecting, based on the predicted future states and first zone future safety values for each of the possible actions in the set, a vehicle action.",B60W 30/16; H04W 4/02,"HUAWEI TECHNOLOGIES CO., LTD.","GRAVES, Daniel Mark; REZAEE, Kasra","15/965,182 27.04.2018 US",
WO2015066453,PCT/US2014/063385,31.10.2014,WO/2015/066453,07.05.2015,WO,COMPUTING ARCHITECTURE FOR OPERATING ON SEQUENTIAL DATA,"A data stream processing unit (DPU) and method for use are provided. A DPU includes a number of processing elements arranged in a sequence, and each datum in the data stream visits each processing element in sequence. Each processing element has a memory circuit, data and metadata input and output channels, and a computing circuit. The metadata input represents a partial computational state that is associated with each datum as it passes through the DPU. The computing circuit for each processing element operates on the data and metadata inputs as a function of its position in the sequence, producing an altered partial computational state that accompanies the datum. Each computing circuit may be modeled, for example, as a finite state machine, and the collection of processing elements cooperate to perform the computation. The computing circuits may be collectively programmed to perform any desired computation.",G06F 15/80,"LEWIS RHODES LABS, INC.","FOLLETT, David; FOLLETT, Pamela, L.","14/071,465 04.11.2013 US",EP-2014805708
EP289344309,19802029,16.05.2019,3617946,04.03.2020,EP,CONTEXT ACQUISITION METHOD AND DEVICE BASED ON VOICE INTERACTION,"Embodiments of the present invention provide a context acquiring method based on voice interaction and a device, the method comprising: acquiring a scene image collected by an image collection device at a voice start point of a current conversation, and extracting a face feature of each user in the scene image; if it is determined that there is a second face feature matching a first face feature according to the face feature of each user and a face database, acquiring a first user identifier corresponding to the second face feature from the face database, where the first face feature is a face feature of a user, and the second face feature is a face feature of a user in conversation state stored in the face database; if it is determined that a stored conversation corresponding to the first user identifier is stored in a voice database, determine a context of a voice interaction according to the current conversation and the stored conversation, and after the voice end point of the current conversation is obtained, storing the current conversation into the voice database. The embodiments can improve the accuracy of acquiring the context of voice interaction.",G06K 9/00,BEIJING BAIDU NETCOM SCIENCE TECH CO LTD,LIANG YANG; LIU KUN; QIAO SHUANGSHUANG; LIN XIANGYUE; HAN CHAO; ZHU MINGFA; GUO JIANGLIANG; LI XU; LIU JUN; LI SHUO; YIN SHIMING,201810709792 02.07.2018 CN; 2019087203 16.05.2019 CN,
WO2009146113,PCT/US2009/039369,02.04.2009,WO/2009/146113,03.12.2009,WO,USER INTENTION MODELING FOR INTERACTIVE IMAGE RETRIEVAL,"A system performs user intention modeling for interactive image retrieval. In one implementation, the system uses a three stage iterative technique to retrieve images from a database without using any image tags or text descriptors. First, the user submits a query image and the system models the user's search intention and configures a customized search to retrieve relevant images. Then, the system extends a user interface for the user to designate visual features across the retrieved images. The designated visual features refine the intention model and reconfigure the search to retrieve images that match the remodeled intention. Third, the system extends another user interface through which the user can give natural feedback about the retrieved images. The three stages can be iterated to quickly assemble a set of images that accurately fulfills the user's search intention. They system can be used for image searching without text tags, can be used for initial text tag generation, or can be used to complement a conventional tagged-image platform.",G06F 17/30; G06F 17/00,MICROSOFT CORPORATION,"WEN, Fang; TANG, Xiaoou","61/042,215 03.04.2008 US; 12/113,014 30.04.2008 US",EP-2009755475
WO2017123665,PCT/US2017/013062,11.01.2017,WO/2017/123665,20.07.2017,WO,DRIVER BEHAVIOR MONITORING,"Systems and methods provide, implement, and use using a computer-vision based methods of context-sensitive monitoring and characterization of driver behavior. Additional systems and methods are provided for unsupervised learning of action values, monitoring of a driver's environment, and transmitting visual information from a client to a server.",G06K 9/60; G08G 1/16; G08G 1/052; G08G 1/054; G08G 1/01; G06K 9/20,NETRADYNE INC.,"JULIAN, David, Jonathan; AGRAWAL, Avneesh","62/277,470 11.01.2016 US",EP-2017738879
WO2017071911,PCT/EP2016/073599,04.10.2016,WO/2017/071911,04.05.2017,WO,AN AUTONOMOUS VEHICLE THAT MINIMIZES HUMAN REACTIONS,A road vehicle capable of autonomous driving has a windshield (10) and a control system (30) being configured to selectively control a regular visible light transmittance of the windshield (10) between two or more electrically switchable light states that provide respective levels of visual access through the windshield (10) from outside the vehicle according to a driving context for the vehicle.,B60J 3/04; G05D 1/02,VLYTE INNOVATIONS LIMITED,"O'KEEFFE, Donal",1519082.0 28.10.2015 GB,EP-2016785376; US-15768867
WO2019234726,PCT/IL2019/050533,12.05.2019,WO/2019/234726,12.12.2019,WO,SYSTEM AND METHODOLOGY FOR PERFORMANCE VERIFICATION OF MULTI-AGENT AUTONOMOUS ROBOTIC SYSTEMS,"A computerized method of performing safety and functional verification of algorithms, for control of autonomous vehicles, comprises: iteratively performing an adjustment, the adjustment comprising at least one of the following: (i) updating the value of parameter(s) indicative of noise and/or delay in simulated sensor(s), associated with a computerized simulation framework corresponding to simulated autonomous vehicle(s) and to operational environment(s), by increasing noise and/or delay; and (ii) updating the value of parameter(s) indicative of noise and/or delay in a response of the simulated autonomous vehicle(s) to command(s), by increasing the noise and/or delay. This is done until obtaining from the computerized simulation framework an increased- severity computerized simulation framework. The increased-severity computerized simulation framework meets a criterion that can be utilized for statistical safety verification and/or statistical functional performance verification of the algorithm(s).",G06F 17/50; G09B 9/04; G05D 1/00,ISRAEL AEROSPACE INDUSTRIES LTD.,"MELTZ, Daniel; SIRKIS, Amit",259835 05.06.2018 IL,
WO2018053464,PCT/US2017/052154,19.09.2017,WO/2018/053464,22.03.2018,WO,SYSTEMS AND METHODS FOR DEEP LEARNING WITH SMALL TRAINING SETS,"A hierarchical compositional network, representable in Bayesian network form, includes first, second, third, fourth, and fifth parent feature nodes; first, second, and third pool nodes; first, second, and third weight nodes; and first, second, third, fourth, and fifth child feature nodes.",G06N 3/02; G06F 15/18,"VICARIOUS FPC, INC.","GREDILLA, Miguel, Lazaro","62/396,657 19.09.2016 US",
WO2018200734,PCT/US2018/029453,25.04.2018,WO/2018/200734,01.11.2018,WO,FIELD-OF-VIEW PREDICTION METHOD BASED ON NON-INVASIVE EEG DATA FOR VR VIDEO STREAMING SERVICES,"Some embodiments of systems and methods disclosed herein include displaying, on a display of a head-mounted display (HMD), a first plurality of tiles of a multi-tile video; measuring an electroencephalography (EEG) signal of the user while the multi-tile video is displayed; predicting a head movement of the user based on the EEG signal; retrieving a second plurality of tiles of the multi-tile video based on the predicted head movement of the user; and rendering one or more of the second plurality of tiles of the multi-tile video.",A61B 5/0484; G06F 3/01; G02B 27/01; A61B 5/00,"PCMS HOLDINGS, INC.","SON, JuHyung; KWAK, Jin Sam; OH, Hyun Oh","62/491,586 28.04.2017 US",
WO2019122954,PCT/IB2017/058087,19.12.2017,WO/2019/122954,27.06.2019,WO,METHOD AND SYSTEM FOR ENSEMBLE VEHICLE CONTROL PREDICTION IN AUTONOMOUS DRIVING VEHICLES,"The present teaching relates to method, system, medium, and implementation of human- like vehicle control for an autonomous vehicle. Recorded human driving data are first received, which include vehicle state data, vehicle control data, and environment data. For each piece of recorded human driving data, a vehicle kinematic model based vehicle control signal is generated in accordance with a vehicle kinematic model based on a corresponding vehicle state and vehicle control data of the piece of recorded human driving data. A human-like vehicle control model is obtained, via machine learning, based on the recorded human driving data as well as the vehicle kinematic model based vehicle control signal generated based on vehicle kinematic model. Such derived human-like vehicle control model is to be used to generate a human-like vehicle control signal with respect to a target motion of an autonomous vehicle to achieve human-like vehicle control behavior.",B60W 40/09; B60W 40/02; B60W 40/06; B60W 40/08; B60W 40/12; G05D 1/02; B60L 15/38; G06N 5/04,PLUSAI CORP,"ZHOU, Mianwei; ZHENG, Hao; LIU, David Wanqian","15/845,423 18.12.2017 US",
WO2017206147,PCT/CN2016/084536,02.06.2016,WO/2017/206147,07.12.2017,WO,RECOGNITION OF ACTIVITY IN A VIDEO IMAGE SEQUENCE USING DEPTH INFORMATION,"Techniques are provided for recognition of activity in a sequence of video image frames that include depth information. A methodology embodying the techniques includes segmenting each of the received image frames into a multiple windows and generating spatio-temporal image cells from groupings of windows from a selected sub-sequence of the frames. The method also includes calculating a four dimensional (4D) optical flow vector for each of the pixels of each of the image cells and calculating a three dimensional (3D) angular representation from each of the optical flow vectors. The method further includes generating a classification feature for each of the image cells based on a histogram of the 3D angular representations of the pixels in that image cell. The classification features are then provided to a recognition classifier configured to recognize the type of activity depicted in the video sequence, based on the generated classification features.",G06K 9/46,"INTEL CORPORATION; TANG, Shaopeng; YAO, Anbang; CHEN, Yurong","TANG, Shaopeng; YAO, Anbang; CHEN, Yurong",,US-16098648; DE-112016006922; KR-1020187031747
WO2018191134,PCT/US2018/026649,09.04.2018,WO/2018/191134,18.10.2018,WO,INTELLIGENT SYSTEMS FOR WEATHER MODIFICATION PROGRAMS,"Data including current locations of candidate clouds to be seeded is obtained; based on same, a vehicle is caused to move proximate at least one of the candidate clouds to be seeded. Weather and cloud system data are obtained from a sensor suite associated with the vehicle, while the vehicle and sensor suite are proximate the at least one of the candidate clouds to be seeded. Vehicle position parameters are obtained from the sensor suite associated with the vehicle. Based on the weather and cloud system data and the vehicle position parameters, it is determined, via a machine learning process, which of the candidate clouds should be seeded, and, within those of the candidate clouds which should be seeded, where to disperse an appropriate seeding material. The vehicle is controlled to carry out the seeding on the candidate clouds to be seeded, in accordance with the determining step.",A01G 15/00; G01W 1/08; G06F 17/30,"DEFELICE, Thomas, Peter; AXISA, Duncan","DEFELICE, Thomas, Peter; AXISA, Duncan","15/944,437 03.04.2018 US; 62/484,043 11.04.2017 US",
WO2015148278,PCT/US2015/021621,20.03.2015,WO/2015/148278,01.10.2015,WO,COMPUTER GENERATED NATURAL LANGUAGE OUTPUTS IN QUESTION ANSWER SYSTEMS,"Methods, computer systems, and computer-storage media are provided for generating natural language outputs. Sets of triples may be used to map voice queries and answers to sentence structures that may be used as an output answer to the voice query. Sentence structures are only appropriate with certain sets of triples. One or more constraints may be associated with the set of triples to make sure sentence structures are only applied in correct situations. In order to be a valid sentence structure, each constraint associated therewith must be satisfied. If each constraint is satisfied, the sentence structure is valid and may be used as the format for an output answer. If each constraint is not satisfied, additional sentence structures associated with the set of triples may be evaluated until a valid sentence structure is identified. If no sentence structure is valid, no output is generated.",G06F 17/30; G06F 17/27; G10L 15/22,"MICROSOFT TECHNOLOGY LICENSING, LLC","CAO, Guihong; KARABAY, Fetiye; MOHAMED, Ahmed","14/224,430 25.03.2014 US",EP-2015715031; CN-201580015901.0; KR-1020167029845
WO2014160760,PCT/US2014/031837,26.03.2014,WO/2014/160760,02.10.2014,WO,METHOD AND APPARATUS FOR USING POST ASSEMBLY PROCESS INTERACTION SIGNATURES TO DETECT ASSEMBLY FAILURES,There is described a technique for detecting the success of an automated process that produces an article of manufacture. A statistically significant number of successful and failed articles are produced by the automated process. Each of these articles is interacted with a test platform to measure interaction signatures that indicate successful and failed articles. A correlation of the difference between the interaction signatures is calculated. An interaction signature is then obtained for an article manufactured by the process after the earlier made articles. The new interaction signature is analyzed against the calculated correlation difference to automatically categorize as either a success or a failure the additional article of manufacture. There is also described a technique for optimizing the motion used to test the manufactured articles to improve the correlation of the difference between the interaction signals of successful articles and the interaction signals of failed articles.,G05B 19/418; G05B 23/02; G01R 31/28,"ABB TECHNOLOGY AG; WANG, Jianjun; FUHLBRIGGE, Thomas, A.; HAULIN, Jonas; ROSSANO, Gregory; BOURNE, David, Alan; ZHANG, Biao; GARCIA, Alberto, Rodriguez","WANG, Jianjun; FUHLBRIGGE, Thomas, A.; HAULIN, Jonas; ROSSANO, Gregory; BOURNE, David, Alan; ZHANG, Biao; GARCIA, Alberto, Rodriguez","61/805,864 27.03.2013 US",CN-201480028747.6
WO2015191731,PCT/US2015/035131,10.06.2015,WO/2015/191731,17.12.2015,WO,SYSTEMS AND METHODS FOR SOFTWARE ANALYTICS,"Systems, methods, and computer program products are provided for locating design patterns in software. An example method includes accessing a database having multiple artifacts corresponding to multiple software, and identifying a design pattern for at least one of the software files by automatically analyzing at least one of the artifacts associated with the software. Additional embodiments also provide for storing an identifier for the design pattern for the software in the database. For certain example embodiments, the artifacts include developmental, which may be searched for a string that denotes a design pattern, such as flaw, feature, or repair. Additional example embodiments also include finding in the software file a program fragment that implements the design pattern.",G06F 9/44,"THE CHARLES STARK DRAPER LABORATORY, INC.","CARBACK, III, Richard, T.; GAYNOR, Brad, D.; SHNIDMAN, Nathan, R.; CHIN, Sang, H.","62/012,127 13.06.2014 US",CA-2949248; JP-2016572723; EP-2015731199
WO2019231644,PCT/US2019/031931,13.05.2019,WO/2019/231644,05.12.2019,WO,FACE RECOGNITION USING DEPTH AND MULTI-SPECTRAL CAMERA,A camera is configured to output a test depth+multi-spectral image including a plurality of pixels. Each pixel corresponds to one of the plurality of sensors of a sensor array of the camera and includes at least a depth value and a spectral value for each spectral light sub-band of a plurality of spectral illuminators of the camera. A face recognition machine is previously trained with a set of labeled training depth+multi-spectral images having a same structure as the test depth+multi-spectral image. The face recognition machine is configured to output a confidence value indicating a likelihood that the test depth+multi-spectral image includes a face.,G06K 9/00; G06K 9/20; G06K 9/46,"MICROSOFT TECHNOLOGY LICENSING, LLC","ORTIZ EGEA, Sergio; FENTON, Michael Scott; AHMED, Abdelrehim","15/991,981 29.05.2018 US",
WO2009041918,PCT/SG2008/000366,26.09.2008,WO/2009/041918,02.04.2009,WO,A METHOD AND SYSTEM FOR GENERATING AN ENTIRELY WELL-FOCUSED IMAGE OF A LARGE THREE-DIMENSIONAL SCENE,"A method and system for generating an entirely well-focused image of a three-dimensional scene. The method comprises the steps of a) learning a prediction model including at least a focal depth probability density function (PDF), h(k), for all depth values k, from historical tiles of the scene; b) predicting the possible focal surfaces in subsequent tiles of the scene by applying the prediction model; c) for each value of k, examining h(k) such that if h(k) is below a first threshold, no image is acquired at the depth k' for said one tile; and if h(k) is above or equal to a first threshold, one or more images are acquired in a depth range around said value of k for said one tile; and d) processing the acquired images to generate a pixel focus map for said one tile.",G06K 9/60; G06T 1/00,"AGENCY FOR SCIENCE, TECHNOLOGY AND RESEARCH; XIONG, Wei; TIAN, Qi; LIM, Joo Hwee","XIONG, Wei; TIAN, Qi; LIM, Joo Hwee","60/975,392 26.09.2007 US",US-12680478
WO2018039648,PCT/US2017/048759,25.08.2017,WO/2018/039648,01.03.2018,WO,SYSTEM AND METHODS FOR PROCESSING NEURAL SIGNALS,"Systems and methods for processing neural signals are provided. A neural data analysis system may comprise a feature extraction module configured to (1) extract a plurality of features from neural signal waveforms obtained by an implanted neural interface probe with a plurality of channels or electrodes, wherein the plurality of features are extracted from the neural signal waveforms without requiring prior digitization of the neural signal waveforms, and (2) to transmit the extracted features as a plurality of discrete outputs. The neural data analysis system may also comprise a feature-event coalescence module configured to: (1) receive the plurality of discrete outputs from the feature extraction module, and (2) construct a model-based inference of bioelectric activity based on feature-event statistics, prior knowledge of bioelectric signals, and/or a behavioral model of the feature-extraction module. The neural data analysis system may further comprise an approximator module configured to (1) receive a plurality of coalesced events from the feature-event coalescence module, and (2) apply a series of transformations to the coalesced event data to generate a higher entropy neural code, wherein the neural code comprises a representation of ensemble activity of a plurality of neurons recorded by the system.",A61N 1/05; A61N 1/04; A61N 1/02; A61B 5/04,"PARADROMICS, INC.","ANGLE, Matthew; HUBER, Edmund; EDGINGTON, Robert","62/379,680 25.08.2016 US",CN-201780066163.1; EP-2017844547
WO2003014949,PCT/US2002/024929,06.08.2002,WO/2003/014949,20.02.2003,WO,"METHOD, SYSTEM, AND COMPUTER PROGRAM PRODUCT FOR PRODUCING AND DISTRIBUTING ENHANCED MEDIA","A method, system, and computer program product are provided to edit and encode enriched multimedia productions for live, delayed, or on-demand web casts or other distribution. The present invention is configured to operate independent of the system platform and media format. The present invention has the ability to operate with any type of manual or automated video production system. The multimedia production is produced according to an electronic show rundown, including webcasting, and can be produced/broadcast over conventional channels simultaneously with a live, delayed, or on-demand web cast. The web cast material is edited, fragmented, tagged and /or archived during the simulcast. An embodiment of said system incorporates pre-production show rundown (2402), shadow rundown (2404), as well as a tradition show (2406), and an electronic show (2408). Post production file (2409) is then combined with archived show (2410) to produce on-demand show (2414). A user can select one or more events from a menu of categorized media productions, determine an order for viewing, and receive a seamless assembly or productions.",G06F 17/30; H04N 5/268,"PARKER VISION, INC.","HOLTZ, Alex; SNYDER, Robert, J.; LAROCQUE, Marcel; COUCH, William, H.; MCALLISTER, Benjamin; HOEPPNER, Charles, M.; TINGLE, Keith, Gregory; ARMBRUSTER, David, A.","60/309,788 06.08.2001 US; 60/386,753 10.06.2002 US; 10/208,810 01.08.2002 US",JP-null; EP-2002756984
WO1999067775,PCT/US1999/014182,23.06.1999,WO/1999/067775,29.12.1999,WO,METHOD AND APPARATUS FOR SIGNAL CLASSIFICATION USING A MULTILAYERNETWORK,"A method and apparatus for signal classification using a multilayer network involves receiving an input signal feature vector, classifying a first signal feature, and classifying a second signal feature using contextual information. The multilayer network applies a relaxation process that updates an activation value of a node in a first layer and updates an activation value of a node in a second layer. The multilayer network then generates a signal classification according to an activation value of a node in the multilayer network.",G06K 9/66; G06N 3/04; G10L 15/16,"FONIX CORPORATION; HANSEN, Carl, Hal","HANSEN, Carl, Hal; MARTINEZ, Tony, R.; MONCUR, R., Brian; SHEPHERD, D., Lynn; PARR, Randall, J.; WILSON, D., Randall","09/103,569 24.06.1998 US",JP-2000556365; KR-1020007014843; EP-1999930584
WO2003067515,PCT/US2002/037848,25.11.2002,WO/2003/067515,14.08.2003,WO,APPARATUS AND METHOD FOR DESIGNING PROTEINS AND PROTEIN LIBRARIES,"Methodology executed by a computer under the control of a program, said computer including a memory for storing said program, said method comprising the steps of inputting an ensemble of protein backbone scaffolds; applying at least one protein design cycle to each of said scaffolds; and generating a probability matrix derived from a plurality of variable sequences.",G06N 3/10; G06N 3/12; G06N 7/04,THE PENN STATE RESEARCH FOUNDATION,"DESJARLAIS, John, R.","10/071,859 06.02.2002 US",JP-null
WO2012021906,PCT/US2011/049621,30.08.2011,WO/2012/021906,16.02.2012,WO,"DEVICES, SYSTEMS, AND METHODS FOR ENABLING AND RECONFIGURING OF SERVICES SUPPORTED BY A NETWORK OF DEVICES","Systems, devices, and methods are disclosed for enabling and reconfiguring of services supported by a network of devices. Such reconfiguration can be realized dynamically and in real time without compromising the security of the overall system from external threats or internal malfunctions. These systems, devices and methods may provide a first functional stack supporting a previous version of a specific service and the provisioning of a second functional stack dynamically and in real-time that supports an updated version of the specific service. In addition, an administration function may be included in the embodiment such that the administration function manages and controls the functional stacks and network operations. Using these mechanisms, an existing service can be changed dynamically or a new service can be added dynamically in a secure manner without interruption of other existing services.",G06F 15/18,"DOMANICOM CORPORATION; BARTHOLOMAY, William; CHANG, Sin-Min; DAS, Santanu; SENGUPTA, Arun","BARTHOLOMAY, William; CHANG, Sin-Min; DAS, Santanu; SENGUPTA, Arun","12/853,146 09.08.2010 US; 61/364,165 14.07.2010 US; 12/835,963 14.07.2010 US; 12/953,602 24.11.2010 US; 12/892,903 28.09.2010 US; 12/871,854 30.08.2010 US",EP-2011817185
WO2019232473,PCT/US2019/035046,31.05.2019,WO/2019/232473,05.12.2019,WO,AUTOMATED DETECTION AND CHARACTERIZATION OF MICRO-OBJECTS IN MICROFLUIDIC DEVICES,"Methods are provided for the automated detection, characterization, and selection of micro-objects in a microfluidic device. In addition, methods are provided for grouping detected micro-objects into subgroups that share the same characteristics and, optionally, repositioning micro-objects in a selected sub-population within the microfluidic device. For example, microobjects in a selected sub-population can be moved into sequestration pens. The methods also provide for visual displays of the micro-object characteristics, such as two- or three-dimensional graphs, and for user-based definition and/or selection of sub-populations of the detected microobjects. In addition, non-transitory computer-readable medium in which a program is stored and systems for carrying out any of the disclosed methods are provided.",G01N 21/31; G01N 15/14; G06F 19/00,"BERKELEY LIGHTS, INC.","TENNEY, John A.; VETTERLI, Thomas M.; KIM, Hansohl E.","62/678,791 31.05.2018 US",
WO2018136315,PCT/US2018/013428,12.01.2018,WO/2018/136315,26.07.2018,WO,AUTOMATIC NARRATION OF SIGNAL SEGMENT,"Automatic generation of a narration of what is happening in a signal segment (live or recorded). The signal segment that is to be narrated is accessed from a physical graph. In the physical graph, the signal segment evidences state of physical entities, and thus has a semantic understanding of what is depicted in the signal segment. The system then automatically determines how the physical entities are acting within the signal segment based on that semantic understanding, and builds a narration of the activities based on the determined actions. The system may determine what is interesting for narration based on a wide variety of criteria. The system could use machine learning to determine what will be interesting to narrate.",G06N 3/02,"MICROSOFT TECHNOLOGY LICENSING, LLC","MITAL, Vijay","62/447,821 18.01.2017 US; 15/436,655 17.02.2017 US",EP-2018703114; CN-201880007406.9
WO2005008596,PCT/EP2004/051190,22.06.2004,WO/2005/008596,27.01.2005,WO,"METHOD, COMPUTER PROGRAM AND COMPUTER READABLE MEANS FOR PROJECTING DATA FROM A MULTIDIMENSIONAL SPACE INTO A SPACE HAVING LESS DIMENSIONS AND TO CARRY OUT A COGNITIVE ANALYSIS ON SAID DATA",,G06F 17/10; G06F 17/18,"SEMEION; BUSCEMA, Paolo, Massimo","BUSCEMA, Paolo, Massimo",03425436.7 01.07.2003 EP,JP-2006516175; US-2007100880; EP-2004741854; CN-200480018862.1; US-10563409
WO2019086856,PCT/GB2018/053136,31.10.2018,WO/2019/086856,09.05.2019,WO,SYSTEMS AND METHODS FOR COMBINING AND ANALYSING HUMAN STATES,"A system comprising a plurality of devices for sensing, detecting or measuring physiological and expressive data streams associated with a person's experience over time, the system comprising a processor configured to synchronise the data streams to obtain synchronised data; select feature data from the synchronised data, the feature data being descriptive of at least one human state of the person; model the feature data using a locally weighted polynomial regression model; and process the modelled feature data using multivariate autoregressive state-space modelling in order to identify at least one potential trend in the experience over time.",G16H 50/20; A61B 5/16,SENSUMCO LIMITED,"MORRISON, Gawain; MCCOURT, Shane; MC KEOWN, Gary John; FYANS, Cavan; DUPRE, Damien",1718237.9 03.11.2017 GB,
WO2019122994,PCT/IB2017/058491,28.12.2017,WO/2019/122994,27.06.2019,WO,METHOD AND SYSTEM FOR HUMAN-LIKE VEHICLE CONTROL PREDICTION IN AUTONOMOUS DRIVING VEHICLES,"The present teaching relates to method, system, medium, and implementation of human- like vehicle control for an autonomous vehicle. Information related to a target motion to be achieved by the autonomous vehicle is received, wherein the information includes a current vehicle state of the autonomous vehicle. A first vehicle control signal is generated with respect to the target motion and the given vehicle state in accordance with a vehicle kinematic model. A second vehicle control signal is generated in accordance with a human-like vehicle control model, with respect to the target motion, the given vehicle state, and the first vehicle control signal, wherein the second vehicle control signal modifies the first vehicle control signal to achieve human-like vehicle control behavior.",B60T 7/12; B60T 8/32; B60W 30/06; B60W 30/14,PLUSAI CORP,"ZHOU, Mianwei; ZHENG, Hao; LIU, David Wanqian","15/845,423 18.12.2017 US; 15/856,163 28.12.2017 US",
EP13316801,99308390,25.10.1999,0999541,10.05.2000,EP,Context sharing for similar words in context dependent hidden markov models,"A natural number recognition method and system that uses minimum classification error trained inter-word context dependent models of the head-body-tail type over a specific vocabulary. One part of the method and system allows recognition of spoken monetary amounts in financial transactions. A second part is in the recognition of numbers such as credit card or U.S. telephone numbers. A third part is the recognition of natural language expressions of time, such as time of day, day of the week and date of the month for applications such as scheduling or schedule inquires. Very excellent error rates have been achieved over more traditional context independent whole-word models. Further, context sharing in a head-body-tail model between similar sounds in the vocabulary helps to greatly reduce storage and processing requirements. This keeps speech recognition units based on such methods and systems be more acceptable from monetary and temporal cost considerations. <IMAGE>",G10L 15/14; G10L 15/18; G10L 15/02; G10L 15/10; G10L 15/14,LUCENT TECHNOLOGIES INC,GANDHI MALAN BHATKI; JACOB JOHN,18462098 02.11.1998 US,
WO2018194994,PCT/US2018/027835,16.04.2018,WO/2018/194994,25.10.2018,WO,ENHANCING PROCESSING PERFORMANCE OF A DNN MODULE BY BANDWIDTH CONTROL OF FABRIC INTERFACE,"An exemplary computing environment having a DNN module can maintain one or more bandwidth throttling mechanisms. Illustratively, a first throttling mechanism can specify the number of cycles to wait between transactions on a cooperating fabric component (e.g., data bus). Illustratively, a second throttling mechanism can be a transaction count limiter that operatively sets a threshold of a number of transactions to be processed during a given transaction sequence and limits the number of transactions such as multiple transactions in flight to not exceed the set threshold. In an illustrative operation, in executing these two exemplary calculated throttling parameters, the average bandwidth usage and the peak bandwidth usage can be limited. Operatively, with this fabric bandwidth control, the processing units of the DNN are optimized to process data across each transaction cycle resulting in enhanced processing and lower power consumption.",G06N 3/04; G06N 3/063,"MICROSOFT TECHNOLOGY LICENSING, LLC","MCBRIDE, Chad Balling; HEIL, Timothy Hume; AMBARDEKAR, Amol Ashok; PETRE, George; CEDOLA, Kent D.; WALL, Larry Marvin; BOBROV, Boris","62/486,432 17.04.2017 US; 15/950,644 11.04.2018 US",EP-2018724644; CN-201880025130.7
WO2016132282,PCT/IB2016/050810,16.02.2016,WO/2016/132282,25.08.2016,WO,ANOMALY DETECTION SYSTEM AND METHOD,"An acoustic array system for anomaly detection is provided. The acoustic array system (100) performs a scan (or a progressive scan of frequencies) of a given volume by transmitting one or more signals, and receives one or more reflected signals from objects within the volume. The reflected signals are then amplified and converted to a set of digital signals. Features of the set of digital signals are extracted both in time and frequency domains. The acoustic array system (100) further performs a comparison of these set of digital extracted features with the reflected signals via machine learning techniques. Based on the comparison, the acoustic array system detects one or more anomalies.",G01N 29/00; G08B 13/18; G10L 15/20,TATA CONSULTANCY SERVICES LIMITED,"DESHPANDE, Parijat; VEMPADA, Ramu; DASGUPTA, Ranjan; PAL, Arpan; ROY, Dibyendu",567/MUM/2015 20.02.2015 IN,US-15552225
WO2016109884,PCT/CA2016/000002,05.01.2016,WO/2016/109884,14.07.2016,WO,AUTOMATED RECOMMENDATION AND VIRTUALIZATION SYSTEMS AND METHODS FOR E-COMMERCE,"Visual appearance is a significant aspect of how we perceive others and how we want to be perceived. With items such as eyewear, make-up and facial jewelry the style, colour, size not only impact how others perceive us based upon the selections themselves but also how these fit or suit the user's face, which is unique. With online retailing the purchaser does not get feedback as in bricks-and-mortar retailing from friends, retail assistants etc. At best the user is exposed to a basic recommendation system which is generally procedural based with a priori aesthetic rules and user classification. However, users are often incorrect in their classification of themselves whilst the aesthetic rules are hidden, can contradict, and do not take into account current fashion, age or culture. Embodiments of the invention provide automated recommendation engines for retail applications based upon simply acquiring an image of the user.",G06K 9/62; G06F 15/18; G06K 9/46; G06K 9/80; G06Q 30/02,VALORBEC LIMITED PARTNERSHIP,"POPA,Tiberiu; ASOODEH, Amir Zafar","62/099,755 05.01.2015 US",US-15541525
WO2014210576,PCT/US2014/044757,27.06.2014,WO/2014/210576,31.12.2014,WO,HIERARCHICAL CLASSIFICATION IN CREDIT CARD DATA EXTRACTION,"Embodiments herein provide computer-implemented techniques for allowing a user computing device to extract financial card information using optical character recognition (""OCR""). Extracting financial card information may be improved by applying various classifiers and other transformations to the image data. For example, applying a linear classifier to the image to determine digit locations before applying the OCR algorithm allows the user computing device to use less processing capacity to extract accurate card data. The OCR application may train a classifier to use the wear patterns of a card to improve OCR algorithm performance. The OCR application may apply a linear classifier and then a nonlinear classifier to improve the performance and the accuracy of the OCR algorithm. The OCR application uses the known digit patterns used by typical credit and debit cards to improve the accuracy of the OCR algorithm.",G06Q 20/22; G06Q 20/34; G06K 9/18; G07F 7/08,GOOGLE INC.,"KUMAR, Sanjiv; ROWLEY, Henry, Allan; WANG, Xiaohang; BISSACCO, Alessandro; RODRIGUES, Jose, Jeronimo, Moreira; PAPINENI, Kishore, Ananda","14/091,093 26.11.2013 US; 61/841,268 28.06.2013 US; 14/059,071 21.10.2013 US; 14/059,108 21.10.2013 US; 14/059,151 21.10.2013 US",
EP276409661,19173136,07.05.2019,3567525,13.11.2019,EP,SYSTEMS AND METHODS FOR ANALYSIS OF ANATOMICAL IMAGES EACH CAPTURED AT A UNIQUE ORIENTATION,,G06K 9/62,ZEBRA MEDICAL VISION LTD,LASERSON JONATHAN,201815972912 07.05.2018 US; 201916269619 07.02.2019 US; 201916269633 07.02.2019 US,
WO2005050563,PCT/US2004/038536,17.11.2004,WO/2005/050563,02.06.2005,WO,PATHOLOGICAL TISSUE MAPPING,"Embodiments of the present invention are directed to quantitative analysis of tissues enabling the measurement of objects and parameters of objects found in images of tissues including perimeter, area, and other metrics of such objects. Measurement results may be input into a relational database where they can be statistically analyzed and compared across studies. The measurement results may be used to create a pathological tissue map of a tissue image, to allow a pathologist to determine a pathological condition of the imaged tissue more quickly.",G06K 9/00; G06T 5/00; G06T 7/00,"AUREON  BIOSCIENCES CORPORATION; KOTSIANTI, Angeliki; SAIDI, Olivier; TEVEROVSKIY, Mikhail","KOTSIANTI, Angeliki; SAIDI, Olivier; TEVEROVSKIY, Mikhail","60/520,815 17.11.2003 US",DE-null
EP232545707,18163807,23.03.2018,3396546,31.10.2018,EP,COMPUTE OPTIMIZATION MECHANISM FOR DEEP NEURAL NETWORKS,"An apparatus to facilitate compute optimization is disclosed. The apparatus includes a plurality of processing units each comprising a plurality of execution units (EUs), wherein the plurality of EUs comprise a first EU type and a second EU type",G06F 9/50; G06F 8/41; G06T 1/20,INTEL CORP,SURTI PRASOONKUMAR; SRINIVASA NARAYAN; CHEN FENG; RAY JOYDEEP; ASHBAUGH BEN J; GALOPPO VON BORRIES NICOLAS C; NURVITADHI ERIKO; VEMBU BALAJI; LIN TSUNG-HAN; SINHA KAMAL; BARIK RAJKISHORE; BAGHSORKHI SARA S; GOTTSCHLICH JUSTIN E; KOKER ALTUG; SATISH NADATHUR RAJAGOPALAN; AKHBARI FARSHAD; KIM DUKHWAN; FU WENYIN; SCHLUESSLER TRAVIS T; MASTRONARDE JOSH B; HURD LINDA L; FEIT JOHN H; BOLES JEFFREY S; LAKE ADAM T; VAIDYANATHAN KARTHIK; BURKE DEVAN; MAIYURAN SUBRAMANIAM; APPU ABHISHEK R; MASTRONARDE JOSH B,201715494886 24.04.2017 US,
WO2019106641,PCT/IB2018/059572,03.12.2018,WO/2019/106641,06.06.2019,WO,SYSTEMS AND METHODS FOR SORTING OF SEEDS,A system for sorting seeds based on their resistance to a stress is disclosed. Batches of purified seeds sorted using the system are also disclosed.,G06K 9/00; G06K 9/20; G06K 9/46; G06K 9/62; B07C 5/34,SEEDX TECHNOLOGIES INC.,"SHNIBERG, Mordekhay; CARMON, Elad; ASHKENAZY, Sarel; GEDALYAHO VAISBERGER, David; AYAL, Sharon","62/593,949 03.12.2017 US; 62/712,293 31.07.2018 US; 62/712,270 31.07.2018 US",
EP241458889,17196983,18.10.2017,3474189,24.04.2019,EP,A DEVICE AND A METHOD FOR ASSIGNING LABELS OF A PLURALITY OF PREDETERMINED CLASSES TO PIXELS OF AN IMAGE,"A device for assigning a label of one of a plurality of predetermined classes to each pixel of an image, the device is configured to receive an image captured by a camera, the image comprising a plurality of pixels; use an encoder convolutional neural network to generate probability values for each pixel, each probability value indicating the probability that the respective pixel is associated with one of the plurality of predetermined classes; generate for each pixel a class prediction value from the probability values, the class prediction value predicting the class of the plurality of predetermined classes the respective pixel is associated with; use an edge detection algorithm to predict boundaries between objects shown in the image, the class prediction values of the pixels being used as input values of the edge detection algorithm; and assign a label of one of the plurality of predetermined classes to each pixel of the image.",G06K 9/46,APTIV TECH LIMITED,FREEMAN IDO; SIEGEMUND JAN,17196983 18.10.2017 EP,
WO2009027486,PCT/EP2008/061339,28.08.2008,WO/2009/027486,05.03.2009,WO,METHODS AND SYSTEMS FOR DATA PROCESSING AND THEIR APPLICATIONS,"A method (400) of processing signal outputs of a plurality of topologically distinct sensors in response to stimuli is described. The method comprises obtaining (402) a plurality of temporal sensor outputs in parallel. Thereafter, features are extracted (406), the features having dynamic behaviour pattern. The extraction is performed in a topology consistent way by arithmetic processing in parallel of neighbouring temporal sensor outputs. Furthermore, a quality of the extracted features is being determined.",G06F 15/00,"TOYOTA MOTOR EUROPE NV; ASCARI, Luca; BERTOCCHI, Ulisse; CORRADI, Paolo; LASCHI, Cecilia; DARIO, Paolo; AMBECK-MADSEN, Jonas; YANAGIHARA, Hiromichi","ASCARI, Luca; BERTOCCHI, Ulisse; CORRADI, Paolo; LASCHI, Cecilia; DARIO, Paolo; AMBECK-MADSEN, Jonas; YANAGIHARA, Hiromichi",07075725.7 28.08.2007 EP,EP-2008787561
WO2008143908,PCT/US2008/006197,14.05.2008,WO/2008/143908,27.11.2008,WO,COMPUTATIONAL USER-HEALTH TESTING,"Methods, apparatuses, computer program products, devices and systems are described that carry out accepting at least one user-health test function output at least partly based on an interaction between at least one user and at least one device-operable application; accepting brain activity measurement data proximate to the interaction; associating the at least one user-health test function output with the brain activity measurement data; and presenting the at least one user-health test function output and the brain activity measurement data at least partly based on the associating the at least one user-health test function output with the brain activity measurement data",A61B 5/00,"SEARETE LLC; JUNG, Edward K.y.; LEUTHARDT, Eric C.; LEVIEN, Royce A.; LORD, Robert W.; MALAMUD, Mark A.","JUNG, Edward K.y.; LEUTHARDT, Eric C.; LEVIEN, Royce A.; LORD, Robert W.; MALAMUD, Mark A.","11/804,304 15.05.2007 US",
WO2008063482,PCT/US2007/023794,15.11.2007,WO/2008/063482,29.05.2008,WO,IMPROVED METHOD AND SYSTEM FOR LEARNING OBJECT RECOGNITION IN IMAGES,"In a first exemplary embodiment of the present invention, an automated, computerized method for learning object recognition in an image is provided. According to a feature of the present invention, the method comprises the steps of providing a training set of standard images, calculating intrinsic images corresponding to the standard images and building a classifier as a function of the intrinsic images.",G06K 9/62,"TANDENT VISION SCIENCE, INC.; FRIEDHOFF, Richard, Mark; MAXWELL, Bruce, Allen","FRIEDHOFF, Richard, Mark; MAXWELL, Bruce, Allen","11/600,624 16.11.2006 US",EP-2007867423
WO2016133900,PCT/US2016/018062,16.02.2016,WO/2016/133900,25.08.2016,WO,MODEL-BASED METHODS AND APPARATUS FOR CLASSIFYING AN INTERFERENT IN SPECIMENS,"A model-based method of inspecting a specimen for presence of one or more interferent, such as Hemolysis, Icterus, and/or Lipemia (HI L) is provided. The method includes generating a pixelated image of the specimen in a first color space, determining color components (e.g., an a-value and a b-value) for pixels in the pixelated image, classifying of the pixels as being either liquid or non-liquid, defining one or more liquid regions based upon the pixels classified as liquid, and determining a presence of one or more interferent within the one or more liquid regions. The liquid classification is based upon a liquid classification model. Pixel classification may be based on a trained multiclass classifier. Interference level for the one or more interferent may be provided. Testing apparatus adapted to carry out the method are described, as are other aspects.",G01N 21/25; G06T 7/40,SIEMENS HEALTHCARE DIAGNOSTICS INC.,"PARK, Jinhyeong; CHANG, Yao-Jen; WU, Wen; CHEN, Terrence; POLLACK, Benjamin","62/117,263 17.02.2015 US",CA-2976769; JP-2017542014
WO2019106638,PCT/IB2018/059568,03.12.2018,WO/2019/106638,06.06.2019,WO,SYSTEMS AND METHODS FOR SORTING OF SEEDS,A system for categorizing seeds of plants into hybrid and non-hybrid categories. Seeds sorted according to the disclosed system are also disclosed.,G06K 9/00; G06K 9/20; G06K 9/46; G06K 9/62; B07C 5/34,SEEDX TECHNOLOGIES INC.,"SHNIBERG, Mordekhay; CARMON, Elad; ASHKENAZY, Sarel; GEDALYAHO VAISBERGER, David; AYAL, Sharon","62/593,949 03.12.2017 US; 62/712,270 31.07.2018 US; 62/712,264 31.07.2018 US",
WO2012037482,PCT/US2011/051977,16.09.2011,WO/2012/037482,22.03.2012,WO,SYSTEM AND METHODS FOR DIGITAL EVALUATION OF CELLBLOCK PREPARATIONS,"Digital evaluation of cellblock preparations to determine the type and extent of disease in order to identify the best approach for treatment without the need for additional testing or sampling. An exemplary method may comprise the steps of: producing digitally a treated Pap smear sample to obtain a digital image; segmenting the digital image to obtain a plurality of segmented digital images; processing each segmented digital image, wherein said processing step further comprises the steps of: locating a nucleus of a cell within each segmented digital image, extracting visual features of the nucleus, and ranking visual features of the nucleus to obtain quantified features within each segmented digital image; joining all segmented digital images to obtain a final digital image; collecting all quantified features of the final digital image to obtain a collection of quantified features; correlating the collection of quantified features to a diagnosis classification; and communicating the diagnosis classification.",G06K 9/00,"UNIVERSITY OF KANSAS; TAWFIK, Ossama; POTETZ, Brian","TAWFIK, Ossama; POTETZ, Brian","61/383,466 16.09.2010 US; 13/234,790 16.09.2011 US",EP-2011826038; JP-2013529370
EP13678088,01202827,03.09.1996,1184840,06.03.2002,EP,Discriminative utterance verification for connected digits recognition,"In a speech recognition system, a recognition processor receives an unknown utterance signal as input. The recognition processor in response to the unknown utterance signal input accesses a recognition database and scores the utterance signal against recognition models in the recognition database to classify the unknown utterance and to generate a hypothesis speech signal. A verification processor receives the hypothesis speech signal as input to be verified. The verification processor accesses a verification database to test the hypothesis speech signal against verification models reflecting a preselected type of training stored in the verification database. Based on the verification test, the verification processor generates a confidence measure signal. The confidence measure signal can be compared against a verification threshold to determine the accuracy of the recognition decision made by the recognition processor. <IMAGE>",G09B 19/06; G10L 15/06; G10L 15/10; G10L 15/14; G10L 15/22; G10L 15/28,AT & T CORP,CHOU WU; JUANG BIING-HWANG; LEE CHIN-HUI; RAHIM MAZING,96306361 03.09.1996 EP; 52890295 15.09.1995 US,
EP249989324,17855305,21.06.2017,3521975,07.08.2019,EP,INFORMATION PROCESSING DEVICE,"[Problem] To perform dynamic output control in response to the emotion of a user even when the subject has difficulty in carrying out an operation involving output. [Solution] Provided is an information processing device equipped with: a deduction unit that deduces a comfort/discomfort level of a subject on the basis of non-verbal expression extracted from vocal information concerning the subject; and an output control unit that performs output control on the basis of the comfort/discomfort level deduced by the deduction unit. Also provided is an information processing device equipped with: a collection unit that collects vocal information concerning a subject; and an output unit that executes informational output based on a control signal, wherein the output unit executes informational output based on the control signal generated on the basis of the subject's comfort/discomfort level deduced from non-verbal expression extracted from the vocal information.",G06F 3/01; G06F 3/16; G06F 13/00; G10L 13/08; G10L 15/10; G10L 15/22; G10L 25/63,SONY CORP; SONY MOBILE COMMUNICATIONS INC,NAKAGAWA AYUMI; SAKAI SHIMON; HOSOKAWA SATOSHI,2016187806 27.09.2016 JP; 2017022766 21.06.2017 JP,
WO2009000474,PCT/EP2008/005001,20.06.2008,WO/2009/000474,31.12.2008,WO,METHOD AND DEVICE FOR REALIZING AN ASSOCIATIVE MEMORY BASED ON INHIBITORY NEURAL NETWORKS,A method for forming an associative computer memory comprises the step of forming an inhibitory memory matrix A' = - (Ap - A). According to the Wilshaw model constrsucted from a given set of address patterns and content patterns' and random matrix structure.,G06N 3/04; G06N 3/08,"HONDA RESEARCH INSTITUTE EUROPE GMBH; KNOBLAUCH, Andreas","KNOBLAUCH, Andreas",07110870.8 22.06.2007 EP,JP-2010512604; US-12599605
WO2018229693,PCT/IB2018/054338,13.06.2018,WO/2018/229693,20.12.2018,WO,METHOD AND SYSTEM FOR AUTOMATICALLY GENERATING LYRICS OF A SONG,A method and system for automatically generating the lyrics of a song is provided to reduce the time and cost of song transcription. The method may include isolating vocal content from instrumental content for a provided audio input. The vocal content may be processed or normalized to obtain a natural vocal content. A speech recognizer may then be utilized to transcribe a plurality of words of the natural vocal content. The plurality of words may then be organized and saved as a lyric time code. The lyric time code may be stored with an audio file or used to generate dynamic outputs associated with the vocal content. The system may include hardware and software to provide deep neural networks used by artificial intelligence to carry out steps of the method.,G10L 15/26; G06F 17/20,"SHARP, Michael; LOVELACE, Kent E.","SHARP, Michael","62/519,466 14.06.2017 US; 15/981,387 16.05.2018 US",
WO2016201508,PCT/AU2016/050500,15.06.2016,WO/2016/201508,22.12.2016,WO,SOIL CONDITION ANALYSIS SYSTEM AND PROCESS,"A soil condition analysis system, including: a support platform to support an elongate soil core extracted from the Earth; a plurality of soil sensing components configured to measure corresponding characteristics of a soil core supported on the support platform; one or more data acquisition components in communication with the soil sensing components and configured to generate measurement data representing the measured characteristics from the soil sensing components; wherein at least one of the support platform and the plurality of soil sensing components is mounted on a computer-controlled translation stage to enable the soil sensing components to automatically measure the corresponding characteristics of the soil core at mutually spaced locations along a longitudinal axis of the elongate soil core. The system includes a data processing and data analytics component configured to process the measurement data to generate soil property data representing corresponding soil properties of the elongate soil core as a function of depth, based on mathematical and statistical methods.",G01N 33/24; G01N 23/04; G01N 1/08,COMMONWEALTH SCIENTIFIC AND INDUSTRIAL RESEARCH ORGANISATION,"VISCARRA ROSSEL, Raphael; FLICK, Paul; LOBSEY, Craig Raymond",2015902264 15.06.2015 AU,AU-2016279908; CL-2017-3233; CA-2989335; EP-2016810620
WO2019211817,PCT/IB2019/053658,03.05.2019,WO/2019/211817,07.11.2019,WO,SYSTEMS AND METHODS FOR GENERATING A CONTEXTUALLY AND CONVERSATIONALLY CORRECT RESPONSE TO A QUERY,"The present disclosure relates to systems and methods for generating contextually, grammatically, and conversationally correct answers to input questions. Embodiments provide for linguistic and syntactic structure analysis of a submitted question in order to determine whether the submitted question may be answered by at least one headnote. The question is then further analyzed to determine more details about the intent and context of the question. A federated search process, based on the linguistic and syntactic structure analysis, and the additional analysis of the question is used to identify candidate question-answer pairs from a corpus of previously created headnotes. Machine learning models are used to analyze the candidate question-answer pairs, additional rules are applied to rank the candidate answers, and dynamic thresholds are applied to identify the best potential answers to provide to a user as a response to the submitted question.",G06F 16/14; G06F 16/20; G06F 16/332; G06F 16/338; G06F 17/24; G06F 17/27; G06Q 50/18; G06Q 50/20,"THOMSON REUTERS ENTERPRISE CENTRE GMBH; CUSTIS, Tonya","CUSTIS, Tonya; SURPRENANT, Matthew A.; LINDBERG, Erik; MCELVAIN, Gayle","62/666,281 03.05.2018 US; 16/402,100 02.05.2019 US",
EP131604001,14181166,15.08.2014,2849087,18.03.2015,EP,A computer generated emulation of a subject,"A system for emulating a subject, to allow a user to interact with a computer generated talking head with the subject's face and voice, 
said system comprising a processor, a user interface and a personality storage section, 
the user interface being configured to emulate the subject, by displaying a talking head which comprises the subject's face and output speech from the mouth of the face with the subject's voice, the user interface further comprising a receiver for receiving a query from the user, the emulated subject being configured to respond to the query received from the user, 
the processor comprising a dialogue section and a talking head generation section, 
wherein said dialogue section is configured to generate a response to a query inputted by a user from the user interface and generate a response to be outputted by the talking head, the response being generated by retrieving information from said personality storage section, said personality storage section comprising content created by or about the subject, 
and said talking head generation section is configured to: 
convert said response into a sequence of acoustic units, the talking head generation section further comprising a statistical model, said statistical model comprising a plurality of model parameters, said model parameters being derived from said personality storage section, the model parameters describing probability distributions which relate an acoustic unit to an image vector and speech vector, said image vector comprising a plurality of parameters which define the subject's face and said speech vector comprising a plurality of parameters which define the subject's voice, the talking head generation section being further configured to output a sequence of speech vectors and image vectors which are synchronised such that the head appears to talk, 
wherein the system is configured to output an expressive response such that said face and voice demonstrate expression, said processor further comprising an expression deriving section configured to determine the expression with which to output the generated response, and wherein the said model parameters describe probability distributions which relate an acoustic unit to an image vector and speech vector for an associated expression, said expression deriving section being configured to extract expressive features from said response to form an expressive linguistic feature vector constructed in a first space and map said expressive linguistic feature vector to an expressive synthesis feature vector that is constructed in a second space, said expressive synthesis feature vector being related to the said model parameters.",G06F 17/27; G06N 3/00; G06T 13/20; G06T 13/40; G10L 21/10,TOSHIBA KK,KOLLURU BALAKRISHNA VENKATA JAGANNADHA; WAN VINCENT PING LEUNG; STENGER BJORN DIETMAR RAFAEL; CIPOLLA ROBERTO; LATORRE-MARTINEZ JAVIER; CHEN LANGZHOU; MAIA RANNIERY DA SILVA; YANAGISAWA KAYOKO; BRAUNSCHWEILER NORBERT; STYLIANOU IOANNIS; BLOKLAND ROBERT ARTHUR,201314711 16.08.2013 GB,
WO2017149443,PCT/IB2017/051154,28.02.2017,WO/2017/149443,08.09.2017,WO,"DEVICE, SYSTEM, AND METHOD FOR CLASSIFICATION OF COGNITIVE BIAS IN MICROBLOGS RELATIVE TO HEALTHCARE-CENTRIC EVIDENCE","A device, system, and method classifies a cognitive bias in a microblog relative to healthcare-centric evidence. The method performed at a microblog server includes receiving a selection from a clinician, the selection indicating a health-related topic. The method includes determining evidence data of the health-related topic from validated information sources. The method includes receiving a microblog, the microblog associated with the health-related topic. The method includes determining a cognitive bias of the microblog based on the evidence data.",G06F 19/00,KONINKLIJKE PHILIPS N.V.,"DATLA, Vivek Varma; FARRI, Oladimeji Feyisetan; AL HASAN, Sheikh Sadid; LEE, Kathy; LIU, Junyi","62/301,250 29.02.2016 US; 62/415,541 01.11.2016 US",EP-2017711762
WO2019213012,PCT/US2019/029790,30.04.2019,WO/2019/213012,07.11.2019,WO,"WEARABLE DEVICE TO MONITOR MUSCULOSKELETAL LOADING, ESTIMATE TISSUE MICRODAMAGE AND PROVIDE INJURY RISK BIOFEEDBACK","A wearable device operably worn by a user for monitoring musculoskeletal loading on structure inside the body of the user includes a plurality of sensors, each sensor operably worn by the user at a predetermined location and configured to detect information about a biomechanical activity of musculoskeletal tissues, a limb segment orientation, and/or a loading magnitude or location thereon; and a processing unit in communication with the plurality of sensors and configured to process the detected information by the plurality of sensors to estimate the musculoskeletal loading, and communicate the estimated musculoskeletal loading to the user and/or a party of interest.",A61B 5/00; A61B 5/11,VANDERBILT UNIVERSITY,"MATIJEVICH, Emily; SCOTT, Leon; ZELIK, Karl","62/664,479 30.04.2018 US",
WO1999005618,PCT/US1998/009711,13.05.1998,WO/1999/005618,04.02.1999,WO,APPARATUS AND METHODS FOR AN INFORMATION RETRIEVAL SYSTEM THAT EMPLOYS NATURAL LANGUAGE PROCESSING OF SEARCH RESULTS TO IMPROVE OVERALL PRECISION,"Apparatus and accompanying methods for an information retrieval system that utilizes natural language processing to process results retrieved by, for example, an information retrieval engine such as a conventional statistical-based search engine, in order to improve overall precision. Specifically, such a search ultimately yields a set of retrieved documents. Each such document is then subjected to natural language processing to produce a set of logical forms. Each such logical form encodes, in a word-relation-word manner, semantic relationships, particularly argument and adjunct structure, between words in a phrase. A user-supplied query is analyzed in the same manner to yield a set of corresponding logical forms therefor. Documents are ranked as a predefined function of the logical forms from the documents and the query. Specifically, the set of logical forms for the query is then compared against a set of logical forms for each of the retrieved documents in order to ascertain a match between any such logical forms in both sets. Each document that has at least one matching logical forms is heuristically scored, with each different relation for a matching logical forms being assigned a different corresponding predefined weight. The score of each such document is, e.g., a predefined function of the weights of its uniquely matching logical forms. Finally, the retained documents are ranked in order of descending score and then presented to a user in that order.",G06F 17/30,MICROSOFT CORPORATION,"BRADEN-HARDER, Lisa; CORSTON, Simon, H.; DOLAN, William, B.; VANDERWENDE, Lucy, H.","08/898,652 22.07.1997 US",CN-98808395.7; EP-1998922234
WO2018126215,PCT/US2017/069104,29.12.2017,WO/2018/126215,05.07.2018,WO,HIGH DEFINITION MAP UPDATES,An online system build a high definition map for geographical regions based on sensor data captured by a plurality of vehicles driving through the geographical regions. The high definition map comprises landmark map including representations of driving paths and landmarks and occupancy map comprising spatial 3D representation of the road and all physical objects around the road. The vehicles provide information to update the landmark map and the occupancy map to the online system. The vehicles detect map discrepancies based on differences in the surroundings observed using sensor data compared to the high definition map and send messages describing these map discrepancies to the online system. The online system ranks the vehicles based on factors including an upload rate of the vehicle and requests data describing high definition map from vehicles selected based on the ranking.,G06F 17/30; G06T 7/60,DEEPMAP CAYMAN LIMITED,"WHEELER, Mark, Damon; WU, Xiaqing; LUO, Wei","62/441,069 30.12.2016 US",EP-2017888334; CN-201780085924.8
EP253959787,18305367,30.03.2018,3547211,02.10.2019,EP,METHODS FOR TRAINING A CNN AND CLASSIFYING AN ACTION PERFORMED BY A SUBJECT IN AN INPUTTED VIDEO USING SAID CNN,,G06K 9/00,NAVER CORP,CHOUTAS VASILEIOS; WEINZAEPFEL PHILIPPE; REVAUD JÉRÔME; SCHMID CORDELIA,18305367 30.03.2018 EP,
WO2013141751,PCT/RU2013/000035,18.01.2013,WO/2013/141751,26.09.2013,WO,EMOTICONS FOR MEDIA,"﻿Disclosed are systems and techniques that generate a set of measures for one or more users to rate media content. A user, for example, indicates her emotions towards the media content according to one or more various inputs. As inputs are received, the inputs are analyzed and associated with at least one of the set of measures to rate the media content according to an emotion. For example, the set of measures include images that indicate various emotions. These measures are associated with the inputs received from the one or more users, and used to evaluate the media content according to the one or more users emotions detected. Therefore, potential users have additional metrics for evaluating potential media content before purchasing, viewing, interacting with, or sharing the media content.",G06F 17/18; G06F 3/01,"RAWLLIN INTERNATIONAL INC.; NIKANKIN, Andrey Nikolaevich; KUZNETSOV, Vsevolod Markovich","NIKANKIN, Andrey Nikolaevich; KUZNETSOV, Vsevolod Markovich","13/424,103 19.03.2012 US",
WO2005098620,PCT/US2005/009999,25.03.2005,WO/2005/098620,20.10.2005,WO,METHOD OF AND APPARATUS FOR REALIZING SYNTHETIC KNOWLEDGE PROCESSES IN DEVICES FOR USEFUL APPLICATIONS,"Arbitrary knowledge and language is retained, manipulated, and transformed according to a universal grammar that defines the mind's innate action on language, or the ""deep"" structure and meaning of language, in analogue and digital devices and software according to operations and knowledge network structures, including programmable digital bytes configured into epistemic moments and parse trees made therefrom.",G06F 15/18; G06F 17/20; G06F 15/00; G06F 17/00; G06F 17/21; G06F 17/24,"DATIG, William, E.","DATIG, William, E.","10/811,507 26.03.2004 US",DE-null
WO2010077979,PCT/US2009/068308,16.12.2009,WO/2010/077979,08.07.2010,WO,DETECTING ANOMALOUS EVENTS USING A LONG-TERM MEMORY IN A VIDEO ANALYSIS SYSTEM,"Techniques are described for detecting anomalous events using a long-term memory in a video analysis system. The long-term memory may be used to store and retrieve information learned while a video analysis system observes a stream of video frames depicting a given scene. Further, the long-term memory may be configured to detect the occurrence of anomalous events, relative to observations of other events that have occurred in the scene over time. A distance measure may used to determine a distance between an active percept (encoding an observed event depicted in the stream of video frames) and a retrieved percept (encoding a memory of previously observed events in the long-term memory). If the distance exceeds a specified threshold, the long-term memory may publish the occurrence of an anomalous event for review by users of the system.",G06F 17/00; G06F 17/10,"BEHAVIORAL RECOGNITION SYSTEMS, INC.; COBB, Wesley Kenneth; SEOW, Ming-Jung; XU, Gang","COBB, Wesley Kenneth; SEOW, Ming-Jung; XU, Gang","12/336,354 16.12.2008 US",EP-2009836911
EP276409730,18879800,01.11.2018,3567585,13.11.2019,EP,INFORMATION PROCESSING DEVICE AND INFORMATION PROCESSING METHOD,"The present technology pertains to an information processing device and an information processing method capable of accelerating the system response to a user's utterance. An information processing device is equipped with a processing unit that determines the presence or absence of a response to a user's utterance on the basis of the results of semantic analysis obtained from the partial results of recognizing the user's utterance. Thus, it is possible to accelerate the system response to the user's utterance. The present technology can be applied to, for example, a speech dialogue system.",G10L 15/22; G06F 3/01; G06F 3/16; G10L 13/00; G10L 15/10,SONY CORP,IWASE HIRO; KAWANO SHINICHI; TAKI YUHEI; SAWAI KUNIHITO,2017219683 15.11.2017 JP; 2018040663 01.11.2018 JP,
WO2004061822,PCT/US2003/041697,31.12.2003,WO/2004/061822,22.07.2004,WO,SPEECH RECOGNITION METHOD,In accordance with a present invention speech recognition is disclosed (10). It uses a microphone to receive audible sounds input by a user into a first computing device (28) having a program with a database (16) comprising (i) digital responses of known audible sounds and associated alphanumeric representations of the known audible sounds and for the first time (ii) digital representations of known audible sounds corresponding to mispronunciations resulting from known class of mispronounced words and phrases. The method is performed by receiving the audible sounds in the form of the electrical output of the microphone (28). A particular audible sound to be recognized is converted into a digital representation of the audible sound (30). The digital representation of the particular audible sound is then compared to the digital representations of the known audible sounds to determine which of those known audible sounds is most likely to be the particular audible sounds in the database (30).,G10L 15/04,"LESSAC TECHNOLOGY, INC.; WILSON, Donald, H.; HANDAL, Anthony, H.; LESSAC, Michael","WILSON, Donald, H.; HANDAL, Anthony, H.; LESSAC, Michael","10/335,226 31.12.2002 US",EP-2003800389; AU-2003300130; IN-1761/CHENP/2005; JP-null
EP231575450,18159487,01.03.2018,3385887,10.10.2018,EP,SUB-GRAPH IN FREQUENCY DOMAIN AND DYNAMIC SELECTION OF CONVOLUTION IMPLEMENTATION ON A GPU,"In an example, an apparatus comprises a plurality of execution units; and logic, at least partially including hardware logic, to determine a sub-graph of a network that can be executed in a frequency domain and apply computations in the sub-graph in the frequency domain. Other embodiments are also disclosed and claimed.",G06N 3/04; G06N 3/063,INTEL CORP,SAREL UZI; COHEN EHUD; SCHWARTZ TOMER; ARMON AMITAI; SHADMIY YAHAV; BEN-ARI LTAMAR; BLEIWEISS AMIT; FAIVISHEVSKY LEV; BAR-ON TOMER; FAIS YANIV; SUBAG JACOB; BEHAR MICHAEL; JACOB GUY; LEIBOVICH GAL; DREYFUSS JEREMIE,201715482724 08.04.2017 US,
WO2016142686,PCT/GB2016/050615,07.03.2016,WO/2016/142686,15.09.2016,WO,LIQUID TRAP OR SEPARATOR FOR ELECTROSURGICAL APPLICATIONS,"An apparatus for mass spectrometry and/or ion mobility spectrometry is disclosed comprising a first device (31) arranged and adapted to generate aerosol, smoke or vapour from a target and one or more second devices (34,35) arranged and adapted to aspirate aerosol, smoke, vapour and/or liquid to or towards an analyser (33). A liquid trap or separator (32) is provided to capture and/or discard liquid aspirated by the one or more second devices (34,35).",G01N 33/68; A61B 17/00; G01N 3/00; G01N 9/00; H01J 49/00; A61B 18/00; G01N 27/62; G01N 33/92,MICROMASS UK LIMITED,"KARANCSI, Tamás; GÖDÖRHÁZY, Lajos; SZALAY, Dániel; TAKÁTS, Zoltán; BALOG, Júlia; PRINGLE, Steven Derek; SIMON, Dániel",1503878.9 06.03.2015 GB; 1503876.3 06.03.2015 GB; 1503864.9 06.03.2015 GB; 1503877.1 06.03.2015 GB; 1503867.2 06.03.2015 GB; 1503863.1 06.03.2015 GB; 1516003.9 09.09.2015 GB; 1518369.2 16.10.2015 GB; 1503879.7 06.03.2015 GB,CN-201680026933.5; GB-1713824.9; KR-1020177028156; CA-2978048; US-15554626; EP-2016710789; JP-2017546868
EP238739209,16899848,29.04.2016,3451238,06.03.2019,EP,APPARATUS AND METHOD FOR EXECUTING POOLING OPERATION,"The present disclosure provides an apparatus for performing a pooling operation. The apparatus includes an instruction storage unit, a controller unit, a data access unit, and an operation module. The instruction storage unit reads instructions through the data access unit and caches the read instructions. The controller unit reads the instructions from the instruction storage unit, decodes the instructions into control signals that controls the behaviors of the operation module, and then distributes the control signals to the operation module. The data access unit is configured to access an external address space to complete data loading and storage. The operation module is configured to perform a maximization operation in a max-pooling operation, or to perform accumulation and multiplication operations in an avgpooling operation. In a forward operation of the max-pooling operation, the operation module cyclically reads an input vector of a pooling kernel, and performs a comparing operation to obtain an output vector of a new kernel and store an index vector corresponding to each output vector until the pooling operation of the current layer is completed. The present disclosure can solve the problem that the operation performance of the CPU and the GPU is insufficient and the front-end decoding overhead is large.",G06N 3/063,CAMBRICON TECH CORPORATION LIMITED,LIU SHAOLI; SONG JIN; CHEN YUNJI; CHEN TIANSHI,2016080696 29.04.2016 CN,
WO2020052678,PCT/CN2019/105854,14.09.2019,WO/2020/052678,19.03.2020,WO,METHOD AND SYSTEM FOR GENERATING SYNTHETIC POINT CLOUD DATA USING A GENERATIVE MODEL,"Methods and systems for generating synthetic point cloud data are described. Projected 2D data grid is generated by projecting a 3D point cloud into a 2D grid, with rotation equivariance. A generative model is learned using the projected 2D data grid, wherein the generative model is implemented using flex-convolution and transpose flex convolution operations, for example in a generative adversarial network. The learned generative model is used to generate synthetic point clouds.",G06K 9/00; G06T 15/10,"HUAWEI TECHNOLOGIES CO., LTD.; THE ROYAL INSTITUTION FOR THE ADVANCEMENT OF LEARNING/MCGILL UNIVERSITY","PAGE-CACCIA, Lucas; PINEAU, Joelle; AMIRLOO ABOLFATHI, Elmira","62/731,690 14.09.2018 US; 16/568,885 12.09.2019 US",
WO2018020462,PCT/IB2017/054581,27.07.2017,WO/2018/020462,01.02.2018,WO,SYSTEM AND METHOD FOR IMPLEMENTING CONTAINERS WHICH EXTRACT AND APPLY SEMANTIC PAGE KNOWLEDGE,"A system for a website building system includes at least one database storing website building system component types of websites of users, semantic composite types and smart box definitions where the semantic composite types are data structures describing components consisting of other components, a smart box handler to analyze and classify sets of components of a page of a website as smart boxes using semantic decomposition, the smart box boxes based on said semantic composite types and the smart box definitions, an editor to enable interactive editing of the website comprising components and the smart boxes, to receive a classification from the smart box handler and to provide additional editing capabilities for the smart boxes based on the classification.",G06F 17/22,WIX.COM LTD.,"BEN-AHARON, Roni","62/367,151 27.07.2016 US; 62/531,897 13.07.2017 US",CA-3030814; MX-MX/a/2019/001112; JP-2019503441; IL-264253; EP-2017833684; AU-2017304396
WO2017112813,PCT/US2016/068123,21.12.2016,WO/2017/112813,29.06.2017,WO,MULTI-LINGUAL VIRTUAL PERSONAL ASSISTANT,"Provided are systems, computer-implemented methods, and computer-program products for a multi-lingual device, capable of receiving verbal input in multiple languages, and further capable of providing conversational responses in multiple languages. In various implementations, the multi-lingual device includes an automatic speech recognition engine capable of receiving verbal input in a first natural language and providing a textual representation of the input and a confidence value for the recognition. The multi-lingual device can also include a machine translation engine, capable of translating textual input from the first natural language into a second natural language. The machine translation engine can output a confidence value for the translation. The multi-lingual device can further include natural language processing, capable of translating from the second natural language to a computer-based language. Input in the computer-based language can be processed, and the multi-lingual device can take an action based on the result of the processing.",G06F 17/28,SRI INTERNATIONAL,"WANG, Wen; VERGYRI, Dimitra; ACHARYA, Girish","62/270,792 22.12.2015 US",
WO2018200979,PCT/US2018/029834,27.04.2018,WO/2018/200979,01.11.2018,WO,GENERATING QUERY VARIANTS USING A TRAINED GENERATIVE MODEL,"Systems, methods, and computer readable media related to generating query variants for a submitted query. In many implementations, the query variants are generated utilizing a generative model. A generative model is productive, in that it can be utilized to actively generate a variant of a query based on application of tokens of the query to the generative model, and optionally based on application of additional input features to the generative model.",G06F 17/30,GOOGLE LLC,"ALAKUIJALA, Jyrki; BUCK, Christian; BULIAN, Jannis; CIARAMITA, Massimiliano; GAJEWSKI, Wojciech; GESMUNDO, Andrea; HOULSBY, Neil; WANG, Wei","62/492,154 29.04.2017 US",CN-201880028212.7; JP-2019558737; EP-2018724709; KR-1020197035500
WO2010084410,PCT/IB2010/000106,21.01.2010,WO/2010/084410,29.07.2010,WO,"METHOD, APPARATUS AND COMPUTER PROGRAM PRODUCT FOR PROVIDING COMPOUND MODELS FOR SPEECH RECOGNITION ADAPTATION","An apparatus for providing compound models for speech recognition adaptation includes a processor. The processor may be configured to receive a speech signal corresponding to a particular speaker, select a cluster model including both a speaker independent portion and a speaker dependent portion based at least in part on a characteristic of speech of the particular speaker, and process the speech signal using the selected cluster model. A corresponding method and computer program product are also provided.",G10L 15/06,"NOKIA CORPORATION; OLSEN, Jesper","OLSEN, Jesper","12/356,814 21.01.2009 US",EP-2010733288; IN-5669/CHENP/2011; CN-201080005155.4
WO2019079493,PCT/US2018/056342,17.10.2018,WO/2019/079493,25.04.2019,WO,METHODS AND SYSTEMS FOR DETECTION OF SOMATIC STRUCTURAL VARIANTS,"Embodiments disclosed herein provide methods, systems, and computer program products that utilize long-range phase information to detect subtle chromosome imbalances in genotype data. Clonal expansions result from mutation followed by selective proliferation, and the embodiments disclosed herein may be used to somatic structural variant events (SVs) predictive or diagnostic of cancer and other diseases.",C40B 20/00; G01N 33/50; G06F 19/00,PRESIDENT AND FELLOWS OF HARVARD COLLEGE,"GENOVESE, Giulio; LOH, Po-Ru; MCCARROLL, Steven","62/573,642 17.10.2017 US",
WO2018140157,PCT/US2017/067327,19.12.2017,WO/2018/140157,02.08.2018,WO,MEASUREMENTS OF PROTEIN-PROTEIN INTERACTIONS AT SINGLE MOLECULE LEVEL,Methods for characterizing the binding characteristic of at least one protein molecule to a detectably labeled probe are provided.,G01N 21/00; G01N 33/52; G01N 33/68,"BIO-RAD LABORATORIES, INC.","LIU, Ning","62/452,231 30.01.2017 US",CN-201780084983.3; EP-2017894436
WO2017032873,PCT/EP2016/070169,26.08.2016,WO/2017/032873,02.03.2017,WO,SYSTEMS AND METHODS FOR MONITORING AND MANAGEMENT OF CHRONIC DISEASE,"Systems and methods assist with managing a chronic disease of a user such as a chronic respiratory or cardiac disease. The system may include a physiological monitor adapted to be carried by the user and operative to sense a physiological parameter of the user by generating one or more signals. The system may include a management device operatively coupled with the physiological monitor to receive the signal(s) and derive the physiological parameter(s) of the user. The management device, such as with an included processor, may be configured to analyze the physiological and/or environmental parameters to detect a trigger pattern of the parameters, the trigger pattern indicative of a probable event of exacerbation of the chronic respiratory and/or cardiac condition. The management device may then generate automated responses based on the trigger pattern such as by providing instructions for activities and/or treatment for the chronic condition.",A61B 5/08; G06F 19/00; A61B 5/00; A61M 16/00; A61B 5/0205,RESMED SENSOR TECHNOLOGIES LIMITED,"SHOULDICE, Redmond","62/210,038 26.08.2015 US",JP-2018510768; EP-2016769871
WO2020033881,PCT/US2019/045987,09.08.2019,WO/2020/033881,13.02.2020,WO,VIRTUAL AGENT SYSTEM AND METHOD FOR MODELLING ORGANIZATION PROCESSSES THEREFOR,"A method, computer program product, and virtual agent system for an organization. The virtual agent system may include one or more processors and one or more memories configured to perform operations. The operations may include loading at least one model related to one or more processes of the organization where the model may be based on the structure information and one or more of procedures and protocols related to the organization. A process request, related to the at least one or more processes of the organization, from a user of the organization, may be received and analyzed",G06Q 10/06; G06F 3/01; G10L 15/18; G10L 15/22; G10L 15/26,"TELEPATHY LABS, INC.","REBER, Martin","62/717,210 10.08.2018 US",
WO2020029235,PCT/CN2018/099914,10.08.2018,WO/2020/029235,13.02.2020,WO,PROVIDING VIDEO RECOMMENDATION,"The present disclosure provides method and apparatus for providing video recommendation. At least one reference factor for the video recommendation may be determined, wherein the at least one reference factor indicates preferred importance of visual information and/or audio information in at least one video to be recommended. A ranking score of each candidate video in a candidate video set may be determined based at least on the at least one reference factor. At least one recommended video may be selected from the candidate video set based at least on ranking scores of candidate videos in the candidate video set. The at least one recommended video may be provided to a user through a terminal device.",H04N 21/45; H04N 21/466,"MICROSOFT TECHNOLOGY LICENSING, LLC; HAN, Bo; LUAN, Qiao; WANG, Yang; THAMBIRATNAM, Albert","HAN, Bo; LUAN, Qiao; WANG, Yang; THAMBIRATNAM, Albert",,
WO2019118256,PCT/US2018/064149,06.12.2018,WO/2019/118256,20.06.2019,WO,GENERATION OF TEXT FROM STRUCTURED DATA,"Implementations of the subject matter described herein provide a solution for generating a text from the structured data. In this solution, the structured data is converted into its representation, where the structured data comprises a plurality of cells, and the representation of the structured data comprises plurality of representations of the plurality of cells. A natural language sentence associated with the structured data may be determined based on the representation of the structured data, thereby implementing the function of converting the structured data into a text.",G06F 17/28; G06F 17/24,"MICROSOFT TECHNOLOGY LICENSING, LLC","DUAN, Nan; LV, Yuanhua; ZHOU, Ming; TANG, Duyu",201711348978.7 15.12.2017 CN,
WO2020003157,PCT/IB2019/055399,26.06.2019,WO/2020/003157,02.01.2020,WO,DYNAMICALLY DETERMINING A REGION,"A computer-implemented method includes monitoring, by a computing device, sensor data during gameplay of a sporting event; determining, by the computing device, predictive factors associated with a target based on the monitoring the sensor data; determining, by the computing device, a real-time region of effectiveness for the target based on the predictive factors and training data identifying historical effectiveness of the target;and outputting, by the computing device, the real-time region of effectiveness for displaying the real-time region of effectiveness around the target.",G06K 9/00,INTERNATIONAL BUSINESS MACHINES CORPORATION; IBM UNITED KINGDOM LIMITED; IBM (CHINA) INVESTMENT COMPANY LIMITED,"BAUGHMAN, Aaron; VAN DER STOCKT, Stefan; TRIM, Craig; NEWELL, John; HAMMER, Stephen","16/021,799 28.06.2018 US",
EP205818743,16168344,04.05.2016,3241489,08.11.2017,EP,PREDICTIVE NEUROMARKERS OF ALZHEIMER'S DISEASE,The present invention relates to predictive neuromarkers of Alzheimer's disease comprising at least one spectral feature obtained from EEG signals of a subject; and at least one Riemannian distance between a spatiofrequential covariance matrix computed from the EEG signals of said subject and at least one reference spatiofrequential covariance matrix. The present invention also relates to a non-invasive method of diagnosing the presence of Alzheimer's disease in a subject using the predictive neuromarkers of Alzheimer's disease; and to a method for self-paced modulation of EEG signals of a subject in order to alleviate symptoms of Alzheimer's disease using the predictive neuromarkers of Alzheimer's disease.,A61B 5/00; A61B 5/0476; A61B 5/048; A61B 5/0482,MENSIA TECH,OJEDA DAVID; BARTHELEMY QUENTIN; MAYAUD LOUIS,16168344 04.05.2016 EP,
WO2001027875,PCT/US2000/028524,12.10.2000,WO/2001/027875,19.04.2001,WO,MODALITY FUSION FOR OBJECT TRACKING WITH TRAINING SYSTEM AND METHOD,"The present invention is embodied in a system and method for training a statistical model, such as a Bayesian network, to effectively capture probabilistic dependencies between the true state of an object (208) being tracked and evidence from various tracking modalities (520) to achieve robust digital vision tracking. The model can be trained and structured offline using data collected from sensors, that may be either vision or non-vision-based, in conjunction with position estimates from the sensing modalities (530). Both the individual reports about targets provided by visual processing modalities and inferences about the context-sensitive accuracies of the reports are considered. Dependencies among variables considered in the model (530) can be restructured with Bayesian learning methods that revise the dependencies considered in the model. In use, the learned models for fusing multiple modalities of visual processing (520) provide real-time position estimates by making inferences from reports from the modalities and by inferences about the context-specific reliabilities of one or more modalities (520).",G06T 7/20,MICROSOFT CORPORATION,"TOYAMA, Kentaro; HORVITZ, Eric","09/416,189 12.10.1999 US",
WO2020005918,PCT/US2019/038953,25.06.2019,WO/2020/005918,02.01.2020,WO,PHRASE RECOGNITION MODEL FOR AUTONOMOUS VEHICLES,"Aspects of the disclosure relate to training and using a phrase recognition model to identify phrases in images. As an example, a selected phrase list 252 including a plurality of phrases may be received. Each phrase of the plurality of phrases includes text. An initial plurality of images may be received. A training image set may be selected from the initial plurality of images by identifying the phrase-containing images that include one or more phrases from the selected phrase list. Each given phrase-containing image of the training image set may be labeled with information identifying the one or more phrases from the selected phrase list included in the given phrase -containing images. The model may be trained based on the training image set such that the model is configured to, in response to receiving an input image, output data indicating whether a phrase of the plurality of phrases is included in the input image.",G06K 9/00; B60W 40/02; B60W 30/14; G05D 1/00; G05D 1/02,WAYMO LLC,"DEAN, Victoria; OGALE, Abhijit, S.; KRETZSCHMAR, Henrik; SILVER, David, Harrison; KERSHAW, Carl; CHAUDHARI, Pankaj; WU, Chen; CONGCONG, Li","16/018,490 26.06.2018 US",
EP15095383,07790791,13.07.2007,2042079,01.04.2009,EP,VISUAL AXIS DIRECTION DETECTION DEVICE AND VISUAL LINE DIRECTION DETECTION METHOD,"Provided is a visual axis direction detection device capable of obtaining a highly accurate visual axis direction detection result without performing a particular calibration for each of examinees. The device (100) includes: a feature calculation unit (160) which calculates as a reference position, a 3D position of the center of a face of an examinee whose visual axis direction is to be detected, from a 3D position of two face parts positioned symmetrically, and calculates as a feature position, a 3D position of the center of the right and left pupils of the examinee in the horizontal direction; a visual axis direction feature amount calculation unit (172) for calculating a shift amount of the feature position from the reference position in the horizontal direction as a visual axis direction feature amount; and a visual axis vector calculation unit (173) for calculating the visual axis direction of the examinee according to the visual axis direction feature amount.",A61B 3/113; G01B 11/26; G06T 1/00; G06T 7/60,PANASONIC CORP,TSUKIZAWA SOTARO,2006194892 14.07.2006 JP; 2007064011 13.07.2007 JP,
WO2018150812,PCT/JP2018/001693,16.01.2018,WO/2018/150812,23.08.2018,WO,BALANCING ACTIVE LEARNING,"An image processing system includes a memory to store a classifier and a set of labeled images for training the classifier, wherein each labeled image is labeled as either a positive image that includes an object of a specific type or a negative image that does not include the object of the specific type, wherein the set of labeled images has a first ratio of the positive images to the negative images. The system includes an input interface to receive a set of input images, a processor to determine a second ratio of the positive images, to classify the input images into positive and negative images to produce a set of classified images, and to select a subset of the classified images having the second ratio of the positive images to the negative images, and an output interface to render the subset of the input images for labeling.",G06K 9/62,MITSUBISHI ELECTRIC CORPORATION,"FENG, Chen; LIU, Ming-Yu; KAO, Chieh-Chi; LEE, Teng-Yok","62/459,834 16.02.2017 US; 15/646,563 11.07.2017 US",
WO2018225012,PCT/IB2018/054126,07.06.2018,WO/2018/225012,13.12.2018,WO,SYSTEM AND METHOD FOR SMART INTERACTION BETWEEN WEBSITE COMPONENTS,"A website building system includes at least one database storing website components and their associated component hierarchies, each component comprising overridable parameterized-behavior elements, non-overridable parameterized-behavior elements and a data handler, the data handler handling override protocols for the components; and an element handler to review all components to be rendered for a current view and for a current component, to handle a communication request between the current component and at least one other component within the component hierarchy in order to implement an override request from the at least one other component, the element handler to update the current component only if the override request is related to an overridable parameterized-behavior element of the current component according to the data handler of the current component.",G06F 17/22,WIX.COM LTD.,"ABRAHAMI, Nadav; IGAL, Barak; BEN-AHARON, Roni","62/516,682 08.06.2017 US; 62/665,629 02.05.2018 US",CA-3063609; EP-2018813721; IL-270766
WO2018011795,PCT/IL2017/050780,10.07.2017,WO/2018/011795,18.01.2018,WO,PROTEIN SIGNATURES FOR DISTINGUISHING BETWEEN BACTERIAL AND VIRAL INFECTIONS,"Methods of diagnosing infections are disclosed. In one embodiment, the method comprises measuring the amount of each of the polypeptides TRAIL, CRP, IP 10 and at least one additional polypeptide selected from the group consisting of IL-6 and PCT.",G01N 33/53; G01N 33/569; G06F 17/18; G06F 19/12; G06F 19/24,MEMED DIAGNOSTICS LTD.,"EDEN, Eran; OVED, Kfir; COHEN-DOTAN, Assaf; NAVON, Roy; BOICO, Olga; KRONENFELD, Gali; PAZ, Meital; BAMBERGER, Ellen","62/360,418 10.07.2016 US",CN-201780055014.5; CA-3027341; EP-2017827121
WO2019075466,PCT/US2018/055892,15.10.2018,WO/2019/075466,18.04.2019,WO,SYSTEM AND METHOD FOR ANALYSIS OF STRUCTURED AND UNSTRUCTURED DATA,"The invention relates to computer-implemented systems and methods for analyzing and standardizing various types of input data such as structured data, semi-structured data, unstructured data, and images and voice. Embodiments of the systems and the methods further provide for generating responses to specific questions based on the standardized input data.",G06F 17/21; G06F 17/22; G06F 17/27; G06F 17/30; G10L 15/18,KPMG LLP,"CERINO, Timothy, J.; EDWARDS, Justin, Mathew; GARDNER, James, Johnson; LEE, John, Hyung; STOENESCU, Gabriel, C.","16/159,088 12.10.2018 US; 62/572,266 13.10.2017 US",
WO2018200685,PCT/US2018/029380,25.04.2018,WO/2018/200685,01.11.2018,WO,"METHODS AND SYSTEMS FOR AN AUTOMATED DESIGN, FULFILLMENT, DEPLOYMENT AND OPERATION PLATFORM FOR LIGHTING INSTALLATIONS",A platform for design of a lighting installation generally includes an automated search engine for retrieving and storing a plurality of lighting objects in a lighting object library and a lighting design environment providing a visual representation of a lighting space containing lighting space objects and lighting objects. The visual representation is based on properties of the lighting space objects and lighting objects obtained from the lighting object library. A plurality of aesthetic filters is configured to permit a designer in a design environment to adjust parameters of the plurality of lighting objects handled in the design environment to provide a desired collective lighting effect using the plurality of lighting objects.,G06F 17/50,ECOSENSE LIGHTING INC.,"HARRISON, Benjamin, James; KOPARKAR, Shruti; REYNOSO, Mark; PICKARD, Paul; PETLURI, Raghuram, L.V.; VICK, Gary; VILLEGAS, Andrew","62/562,714 25.09.2017 US; 62/491,137 27.04.2017 US",
WO2018092135,PCT/IL2017/051251,16.11.2017,WO/2018/092135,24.05.2018,WO,METHOD AND SYSTEM FOR CROP YIELD ESTIMATION,A method for identifying the presence of fruit in image data in an image sensor of a scene includes acquiring image data in an image sensor for at least two distinct wavelengths of a scene. A normalized difference reflectivity index (NDRI) for each location in an array of locations in the image data is calculated with respect to said at least two distinct wavelengths. Regions in the array of locations are identified where the value of the calculated NDRI of the locations in these regions is within a range of values indicative of a presence of fruits in the scene. An output is generated on an output device with information related to the identified presence of fruits.,G01N 21/00; G01N 21/25; G01N 33/02,FRUITSPEC LTD.,"MARGALIT, Nir; NITSAN, Shahar; KULA, Raviv","15/353,754 17.11.2016 US",EP-2017872194; MX-MX/a/2019/005702; AU-2017360842
WO2019172546,PCT/KR2019/001801,14.02.2019,WO/2019/172546,12.09.2019,WO,ELECTRONIC APPARATUS AND CONTROL METHOD THEREOF,"An electronic apparatus is provided. The electronic apparatus includes a storage configured to store a compression rate network model configured to determine a compression rate applied to an image block from among a plurality of compression rates, and a plurality of compression noise removing network models configured to remove compression noise for each of the plurality of compression rates. The compression rate network model can be obtained by learning image characteristics of a plurality of restored image blocks corresponding to each of the plurality of compression rates through a first artificial intelligence algorithm.",H04N 19/85; H04N 19/164; H04N 19/176; H04N 19/119; G06N 20/00; G06N 3/08,"SAMSUNG ELECTRONICS CO., LTD.; SEOUL NATIONAL UNIVERSITY R&DB FOUNDATION","LEE, Hyunseung; KIM, Donghyun; MOON, Youngsu; AHN, Taegyoung; KIM, Yoonsik; PARK, Jaewoo; SOH, Jae Woong; CHO, Nam Ik; AHN, Byeongyong",10-2018-0026209 06.03.2018 KR,
WO2010075312,PCT/US2009/069062,21.12.2009,WO/2010/075312,01.07.2010,WO,METHOD AND APPARATUS FOR CREATING A PATTERN RECOGNIZER,"An image-based pattern recognizer and a method and apparatus for making such a pattern recognizer are disclosed. By employing positional coding, the meaning of any feature present in an image can be defined implicitly in space. The pattern recognizer can be a neural network including a plurality of stages of observers. The observers are configured to cooperate to identify the presence of features in the input image and to recognize a pattern in the input image based on the features. Each of the observers includes a plurality of neurons. The input image includes a plurality of units, and each of the observers is configured to generate a separate output set that includes zero or more coordinates of such units.",G06T 7/40; G06T 7/00,"FIVE APES, INC.; PAQUIER, Williams J. F.","PAQUIER, Williams J. F.","12/344,347 26.12.2008 US",
WO2018156192,PCT/US2017/038949,23.06.2017,WO/2018/156192,30.08.2018,WO,PROVIDING AUXILIARY INFORMATION REGARDING HEALTHCARE PROCEDURE AND SYSTEM PERFORMANCE USING AUGMENTED REALITY,"Techniques for providing information regarding healthcare performance in real-time using augmented reality are provided. In one example, a computer-implemented method comprises receiving input data generated in real-time during performance of a healthcare procedure by a user, including video captured of the user during the performance of the healthcare related procedure. The method further includes determining descriptive information characterizing the performance based on the input data, wherein the descriptive information characterizes at least actions performed by the user during the procedure, and determining whether an aspect of one of the actions currently being performed by the user deviates from a defined protocol for the healthcare related procedure based on comparison of the descriptive information with reference descriptive parameters for the healthcare related procedure. The method further includes determining feedback information regarding correction of the aspect in response to a determination that the aspect deviates from the defined protocol.",G06F 19/00; G06K 9/00,GENERAL ELECTRIC COMPANY,"DIVINE, Lucas; GIBEAUT, Curtis; DICKERSON, Bryan; WIMMER, Megan","15/442,386 24.02.2017 US",JP-2019544806; EP-2017735334; CN-201780086622.2
WO2001069432,PCT/US2001/008710,16.03.2001,WO/2001/069432,20.09.2001,WO,PRIORITIES GENERATION AND MANAGEMENT,"The present invention relates to a system (10, 200) and methodology (74) to enable a plurality of information associated with electronic messages, for example, to be automatically prioritized by a priorities system (12, 230) for transmittal to a user or system. The priorities system (12, 230) can employ classifiers (20) that can be explicitly and/or implicitly trained to prioritize one or more received messages (14) according to a learned importance to the user. As an example, messages (14) can be classified as high, medium, low or other degrees of importance via a training set of examples (30) or types of messages having similar degrees of importance. A background monitor (34) can be provided to monitor a user's activities regarding message processing to further refine or tune the classifier (20) according to the user's personal decisions relating to message importance. Other priorities classifications can involve determinations relating to a loss associated with a time for delayed review or processing of the message.",G06F 17/30; G06F 13/00; G06Q 10/00; H04L 12/58,"MICROSOFT CORPORATION; HORVITZ, Eric, J.; HOVEL, David, O.; JACOBS, Andrew, W.; KADIE, Carl, M.","HORVITZ, Eric, J.; HOVEL, David, O.; JACOBS, Andrew, W.; KADIE, Carl, M.","60/189,801 16.03.2000 US; 09/596,365 17.06.2000 US; 09/596,348 17.06.2000 US; 09/596,364 17.06.2000 US; 60/255,016 12.12.2000 US",US-09882857; JP-2001567443; KR-1020097015992; US-09881502; EP-2001920508; KR-1020097015989; US-10220550; KR-1020087012535; KR-1020027010701; CN-01809513.5
WO2019106639,PCT/IB2018/059569,03.12.2018,WO/2019/106639,06.06.2019,WO,SYSTEMS AND METHODS FOR SORTING OF SEEDS,"Systems for sorting seeds are disclosed, as well as batches of seeds that have been sorted using the systems.",G06K 9/00; G06K 9/20; G06K 9/46; G06K 9/62; B07C 5/34,SEEDX TECHNOLOGIES INC.,"SHNIBERG, Mordekhay; CARMON, Elad; ASHKENAZY, Sarel; GEDALYAHO VAISBERGER, David; AYAL, Sharon","62/593,949 03.12.2017 US; 62/712,270 31.07.2018 US",
EP236490005,17766562,10.03.2017,3431229,23.01.2019,EP,ACTION INFORMATION GENERATION DEVICE,"An operation information generating apparatus includes: a task data recording unit configured to record, as task data, information regarding an operation of a person from a start to an end of a task; an operation classifying unit configured to divide an overall operation from the start to the end of the task into a plurality of partial operations; and an operation combining unit configured to select a best partial operation for each partial operation from a plurality of samples of the task data for the same task, and generates data of an optimum operation of the entire task by combining the selected best partial operations.",B25J 9/22; B25J 9/16; G05B 19/418; G05B 19/42; G05B 19/423; G06Q 10/06,OMRON TATEISI ELECTRONICS CO,ANDO TANICHI,2016049623 14.03.2016 JP; 2017009718 10.03.2017 JP,
EP20634807,10007096,09.07.2010,2309491,13.04.2011,EP,System and method for activating functions including a first function and a second function,"A method and a system for activating functions including a first function and a second function, wherein the system is embedded in an apparatus, are disclosed. The system includes a control configured to be activated by a plurality of activation styles, wherein the control generates a signal indicative of a particular activation style from multiple activation styles; and controller configured to activate either the first function or the second function based on the particular activation style, wherein the first function is configured to be executed based only on the activation style, and wherein the second function is further configured to be executed based on a speech input.",G10L 15/26; G01C 21/36; H04L 29/06,MITSUBISHI ELECTRIC CORP,WEINBERG GARRETT L,55701009 10.09.2009 US,
EP248177986,18164418,27.03.2018,3508823,10.07.2019,EP,METHOD AND SYSTEM FOR GENERATING AND UPDATING VEHICLE NAVIGATION MAPS WITH FEATURES OF NAVIGATION PATHS,"This disclosure relates generally to vehicle navigation maps, and more particularly to method and system for generating and updating vehicle navigation maps with features of navigation paths. In one embodiment, a method may include receiving a position of a vehicle and an environmental field of view (FOV) of the vehicle along a navigation path of the vehicle on a navigation map, extracting features of the navigation path from the environmental FOV, correlating the features with the navigation path on the navigation map based on the position, generating a features based navigation map based on the correlation, and transmitting the features based navigation map to a server of a navigation map service provider for storage and for subsequent use. The features based navigation map, when required to assist a navigation of another vehicle, may be accessed to assess the features of the navigation path and to provide the assessment to the other vehicle.",G01C 21/32; G01S 13/89; G01S 17/89; G06K 9/00,WIPRO LTD,MEGANATHAN RANJITH ROCHAN; KASI AARTHI ALAGAMMAI; JAGANNATH SUJATHA; MANNOPANTAR RAGHOTTAM,201841000427 04.01.2018 IN,
EP128588043,13174360,28.06.2013,2818864,31.12.2014,EP,Remote assistance for aquarists,"A monitoring and control system (10) for an aquarium or pond, comprising a sensor module (11) including sensors for monitoring environmental conditions within the aquarium or pond, and at least one video camera for providing video images of one or more regions of the aquarium or pond; an information transmitting and receiving module (12) for transmitting information gathered by the sensor module to a remote server (20), and receiving instructions; and an action triggering module (13) responsive to said instructions for actuating one or more automated control devices to alter the environmental conditions within the aquarium or pond. Preferably, the sensor module (11) includes sensors for any of water level, temperature, pH, hardness, ammonia, nitrates or nitrites. The sensor module (11) monitors such parameters continuously and autonomously without any need for human intervention, and can thus be left unattended. Video images are transmitted to the remote server (20), allowing an expert system at the remote server to identify conditions within the aquarium/pond, or conditions of individual specimens from analysis of the video images. The action triggering module may include automated control devices for water heating, lighting, filter pump, aeration pump, water changing, food dispensing, water additive dispensing, and medicament dispensing. In this way, corrective action can be taken by the monitoring and control system without the need for manual intervention.",G01N 33/18; A01K 63/00; A01K 63/04,FUJITSU LTD,XIAO HUI,13174360 28.06.2013 EP,
WO2012109630,PCT/US2012/024775,11.02.2012,WO/2012/109630,16.08.2012,WO,IMAGE REGISTRATION,"Image registration is described. In an embodiment an image registration system executes automatic registration of images, for example medical images. In an example, semantic information is computed for each of the images to be registered comprising information about the types of objects in the images and the certainty of that information. In an example a mapping is found to register the images which takes into account the intensities of the image elements as well as the semantic information in a manner which is weighted by the certainty of that semantic information. For example, the semantic information is computed by estimating posterior distributions for the locations of anatomical structures by using a regression forest and transforming the posterior distributions into a probability map. In an example the mapping is found as a global point of inflection of an energy function, the energy function having a term related to the semantic information.",A61B 6/00; A61B 6/03; G06T 5/50; G06F 19/00,MICROSOFT CORPORATION,"KONUKOGLU, Ender; PATHAK, Sayan; SIDDIQUI, Khan Mohammad; CRIMINISI, Antonio; WHITE, Steven; SHOTTON, Jamie Daniel Joseph; ROBERTSON, Duncan Paul","13/025,500 11.02.2011 US",
WO2008109248,PCT/US2008/054239,19.02.2008,WO/2008/109248,12.09.2008,WO,METHOD FOR REAL TIME INTERACTIVE VISUALIZATION OF MUSCLE FORCES AND JOINT TORQUES IN THE HUMAN BODY,"A method and system are provided for the visual display of anatomical forces, that system having : a motion capture system; a computer, receiving data from said motion capture system; and a computational pipeline disposed on said computer; that computational pipeline being configured to calculate muscle forces and joint torques in real time and visually display those forces and torques.",A61B 5/103; A61B 5/117,"MOTEK BV; EVEN-ZOHAR, Oshri; VAN DEN BOGERT, Antonie, J.","EVEN-ZOHAR, Oshri; VAN DEN BOGERT, Antonie, J.","60/893,394 07.03.2007 US; 11/832,726 02.08.2007 US",EP-2008730108; CA-2680462; JP-2009552792
WO2007133694,PCT/US2007/011429,11.05.2007,WO/2007/133694,22.11.2007,WO,FAST COMPUTATION OF COMPACT POSET ISOMORPHISM CERTIFICATES,"A method of for fast construction of poset isomorphism certificates is provided. First, receive poset P1 (201) as seen in Figure 2. Next, receive Poset P2 (202). Then, create the certificates using Omicron-Iota Certificate Constructor (110) and receive Omicron-Iota(pp1) (204) and P2 (205). Check to see if they are equal (206), if they are not, then P1 and P2 are non-Isomorphic (208) if they are, then P1 and P2 are Isomorphic (207).",G06F 15/18,"GEISTIGES EIGENTUM, INC.; EUSTERBROCK, Jutta","EUSTERBROCK, Jutta","60/799,637 11.05.2006 US",US-12300288
WO2019099210,PCT/US2018/058895,02.11.2018,WO/2019/099210,23.05.2019,WO,AUTOMATIC LOCALIZATION GEOMETRY GENERATOR FOR STRIPE-SHAPED OBJECTS,Apparatus and methods are described for generating geometries for stripe- shaped objects. An image is identified that includes a roadway having one or more stripe-shaped objects. The stripe-shaped objects may include lane lines for road edges or lanes of the roadway. The stripe-shaped objects may include a barrier. At least one targeted region within the image is determined. The at least one targeted region is shaped to intersect the one or more stripe-shaped objects and includes a plurality of pixels. An image analysis is performed on the image to determine when the at least one target region includes a pixel in common with the one or more stripe-shaped objects. A geometry is constructed using the pixel in common. The geometry may be used to update a map or subsequently perform localization.,G06K 9/00; G06K 9/62,HERE GLOBAL B.V.,"ZHANG, Qilin; MA, Xiang; CHEN, Xin; SOOD, Sanjay; TABB, Mark; LUO, Chen","15/818,230 20.11.2017 US",
WO2018130871,PCT/IB2017/001776,21.12.2017,WO/2018/130871,19.07.2018,WO,"SYSTEM, METHOD, APPARATUS AND DIAGNOSTIC TEST FOR PLASMODIUM VIVAX","A system, method, apparatus and diagnostic test for Plasmodium vivax, to determine a likelihood of a specific timing of infection by P. vivax in a subject, and hence identify individuals with a high probability of being infected with otherwise undetectable liver-stage hypnozoites. The system, method, apparatus and diagnostic test relate to the identification of hypnozoites (""dormant"" liver-stages), or at least of the likelihood of the subject being so infected. Optionally and preferably, the specific timing relates to recent infections, for example within the last 9 months.",G01N 33/569; C07K 14/445; C07K 16/00,THE WALTER AND ELIZA HALL INSTITUTE OF MEDICAL RESEARCH,"MUELLER, Ivo; TSUBOI, Takafumi; WHITE, Michael; LONGLEY, Rhea","62/438,963 23.12.2016 US",AU-2017393085; EP-2017891342
EP280245511,19156688,12.02.2019,3591581,08.01.2020,EP,METHOD AND APPARATUS FOR BUILDING IMAGE MODEL,,G06K 9/62; G06K 9/46,SAMSUNG ELECTRONICS CO LTD,SUNG JAEMO; KIM CHANGHYUN,20180076226 02.07.2018 KR,
EP105945611,14152193,22.01.2014,2757510,23.07.2014,EP,Method and system for linking data sources for processing composite concepts,A computer-implemented method and system and computer-readable medium are disclosed for linking an ontology provided by a content service (i.e. category ontology) with a word expansion ontology (i.e. lexical ontology). A user may provide an input such as a voice command to an application. The voice command is processed by a natural language processing (NLP) engine to derive the user's intent and to extract relevant entities embodied in the command. The NLP engine may create a composite concept set containing multiple permutations of the concepts (entities extracted) and provide the composite concept set to a concept mapper. The concept mapper searches a mapping file and applies one or more scoring operations to determine a best match between the composite concept set and at least one category provided by the category ontology. The content service is searched using the category and the results are displayed to the user.,G06Q 10/10; G06F 17/30,MALUUBA INC,,201361755107 22.01.2013 US,
WO2017201222,PCT/US2017/033221,18.05.2017,WO/2017/201222,23.11.2017,WO,MODEL-FREE CONTROL FOR REINFORCEMENT LEARNING AGENTS,"Methods, systems, and apparatus for selecting actions to be performed by an agent interacting with an environment. One method includes maintaining return data that maps each observation-action pair to a respective return, the action in each observation-action pair being an action that was performed by the agent in response to the observation in the observation-action pair and the respective return mapped to by each of the observation-action pairs being a return that resulted from the agent performing the action in the observation-action pair; receiving a current observation; determining whether the current observation matches any observation identified in the return data; and in response to determining that the current observation matches a first observation identified in the return data, selecting an action to be performed by the agent using the returns mapped to by observation-action pairs in the return data that include the first observation.",G06N 3/04; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"BLUNDELL, Charles; URIA-MARTINEZ, Benigno","62/339,763 20.05.2016 US",CN-201780031163.8; EP-2017727993
WO2011150316,PCT/US2011/038306,27.05.2011,WO/2011/150316,01.12.2011,WO,OBTAINING ANALYTES FROM A TISSUE SPECIMEN,"A method of obtaining for analysis one or more analytes of diagnostic interest from a tissue specimen having an identified area of diagnostic interest in a two-dimensional spatial location, comprising contacting the identified area of diagnostic interest with a contact medium, effecting at least partial transfer of the one or more analytes from the area of diagnostic interest to the contact medium, and removing the contact medium from the specimen for analysis for the one or more analytes of diagnostic interest.",G01N 33/566,"RAJAGOPALAN, Sridharan; MCLUCAS, William, G.","RAJAGOPALAN, Sridharan; MCLUCAS, William, G.","61/349,654 28.05.2010 US",
WO2019063488,PCT/EP2018/075815,24.09.2018,WO/2019/063488,04.04.2019,WO,SENSOR POSITIONING AND OPTICAL SENSING FOR SENSOR ENABLED WOUND THERAPY DRESSINGS AND SYSTEMS,"In some embodiments, a wound monitoring and/or therapy apparatus can include a wound dressing configured to be positioned over a wound. The wound dressing can support one or more sensors. The one or more sensors can include an optical sensor array cluster, which can include an optical sensor and single light source. In some embodiments, the wound dressing can include a substantially stretchable wound contact layer that includes a wound facing side and a non-wound facing side opposite the wound facing side, the wound facing side configured to be positioned in contact with a wound. The non-wound facing side of the wound contact layer can support a plurality of electronic components and a plurality of electronic connections that connect at least some of the plurality of the electronic components. The electronic components can include one or more sensors configured to obtain measurements of the wound or the periwound, or both.",A61F 13/00; A61B 5/00; A61M 1/00,SMITH & NEPHEW PLC,"HUNT, Allan, Kenneth, Frazer, Grugeon; PHILLIPS, Marcus, Damian",62/563352 26.09.2017 US; 1718859.0 15.11.2017 GB,
WO2019113605,PCT/US2018/065238,12.12.2018,WO/2019/113605,13.06.2019,WO,SYSTEMS AND METHODS FOR MATCHING COLOR AND APPEARANCE OF TARGET COATINGS,"Processor implemented systems and methods for matching color and appearance of a target coating are provided herein. A system includes a storage device for storing instructions, and one or more data processors. The data processor(s) are configured to execute instructions to receive a target image of a target coating. The data processor(s) are also configured to apply a feature extraction analysis process that divides the target image into a plurality of target pixels for image analysis.",G06K 9/00,"AXALTA COATING SYSTEMS IP CO.LLC; STEENHOEK, Larry E.; CANNING, Robert V.; POERIO, Dominic V,; MURPHY, Neil","STEENHOEK, Larry E.; CANNING, Robert V.; POERIO, Dominic V,; MURPHY, Neil","15/833,597 06.12.2017 US",
WO2020050886,PCT/US2019/033352,21.05.2019,WO/2020/050886,12.03.2020,WO,COMPILER-LEVEL GENERAL MATRIX MULTIPLICATION CONFIGURATION OPTIMIZATION,"A system and method is provided for optimizing general matrix multiplication (GEMM) on target hardware by splitting matrices to be multiplied into respective tiles and formulating an optimal tiling configuration for the matrices that collectively achieves a lowest running time for multiplication of matrices A (m x k) and B (k x n) on the target hardware into a search optimization problem that minimizes the running time for respective configuration states as a function of matrix parameters m, k, and n, and numbers of respective nested loops for each dimension m, k, and n, respectively. The optimal tiling configuration for the target hardware is obtained by implementing a Greedy Best-First-Search (GBFS) algorithm or a Neighborhood Actor Advantage Critic (N-A2C) algorithm that optimizes the running time for multiplication of the matrices on the target hardware, and the target hardware is configured and computations are run accordingly.",G06F 17/16,"FUTUREWEI TECHNOLOGIES, INC.","ZANG, Hui; ZHANG, Huaqing; CHENG, Xiaolin","62/727,423 05.09.2018 US",
WO2018107220,PCT/AU2017/051375,12.12.2017,WO/2018/107220,21.06.2018,WO,IMPROVEMENTS IN MEDICATION DELIVERY TO ANIMALS,"In an aspect there is disclosed, a method for monitoring and controlling a dose of a substance to an animal using a substance delivery system, the method including: measuring, at least one of immediately prior to and during delivery of the substance, a one or more measured parameters associated with a substance profile of the substance; determining, error data between the one or more measured parameters and a one or more reference parameters of the associated substance profile; and processing the error data to determine one of an active state, in which the dose is deliverable by the delivery system, and an error state in which the delivery system is configured to at least one of inhibit delivery of the dose, provide an error alert and record a non-compliant state. An associated system and various further methods and configurations of the system are also disclosed.",A61D 7/00; G06F 19/00,AUTOMED PTY LTD,"EDWARDS, David Royce",2016905117 12.12.2016 AU,
EP248884883,18151286,11.01.2018,3511868,17.07.2019,EP,DOCUMENT AUTHENTICITY DETERMINATION,,G06K 9/68; G06K 9/00; G06K 9/32,ONFIDO LTD,GOMES JOAO SILVA; CALI JACQUES,18151286 11.01.2018 EP,
EP203841214,15794785,06.11.2015,3218901,20.09.2017,EP,PREDICTION-BASED SEQUENCE RECOGNITION,,G10L 15/16; G06N 3/04,MICROSOFT TECHNOLOGY LICENSING LLC,YU DONG; ZHANG YU; SELTZER MICHAEL L; DROPPO JAMES G,201414578938 22.12.2014 US; 201462079164 13.11.2014 US; 2015059361 06.11.2015 US,
EP239836942,17798976,03.03.2017,3459344,27.03.2019,EP,"INFORMATION PROCESSING DEVICE, PROGRAM, AND INFORMATION PROCESSING METHOD","[Object] To implement display of a nurture target that conforms more closely to a real environment.  [Solution] Provided is an information processing apparatus including: a determination unit configured to determine, on a basis of collected sensor information and a nurture model associated with a nurture target, a nurture state of the nurture target; and an output control unit configured to control an output related to the nurture target, in accordance with the nurture state of the nurture target. Also provided is an information processing method including: determining, by a processor, on a basis of collected sensor information and a nurture model associated with a nurture target, a nurture state of the nurture target; and controlling an output related to the nurture target, in accordance with the nurture state of the nurture target.",A01G 7/00; A63F 13/213; A63F 13/217; A63F 13/58; A63F 13/65; A63F 13/825; G06N 3/00; G06Q 50/02,SONY CORP,MATSUZAWA SOTA; FUJITA TAKUYA; KANEMOTO KATSUYOSHI,2016099729 18.05.2016 JP; 2017008607 03.03.2017 JP,
WO2018211408,PCT/IB2018/053364,15.05.2018,WO/2018/211408,22.11.2018,WO,NEURAL PARAPHRASE GENERATOR,"A neural paraphrase generator receives a sequence of tuples comprising a source sequence of words, each tuple comprising word data element and structured tag element representing a linguistic attribute about the word data element. An RNN encoder receives a sequence of vectors representing a source sequence of words, and RNN decoder predicts a probability of a target sequence of words representing a target output sentence based on a recurrent state in the decoder. An input composition component includes a word embedding matrix and a tag embedding matrix transforms the input sequence of tuples into a sequence of vectors. An output decomposition component outputs a target sequence of tuples representing predicted words and structured tag elements, the probability of each single tuple from the output is predicted based on a recurrent state of the decoder.",G06F 17/27; G06F 17/28,THOMSON REUTERS GLOBAL RESOURCES UNLIMITED COMPANY,"LEIDNER, Jochen; PLACHOURAS, Vassilis; PETRONI, Fabio","62/506,223 15.05.2017 US",CA-3063006; AU-2018270241; EP-2018737016
WO2019032723,PCT/US2018/045840,08.08.2018,WO/2019/032723,14.02.2019,WO,"SYSTEMS, DEVICES, AND METHODS FOR IMAGE PROCESSING TO GENERATE AN IMAGE HAVING PREDICTIVE TAGGING","A computing device, method, system, and instructions in a non-transitory computerreadable medium for performing image analysis on 3D microscopy images to predict localization and/or labeling of various structures or objects of interest, by predicting the location in such images at which a dye or other marker associated with such structures would appear. The computing device, method, and system receives sets of 3D images that include unlabeled images, such as transmitted light images or electron microscope images, and labeled images, such as images captured with fluorescence tagging. The computing device trains a statistical model to associate structures in the labeled images with the same structures in the unlabeled light images. The processor further applies the statistical model to a new unlabeled image to generate a predictive labeled image that predicts the location of a structure of interest in the new image.",A61B 5/0275; G06K 9/66,ALLEN INSTITUTE,"JOHNSON, Gregory; OUNKOMOL, Chawin; COLLMAN, Forrest; SESHAMANI, Sharmishtaa","62/543,333 09.08.2017 US; 62/560,043 18.09.2017 US; 62/568,749 05.10.2017 US; 62/647,456 23.03.2018 US; 62/651,765 03.04.2018 US",AU-2018313841; EP-2018843647
EP13849250,01119350,10.08.2001,1267288,18.12.2002,EP,Online creation and management of enterprises,"The underlying invention generally relates to the field of electronic business and commerce via the Internet, especially to websites using graphical interfaces (200) to provide a method for an online creation and management of enterprises by means of applications running on a server (102) in a data network environment (104). Thereby, the server (102) can be accessed from clients (106,108) over the data network (104). Application programs can be started by means of a graphical interface (200) offered to the clients. The process data of the application programs can be accessed by the clients (106,108) or stored on distributed resources (110) of the data network (104). Moreover, the applications generate data relevant for creating and/or managing enterprises. <IMAGE>",G06F 17/60; G06Q 40/00,DONATIEN ROGER,DONATIEN ROGER,01114130 11.06.2001 EP; 01119350 10.08.2001 EP,
WO2018104834,PCT/IB2017/057578,01.12.2017,WO/2018/104834,14.06.2018,WO,"REAL-TIME, EPHEMERAL, SINGLE MODE, GROUP & AUTO TAKING VISUAL MEDIA, STORIES, AUTO STATUS, FOLLOWING FEED TYPES, MASS ACTIONS, SUGGESTED ACTIVITIES, AR MEDIA & PLATFORM","Various embodiments of a system, methods, platform, database, search engine & device enabling user to auto open or unlocks user device, auto open camera display screen, auto capture photo or auto start recording of video, auto open media viewer when user wants to view, apply ephemeral or non-ephemeral and real-time content access rules and settings for one or more destinations and/or sources, enables user to search, match, save, bookmark, subscribe and view one or more object criteria specific contents, user related visual media captured by other users related privacy settings, supplied object models specific advertisements in visual media feeds, enables sender of media to access media shared by sender at recipient device, enables various embodiments relates to the display of ephemeral messages and real-time ephemeral messages, enables multi-tasking intelligent visual media capture controller so user can easily take front or back photo or video or live stream and view received media items and/or access one or more pre-set interfaces or applications, enables auto generating of user's current status, user's current activities and auto generate emoticons, emoji, cartoon based on front and/or back camera photo(s) and/or video(s) and user data, auto open or unlock camera device and auto start recording of parent video and during recording of said parent video enabling to store trimmed video(s) and/or back camera & front camera video(s) and/or capture photo(s) and/or share with contact(s) and/or group(s) and/or destination(s), enable to create events so invited or targeted criteria specific participants including based on profile data, supplied object, voice, location or place, status or presented members at particular place or location can capture, share & view one or more types of media, enable augmented reality platform, enabling new type of media including augmented reality photo or video which user can share with others, enabling automated recording and providing of viewing user's reactions, enabling requirement specification specific responses and real-time communications for better matchmaking, quality, services & saving money, enabling user to user providing and consuming visual media taking service(s), enabling periocular session start and end date & time specific presentation of one or more types of contents for enabling one or more types of mass user actions (view, buy, participate, react etc.), enabling user's availability specific presentation of suggested activities, enabling user's multi types feeds following, enabling to identify user related keywords, and enables natural talking like communication application.",G06K 9/00; G06F 3/01; G06T 7/00; G06T 7/73,"RATHOD, Yogesh Chunilal","RATHOD, Yogesh Chunilal",PCT/IB2016/057398 07.12.2016 IB; PCT/IB2017/050468 29.01.2017 IB,
WO2018102425,PCT/US2017/063732,29.11.2017,WO/2018/102425,07.06.2018,WO,VEHICLE CONTROL SYSTEM AND METHOD OF USE,"A system for controlling a vehicle navigating a roadway, including a perception module that generates sensor data and outputs a cost map and traffic data associated with traffic objects, a behavior planning module that receives the cost map and the traffic data from the perception module and generates planner primitives, a training module that receives the cost map and the traffic data from the perception module, receives driver input from a vehicle operator, and trains the behavior planning module, a local planning module comprising a set of task blocks that receives the cost map from the perception module and the planner primitives from the behavior planning module, selects a task block, and generates control commands using the selected task block; and a control module comprising an actuation subsystem, wherein the control module receives the control commands from the local planning module and controls the actuation subsystem.",G06F 19/00,"STARSKY ROBOTICS, INC.","TIWARI, Kartik; SELTZ-AZMACHER, Stefan","62/521,127 16.06.2017 US; 62/429,272 02.12.2016 US",CN-201780074363.1; EP-2017876351
WO2015074918,PCT/EP2014/074304,12.11.2014,WO/2015/074918,28.05.2015,WO,APNEA SAFETY CONTROL,"The present invention relates to a safety support system (10), comprising a data interface (20) for receiving sleep quality data carrying information on the sleep quality of a person (12), a sleep quality assessment unit (22) for determining a sleep quality indicator being indicative of the sleep quality of the person (12) based on the received sleep quality data and a safety unit (24) for determining machine operation settings for the person (12) based on the sleep quality indicator, said machine operation settings being indicative of an allowed operation of a machine (14) by the person (12). The present invention further relates to a corresponding method and to a machine (14) comprising a safety support system (10) as described above.",A61B 5/00; B60K 28/06; A61B 5/18; A61B 5/0402; A61B 5/0476; A61B 5/0488; A61B 5/0496; A61B 5/0295; A61B 5/08; A61B 5/087; G08B 21/06,KONINKLIJKE PHILIPS N.V.,"LAWRENSON, Matthew John",13193995.1 22.11.2013 EP,US-15035512; JP-2016532109; EP-2014799387
WO2015084682,PCT/US2014/067800,28.11.2014,WO/2015/084682,11.06.2015,WO,INTERACTIVE CONTENT CONSUMPTION THROUGH TEXT AND IMAGE SELECTION,"Methods, systems, and computer program products are provided that enable content feedback to be provided in association with displayed content. A user is enabled to interact with the displayed content to indicate a first preference that the displayed content is not preferred and that replacement content be provided, to indicate a second preference that the displayed content is preferred and that similar content to the displayed content be provided, or to indicate a third preference that the displayed content is preferred and that content that is descriptive of the displayed content be provided.",G06F 17/30,"MICROSOFT TECHNOLOGY LICENSING, LLC","LIU, Zhen; HSU, Chien Chih (Jacky); JAW, Jing-Yeu; LIU, Chen (Howard)","14/098,077 05.12.2013 US",
WO2015127394,PCT/US2015/017155,23.02.2015,WO/2015/127394,27.08.2015,WO,"SYSTEM FOR BEAUTY, COSMETIC, AND FASHION ANALYSIS","A system and method are provided to detect, analyze and digitally remove makeup from an image of a face. An autoencoder-based framework is provided to extract attractiveness-aware features to perform an assessment of facial beauty.",G06K 9/46; G06K 9/66; G06T 7/40,NORTHEASTERN UNIVERSITY,"FU, Yun; WANG, Shuyang","61/943,439 23.02.2014 US; 61/994,169 16.05.2014 US",US-15120287
WO2008121401,PCT/US2008/004187,28.03.2008,WO/2008/121401,09.10.2008,WO,COMPUTATIONAL USER-HEALTH TESTING,"Methods, apparatuses, computer program products, devices and systems are described that carry out detecting user data from an interaction between a user and at least one device-implemented application whose primary function is different from symptom detection; mapping the user data from the interaction between the user and the at least one device-implemented application whose primary function is different from symptom detection to at least one user-health test function set; and selecting at least one user-health test function in response to the at least one user-health test function set.",G06F 19/00,"SEARETE LLC; JUNG, Edward, K., Y.; LEUTHARDT, Eric, C.; LEVIEN, Royce, A.; LORD, Robert, W.; MALAMUD, Mark, A.","JUNG, Edward, K., Y.; LEUTHARDT, Eric, C.; LEVIEN, Royce, A.; LORD, Robert, W.; MALAMUD, Mark, A.","11/731,745 30.03.2007 US; 11/731,778 30.03.2007 US; 11/731,801 30.03.2007 US; 11/804,304 15.05.2007 US; 11/807,220 24.05.2007 US",GB-0918569.5
WO2016081954,PCT/US2015/066547,18.12.2015,WO/2016/081954,26.05.2016,WO,PREDICTIVE MAINTENANCE AND QUALITY ASSURANCE OF A PROCESS AND MACHINE USING RECONFIGURABLE SENSOR NETWORKS,"A system for rule management, predictive maintenance and quality assurance of a process using automatic rule formation comprising a plurality of sensors capable of being attached to at least one machine for measuring at least one information about the process and machine operation. The system comprises a server connected to the sensors over a wireless communication network and running a reconfigurable rule management program for identifying and processing the particular process and machine information related to at least one process received from the plurality of sensors. A controller in communication with the server capable of controlling the process based on a rule set by the rule engine. The rule engine automatically detects the normal process data, classifies the received data based on the dynamic rule formed by the rule engine and finds anomalies in the process or machine operation for predictive maintenance and process quality assurance.",G06E 1/00,"PROPHECY SENSORS, LLC; PAL, Biplab","PAL, Biplab; SARKAR, Avijit; NAGI, Neeraj; PAL, Prosenjit","62/081,198 18.11.2014 US",
WO2018157130,PCT/US2018/019945,27.02.2018,WO/2018/157130,30.08.2018,WO,COMPUTATIONAL ULTRASOUND FOR IMPROVED LIVER AND KIDNEY CANCER DIAGNOSIS,This disclosure provides a system and method for generating an ultrasound image. The method includes receiving a raw ultrasound signal output from an ultrasound device and performing operations to transform the raw ultrasound signal into an enhanced ultrasound image. The enhanced ultrasound image may be further processed by radial symmetry filtering to generate a radial symmetry image. Both the enhanced image and the radial symmetry image can be by a medical practitioner to make a liver or kidney cancer diagnosis exclusively based on ultrasound data.,G01R 33/50; G06K 9/40,"RUTGERS, THE STATE UNIVERSITY OF NEW JERSEY","NOSHER, John; HACIHALILOGLU, Ilker","62/464,058 27.02.2017 US",EP-2018758169; JP-2019546275; CN-201880028198.0
EP174142074,15197198,01.12.2015,3032459,15.06.2016,EP,REALOGRAM SCENE ANALYSIS OF IMAGES: SHELF AND LABEL FINDING,"The techniques include an image recognition system to receive a realogram image including a plurality of organized objects and to detect and identify objects in the realogram image of one or more items on a retail shelf, identify shelf fronts and labels on the shelf fronts, identify empty space under shelves, identify areas where unidentified products may be, and identify areas where products are ""out of stock"".",G06K 9/00; G06Q 10/08,RICOH CO LTD,SCHWARTZ EDWARD L,201462090177 10.12.2014 US; 201514641290 06.03.2015 US; 201514641292 06.03.2015 US; 201514641296 06.03.2015 US,
WO2018148136,PCT/US2018/016812,05.02.2018,WO/2018/148136,16.08.2018,WO,INVERSION OF SIGNAL MEASUREMENTS TO GENERATE MEDICAL IMAGES,"Systems and methods for inversion of signal measurements for medical imaging are provided. In one example implementation, a method can include accessing a plurality of signal measurements. The method can include accessing a convolution model defining a relationship between signal measurements and property of the specimen. The method can include determining a property distribution for the specimen by performing an inversion based at least in part on the convolution model and signal measurements. The inversion can based at least in part on a penalized objective function. The penalized objective function having a penalty term. The penalty term for individual solution components can be independently weighted. The method can include generating a property map of the specimen based at least in part on the property distribution; and outputting the property map as an image on a display device.",A61B 5/05,"KIMBERLY-CLARK WORLDWIDE, INC.","FELDKAMP, Joseph, R.","62/455,756 07.02.2017 US",
WO2020053573,PCT/GB2019/052521,10.09.2019,WO/2020/053573,19.03.2020,WO,"CONTROL AND NAVIGATION SYSTEMS, POSE OPTIMISATION, MAPPING, AND LOCALISATION TECHNIQUES","A navigation program for an autonomous vehicle, the navigation program configured to: receive an initial model of an object to be inspected by the autonomous vehicle; identify an inspection target associated with the initial model of the object; and determine an inspection location for the autonomous vehicle from which inspection target is inspectable by an inspection system of the autonomous vehicle, wherein the initial model includes one or more convex shapes representing the object.",G05D 1/00; F03D 17/00; B64C 39/02; G01M 1/00; G06F 17/00; G06K 9/00; G08G 5/00,PERCEPTUAL ROBOTICS LIMITED,"KARACHALIOS, Konstantinos; NIKOLAIDIS, Dimitrios; DRISCOLL-LIND, Kevin; GREATWOOD, Colin; CALWAY, Andrew; MOOLAN-FEROZE, Oliver",20180100410 10.09.2018 GR; 1815864.2 28.09.2018 GB; 20190100076 13.02.2019 GR; 1902475.1 22.02.2019 GB,
WO2016123635,PCT/US2016/016024,01.02.2016,WO/2016/123635,04.08.2016,WO,CONTROL OF A COMPUTER VIA DISTORTIONS OF FACIAL GEOMETRY,"A system which, with data provided by one or more sensors, detects a user's alteration of the geometries of parts of his face, head, neck, and/or shoulders. It determines the extent of each alteration and normalizes it with respect to the maximum possible range of each alteration so as to assign to each part-specific alteration a numeric score indicative of its extent. The normalized part-specific scores are combined so as to produce a composite numeric code representative of the complete set of simultaneously-executed geometric alterations. Each composite code is translated, or interpreted, relative to an appropriate context defined by an embodiment, an application executing on an embodiment, or by the user. For example, each composite code might be interpreted as, or assigned to, a specific alphanumeric letter, a color, a musical note, etc.",G06K 9/66,"MOFFAT, Brian Lee; CHEN, Rin In","MOFFAT, Brian Lee; CHEN, Rin In","62/125,758 31.01.2015 US",US-15546929; CA-2975124; JP-2017559280
WO2018022602,PCT/US2017/043693,25.07.2017,WO/2018/022602,01.02.2018,WO,METHODS AND APPARATUS FOR PREDICTING MUSCULO-SKELETAL POSITION INFORMATION USING WEARABLE AUTONOMOUS SENSORS,"Methods and apparatus for providing a dynamically-updated computerized musculo- skeletal representation comprising a plurality of rigid body segments connected by joints. The method comprises recording, using a plurality of autonomous sensors arranged on one or more wearable devices, a plurality of autonomous signals from a user, wherein the plurality of autonomous sensors include a plurality of neuromuscular sensors configured to record neuromuscular signals. The method further comprises providing as input to a trained statistical model, the plurality of neuromuscular signals and/or information based on the plurality of neuromuscular signals. The method further comprises determining, based on an output of the trained statistical model, musculo-skeletal position information describing a spatial relationship between two or more connected segments of the plurality of rigid body segments of the computerized musculo-skeletal representation, and updating the computerized musculo-skeletal representation based, at least in part, on the musculo-skeletal position information.",A61B 5/00; A61B 5/0205; A61B 5/024; A61B 5/0402; A61B 5/103; A61B 5/1477,"CTRL-LABS CORPORATION; KAIFOSH, Patrick; MACHADO, Timothy; REARDON, Thomas; SCHOMBURG, Erik","KAIFOSH, Patrick; MACHADO, Timothy; REARDON, Thomas; SCHOMBURG, Erik","62/366,421 25.07.2016 US",EP-2017835112; CN-201780059093.7
WO2016182558,PCT/US2015/030292,12.05.2015,WO/2016/182558,17.11.2016,WO,ENHANCING OILFIELD OPERATIONS WITH COGNITIVE COMPUTING,"A cognitive computing system for enhancing oilfield operations, in some embodiments, comprises: neurosynaptic processing logic; and one or more information repositories accessible to the neurosynaptic processing logic, wherein the neurosynaptic processing logic produces a recommendation in response to an oilfield operations indication, the neurosynaptic processing logic produces said recommendation based on a probabilistic analysis of said oilfield operations indication, resources in the one or more information repositories, and oilfield operations models in the one or more information repositories, said oilfield operations models pertaining to oilfield operations associated with said indication, wherein the neurosynaptic processing logic presents said recommendation to a user.",G06F 19/00; G05B 19/02; E21B 44/00,"HALLIBURTON ENERGY SERVICES, INC.","JAMISON, Dale, E.; WILLIAMS, Robert, Lynn; BAR, Amir",,AU-2015394577; CA-2980874; GB-1715559.9; MX-MX/a/2017/013242; NO-20171576; US-15564167
EP14050529,00952285,31.07.2000,1384163,28.01.2004,EP,METHOD AND SYSTEM FOR PRIORITIZED ALERTS,"Methods for prioritizing documents, such as email messages, are disclosed. In one embodiment, a method first receives a document. The method assigns a measure of priority to the document, by employing a text classifier such as a Bayesian classifier or a support-vector machine classifier. The method then outputs the priority. In one embodiment, the method includes alerting the user about a document, such as an email message, based on the expected loss associated with delays expected in reviewing the document as compared to the expected cost of distraction and transmission incurred with alerting the user about the document.",G06F 13/00; G06F 17/30; G06Q 10/00,MICROSOFT CORP,HORVITZ ERIC J; JACOBS ANDREW W,0020685 31.07.2000 US; 36452299 30.07.1999 US; 36452799 30.07.1999 US; 36452899 30.07.1999 US; 36529399 30.07.1999 US,
WO2015191338,PCT/US2015/033858,03.06.2015,WO/2015/191338,17.12.2015,WO,ENTRANCE DETECTION FROM STREET-LEVEL IMAGERY,"Architecture that detects entrances on building facades. In a first stage, scene geometry is exploited and the multi-dimensional problem is reduced down to a one-dimensional (1D) problem. Entrance hypotheses are generated by considering pairs of locations along lines exhibiting strong gradients in the transverse direction. In a second stage, a rich set of discriminative image features for entrances is explored according to constructed designs, specifically focusing on properties such as symmetry and color consistency, for example. Classifiers (e.g., random forest) are utilized to perform automatic feature selection and entrance classification. In another stage, a joint model is formulated in three dimensions (3D) for entrances on a given facade, which enables the exploitation of physical constraints between different entrances on the same facade in a systematic manner to prune false positives, and thereby select an optimum set of entrances on a given facade.",G06K 9/00,"UBER TECHNOLOGIES, INC.","LIU, Jingchen; PARAMESWARAN, Vasudev; KORAH, Thommen; HEDAU, Varsha; GRZESZCZUK, Radek; LIU, Yanxi","14/298,932 08.06.2014 US",EP-2015748333
WO2018096789,PCT/JP2017/035762,26.09.2017,WO/2018/096789,31.05.2018,WO,METHOD FOR TRAINING NEURON NETWORK AND ACTIVE LEARNING SYSTEM,"A method for training a neuron network using a processor in communication with a memory includes determining features of a signal using the neuron network, determining an uncertainty measure of the features for classifying the signal, reconstructing the signal from the features using a decoder neuron network to produce a reconstructed signal, comparing the reconstructed signal with the signal to produce a reconstruction error, combining the uncertainty measure with the reconstruction error to produce a rank of the signal for a necessity of a manual labeling, labeling the signal according to the rank to produce the labeled signal; and training the neuron network and the decoder neuron network using the labeled signal.",G06N 3/04; G06N 3/08,MITSUBISHI ELECTRIC CORPORATION,"LIU, Ming-Yu; KAO, Chieh-Chi","15/358,420 22.11.2016 US",EP-2017788318; SG-11201902477R; JP-2019501745
WO2013066497,PCT/US2012/054572,11.09.2012,WO/2013/066497,10.05.2013,WO,METHOD AND APPARATUS FOR AUTOMATICALLY SUMMARIZING THE CONTENTS OF ELECTRONIC DOCUMENTS,"One embodiment of a method for summarizing an electronic document includes splitting the electronic document into a plurality of terms, wherein each of the plurality of terms is associated with a respective length, a respective informativeness score, and a respective coherence score, automatically selecting a subset of the plurality of terms, such that an aggregate informativeness score of the subset is maximized while an aggregate length of the subset is less than or equal to a maximum length, and arranging the subset as a summary of the electronic document.",G06F 17/21,"YAHOO! INC.; MANI, Inderjeet; CIURANA, Eugenio; D'ALOISIO-MONTILLA, Nicholas; SWANSON, Bart K.","MANI, Inderjeet; CIURANA, Eugenio; D'ALOISIO-MONTILLA, Nicholas; SWANSON, Bart K.","61/568,188 08.12.2011 US; GB1117848.0 14.10.2011 GB; GB1121033.3 07.12.2011 GB",JP-2014535720; US-14348830; CA-2851772; RU-2014119239; IL-231802; AU-2012327239; EP-2012846059
WO2019015633,PCT/CN2018/096238,19.07.2018,WO/2019/015633,24.01.2019,WO,SYSTEMS AND METHODS FOR PROCESSING A CONVERSATION MESSAGE,The present disclosure is related to systems and methods for processing a conversation message. The method includes receiving the conversation message from the client terminal via the data exchange port. The method also includes determining whether the conversation message is associated with at least one pre-set topic category. The method also includes determining a topic category associated with the conversation message based on a prior conversation message in response to a determination that the conversation message is not associated with at least one pre-set topic category. The method further includes determining a semantics associated with the conversation message based on the topic category and the conversation message. The method still further includes generating a response to the conversation message based on the determined semantics to be transmitted to the service system implemented on the client terminal via the data exchange port.,G06F 17/28,"BEIJING DIDI INFINITY TECHNOLOGY AND DEVELOPMENT CO., LTD.","WANG, Yu; YE, Zhou; ZHANG, Duokun; LI, Min; LEI, Hui; GUO, Rui",201710590119.2 19.07.2017 CN,EP-2018835324
WO2020006571,PCT/US2019/040200,01.07.2019,WO/2020/006571,02.01.2020,WO,MACHINE LEARNING SYSTEMS AND METHODS FOR PREDICTING RISK OF RENAL FUNCTION DECLINE,"Systems, methods and apparatuses are described herein that employ machine learning techniques to assess a likelihood or risk that one or more patients will experience an adverse outcome, such as a decline in renal function, within one or more timeframes. The embodiments may utilize patient data relating to demographics, vital signs, diagnoses, procedures, diagnostic tests, biomarker assays, genetic tests, behaviors, and/or patient symptoms, to determine risk information, such as important predictive features and patient risk scores. And the embodiments may automatically execute patient workflows, such as providing treatment recommendations to providers and/or patients, based on determined risk scores.",G01N 33/00,PULSEDATA INC.,"CHA, Theodore; SUN, Hai Po; KIPERS, Chris; FIELDING, Oliver; LEE, Edward; SON, Jung Hoon","62/692,450 29.06.2018 US",
WO2019145708,PCT/GB2019/050185,23.01.2019,WO/2019/145708,01.08.2019,WO,SPEAKER IDENTIFICATION,"A method of speaker identification comprises receiving an audio signal representing speech; performing a first voice biometric process on the audio signal to attempt to identify whether the speech is the speech of an enrolled speaker; and, if the first voice biometric process makes an initial determination that the speech is the speech of an enrolled user, performing a second voice bio metric process on the audio signal to attempt to identify whether the speech is the speech of the enrolled speaker. The second voice biometric process is selected to be more discriminative than the first voice biometric process.",G10L 17/06,CIRRUS LOGIC INTERNATIONAL SEMICONDUCTOR LIMITED,"LESSO, John Paul","15/877,660 23.01.2018 US; 1809474.8 08.06.2018 GB; 62/733,755 20.09.2018 US",
WO2019127079,PCT/CN2017/118905,27.12.2017,WO/2019/127079,04.07.2019,WO,VEHICLE LANE CHANGE PREDICTION,"Examples of the present disclosure describe a method and a system for lane change prediction. The method comprises collecting raw driving data; extracting a plurality sets of features from the collected raw driving data; obtaining corresponding lane change information, the lane change information indicating a status of lane change of a vehicle under each of the extracted feature sets; automatically labelling each of the extracted plurality sets of features with the obtained corresponding lane change information; and training a lane change prediction model with the labelled plurality sets of features. Examples of the present disclosure further describe methods, systems, and vehicles for applying the lane change prediction model.",B60W 30/00; G05D 1/00,"BAYERISCHE MOTOREN WERKE AKTIENGESELLSCHAFT; XU, Tomas Tao","XU, Tomas Tao; DOMLING, Maximilian; XU, Gavin Gaowei",,
WO2018098562,PCT/CA2017/000259,04.12.2017,WO/2018/098562,07.06.2018,WO,METHODS AND SYSTEMS FOR MANAGING AND PREDICTING UTILITY CONSUMPTION,"A joint utility predictor and controller (JUPAC) system would allow a utility such as an energy supplier and its consumers to better predict electricity grid activity and then, optimize its energy production, management, distribution, and consumption. The more accurate the prediction the more positive its economic and environmental impacts will be. A JUPAC system at a consumer collects ambient parameters, user patterns, and energy usage before by exploiting an embedded machine learning algorithm it predicts the consumer's future consumption This prediction may be recurrently transmitted to the energy supplier as a formatted commitment then, in a second time, the same device will try to respect this commitment by adjusting, wisely, the user appliances and heating - ventilation and air conditioning. As a result, an energy supplier can crowd-source the global energy demand by aggregating highly detailed individual consumption commitments as well as allowing consumers to manage consumption against pricing - power tariffs.",G06Q 10/04; G06F 15/18; G06Q 50/06,VALORBEC SOCIETE EN COMMANDITE,"YU, Jia Yuan; MERAI, Mehdi","62/429,261 02.12.2016 US",CA-3045519
WO2018022658,PCT/US2017/043792,25.07.2017,WO/2018/022658,01.02.2018,WO,ADAPTIVE SYSTEM FOR DERIVING CONTROL SIGNALS FROM MEASUREMENTS OF NEUROMUSCULAR ACTIVITY,"Methods and apparatus for adapting a control mapping associating sensor signals with control signals for controlling an operation of a device. The method comprises obtaining first state information for an operation of the device, providing the first state information as input to an intention model associated with an operation of the device and obtaining corresponding first intention model output, providing a plurality of neuromuscular signals recorded from a user and/or signals derived from the neuromuscular signals as inputs to a first control mapping and obtaining corresponding first control mapping output, and updating the first control mapping using the inputs provided to the first control mapping and the first intention model output to obtain a second control mapping.",A61F 2/68; A61F 2/70; A61F 2/72; G06F 15/18,"CTRL-LABS CORPORATION; KAIFOSH, Patrick; MACHADO, Timothy; REARDON, Thomas; SCHOMBURG, Erik; MEREL, Joshua; DEMERS, Steven","KAIFOSH, Patrick; MACHADO, Timothy; REARDON, Thomas; SCHOMBURG, Erik; MEREL, Joshua; DEMERS, Steven","62/366,427 25.07.2016 US",EP-2017835141; CN-201780059076.3
WO2019200295,PCT/US2019/027285,12.04.2019,WO/2019/200295,17.10.2019,WO,INTERIOR SENSING,"A controller for sensing interior motion includes a sensor structure having transmitting conductors and receiving conductors. The controller comprises circuitry to drive and sense signals on interacting pairs of conductors (the transmitting conductor or receiving conductor can act as the drive side, or as the sense side). Signals are processed to analyze changes in measured signal and analyzed to determine interior movement. When the controller is deployed proximate to human skin, movement of muscles, tendons and bones within the skin are reflected in the measured signals.",A61B 5/11; A61B 5/00,TACTUAL LABS CO.,"HOLMAN, David","62/657,120 13.04.2018 US",
WO2019125486,PCT/US2017/068211,22.12.2017,WO/2019/125486,27.06.2019,WO,NATURAL LANGUAGE GRAMMARS ADAPTED FOR INTERACTIVE EXPERIENCES,"Natural language grammars interpret expressions at the conversational human-machine interfaces of devices. Under conditions favoring engagement, as specified in a unit of conversational code, the device initiates a discussion using one or more of TTS, images, video, audio, and animation depending on the device capabilities of screen and audio output. Conversational code units specify conditions based on conversation state, mood, and privacy. Grammars provide intents that cause calls to system functions. Units can provide scripts for guiding the conversation. The device, or supporting server system, can provide feedback to creators of the conversational code units for analysis and machine learning.",G06F 17/30; G06Q 30/02,"SOUNDHOUND, INC.","ZHANG, Qindi; MCKENZIE, Joel",,
WO2019032128,PCT/US2017/051968,18.09.2017,WO/2019/032128,14.02.2019,WO,METHODS AND APPARATUS TO ENHANCE EMOTIONAL INTELLIGENCE USING DIGITAL TECHNOLOGY,"Methods, systems, and apparatuses are disclosed herein that output suggestions to users based on current or upcoming inter-personal interactions. Digital technology can be used to understand situations, relationships, and context to help improve the emotional intelligence of users as they engage in such inter-personal interactions. The system can receive inputs about the current situation, environment, users, and other factors. These inputs can be used to determine emotional states of the user and other participants. Based on determined emotional states, the system can suggest one or more outputs to a user to help improve the inter-personal interaction.",G16H 50/20; G06F 17/30; G06Q 50/00,GENERAL ELECTRIC COMPANY,"DIVINE, Lucas Jason; RUSSO, Lauren A.; SHANNON, Brian; BERGMAN, Ophira; WIMMER, Megan","15/671,789 08.08.2017 US",
EP14094218,03022400,06.10.2003,1408560,14.04.2004,EP,"Control apparatus for vibration type actuator, vibration type actuator system, and method for controlling vibration type actuator","A control apparatus for a vibration type actuator is disclosed, with which at least three kinds of vibrations are excited, and a desired motion can be carried out with high efficiency. The vibration type actuator includes a rotatable moving member, an elastic member contacting the moving member, and an electro-mechanical energy conversion element exciting at least three different kinds of vibrations in the elastic member by supplying at least three periodic signals having different phases. The control apparatus includes a rotation axis determining unit, a parameter determining unit and a control circuit. The rotation axis determining unit determines a rotation axis for rotating the moving member. The parameter determining unit determines, by using an inverse model, phase and amplitude of the periodical signals.",G05B 13/02; H01L 41/04; H01L 41/09; H02N 2/00; H02N 2/14,CANON KK,TAKEMURA KENJIRO; YAMAMOTO SHINJI; KOJIMA NOBUYUKI; MAENO TAKASHI,2002293437 07.10.2002 JP,
WO2002077640,PCT/IB2002/002209,25.03.2002,WO/2002/077640,03.10.2002,WO,SYSTEMS FOR ANALYSIS OF BIOLOGICAL MATERIALS,,G06F 19/24; C40B 40/06; G06F 19/20,EXIQON A/S,"JAKOBSEN, Mogens, Havsteen","60/278,592 25.03.2001 US",JP-null
WO2004072926,PCT/US2004/004194,11.02.2004,WO/2004/072926,26.08.2004,WO,MANAGEMENT OF CONVERSATIONS,"In one aspect, an arbitrary natural language communication is received from a user. A concept recognition process is applied to automatically derive a representation of concepts embodied in the communication. The concept representation is used to provide to a human agent information useful in responding to the natural language communication.",G10L 15/18; G10L 15/22,"UNVEIL TECHNOLOGIES, INC; HILL, Jeffrey; ZIEMAN, Yuri","HILL, Jeffrey; ZIEMAN, Yuri","10/364,662 11.02.2003 US",IN-4052/DELNP/2005; EP-2004710262
WO2006123137,PCT/GB2006/001809,16.05.2006,WO/2006/123137,23.11.2006,WO,CELL ANALYSIS,A system for performing cell population classification in respect of a biological sample. An image is captured in respect of an optical conduit array containing a plurality of cells and signals received therefrom are used to derive a classification scheme defining classes of cells. This scheme is then applied to classify the cells and data representative of the classes and respective locations in the conduit array of the cells.,G06K 9/00,"ISIS INNOVATION LIMITED; HUNT, Simon; YOUNG, Steve; SALATA, Oleg; PAYNE, Stephen","HUNT, Simon; YOUNG, Steve; SALATA, Oleg; PAYNE, Stephen",0509833.0 16.05.2005 GB,RU-null; US-11920556; EP-2006727131; DE-null
EP159711008,15181099,14.08.2015,2985711,17.02.2016,EP,SYSTEM FOR AUTOMATED ANALYSIS OF CLINICAL TEXT FOR PHARMACOVIGILANCE,"In the pharmaceutical research and development process, it may be necessary to process large amounts of medical records or clinical literature, to ensure safety of patients consuming a drug. A pharmacovigilance system may assist in this process by efficiently and automatically processing medical records to extract information and relationships contained therein and may also form a preliminary assessment regarding a medical or clinical judgment. The pharmacovigilance system may automatically generate reports based on this information, which may be validated by trained clinicians and medical experts.",G06F 19/00,ACCENTURE GLOBAL SERVICES LTD,ANUTOSH MAITRA; ANNERVAZ KARUKAPADATH MOHAMEDRASHEED; TOM GEO JAIN; MADHURA SHIVARAM; SHUBHASHIS SENGUPTA; ROSHNI RAMESH RAMNANI; NEETU PATHAK; DEBAPRIYA BANERJEE; VEDAMATI SAHU,3984CH2014 14.08.2014 IN; 4173CH2014 26.08.2014 IN,
EP199495877,15306952,07.12.2015,3179407,14.06.2017,EP,RECOGNITION OF A 3D MODELED OBJECT FROM A 2D IMAGE,"The invention notably relates to a computer-implemented method for recognizing a three-dimensional modeled object from a two-dimensional image. The method comprises providing a first set of two-dimensional images rendered from three-dimensional modeled objects, each two-dimensional image of the first set being associated to a label; providing a second set of two-dimensional images not rendered from three-dimensional objects, each two-dimensional image of the second set being associated to a label; training a model on both first and second sets; providing a similarity metric; submitting a two-dimensional image depicting at least one object; and retrieving a three-dimensional object similar to the said at least one object of the two-dimensional image submitted by using the trained model and the similarity metric.",G06K 9/00,DASSAULT SYSTÈMES,BOULKENAFED MALIKA; MICHEL FABRICE; REJEB SFAR ASMA,15306952 07.12.2015 EP,
WO2016077157,PCT/US2015/059361,06.11.2015,WO/2016/077157,19.05.2016,WO,PREDICTION-BASED SEQUENCE RECOGNITION,A sequence recognition system comprises a prediction component configured to receive a set of observed features from a signal to be recognized and to output a prediction output indicative of a predicted recognition based on the set of observed features. The sequence recognition system also comprises a classification component configured to receive the prediction output and to output a label indicative of recognition of the signal based on the prediction output.,G10L 15/16; G06N 3/04,"MICROSOFT TECHNOLOGY LICENSING, LLC","YU, Dong; ZHANG, Yu; SELTZER, Michael L.; DROPPO, James G.","62/079,164 13.11.2014 US; 14/578,938 22.12.2014 US",
WO2000038949,PCT/US1999/031184,31.12.1999,WO/2000/038949,06.07.2000,WO,METHODS FOR DETERMINING THE IDENTIFICATION AND POSITION OF AND MONITORING OBJECTS IN A VEHICLE,"A vehicle interior monitoring system to identify, locate and monitor occupants, including their parts, and other objects in the passenger compartment (100) and objects outside of a motor vehicle, such as an automobile or truck, by illuminating the contents of the vehicle and objects outside of the vehicle with electromagnetic, and specifically infrared, radiation and using one or more lenses to focus images of the contents onto one or more arrays of charge coupled devices (CCD arrays) (110, 111, 112, 113, 114). Outputs from the CCD arrays (110, 111, 112, 113, 114) are analyzed by appropriate computational means (120) employing trained pattern recognition technologies, to classify, identify or locate the contents (101) or external objects. In general, the information obtained by the identification and monitoring system is used to affect the operation of some other system in the vehicle. When system is installed in the passenger compartment of an automotive vehicle equipped with an airbag, the system determines the position of the vehicle occupant relative to the airbag and disables deployment of the airbag if the occupant is positioned so that he/she is likely to be injured by the deployment of the airbag.",B60N 2/02; B60N 2/28; B60R 21/01; G06K 9/00,"AUTOMOTIVE TECHNOLOGIES INTERNATIONAL, INC.","BREED, David, S.; DUVALL, Wilbur, E.; JOHNSON, Wendell, C.","60/114,507 31.12.1998 US; 09/476,255 30.12.1999 US",GB-GB0116062.1
WO2013043903,PCT/US2012/056389,20.09.2012,WO/2013/043903,28.03.2013,WO,APPARATUS AND METHODS FOR SYNAPTIC UPDATE IN A PULSE-CODED NETWORK,"Apparatus and methods for efficient synaptic update in a network such as a spiking neural network. In one embodiment, the post-synaptic updates, in response to generation of a post-synaptic pulse by a post-synaptic unit, are delayed until a subsequent pre-synaptic pulse is received by the unit. Pre-synaptic updates are performed first following by the post-synaptic update, thus ensuring synaptic connection status is up-to-date. The delay update mechanism is used in conjunction with system ""flush7"" events in order to ensure accurate network operation, and prevent loss of information under a variety of pre-synaptic and post-synaptic unit firing rates. A large network partition mechanism is used in one variant with network processing apparatus in order to enable processing of network signals in a limited functionality embedded hardware environment.",G06F 15/18,"BRAIN CORPORATION; IZHIKEVICH, Eugene, M.; PIEKNIEWSKI, Filip; NAGESWARAN, Jayram, Moorkanikara","IZHIKEVICH, Eugene, M.; PIEKNIEWSKI, Filip; NAGESWARAN, Jayram, Moorkanikara","13/239,255 21.09.2011 US",
WO2016035072,PCT/IL2015/050879,02.09.2015,WO/2016/035072,10.03.2016,WO,SENTIMENT RATING SYSTEM AND METHOD,"A sentiment rating system adapted to processing website(s) to determine key phrases descriptive of items presented therein; mining one or more social posts (e.g. from social networks), which are indicative of the key phrases; processing the social posts to determine sentiment values expressed therein in relation to the key phrases; and based on the one or more sentiment values determine sentiment score for the key phrases. In some implementations the system includes a publisher module that embeds the sentiment scores of the key phrases within the website(s) in association with the items associated therewith. In some implementations, determination of the sentiment score includes processing the social posts to filter out social posts, which are biased, and/or from which sentiment values cannot be extracted with high confidence level, and then determining the sentiment score based on the sentiment values of social posts, which are un-biased and from which reliable sentiment values can be extracted.",G06F 17/30,FEELTER SALES TOOLS LTD,"BROVINSKY , Gilad; ISRAEL, Zohar; LANDAU, Smadar","62/044,560 02.09.2014 US",CA-2959835; EP-2015837372; AU-2015310494; IL-250829
WO2016112503,PCT/CN2015/070657,14.01.2015,WO/2016/112503,21.07.2016,WO,CONTENT CREATION FROM EXTRACTED CONTENT,Examples describe content creation of at least one abstract from extracted content. Input information is received that comprises a link to a landing page and keyword information (302). The landing page is evaluated and content including at least one of image data and text data is extracted from the landing page (304). Properties of the content extracted are analyzed (306). The content extracted is ranked based on the analyzed properties and application of at least two ranking algorithms (308). A first ranking algorithm applied ranks the content based on relevance to the landing page and a second ranking algorithm applied ranks the content extracted based on relevance to the keyword information. The ranked content is filtered to remove content or portions of content that are determined to be unappealing based on applying filtering rules to the ranked content(310). At least one abstract is created from the filtered and ranked content (312).,G06F 17/30,"MICROSOFT TECHNOLOGY LICENSING, LLC; LIN, Ying; JOURDAIN, Mathias; YANG, Guang","LIN, Ying; JOURDAIN, Mathias; YANG, Guang",,US-15543879
WO2002071794,PCT/DK2002/000137,01.03.2002,WO/2002/071794,12.09.2002,WO,METHOD FOR MODELLING CUSTOMISED EARPIECES,"The present invention relates to a method for computer-controlled modelling of customised earpieces. These earpieces include housings for hearing aids, wireless or connected communication devices (headsets, mobile phones, personal agents), loud speakers, tinnitus masking devices, devices recording vibrations in the skull and transforming these into audio signals, voice recognition devices, earplugs, noise blockers with selective frequencies or sound levels, Man Machine Interface (MMI) products that enable clear communication even in the noisiest environments, or products related to wireless Internet applications. All these earpieces may be worn in the user's meatus and/or auditory canal. The invention also relates to a computerised system for manufacturing such customised earpieces. In particular, the invention is directed to a computerised system that models an earpiece based on a three-dimensional replica of the user's meatus and/or auditory canal.",A61F 11/00; A61F 11/08; H04R 1/10; H04R 25/00,"3SHAPE APS; FISKER, Rune; CLAUSEN, Tais; BARTHE, Christophe, Vasiljev; DEICHMANN, Nikolaj","FISKER, Rune; CLAUSEN, Tais; BARTHE, Christophe, Vasiljev; DEICHMANN, Nikolaj","PA 2001 00346 02.03.2001 DK; 60/275,112 13.03.2001 US; PA 2001 00519 28.03.2001 DK; PA 2001 01521 17.10.2001 DK",EP-2002702231; JP-null; US-10469591
EP217786254,17177454,22.06.2017,3324339,23.05.2018,EP,METHOD AND APPARATUS TO PERFORM MATERIAL RECOGNITION AND TRAINING FOR MATERIAL RECOGNITION,Provided are method and apparatuses related to material recognition and training. A training apparatus for material recognition generates training data associated with a material by generating a texture image having a texture attribute from an object image and recognizing material information from the texture image using a material model.,G06K 9/46,SAMSUNG ELECTRONICS CO LTD,SAGONG DONGHOON; SON MINJUNG; CHANG HYUN SUNG; SUNG YOUNG HUN,20160152428 16.11.2016 KR,
WO2017021753,PCT/IB2015/002615,06.08.2015,WO/2017/021753,09.02.2017,WO,CONDITION DETECTION USING IMAGE PROCESSING,"Condition detection using image processing may include receiving telemetry data related to movement of a vehicle along a vehicle path. Condition detection using image processing may further include receiving images captured by the vehicle, and generating, based on the telemetry data and the images, an altitude map for the images, and world coordinates alignment data for the images. Condition detection using image processing may further include detecting the entities in the images, and locations of the entities detected in the images, consolidating the locations of the entities detected in the images to determine a consolidated location for the entities detected in the images, generating, based on the consolidated location, a mask related to the vehicle path and the entities detected in the images, and reconstructing three-dimensional entities model for certain types of entities, based on the entities masks and world coordinates alignment data for the images.",G06K 9/00,ACCENTURE GLOBAL SERVICES LIMITED,"PESTUN, Vadim; TYULYAEVA, Ekaterina; EREMINA, Olga; LEVASHOV, Alexey; GULDOGAN, Olcay; ROTOLA-PUKKILA, Jani; ROSSI, Teemu, Kalevi",,US-15740305; CA-2994511; SG-11201800976Q; AU-2015404580; EP-2015843098; RU-2017146414
WO2019079757,PCT/US2018/056768,19.10.2018,WO/2019/079757,25.04.2019,WO,SYSTEMS AND METHODS FOR IDENTIFYING BIOLOGICAL STRUCTURES ASSOCIATED WITH NEUROMUSCULAR SOURCE SIGNALS,"A system comprising a plurality of neuromuscular sensors, each of which is configured to record a time-series of neuromuscular signals from a surface of a user's body; and at least one computer hardware processor programmed to perform: applying a source separation technique to the time series of neuromuscular signals recorded by the plurality of neuromuscular sensors to obtain a plurality of neuromuscular source signals and corresponding mixing information; providing features, obtained from the plurality of neuromuscular source signals and/or the corresponding mixing information, as input to a trained statistical classifier and obtaining corresponding output; and identifying, based on the output of the trained statistical classifier, and for each of one or more of the plurality of neuromuscular source signals, an associated set of one or more biological structures.",A61B 5/04,CTRL-LABS CORPORATION,"MACHADO, Timothy; REARDON, Thomas; KAIFOSH, Patrick; SCHOMBURG, Erik; GIURGICA-TIRON, Tudor","62/574,496 19.10.2017 US",
WO2016083166,PCT/EP2015/076635,16.11.2015,WO/2016/083166,02.06.2016,WO,MAGNETIC RESONANCE FINGERPRINTING DATA COLLECTION AND ANALYSIS SYSTEM,"A method of employing a central computer database (18) for supporting a characterization of tissue by magnetic resonance fingerprinting measurements, including steps of -exciting nuclei of a subject of interest by applying (50) a radio frequency excitation field B1 generated according to a magnetic resonance fingerprinting sequence (38), -acquiring (52) magnetic resonance imaging signal data from radiation emitted by excited nuclei of the subject of interest, -transferring (54) a magnetic resonance fingerprinting data set (42) to the central computer database (18), -retrieving (56) a predefined dictionary from the central computer database (18), -matching (60) the acquired magnetic resonance imaging signal data to the retrieved dictionary by applying a pattern recognition algorithm to determine a value (40) or a set of values (40) for at least one physical quantity (T1, T2), -adding (62) at least the determined value (40) or the determined set of values (40) as a new entry of an associated medical data set (36) to the central computer database (18), and -making (64) the new entry of an associated medical data set (36) accessible to users of the central computer database (18); and -a magnetic resonance fingerprinting data collection and analysis system (10) comprising a central computer database, a data receiving unit (20), a data output unit (22) and a data analysis device (26) configured to carry out the method.",G01R 33/44; G01R 33/48; G01R 33/50; G06F 21/32; G06F 19/00,KONINKLIJKE PHILIPS N.V.,"AMTHOR, Thomas Erik; KRUEGER, Sascha; DONEVA, Mariya Ivanova; KOKEN, Peter; SENEGAS, Julien; KEUPP, Jochen; BOERNERT, Peter",14195174.9 27.11.2014 EP,US-15527028; JP-2017527860
WO2019089919,PCT/US2018/058701,01.11.2018,WO/2019/089919,09.05.2019,WO,SYSTEMS AND METHODS FOR TISSUE CHARACTERIZATION,"Systems for characterizing tissue comprise: a tissue probe comprising a plurality of probe electrodes; a signal generator, a controller, and a user interface. The signal generator is in communication with the probe electrodes for delivering a drive signal to at least one probe electrode. The controller receives a recorded signal from one or more probe electrodes, the recorded signal resulting from delivery of the drive signal through tissue proximate the plurality of probe electrodes. The controller is configured to determine patient-to-patient differences when the tissue probe is proximate a known type of patient tissue and/or bodily fluid, and it produces tissue characterization information based on the recorded signal and the patient-to-patient differences. The user interface provides the tissue characterization information to an operator of the system. Methods of characterizing tissue are also provided.",A61B 5/06,"SHEN, Daniel; HERSCHER, Bret; KRAWZSENEK, David; CONNELLY, Kyler; BAKER, Michael; FLAHERTY, R. Maxwell; FLAHERTY, J. Christopher","SHEN, Daniel; HERSCHER, Bret; KRAWZSENEK, David; CONNELLY, Kyler; BAKER, Michael; FLAHERTY, R. Maxwell; FLAHERTY, J. Christopher","62/580,017 01.11.2017 US",
EP14455900,05000569,13.01.2005,1610557,28.12.2005,EP,System and method for embedding multimedia processing information in a multimedia bitstream,Systems and methods for embedding multimedia processing information in a multimedia bitstream to form a hybrid multimedia bitstream having data representing multimedia processing information as well data representing a multimedia signal. The embedded multimedia processing information may be extracted from the multimedia bitstream by an executable module to assist in processing the multimedia bitstream in subsequent steps. <IMAGE>,G06F 17/30; H04N 7/24; G06F 17/30; H04N 7/24,CYBERLINK CORP,HUANG JAU HSIUNG; HUANG HO CHAO; LEE YU CHUNG,87309704 21.06.2004 US,
EP14519188,04778823,21.07.2004,1648303,26.04.2006,EP,RADIOGRAPHIC IMAGING SYSTEM AND METHOD,"The invention relates generally to systems and methods for processing radiographic and other medical-related images (collectively 'imaging system' or simply the 'system'). More specifically, the invention relates to a system for associating particular calibration information with a particular radiographic image. Calibrated images processed by the system can be created from radiographic images and calibration information associated with the radiographic images. In many embodiments, the system includes a user interface that automatically configures itself in accordance with the calibration information embedded with the radiographic image. The system can include a user interface configured to obtain the calibration from the data object.",A61B 6/00; G06F 19/00,RADIOLOGICAL IMAGING TECHNOLOGY INC,RITT DANIEL M; WHITAKER MATTHEW L,2004023475 21.07.2004 US; 49138503 31.07.2003 US; 68813003 17.10.2003 US,
WO2002005207,PCT/IL2001/000597,28.06.2001,WO/2002/005207,17.01.2002,WO,CLASSIFIER FOR IMAGE PROCESSING,"An image classifying objects (Fig. 1) of an image, (Fig. 6) comprising: an optical and/or electronic and/or hybrid optical-electronic processor for measuring objects to determine whether said objects comprise features useful in classifying said objects, (Fig. 2, item 38, 40) and a conditionality network associated with said optical processor for using conditionality to select said features useful in classifying interactively with measurement outputs, (Fig. 4) of said optical processor, thereby to classify said objects.",G06K 9/62,"TECHNION RESEARCH AND DEVELOPMENT FOUNDATION LTD.; SHAMIR, Joseph; HAR, Offer","SHAMIR, Joseph; HAR, Offer","60/215,120 29.06.2000 US",RU-null
WO2019108880,PCT/US2018/063215,30.11.2018,WO/2019/108880,06.06.2019,WO,METHODS AND APPARATUS FOR SIMULTANEOUS DETECTION OF DISCRETE AND CONTINUOUS GESTURES,"According to at least one aspect, a computerized system is provided. The computerized system comprises a plurality of neuromuscular sensors configured to record a plurality of neuromuscular signals from a user, wherein the plurality of neuromuscular sensors are arranged on one or more wearable devices and at least one computer processor or computing device. The at least one computer processor may be programmed to determine, using one or more trained statistical models and the plurality of neuromuscular signals, position information and force information representing at least one movement performed by the user; and identify gestures performed by the user based, at least in part, on the position information and/or the force information.",G06F 3/01; G06F 1/16; G06F 3/0346; G06N 99/00,CTRL-LABS CORPORATION,"KAIFOSH, Patrick; DEMERS, Steven; BERENZWEIG, Adam; ASTOLFI, Michael; AWAD, Lana; GIURGICA-TIRON, Tudor; AL-NATSHEH, Adam","62/592,656 30.11.2017 US; 62/621,728 25.01.2018 US",
WO2013166373,PCT/US2013/039445,03.05.2013,WO/2013/166373,07.11.2013,WO,GENE EXPRESSION SIGNATURE FOR IL-6/STAT3 SIGNALING PATHWAY AND USE THEREOF,"The present invention relates to a set of biomarkers, microarrays that provide for detection thereof, an expression signature comprising 16 genes or a subset thereof, and the use thereof in determining the regulation status of IL-6/STAT3 signaling pathway in a cell sample or subject, as well as compositions for the detection thereof. The regulation status of IL-6/STAT3 signaling pathway in a cell sample or subject may be assayed based on the level of expression of one or more of these genes. The methods and compositions provided herein may be used to evaluate IL-6/STAT3 pathway regulation status in a sample; classify a cell sample as having a deregulated or regulated IL-6/STAT3 signaling pathway; determine whether an agent modulates the IL-6/STAT3 signaling pathway; predict the response of a subject to an agent that modulates the IL-6/STAT3 signaling pathway; assign treatment to a subject; and/or evaluate the pharmacodynamic effects of therapies designed to regulate IL-6/STAT3 pathway signaling. Expression of the biomarkers is preferably determined by RT- PCR using SYBR Green methods, and the expression data analyzed and compared to a control sample by use of the random forest method.",C12Q 1/68; C12N 15/11; G01N 33/53,"WU, Zhong; SCHLUMPBERGER, Martin; DICARLO, John; DEVGAN, Vikram; WANG, Yexun","WU, Zhong; SCHLUMPBERGER, Martin; DICARLO, John; DEVGAN, Vikram; WANG, Yexun","61/642,037 03.05.2012 US",EP-2013784566; US-14398532
WO2015006631,PCT/US2014/046257,11.07.2014,WO/2015/006631,15.01.2015,WO,ACTIVE LABELING FOR COMPUTER-HUMAN INTERACTIVE LEARNING,"A collection of data that is extremely large can be difficult to search and/or analyze. Relevance may be dramatically improved by automatically classifying queries and web pages in useful categories, and using these classification scores as relevance features. A thorough approach may require building a large number of classifiers, corresponding to the various types of information, activities, and products. Creation of classifiers and schematizers is provided on large data sets. Exercising the classifiers and schematizers on hundreds of millions of items may expose value that is inherent to the data by adding usable meta-data. Some aspects include active labeling exploration, automatic regularization and cold start, scaling with the number of items and the number of classifiers, active featuring, and segmentation and schematization.",G06N 99/00; G06F 17/27,"MICROSOFT TECHNOLOGY LICENSING, LLC","SIMARD, Patrice Y.; CHICKERING, David Max; LAKSHMIRATAN, Aparna; CHARLES, Denis X.; BOTTOU, Leon","61/845,844 12.07.2013 US; 14/075,690 08.11.2013 US",
WO2015154305,PCT/CN2014/075165,11.04.2014,WO/2015/154305,15.10.2015,WO,OBJECT DETECTION USING DIRECTIONAL FILTERING,"Techniques related to object detection using directional filtering are discussed. Such techniques may include determining directional weighted averages for pixels of an input image, generating a feature representation of the input image based on the directional weighted averages, and performing object detection by applying a multi-stage cascade classifier to the feature representation.",G06K 9/62,"INTEL CORPORATION; LI, Jianguo; CHEN, Ke; CHIU, Yi-Jen; WANG, Chen; PENG, Ya-Ti; WANG, Bin Robin","LI, Jianguo; CHEN, Ke; CHIU, Yi-Jen; WANG, Chen; PENG, Ya-Ti; WANG, Bin Robin",,US-15125027; EP-2014889031
WO2019200474,PCT/CA2019/050473,16.04.2019,WO/2019/200474,24.10.2019,WO,"SYSTEMS AND METHODS FOR THE DETERMINATION OF AROUSAL STATES, CALIBRATED COMMUNICATION SIGNALS AND MONITORING AROUSAL STATES","A computer-implemented method and system for determining an arousal state of a user, the method comprising: obtaining input data relating to a response of the user to a communication signal, wherein the input data relates to one or more of: a direct response of the user, a physiological response of the user, the physiological response comprising at least one measured physiological value, and determining the arousal state of the user based on the input data, and one or more of: contextual data, an initial arousal state of the user, and user profiles. A computer-implemented method and system for determining a calibration communication signal for arousal state modulation. A computer-implemented method and system for monitoring a user`s arousal state.",A61B 5/16; A61B 5/00,"TECHNOLOGIES HOP-CHILD, INC.; GROLEAU, Diane; BROCHU, Pascale; PELLETIER, Marc-Antoine; CORCOS, Simon; SALVAIL, Alex; DUCHESNE, Julien; HOWTON, Rozarina Md Yusof","GROLEAU, Diane; BROCHU, Pascale; PELLETIER, Marc-Antoine; CORCOS, Simon; SALVAIL, Alex; DUCHESNE, Julien; HOWTON, Rozarina Md Yusof","62/658,353 16.04.2018 US",
WO2002021274,PCT/US2001/016629,21.05.2001,WO/2002/021274,14.03.2002,WO,A COMPUTER WITH SWITCHABLE COMPONENTS,"A computer (1) has three modes of operation: normal, repair and switching. In the switching mode, user input makes the system switch (13, 19) to the repair mode. Switching can be logically or physically and can control different components of the system. The system reboots and automatically copies data from the template data store (14) to the data store (12) to be repaired. After repair, the user resets the switch (13, 19) and reboots in normal mode. User settings determine what actions are performed in the repair mode.",G06F 11/14,"SELF REPAIRING COMPUTERS, INC.","LARGMAN, Kenneth; MORE, Anthony, B.; BLAIR, Jeffery","60/205,531 19.05.2000 US; 60/220,282 24.07.2000 US; 60/291,767 17.05.2001 US",IL-152936; KR-1020027015613; AU-2001263377; EP-2001937664; CA-2414251
WO2019222467,PCT/US2019/032616,16.05.2019,WO/2019/222467,21.11.2019,WO,SELF-SUPERVISED TRAINING OF A DEPTH ESTIMATION SYSTEM,A method for training a depth estimation model and methods for use thereof are described. Images are acquired and input into a depth model to extract a depth map for each of the plurality of images based on parameters of the depth model. The method includes inputting the images into a pose decoder to extract a pose for each image. The method includes generating a plurality of synthetic frames based on the depth map and the pose for each image. The method includes calculating a loss value with an input scale occlusion and motion aware loss function based on a comparison of the synthetic frames and the images. The method includes adjusting the plurality of parameters of the depth model based on the loss value. The trained model can receive an image of a scene and generate a depth map of the scene according to the image.,G06T 7/593; G06T 7/00; G06T 7/30,"NIANTIC, INC.","GODARD, Clément; MAC AODHA, Oisin; BROSTOW, Gabriel J.; FIRMAN, Michael","62/673,045 17.05.2018 US",
WO2016175773,PCT/US2015/028120,29.04.2015,WO/2016/175773,03.11.2016,WO,METHOD AND SYSTEM FOR SEMANTIC SEGMENTATION IN LAPAROSCOPIC AND ENDOSCOPIC 2D/2.5D IMAGE DATA,A method and system for semantic segmentation laparoscopic and endoscopic 2D/2.5D image data is disclosed. Statistical image features that integrate a 2D image channel and a 2.5D depth channel of a 2D/2.5 laparoscopic or endoscopic image are extracted for each pixel in the image. Semantic segmentation of the laparoscopic or endoscopic image is then performed using a trained classifier to classify each pixel in the image with respect to a semantic object class of a target organ based on the extracted statistical image features. Segmented image masks resulting from the semantic segmentation of multiple frames of a laparoscopic or endoscopic image sequence can be used to guide organ specific 3D stitching of the frames to generate a 3D model of the target organ.,G06T 7/00,SIEMENS AKTIENGESELLSCHAFT,"KLUCKNER, Stefan; KAMEN, Ali; CHEN, Terrence",,JP-2017556702; US-15568590; EP-2015722833
WO2005001750,PCT/IB2004/003274,30.06.2004,WO/2005/001750,06.01.2005,WO,SYSTEM AND METHOD FOR FACE RECOGNITION,"A face recognition system is provided with a component learning/extraction module, a component classifier training module, a knowledge base for component classification, a component extraction module, an object identification training module, a knowledge base for face identification and an object identification module. The component learning/extraction module receives image data of faces of individuals at various viewpoints and extracts component data at various viewpoints from the image data of faces of individuals at various viewpoints. The component classifier training module receives the component data at various viewpoints and produces results of classifier training of the component data at various viewpoints. The knowledge base for component classification stores the results of classifier training of the component data at various viewpoints. The component extraction module receives image data of faces of individuals at various viewpoints and extracts outputs of classification of the component data at various viewpoints, using the results of classifier training of the component data at various viewpoints, stored in the knowledge base for component classification. The object identification training module receives the outputs of classification of the component data at various viewpoints and determines indicator component for each of the individuals by Bayesian estimation in such a way that posterior probability of a predetermined attention class is maximized under the outputs of classification of the component data at various viewpoints. The knowledge base for face identification stores indicator components for the individuals. The object identification module receives the outputs of classification of the component data at various viewpoints and identifies faces of the individuals using the indicator components for the individuals stored in the knowledge base for face identification.",G06K 9/00; G06K 9/62,"HONDA MOTOR CO., LTD.; KOSHIZEN, Takamasa; HEISELE, Bernd; TSUJINO, Hiroshi","KOSHIZEN, Takamasa; HEISELE, Bernd; TSUJINO, Hiroshi","60/484,201 30.06.2003 US",JP-2006516619; US-2006280341; EP-2004785725; US-10561256
EP225889562,18153840,29.01.2018,3373132,12.09.2018,EP,TERMINAL AND VEHICLE CONTROL METHOD OF MOBILE TERMINAL USING MACHINE LEARNING FOR VEHICLE COMMUNICATION,"A terminal using machine learning for selecting an output mode based on the context information of a user. An embodiment of a terminal may include an audio output unit, a display, and a controller configured to obtain context information of a user, set an output mode of the mobile terminal based on the obtained context information, convert communication information of a first type received from an external device to a second type associated with the set output mode when the first type and the second type are different, and control the audio output unit or the display to output the communication information, wherein the audio output unit or the display is used to output the communication information based on the output mode. An embodiment may include a data learning unit configured to store data to implement machine learning and logic based determinations for selecting the output mode.",G06F 3/16; G10L 15/22,LG ELECTRONICS INC,CHO SUNGIL; KIM YOUNGJUN; JANG YUJUNE,20170029578 08.03.2017 KR,
WO2006093523,PCT/US2005/025305,15.07.2005,WO/2006/093523,08.09.2006,WO,COMPUTERIZED SCHEME FOR DISTINCTION BETWEEN BENIGN AND MALIGNANT NODULES IN THORACIC LOW-DOSE CT,"A system, method, and computer program product for classifying a target structure in an image into abnormality types. The system has a scanning mechanism that scans a local window across sub-regions of the target structure by moving the local window across the image to obtain sub-region pixel sets (fig. 2b element 200). A mechanism inputs the sub-region pixel sets into a classifier (fig. 2b element 210) to provide output pixel values based on the sub-region pixel sets, each output pixel abnormality, the output pixel values collectively determining a likelihood distribution output image map. A mechanism scores the likelihood distribution map to classify the target structure into abnormality types (fig. 2b element 220). The classifier cab be, e.g. , a single-output or multiple-output massive trainin artifical neural network MTANN .",G06K 9/62,"SUZUKI, Kenji; DOI, Kunio","SUZUKI, Kenji; DOI, Kunio","60/587,855 15.07.2004 US",EP-5857532; DE-null
WO2019101330,PCT/EP2017/080345,24.11.2017,WO/2019/101330,31.05.2019,WO,COLLISION PREVENTION SYSTEM AND METHOD,"We generally describe a collision prevention system (100) comprising: a localization system (402) for determining positions of an autonomous vehicle (104) and a human (106); and a collision determination unit (404) coupled to or in communication with the localization system (402), wherein the collision determination unit (404) is configured to determine, based on the determined positions of the autonomous vehicle (104) and the human (106), whether a predefined condition for an anticipated collision of the autonomous vehicle (104) with the human (106) is met; wherein the collision prevention system (100) is configured to: lock the autonomous vehicle (104) if the predefined condition is met; alert the human (106) for whom the predefined condition for colliding with the autonomous vehicle (104) is met; and allow unlocking of the autonomous vehicle (104) to be performed or initialized by the alerted human (106) only.",G05D 1/02,TELEFONAKTIEBOLAGET LM ERICSSON (PUBL),"BORSOS, Tamas; HÁGA, Péter; KALLUS, Zsófia; KENESI, Zsolt; SZEBENYEI, Mate; VADERNA, Peter; VERES, András",,
EP214742919,17162202,24.06.2010,3309556,18.04.2018,EP,METHODS FOR DIAGNOSING IRRITABLE BOWEL SYNDROME,"The invention provides a method for aiding in the diagnosis of IBS in a subject, said method comprising: 
(a) contacting a blood or serum sample from the subject with a prostaglandin E 2  (PGE 2 ) binding moiety under conditions suitable to transform PGE 2  present in the sample into a complex comprising PGE 2  and the PGE 2  binding moiety; and 
(b) determining the level of said complex, thereby determining the level of PGE 2  present in the sample.",G01N 33/74; G01N 33/68,NESTEC SA,GONG HUA; WANG SHUI LONG; SINGH SHARAT,10792683 24.06.2010 EP; 14170774 24.06.2010 EP; 22052509 25.06.2009 US; 25209409 15.10.2009 US,
WO2016025691,PCT/US2015/045018,13.08.2015,WO/2016/025691,18.02.2016,WO,REMOTE EXPERT SYSTEM,A remote expert application identifies a manipulation of virtual objects displayed in a first wearable device. The virtual objects are rendered based a physical object viewed with a second wearable device. A manipulation of the virtual objects is received from the first wearable device. A visualization of the manipulation of the virtual objects is generated for a display of the second wearable device. The visualization of the manipulation of the virtual objects is communicated to the second wearable device.,G06F 3/01; G06F 19/00,"DAQRI, LLC","MULLINS, Brian; KAMMERAIT, Matthew; BROADDUS, Christopher","14/461,252 15.08.2014 US",JP-2017507771; EP-2015832547; AU-2015301620
WO2016142669,PCT/GB2016/050597,07.03.2016,WO/2016/142669,15.09.2016,WO,"PHYSICALLY GUIDED RAPID EVAPORATIVE IONISATION MASS SPECTROMETRY (""REIMS"")","A method is disclosed comprising obtaining physical or other non-mass spectrometric data from one or more regions of a target using a probe (20). The physical or other non-mass spectrometric data may be used to determine one or more regions of interest of the target. An ambient ionisation ion source (1) may then used to generate an aerosol, smoke or vapour (5) from one or more regions of the target.",G01N 33/68; A61B 17/00; G01N 3/00; G01N 9/00; H01J 49/00; A61B 18/00; G01N 27/62,MICROMASS UK LIMITED,"PRINGLE, Steven Derek; JONES, Emrys; MORRIS, Michael Raymond; BALOG, Júlia; LANGRIDGE, James Ian; RICHARDSON, Keith; SIMON, Dániel; GÖDÖRHÁZY, Lajos; SZALAY, Dániel; TAKÁTS, Zoltán",1503876.3 06.03.2015 GB; 1503864.9 06.03.2015 GB; 1503877.1 06.03.2015 GB; 1503867.2 06.03.2015 GB; 1503863.1 06.03.2015 GB; 1503878.9 06.03.2015 GB; 1516003.9 09.09.2015 GB; 1518369.2 16.10.2015 GB; 1503879.7 06.03.2015 GB,GB-1713964.3; US-15556052
WO2004090803,PCT/AU2004/000437,02.04.2004,WO/2004/090803,21.10.2004,WO,OBTAINING PRODUCT ITEM ASSISTANCE,"A method of requesting assistance relating to a product item, the product item including an associated interface surface, the interface surface having disposed thereon or therein coded data indicative of an identity of the product item, the method including, in a sensing device: (a) sensing at least some of the coded data; (b) generating, using the sensed coded data, indicating data indicative of the product item identity; and, (c) transferring the indicating data to a computer system, the computer system being responsive to the indicating data to cause provision of assistance.",B41J 2/01; C09B 49/12; C09B 57/10; C09D 11/00; C09D 11/02; D21H 19/38; G01N 33/48; G01N 33/50; G05B 15/00; G06F 3/08; G06F 7/00; G06F 7/02; G06F 7/08; G06F 15/00; G06F 17/00; G06F 17/30; G06F 19/00; G06K 5/00; G06K 7/00; G06K 7/10; G06K 7/14; G06K 9/00; G06K 9/18; G06K 9/20; G06K 9/22; G06K 9/78; G06K 15/00; G06K 19/06; H04N 1/04,"SILVERBROOK RESEARCH PTY LTD; SILVERBROOK, Kia; LAPSTUN, Paul","SILVERBROOK, Kia; LAPSTUN, Paul",2003901617 07.04.2003 AU; 2003901795 15.04.2003 AU,EP-2004725231; CA-2519411; AU-2004227426
WO2007131530,PCT/EP2006/004598,16.05.2006,WO/2007/131530,22.11.2007,WO,INTERSESSION VARIABILITY COMPENSATION FOR AUTOMATIC EXTRACTION OF INFORMATION FROM VOICE,"Disclosed herein is a method for compensating intersession variability for automatic extraction of information from an input voice signal representing an utterance of a speaker, comprising: processing the input voice signal to provide feature vectors each formed by acoustic features extracted from the input voice signal at a time frame; computing an intersession variability compensation feature vector; and computing compensated feature vectors based on the extracted feature vectors and the intersession variability compensation feature vector; wherein computing an intersession variability compensation feature vector includes: creating a Universal Background Model (UBM) based on a training voice database, the Universal Background Model (UBM) including a number of Gaussians and probabilistically modeling an acoustic model space, creating a voice recording database related to different speakers and containing, for each speaker, a number of voice recordings acquired under different conditions; computing an intersession variability subspace matrix (U) based on the voice recording database, the intersession variability subspace matrix (U) defining a transformation from an acoustic model space to an intersession variability subspace representing intersession variability for all the speakers; computing an intersession factor vector (xi) based on the intersession variability subspace matrix (U), the intersession factor vector representing the intersession variability of the input speech signal in the intersession variability subspace; and computing the intersession variability compensation feature vector based on the intersession variability subspace matrix (U), the intersession factor vector (xi) and the Universal Background Model (UBM).",G10L 15/20,"LOQUENDO S.P.A.; VAIR, Claudio; COLIBRO, Daniele; LAFACE, Pietro","VAIR, Claudio; COLIBRO, Daniele; LAFACE, Pietro",,EP-2006742938; CA-2652302; US-12227282; AU-2006343470
WO2017181068,PCT/US2017/027705,14.04.2017,WO/2017/181068,19.10.2017,WO,IMPLANTABLE LIVING ELECTRODES AND METHODS FOR USE THEREOF,"In one aspect, the invention comprises an implantable living electrode comprising a substantially cylindrical extracellular matrix core; one or more neurons implanted along or within the substantially cylindrical extracellular matrix core, the one or more neurons including one or more optogenetic or magnetogenetic neurons proximal to a first end of the implantable living electrode.",A61B 5/04; A61B 5/0478; A61N 1/05,THE TRUSTEES OF THE UNIVERSITY OF PENNSYLVANIA; THOMAS JEFFERSON UNIVERSITY,"CULLEN, Daniel Kacy; HARRIS, James P.; WOLF, John A.; CHEN, H. Isaac; SMITH, Douglas H.; SERRUYA, Mijail","62/322,434 14.04.2016 US",EP-2017783279; US-16093036; JP-2018554371; AU-2017248756
WO2019005039,PCT/US2017/039741,28.06.2017,WO/2019/005039,03.01.2019,WO,DIAGNOSIS TAILORING OF HEALTH AND DISEASE,"The present invention relates generally and specifically to computerized devices capable of diagnosis tailoring for an individual, a nd capable of controlling effectors to deliver therapy or enhance performance also tailored to an individual. The invention integrates sensors which sense signals from measurable body systems together with external machines, to form adaptive digital networks over time of general health and health of specific body functions. The invention has applications in sleep and wakefulness, sleep-disordered breathing, other breathing disturbances, memory and cognition, monitoring and response to obesity or heart failure, monitoring and response to other conditions, and general enhancement of performance.",A61B 5/113; A61B 5/145; A61B 5/20,INCYPHAE INC.,"NARAYAN, Sanjiv, M.; SEHRA, Ruchir","15/636,056 28.06.2017 US",EP-2017811424
WO2019226474,PCT/US2019/032796,17.05.2019,WO/2019/226474,28.11.2019,WO,IMPROVING ABSTRACTION OF TEXT SUMMARIZATON,"A system is disclosed for providing an abstractive summary of a source textual document. The system includes an encoder, a decoder, and a fusion layer. The encoder is capable of generating an encoding for the source textual document. The decoder is separated into a contextual model and a language model. The contextual model is capable of extracting words from the source textual document using the encoding. The language model is capable of generating vectors paraphrasing the source textual document based on pre-training with a training dataset. The fusion layer is capable of generating the abstractive summary of the source textual document from the extracted words and the generated vectors for paraphrasing. In some embodiments, the system utilizes a novelty metric to encourage the generation of novel phrases for inclusion in the abstractive summary.",G06F 17/27; G06N 3/04,"SALESFORCE.COM, INC.","PAULUS, Romain; KRYSCINSKI, Wojciech; XIONG, Caiming","62/675,147 22.05.2018 US; 16/051,188 31.07.2018 US",
WO2017175208,PCT/IB2017/052067,10.04.2017,WO/2017/175208,12.10.2017,WO,"METHODS, APPARATUSES, AND SYSTEMS FOR GRADIENT DETECTION OF SIGNIFICANT INCIDENTAL DISEASE INDICATORS","Computer program products, methods, systems, apparatus, and computing entities are described for identifying significant incidental findings from medical records. In one example embodiment, an example computing device receives a medical report and derives a textual component from the medical report. The computing device then identifies one or more medical findings from the textual component and determines a clinical context for each of the one or more medical findings. The computing device then identifies one or more clinical cues from the one or more medical findings and generates one or more condition signals from the one or more clinical cues. The computing device then generates a condition alert from the one or more condition signals. The condition alert is indicative of a significant incidental finding. Using various embodiments contemplated herein, significant incidental findings can be identified for follow-up by a user.",G06F 19/00,"OPTUM, INC.","POTTER, Brian C.; MORSCH, Mark L.; HO, Emily V.","62/319,912 08.04.2016 US; 15/483,567 10.04.2017 US",
EP276032558,18170047,30.04.2018,3564846,06.11.2019,EP,METHODS AND SYSTEMS FOR AUTOMATIC OBJECT RECOGNITION AND AUTHENTICATION,,G06K 9/00; H04L 9/32,MERCK PATENT GMBH,ENDRESS THOMAS DR; SZABO DANIEL; BERKERMANN FREDERIC DR,18170047 30.04.2018 EP,
EP13723692,00938189,07.06.2000,1208521,29.05.2002,EP,UNITARY PACKAGE IDENTIFICATION AND DIMENSIONING SYSTEM EMPLOYING LADAR-BASED SCANNING METHODS,"A fully automated package identification and measuring system (300), in which an onmidirectional holographic scanning tunnel (100) is used to read bar codes on packages entering the tunnel, while a package dimensioning subsystem (500, 600) is used to capture information about the package prior to entry into the tunnel. Mathematical models are created on a real-time basis for the geometry of the package and the position of the laser scanning beam used to read the bar code symbol thereon. The mathematical models are analyzed to determine if collected and queued package identification data is spatially and/or temporally correlated with package measurement data using vector-based ray-tracing methods, homogeneous transformations, and object-oriented decision logic so as to enable simultaneous tracking of multiple packages being transported through the scanning tunnel.",G06K 7/10; G02B 26/10; G06K 7/14; G06K 17/00; G07G 1/00; H01L 21/285; H01L 29/45,METROLOGIC INSTR INC,ZHU XIAOXUN; AU KA MAN; GERMAINE GENNADY; KOLIS GEORGE; GOOD TIMOTHY A; SCHNEE MICHAEL D; BLAKE ROBERT E; KNOWLES CARL HARRY; GHOSH SANKAR; NAYLOR CHARLES; WILZ DAVID M SR; TSIKOS CONSTANTINE J; LODGE FRANCIS; COLAVITO STEPHEN J; ROCKSTEIN GEORGE B,0015624 07.06.2000 US; 32775699 07.06.1999 US,
WO2013177132,PCT/US2013/041979,21.05.2013,WO/2013/177132,28.11.2013,WO,BATTERY MANAGEMENT SYSTEM WITH DISTRIBUTED WIRELESS SENSORS,A system for monitoring parameters of an energy storage system having a multiplicity of individual energy storage cells. A radio frequency identification and sensor unit is connected to each of the individual energy storage cells. The radio frequency identification and sensor unit operates to sense the parameter of each individual energy storage cell and provides radio frequency transmission of the parameters of each individual energy storage cell. A management system monitors the radio frequency transmissions from the radio frequency identification and sensor units for monitoring the parameters of the energy storage system.,G01R 31/36; H01M 10/48; G06K 19/07,"LAWRENCE LIVERMORE NATIONAL SECURITY, LLC","FARMER, Joseph C.; BANDHAUER, Todd M.","61/650,649 23.05.2012 US; 13/772,620 21.02.2013 US",
WO2000039666,PCT/US1999/031048,28.12.1999,WO/2000/039666,06.07.2000,WO,CONVERTING CONTENT OF MARKUP DATA FOR WIRELESS DEVICES,"A method and system for converting content of electronic data for wireless services is provided. The method and system allow a wireless device such as a wireless telephone (12) to receive electronic documents with electronic data such as web pages from the World-Wide-Web on the Internet (20) in a format suitable for display on a wireless device (12). An original electronic document in a first markup language such as Hyper Text Markup Language ('HTML') is converted (16) from a Wireless Application Protocol ('WAP'). Textual document elements and non-textual document elements (e.g., images) are converted (16) from a format suitable for the first markup language into a format suitable for the second markup language. A converted document (e.g., WML) suitable for display on a wireless device (12) is sent in response to a request for an original electronic document (e.g., HTML). Receiving a converted electronic document in response to a request for an original document may lead to greater satisfaction for users of wireless devices.",G06F 17/30; H04L 29/06; H04L 29/08; H04M 1/725,"SPYGLASS, INC.; CARLINO, Kenneth, F.; HOHL, Kenneth, B.","CARLINO, Kenneth, F.; HOHL, Kenneth, B.","09/221,750 28.12.1998 US",
WO2014049310,PCT/GB2013/000369,04.09.2013,WO/2014/049310,03.04.2014,WO,METHOD AND APPARATUSES FOR INTERACTIVE SEARCHING OF ELECTRONIC DOCUMENTS,"Interactive extraction of information and interactive searching of an electronic document, where there is formulation of a query to extract specific information from a given part of the electronic document while preserving technical and scientific information quality and accuracy; the process involving a query-controlled automatic segmentation of the given part of the electronic document into a plurality of terms represented as a weighted directed graph; query-controlled automatic classification of each of these terms by associating it with type and feature vector; query-controlled relevance scoring of each of these terms; query-controlled automatic selection of a subset of these terms; and automated composition of the system output guaranteeing to have at least some minimum level of coherence to be presented to the user.",G06F 17/30,SWANSEA UNIVERSITY,"LOSKOT, Pavel",1217334.0 27.09.2012 GB,
WO2007070842,PCT/US2006/062072,14.12.2006,WO/2007/070842,21.06.2007,WO,"SYSTEM AND METHODS FOR INITIATING, MAINTAINING, AND DELIVERING PERSONALIZED INFORMATION BY COMMUNICATION SERVER","Systems and methods are disclosed for personalized information retrieval related to identified objects prompted by a coded activation message (AM) Containing Object identifiers (OIs) (112), and necessary message-source’s identifiers. Decoded AMs identify the required information recipients and their communication devices (RIDs) (102) and direct a communication server (100) to a site containing identified object-related information, formatted for personalized delivery defined by RlD features and preset preferences of relevant entities. The PCWS (100) interactively monitors and directs information flow through selected preferred communication links, re-establishing flow upon disruptions or per AMs. Alternatively, the system can include sensors for detecting events associated with relevant objects and potential recipients, and submitting AMs on behalf of relevant recipients. Recipients can use keypad or voice commands for online interactive remote control of PCWS information retrieval, routing and storage.",G06F 15/16,"BERGER, Josef; SHALEV, Shaul","BERGER, Josef; SHALEV, Shaul","60/750,605 15.12.2005 US",IN-5293/DELNP/2008; EP-2006846615; CA-2634032; DE-null
WO2004048937,PCT/US2003/038186,25.11.2003,WO/2004/048937,10.06.2004,WO,ELECTRO-OPTICAL NUCLEIC ACID-BASED SENSOR ARRAY AND METHOD FOR DETECTING ANALYTES,"The present invention is directbd to methods of detection, identification and monitoring of vapor phase analytes by using sensor arrays comprising fluorophore labeled nucleic acids, dried onto a substrate which react with vapor phase analytes. Methods of using and preparing such sensor arrays are also provided.",C12M 1/34; G01N 33/543; G01N 33/551,"TUFTS UNIVERSITY; WHITE, Joel, E.; KAUER, John, S.","WHITE, Joel, E.; KAUER, John, S.","60/428,869 25.11.2002 US; 10/303,548 25.11.2002 US",CA-2547331; US-10535748; JP-2004555829; EP-2003799861
WO2014115147,PCT/IL2014/050085,23.01.2014,WO/2014/115147,31.07.2014,WO,SYSTEM AND METHOD FOR FLEXIBLE VIDEO CONSTRUCTION,A system and method for automatically constructing personalized video clips for a viewer.,G11B 27/02; H04N 7/173; G06F 19/00,TELESOFIA MEDICAL LTD.,"COHEN, Rami; ROTSHTEIN, Tzvi; BEN SHITRIT, Danny","61/756,040 24.01.2013 US",US-14762820; EP-2014743541; IL-240124
EP205858833,16735507,08.01.2016,3242588,15.11.2017,EP,BLOOD BASED BIOMARKERS FOR DIAGNOSING ATHEROSCLEROTIC CORONARY ARTERY DISEASE,,A61B 5/00; G01N 33/48; G01N 33/53; G01N 33/68,GLOBAL GENOMICS GROUP LLC,VOROS SZILARD; BROWN BRADLEY O; MARVASTY IDEAN B,201562101445 09.01.2015 US; 2016012725 08.01.2016 US,
WO2006076760,PCT/AU2006/000012,06.01.2006,WO/2006/076760,27.07.2006,WO,SEQUENTIAL DATA SEGMENTATION,The invention concerns sequential data segmentation using spectral clustering. Attributes of data samples are extracted to construct affinity matrices for sequences of samples in sequential order. K-segmentation is then applied to a representation of the sequences of samples derived from the affinity matrices to identify K-segments. Each K-segment is comprised of representations of samples in sequential order. In this way data samples are not viewed as independent and this prevents data samples from the same true segment being assigned to different clusters. The invention respects the sequential semantics of the data and ensures that adjacent samples are consistently assigned to the same cluster. An example of sequential data segmentation is the segmentation of sequential video frames into separate shots. The invention also concerns a computer system and computer software able to perform sequential data segmentation.,G06K 9/00; G06F 17/30,"NATIONAL ICT AUSTRALIA LIMITED; YU, Zhenghua; VISHWANATHAN, Swaminathan, Venkata, Narayana; SMOLA, Alex","YU, Zhenghua; VISHWANATHAN, Swaminathan, Venkata, Narayana; SMOLA, Alex",2005900278 24.01.2005 AU; 2005901525 29.03.2005 AU,EP-6700258; AU-2006207811
WO2005017767,PCT/AU2004/001088,16.08.2004,WO/2005/017767,24.02.2005,WO,NATURAL LANGUAGE RECOGNITION USING DISTRIBUTED PROCESSING,"A method and system for computer-based recognition of natural language data. The method is implemented on a distributed computer network and includes obtaining natural language data, such as digital ink handwriting, using an input device (415), receiving the natural language data on a server (430) via a network, processing the natural language data using a recognizer (440) residing on the server (430) to produce intermediate format data (445), transmitting the intermediate format data (445) to an application (450), and decoding the intermediate format data 445 into computer-readable format data using the application (450) and context information associated with the application (450).",G06F 17/24; G06F 17/27; G10L 15/28,"SILVERBROOK RESEARCH PTY LTD; NAPPER, Jonathon, Leigh; LAPSTUN, Paul; SILVERBROOK, Kia","NAPPER, Jonathon, Leigh; LAPSTUN, Paul; SILVERBROOK, Kia",2003904350 15.08.2003 AU; 2003904351 15.08.2003 AU,EP-2004761125; US-10510392; AU-2004265700; CA-2529037
WO2016183770,PCT/CN2015/079190,18.05.2015,WO/2016/183770,24.11.2016,WO,A SYSTEM AND A METHOD FOR PREDICTING CROWD ATTRIBUTES,"Disclosed is a system for predicting crowd attributes, comprising: a feature extracting device obtaining a video with crowd scenes and extracting appearances features and motion features from the obtained video, wherein the motion features are scene-independent and indicate motion properties of crowd of the video; and a prediction device being electronically communicated with the feature extracting device and predicting attributes of the crowd in the video based on the extracted motion features and the extracted appearances.",G06F 17/30,"WANG, Xiaogang","WANG, Xiaogang; LOY, Chen Change; SHAO, Jing; KANG, Kai",,
EP215067127,17197588,20.10.2017,3312742,25.04.2018,EP,METHOD AND APPARATUS FOR HIERARCHICAL CLUSTERING OF GEOGRAPHICAL DATA,"An approach is provided for hierarchical clustering of geographical data. The approach involves receiving a request to cluster geographical data by location. The geographical area is represented by a hierarchical tile projection comprising a plurality of zoom levels, and tiles of each of the zoom levels represent different respective scales of a corresponding portion of the geographical area. The approach also involves determining that the geographical data is located in a border area of a first tile at a higher zoom level of the hierarchical tile projection. The approach further involves recursively forwarding the geographical data for clustering at a lower zoom level of the hierarchical tile projection until the geographical data is not located in a border area of a second tile at the lower zoom level. The approach then involves initiating the clustering of the geographical data into a cluster located in the second tile at the lower zoom level.",G06F 17/30,HERE GLOBAL BV,METCALF-PUTNAM EVAN; MILOJKOVIC DEJAN,201615331263 21.10.2016 US,
WO2019232670,PCT/CN2018/089773,04.06.2018,WO/2019/232670,12.12.2019,WO,SYSTEMS AND METHODS FOR ON-DEMAND SERVICES,A method for online to offline services is provided. The method may include one or more of the following operations. A transportation service request may be received. The transportation service request may include a target address query from a user terminal. Whether the target address query is directed to a target area of interest (AOI) may be determined. At least one target point of interest (POI) and a target semantic description associated with the target AOI may be obtained from an AOI database. The at least one target POI and the target semantic description may be sent to the user terminal.,G06F 17/24,"BEIJING DIDI INFINITY TECHNOLOGY AND DEVELOPMENT CO., LTD.","ZHAO, Ji; CHEN, Huan; YU, Peng; SONG, Qi",,CN-201880043920.8
WO2006022910,PCT/US2005/015003,29.04.2005,WO/2006/022910,02.03.2006,WO,METHOD FOR TRAFFIC SIGN DETECTION,"A method for detecting and recognizing at least one traffic sign is disclosed. A video sequence having a plurality of image frames is received. One or more filters are used to measure features in at least one image frame indicative of an object of interest. The measured features are combined and aggregated into a score indicating possible presence of an object. The scores are fused over multiple image frames for a robust detection. If a score indicates possible presence of an object in an area of the image frame, the area is aligned with a model. A determination is then made as to whether the area indicates a traffic sign. If the area indicates a traffic sign, the area is classified into a particular type of traffic sign. The present invention is also directed to training a system to detect and recognize traffic signs.",G06K 9/32; G06K 9/64,"SIEMENS CORPORATE RESEARCH, INC.; SIEMENS AKTIENGESELLSCHAFT; BAHLMANN, Claus; ZHU, Ying; RAMESH, Visvanathan; PELLKOFER, Martin; KOEHLER, Thomas","BAHLMANN, Claus; ZHU, Ying; RAMESH, Visvanathan; PELLKOFER, Martin; KOEHLER, Thomas","60/601,788 16.08.2004 US; 60/637,841 21.12.2004 US; 11/109,106 19.04.2005 US",KR-1020077002966; EP-2005745151; CN-200580027960.6; JP-2007527259
WO2018068176,PCT/CN2016/101649,10.10.2016,WO/2018/068176,19.04.2018,WO,COMBO OF LANGUAGE UNDERSTANDING AND INFORMATION RETRIEVAL,"A method, an apparatus and a system for information retrieval are provided. The method for information retrieval may comprise: receiving a query in a natural language form from a user (210); extracting a plurality of feature vectors from the query based on a plurality of knowledge entries in a knowledge base associated with the user and a built-in featurization source, one feature vector per knowledge entry (220); obtaining, with a pre-trained language understanding model, a plurality of language understanding results based on the plurality of feature vectors (230); and selecting a knowledge entry corresponding to the query among the plurality of entries based on the plurality of language understanding results (240). The method may extract more features and combine information retrieval and language understanding in one shot to improve efficiency.",G06F 17/27,"MICROSOFT TECHNOLOGY LICENSING, LLC; NI, Yong","NI, Yong",,EP-2016918575
EP291472779,18868807,13.07.2018,3627397,25.03.2020,EP,PROCESSING METHOD AND APPARATUS,"Provided are a processing method and apparatus. The method involves: respectively quantizing a weight and an input neuron to determine a weight dictionary, a weight code book, a neuron dictionary and a neuron code book; and determining a calculation code book according to the weight code book and the neuron code book. In addition, in the present application, a calculation code book is determined according to quantized data, and the two types of quantized data are combined, thereby facilitating data processing.",G06N 3/02,SHANGHAI CAMBRICON INFORMATION TECH CO LTD,LIU SHAOLI; ZHOU XUDA; DU ZIDONG; LIU DAOFU; ZHANG LEI; CHEN TIANSHI; HU SHUAI; WEI JIE; MENG XIAOFU,201710989575 20.10.2017 CN; 201711004974 24.10.2017 CN; 201711029543 29.10.2017 CN; 201711061069 24.10.2017 CN; 201711118938 29.10.2017 CN; 201711289667 07.12.2017 CN; 2018095548 13.07.2018 CN,
WO2002025574,PCT/GB2001/004236,24.09.2001,WO/2002/025574,28.03.2002,WO,DATA CLUSTERING METHODS AND APPLICATIONS,"A data clustering method involves techniques for improving the speed of generation of clustering data representing hierarchical clustering of a set of data samples. The techniques include the selection of clusters in increasing size for selecting the nearest other cluster for merging, ordering the data samples according to absolute distance from a reference and searching for nearest neighbours within a restricted index range, and making distance comparisons by summing the contributions from components in each dimension in turn in order of the interquartile ranges of components of the data samples in each dimension. A data classification method involves calculating a rank value for a test sample in relation to a cluster of data samples, by taking into account the dissimilarities of the data samples at either end of the closest edge to the data sample and/or by calculating as a function of a test sample dissimilarity of the test sample to the most similar data sample within the cluster, unless the test sample dissimilarity is less than the dissimilarity of an edge in a minimum spanning tree which has the greatest dissimilarity less than an edge connected to the most similar data sample. The applications of the methods include data compression, feature extraction, unmixing, data mining and browsing, network design and pattern recognition.",G06F 17/30; G06K 9/62,"HTTP INSIGHTS LIMITED; RAHMAN, Sabbir, Ahmed; NIGHTINGAL TECHNOLOGIES LTD.","RAHMAN, Sabbir, Ahmed",00308303.7 22.09.2000 EP,
EP236734343,16890639,07.11.2016,3418881,26.12.2018,EP,"INFORMATION PROCESSING DEVICE, INFORMATION PROCESSING METHOD, AND PROGRAM","It is desired to provide a technology capable of easily recording a program for obtaining an intention of a user from text data corresponding to dialogue using a natural language.  Provided is an information processing device including: a text data analysis unit configured to analyze text data corresponding to dialogue using a natural language, and extract an event included in the text data and a process to be executed in accordance with the event; and a record control unit configured to record a correspondence relation between the event and the process on a recording medium as a program.",G10L 15/22; G06F 3/16; G06F 17/27; G10L 15/10,SONY CORP,NAGASAKA HIDEO; DOI SHOUICHI,2016028539 18.02.2016 JP; 2016082976 07.11.2016 JP,
EP199527990,15307053,18.12.2015,3182297,21.06.2017,EP,METHOD FOR GENERATING SEMANTIC DESCRIPTION OF TEXTUAL CONTENT AND APPARATUS PERFORMING THE SAME,"A method, a computer readable storage medium and an apparatus (20) for generating a semantic description of a textual content are described. A textual content and information about the characters in the textual content are received. The textual content are analysed to identify the structure of the textual content and to identify words and their semantic roles in the sentences in the textual content. A graphical representation of the textual content is generated. Each of the identified words of the textual content is represented as an item in the graphical representation, and the semantic roles of the words in the sentences of the textual content are represented by the connection of the items of the words in the graphical representation.",G06F 17/30,THOMSON LICENSING,GLAESER FRANK; WEBER MICHAEL; JACHALSKY JOERN,15307053 18.12.2015 EP,
WO2015006630,PCT/US2014/046256,11.07.2014,WO/2015/006630,15.01.2015,WO,INTERACTIVE CONCEPT EDITING IN COMPUTER-HUMAN INTERACTIVE LEARNING,"A collection of data that is extremely large can be difficult to search and/or analyze. Relevance may be dramatically improved by automatically classifying queries and web pages in useful categories, and using these classification scores as relevance features. A thorough approach may require building a large number of classifiers, corresponding to the various types of information, activities, and products. Creation of classifiers and schematizers is provided on large data sets. Exercising the classifiers and schematizers on hundreds of millions of items may expose value that is inherent to the data by adding usable meta-data. Some aspects include active labeling exploration, automatic regularization and cold start, scaling with the number of items and the number of classifiers, active featuring, and segmentation and schematization.",G06N 99/00,"MICROSOFT TECHNOLOGY LICENSING, LLC","SIMARD, Patrice Y.; GRANGIER, David G.; BOTTOU, Leon; AMERSHI, Saleema A.","61/845,844 12.07.2013 US; 14/075,679 08.11.2013 US",EP-2014745312
WO2019023462,PCT/US2018/043910,26.07.2018,WO/2019/023462,31.01.2019,WO,MOBILE-PLATFORM COMPRESSION-INDUCED IMAGING FOR SUBSURFACE AND SURFACE OBJECT CHARACTERIZATION,"A mobile-platform imaging device uses compression of the target region to generate an image of an object. A tactile sensor has an optical waveguide with a flexible, transparent first layer. Light is directed into the waveguide. Light is scattered out of the first layer when the first layer is deformed. The first layer is deformed by the tactile sensor being pressed against the object, A force sensor detects a force pressing the tactile sensor against the object and outputs corresponding force information. A first communication unit receives the force information from the force sensor. A receptacle holds a mobile device with a second communication unit and an imager that can generate image information using light scattered out of the first layer. The first communication unit communicates with the second communication unit and the mobile device communicates with an external network.",G01L 1/16; G01L 1/24; G01N 19/00; G01N 3/08; G01N 3/24; G02B 6/10; G06K 9/78,TEMPLE UNIVERSITY - OF THE COMMONWEALTH SYSTEM OF HIGHER EDUCATION,"WON, Chang-Hee","62/538,032 28.07.2017 US",IL-272250; AU-2018306438; EP-2018837690
WO2019241639,PCT/US2019/037198,14.06.2019,WO/2019/241639,19.12.2019,WO,PROCESSING SYSTEM FOR EVALUATING AUTONOMOUS VEHICLE CONTROL SYSTEMS THROUGH CONTINUOUS LEARNING,"Aspects of the disclosure relate to an autonomous vehicle evaluation system that performs continuous evaluation of the actions, strategies, preferences, margins, and responses of an autonomous driving control system. A computing platform may receive sensor data from one or more autonomous vehicle sensors, manufacturer computing platform, or V2X computing platform. Based on this sensor data, the computing platform may determine one or more driving patterns. Based on a primary context corresponding to the one or more driving patterns, the computing platform may group the one or more driving patterns. The computing platform may determine a driving pattern degradation output indicating degradation corresponding to the one or more grouped driving patterns, and the computing platform may send the driving pattern degradation output to an autonomous driving system, which may cause the autonomous driving system to take corrective action accordingly.",G05D 1/00,ALLSTATE INSURANCE COMPANY,"ARAGON, Juan Carlos; MADIGAN, Regina","62/685,625 15.06.2018 US; 16/232,210 26.12.2018 US",
WO2004019224,PCT/IB2003/003401,31.07.2003,WO/2004/019224,04.03.2004,WO,UNIT FOR AND METHOD OF DETECTION A CONTENT PROPERTY IN A SEQUENCE OF VIDEO IMAGES,A method of detection of a content property in a data stream on basis of low-level features is proposed. The method comprises: determining (202) a behavior feature (e.g. 320) from a sequence of the low-level features; determining (204) to which one of the predetermined clusters (304) of behavior features (318-328) within a behavior feature space (300) the determined behavior feature (320) belongs; determining a confidence level of the content property presence on basis of the determined cluster (304) of behavior features and the determined behavior feature; and detecting the content property on basis of the confidence level of the content property presence.,G06F 17/30; G06K 9/00,"KONINKLIJKE PHILIPS ELECTRONICS N.V.; SNIJDER, Freddy; PAULUSSEN, Igor, W., F.","SNIJDER, Freddy; PAULUSSEN, Igor, W., F.",02078516.8 26.08.2002 EP,US-10525171; KR-1020057003343; CN-03820301.4; JP-2004530435; EP-2003792555
WO2015102677,PCT/US2014/052799,27.08.2014,WO/2015/102677,09.07.2015,WO,CONCEALING SENSITIVE PATTERNS FROM LINKED DATA GRAPHS,"A method, system and computer program product for preventing sensitive pattern disclosures from Linked Data graphs. The proposed method (i) receives as input a Linked Data graph and a set of query patterns that correspond to sensitive knowledge that needs to be concealed, and (b) minimally distorts the Linked Data graph to generate a sanitized counterpart (graph) in which only the non-sensitive patterns can be discovered. The method supports a variety of utility functions, which it optimizes during the graph sanitization process. The resulting, sanitized graph can be subsequently used for publishing and/or querying purposes.",G06N 5/02,INTERNATIONAL BUSINESS MACHINES CORPORATION,"GKOULALAS-DIVANIS, Aris; KOTOULAS, Spyros; LOPEZ GARCIA, Vanessa; SBODIO, Marco Luca","14/143,923 30.12.2013 US",
EP234205167,17741247,10.01.2017,3407054,28.11.2018,EP,"CRACK INFORMATION EDITING DEVICE, CRACK INFORMATION EDITING METHOD, AND CRACK INFORMATION EDITING PROGRAM","Provided are a crack information editing device, a method of editing crack information, and a crack information editing program that can easily designate and edit one crack by appropriately labeling discontinuous cracks. A hierarchical structure information generation unit 112 corrects hierarchical structure information based on an editing instruction input by a user through an operation unit (120) (step S160: editing step). A display of the hierarchical structure information is updated based on the editing instruction input. The editing instruction input includes deleting a damage vector corresponding to a randomly selected label, combining a plurality of discontinuous damage vectors associated with a plurality of randomly selected labels into one continuous damage vector, releasing the combination between the plurality of the damage vectors, and selection of a label corresponding to a vector group, and deletion, combination, and release of the combination of the vector group corresponding to the selected label.",G01N 21/88; G06T 7/00; G06T 7/60,FUJIFILM CORP,KARUBE MIKIHIKO,2016010709 22.01.2016 JP; 2017000502 10.01.2017 JP,
WO2012154230,PCT/US2012/021743,18.01.2012,WO/2012/154230,15.11.2012,WO,LEARNING SITUATIONS VIA PATTERN MATCHING,"Example methods, apparatuses, or articles of manufacture are disclosed herein that may be utilized, in whole or in part, to facilitate or support one or more operations or techniques for machine learning of situations via pattern matching or recognition.",G06K 9/00,"QUALCOMM INCORPORATED; NARAYANAN, Vidya; NANDA, Sanjiv; SHIH, Fuming","NARAYANAN, Vidya; NANDA, Sanjiv; SHIH, Fuming","61/434,400 19.01.2011 US; 13/269,516 07.10.2011 US",EP-2012704340; JP-2013550569; KR-1020137021586
WO2019046835,PCT/US2018/049287,01.09.2018,WO/2019/046835,07.03.2019,WO,ULTRA-LOW POWER NEUROMORPHIC ARTIFICIAL INTELLIGENCE COMPUTING ACCELERATOR,"A three-dimensional (3D) ultra-low power neuromorphic accelerator is described. The 3D ultra-low power neuromorphic accelerator includes a power manager as well as multiple tiers. The 3D ultra-low power neuromorphic accelerator also includes multiple cores defined on each tier and coupled to the power manager. Each core includes at least a processing element, a non-volatile memory, and a communications module.",G06N 3/063; G06F 1/32; G06N 3/04; G06N 3/08; G11C 11/00; G11C 11/16; G11C 11/54; G11C 13/00; H01L 25/18; H01L 25/00,QUALCOMM INCORPORATED,"PU, Yu; DU, Yang","62/553,447 01.09.2017 US; 16/119,929 31.08.2018 US",
WO2014196984,PCT/US2013/044714,07.06.2013,WO/2014/196984,11.12.2014,WO,SPEECH-BASED SEARCH USING DESCRIPTIVE FEATURES OF SURROUNDING OBJECTS,"A natural language query arrangement is described for a mobile environment. An automatic speech recognition (ASR) engine can process an unknown speech input from a user to produce corresponding recognition text. A natural language understanding module can extract natural language concept information from the recognition text. A query classifier uses the recognition text and the natural language concept information to assign to the speech input a query intent related to one or more objects in the mobile environment. An environment database contains information descriptive of objects in the mobile environment. A query search engine searches the environment database based on the query intent, the natural language concept information, and the recognition text to determine corresponding search results, which can be to the user.",G10L 15/18,"NUANCE COMMUNICATIONS, INC.","KLEINDIENST, Jan; KUNC, Ladislav; LABSKY, Martin; LENKE, Nils; MACEK, Tomas",,EP-2013886305
EP240631199,18192801,05.09.2018,3467708,10.04.2019,EP,METHOD FOR ACQUIRING A PSEUDO-3D BOX FROM A 2D BOUNDING BOX BY REGRESSION ANALYSIS AND LEARNING DEVICE AND TESTING DEVICE USING THE SAME,"A method for acquiring a pseudo-3D box from a 2D bounding box in a training image is provided. The method includes steps of: (a) a computing device acquiring the training image including an object bounded by the 2D bounding box; (b) the computing device performing (i) a process of classifying a pseudo-3D orientation of the object, by referring to information on probabilities corresponding to respective patterns of pseudo-3D orientation and (ii) a process of acquiring 2D coordinates of vertices of the pseudo-3D box by using regression analysis; and (c) the computing device adjusting parameters thereof by backpropagating loss information determined by referring to at least one of (i) differences between the acquired 2D coordinates of the vertices of the pseudo-3D box and 2D coordinates of ground truth corresponding to the pseudo-3D box, and (ii) differences between the classified pseudo-3D orientation and ground truth corresponding to the pseudo-3D orientation.",G06K 9/00,STRADVISION INC,KIM YONGJOONG; NAM WOONHYUN; BOO SUKHOON; SUNG MYUNGCHUL; YEO DONGHUN; RYU WOOJU; JANG TAEWOONG; JEONG KYUNGJOONG; JE HONGMO; CHO HOJIN,201715723538 03.10.2017 US,
WO2015168026,PCT/US2015/027809,27.04.2015,WO/2015/168026,05.11.2015,WO,METHOD FOR LABEL-FREE IMAGE CYTOMETRY,"A computer-implemented method for the label-free classification of cells using image cytometry is provided. In some exemplary embodiments of the computer implemented method, the classification is the classification of the cells, such as individual cells, into a phase of the cell cycle or by cell type. A user computing device receives as an input one or more images of a cell obtained from a image cytometer. The user computing device extracts features form the one or more images, such as brightfield and/or darkfield images. The user computing device classifies the cell in the one or more images based on the extracted features using a cell classifier. The user computing device then outputs the class label of the cell, as defined by the classifier.",G06K 9/00,"THE BROAD INSTITUTE, INC.; SWANSEA UNIVERSITY; HELMHOLTZ ZENTRUM MUNCHEN","CARPENTER VAN DYK, Anne; BLASI, Thomas; REES, Paul; HENNIG, Holger","62/088,151 05.12.2014 US; 61/985,236 28.04.2014 US; 62/135,820 20.03.2015 US",US-15307706
EP232159349,17167514,21.04.2017,3392798,24.10.2018,EP,A METHOD FOR THE SEMANTIC SEGMENTATION OF AN IMAGE,"A method for the semantic segmentation of an image having a two-dimensional arrangement of pixels comprises the steps of segmenting at least a part of the image into superpixels, determining image descriptors for the superpixels, wherein each image descriptor comprises a plurality of image features, feeding the image descriptors of the superpixels to a convolutional network and labeling the pixels of the image according to semantic categories by means of the convolutional network, wherein the superpixels are assigned to corresponding positions of a regular grid structure extending across the image and the image descriptors are fed to the convolutional network based on the assignment.",G06K 9/00; G06K 9/34; G06K 9/46; G06T 7/11,DELPHI TECH INC,ZOHOURIAN FARNOUSH; ANTIC BORISLAV; SIEGEMUND JAN; MEUTER MIRKO,17167514 21.04.2017 EP,
WO2014116410,PCT/US2014/010448,07.01.2014,WO/2014/116410,31.07.2014,WO,SYSTEMS AND METHODS FOR COLLABORATING IN A NON-DESTRUCTIVE TESTING SYSTEM,"A collaboration system may include a computing device that may communicate with the at least one other computing device via a computing network network. The computing device may receive data that has been acquired using one or more non-destructive testing (NDT) inspection devices, receive an input that may cause a list of one or more experts indicated as available to collaborate to be derived. The computing device may also receive a selection of at least one expert from the list of experts. After receiving the expert selection, the computing device may establish a communication connection between the computing device and the at least one other computing device that corresponds to the at least one expert. Here, the communication connection may share data depicted on the computing device with the at least one other computing device.",G06Q 50/00; G01N 21/88; G01N 23/18; G01N 27/90; G01N 29/04; G06F 19/00,GENERAL ELECTRIC COMPANY,"SOORIANARAYANAN, Sekhar; WARD, Robert, Carroll; DOMKE, Michael, Christopher; MESSINGER, Jason, Howard; SBIHLI, Scott, Leo","13/747,453 22.01.2013 US",CN-201480017521.6; JP-2015553752; EP-2014703643; CA-2898458
EP234473498,17775691,14.03.2017,3410312,05.12.2018,EP,DIAGNOSTIC MODEL GENERATING METHOD AND DIAGNOSTIC MODEL GENERATING APPARATUS THEREFOR,"Provided are a diagnostic model generating apparatus and a diagnostic model generating method therefor. The diagnostic model generating method may comprising: extracting at least one keyword from consultation data between a user and a consultant for resolving electronic device errors; on the basis of the at least one extracted keyword, determining a diagnostic sequence between the plurality of diagnostic commands for resolving errors and a plurality of diagnostic commands; and storing a diagnostic model comprising the plurality of determined diagnostic commands and determined diagnostic sequence.",G06F 11/07; G06F 16/00; G06F 16/33; G06F 17/18; G06F 17/27; G06N 20/00,SAMSUNG ELECTRONICS CO LTD,YU SEUNG-HAK; KIM MIN-SEO; KIM DEOK-HO; YUN JI-HWAN,20160040291 01.04.2016 KR; 2017002704 14.03.2017 KR,
WO2020074959,PCT/IB2019/001106,15.10.2019,WO/2020/074959,16.04.2020,WO,"SYSTEM, DEVICE AND METHOD FOR OBJECT DETECTION IN VIDEO FEEDS",Embodiments are directed to a smart camera device that analyzes independent video streams.,G06K 9/00; G06K 9/62,MONITOREAL LIMITED,"YAKUPOV, Aydar; ALATORTSEV, Michael","62/745,011 12.10.2018 US",
WO2015103534,PCT/US2015/010146,05.01.2015,WO/2015/103534,09.07.2015,WO,TRIGGERING REROUTES USING EARLY LEARNING MACHINE-BASED PREDICTION OF FAILURES,"Network metrics are collected and analyzed. It is predicted by using machine learning whether a network element failure is relatively likely to occur based on the collected and analyzed network metrics. In response to predicting that a network element failure is relatively likely to occur, traffic in the network is rerouted in order to avoid the network element failure. Application to Low Power and Lossy Network (LLN).",H04L 12/24; H04W 40/18,"CISCO TECHNOLOGY, INC.","VASSEUR, Jean-philippe; MERMOUD, Gregory; DASGUPTA, Sukrit","61/923,910 06.01.2014 US; 14/164,567 27.01.2014 US",CN-201580003767.2; EP-2015703128
WO2016196527,PCT/US2016/035126,01.06.2016,WO/2016/196527,08.12.2016,WO,METADATA TAG DESCRIPTION GENERATION,"One or more techniques and/or systems are provided for metadata tag evaluation. For example, a metadata tag, associated with content, may be identified (e.g., a hashtag #ML may be used to tag a social network post). A set of characters, within the content, may be evaluated utilizing a probability matrix and the content to identify an expanded metadata tag (e.g., an expanded hashtag ""machine learning""). Descriptive content, such as websites, articles, social network posts, and/or other content associated with the expanded metadata tag, may be retrieved. A description for the metadata tag may be generated based upon the descriptive content (e.g., a definition for machine learning). In this way, the description, related metadata tags, and/or supplemental content may be provided to users having an interest in learning about the metadata tag.",G06F 17/30,"MICROSOFT TECHNOLOGY LICENSING, LLC","BANNUR, Sushma Nagesh; ALONSO, Omar; HENTSCHEL, Martin","14/728,440 02.06.2015 US",EP-2016728205
EP276409728,18197986,01.10.2018,3567583,13.11.2019,EP,DEVICE AND METHOD TO PERSONALIZE SPEECH RECOGNITION MODEL,,G10L 15/07; G10L 15/16,SAMSUNG ELECTRONICS CO LTD,KWON KI SOO; SONG INCHUL; CHOI YOUNG SANG,20180054448 11.05.2018 KR,
WO2004010365,PCT/US2003/022545,21.07.2003,WO/2004/010365,29.01.2004,WO,FACE RECOGNITION SYSTEM AND METHOD THEREFOR,"A method and system for automated face recognition overcomes operational difficulties such as: face finding problems, inability to recognize some ethnic groups, inability to enroll users, pose, and being too slow for high volume usage. The automated face recognition system uses a new face finding and an automated eye finding approach combined with an intelligent metric. A small template size of the face biometric (biomatrix), of under 90 bytes, is provided, which allows templates to be placed on any size chip or into two dimensional (2-D) barcodes for self-authenticating documents, as well as for quick easy transmission over the internet, wireless devices, or Ethernet (i.e., LAN, WAN, etc.). The small template also provides quick identification and authentication speed, as well as minimal storage requirements, small processing requirements, and increased processing speed. The system can be included in dolls, games, auto theft deterrent systems and drowsiness detection systems.",G06K 9/00,"DICUT INC.; WISNIEWSKI, Helena","WISNIEWSKI, Helena","60/396,751 19.07.2002 US",JP-null
WO2015006254,PCT/US2014/045639,08.07.2014,WO/2015/006254,15.01.2015,WO,INTERACTIVE SEGMENT EXTRACTION IN COMPUTER-HUMAN INTERACTIVE LEARNING,"A collection of data that is extremely large can be difficult to search and/or analyze. Relevance may be dramatically improved by automatically classifying queries and web pages in useful categories, and using these classification scores as relevance features. A thorough approach may require building a large number of classifiers, corresponding to the various types of information, activities, and products. Creation of classifiers and schematizers is provided on large data sets. Exercising the classifiers and schematizers on hundreds of millions of items may expose value that is inherent to the data by adding usable meta-data. Some aspects include active labeling exploration, automatic regularization and cold start, scaling with the number of items and the number of classifiers, active featuring, and segmentation and schematization.",G06N 99/00; G06F 17/27,"MICROSOFT TECHNOLOGY LICENSING, LLC","SIMARD, Patrice Y.; CHICKERING, David Max; GRANGIER, David G.; CHARLES, Denis X.; BOTTOU, Leon; AMERSHI, Saleema A.; LAKSHMIRATAN, Aparna; SUAREZ, Carlos Garcia Jurado","61/845,844 12.07.2013 US; 14/075,713 08.11.2013 US",CN-201480039808.9; EP-2014745285; KR-1020167003639
WO2019094895,PCT/US2018/060653,13.11.2018,WO/2019/094895,16.05.2019,WO,SYSTEMS AND METHODS FOR ADAPTIVE PROPER NAME ENTITY RECOGNITION AND UNDERSTANDING,"Various embodiments contemplate systems and methods for performing automatic speech recognition (ASR) and natural language understanding (NLU) that enable high accuracy recognition and understanding of freely spoken utterances which may contain proper names and similar entities. The proper name entities may contain or be comprised wholly of words that are not present in the vocabularies of these systems as normally constituted. Recognition of the other words in the utterances in question, e.g. words that are not part of the proper name entities, may occur at regular, high recognition accuracy. Various embodiments provide as output not only accurately transcribed running text of the complete utterance, but also a symbolic representation of the meaning of the input, including appropriate symbolic representations of proper name entities, adequate to allow a computer system to respond appropriately to the spoken request without further analysis of the user's input.",G10L 15/22; G06F 17/27; G10L 15/32,PROMPTU SYSTEMS CORPORATION,"PRINTZ, Harry, William","15/811,586 13.11.2017 US",
WO2007010187,PCT/GB2006/002477,04.07.2006,WO/2007/010187,25.01.2007,WO,DATA HANDLING SYSTEM,"Media objects (28) are organised for storage and subsequent retrieval by applying metadata tags in response to both a manual input (21) and at least one automated process (24, 25, 26) for analysing the media objects and the metadata tags applied thereto, the outputs of the processes being combined (27) to provide an output to the manual process. The process may be repeated iteratively",G06F 17/30,"BRITISH TELECOMMUNICATIONS PUBLIC LIMITED COMPANY; JOHNSTON, David, Alexander; MENDIS, Venura, Chakri; SHEPPARD, Iain, Daniel, Mark","JOHNSTON, David, Alexander; MENDIS, Venura, Chakri; SHEPPARD, Iain, Daniel, Mark",05254577.9 22.07.2005 EP,DE-null
WO2017064705,PCT/IL2016/051102,10.10.2016,WO/2017/064705,20.04.2017,WO,METHOD OF IDENTIFYING AND TRACKING SENSITIVE DATA AND SYSTEM THEREOF,"Methods and systems for identifying sensitive data (SD) stored on data repositories is disclosed. The data is processed to calculate a plurality of float feature (FF) vectors associated with the data. The FF vectors are clustered into a plurality of clusters, each cluster associated with a respective subset of the data. A DNA vector representative of the cluster is generated for each cluster. The DNA vectors of respective clusters are compared to one or more FF vectors calculated for a respective one or more user supplied examples of SD. One or more clusters are classified as SD based on the result of the comparing, thereby identifying respective subsets of data as SD.",G06F 17/30; G06F 21/62; G06K 9/62,MINEREYE LTD.,"AVIDAN, Yaniv; ATIAS, Avner","62/241,298 14.10.2015 US; 62/259,749 25.11.2015 US",US-15767752
WO2000039658,PCT/US1999/031124,30.12.1999,WO/2000/039658,06.07.2000,WO,NEURAL PROCESSING MODULE WITH INPUT ARCHITECTURES THAT MAKE MAXIMAL USE OF A WEIGHTED SYNAPSE ARRAY,"A neural processing module (100) is disclosed which combines a weighted synapse array (200) that performs 'primitive arithmetic' (products and sums) in parallel with a weight change architecture and a data input architecture that collectively maximize the use of the weighted synapse array by providing it with signal permutations (310) as frequently as possible. The neural processing module may be used independently, or in combination with other modules in a planar or stacked arrangement.",G06N 3/063,IRVINE SENSORS CORPORATION,"CARSON, John, C.; SAUNDERS, Christ, H.","09/223,476 30.12.1998 US",JP-2000591490; EP-1999967712
WO2012047530,PCT/US2011/052722,22.09.2011,WO/2012/047530,12.04.2012,WO,PROVIDING ANSWERS TO QUESTIONS USING LOGICAL SYNTHESIS OF CANDIDATE ANSWERS,"A method, system and computer program product for generating answers to questions. In one embodiment, the method comprises receiving an input query, decomposing the input query into a plurality of different subqueries, and conducting a search in one or more data sources to identify at least one candidate answer to each of the subqueries. A ranking function is applied to each of the candidate answers to determine a ranking for each of these candidate answers; and for each of the subqueries, one of the candidate answers to the subquery is selected based on this ranking. A logical synthesis component is applied to synthesize a candidate answer for the input query from the selected the candidate answers to the subqueries. In one embodiment, the procedure applied by the logical synthesis component to synthesize the candidate answer for the input query is determined from the input query.",G06F 17/27,"INTERNATIONAL BUSINESS MACHINES CORPORATION; BROWN, Eric W.; CHU-CARROLL, Jennifer; FERRUCCI, David A.; LALLY, Adam P.; MURDOCK IV, James W.; PRAGER, John M.","BROWN, Eric W.; CHU-CARROLL, Jennifer; FERRUCCI, David A.; LALLY, Adam P.; MURDOCK IV, James W.; PRAGER, John M.","61/387,194 28.09.2010 US",EP-2011831208
WO2020043855,PCT/EP2019/073148,29.08.2019,WO/2020/043855,05.03.2020,WO,"PHOTOPLETHYSMOGRAPHY BASED DETECTION OF TRANSITIONS BETWEEN AWAKE, DROWSINESS, AND SLEEP PHASES OF A SUBJECT","A smart system comprising a contact or contactless PPG sensor to output a PPG signal; and an electronic processing system in communication with the PPG sensor to acquire the PPG signal therefrom and analyse the PPG signal in one or both of time and frequency domains to real-time predict transitions between awake and sleep phases of a subject based on an output of the analysis, either wearing the smart wearable system equipped with the contact PPG sensor or remotely monitored by the contactless PPG sensor.",A61B 5/024; A61B 5/18; A61B 5/00,SLEEP ADVICE TECHNOLOGIES S.R.L.,"GROPPO, Sara",18191543.0 29.08.2018 EP; 18191547.1 29.08.2018 EP; 19160639.1 04.03.2019 EP,
WO2002044994,PCT/US2001/045705,30.11.2001,WO/2002/044994,06.06.2002,WO,"SYSTEMS AND METHODS FOR DETECTION ASSAY ORDERING, DESIGN, PRODUCTION, INVENTORY, SALES AND ANALYSIS FOR USE WITH OR IN A PRODUCTION FACILITY","The present invention relates to detection assay development, production and optimization. In particular, the present invention provides systems and methods for acquiring and analyzing biological information. The present invention also provides detection assay production with improved oligonucleotide synthesis and processing systems. The present invention further provides systems that integrate biological information collection with detection assay production that allow for rapid development of commercial products, such as analyte specific reageants (AsRs) and in vitro diagnostics (IVDs).",G06F 19/00,"THIRD WAVE TECHNOLOGIES, INC.; BROWER, Amy; BROW, Mary, Ann; CRACAUER, Raymond, F.; FORS, Lance; GRANSKE, Rocky; DE ARRUDA INDIG, Monika; KURENSKY, David; LUEDTKE, Craig; LUKOWIAK, Andrew, A.; LYAMICHEV, Victor; NERI, Bruce, P.; REIMER, Ned, D.; ROEVEN, Robert, T., P.; SKRZYPCZYNSKI, Zbiginiev; ZIARNO, Witold, A.; COMERFORD, John; STUMP, Steven; VIEGUT, Daniel, D.","BROWER, Amy; BROW, Mary, Ann; CRACAUER, Raymond, F.; FORS, Lance; GRANSKE, Rocky; DE ARRUDA INDIG, Monika; KURENSKY, David; LUEDTKE, Craig; LUKOWIAK, Andrew, A.; LYAMICHEV, Victor; NERI, Bruce, P.; REIMER, Ned, D.; ROEVEN, Robert, T., P.; SKRZYPCZYNSKI, Zbiginiev; ZIARNO, Witold, A.; COMERFORD, John; STUMP, Steven; VIEGUT, Daniel, D.","60/250,112 30.11.2000 US; 60/250,449 30.11.2000 US; 09/771,332 26.01.2001 US; 09/782,702 13.02.2001 US; 60/285,895 23.04.2001 US; 60/288,229 02.05.2001 US; 60/289,764 09.05.2001 US; 60/304,521 11.07.2001 US; 60/307,660 25.07.2001 US; 09/915,063 25.07.2001 US; 60/308,878 31.07.2001 US; 60/311,582 10.08.2001 US; 09/930,535 15.08.2001 US; 09/930,688 15.08.2001 US; 09/930,646 15.08.2001 US; 09/930,543 15.08.2001 US; 60/326,549 02.10.2001 US; 60/238,312 10.10.2001 US; 60/329,113 12.10.2001 US; 60/328,861 12.10.2001 US; 10/054,023 13.11.2001 US; 09/929,135 14.08.2001 US; 60/360,489 19.10.2001 US; 10/002,251 26.10.2001 US; null 30.11.2001 US",EP-2001987217; JP-2002547086
EP223792216,17188194,28.08.2017,3349143,18.07.2018,EP,"NFORMATION PROCESSING DEVICE, INFORMATION PROCESSING METHOD, AND COMPUTER-READABLE MEDIUM","An information processing device according to an arrangement includes an acquirer, a setter, a specifier and a determiner. The acquirer is configured to acquire a peripheral image of a moving object. The setter is configured to set a cell in response to a plurality of traveling candidate lines of the moving object in a peripheral area of the moving object. The specifier is configured to specify a type of an object included in the cell using one or more partitioned areas smaller than the cell included in the peripheral image. The determiner is configured to determine whether or not the moving object can progress for the cell based on the type of the object.",G06K 9/00,TOSHIBA KK,SUGITA KAORU; WATANABE TOMOKI; ITO SATOSHI,2017002800 11.01.2017 JP,
EP245433682,18199276,09.10.2018,3502857,26.06.2019,EP,METHOD AND APPARATUS FOR PROCESSING IMAGE INTERACTION,,G06F 3/048; G06N 3/02; G06N 3/04,SAMSUNG ELECTRONICS CO LTD,SON MINJUNG; CHANG HYUN SUNG; SAGONG DONGHOON,20170175942 20.12.2017 KR,
WO2014000141,PCT/CN2012/077425,25.06.2012,WO/2014/000141,03.01.2014,WO,METHOD AND APPARATUS FOR PROVIDING TRANSPORTATION BASED RECOMMENDER SYSTEM,"An approach for recommending location-based content items that account for locations with ease of access based on available transportation options is described. A content recommender platform determines one or more predicted locations of a user based, at least in part, on an ease of access from a location associated with the use. The content recommender platform determines one or more location-based content items associated with the one or more predicted locations, the location, or a combination thereof. The content recommender platform determines one or more recommended content items from among the one or more location-based content items. In this way, the recommended content items may be easily accessible and may accord with the user's preferences.",G06F 17/30,"NOKIA CORPORATION; CAO, Huanhuan; TIAN, Jilei","CAO, Huanhuan; TIAN, Jilei",,US-14409567
WO2020048445,PCT/CN2019/104173,03.09.2019,WO/2020/048445,12.03.2020,WO,END-TO-END STRUCTURE-AWARE CONVOLUTIONAL NETWORKS FOR KNOWLEDGE BASE COMPLETION,"A method for knowledge base completion includes encoding a knowledge base comprising entities and relations between the entities into embeddings for the entities and embeddings for the relations. The embeddings for the entities are encoded based on a Graph Convolutional Network (GCN) with different weights for at least some different types of the relations, which GCN is called a Weighted GCN (WGCN). The method further includes decoding the embeddings by a convolutional network for relation prediction. The convolutional network is configured to apply one dimensional (1D) convolutional filters on the embeddings, which convolutional network is called Conv-TransE. The method further includes at least partially complete the knowledge base based on the relation prediction.",G06F 16/20; G06N 3/02,"BEIJING JINGDONG SHANGKE INFORMATION TECHNOLOGY CO., LTD.; JD.COM AMERICAN TECHNOLOGIES CORPORATION","SHANG, Chao; TANG, Yun; HUANG, Jing; HE, Xiaodong; ZHOU, Bowen","62/726,962 04.09.2018 US; 16/542,403 16.08.2019 US",
EP14745871,06124115,15.11.2006,1791082,30.05.2007,EP,Feature extraction using pixel cues and object cues,"Image processing for extracting features in images. Pixel-level cue algorithms can be performed on raster images. The raster images can be converted to a vector layer. Object-level cue algorithms can be performed on the vector layer. The feature can be detected using a result of the pixel-level cues and using a result of the object-level cue algorithms performed. A computer-readable medium can include a first data field containing data representing pixel-level cues functioning to describe a pixel-level cue of the feature. The computer-readable medium can also include a second data field containing data representing object-level cues functioning to describe the object-level cues of the feature. Relation-level cue algorithms can be performed on the vector layers. The features can be detected using a result of any combination of the pixel-level cue algorithms, object-level cue algorithms, and/or relation-level cue algorithms.",G06K 9/62; G06K 9/68; G06T 17/05,LEICA GEOSYSTEMS AG,KLOER BRIAN ROBERT,55923706 13.11.2006 US; 73965005 23.11.2005 US,
WO2020058356,PCT/EP2019/075059,18.09.2019,WO/2020/058356,26.03.2020,WO,ANTI-SPOOFING,"Anti-spoofing technology is provided for verifying a user of a fixed computer terminal. Image data of at least one verification image is received, as captured by an image capture device of the fixed computer terminal at a time corresponding to a request for access to a restricted function of the fixed computer terminal. User verification is applied to determine whether to grant access to the restricted function of the fixed computer terminal. A differential feature descriptor is determined, which encodes feature differences between the verification image data and image data of at least one unobstructed background image as captured by the image capture device. An anti-spoofing classifier processes the differential feature descriptor to classify it in relation to real and spoofing classes. Access to the restricted function of the fixed computer terminal is refused or granted based on the classification of the differential feature descriptor by the anti-spoofing classifier.",G06K 9/00,YOTI HOLDING LIMITED,"RODRIGUEZ, Francisco Angel Garcia; PAL, Ahmed Kazim; ABBOTT, John","16/134,845 18.09.2018 US",
WO2018057945,PCT/US2017/053039,22.09.2017,WO/2018/057945,29.03.2018,WO,"SYSTEMS, METHODS, AND COMPUTER READABLE MEDIA FOR VISUALIZATION OF SEMANTIC INFORMATION AND INFERENCE OF TEMPORAL SIGNALS INDICATING SALIENT ASSOCIATIONS BETWEEN LIFE SCIENCE ENTITIES","Disclosed systems, methods, and computer readable media can detect an association between semantic entities and generate semantic information between entities. For example, semantic entities and associated semantic collections present in knowledge bases can be identified. A time period can be determined and divided into time slices. For each time slice, word embeddings for the identified semantic entities can be generated; a first semantic association strength between a first semantic entity input and a second semantic entity input can be determined; and a second semantic association strength between the first semantic entity input and semantic entities associated with a semantic collection that is associated with the second semantic entity can be determined. An output can be provided based on the first and second semantic association strengths.",G06F 19/28,"NFERENCE, INC.","ARAVAMUDAN, Murali; SOUNDARARAJAN, Venkataramanan; RAJASEKHARAN, Ajit; ELLINA, Prashanth; PURANIK, Arjun; MURALI, Ashwin; GIBSON, William; GARCIA-RIVERA, Enrique; MURUGADOSS, Karthik","62/398,386 22.09.2016 US; 62/514,697 02.06.2017 US",JP-2019537751; KR-1020197011495; EP-2017780282; CN-201780071846.6
WO2017156791,PCT/CN2016/076808,18.03.2016,WO/2017/156791,21.09.2017,WO,METHOD AND APPARATUS FOR TRAINING A LEARNING MACHINE,"The disclosure relates to a method and apparatus for training a learning machine, wherein the apparatus includes : a broadcasting module for broadcasting an initial global model for a training cycle to a plurality of worker nodes; a receiving module for receiving a plurality of updated local models from the plurality of worker nodes， wherein each updated local model is generated by one of the plurality of worker nodes independently based on a data split assigned to the worker node and the initial global model for the training cycle; an aggregating module for aggregating the plurality of updated local models to obtain an aggregated model; and a generating module for generating an updated global model for the training cycle based at least on the aggregated model and historical information which is obtained from a preceding training cycle.",G06F 15/18,"MICROSOFT TECHNOLOGY LICENSING, LLC; CHEN, Kai; HUO, Qiang","CHEN, Kai; HUO, Qiang",,EP-2016893956; US-16078983
EP12637982,95100688,19.01.1995,0666534,09.08.1995,EP,Interactive rule based system.,"This invention presents a novel rule based system and method that interacts with a user to provide the user a series of interim results. The system has a set of one or more operations. Each of these operations in turn has a set of one or more choices, called a choice set, associated with an operation. Rule based intelligence is applied to the operations set and/or one or more operation choice set by a set of rules associated with its respective operation and/or choice set. When one or more rules in a rule set are applied to the operation set, an offered operation set is created which is a subset of the operation set. Only the operations in the offered operation set are offered to the user. When one or more rules in a rule set are applied to a choice set, an offered choice set is created which is a subset of the choice set. Only those operation choices in the offered choice set are offered to the user. The operations (operation choices) that are in the offered operation set (offered choice set) are those that conform to the constraints of the rules that are applied. The user selects operations (operation choices) from the offered operation set (offered choice set). Information about the user selections feeds back to the rules and is used to constrain the next offered operations and operation choices. The user is also permitted to change rules, rule specific metadata, and rule specific metadata algorithms as well as the data in the system. Interacting with the system this way, the user preference, knowledge, and judgment is incorporated in each of a series of interim results and is used to further develop the next interim result in the series of iterations. <IMAGE>   <IMAGE>",G06F 3/14; G06F 3/048; G06F 9/44; G06N 5/02; G06N 5/04,IBM,ROGOWITZ BERNICE ELLEN; RABENHORST DAVID ALEN; TREINISH LLOYD ALAN,19188294 03.02.1994 US,
WO2018217361,PCT/US2018/028972,24.04.2018,WO/2018/217361,29.11.2018,WO,MULTIFUNCTION VECTOR PROCESSOR CIRCUITS,"A processor circuit is provided that includes an input terminal and an output terminal, a plurality of vector processor operation circuits, a selector circuit coupled to the input terminal, the output terminal, and each of the vector processor operation circuits, and a scheduler circuit adapted to control the selector circuit to configure a vector processing pipeline comprising zero, one or more of the vector processor operation circuits in any order between the input terminal and the output terminal.",G06F 9/30; G06N 3/063,"MICROSOFT TECHNOLOGY LICENSING, LLC","FOWERS, Jeremy Halden; LIU, Ming Gang; OVTCHAROV, Kalin; REINHARDT, Steven Karl; CHUNG, Eric Sen","15/603,934 24.05.2017 US",CN-201880033692.6; EP-2018725703
WO2006032032,PCT/US2005/033206,15.09.2005,WO/2006/032032,23.03.2006,WO,SYSTEM AND METHOD FOR SYSTEMATICALLY ARRANGING A SET OF DISPLAY ELEMENTS IN ASSEMBLAGES TO MEANINGFULLY REPRESENT DATA,"A system, method and computer program for creating a software application specification, including arranging graphical elements to form assemblages including information displays for the graphical elements (137). The assemblages are classified along a layout type dimension, and a relationship metaphor dimension, are specified by attributes of a situation being studied, and are respectively associated so as to describe a behavior of the graphical elements, a software application specification (129) is generated based thereon. Further embodiments display graphical elements, corresponding to a feature set based on a matrix, a list, a collection, a curve, a timeflow, a sequence flow, a relationship, a map, a stack or a control and a feature set based on a situation of interest, a goal, a plan, a comparison, an evaluation, a conceptual aid, a qualifier, an action, an alert or an alarm, in a consistent manner to represent information in a form useful for decision-making or problem-solving.",G06F 15/00,"SCHINDLER ASSOCIATES, INC. doing business as VISUAL I/0; SCHINDLER, Mark, Byron; SHEN-HSIEH, Angela, Barbara; LISTFIELD, Scott","SCHINDLER, Mark, Byron; SHEN-HSIEH, Angela, Barbara; LISTFIELD, Scott","60/609,824 15.09.2004 US; 60/617,194 12.10.2004 US",CA-2580267; EP-2005797696
WO2018055228,PCT/FI2016/050649,20.09.2016,WO/2018/055228,29.03.2018,WO,METHOD AND APPARATUS FOR SYNCHRONIZING IMPEDANCE CARDIOGRAPHY WITH ELECTROCARDIOGRAPHY TO LOWER PATIENT AUXILLARY CURRENT,"An approach is provided for synchronizing an impedance cardiography (""ICG"") measurement period with an electrocardiography (""ECG"") signal to reduce patient (105) auxiliary current. The approach involves measuring an ECG signal of a patient via an ECG device (103). The approach also involves processing the ECG signal to cause, at least in part, a detection of one or more ECG features of the signal. The approach further involves synchronizing a start, a stop, or a combination thereof of a measurement of an ICG signal of the patient via an ICG device (101) based, at least in part, on the detection of the one or more ECG features. The measurement of the ICG signal includes injecting an electrical current into the patient (105) for a duration of the measurement.",A61B 5/053; A61B 5/0295; A61B 5/0402; A61B 5/0452; A61B 5/04; A61B 5/00,NOKIA TECHNOLOGIES OY,"BLOMQVIST, Kim; HONKALA, Mikko; LINDHOLM, Harri",,CN-201680090936.5; EP-2016916714
WO2016134341,PCT/US2016/018821,20.02.2016,WO/2016/134341,25.08.2016,WO,MODELING OF SOIL COMPACTION AND STRUCTURAL CAPACITY FOR FIELD TRAFFICABILITY BY AGRICULTURAL EQUIPMENT FROM DIAGNOSIS AND PREDICTION OF SOIL AND WEATHER CONDITIONS ASSOCIATED WITH USER-PROVIDED FEEDBACK,"A framework for diagnosing and predicting a suitability of soil conditions to various agricultural operations is performed in a combined, multi-part approach for simulating relationships between predictive data and observable outcomes. The framework includes analyzing one or more factors relevant to field trafficability, workability, and suitability for agricultural operations due to the effects of freezing and thawing cycles, and developing artificial intelligence systems to learn relationships between datasets to produce improved indications of trafficability, workability, and forecasts of suitability windows for a particular user, user community, farm, farm group, field, or equipment. The framework also includes a real-time feedback mechanism by which a user can validate or correct these indications and forecasts. The framework may further be configured to override one or more of the soil state assessments to ensure that indicators and forecasts are consistent with the recently-provided feedback.",A01G 7/00; G06Q 10/06; G01N 33/00,"ITERIS, INC.","MEWES, John; SALENTINY, Dustin","62/118,615 20.02.2015 US; 15/049,044 20.02.2016 US; 15/049,045 20.02.2016 US; 15/049,047 20.02.2016 US",
WO2006047253,PCT/US2005/037825,21.10.2005,WO/2006/047253,04.05.2006,WO,OBJECT RECOGNIZER AND DETECTOR FOR TWO-DIMENSIONAL IMAGES USING BAYESIAN NETWORK BASED CLASSIFIER,"A system and method for determining a classifier to discriminate between two classes­object or non-object. The classifier may be used by an object detection program to detect presence of a 3D object in a 2D image (e.g., a photograph or an X-ray image). The overall classifier is constructed of a sequence of classifiers (or 'sub-classifiers'), where each such classifier is based on a ratio of two graphical probability models (e.g., Bayesian networks). A discrete-valued variable representation at each node in a Bayesian network by a two-stage process of tree-structured vector quantization is discussed. The overall classifier may be part of an object detector program that is trained to automatically detect many different types of 3D objects (e.g., human faces, airplanes, cars, etc.). Computationally efficient statistical methods to evaluate overall classifiers are disclosed. The Bayesian network-based classifier may also be used to determine if two observations (e.g., two images) belong to the same category. For example, in case of face recognition, the classifier may determine whether two photographs are of the same person. A method to provide lighting correction or adjustment to compensate for differences in various lighting conditions of input images is disclosed as well. As per the rules governing abstracts, the content of this abstract should not be used to construe the claims in this application.",G06K 9/00,"CARNEGIE MELLON UNIVERSITY; SCHNEIDERMAN, Henry","SCHNEIDERMAN, Henry","10/971,868 22.10.2004 US",
WO2008018064,PCT/IL2007/000980,07.08.2007,WO/2008/018064,14.02.2008,WO,DATA SIMILARITY AND IMPORTANCE USING LOCAL AND GLOBAL EVIDENCE SCORES,"A method includes finding regions of a reference signal which provide at least one of: local evidence scores and a global evidence score. The local evidence scores indicate local similarity of the regions of the reference signal to regions of a query signal and the global evidence score defines the extent of a global similarity of the query signal to the reference signal. A media exploring device is also included which includes an importance encoder and a media explorer. The importance encoder generates importance scores of at least portions of digital media as a function of at least one of local evidence scores and global evidence scores. The media explorer enables exploring through the digital media according to (i) the importance scores, (ii) data associations/links induced by the evidence scores between different portions of the digital media. The device may also include a media player to play the digital media with adaptive speeds as a function of the importance scores. The device may also include a labeling/annotation module which inherits labels/annotations/markings according to the abovementioned data associations.",G06F 7/00; G06F 17/00,"YEDA RESEARCH AND DEVELOPMENT CO. LTD.; BOIMAN, Oren; IRANI, Michal","BOIMAN, Oren; IRANI, Michal","60/835,895 07.08.2006 US",EP-2007790035; IL-196944; US-12376787
WO2019006365,PCT/US2018/040395,29.06.2018,WO/2019/006365,03.01.2019,WO,AUDIENCE-BASED OPTIMIZATION OF COMMUNICATION MEDIA,"Introduced here are communication optimization platforms configured to improve comprehension, persuasion, or clarity of communications. Initially, a communication optimization platform can acquire input sample(s) that are associated with a source audience. The communication optimization platform can then create a linguistic profile for the source audience by examining the content of the input sample(s). Additionally or alternatively, the communication optimization platform may produce a psychographic profile that specifies various characteristics of the source audience, such as personality, opinions, attitudes, interests, etc. The communication optimization platform can then generate, based on the linguistic profile and/or the psychographic profile, affinity language for communicating with a target audience. By incorporating the affinity language into communications, the communication optimization platform can increase appeal to the target audience.",G06F 17/27,"PEPPEL, Tyler","PEPPEL, Tyler","62/526,866 29.06.2017 US; 16/022,300 28.06.2018 US",
WO2015077398,PCT/US2014/066513,20.11.2014,WO/2015/077398,28.05.2015,WO,ADAPTIVE VIRTUAL INTELLIGENT AGENT,"Embodiments of an adaptive virtual intelligent agent (""AVIA"") service are disclosed. It may include the functions of a human administrative assistant for an enterprise including customer support, customer relationship management, and fielding incoming caller inquiries. It also has multi-modal applications for the home through interaction with AVIA implemented in the home. It may engage in free-form natural language dialogs. During a dialog, embodiments maintain the context and meaning of the ongoing dialog and provides information and services as needed by the domain of the application. Over time, the service automatically extends its knowledge of the domain (as represented in the Knowledge Tree Graphs) through interaction with external resources. Embodiments can intelligently understand and converse with users using free-form speech without pre-programmed deterministic sequences of questions and answers, can dynamically determine what it needs to know to converse meaningfully with users, and knows how to obtain information it needs.",G10L 15/00,"LONDON, Justin","LONDON, Justin","61/906,839 20.11.2013 US; 62/026,023 17.07.2014 US; 14/546,097 18.11.2014 US",
WO2019055661,PCT/US2018/050893,13.09.2018,WO/2019/055661,21.03.2019,WO,PREECLAMPSIA BIOMARKERS AND RELATED SYSTEMS AND METHODS,"Disclosed herein are methods, kits, tests, and systems for detecting, predicting, monitoring, or ruling out preeclampsia in pregnant women. Also provided herein are novel diagnostic markers, methods of data analysis, assay formats, and kits employing such markers to improve one or more characteristics of a test for identifying or ruling out preeclampsia based on biomarkers from patient samples.",G01N 33/68,"PROGENITY, INC.","COOPER, Matthew; SINGH, Sharat; COPELAND, Karen A. F.; HESTERBERG, Lyndal; MAZLOOM, Amin R.; ABBASI, Mohammad; DEL MASTRO, Richard Giulio","62/558,184 13.09.2017 US",
WO2019240989,PCT/US2019/035386,04.06.2019,WO/2019/240989,19.12.2019,WO,SYSTEM AND METHOD FOR MANAGING TRAFFIC FLOW OF UNMANNED VEHICLES,"The present invention is directed to systems and methods for managing traffic one or more unmanned vehicles. A traffic flow managing system can include: a plurality of unmanned vehicle, each of the plurality of the unmanned vehicle comprising: a processor having executable instructions stored in a non-transitory computer-readable storage medium; and one or more sensors in communication with the processor, wherein the processor is configured to: detect any other unmanned vehicles approaching the unmanned vehicle within a predetermined distance via one or more sensors, communicate with any other unmanned vehicles to create a buffer zone around the unmanned vehicle to avoid entering the buffer zone of any other unmanned vehicles, and determine a route of the unmanned vehicle to a mission destination based on a signal received by the one or more sensors of the unmanned vehicle.",B60W 30/08; B60W 30/09; G05D 1/02; G08G 1/0965; G08G 1/16; H04W 4/46,"WALMART APOLLO, LLC","CANTRELL, Robert; HIGH, Donald R.; O'BRIEN, John J.; SIMON, John; MCHALE, Brian","62/685,548 15.06.2018 US",
EP221780213,17190423,11.09.2017,3336775,20.06.2018,EP,METHOD AND APPARATUS FOR PERFORMING RECOGNITION USING RECURRENT MODEL AND TRAINING RECURRENT MODEL,"A recognition method includes extracting target data corresponding to a current window and padding data subsequent to the target data from sequence data; acquiring a state parameter corresponding to a previous window; and calculating a recognition result for the current window based on the state parameter, the extracted target data, and the extracted padding data using a recurrent model.",G06N 3/04; G06N 3/08; G10L 15/16,SAMSUNG ELECTRONICS CO LTD,YOO SANG HYUN,20160170198 14.12.2016 KR,
EP30910544,11166481,18.05.2011,2390822,30.11.2011,EP,System and method for efficient interpretation of images in terms of objects and their parts,"The present application is a method and system of interpreting an image by finding a configuration of multiple variables which optimizes an objective function with a factorizable upper bound, by applying an iterative algorithm that relies on efficient dynamic ordering of candidate configurations, in a priority queue, in a descending order of an upper bound score. As an example, consider a constellation model for an object. It specifies the appearance models f or individual parts of objects, as well as spatial relations among these parts. These are combined into a single function whose value represents the likeness of the object in an image. To find the configuration in which the object is present in the image, we maximize this function over all candidate configurations. The purpose of the iterative algorithm mentioned above is to find such optimal configurations efficiently.",G06K 9/62,PALO ALTO RES CT INC,SARKAR PRATEEK; BART EVGENIY,78885210 27.05.2010 US,
WO2016202613,PCT/EP2016/062697,03.06.2016,WO/2016/202613,22.12.2016,WO,"POWERED, MULTI-FUNCTIONAL LIMB MOVEMENT AUXILIARY DEVICE, PARTICULARLY PROSTHESIS AND MOVEMENT-ASSISTING ORTHOSIS, WITH COMBINED ESTIMATION REGIMES","A method of operating a multi-functional limb movement auxiliary device comprising a plurality of actuators configured to move, upon activation, limb movement auxiliary device members in at least two independent degrees of freedom, a bio-signal sensing unit that is configured to acquire bio-signals indicative of motor activity, a control unit configured to receive and evaluate the acquired bio-signals, and a multi-functional limb movement auxiliary device including a control unit configured for carrying out such method.",A61F 2/58; A61B 5/0488; A61F 2/72; A61F 5/01; A61F 2/54; A61F 2/60; A61F 2/70; A61F 2/76; A61F 2/80,GEORG-AUGUST-UNIVERSITÄT GÖTTINGEN STIFTUNG ÖFFENTLICHEN RECHTS; OTTO BOCK HEALTHCARE GMBH,"GRAIMANN, Bernhard; AMSÜSS, Sebastian; FARINA, Dario",15173019.9 19.06.2015 EP,CA-2987704; US-15737635
WO2001019170,PCT/EP2000/009028,15.09.2000,WO/2001/019170,22.03.2001,WO,AN ARRANGEMENT FOR AUTOMATICALLY MILKING ANIMALS,"An apparatus for milking animals is proposed which enables the presence of discontinuous or transitory elements in the milk, such as flocculent masses, or streaks of blood or slime indicating mastitis or other udder disorders to be detected. This is achieved with a monitoring arrangement (3) including two optical sensors disposed in spaced relation along a conduit and each including an optical emitter (33) and detector (34) facing one another across the conduit (2). The arrangement further includes a monitoring unit (32) coupled to the detectors of the sensors with means (35) for determining the difference between the detector signals. By determining the difference signal, the monitoring arrangement (3) is effectively self-calibrating. Any variation in the state of the conduit, for example due to the gradual build-up of deposits or roughening or discolouring of the surface, will be cancelled out by the difference function.",A01J 5/01; G01N 21/31; G01N 33/04,"DELAVAL  HOLDING AB; EDERSTÅL, Gunnar; ERIKSSON, Jan; SJÖBLOM, Krister","EDERSTÅL, Gunnar; ERIKSSON, Jan; SJÖBLOM, Krister",9903284-9 15.09.1999 SE,
WO1991009375,PCT/US1989/005580,11.12.1989,WO/1991/009375,27.06.1991,WO,"INTEGRATED VEHICLE POSITIONING AND NAVIGATION SYSTEM, APPARATUS AND METHOD","A system (400) for positioning and navigating an autonomous vehicle (310) allows the vehicle (310) to travel between locations. Position information (432) is derived from global positioning system satellites (200, 202, 204, and 206) or other sources (624) when the satellites (200, 202, 204, and 206) are not in the view of the vehicle (310). Navigation of the vehicle (310) is obtained using the position information (432), route information (414), obstacle detection and avoidance data (416), and on board vehicle data (908 and 910).",B60K 31/00; B60K 31/04; G01C 21/16; G01S 1/00; G01S 5/00; G01S 5/14; G01S 17/93; G05D 1/02; G08G 1/0968; G08G 1/127,"CATERPILLAR INC.; GUDAT, Adam, J.; BRADBURY, Walter, J.; CHRISTENSEN, Dana, A.; CLOW, Richard, G.; DEVIER, Lonnie, J.; KEMNER, Carl, A.; KLEIMENHAGEN, Karl, W.; KOEHRSEN, Craig, L.; KYRTSOS, Christos, T.; LAY, Norman, K.; PETERSON, Joel, L.; RAO, PRITHVI, N.; SCHMIDT, Larry, E.; SENNOTT, James, W.; SHAFFER, Gary, K.; SHI, WenFan; SHIN, Dong, Hun; SINGH, Sanjiv, J.; STAFFORD, Darrell, E.; WEINBECK, Louis, J.; WEST, Jay, H.; WHITTAKER, William, L.; WU, BaoXin","GUDAT, Adam, J.; BRADBURY, Walter, J.; CHRISTENSEN, Dana, A.; CLOW, Richard, G.; DEVIER, Lonnie, J.; KEMNER, Carl, A.; KLEIMENHAGEN, Karl, W.; KOEHRSEN, Craig, L.; KYRTSOS, Christos, T.; LAY, Norman, K.; PETERSON, Joel, L.; RAO, PRITHVI, N.; SCHMIDT, Larry, E.; SENNOTT, James, W.; SHAFFER, Gary, K.; SHI, WenFan; SHIN, Dong, Hun; SINGH, Sanjiv, J.; STAFFORD, Darrell, E.; WEINBECK, Louis, J.; WEST, Jay, H.; WHITTAKER, William, L.; WU, BaoXin",,
WO2019053188,PCT/EP2018/074875,14.09.2018,WO/2019/053188,21.03.2019,WO,"METHOD FOR MODIFYING A STYLE OF AN AUDIO OBJECT, AND CORRESPONDING ELECTRONIC DEVICE, COMPUTER READABLE PROGRAM PRODUCTS AND COMPUTER READABLE STORAGE MEDIUM","Method for modifying a style of an audio object, and corresponding electronic device, computer readable program products and computer readable storage medium The disclosure relates to a method for processing an input audio signal. According to an embodiment, the method includes obtaining a base audio signal being a copy of the input audio signal and generating an output audio signal from the base signal, the output audio signal having style features obtained by modifying the base signal so that a distance between base style features representative of a style of the base signal and a reference style feature decreases. The disclosure also relates to corresponding electronic device, computer readable program product and computer readable storage medium.",G10L 21/003; G10L 25/30; G10L 25/48; G10L 21/013,INTERDIGITAL CE PATENT HOLDINGS,"DUONG, Quang Khanh Ngoc; OZEROV, Alexey; PEREZ, Patrick; GRINSTEIN, Eric",17306202.7 18.09.2017 EP,
WO2017100377,PCT/US2016/065465,07.12.2016,WO/2017/100377,15.06.2017,WO,MICROBIAL STRAIN IMPROVEMENT BY A HTP GENOMIC ENGINEERING PLATFORM,"The present disclosure provides a HTP microbial genomic engineering platform that is computationally driven and integrates molecular biology, automation, and advanced machine learning protocols. This integrative platform utilizes a suite of HTP molecular tool sets to create HTP genetic design libraries, which are derived from, inter alia, scientific insight and iterative pattern recognition. The HTP genomic engineering platform described herein is microbial strain host agnostic and therefore can be implemented across taxa. Furthermore, the disclosed platform can be implemented to modulate or improve any microbial host parameter of interest.",G06F 19/22; G06F 19/28; C12N 15/10,ZYMERGEN INC.,"SERBER, Zach; DEAN, Erik Jedediah; MANCHESTER, Shawn; GORA, Katherine; FLASHMAN, Michael; SHELLMAN, Erin; KIMBALL, Aaron; SZYJKA, Shawn; FREWEN, Barbara; TREYNOR, Thomas; BRUNO, Kenneth S.","62/264,232 07.12.2015 US; 15/140,296 27.04.2016 US; 62/368,786 29.07.2016 US",CA-3007840; JP-2017558440; EP-2016873805; KR-1020177036283; KR-1020197021794
WO2019236334,PCT/US2019/034124,28.05.2019,WO/2019/236334,12.12.2019,WO,OBJECT RECOGNITION USING DEPTH AND MULTI-SPECTRAL CAMERA,A camera is configured to output a test depth+multi-spectral image including a plurality of pixels. Each pixel corresponds to one of the plurality of sensors of a sensor array of the camera and includes at least a depth value and a spectral value for each spectral light sub-band of a plurality of spectral illuminators of the camera. An object recognition machine is previously trained with a set of labeled training depth+multi-spectral images having a same structure as the test depth+multi-spectral image. The object recognition machine is configured to output a confidence value indicating a likelihood that the test depth+multi-spectral image includes a specified object.,G06K 9/00; G06K 9/20; G06K 9/46; G06K 9/62; H04N 5/33,"MICROSOFT TECHNOLOGY LICENSING, LLC","AHMED, Abdelrehim; ORTIZ EGEA, Sergio; FENTON, Michael Scott","16/004,072 08.06.2018 US",
WO2009128998,PCT/US2009/036649,10.03.2009,WO/2009/128998,22.10.2009,WO,METHOD FOR SORTING A PLURALITY OF GROWTH-INDUCED SEEDS FOR COMMERCIAL USE,"A method and system for producing a group of growth-induced seeds for commercial use or sale, the method including monitoring a physiological indication and/or morphometric indication for a seed, automatically determining if the monitored seed has a specific characteristic, separating the monitored seed having the specific characteristic into a group of seeds for commercial use or sale so that each and every seed in the group has been monitored and determined to have the specific characteristic.",A01C 1/00; G06T 7/60,"BALL HORTICULTURAL COMPANY; CONRAD, Robert, Scott","CONRAD, Robert, Scott","12/106,029 18.04.2008 US",EP-2009732902
WO2019221850,PCT/US2019/026932,11.04.2019,WO/2019/221850,21.11.2019,WO,BUILDING MANAGEMENT AUTONOMOUS HVAC CONTROL USING REINFORCEMENT LEARNING WITH OCCUPANT FEEDBACK,"A building management system includes one or more processors, and one or more computer-readable storage media communicably coupled to the one or more processors and having instructions stored thereon that cause the one or more processors to: define a state of a zone or space within a building; control an HVAC system to adjust a temperature of the zone or space corresponding to a first action; receive utterance data from a voice assist device located in the zone or space; analyze the utterance data to identify a sentiment relating to the temperature of the zone or space; calculate a reward based on the state, the first action, and the sentiment; determine a second action to adjust the temperature of the zone or space based on the reward; and control the HVAC system to adjust the temperature of the zone or space corresponding to the second action.",G05B 15/02; G05B 13/02; F24F 11/30; F24F 11/62; F24F 120/20,JOHNSON CONTROLS TECHNOLOGY COMPANY,"RAMAMURTI, Viswanath; LEE, Young M.; PARK, Youngchoon; MURUGESAN, Sugumar","15/980,547 15.05.2018 US",
EP11086457,08290535,10.06.2008,2133829,16.12.2009,EP,Simulation of complex systems,"The invention provides a software architecture for generating and self-assembling multi-scale computer models of dynamic systems, in a way that mimics (bottom-up) morphogenesis in living organisms, but with the addition of (top-down) constraints that result in efficient model generation. Once generated, the model can be used for simulations within the same software architecture. Exemplary applications include the generation of models for the simulation of: human cells / organs; non-living physical artefacts; business processes; urban environments; nanotech structures. Non-modelling applications for the architecture are also envisaged, including: data mining applications; decision making; e-learning/training and self-programming agents.  The architecture itself comprises a collection of nested physical objects (""FUs"") and a related, parallel collection of nested agents (""PSUs"") that can act on the physical objects.",G06N 7/06,INTEGRATIVE BIOCOMPUTING S A R,SIREGAR PRIDI,08290535 10.06.2008 EP,
EP13453162,99305623,15.07.1999,1069000,17.01.2001,EP,Method for identifying the presence and orientation of an object in a vehicle,"A method for determining the location of an object in a passenger compartment of a vehicle in which ultrasonic waves are transmitted from a first transducer into the passenger compartment, waves reflected off an object in the passenger compartment are received by the first transducer and a first distance from the first transducer to the object is calculated based on the time difference between the transmitted waves and reflected waves when received by the first transducer. Further, different ultrasonic waves are transmitted from a second transducer into the passenger compartment which then receives reflected waves off the object and a second distance from the second transducer to the object is calculated based on the time difference between the transmitted waves and reflected waves when received by the second transducer. The approximate location of the object in the passenger compartment is determined based on the first distance and the second distance.  <IMAGE>",B60R 21/00; B60R 21/01; B60R 21/015; G01S 15/04; G01S 15/42; G01S 15/88; G06K 9/00,AUTOMOTIVE TECH INT,VARGA ANDREW J; BREED DAVID S; DUVALL WILBUR E,99305623 15.07.1999 EP; 79802997 06.02.1997 US; 91982397 28.08.1997 US,
EP232159442,18168754,23.04.2018,3392878,24.10.2018,EP,VOICE RECOGNITION APPARATUS AND VOICE RECOGNITION METHOD,"Disclosed is a voice recognition apparatus including: an audio input unit configured to receive a voice; a communication module configured to transmit voice data received from the audio input unit to a server system, which performs voice recognition processing, and receive recognition result data on the voice data from the server system; and a controller configured to control the audio input unit and the communication module, wherein, when a voice command in the voice data corresponds to a pre-stored keyword command, the controller performs control to perform an operation corresponding to the keyword command, and wherein when the voice command in the voice data does not correspond to the pre-stored keyword command, the controller performs control to transmit the voice data including the voice command to the server system. Accordingly, voice recognition may be performed efficiently.",G10L 15/22; G10L 15/26,LG ELECTRONICS INC,LIM SUHEE; PARK JOONGEON; PARK YEONHO; LYU SUKYOUNG,20170051835 21.04.2017 KR,
WO2020001868,PCT/EP2019/063233,22.05.2019,WO/2020/001868,02.01.2020,WO,OBJECT REPRESENTATION AND CLASSIFICATION BASED ON VEHICLE SENSOR DETECTIONS,"A method for representing an object using vehicle sensor (110) data. The method comprising, for each cycle in a plurality of cycles; obtaining (S1) detections related to the object (150, 60), the detections comprising detection coordinates, the object being associated with a heading (Vg1, Vg2), transforming (S2) the detections into a representation coordinate system, the representation coordinate system having an orientation determined based on the heading (Vg1, Vg2), aggregating (S4) transformed detection coordinates with transformed detection coordinates from previous cycles, and representing (S5) the object by the aggregated detections.",G01S 13/89; G01S 13/93; G01S 7/41; G01S 13/42; G01S 13/72,VEONEER SWEDEN AB,"SCHNEIDER, Robert",18180318.0 28.06.2018 EP,
EP14304750,03732879,05.06.2003,1520409,06.04.2005,EP,TRICK PLAY FOR AUDIO/VIDEO/DATA STREAMS WITH CONDITIONAL ACCESS,A method for trick-mode play of an encrypted transport stream containing audio/video/data information comprising: extracting and decrypting data used as local metadata for programs in the encrypted transport stream; creating trick-mode pointers from the metadata; and storing the trick-mode pointers and the encrypted transport stream on a storage medium.,H04N 5/76; H04N 21/434; G11B 20/10; H04J 3/00; H04N 5/783; H04N 5/91; H04N 5/913; H04N 7/167; H04N 7/24; H04N 7/26; H04N 9/804; H04N 21/432; H04N 21/4402; H04N 21/84; H04N 21/845,ENTROPIC COMMUNICATIONS INC,CAVALLERANO ALAN P; SHEN RICHARD CHI-TE,0302552 05.06.2003 IB; 18377902 27.06.2002 US,
WO2014198315,PCT/EP2013/062230,13.06.2013,WO/2014/198315,18.12.2014,WO,IMAGE BASED OBJECT CLASSIFICATION,"A method for classifying an object in image data to one out of a set of classes using a classifier, said image data comprising an image of the object, each class indicating a property common to a group of objects, the method comprising the steps of obtaining said classifier used to estimate for an input feature vector a probability for each of the set of classes, one probability indicating whether the input feature vector belongs to one class; extracting a feature vector from said image data; using the obtained classifier to estimate the probabilities for the extracted feature vector; and evaluating the estimated probabilities for determining whether the object does not belong to any one of the set of classes based using a quality indicator.",G06K 9/62; G06T 7/00,SICPA HOLDING SA,"HEUSCH, Guillaume; PICAN, Nicolas",,US-14897916; EP-2013731313
WO2020055156,PCT/KR2019/011818,11.09.2019,WO/2020/055156,19.03.2020,WO,SYSTEM AND METHOD FOR A SCENE BUILDER,"A system and method for creating organized intent clusters or scenes using machine learning algorithms is provided. A method of creating organized intent clusters or scenes comprises extracting intent features related to the plurality of request inputs. The method also includes creating a plurality of groups comprising the extracted intent features. The method includes identifying a cluster based on co-occurring extracted intent features, the co-occurring extracted intent features belonging to a plurality of domains. The method further includes generating a proto-scene based in part by ranking the extracted intent features within the cluster.",G06F 16/35; G06F 16/33; G06F 16/335; G06F 17/27; G06N 20/00,"SAMSUNG ELECTRONICS CO., LTD.","SCHWADE, Allan J; YADAV, Anil; LOBO, Melvin","62/730,487 12.09.2018 US; 16/566,459 10.09.2019 US",
WO2019099593,PCT/US2018/061154,14.11.2018,WO/2019/099593,23.05.2019,WO,SYSTEMS AND METHODS FOR TRANSLATING USER SIGNALS INTO A VIRTUAL ENVIRONMENT HAVING A VISUALLY PERCEPTIBLE COMPETITIVE LANDSCAPE,"Techniques for efficiently translating user signals that are received in association with an online auction to render a virtual environment that has a visually perceptible competitive landscape. Various participants' acquisition interest levels are determined by analyzing the participants' user activity in association with the online auction. Avatars that represent the participants are rendered differently based on the participants' level of interest in (e.g., motivation toward) acquiring the item that is being auctioned. In this way, the individual participants' avatars are rendered in the virtual environment in a manner such that the individual participants' level of interest in acquiring the item is visually perceptible. As a specific example, avatars may be rendered to appear more (or less) excited about the item as their corresponding user activity indicates that they are more (or less) likely to competitively bid on the item in a genuine attempt to win the online auction.",G06Q 30/08; G06Q 30/06; G06T 19/00; G06K 9/00,EBAY INC.,"YANKOVICH, Steve; TIMONEN, Josh","62/588,189 17.11.2017 US; 16/189,849 13.11.2018 US",
WO2019201141,PCT/CN2019/082188,11.04.2019,WO/2019/201141,24.10.2019,WO,METHODS AND SYSTEMS FOR IMAGE PROCESSING,A method and system for image processing are provided in the present disclosure. The method may include obtaining a first image including an object in a first representation. The method may also include determining at least one first position of the object in the first image. The method may further include generating a second image by adjusting the first image based on the at least one first position and a second representation with respect to the object. The second image may include the object in the second representation.,G06K 9/32; G06T 3/00; G06N 3/04,"BEIJING DIDI INFINITY TECHNOLOGY AND DEVELOPMENT CO., LTD.","DU, Xiaogang",201810349840.7 18.04.2018 CN; 201810374653.4 24.04.2018 CN,CN-201980000845.1
WO2018057888,PCT/US2017/052956,22.09.2017,WO/2018/057888,29.03.2018,WO,"INTEGRATED SYSTEMS AND METHODS FOR AUTOMATED PROCESSING AND ANALYSIS OF BIOLOGICAL SAMPLES, CLINICAL INFORMATION PROCESSING AND CLINICAL TRIAL MATCHING","The present disclosure provides a method for qualifying a subject for a subset of therapies. The medical history data and biologic data may be received for the subject wherein the biologic data is generated from one or more biological samples of the subject. Then, the medical history data and the biologic data may be computer analyzed to yield a genomic-based medical history analysis for the subject. The genomic-based medical history analysis may be used for the subject to query one or more databases of therapies for the subject, to generate the subset of therapies for which the subject qualifies. The subset of therapies may be provided on a user interface on an electronic device of a user.",G06F 19/12; G06F 19/24; G06F 19/28; G06F 19/20,"DRIVER, INC.","MATSUGUCHI, Tetsuya; CAULIN, Aleah, Fox; ST.JOHN, John, Alden; BOLEY, Nathan; SOI, Sameer; NUNLEY, Elizabeth; GUSHUE, Timothy; AHMED, Erin, Caitlin; PAZARENTZOS, Evangelos; POLKINGHORN, William; GIANNIKOPOULOS, Petros","62/399,221 23.09.2016 US; 62/480,307 31.03.2017 US",
WO2017123821,PCT/US2017/013270,12.01.2017,WO/2017/123821,20.07.2017,WO,METHOD AND PLUGGABLE SYSTEM FOR TREND-BASED ALLOCATION OF MEDIA ASSETS BETWEEN GLOBAL AND LOCAL STORAGE,"A method, apparatus, article of manufacture, and a memory structure for allocating storage of media programs among global and local storage assets for hot and cold storage is disclosed. Trend data is obtained from a plurality of sources including web page click-throughs and social media, indexed and combined with data describing available media programs to identify media programs of interest and reallocate them to hot storage as required. The system uses REST-compliant methods and commands and is therefore pluggable and can be used with a variety of existing systems.",G06F 17/30,FOX BROADCASTING COMPANY,"PERRINE, Dean; BLANDY, Christopher D.; COFFARO, Joseph P.","62/277,852 12.01.2016 US; 15/042,066 11.02.2016 US",
EP137966059,15153432,16.09.2009,2890149,01.07.2015,EP,"Systems and methods for video/multimedia rendering, composition, and user-interactivity","An interactive video/multimedia application (IVM application) may specify one or more media assets for playback. The IVM application may define the rendering, composition, and interactivity of one or more the assets, such as video. Video multimedia application data (IVMA data may) be used to define the behavior of the IVM application. The IVMA data may be embodied as a standalone file in a text or binary, compressed format. Alternatively, the IVMA data may be embedded within other media content. A video asset used in the IVM application may include embedded, content-aware metadata that is tightly coupled to the asset. The IVM application may reference the content-aware metadata embedded within the asset to define the rendering and composition of application display elements and user-interactivity features. The interactive video/multimedia application (defined by the video and multimedia application data) may be presented to a viewer in a player application.",H04N 21/8543; G06F 3/0481; G06T 5/50; G06T 11/60; H04L 12/801; H04N 5/45; H04N 19/115; H04N 19/167; H04N 19/61; H04N 21/234; H04N 21/2343; H04N 21/44; H04N 21/4402; H04N 21/472; H04N 21/4722; H04N 21/4725; H04N 21/4728; H04N 21/8545,INTEL CORP,KALVA HARI; PURI ATUL,09815150 16.09.2009 EP; 19213608 16.09.2008 US,
WO2017166098,PCT/CN2016/077815,30.03.2016,WO/2017/166098,05.10.2017,WO,A METHOD AND A SYSTEM FOR DETECTING AN OBJECT IN A VIDEO,"The disclosure relates to a method and a system for detecting an object in a video, the method comprises: acquiring a video; generating bounding boxes for the objects; determining, an object class and a detection confidence score corresponding to the object class, resulting in a detection information set; modifying the detection information set by suppressing the detection confidence score corresponding to an object class having a detection confidence score below a first threshold; tracking the object class, resulting in a first tubelet; replacing the tubelet bounding box by a bounding box overlapping the tubelet bounding box, resulting in a second tubelet; adjusting the detection information set by re-scoring the detection confidence score corresponding to the object class in the second tubelet; combining the modified detection information set and the adjusted detection information set; and locating the object in the frames.",G06K 9/00,"BEIJING SENSETIME TECHNOLOGY DEVELOPMENT CO., LTD","WANG, Xiaogang; KANG, Kai; LI, Hongsheng; YAN, Junjie; OUYANG, Wanli",,
WO2012047557,PCT/US2011/053049,23.09.2011,WO/2012/047557,12.04.2012,WO,EVIDENCE DIFFUSION AMONG CANDIDATE ANSWERS DURING QUESTION ANSWERING,"Diffusing evidence among candidate answers during question answering may identify a relationship between a first candidate answer and a second candidate answer, wherein the candidate answers are generated by a question-answering computer process, the candidate answers have associated supporting evidence, and the candidate answers have associated confidence scores. All or some of the evidence may be transferred from the first candidate answer to the second candidate answer based on the identified relationship. A new confidence score may be computed for the second candidate answer based on the transferred evidence.",G10L 15/18,"INTERNATIONAL BUSINESS MACHINES CORPORATION; FERRUCCI, David, A.; GONDEK, David, C.; KALYANPUR, Aditya, A.; LALLY, Adam, P.","FERRUCCI, David, A.; GONDEK, David, C.; KALYANPUR, Aditya, A.; LALLY, Adam, P.","61/387,203 28.09.2010 US",EP-2011831228
WO2018119220,PCT/US2017/067878,21.12.2017,WO/2018/119220,28.06.2018,WO,METHOD TO DESIGN TEMPORAL PATTERNS OF NERVOUS SYSTEM STIMULATION,"The present invention relates to methods that enable one to design temporal patterns for the optimal stimulation of a nervous system, one or more nerve cells, or nervous tissue. In one embodiment, the present invention relates to methods to design improved stimulation patterns and/or genetic algorithms for the optimal stimulation of a nervous system, one or more nerve cells, or nervous tissue. In one embodiment, the present invention utilizes a model-based design to achieve a more optimal stimulation pattern for use in connection with a nervous system, one or more nerve cells, or nervous tissue (e.g., a human nervous system). In another embodiment, the model-based design of the present invention utilizes a systematic search method to identify parameters (e.g., design variables) that minimize a cost function (e.g., optimize the fitness of a particular design). In one instance, the system and method of the present invention is demonstrated via optimal temporal patterns of electrical stimulation for a nervous system, one or more nerve cells, or nervous tissue.",A61N 1/00; A61N 1/32; A61N 1/36; G06F 19/12,DUKE UNIVERSITY,"GRILL, Warren M.; BROCKER, David T.; KENT, Alexander R.","62/437,356 21.12.2016 US",EP-2017883046
WO2019137959,PCT/EP2019/050451,09.01.2019,WO/2019/137959,18.07.2019,WO,AUTONOMOUS VEHICLES AND METHODS OF USING SAME,"An autonomous vehicle and methods of using same is disclosed. The vehicle includes one or more sensors (102, 103, 104, 105, 106) arranged on at least one of a dashboard (110), a roof (112), and a center console of the vehicle, or one or more image capturing devices (6) for capturing one or more images from a left side and a right side of the vehicle. The vehicle may also include an electronic control unit (ECU) (220) configured to communicate with the one or more sensors (102, 103, 104, 105, 106) or the one or more image capturing devices (6), and at least one of a morphing surface (236), a windshield display, and one or more displays (1, 2, 3, 4, 5, 900) configured to be controlled by the ECU (220).",B60K 37/02; G06K 9/00; B60N 3/10; B60R 11/00; B60R 13/00; B65D 81/107,MOTHERSON INNOVATIONS COMPANY LTD.,"WIECZOREK, Romeo; LANGBEIN, Reinhold; KOLLER, Matthias; ZHAO, Yijun; NUGRAHA, Thomas Agung; CARETTA, Gianluca; JAEGER, David-Kenneth; RÖTZER, Ilka; HERRMANN, Andreas; PATEL, Mukesh; DORMANNS, Jan; WEINGÄRTNER, Torsten; BUCHET, Yann; LIESENER, Alf; GÖTTLICHER, Stefanie","62/615,249 09.01.2018 US",
WO2019140075,PCT/US2019/013027,10.01.2019,WO/2019/140075,18.07.2019,WO,CODE-SWITCHING OF BLENDED MULTILINGUAL CONTENT,An electronic platform to generate and display blended multilingual content. The methods and systems can be employed in an educational environment to assist a user fluent in a native language in learning a target language. One or more blended combinations of content in the native language and the target language are generated and displayed to the user. A machine learning component can be used to evaluate performance data to execute adjusts to the level and type of blending applied to the blended combinations to increase and improve learning efficiency.,G06F 17/21; G06F 17/27; G06F 17/28; G09B 19/06,"TRANSCENDENT INTERNATIONAL, LLC.","TAN, William Z.","62/615,739 10.01.2018 US",
WO2019234175,PCT/EP2019/064826,06.06.2019,WO/2019/234175,12.12.2019,WO,IMAGE SEGMENTATION,"In one aspect, hierarchical image segmentation is applied to an image formed of a plurality of pixels, by classifying the pixels according to a hierarchical classification scheme, in which at least some of those pixels are classified by a parent level classifier in relation to a set of parent classes, each of which is associated with a subset of child classes, and each of those pixels is also classified by at least one child level classifier in relation to one of the subsets of child classes, wherein each of the parent classes corresponds to a category of visible structure, and each of the subset of child classes associated with it corresponds to a different type of visible structure within that category.",G06K 9/00; G06K 9/62; G06K 9/46; G06N 3/04; G06N 3/08,FIVE AI LIMITED,"REDFORD, John; SAMANGOOEI, Sina",1809345.0 07.06.2018 GB,
WO2018182293,PCT/KR2018/003605,27.03.2018,WO/2018/182293,04.10.2018,WO,METHOD FOR OPERATING SPEECH RECOGNITION SERVICE AND ELECTRONIC DEVICE SUPPORTING THE SAME,"An electronic device includes a communication module, a sensor module, a microphone, a memory, a display, and a processor. The processor is configured to determine whether a user is in proximity to the electronic device, to transmit at least one of voice input information or information on the proximity of the user to the external device, to receive at least one action associated with the execution of the function of the electronic device corresponding to a recognition result from the external device, based on voice input recognition of the external device, to output content associated with execution and/or processing of each of the at least one action, when the user is spaced apart from the electronic device, and to prevent at least a portion of the at least one content from being output in a state that the user is within the specified proximity to the electronic device.",G10L 15/22; G06F 3/16; G10L 15/18; G10L 15/30; G06F 3/01; G06F 1/32,"SAMSUNG ELECTRONICS CO., LTD.","SEO, Jang Seok; KANG, Sang Ki; KU, Han Jun; PARK, Sung Pa; RHEE, In Jong; YI, Ji Soo; HONG, Yoo Jin; KIM, Kyung Tae; KIM, Ji Hyun; JEON, Yong Joon",10-2017-0039590 28.03.2017 KR,EP-2018777326
WO2018032354,PCT/CN2016/095512,16.08.2016,WO/2018/032354,22.02.2018,WO,METHOD AND APPARATUS FOR ZERO-SHOT LEARNING,"Embodiments of the present disclosure provide a method, apparatus and computer program product for ZSL. The method comprises: constructing a dictionary model based on visual features and semantic features of multimedia content of seen classes, the semantic features corresponding to the visual features; reconstructing visual features of multimedia content of unseen classes using the dictionary model and semantic features of multimedia content of unseen classes; and determining a class of a testing sample based on comparison of a visual feature of the testing sample and reconstructed visual features.",G06K 9/66; G06K 9/62; G06K 9/46,"NOKIA TECHNOLOGIES OY; NOKIA TECHNOLOGIES (BEIJING) CO., LTD.","YU, Yunlong",,EP-2016913114; CN-201680088517.8
WO2017060850,PCT/IB2016/055992,06.10.2016,WO/2017/060850,13.04.2017,WO,SYSTEM AND METHODS OF AN EXPENSE MANAGEMENT SYSTEM BASED UPON BUSINESS DOCUMENT ANALYSIS,"The disclosure herein relates to business content analysis. In particular, the disclosure relates to systems and methods of an expense management system operable to perform automatic business documents' content analysis for generating business reports associated with automated value added tax (VAT) reclaim, Travel and Expenses (T&E) management, Import / Export management and the like. The system is further operable to provide various organizational expense management aspects for the corporate finance department and the business traveler based upon stored data. Additionally, the system is configured to use a content recognition engine, configured as an enhanced OCR mechanism used for extracting tagged text from invoice images and also provides continuous learning mechanism in a structured mode allowing classification of invoice images by type, providing continual process of improvement and betterment throughout.",G06Q 30/04; G06F 15/18; G06F 17/30,WAY2VAT LTD.,"SIMANTOV, Amos; SHILKROT, Roy; YAAR, Arnon","62/238,148 07.10.2015 US",EP-2016853178; US-15544008
WO2015153835,PCT/US2015/023992,02.04.2015,WO/2015/153835,08.10.2015,WO,SYSTEMS AND METHODS FOR THE DETECTION OF IMPLICIT GESTURES,Some embodiments provide systems and methods for enabling a learning implicit gesture control system for use by an occupant of a vehicle. The method includes identifying features received from a plurality of sensors and comparing the features to antecedent knowledge stored in memory. A system output action that corresponds to the features can then be provided in the form of a first vehicle output. The method further includes detecting a second vehicle output from the plurality of sensors and updating the antecedent knowledge to associate the system output action with the second vehicle output.,G06F 3/01; B60K 35/00; B60K 37/06; G06F 3/038; G06K 9/00,"HONDA MOTOR CO., LTD; EL DOKOR, Tarek, A.; KING, Joshua; CLUSTER, Jordan; HOLMES, James, E.; YAMAMOTO, Stuart","EL DOKOR, Tarek, A.; KING, Joshua; CLUSTER, Jordan; HOLMES, James, E.; YAMAMOTO, Stuart","14/244,790 03.04.2014 US; 62/063,340 13.10.2014 US; 14/490,591 18.09.2014 US",EP-2015716684
WO1998035314,PCT/US1998/002400,11.02.1998,WO/1998/035314,13.08.1998,WO,SYSTEM AND METHOD FOR PATTERN RECOGNITION,"System and method for pattern recognition. The method includes a method for generating a classifier from a set of collected sample patterns. The sample patterns are representative of data to be processed by the classifier and are converted to electronic signals to be manipulated by a programmed computer. Further, the method generates and identifies a number of transformers that map between sample patterns of the same pattern-type in the collected sample patterns. The method uses the transformers and the sample patterns to generate additional patterns. The method forms a table that contains the generated patterns and an indication of the pattern-type to which each pattern belongs. The classifier is used for recognizing patterns. First, a digital image of one or more physical items is generated. Features are extracted from the digital image and a numerical representation of each feature is generated. The numerical representation is used as a reference to look into a look-up table to determine candidate patterns wherein the look-up table was generated by using the technique described above. A candidate pattern is selected using selected validation modules that determine the pattern-type of the pattern.",G06K 9/20; G06K 9/62,"SILICON BIOLOGY, INC.","ANDERHOLM, Eric, J.","08/798,938 11.02.1997 US",
WO2016142689,PCT/GB2016/050619,07.03.2016,WO/2016/142689,15.09.2016,WO,TISSUE ANALYSIS BY MASS SPECTROMETRY OR ION MOBILITY SPECTROMETRY,"A method of analysis using mass and/or ion mobility spectrometry or ion mobility spectrometry is disclosed comprising: using a first device to generate aerosol, smoke or vapour from one or more regions of a first target of biological material; and mass and/or ion mobility analysing and/or ion mobility analysing said aerosol, smoke, or vapour, or ions derived therefrom so as to obtain first spectrometric data. The method may use an ambient ionisation method.",G01N 33/68; H01J 49/00; A61B 18/00,MICROMASS UK LIMITED,"PRINGLE, Steven Derek; KARANCSI, Tamás; JONES, Emrys; MORRIS, Michael Raymond; BALOG, Júlia; LANGRIDGE, James Ian; TAKÁTS, Zoltán; BOLT, Frances; GÖDÖRHÁZY, Lajos; SZALAY, Dániel; SIMON, Dániel; RICHARDSON, Keith",1503876.3 06.03.2015 GB; 1503864.9 06.03.2015 GB; 1503877.1 06.03.2015 GB; 1503867.2 06.03.2015 GB; 1503863.1 06.03.2015 GB; 1503878.9 06.03.2015 GB; 1516003.9 09.09.2015 GB; 1518369.2 16.10.2015 GB; 1503879.7 06.03.2015 GB,GB-1715767.8; US-15555998; CA-2978042; EP-2016710790
WO2007044037,PCT/US2005/044656,09.12.2005,WO/2007/044037,19.04.2007,WO,ROBUST PERCEPTUAL COLOR IDENTIFICATION,"Systems and methods for robust perceptual color identification are disclosed. The methods include a multilevel analysis (120) for determining the robust perceptual color of an object based on observed colors. This multilevel analysis can include a pixel level (120), a frame level (145), and/or a sequence level (150). The determination may make use of color drift matrices (130) and trained functions such as statistical probability functions (160). The color drift tables and function training are based on training data generated by observing objects of known robust perceptual color in a variety of circumstances. Embodiments of the invention are applicable to the identification and tracking of objects, for example, in a surveillance video system (100).",G06K 9/00; G06K 9/62,"PROXIMEX CORPORATION; GOH, King-Shy; CHANG, Edward; WANG, Yuan-fang","GOH, King-Shy; CHANG, Edward; WANG, Yuan-fang","11/229,091 16.09.2005 US",DE-null; EP-05826633; EP-5826633
WO2018171531,PCT/CN2018/079348,16.03.2018,WO/2018/171531,27.09.2018,WO,SYSTEM AND METHOD FOR PREDICTING CLASSIFICATION FOR OBJECT,"System and method for predicting a classification for an object are disclosed. Data relating to a first set of objects may be obtained. The first set of objects may include a plurality of first objects (1010, 1030) and a plurality of second objects (1020, 1040). A predicted label may be determined for each of the first set of objects. An initial label transformation matrix (1065) with respect to the first set of objects may be determined. One or more subsets (1050) of second objects (1020, 1040) may be obtained. One or more combined subsets (1060) of objects may be generated. A classification prediction model (1070) and an updated label transformation matrix (1080) associated with each of the one or more combined subsets (1060) of objects may be determined. A classification for at least one of the plurality of second objects (1020, 1040) may be predicted.",G06K 9/62,"BEIJING DIDI INFINITY TECHNOLOGY AND DEVELOPMENT CO., LTD.","QIN, Zhiwei; ZHUO, Chengxiang; TAN, Wei",201710179031.1 23.03.2017 CN,CN-201880020197.1
WO2008157843,PCT/US2008/067949,23.06.2008,WO/2008/157843,24.12.2008,WO,"SYSTEM AND METHOD FOR THE DETECTION, CHARACTERIZATION, VISUALIZATION AND CLASSIFICATION OF OBJECTS IN IMAGE DATA","A system and method for the detection, characterization, visualization and classification of objects in image data is provided. The present invention utilizes principles of iterative transformational divergence and signature mapping, in which objects in images, when subjected to special transformations, will exhibit radically different responses based on the physical, chemical, or numerical properties of the object or its representation (such as images), combined with machine learning capabilities. Using the system and methods of the present invention, certain objects that appear indistinguishable from other objects to the eye or computer recognition systems, or are otherwise almost identical, generate radically different and statistically significant differences in the image describers (metrics) that can be easily measured.",G06K 9/46; G06K 9/66,"GUARDIAN TECHNOLOGIES INTERNATIONAL INC.; RAMSAY, Thomas, E.; RAMSAY, Eugene, B.; FELTEAU, Gerard; KRIPOROTOV, Victor, F.; ANDRUSHCHENKO, Oleksandr","RAMSAY, Thomas, E.; RAMSAY, Eugene, B.; FELTEAU, Gerard; KRIPOROTOV, Victor, F.; ANDRUSHCHENKO, Oleksandr","60/929,313 21.06.2007 US; 12/014,028 14.01.2008 US; 12/014,034 14.01.2008 US; 12/014,043 14.01.2008 US; 12/010,298 23.01.2008 US; 61/057,486 30.05.2008 US",
EP219398198,17177468,22.06.2017,3327628,30.05.2018,EP,METHOD AND APPARATUS FOR RECOGNIZING AN OBJECT,"A method includes actuating a processor to apply an input image to a feature extractor including a plurality of layers, determine a third feature vector based on first feature vectors of an input image output by a first layer included in a feature extractor and second feature vectors of the input image output by a second layer in the feature extractor, and identify an object in the input image based on the third feature vector.",G06K 9/46; G06K 9/32; G06K 9/62,SAMSUNG ELECTRONICS CO LTD,CHANG HYUN SUNG; SAGONG DONGHOON; SON MINJUNG; JUNG KYUNGBOO; SUNG YOUNG HUN,20160159536 28.11.2016 KR,
WO2009140473,PCT/US2009/043918,14.05.2009,WO/2009/140473,19.11.2009,WO,SYSTEM AND METHOD FOR PROVIDING ANSWERS TO QUESTIONS,"A system, method and computer program product (or providing answers to questions based on any corpus of data The method facilitates generating a number of candidate passages from the corpus that answer an input query, and finds the correct resulting answer by collecting supporting evidence from the multiple passages By analyzing all retrieved passages and that passage's metadata in parallel, there is generated an output plurality of data structures including candidate answers based upon the analyzing All candidate answers are automatically scored causing the supporting passages by a plurality of scoring modules, each producing a module score The modules scores are processed to determine one or more query answers, and, a query response is generated for delivery to a user based on the one or more query answers",G06F 17/30,"INTERNATIONAL BUSINESS MACHINES CORPORATION; BROWN, Eric, W.; FERRUCCI, David; LALLY, Adam; ZADROZNY, Wlodek, W.","BROWN, Eric, W.; FERRUCCI, David; LALLY, Adam; ZADROZNY, Wlodek, W.","12/152,411 14.05.2008 US",EP-2009747555
WO2019112326,PCT/KR2018/015355,06.12.2018,WO/2019/112326,13.06.2019,WO,SECURITY ENHANCEMENT METHOD AND ELECTRONIC DEVICE THEREFOR,"An electronic device and method that are robust against attacks on encryption-related vulnerabilities as detection of an encryption algorithm based on if artificial intelligence technology is enabled are provided. A security enhancement method includes a hooking loading of an executable code into a memory, inputting the executable code into an encryption code identification model that is based on an artificial neural network, determining, by the encryption code identification model, whether the loading of the executable code into the memory is allowed, and when the loading of the executable code is not allowed, blocking the loading of the executable code into the memory.",G06F 21/55; G06F 21/57; G06F 21/60; G06N 99/00,"SAMSUNG ELECTRONICS CO., LTD.","SEO, Jaewoo",10-2017-0167588 07.12.2017 KR,EP-2018886351
WO2008011029,PCT/US2007/016203,17.07.2007,WO/2008/011029,24.01.2008,WO,METHOD AND SYSTEM FOR CREATING A CONCEPT-OBJECT DATABASE,"Embodiments of the present invention are directed to acquiring information from the worldwide web, organizing information acquired from the worldwide web, and using the acquired and organized information to facilitate web-page searching, web-page browsing, and other worldwide-web-based activities. In one embodiment of the present invention, a database of concept objects is created from an initial set of semantic objects and from hyperlink information obtained from web pages by one or more web crawlers. The initial set of semantic objects is processed using hyperlink based objects created by the web crawler. The processed semantic objects are then associated with additional hyperlink-based objects to create a concept-object database. In certain embodiments of the present invention, the concept-object database can be further refined and supplemented in an automated fashion by additional web crawling, subsequent association of hyperlink-based objects with concept objects, and creation of new concept objects as well as by user input to, and editing of, the concept-object database. The concept-object database may be employed, in various embodiments of the present invention, to facilitate web browsing, web-page searching, and other orldwide-web-base activities.",G06F 7/00; G06F 17/00,"VULCAN, INC.; GREAVES, Mark, Thomas; HALL, Stephen, G.; JACOB, Arun, T.; ALLEN, Paul, G.","GREAVES, Mark, Thomas; HALL, Stephen, G.; JACOB, Arun, T.; ALLEN, Paul, G.","11/489,243 18.07.2006 US",
WO2007076455,PCT/US2006/062519,21.12.2006,WO/2007/076455,05.07.2007,WO,WEB PAGE OPTIMIZATION SYSTEMS,"This invention relates to providing a system for improved web page generation and display. More particularly this invention relates to providing a system for dynamically creating web pages on demand, which are can be indexed by Internet-based search engine indexing programs, from contents stored in one or more databases. Further, index rankings created from the dynamically created pages are optimized using random, but contextiially appropriate text replacement, within the web page URL link references and web-page content, and source code ordering.",G06F 15/16,"TOPPENBERG, Larry, W.; HACKNEY, Roger, A.; WILSON, Craig, J.; FLATBUSH, Steve","TOPPENBERG, Larry, W.; HACKNEY, Roger, A.; WILSON, Craig, J.; FLATBUSH, Steve","60/753,667 22.12.2005 US; 60/783,673 17.03.2006 US; 60/800,236 12.05.2006 US; 11/614,020 20.12.2006 US",DE-null
WO2018051307,PCT/IB2017/055644,19.09.2017,WO/2018/051307,22.03.2018,WO,"FRAMEWORKS AND METHODOLOGIES CONFIGURED TO ENABLE SUPPORT AND DELIVERY OF A MULTIMEDIA MESSAGING INTERFACE, INCLUDING AUTOMATED CONTENT GENERATION AND CLASSIFICATION, CONTENT SEARCH AND PRIORITISATION, AND DATA ANALYTICS","The present invention relates to frameworks and methodologies configured to enable support and delivery of a multimedia messaging interface, including (but not limited to) automated content generation and classification, content search and prioritisation, and data analytics. Some embodiments relate to frameworks and methodologies configured to enable generation of and management of content items, which are optionally made available via a messaging interface, via media artefact identification (for example based on contextual data, audio, text and/or object recognition). Examples include technology that enables automated generation and categorisation of sub-clips from one or more media source files. Other embodiments relate to content promotion functionalities for a content library driven video/animation messaging framework, multi-dimensional search and display of animated content made available via a messaging interface, including filtered delivery of clip segments to a messaging interface based on conversation genre determination, and content ordering based on utilisation and non-utilisation analytics in a content library driven video/animation messaging framework.",G06F 17/00; G11B 27/00,PROCKOPEE HOLDINGS PTE LTD,"COLLINS, Daniel Patrick",2016903755 19.09.2016 AU; 2016903757 19.09.2016 AU; 2016903759 19.09.2016 AU; 2016903761 19.09.2016 AU; 2016903762 19.09.2016 AU; 2016903768 19.09.2016 AU; 2016903984 30.09.2016 AU,
EP249989422,17855579,01.09.2017,3522060,07.08.2019,EP,"APPLICATION DEVELOPMENT ENVIRONMENT PROVISION SYSTEM, APPLICATION DEVELOPMENT ENVIRONMENT PROVISION METHOD, COMPUTER-READABLE NON-TRANSITORY MEDIUM, AND TERMINAL DEVICE","An application development environment provision system that provides development environments for application programs via a network and comprises a management unit that: if first information that identifies a device node used by the application program is specified by an instruction from a tenant using the development environment, associates the specified first information and second information relating to the tenant that specified the first information; and performs management processing that restricts or permits use of the device node.",G06F 21/60; G06F 9/44; G06F 9/445; G06Q 50/10,YOKOGAWA ELECTRIC CORP,TANIGUCHI KOICHI,2016193560 30.09.2016 JP; 2017031659 01.09.2017 JP,
WO2016183229,PCT/US2016/031908,11.05.2016,WO/2016/183229,17.11.2016,WO,UNIVERSAL TASK INDEPENDENT SIMULATION AND CONTROL PLATFORM FOR GENERATING CONTROLLED ACTIONS USING NUANCED ARTIFICIAL INTELLIGENCE,"A system and method providing improved computations of input knowledge data within a computer environment and managing the creation, storage, and use of atomic knowledge data developed from the input knowledge data that includes nuanced cognitive data related to the input knowledge data and enhancing the operations of the computer system by improving decision processing therein by using nuanced cognitive data storage and decision processing and then generating a controlled action output based thereon.",G06N 5/00,"OLSHER, Daniel Joseph","OLSHER, Daniel Joseph","62/159,800 11.05.2015 US",EP-2016793467; US-15573308
EP14018772,03008805,23.04.2003,1361522,12.11.2003,EP,A system for automatically annotating training data for a natural language understanding system,"The present invention uses a natural language understanding system that is currently being trained to assist in annotating training data for training that natural language understanding system. Unannotated training data is provided to the system and the system proposes annotations to the training data. The user is offered an opportunity to confirm or correct the proposed annotations, and the system is trained with the corrected or verified annotations. <IMAGE>",G06F 3/16; G06F 17/24; G06F 17/27; G06F 17/28,MICROSOFT CORP,ACERO ALEJANDRO; WANG YE-YI; WONG LEON,14262302 10.05.2002 US,
EP290834683,19185859,11.07.2019,3623761,18.03.2020,EP,LOCALIZATION METHOD AND APPARATUS OF DISPLAYING VIRTUAL OBJECT IN AUGMENTED REALITY,"Disclosed is a localization method and apparatus that may acquire localization information of a device, generate a first image that includes a directional characteristic corresponding to an object included in an input image, generate a second image in which the object is projected based on the localization information, to map data corresponding to a location of the object, and adjust the localization information based on visual alignment between the first image and the second image.",G01C 21/30; G01C 25/00; G06K 9/00,SAMSUNG ELECTRONICS CO LTD,CHANG HYUN SUNG; SON MINJUNG,20180108252 11.09.2018 KR,
WO2008036960,PCT/US2007/079257,22.09.2007,WO/2008/036960,27.03.2008,WO,CONTENT DISCOVERY AND PEER-TO-PEER COLLABORATION,"A system and method for indexing content. The system includes a crawler, a crawl database, an indexer, a classification application, and an indexed data server. The crawler is configured to crawl the internet for content objects. The crawl database is coupled to the crawler and configured to cache the content objects. The indexer is coupled to the crawl database and configured to perform feature extraction on the content objects and cluster the content objects by generating an object vector. The classification application is coupled to the indexer and configured to cluster the object vectors and generate a summary vector. The indexed data server is coupled to the indexer and configured to communicate the content objects with a client.",G06F 17/00,"LEAPTAG INC.; OZVEREN, Cuneyt; KIRAZCI, Ulas","OZVEREN, Cuneyt; KIRAZCI, Ulas","60/846,788 22.09.2006 US; 11/859,514 21.09.2007 US; 11/859,478 21.09.2007 US; 11/859,467 21.09.2007 US; 11/859,504 21.09.2007 US; 11/859,457 21.09.2007 US; 11/859,496 21.09.2007 US; 11/859,446 21.09.2007 US",
WO2017087847,PCT/US2016/062854,18.11.2016,WO/2017/087847,26.05.2017,WO,MULTIPLEX IMMUNOHISTOCHEMISTRY IMAGE CYTOMETRY,"Immunohistochemical (IHC) techniques that enable the sequential evaluation of at least seven biomarkers in one formalin-fixed paraffin-embedded (FFPE) tissue section are disclosed. The methods involve high-throughput multiplexed, quantitative IHC imaging, sequential IHC with iterative labeling, digital scanning, image coregistration and merging, and subsequent stripping of sections.",G01N 33/53; G01N 33/554; G01N 33/535; G01N 33/543; G01N 33/483,"OREGON HEALTH & SCIENCE UNIVERSITY; TSUJIKAWA, Takahiro; KUMAR, Sushil; BORKAR, Rohan; COUSSENS, Lisa, M.; AZIMI, Vahid; SRINIVASA, Ganapati","TSUJIKAWA, Takahiro; KUMAR, Sushil; BORKAR, Rohan; COUSSENS, Lisa, M.; AZIMI, Vahid; SRINIVASA, Ganapati","62/257,926 20.11.2015 US; 62/368,818 29.07.2016 US",
WO2016112337,PCT/US2016/012725,08.01.2016,WO/2016/112337,14.07.2016,WO,BLOOD BASED BIOMARKERS FOR DIAGNOSING ATHEROSCLEROTIC CORONARY ARTERY DISEASE,"The invention, in some aspects, relates to methods for evaluating a human subject for having atherosclerotic coronary artery disease (ASCAD) or as having a coronary atherosclerotic plaque. In some aspects, the invention relates to methods and kits useful for diagnosing, classifying, profiling and treating atherosclerotic CAD and or a coronary atherosclerotic plaque.",A61B 5/00; G01N 33/48; G01N 33/53,"GLOBAL GENOMICS GROUP, LLC","VOROS, Szilard; BROWN, Bradley O.; MARVASTY, Idean B.","62/101,445 09.01.2015 US",CA-2973116; IL-253179; MX-MX/a/2017/008904; SG-11201705444Q; KR-1020177022311
WO2019209743,PCT/US2019/028564,22.04.2019,WO/2019/209743,31.10.2019,WO,HISTOLOGY-GRADE THREE-DIMENSIONAL IMAGING OF TISSUE USING MICROSCOPY WITH ULTRAVIOLET SURFACE EXCITATION,"The disclosed embodiments relate to a system that performs a three-dimensional (3D) imaging operation on a sample of biological material. During operation, the system obtains the sample of biological material, and performs a sequence of sectioning operations on the sample to successively remove sections of the sample. While the sequence of sectioning operations is taking place, the system performs an imaging operation on an exposed block face of the sample after each sectioning operation using microscopy with ultraviolet surface excitation (MUSE) surface-weighted imaging. Finally, the system assembles images produced by the block-face imaging operations into a three-dimensional dataset for viewing and analysis.",G01N 1/06; G01N 1/30; G01N 1/31; G01N 21/64; G01N 33/52; G02B 21/26; G02B 21/36; G02B 21/02; G02B 21/06; G02B 21/16,THE REGENTS OF THE UNIVERSITY OF CALIFORNIA,"LEVENSON, Richard M.; FEREIDOUNI, Farzad","62/662,578 25.04.2018 US",
WO2018125848,PCT/US2017/068351,22.12.2017,WO/2018/125848,05.07.2018,WO,ROUTE GENERATION USING HIGH DEFINITION MAPS FOR AUTONOMOUS VEHICLES,"A system generates a high definition map for an autonomous vehicle to travel from a source location to a destination location. The system determines a low resolution route and receives high definition map data for a set of geographical regions overlaying the low resolution route. The system uses lane elements within the geographical regions to form a set of potential partial routes. The system calculates the error between the potential partial route and the low resolution route and removes potential partial routes with errors above the threshold. Once completed, the system selects a final route and sends signals to the controls of the autonomous vehicle to follow the final route. The system determines whether surface areas adjacent to a lane that are not part of the road are safe for the vehicle to drive in case of emergency. The system stores information describing navigable surface areas with representations of lanes.",G05D 1/00; G05D 3/00,DEEPMAP CAYMAN LIMITED,"WHEELER, Mark, Damon","62/441,078 30.12.2016 US",CN-201780087295.2
WO2013090451,PCT/US2012/069286,12.12.2012,WO/2013/090451,20.06.2013,WO,COMPUTER-IMPLEMENTED SIMULATED INTELLIGENCE CAPABILITIES BY NEUROANATOMICALLY-BASED SYSTEM ARCHITECTURE,"Computer-implemented systems for simulated intelligence information processing comprising: a digital processing device comprising an operating system configured to perform executable instructions and a memory; a computer program including instructions executable by the digital processing device to create a hierarchical software architecture comprising: a software module for providing a functional interpretation of the prosencephalon, or parts thereof; a software module for providing a functional interpretation of the mesencephalon, or parts thereof; and a software module for providing a functional interpretation of the rhombencephalon, or parts thereof; wherein the software architecture simulates vertebrate, mammalian, primate, or human neuroanatomy. In some embodiments, the systems create simulated intelligence.",G06N 3/02,"SIMIGENCE, INC.","SOLARI, Soren, V.","61/570,040 13.12.2011 US",
EP13961888,03250358,21.01.2003,1335301,13.08.2003,EP,Context-aware linear time tokenizer,"A context automaton such as a left context automaton predefined and a right context automaton generate a context record that is combined with pattern knowledge stored in a token automaton to segment an input data stream into tokens. The resulting context-aware tokenizer can be used in many natural language processing application including text-to-speech synthesizers and text processors. The tokenizer is robust in that upon failure to match any explicitly stored token pattern a default token is recognized. Token matching follows a left-to-right longest-match strategy. The overall process operates in linear time, allowing for fast context-dependent tokenization in practice. <IMAGE>",G06F 17/27; G06F 17/28,MATSUSHITA ELECTRIC IND CO LTD,WALTHER MARKUS,7193402 07.02.2002 US,
WO2004088574,PCT/GB2004/001466,02.04.2004,WO/2004/088574,14.10.2004,WO,"METHOD OF, AND COMPUTER SOFTWARE FOR, CLASSIFICATION OF CELLS INTO SUBPOPULATIONS","A method of classifying cells into subpopulations using cell classifying data is described. The method comprises receiving and analyzing image data to identify object areas in the image data to determine, for at least one selected first cell, one or more measurements. A first parameter set is derived from the measurements for the first cell, the first parameter set comprising at least one of said one or more measurements. The first set of cells are classified into subpopulations, and identified to produce first identifying data. Cell classifying data for use in classifying a second set of cells into subpopulations is derived from the first parameter set and the first identifying data. A second set of cells is classified into subpopulations on the basis of one or more measurements taken for cells in the second set of cells, by use of the cell classifying data. The parameter sets of cells may be represented as vectors in an n-dimensional space.",G01N 15/14; G01N 21/64; G06K 9/00,"AMERSHAM BIOSCIENCES UK LIMITED; ARINI, Nicholas; GOODYER, Ian, David; MURPHY, Samantha; ROQUEMORE, Elizabeth; ZALTSMAN, Alla; ALEXANDROV, Yuriy; DAGENAIS, Louis; SOLTYS, Bohdan; CYBUCH, Jurek","ARINI, Nicholas; GOODYER, Ian, David; MURPHY, Samantha; ROQUEMORE, Elizabeth; ZALTSMAN, Alla; ALEXANDROV, Yuriy; DAGENAIS, Louis; SOLTYS, Bohdan; CYBUCH, Jurek",0307684.1 02.04.2003 GB; 0327651.6 28.11.2003 GB,EP-2004725411
EP107040457,13155069,13.02.2013,2767275,20.08.2014,EP,"Nortriptyline, haloperidol or prochlorperazine edisylate for use in the treatment of tuberculosis as well as two screening methods","The present invention relates to a compound capable of killing mycobacteria by activating host cellular mechanisms for use in treating tuberculosis, wherein the compound is selected from the group consisting of nortriptyline, haloperidol and prochlorperazine edisylate (PE). Furthermore, the present invention relates to a pharmaceutical composition comprising the compound of the invention, and optionally a pharmaceutically acceptable carrier. The invention further relates to a method of treating tuberculosis as well as a method of identifying a lead compound for the treatment of tuberculosis.",A61K 31/135; A61K 31/4515; A61K 31/5415; A61P 31/06; G01N 33/569,MAX PLANCK GES ZUR FÖRDERUNG DER WISSENSCHAFTEN E V,SUNDARAMURTHY VARADHARAJAN; BARSACCHI RICO; ZERIAL MARINO; BICKLE MARC; KALAITZIDIS IOANNIS; SAMUSIK NIKOLAY,13155069 13.02.2013 EP,
WO2019020002,PCT/CN2018/096789,24.07.2018,WO/2019/020002,31.01.2019,WO,METHODS AND SYSTEMS FOR PREVENTING USER CHURN,"Methods and systems are provided for preventing user churn. The method may include retrieving historical data associated with a first plurality of users. The method may also include, for each user of the first plurality of users, determining a first feature vector of the user based on the historical data associated with the user, and determining a churn probability of the user by inputting the first feature vector of the user into a prediction model. The method may further include, for each user of the first plurality of users, assigning, based on the determined churn probability of the user, the user to one of a plurality of predetermined groups, each of which is associated with a user retention strategy. The method may also include, for each user of the first plurality of users, determining a user retention operation for the user based on the user retention strategy associated with the predetermined group that the user is assigned to, and performing the user retention operation on the user.",G06F 17/30,"BEIJING DIDI INFINITY TECHNOLOGY AND DEVELOPMENT CO., LTD.","QI, Licai; WANG, Hengzhi",201710608121.8 24.07.2017 CN,
EP238117490,18161854,14.03.2018,3447681,27.02.2019,EP,SEPARATION OF OBJECTS IN IMAGES FROM THREE-DIMENSIONAL CAMERAS,"Methods, systems, and programs are presented for simultaneous recognition of objects within a detection space utilizing three-dimensional (3D) cameras configured for capturing 3D images of the detection space. One system includes the 3D cameras, calibrated based on a pattern in a surface of the detection space, a memory, and a processor. The processor combines data of the 3D images to obtain pixel data and removes, from the pixel data, background pixels of the detection space to obtain object pixel data associated with objects in the detection space. Further, the processor creates a geometric model of the object pixel data, the geometric model including surface information of the objects in the detection space, generates one or more cuts in the geometric model to separate objects and obtain respective object geometric models, and performs object recognition to identify each object in the detection space based on the respective object geometric models.",G06K 9/00; G01B 11/245; G06K 9/32; G06T 7/11; G06T 7/174; G06T 7/194; G06T 7/55; G06T 17/00; H04N 13/254,MASHGIN INC,SRIVASTAVA ABHINAI; DHANKHAR MUKUL,201715685455 24.08.2017 US,
WO2011084788,PCT/US2010/061531,21.12.2010,WO/2011/084788,14.07.2011,WO,INSERTION OF MEDICAL DEVICES THROUGH NON-ORTHOGONAL AND ORTHOGONAL TRAJECTORIES WITHIN THE CRANIUM AND METHODS OF USING,"The invention comprises an elongated device adapted for insertion, including self-insertion, through the body, especially the skull. The device has at least one effector or sensor and is configured to permit implantation of multiple functional components through a single entry site into the skull by directing the components at different angles. The device may be used to provide electrical, magnetic, and other stimulation therapy to a patient's brain. The lengths of the effectors, sensors, and other components may completely traverse skull thickness (at a diagonal angle) to barely protrude through to the brain's cortex. The components may directly contact the brain's cortex, but from there their signals can be directed to targets deeper within the brain. Effector lengths are directly proportional to their battery size and ability to store charge. Therefore, longer angled electrode effectors not limited by skull thickness permit longer-lasting batteries which expand treatment options.",A61B 5/00; A61B 5/05; A61B 5/0478,"HUA, Sherwin","HUA, Sherwin","61/288,619 21.12.2009 US",CN-201080058486.4; AU-2010339720; US-13318462; EP-2010842715; CA-2785285; KR-1020127018223; IN-1770/MUMNP/2012; MX-MX/a/2012/007150; RU-2012123549; JP-2012546147
WO2019079658,PCT/US2018/056600,19.10.2018,WO/2019/079658,25.04.2019,WO,MULTI-STEP IMAGE ALIGNMENT METHOD FOR LARGE OFFSET DIE-DIE INSPECTION,"A die-die inspection image can be aligned using a method or system configured to receive a reference image and a test image, determine a global offset and rotation angle from local sections on the reference image and test image, and perform a rough alignment de-skew of the test image prior to performing a fine alignment.",G06T 7/33; G06T 7/00; H01L 21/66,KLA-TENCOR CORPORATION,"LAUBER, Jan; VAJARIA, Himanshu; ZHANG, Yong","62/575,304 20.10.2017 US; 16/160,515 15.10.2018 US",
EP77025175,12188200,11.10.2012,2581837,17.04.2013,EP,System and method for suggestion mining,"A system and method for extraction of suggestions for improvement form a corpus of documents, such as customer reviews, are disclosed. A structured terminology (28) provided or a topic includes a set of semantic classes, each including a set of terms. A thesaurus of terms (26) relating to suggestions of improvement is provided. Text elements of text strings in the documents which are instances of terms in the structured terminology are labeled with the corresponding semantic class and text elements which are instances of terms in the thesaurus are also labeled. A set of patterns (24) is applied to the labeled text strings to identify suggestions of improvement expressions. The patterns define syntactic relations between text elements, some of which are required to be instances of one of the terms in a particular semantic class or thesaurus. A set of suggestions for improvements is output based on the identified suggestions of improvement expressions.",G06F 17/27; G06F 17/30,XEROX CORP,BRUN CAROLINE; HAGEGE CAROLINE,201113272553 13.10.2011 US,
WO2018200090,PCT/US2018/022644,15.03.2018,WO/2018/200090,01.11.2018,WO,DATA SYNCHRONIZATION FROM MULTIPLE THREE-DIMENSIONAL CAMERAS,"Methods, systems, and computer programs are presented for object recognition performed by electronic devices. One method includes an operation for capturing three-dimensional (3D) images of a region over a surface using 3D cameras, the surface having a pattern and each 3D camera defining a respective camera coordinate system. For each camera, the 3D image is analyzed to identify a location of the pattern indicating an origin of a common coordinate system, and a coordinate transformation function is defined to convert data to the common coordinate system. Each 3D camera captures a 3D object image of an object on the surface that includes 3D object data. Further, the 3D object data is transformed to the common coordinate system to obtain transformed 3D object data. The 3D object data is combined to obtain a composite 3D object data, and object recognition of the object is performed based on the composite 3D object data.",G06K 9/00,MASHGIN INC.,"SRIVASTAVA, Abhinai; DHANKHAR, Mukul","15/497,730 26.04.2017 US",
WO2003005167,PCT/US2002/021378,08.07.2002,WO/2003/005167,16.01.2003,WO,BUSINESS PROCESS POLICY OBJECT,"A method for implementing business process policy logic (750, 752, 754) in an object is provided. The method provides a computer executable methodology that includes modeling business logic (710), creating instances of modeling objects (720), messaging the instances (730), and selectively performing business logic (740). A system for automatically performing business process policy logic in an object is provided. The system includes business process policy objects and a business manager that selectively interacts with business process policy objects. The methods and systems are stored, in one example, on computer readable media.",G06F 9/44; G06Q 10/00,"COMPUTER ASSOCIATES THINK, INC.; YOUNG, Alan","YOUNG, Alan","60/303,424 06.07.2001 US",KR-1020047000185; IL-159690; ZA-200400130; AU-2002354789; JP-2003511070; CN-02816414.8; CA-2452730; IN-29/CHENP/2004
WO2007048794,PCT/EP2006/067722,24.10.2006,WO/2007/048794,03.05.2007,WO,"METHOD OF REGISTERING IMAGES, ALGORITHM FOR CARRYING OUT THE METHOD OF REGISTERING IMAGES, A PROGRAM FOR REGISTERING IMAGES USING THE SAID ALGORITHM AND A METHOD OF TREATING BIOMEDICAL IMAGES TO REDUCE IMAGING ARTEFACTS CAUSED BY OBJECT MOVEMENT","In a method for registering biomedical images such as at least a first and a second digital or digitalized image or set of cross-sectional images of the same object, within the first image or set of images a certain number of landmarks, so called features are individuated by selecting a certain number of pixels or voxels. The position of each pixel or voxel selected as a feature is tracked from the first to the second image or set of images by determining the optical flow vector from the first to the second image or set of images for each pixel or voxel selected as a feature. Registration of the first and second images or set of images is carried out by applying the inverse optical flow to the pixels or voxels of the second image or set of images. The invention provides for an automatic trackable landmark selection step consisting in defining a pixel or voxel neighbourhood around each pixel or voxel of the first image or first set of cross-sectional images; for each target pixel or voxel determining one or more characteristic parameters which are calculated as a function of the parameters describing the appearance of the said target pixel or voxel and of each or a part of the pixels or voxels of the window and as a function of one or more characteristic parameters of either the numerical matrix or of a transformation of the said numerical matrix representing the pixels or voxels of the said window. The pixels or voxels coinciding with validly trackable landmarks are determined as a function of the said characteristic parameters of the target pixels or voxels.",G06T 7/00,"BRACCO IMAGING S.P.A.; MATTIUZZI, Marco; GORI, Ilaria; WERNER VOMWEG, Toni","MATTIUZZI, Marco; GORI, Ilaria; WERNER VOMWEG, Toni",05425750.6 25.10.2005 EP,US-12063244; EP-2006819131; CN-200680039508.6
WO1998026357,PCT/CA1997/000970,09.12.1997,WO/1998/026357,18.06.1998,WO,NATURAL LANGUAGE META-SEARCH SYSTEM AND METHOD,"A meta-search system accepts natural language queries which are parsed to extract relevant content, this relevant content being formed into queries suitable for each of a selected number of search engines and being transmitted thereto. The results from the search engines are received and examined and a selected number of the information sources represented therein are obtained. These obtained information sources are then examined to rank their relevance to the extracted relevant content and the portions of interest in each of these ranked information sources are determined. The determined portions are output to the user in ranked order, having first been processed to clean up the portions to include valid formatting and complete paragraphs and/or sentences.",G06F 17/30,"PRACTICAL APPROACH CORPORATION; REDFERN, Darren, M.","REDFERN, Darren, M.","08/769,929 09.12.1996 US",
EP205860745,17000813,10.05.2017,3244301,15.11.2017,EP,USER INTERFACE APPLICATION AND DIGITAL ASSISTANT,"A computer-implemented method for interacting with a digital personal assistant having a user interface includes displaying a user interface for a digital personal assistant, receiving user input through the user interface for the digital personal assistant, the user input including a user selection of a collection data structure, containing one or more items, from a set of collection data structures, determining at least a context indicia and a user role, processing at least one item in the selected collection data structure using the context indicia and the user role and generating information for display on the user interface responsive to results of the processing.",G06F 9/44; G06F 3/0482,SAP SE,JANN FLORIAN; STEFANOV TZANKO; JANN ANNETTE; VOUTTA EMIL,201615390262 23.12.2016 US; 201662335879 13.05.2016 US,
WO2016176229,PCT/US2016/029404,27.04.2016,WO/2016/176229,03.11.2016,WO,CONTEXTUAL PEOPLE RECOMMENDATIONS,"Techniques for providing a people recommendation system for predicting and recommending relevant people (or other entities) to include in a conversation based on contextual indicators. In an exemplary embodiment, email recipient recommendations may be suggested based on contextual signals, e.g., project names, body text, existing recipients, current date and time, etc. In an aspect, a plurality of properties including ranked key phrases are associated with profiles corresponding to personal entities. Aggregated profiles are analyzed using first- and second-layer processing techniques. The recommendations may be provided to the user reactively, e.g., in response to a specific query by the user to the people recommendation system, or proactively, e.g., based on the context of what the user is currently working on, in the absence of a specific query by the user.",G06Q 10/06; G06F 17/27,"MICROSOFT TECHNOLOGY LICENSING, LLC","GUO, Chenlei; GAO, Jianfeng; SONG, Xinying; BYUN, Byungki; SHEN, Yelong; WANG, Ye-Yi; REMICK, Brian D.; THIELE, Edward; ALI, Mohammed Aatif; GOIS, Marcus; HE, Xiaodong; CHEN, Jianshu; JETLEY, Divya; FRIESEN, Stephen","62/154,039 28.04.2015 US; 62/156,362 04.05.2015 US; 14/806,281 22.07.2015 US",EP-2016720665
WO2019006022,PCT/US2018/039843,27.06.2018,WO/2019/006022,03.01.2019,WO,SYSTEMS AND METHODS FOR MHC CLASS II EPITOPE PREDICTION,A system and method for prediction of immunodominant epitopes is provided herein. MHCII peptidomics was used to discover complex bacterial epitopes and host antigen processing pathways. Novel insights into the features of antigenicity are leveraged to build an algorithm for prediction of immunodominant epitopes. Use of immunodominant epitopes is described.,G06F 19/22; A61K 39/00; A61K 39/02; A61K 38/10; A61K 35/15; C07K 7/08,"THE BROAD INSTITUTE, INC.; THE GENERAL HOSPITAL CORPORATION","GRAHAM, Daniel B.; LUO, Chengwei; XAVIER, Ramnik","62/525,673 27.06.2017 US",
WO2016207875,PCT/IL2015/051161,29.11.2015,WO/2016/207875,29.12.2016,WO,SYSTEM AND METHOD FOR DETECTING OBJECTS IN AN IMAGE,"A method for cropping photos images captured by a user from an image of a page of a photo album is described. Corners in the page image are detected using corner detection algorithm or by detecting intersections of line-segments (and their extensions) in the image using edge, corner, or line detection techniques. Pairs of the detected corners are used to define all potential quads, which are then are qualified according to various criteria. A correlation matrix is generated for each potential pair of the qualified quads, and candidate quads are selected based on the Eigenvector of the correlation matrix. The content of the selected quads is checked using a salience map that may be based on a trained neuron network, and the resulting photos images are extracted as individual files for further handling or manipulation by the user.",G06K 9/46; G06K 9/78,PHOTOMYNE LTD.,"SHOOR, Omer; LIPMAN, Yaron; TZEMAH, Nir; VERTER, Natalie; SEGALOVITZ, Yair","62/182,652 22.06.2015 US; 62/202,870 09.08.2015 US",
WO2020002705,PCT/EP2019/067600,01.07.2019,WO/2020/002705,02.01.2020,WO,ITEM INSPECTION BY RADIATION IMAGING USING AN ITERATIVE PROJECTION-MATCHING APPROACH,"A method and system for inspection of an item, and a use thereof, are presented. The method comprises acquiring a plurality of projection images of an item at a plurality of projection angles for performing a tomographic reconstruction of the item. A plurality of objects are detected in the tomographic reconstruction and each object has a generic shape described by a parametric three-dimensional numerical model. Said detection comprises determining initial estimates of position and/or orientation of each object and at least one geometrical parameter of the three-dimensional model for each object. The initial estimates are iteratively refining by using a projection-matching approach, in which forward projection images are simulated for the objects according to operating parameters of the radiation imaging device and a difference metric between acquired projection images and simulated forward projection images is reduced at each iteration step.",G01N 23/046; G01N 33/36,UNIVERSITEIT ANTWERPEN; IMEC VZW,"DE BEENHOUWER, Jan; SIJBERS, Jan",18180893.2 29.06.2018 EP,
WO2017218431,PCT/US2017/037067,12.06.2017,WO/2017/218431,21.12.2017,WO,RAPID DETECTION OF BLEEDING FOLLOWING INJURY,"Novel tools and techniques are provided for assessing, predicting and/or estimating a probability that a patient is bleeding, in some cases, noninvasively. In various embodiments, tools and techniques are provided for implementing rapid detection of bleeding of the patient or implementing assessment, prediction, or estimation of a probability of bleeding of the patient following injury, in some instances, in real-time before, during, and after fluid resuscitation. According to some embodiments, one or more sensors might monitor physiological data of the patient before, during, and after resuscitation following injury. A computer system might receive and analyze the physiological data, and might estimate a probability that the patient is bleeding, based at least in part on the analyzed physiological data. An indication of at least one of an assessment, prediction, or estimate of a probability that the patient is bleeding may then be displayed on a display device.",A61B 5/00; A61B 5/024; A61M 37/00,"FLASHBACK TECHNOLOGIES, INC.; THE REGENTS OF THE UNIVERSITY OF COLORADO, A BODY CORPORATE","MULLIGAN, Isobel Jane; GRUDIC, Gregory Zlatko; MOULTON, Steven L.","62/349,516 13.06.2016 US",EP-2017813880
EP152525750,15160661,24.03.2015,2924111,30.09.2015,EP,Method and system for continous monitoring of toxicity,"Systems, kits and methods for non-invasive, long-term, real-time monitoring of one or more physiological parameters of a cell, including but not limited to oxygen uptake, are provided.",C12M 1/32; B01L 3/00; C12M 1/00; C12M 1/34; C12M 1/42; C12M 3/06; G01N 33/50,YISSUM RES DEV CO; FRAUNHOFER GES ZUR FÖRDERUNG DER ANGEWANDTEN FORSCHUNG E V; COLIBRI PHOTONICS GMBH,YAAKOV NAHMIAS; PRILL SEBASTIAN; JAEGER MAGNUS; BAVLI DANNY; SCHMÄLZLIN ELMAR,201461969377 24.03.2014 US,
WO1997020274,PCT/US1996/019036,29.11.1996,WO/1997/020274,05.06.1997,WO,PERSONAL ELECTRONIC BOOK SYSTEM,"The personal Electronic Book System invention replaces a standard handheld book with an electronic equivalent. The invention is sized and configured to be book size and to open like a book for use. When opened, the user sees two facing page-like touch-sensitive, display screens with black print on white background. Icons represent the electronically stored material, 'artwork, audio clips, books, E-mail, faxes, games, magazines, movies, musical compositions, newspapers, photographs, software, video clips, etc.', which are selected by touching the icon. When a book, magazine, newspaper, or the like is selected, its table of contents is displayed and the user can then read page by page or go directly to a particular page by touching the selection listed in the table of contents. Closing the Personal Electronic Book automatically shuts down the device. Touching a page number before closing the Personal Electronic Book inserts a bookmark so that when the Personal Electronic Book is re-opened, the user is returned to the same page. New printed or multimedia material can be downloaded from a remote server, that is, 'a bookstore', and old material, books read, etc., can be deleted to make room for the new material.",G06F 15/02,"EVERYBOOK DELAWARE, INC.; MUNYAN, Daniel, E.","MUNYAN, Daniel, E.","08/565,915 01.12.1995 US",MX-PA/a/1998/004331; CA-2231807; EA-199800504; TR-1998/00953; JP-1997520675; EP-1996940904; CN-96198721.9
WO2016012868,PCT/IB2015/050575,26.01.2015,WO/2016/012868,28.01.2016,WO,METHOD OF AND SYSTEM FOR CRAWLING A WEB RESOURCE,"There is disclosed a method of setting up a crawling schedule, the method executable at a crawling server, the crawling server coupled to a communication network, the communication network having coupled thereto a first web resource server and a second web 5 resource server. The method comprises: appreciating a first new web page associated with the first web resource server; appreciating a second new web page associated with the second web resource server;",G06F 17/30,YANDEX EUROPE AG; YANDEX LLC; YANDEX INC.,"LEFORTIER, Damien Raymond Jean-françois; OSTROUMOVA, Liudmila Alexandrovna; SAMOSVAT, Egor Aleksandrovich; SERDYUKOV, Pavel Viktorovich; BOGATYY, Ivan Semeonovich; CHELNOKOV, Arsenii Andreevich; GUSEV, Gleb Gennadievich",2014130448 24.07.2014 RU,US-15326045
WO2019016156,PCT/EP2018/069307,16.07.2018,WO/2019/016156,24.01.2019,WO,METHOD FOR PREDICTION OF RESPONSE TO CARDIOVASCULAR REGENERATION,"The present invention relates to a method for prediction of response to cardiovascular regeneration comprising the use of biomarkers. Further, the present invention relates to a combination of the biomarkers for use in a method for prediction of response to cardiovascular regeneration, a computer device to perform a method according to the present invention and a device adapted for carrying out the inventive method.",G01N 33/50; G01N 33/68,UNIVERSITÄT ROSTOCK ZENTRALE UNIVERSITÄTSVERWALTUNG REFERAT 1.1 RECHT,"STEINHOFF, Gustav; NESTERUK, Julia; WOLFIEN, Markus",10 2017 116 204.6 18.07.2017 DE,KR-1020207003430; EP-2018745528; AU-2018302405; SG-11201912233T
WO2019234564,PCT/IB2019/054523,31.05.2019,WO/2019/234564,12.12.2019,WO,CONSTRUCTING A MIXED-DOMAIN MODEL,"A technique for constructing a model supporting a plurality of domains is disclosed. In the technique, a plurality of teacher models, each of which is specialized for different one of the plurality of the domains, is prepared. A plurality of training data collections, each of which is collected for different one of the plurality of the domains, is obtained. A plurality of soft label sets is generated by inputting each training data in the plurality of the training data collections into corresponding one of the plurality of the teacher models. A student model is trained using the plurality of the soft label sets.",G06N 3/08,INTERNATIONAL BUSINESS MACHINES CORPORATION; IBM UNITED KINGDOM LIMITED; IBM (CHINA) INVESTMENT COMPANY LIMITED,"FUKUDA, Takashi; ICHIKAWA, Osamu; THOMAS, Samuel; RAMABHADRAN, Bhuvana","16/003,790 08.06.2018 US",
EP248884811,19150975,09.01.2019,3511803,17.07.2019,EP,METHOD AND APPARATUS TO DETERMINE TRIGGER INTENT OF USER,,G06F 3/01; G06F 3/0481; G06F 3/0484; G06K 9/00,SAMSUNG ELECTRONICS CO LTD,ZHANG HUI; GUO TIANCHU; QIAN DEHENG; LIU XIABING; KIM YOUNGSUNG; YOO BYUNG IN; HAN JAEJOON; CHOI CHANGKYU,201810024682 10.01.2018 CN; 20180118228 04.10.2018 KR,
EP128449342,14171650,09.06.2014,2813931,17.12.2014,EP,Electronic apparatus and method for providing services thereof,"An electronic apparatus and a method for providing a service thereof are provided. The method for providing the service of the electronic apparatus includes: executing an interactive application which integrates a plurality of services and provides the plurality of services, in response to selection of at least one of the plurality of services, performing a first displaying operation to display a chatting screen for chatting with the at least one selected service, and in response to input of a user message through the chatting screen, analyzing the user message according to the at least one selected service and performing a function of the at least one selected service corresponding to the user message.",G06Q 10/10; G06F 9/44; G06Q 50/00; H04L 12/58,SAMSUNG ELECTRONICS CO LTD,YANG JI-YUN,20130066180 10.06.2013 KR,
WO2011152843,PCT/US2010/044135,02.08.2010,WO/2011/152843,08.12.2011,WO,CLOTHING-BASED IMAGE CLUSTERING BASED ON CLUSTER ENSEMBLE SETS,The disclosure is related to a system and method for learning robust clothing clustering based on a cluster ensemble technique applied to the clothing features of images to improve clustering of images. Different types of clothing features that are complementary to each other are computed to provide extensive description of the clothing in the images. Multiple partitions are computed based on the clothing features to generate a cluster ensemble set. A consensus function is applied to the multiple partitions to generate a final clothing consensus clustering that encompasses the information contained in the multiple partitions. A system and method are disclosed for clustering images based on the clothing of one or more persons in the images.,G06F 17/00; G06T 1/00; G06F 13/14,"HEWLETT-PACKARD DEVELOPMENT COMPANY, L.P.; ZHANG, Tong; ZHANG, Wei; TRETTER, Daniel","ZHANG, Tong; ZHANG, Wei; TRETTER, Daniel","61/350,461 01.06.2010 US",US-13642352
WO2017127850,PCT/US2017/014699,24.01.2017,WO/2017/127850,27.07.2017,WO,COMPUTER SECURITY BASED ON ARTIFICIAL INTELLIGENCE,"Computer Security System Based On Artificial Intelligence includes Critical Infrastructure Protection & Retribution (CIPR) through Cloud & Tiered Information Security (CTIS), Machine Clandestine Intelligence (MACINT) & Retribution through Covert Operations in Cyberspace, Logically Inferred Zero-database A-priori Realtime Defense (LIZARD), Critical Thinking Memory & Perception (CTMP), Lexical Objectivity Mining (LOM), Linear Atomic Quantum Information Transfer (LAQIT) and Universal BCHAIN Everything Connections (UBEC) system with Base Connection Harmonization Attaching Integrated Nodes.",G06N 5/02; G06F 17/30; G06F 21/50; G06F 21/51; G06F 21/53; G06F 21/54; G06F 21/55; G06F 21/56; G06F 21/57,"HASAN, Syed, Kamran","HASAN, Syed, Kamran","62/294,258 11.02.2016 US; 62/286,437 24.01.2016 US; 62/307,558 13.03.2016 US; 62/323,657 16.04.2016 US; 15/145,800 04.05.2016 US; 62/326,723 23.04.2016 US; 62/341,310 25.05.2016 US; 62/439,409 27.12.2016 US; 15/264,744 14.09.2016 US",AU-2017210132; KR-1020187024400; IL-260711; CA-3051164; MX-MX/a/2018/009079; SG-11201806117T; EP-2017742143; JP-2018538714; CN-201780019904.0
EP11018716,08151229,08.02.2008,2088536,12.08.2009,EP,Text input system and method involving finger-based handwriting recognition and word prediction,"The present invention relates to a text input system and method involving finger-based handwriting recognition and word prediction. A text input device (300) comprises: a text prediction component (310) for predicting a plurality of follow-up words based on a text context, the text prediction component (310) outputting a set of candidate words; a character handwriting recognition component (330) for recognizing a handwritten character candidate, the handwritten character candidate being determined based upon handwriting input received from a touch sensitive input field (340); a candidate word filtering component (350) for filtering the set of candidate words received from the text prediction component (310) based on the recognized handwritten character candidate; a word presentation component (360) for presenting candidate words from the filtered set of candidate words to a user of the device; and a word selection component (380) for receiving a user selection of a presented candidate word from the user.",G06K 9/22; G06F 3/023,EXB ASSET MAN GMBH,ASSADOLLAHI RAMIN O,08151229 08.02.2008 EP,
WO2018171267,PCT/CN2017/116099,14.12.2017,WO/2018/171267,27.09.2018,WO,SYSTEMS AND METHODS FOR ROUTE SEARCHING,"A system and method for searching for a route. The system may perform the method to obtain route information of a first route(410); encode the route information of the first route into a first code based on a target model(420); access a target database in at least one storage medium, wherein the target database includes a plurality of candidate codes encoded through the target model from a plurality of candidate routes(430); identify, from the plurality of candidate codes, a second code based on the first code(440), the second code being associated with at least one second route; and send information associated with the at least one second route to a receiving device(450).",G06F 17/30,"BEIJING DIDI INFINITY TECHNOLOGY AND DEVELOPMENT CO., LTD.","YE, Zhou; WANG, Yu; SHAO, Dan",201710179750.3 23.03.2017 CN,EP-2017902011
WO2011149961,PCT/US2011/037773,24.05.2011,WO/2011/149961,01.12.2011,WO,SYSTEMS AND METHODS FOR IDENTIFYING INTERSECTIONS USING CONTENT METADATA,"User-submitted content (e.g., stories) may be associated with descriptive metadata (intersection metadata), such as a timeframe, location, tags, and so on. The user-submitted content may be browed and/or searched using the descriptive metadata. Intersection criteria comprising a prevailing timeframe, a location, and/or other metadata criteria may be used to identify an intersection space comprising one or more stories. The stories may be ordered according to relative importance, which may be determined (at least in part) by comparing story metadata to the intersection criteria.",G06F 17/30; G06F 17/00; G06F 3/14; G06Q 50/00,"INTERSECT PTP, INC.; RINEARSON, Peter; SELDEN, Kristofor; FLASHMAN, Michael","RINEARSON, Peter; SELDEN, Kristofor; FLASHMAN, Michael","61/347,815 24.05.2010 US",
WO2006037219,PCT/CA2005/001513,05.10.2005,WO/2006/037219,13.04.2006,WO,SYSTEM AND METHODS FOR IMPROVING ACCURACY OF SPEECH RECOGNITION,"The invention provides a system and method for improving speech recognition. A computer software system is provided for implementing the system and method. A user of the computer sofware system may speak to the system directly and the system may respond, in spoken language, with an appropriate response. Grammar rules may be generated automatically from sample utterances when implementing the system for a particular application. Dynamic grammar rules may also be generated during interaction between the user and the system. In addition to arranging searching order of grammar files based on a predetermined hierarchy, a dynamically generated searching order based on history of contexts of a single conversation may be provided for further improved speech recognition. Dialogue between the system and the user of the system may be recorded and extracted for use by a speech recognitiion engine to refine or create language models so that accuracy of speech recognition relevant to a particular knowledge area may be improved.",G10L 15/26; G06F 17/27,"INAGO CORPORATION; DICARLANTONIO, Ron; LEONARD, Huw; FARMANER, Gary","DICARLANTONIO, Ron; LEONARD, Huw; FARMANER, Gary","10/957,579 05.10.2004 US; 2,483,805 05.10.2004 CA",EP-2005792217; EP-2010182514; EP-2010182546; EP-2010164674
WO2017156634,PCT/CA2017/050341,17.03.2017,WO/2017/156634,21.09.2017,WO,DEVICES AND METHODS FOR CELLULAR SECRETION ANALYSIS,"Methods and devices for identifying a cell population comprising an effector cell exhibiting an extracellular effect are provided. The method comprises retaining in a plurality of open chambers a plurality of cell populations, each optionally comprising one or more effector cells. The open chambers can each comprise a readout particle population, and the open chambers are present in a first component of a device comprising a first component and optionally a second component. The open chambers have an average aspect ratio of ≥ 0.6 and the first component forms a reversible seal with the second component. The method further comprises incubating the plurality of cell populations or a subset thereof, and the one or more readout particles, or a subset thereof, within the chambers, assaying the cell populations for the presence of the extracellular effect, wherein the readout particle(s) provides a direct or indirect readout of the extracellular effect, and determining, based on the results of the assaying step, whether one or more cells within one or more cell populations of the plurality exhibits the extracellular effect.",C12Q 1/02; B81B 1/00; C12M 1/34; C12Q 1/00; G01N 33/483; G01N 33/50; G01N 33/52; G01N 35/00; G01N 35/10,THE UNIVERSITY OF BRITISH COLUMBIA,"HANSEN, Carl Lars Genghis; LISAINGO, Kathleen; LECAULT, Veronique","62/309,663 17.03.2016 US",KR-1020187029795; CN-201780030152.8; JP-2018548883; EP-2017765619; AU-2017233729; CA-3015237
WO2006081505,PCT/US2006/003104,26.01.2006,WO/2006/081505,03.08.2006,WO,A DISTANCE IRIS RECOGNITION SYSTEM,"A system for one dimensional segmentation of an iris of an eye into a map of the iris and classification of the map into unaffected areas and affected areas. Also, the system may provide for regular shape fitting of the areas for normalization and identifying the unaffected areas as symmetric segments. Further, the system may assign weights to the unaffected areas and the affected areas of the map of the iris and an enrolled map of an iris and their corresponding bins for matching purposes.",G06K 9/00,"HONEYWELL INTERNATIONAL INC.; HAMZA, Rida","HAMZA, Rida","60/647,270 26.01.2005 US; 11/275,703 25.01.2006 US",EP-2006734016; KR-1020077019289; JP-2007553302
WO2019055080,PCT/US2018/036928,11.06.2018,WO/2019/055080,21.03.2019,WO,OBJECT DETECTION AND REPRESENTATION IN IMAGES,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for object detection and representation in images. In one aspect, a method includes detecting occurrences of objects of a particular type in images captured within a first duration of time, and iteratively training an image embedding function to produce as output representations of features of the input images depicting occurrences of objects of the particular type, where similar representations of features are generated for images that depict the same instance of an object of a particular type captured within a specified duration of time, and dissimilar representations of features are generated for images that depict different instances of objects of the particular type.",G06K 9/00; G06F 17/30; G06K 9/62,GOOGLE LLC,"SCHROFF, Gerhard Florian; HU, Wenze","15/704,746 14.09.2017 US",CN-201880024390.2; KR-1020197029644; EP-2018735148
WO2009154484,PCT/NZ2009/000114,19.06.2009,WO/2009/154484,23.12.2009,WO,"METHODS, APPARATUS AND SYSTEMS FOR DATA VISUALIZATION AND RELATED APPLICATIONS","In a data visualization system,a method of creating a visual representation of data, the method including the steps of providing instructions to an end user to assist the end user in: constructing multiple graphical representations of data, where each graphical representation is one of a predefined type and includes multiple layers of elements that contribute to the end user's understanding of the data; arranging multiple graphical representations of different types within the visual representation in a manner that enables the end user to understand and focus on the data being represented; and displaying the visual representation.",G06F 3/048; G06F 3/14; G06F 3/12; G06T 1/20,"BUSINESS INTELLIGENCE SOLUTIONS SAFE B.V.; CARDNO, Andrew John; INGHAM, Peter Stewart; LEWIN, Bart Andrew; SINGH, Ashok Kumar","CARDNO, Andrew John; INGHAM, Peter Stewart; LEWIN, Bart Andrew; SINGH, Ashok Kumar","61/074,347 20.06.2008 US; 61/093,428 01.09.2008 US; 61/101,670 30.09.2008 US; 61/101,672 30.09.2008 US; 61/107,665 22.10.2008 US; 61/115,036 15.11.2008 US; 61/118,211 26.11.2008 US; 61/140,556 23.12.2008 US; 61/146,133 21.01.2009 US; 61/145,775 20.01.2009 US; 61/146,525 22.01.2009 US; 61/146,430 22.01.2009 US; 61/161,472 19.03.2009 US",US-13000323
WO2019016614,PCT/IB2018/001238,13.07.2018,WO/2019/016614,24.01.2019,WO,METHOD AND APPARATUS FOR DISPLAYING SEARCH RESULTS,"A method of displaying search results, and a related apparatus are provided. The method includes obtaining candidate search results, each candidate search result having a data type to which the respective candidate search result belongs; determining a display ratio of each data type; separately extracting target search results of corresponding data types from the candidate search results according to the display ratio of each data type; and displaying the target search results. By combining a user identifier with personalized information of a user, the present disclosure can dynamically allocate respective numbers of target search results that are displayed for various data types using optimal target parameters.",G06F 17/30,ALIBABA GROUP HOLDING LIMITED,"LI, Heng; LIU, Shichen",201710575606.1 14.07.2017 CN,
WO2017044257,PCT/US2016/047184,16.08.2016,WO/2017/044257,16.03.2017,WO,INTELLIGENT AUTOMATED ASSISTANT IN A MEDIA ENVIRONMENT,"Systems and processes are disclosed for operating a digital assistant in a media environment. In an exemplary embodiment, a user can interact with a digital assistant of a media device while content is displayed by the media device. In one approach, a plurality of exemplary natural language requests can be displayed in response to detecting a user input of a first input type. The plurality of exemplary natural language requests can be contextually-related to the displayed content. In another approach, a user request can be received in response to detecting a user input of a second input type. A task that at least partially satisfies the user request can be performed. The performed task can depend on the nature of the user request and the content being displayed by the media device. In particular, the user request can be satisfied while reducing disruption to user consumption of media content.",H04N 21/41; G06F 17/30; H04N 21/422; H04N 21/482,APPLE INC.,"NAPOLITANO, Lia, T.; HWANG, Grace, H.; PENHA, Henrique, D.; SHAW, Jeremiah, D.; FINO, Jorge, S.","62/215,676 08.09.2015 US; 14/963,094 08.12.2015 US",KR-1020207001841; KR-1020177007440; JP-2016569709; EP-2017178232; KR-1020177023656; EP-2016766674; AU-2016247040
WO2000038135,PCT/US1999/002653,08.02.1999,WO/2000/038135,29.06.2000,WO,"A SYSTEM, METHOD AND ARTICLE OF MANUFACTURE FOR A RUNTIME PROGRAM REGRESSION ANALYSIS TOOL FOR A SIMULATION ENGINE","A system is disclosed that provides a goal based learning system utilizing a rule based expert training system to provide a cognitive educational experience. The system provides the user with a simulated environment that presents a business opportunity to understand and solve optimally. Mistakes are noted and remedial educational material presented dynamically to build the necessary skills that a user requires for success in the business endeavor. The system utilizes an artificial intelligence engine driving individualized and dynamic feedback with synchronized video and graphics used to simulate real-world environment and interactions. Multiple 'correct' answers are integrated into the learning system to allow individualized learning experiences in which navigation through the system is at a pace controlled by the learner. A robust business model provides support for realistic activities and allows a user to experience real-world consequences for their actions and decisions and entails realtime decision-making and synthesis of the educational material. The system includes tools for analysis, logging and display of regression analysis information for a presentation as it is presented.",G06F 9/44; G09B 7/04,"ACCENTURE PROPERTIES (2) B.V.; BERTRAND, Benoit, Patrick; WILLS, Kerry, Russell","BERTRAND, Benoit, Patrick; WILLS, Kerry, Russell","09/218,976 22.12.1998 US",US-09868743; EP-1999905850
WO2018115963,PCT/IB2017/001684,21.12.2017,WO/2018/115963,28.06.2018,WO,NAVIGATIONAL SYSTEM WITH IMPOSED LIABILITY CONSTRAINTS,"Systems and methods are provided for navigating a host vehicle. In some embodiments, the system may include at least one processing device programmed to: receive, from an image capture device, at least one image representative of an environment of the host vehicle; determine, based on at least one driving policy, a planned navigational action for accomplishing a navigational goal of the host vehicle; analyze the at least one image to identify a target vehicle in the environment of the host vehicle; test the planned navigational action against at least one accident liability rule for determining potential accident liability for the host vehicle relative to the identified target vehicle; if the test of the planned navigational action against the at least one accident liability rule indicates that potential accident liability exists for the host vehicle if the planned navigational action is taken, then cause the host vehicle not to implement the planned navigational action; and if the test of the planned navigational action against the at least one accident liability rule indicates that no accident liability would result for the host vehicle if the planned navigational action is taken, then cause the host vehicle to implement the planned navigational action.",G01C 21/36; G05D 1/00; B60W 30/08; G01C 21/34,MOBILEYE VISION TECHNOLOGIES LTD.,"SHALEV-SHWARTZ, Shai; SHAMMAH, Shaked; SHASHUA, Amnon","62/438,563 23.12.2016 US; 62/546,343 16.08.2017 US; 62/565,244 29.09.2017 US; 62/582,687 07.11.2017 US",KR-1020197021476; EP-2017835865; CN-201780084515.6; JP-2019527180; IL-266725
WO2008157792,PCT/US2008/067746,20.06.2008,WO/2008/157792,24.12.2008,WO,DIGITAL IMAGE ENHANCEMENT WITH REFERENCE IMAGES,"A digital image processing technique detects and corrects visual imperfections using a reference image. A main image and one or more reference images having a temporal and/or spatial overlap and/or proximity with the original image are captured. Device information, image data and/or meta data are analyzed of the one or more reference images relating to a defect in the main image. The device corrects the defect based on the information, image data and/or meta-data to create an enhanced version of the main image.",G06K 9/00; H04N 5/228; G06K 9/62; G06T 1/00,"FOTONATION IRELAND LIMITED; STEINBERG, Eran; BIGIOI, Petronel; ZAMFIR, Adrian; DRIMBAREAN, Alexandru; CORCORAN, Peter","STEINBERG, Eran; BIGIOI, Petronel; ZAMFIR, Adrian; DRIMBAREAN, Alexandru; CORCORAN, Peter","60/945,558 21.06.2007 US",
WO2017088828,PCT/CN2016/107353,25.11.2016,WO/2017/088828,01.06.2017,WO,SYSTEMS AND METHODS FOR ALLOCATING SHARABLE ORDERS,"Systems and methods for allocating a plurality of orders. The systems may perform the methods to obtain a plurality of orders (402), wherein each order may be associated with a request of a service and include a plurality of features; determine matching information of the plurality of orders based on the features of the plurality of orders (404); determine a set of sharable orders based on the matching information (406); allocate the set of sharable orders (408), wherein the allocation may result in a maximum profit value associated with a combination of at least two sharable orders of the set of sharable orders; and send the combination of the at least two sharable orders to a service provider.",G06F 17/30,"BEIJING DIDI INFINITY TECHNOLOGY AND DEVELOPMENT CO., LTD.","ZHANG, Lingyu; SUN, Hongjing; MENG, Yang; HE, Li; ZHANG, Yang; CHENG, Wei",201510846367.X 26.11.2015 CN; 201610093904.2 19.02.2016 CN,JP-2018506428; AU-2016359530; GB-1801955.4; EP-2016868051
WO2009067655,PCT/US2008/084325,21.11.2008,WO/2009/067655,28.05.2009,WO,METHODS OF FEATURE SELECTION THROUGH LOCAL LEARNING; BREAST AND PROSTATE CANCER PROGNOSTIC MARKERS,"A method is provided that addresses the feature selection problem in the presence of copious irrelevant features. According to this method, feature selection can be accomplished by decomposing a given complex problem into a set of locally linear problems through local learning, and estimating the relevance of features globally within a large margin framework. Local learning allows one to capture local structure of the data, while the global parameter estimation within a large margin framework allows one to a\oid possible overfitting. This method addresses many major issues of the prior art, including their problems with computational complexity, solution accuracy, algorithm implementation, exportability of selected features, and extension to multiclass settings. Using the method, a small number of genes useful for predicting the occurrence of distal metastases in breast cancer patients were identified: LOC58509, CEGPl, AL080059, ATP5E. and FRAME. Also using the method, prostate cancer prognostic signatures based on gene expression alone and gene expression in combination with post-operative nomogram were derived. Genes determined to be particularly relevant to prostate cancer prognosis include PCOLN3, TGFB3, PAK3. RBM34. RPL23, EI24, FUT7, RlCS Rho. MAP4K4. CUTLl, and ZNF324B.",C12Q 1/68; G06F 19/24; G06F 19/20,"UNIVERSITY OF FLORIDA RESEARCH FOUNDATION, INC.; SUN, Yijun; GOODISON, Steve; LIU, Li; FARMERIE, William, George","SUN, Yijun; GOODISON, Steve; LIU, Li; FARMERIE, William, George","60/989,592 21.11.2007 US; 61/040,232 28.03.2008 US; 61/040,237 28.03.2008 US",
WO2002031604,PCT/US2001/031414,10.10.2001,WO/2002/031604,18.04.2002,WO,METHOD AND SYSTEM TO CONSTRUCT ACTION COORDINATION PROFILES,"Action coordination profiles are part of a platform data processing technology that is distinct from but often complementary to the statistical method. It uses repeated measures or time series data to measure interactions (longitudinal associations, temporal contingencies) between and among variables or sets of variables for individuals. The interaction measures show how individual complex systems may interact, of how complex systems may be controlled or affected by their environments including treatments, and of how individual systems may control or affect their environments. The systems can be object of investigation such as brains, organisms, patients, economies, investment markets, populations, machines, or processes. The actions can be physical, chemical, biological, behavioral, mental, or social. This invention can be used to help inform the process of building mathematical models. This invention also can be said to help make data speak by drawing generalized conclusions and making predictions about how individuals function and interact with their environments. Action coordination profiles and any resulting models can help advance basic and applied science.",G06T 7/00; G06T 7/20,"BAGNE, Curtis, A.","BAGNE, Curtis, A.","60/238,937 10.10.2000 US",CA-2425871; EP-2001981414
EP76171940,12180550,15.08.2012,2560118,20.02.2013,EP,User interface feature for drug delivery system,"A medical system includes a monitoring unit and a drug delivery unit. The monitoring unit is operable to monitor at least one physiological parameter of a patient. The drug delivery unit includes an integral volume of a drug. A control logic is in communication with the monitoring unit and the drug delivery unit and is operable to regulate delivery of the drug to the patient from the integral volume, based on data associated with the at least one physiological parameter of the patient, in accordance with a safety shell control algorithm. A user interface feature is operable to receive input indicating administration of an external drug to the patient. The safety shell control algorithm responds to inputs received through the user interface feature indicating administration of an external drug to the patient, such as by modifying subsequent drug delivery regulation based on the administration of the external drug.",G06F 19/00,ETHICON ENDO SURGERY INC,NIKLEWSKI PAUL J; MARTIN JAMES F; MUELLER DONN C; FENG DAVID Q; KROGH ROSS G; JAMPALA HEMANT,201113210530 16.08.2011 US,
WO2018126077,PCT/US2017/068832,28.12.2017,WO/2018/126077,05.07.2018,WO,SERVICE PROVISION TO IOT DEVICES,"An Internet of Things (IoT) network includes an orchestrator to issue service management requests, a service coordinator to identify components to participate in the service, and a component to perform a network service element. An IoT network includes an IoT device with service enumerator, contract enumerator, and join contract function. An IoT network apparatus includes permissions guide drafter for discovered peers, and permissions guide action executor. An IoT network apparatus includes floating service permissions guide drafter for discovered hosts, host hardware selector, floating service permissions guide executor, and service wallet value transferor. An IoT network apparatus includes permissions guide drafter for first and second discovered peers, parameter weight calculator, permissions guide term generator, and permissions guide action executor. An IoT network includes an IoT device with resource hardware component identifier, processor to process a received indication of an external module hardware requirement, an external module comparer, and deactivation signal transmitter.",H04L 12/24; H04W 4/70; H04W 4/38; H04L 29/08; G01D 4/00; H04W 84/18,INTEL CORPORATION,"NOLAN, Keith; KELLY, Mark; NOLAN, Michael; CARBONI, Davide; NI SCANAILL, Cliodhna; RYAN, Eugene; DAVIES, Richard; BRADY, John","62/441,070 30.12.2016 US",CN-201780074400.9; EP-2017835558
WO2016142679,PCT/GB2016/050608,07.03.2016,WO/2016/142679,15.09.2016,WO,CHEMICALLY GUIDED AMBIENT IONISATION MASS SPECTROMETRY,"A method is disclosed comprising obtaining or acquiring chemical or other non- mass spectrometric data from one or more regions of a target (2) using a chemical sensor (20). The chemical or other non-mass spectrometric data may be used to determine one or more regions of interest of the target (2). An ambient ionisation ion source 1 may then be used to generate aerosol, smoke or vapour (5) from one or more regions of the target (2).",G01N 33/68; A61B 17/00; G01N 3/00; G01N 9/00; H01J 49/00; A61B 18/00; G01N 27/62,MICROMASS UK LIMITED,"PRINGLE, Steven Derek; JONES, Emrys; MORRIS, Michael Raymond; BALOG, Júlia; LANGRIDGE, James Ian; RICHARDSON, Keith; SIMON, Dániel; GÖDÖRHÁZY, Lajos; SZALAY, Dániel; TAKÁTS, Zoltán",1503879.7 06.03.2015 GB; 1503876.3 06.03.2015 GB; 1503864.9 06.03.2015 GB; 1503877.1 06.03.2015 GB; 1503867.2 06.03.2015 GB; 1503863.1 06.03.2015 GB; 1503878.9 06.03.2015 GB; 1516003.9 09.09.2015 GB; 1518369.2 16.10.2015 GB,GB-1715805.6; EP-2016710786; US-15556064
WO2014031451,PCT/US2013/055225,16.08.2013,WO/2014/031451,27.02.2014,WO,USER INTERFACE FOR INTERACTIVE VISUAL DATA MINING,A data exploration user interface includes a selection area with selectable representations of queryable fields of a data source and a visualization area where query results are displayed as data visualizations. Queries are generated by dragging fields from the selectable area to the visualization area of the user interface. A tree structure of data visualizations may be created by dragging data points out of a displayed visualization and applying additional fields to create a new query and resulting visualization. The tree structure is graphically represented with path indicators that provide historical context for each new data visualization within the visualization are of the user interface.,G06F 17/30; G06F 3/0487; G06F 3/0488; G06F 3/01; G06F 3/0486,"MICROSOFT TECHNOLOGY LICENSING, LLC","HOU, Zhitao; LIANG, Xiao; ZHANG, Haidong; ZHANG, Dongmei","13/589,999 20.08.2012 US",
WO2016181383,PCT/IL2016/050466,04.05.2016,WO/2016/181383,17.11.2016,WO,SYSTEM AND METHOD FOR STREAMING CONTENT FROM MULTIPLE SERVERS,"A system and a method for media streaming from multiple sources are disclosed. A content requesting client device accesses a server to receive a list of available sources that may include multiple Content Delivery Networks (CDNs) and independent servers. Based on a pre-set criteria, such as the source delivery performance and cost, the client device partitions the content into parts, allocates a source to each part, and simultaneously receives media streams of the content parts from the allocated sources. The server may be a Video-on-Demand (VOD) server, and the content may be a single file of a video data, such as a movie. The delivery performance of the used sources is measured during the streaming for updating the partition or the allocation. The updated measured performance may be stored locally at the client device, or at a server for use by other clients. The client actions may be implemented as a client-side script.",H04L 29/06; G06F 15/16; H04N 21/462; H04N 21/2343,HOLA NETWORKS LTD.,"SHRIBMAN, Derry; VILENSKI, Ofer","62/161,553 14.05.2015 US; 62/173,411 10.06.2015 US; 62/210,081 26.08.2015 US; 62/308,291 15.03.2016 US; 15/089,721 04.04.2016 US",
WO2011038445,PCT/AU2010/001267,28.09.2010,WO/2011/038445,07.04.2011,WO,A CONTENT BASED APPROACH TO EXTENDING THE FORM AND FUNCTION OF A BUSINESS INTELLIGENCE SYSTEM,"A business intelligence (BI) system includes the ability to extend its functionality outside of the project life cycle by means of specific content. Complex multidimensional queries are interpreted as trees of atomic sub-expressions that are combined in a parse-tree-like structure to form the overall query. Each sub tree is valid in isolation when provided with the proper context. Any sub tree can be an expression template, stored as application content, which at generation time uses simple text substitution with instance specific parameters to produce multidimensional expression syntax. The system includes a sophisticated type system and semantic layer that hides the user from the complexities inherent in working with OLAP databases. A business intelligence expert can provide type and semantic cues for each expression template, held as content.",G06F 17/30,"ZAP HOLDINGS LIMITED; REEVES, Christopher John; MEYNINK, Todd William","REEVES, Christopher John; MEYNINK, Todd William",2009904710 29.09.2009 AU,EP-2010819730; US-13498427; CA-2774577; AU-2010302939; IN-2100/CHENP/2012; CN-201080043574.7
WO2019143614,PCT/US2019/013657,15.01.2019,WO/2019/143614,25.07.2019,WO,"SYSTEMS, METHODS, AND APPARATUSES FOR PROVIDING ASSISTANT DEEP LINKS TO EFFECTUATE THIRD-PARTY DIALOG SESSION TRANSFERS","Methods, apparatus, systems, and computer-readable media are provided for transferring dialog sessions between devices using deep links. The dialog sessions can correspond to interactions, mediated by an automated assistant, between a user and a third party application. During the dialog session, a user can request that the dialog session be transferred to a different device, for example, to interact with the third party application through a different modality. In response, the automated assistant and/or the third party application can generate a link that can be transferred to the transferee device to allow the transferee device to seamlessly take over the dialog session. In this way, computational resources and electrical power can be preserved by not requiring a recipient device to re-process natural language inputs previously provided during the dialog session.",G06F 17/22; G06F 17/27,GOOGLE LLC,"LEWIS, Justin; DAVIES, Scott","62/617,796 16.01.2018 US",EP-2019704479
EP231575395,18162282,16.03.2018,3385839,10.10.2018,EP,METHOD AND DEVICE FOR GENERATING NATURAL LANGUAGE EXPRESSION BY USING FRAMEWORK,"An electronic device includes a touchscreen display, a wireless communication circuit, a memory storing a framework, and at least one processor. The processor is configured to receive a first event or a second event, to provide the framework with a notification object associated with an event received among the first event and the second event, to parse the notification object to obtain one or more parameters, to select one or more tasks associated with the received event based on at least part of the one or more parameters by using the framework, to select a natural language expression indicating at least one task of the one or more tasks, to provide a user interface including the natural language expression, through the touchscreen display, and to execute the at least one task based at least partly on a user input of the natural language expression provided on the touchscreen display.",G06F 9/451; G06F 3/16; G06F 17/30,SAMSUNG ELECTRONICS CO LTD,LEE JAE YONG; UM TAE KWANG; KU HAN JUN; PARK SUNG PA; YEO JAE YUNG; LEE DA SOM; JEON YONG JOON,20170044302 05.04.2017 KR,
WO2016001043,PCT/EP2015/064318,25.06.2015,WO/2016/001043,07.01.2016,WO,METHOD AND APPARATUS FOR PROVIDING ACTIVITY-BASED MAP JOBS,"An approach is provided for validating crowd-sourced information. The approach includes processing and/or facilitating a processing of map error data to generate at least one map job and at least one activity context associated with the at least one map job, the map error data, or a combination thereof. The approach also includes determining one or more devices based, at least in part, on the at least one activity context. Further, the approach includes causing, at least in part, a transmission of the at least one map job to the one or more devices for resolving one or more map errors indicated in the at least one map job, the map error data, or a combination thereof.",G06Q 10/10; G06Q 50/00; G01C 21/32; G06F 17/30; G09B 29/10,HERE GLOBAL B.V.,"HOHS, Cory; RICHTER, Jan Peter; FINK, Oliver; TJIE, Sian-Kit; MARIONI, Reno; HERMANN, Nicol; OTERO, Priscila","14/322,361 02.07.2014 US",
WO2011008262,PCT/US2010/001955,13.07.2010,WO/2011/008262,20.01.2011,WO,METHODS AND APPARATUS FOR DIAGNOSIS AND/OR PROGNOSIS OF CANCER,"The subject invention concerns methods for the detection, diagnosis, and/or prognosis of cancer by analyzing centrosomal features. In one embodiment, a method includes receiving an image of one or more cells; selecting a region of interest in one cell; segmenting the region of interest to delineate at least one centrosomal; extracting one or more features from the segmented image; and analyzing the extracted features to diagnose cancer. In another embodiment, the progression of cancer can be predicted through analysis and classification of the extracted features. In one embodiment, the method can be performed by a quantitative cancer analysis system including a diagnosis module and/or a prognosis module. In one embodiment, the method can be performed using an image processing system.",G01N 33/483; G01N 33/15; C40B 30/06; A61B 10/00; G01N 33/574,"H. LEE MOFFITT CANCER CENTER & RESEARCH INSTITUTE; ZHUKOV, Tatyana, A.; SONG, Dansheng; TOCKMAN, Melvyn, S.","ZHUKOV, Tatyana, A.; SONG, Dansheng; TOCKMAN, Melvyn, S.","61/225,003 13.07.2009 US",US-13383801
WO2018091963,PCT/IB2017/001411,21.11.2017,WO/2018/091963,24.05.2018,WO,CONTEXTUALLY AWARE SYSTEM AND METHOD,A method of analysing an image the image transmitted from a local image acquisition device to a local image processor; the local image processor processing the image locally in order to define at least one context descriptor relevant to a scene contained in the image.,G06K 9/62,"POLY AI, INC.","RIZZOLI, Alberto; EDWARDSSON, Simon",2016904758 21.11.2016 AU,
EP232545762,18161853,14.03.2018,3396590,31.10.2018,EP,SYNCHRONIZATION OF IMAGE DATA FROM MULTIPLE THREE-DIMENSIONAL CAMERAS FOR IMAGE RECOGNITION,"Methods, systems, and computer programs are presented for object recognition performed by electronic devices. One method includes an operation for capturing three-dimensional (3D) images of a region over a surface using 3D cameras, the surface having a pattern and each 3D camera defining a respective camera coordinate system. For each camera, the 3D image is analyzed to identify a location of the pattern indicating an origin of a common coordinate system, and a coordinate transformation function is defined to convert data to the common coordinate system. Each 3D camera captures a 3D object image of an object on the surface that includes 3D object data. Further, the 3D object data is transformed to the common coordinate system to obtain transformed 3D object data. The 3D object data is combined to obtain a composite 3D object data, and object recognition of the object is performed based on the composite 3D object data.",G06K 9/00; A47F 9/04; G01B 11/245; G03B 37/04; G06K 9/32; G06Q 20/20; G06T 7/33; G06T 7/521; G06T 7/593; G07G 1/00; H04N 5/341,MASHGIN INC,SRIVASTAVA ABHINAI; DHANKHAR MUKUL,201715497730 26.04.2017 US,
WO1997036256,PCT/US1997/003266,04.03.1997,WO/1997/036256,02.10.1997,WO,PATTERN RECOGNITION EMPLOYING ARBITRARY SEGMENTATION AND COMPOUND PROBABILISTIC EVALUATION,"A pattern recognition system classifies images of patterns in which the definition of individual features of the pattern may have become blurred. The image is segmented into pieces of arbitrary size and shape, and various combinations are examined to determine those which represent the most likely segmentation of the pattern into its individual features. These individual features are then classified, according to known techniques. Through the use of a second order Markov model, not all possible combinations of pieces need to be examined, to determine the best ones. Rather, the examination of various combinations is limited in accordance with previously determined information, to thereby render the process more efficient. By combining multiple, independently determined probabilities, the accuracy of the overall operation is enhanced.",G06K 9/34,CAERE CORPORATION,"BOKSER, Mindy; PON, Leonard; YANG, Jun; CHOY, Kenneth","08/622,988 27.03.1996 US",EP-1997908814
WO2019226406,PCT/US2019/032077,14.05.2019,WO/2019/226406,28.11.2019,WO,DYNAMIC EXTRACTION OF CONTEXTUALLY-COHERENT TEXT BLOCKS,"Disclosed are techniques for providing dynamic identification and extraction or tagging of contextually-coherent text blocks from an electronic document. An electronic document can be parsed into content tokens that each corresponds to a portion of the electronic document, such as a sentence or a paragraph. Employing a sliding window approach, a number of token groups are independently analyzed, where each group has a corresponding number of tokens included therein. Each token group is analyzed to determine confidence scores for various determinable contexts based on content included therein. The confidence scores can be processed for each token group to determine an entropy score. In this way, one of the analyzed token groups can be selected as a representative text block that corresponds to one of the plurality of determinable contexts. A corresponding portion of the electronic document can be tagged with a corresponding determined context and provided for output.",G06F 17/27,"MICROSOFT TECHNOLOGY LICENSING, LLC","ASI, Abedelkader; IZHAKI-ALLERHAND, Liron; MIZRACHI, Ran; RONEN, Royi; JASSIN, Ohad","15/990,405 25.05.2018 US",
EP231425647,17205847,07.12.2017,3382949,03.10.2018,EP,SMART CONTROLLING DEVICE AND METHOD OF CONTROLLING THEREFOR,"The present specification relates to a smart controlling device capable of utilizing machine learning for voice recognition and a method of controlling therefor. The smart controlling device according to the present invention includes a receiver configured to receive (S802) an input including a command trigger, and a controller configured to detect (S806) one or more external display devices, select a display device of the detected one or more external display devices, cause a power status of the selected display device to be changed to a first state (S816), and cause a response data corresponding to a first command data received after the command trigger to be output on a display of the selected display device (S822). Preferably, the received input corresponds to a first voice input and the controller obtains a first location of a speaker of the first voice input. Moreover, the controller selects the display device from the detected one or more external display devices based on at least the first location of the speaker or a location of the smart controlling device based on an attribute of the command trigger, an attribute of the first command data, an attribute of the response data, a location of a source of the received input, a direction of the source of the received input, an attribute of the selected display device, a display size of the selected display device, or a current power status of the selected display device. The smart controlling device is capable of recognizing an input signal, preferaby a voice input signal, analyzing the recognized input signal, and performing an operation corresponding to the input signal. The speaker of the input signal is provided with an adaptive response based on an event such as a status of the speaker, and the like, using a display of an adjacent device. The smart controlling device is part of a digital system including various devices connected via a home network.The display device may be a digital TV or a mobile terminal.",H04L 12/28; G10L 15/22,LG ELECTRONICS INC,JEONG GYUHYEOK,20170039299 28.03.2017 KR,
WO2017189286,PCT/US2017/028229,19.04.2017,WO/2017/189286,02.11.2017,WO,DYNAMIC SPEECH RECOGNITION DATA EVALUATION,"Computing devices and methods for providing speech recognition data from one computing device to another device are disclosed. In one disclosed embodiment, audio input is received at a client device and processed to generate speech recognition data. An estimated confidence level is determined for a portion of the data, where the confidence level exceeds a predetermined confidence threshold corresponding to a valid result. At least one statistically improbable characteristic associated with the portion of data is identified. Based on identifying the statistically improbable characteristic, the portion of data is provided to a server computing device for evaluation.",G10L 15/32; G10L 15/30; G10L 15/16; G10L 15/02,"MICROSOFT TECHNOLOGY LICENSING, LLC","LOVITT, Andrew William","15/140,704 28.04.2016 US",CN-201780026332.9; EP-2017723174
WO1999038149,PCT/US1999/001454,25.01.1999,WO/1999/038149,29.07.1999,WO,METHOD AND APPARATUS FOR INTEGRATING MANUAL INPUT,"Apparatus and methods are disclosed for simultaneously tracking multiple finger (202-204) and palm (206, 207) contacts as hands approach, touch, and slide across a proximity-sensing, compliant, and flexible multi-touch surface (2). The surface consists of compressible cushion (32), dielectric electrode (33), and circuitry layers. A simple proximity transduction circuit is placed under each electrode to maximize the signal-to-noise ratio and to reduce wiring complexity. Scanning and signal offset removal on electrode array produces low-noise proximity images. Segmentation processing of each proximity image constructs a group of electrodes corresponding to each distinguishable contacts and extracts shape, position and surface proximity features for each group. Groups in successive images which correspond to the same hand contact are linked by a persistent path tracker (245) which also detects individual contact touchdown and liftoff.  Classification of intuitive hand configurations and motions enables unprecedented integration of typing, resting, pointing, scrolling, 3D manipulation, and handwriting into a versatile, ergonomic computer input device.",G06F 3/044; G06F 3/03; G06F 3/041; G06F 3/0481; G06F 3/0484; G06F 3/0485; G06F 3/0488; G06K 9/00; G06T 7/20; G09G 5/00,"WESTERMAN, Wayne; ELIAS, John, G.","WESTERMAN, Wayne; ELIAS, John, G.","60/072,509 26.01.1998 US; 09/236,513 25.01.1999 US",AU-24673/99; CA-2318815; EP-2006016858; JP-2000528974; EP-2006016833; KR-1020007008121; EP-2006016830; EP-2010010057; EP-2006016832; EP-2010010058; EP-1999904228; EP-2006016831; EP-2010010056; IL-137478; EP-2006016855; EP-2006016856; EP-2006016857
WO2019171128,PCT/IB2018/051422,06.03.2018,WO/2019/171128,12.09.2019,WO,"IN-MEDIA AND WITH CONTROLS ADVERTISEMENT, EPHEMERAL, ACTIONABLE AND MULTI PAGE PHOTO FILTERS ON PHOTO, AUTOMATED INTEGRATION OF EXTERNAL CONTENTS, AUTOMATED FEED SCROLLING, TEMPLATE BASED ADVERTISEMENT POST AND ACTIONS AND REACTION CONTROLS ON RECOGNIZED OBJECTS IN PHOTO OR VIDEO","Described are various embodiments of system and method for a contextual and non-obstructed advertisement or contents in photo, image, video, media, post, and message. In one embodiment, a system and method are provided to present contextual advertisement on/with/overlays on user actions and reactions controls based on triggering of one or more types of events on interacted controls, interfaces, objects, contents, browser and device. In one embodiment, a system and method are provided to present recognized objects in photo or video associated actions and reactions controls including like button to enable viewing user to take one or more actions or reactions on recognized objects in photo or video including like particular object associated item, accessories, cloth, body part, place, scene, infrastructure, food item, product by clicking or tapping on object associated like button or icon. In one embodiment, a system and method are provided wherein user can intelligently manage auto viewing of feed items or posts or one or more types of contents. In one embodiment automated integration of external contents with user generated contents based on viewing user's one or more types of data. In one embodiment automated integration of external ephemeral contents with user generated contents based on viewing user's one or more types of data. In one embodiment automated integration of photo filters with user generated contents including actionable photo filters, advertisement photo filters and content item photo filters. In one embodiment enabling to select first set of photo filters and enable to select second set of photo filters for same photo and displaying first set of photo filters and in the event of swipe on photo or expiration of associated vie duration timer, displaying second set of photo filters on photo. In one embodiment enabling ephemeral photo filters. In one embodiment enabling template based advertisement post or content post.",G06F 15/16; G06F 17/30; G06Q 30/02; H04L 29/06,"RATHOD, Yogesh Chunilal","RATHOD, Yogesh Chunilal",,
EP214285030,16306245,28.09.2016,3301891,04.04.2018,EP,MOBILE DEVICE AND METHOD FOR DETERMINING ITS CONTEXT,"According to a first aspect of the present disclosure, a mobile device (100) is provided, comprising: a motion sensor (102) configured to detect one or more movements of the mobile device (100); an audio sensor (104) configured to capture one or more audio signals; a processing unit (106) configured to determine a context of the mobile device (100) in dependence on at least one movement detected by the motion sensor (102) and at least one audio signal captured by the audio sensor (104). According to a second aspect of the present disclosure, a corresponding method (200) for determining a context of a mobile device (100) is conceived. According to a third aspect of the present disclosure, a corresponding computer program is provided.",H04M 1/725; G10L 25/48; H04M 1/60; H04W 4/02; H04W 24/00; H04W 48/04; H04W 52/02; H04W 64/00,NXP BV,TORRES RAFAEL; BATTAGLINO DANIELE; LEPAULOUX LUDOVICK,16306245 28.09.2016 EP,
WO2001048729,PCT/US2000/034682,21.12.2000,WO/2001/048729,05.07.2001,WO,"SYSTEM, METHOD AND APPARATUS FOR PATTERN RECOGNITION WITH APPLICATION TO SYMBOL RECOGNITION AND REGENERATION FOR A CALIGRAPHIC DISPLAY","The invention provides a technique for pattern recognition that employs a state machine that incorporates a sequence of table-look-up operations. A sequence of input parameters, derived according to an application-specific algorithm, generates a corresponding sequence of memory addresses for these operations. The memory tables are organized in a hierarchical structure that corresponds to the input sequence. Table data is designed to recognize a specific library of input patterns. An input sequence traces an input-specific path through the memory tables until one of the patterns in the library is recognized (578) or until it is determined that the input sequence is inconsistent with any of the library patterns. For each library pattern, the table data is designed to accommodate the variations in the input values that are specific to the application (e.g., variations due to noise and/or tolerances). Table data can be derived by analysis, simulation, learning or a combination of these methods. The invention can replace neural networks or DSP correlation techniques in real-time applications. It achieves very high performance by comparing the input sequence to all of the patterns in the library simultaneously. The invention can be employed to improve the image quality of a caligraphic display system that uses flat-panel display technology. A method for improving the performance of display systems that employ image memories to refresh a computer generated image is also disclosed.",G06K 9/68; G09G 1/07; G09G 5/39,"HONEYWELL INTERNATIONAL INC.; ANDERSON, Bruce","ANDERSON, Bruce","09/474,667 29.12.1999 US; null 20.12.2000 US",IL-150435; NO-20023094; EP-2000986630; CA-2396009; JP-2001548373; AU-22829/01; NZ-520196; KR-1020027008508
WO2009097558,PCT/US2009/032695,30.01.2009,WO/2009/097558,06.08.2009,WO,FINANCIAL EVENT AND RELATIONSHIP EXTRACTION,"For automated text processing, the inventors devised, among other things, an exemplary system (100) that automatically extracts financial events from various unstructured text based sources, such as press releases and news articles. Extracted events, such as mergers & acquisitions, earnings guidance reports, and actual earnings announcements, are represented as structured data records which can be linked, searched, and displayed and used as a basis for controlling accessing to the source documents and other related financial documents for named entities.",G06F 17/27; G06F 17/30,"THOMSON REUTERS GLOBAL RESOURCES; SCHILDER, Frank; DOZIER, Christopher; KONDADADI, Ravi Kumar","SCHILDER, Frank; DOZIER, Christopher; KONDADADI, Ravi Kumar","61/063,047 30.01.2008 US; 12/341,926 22.12.2008 US",EP-2009706670; CA-2726576
WO2019166301,PCT/EP2019/054228,20.02.2019,WO/2019/166301,06.09.2019,WO,AN IMAGE PROCESSING METHOD AND AN IMAGE PROCESSING SYSTEM,"An image processing method and an image processing system for recognising characters included in an image. A first character recognition unit performs recognition of a first group of characters corresponding to a first region of the image. A measuring unit calculates a confidence measure of the first group of characters. A determination unit determines whether further recognition is to be performed based on the confidence measure. A selection unit selects a second region of the image that includes the first region, if it is determined that further recognition is to be performed. A second character recognition unit performs further recognition of a second group of characters corresponding to the second region of the image.",G06K 9/03; G06K 9/72,CANON EUROPA N.V.,"COLLET, Frédéric; HAUTOT, Jordi; DAUW, Michel",1803262.3 28.02.2018 GB,
WO2013138516,PCT/US2013/031031,13.03.2013,WO/2013/138516,19.09.2013,WO,PUBLISHING PRODUCT INFORMATION,"The present disclosure provides a method and an apparatus for publishing product information. The present disclosure provides a method for publishing product information. Based on a stored search click log of buyers, correlation information between inquiry words and categories in the search click log is calculated. A keyword input by the seller is matched to the inquiry words. The keyword may be a word or a phrase that includes one or more words. If the keyword is matched to at least one inquiry word, at least one category corresponding to the matched inquiry word is obtained based on the correlation information. The product information is stored under one or more categories of the obtained categories. The present techniques improve the accuracy rate of recommended categories to the seller and the return rate of the published product information.",G06F 17/30,ALIBABA GROUP HOLDING LIMITED,"SUN, Li; WU, Zhenyuan; LIN, Feng; TANG, Jiayu",201210069464.9 15.03.2012 CN,EP-2013712996; JP-2015500573
EP14537741,04388077,17.11.2004,1659503,24.05.2006,EP,A database track history,"A computer-implemented method of providing a track history before a database, comprising the steps of: providing in a storage memory, a track history of choice selectable records that each comprises metadata items applicable to identify a data set from a data superset stored in the database; providing a bank of transformers with different choice selectable transformers; wherein a choice selected transformer takes a selected record and transforms the metadata items of the record to application specific metadata according to a syntax determined by the transformer; and activating an application, which accepts the determined syntax, comprising posting the application specific metadata.",G06F 17/30,TARGIT AS,MIDDELFART MORTEN; JENSEN TOMMY,04388077 17.11.2004 EP,
EP241458588,18197984,01.10.2018,3474157,24.04.2019,EP,METHOD OF UPDATING SENTENCE GENERATION MODEL AND SENTENCE GENERATING APPARATUS,The application comprises a processor implemented method of updating sentence generation model and sentence generating apparatus and includes: generating a target sentence corresponding to a source sentence using a first decoding model; calculating reward information associated with the target sentence using a second decoding model configured to generate a sentence in a word order different from a word order of the sentence generated by the first decoding model; and generating an updated sentence generation model by resetting a weight of respective nodes in the first decoding model based on the calculated reward information.,G06F 17/28,SAMSUNG ELECTRONICS CO LTD,LEE HOSHIK; NA HWIDONG,20170133971 16.10.2017 KR,
WO2019046307,PCT/US2018/048353,28.08.2018,WO/2019/046307,07.03.2019,WO,SYSTEM AND METHOD FOR ISOLATING AND ANALYZING CELLS,"A system and method for isolating and analyzing single cells, wherein the system includes: an array of wells defined at a substrate, each well including an open surface and a well cavity configured to capture cells in one of a single-cell format and single-cluster format, and a fluid delivery module including a fluid reservoir superior to the array of wells through which fluid flow is controlled along a fluid path in a direction parallel to the broad face of the substrate; and wherein the method includes: distributing a population of cells and a population of non-cell particles across the array of wells through the fluid reservoir to increase capture efficiency of individual cell-particle pairs within the array of wells, and processing the captured cell-particle pairs at the set of wells.",B01L 3/00; G01N 33/00; G01N 33/06; G01N 30/26,"CELSEE DIAGNOSTICS, INC.","HANDIQUE, Kalyan; SHARMA, Vishal; GOGOI, Priyadarshini; CHOW, William; PAYNE, Austin; BONIFACE, Brian; GLEASON, Kyle; CONNOLLY, John; TUCK, Sam","62/671,750 15.05.2018 US; 62/551,575 29.08.2017 US",EP-2018850411; AU-2018323449
WO2012167359,PCT/CA2012/000550,05.06.2012,WO/2012/167359,13.12.2012,WO,"METHOD, SYSTEM AND AGGREGATION ENGINE FOR PROVIDING STRUCTURAL REPRESENTATIONS OF PHYSICAL ENTITIES","The present disclosure relates to a method a system and an aggregation engine for providing a structural representation of a physical entity. Processing units provide representation of elements composing the physical entity. Processing units comprise a label, which represent the elements, and a state. Links are established between the processing units. By iteration in the aggregation engine, the states and labels of the processing units are updated based on states and labels of linked processing units. A graphical representation of the physical entity is obtained based on the labels, on the states, and on the links.",G06K 9/00; G06F 7/00,"ROUAT, Jean; BERGERON, Jocelyn; CARON, Louis-Charles; DE LADURANTAYE, Vincent; MAILHOT, Frédéric; SOCPRA SCIENCES ET GÉNIE, S.E.C.","ROUAT, Jean; BERGERON, Jocelyn; CARON, Louis-Charles; DE LADURANTAYE, Vincent; MAILHOT, Frédéric","61/493,672 06.06.2011 US",US-14123895; CA-2835701
WO2000038134,PCT/US1999/002652,08.02.1999,WO/2000/038134,29.06.2000,WO,"A SYSTEM, METHOD AND ARTICLE OF MANUFACTURE FOR A GOAL BASED SYSTEM UTILIZING A SPREADSHEET ARCHITECTURE",A system is disclosed that provides a goal based learning system utilizing a rule based expert training system to provide a cognitive educational experience. The system provides the user with a simulated environment that presents a business opportunity to understand and solve optimally. Mistakes are noted and remedial educational material presented dynamically to build the necessary skills that a user requires for success in the business endeavor. The system utilizes an artificial intelligence engine driving individualized and dynamic feedback with synchronized video and graphics used to simulate real-world environment and interactions. Multiple 'correct' answers are integrated into the learning system to allow individualized learning experiences in which navigation through the system is at a pace controlled by the learner. A robust business model provides support for realistic activities and allows a user to experience real world consequences for their actions and decisions and entails realtime decision-making and synthesis of the educational material. The system is architected around a spreadsheet input to manage and control the system.,G06F 17/24; G09B 7/04,"ACCENTURE PROPERTIES (2) B.V.; BERTRAND, Benoit, Patrick; WILLS, Kerry, Russell","BERTRAND, Benoit, Patrick; WILLS, Kerry, Russell","09/219,086 22.12.1998 US",US-09868693; EP-1999906797
WO2015155770,PCT/IL2015/050372,02.04.2015,WO/2015/155770,15.10.2015,WO,IMAGE ANALYSIS IN THE PRESENCE OF A MEDICAL DEVICE,"Apparatus and methods are described for use with an image of at least one blood vessel (50) of a subject including, using at least one computer processor (28), determining a presence of a device (55) within at least a portion of the blood vessel within the image. The computer processor determines a classification of the device as a given type of device, and, based upon the classification of the device as the given type of device, designates a parameter to be calculated. The computer processor automatically calculates the designated parameter, and generates an output on an output device (40) in response to the calculated parameter. Other applications are also described.",G06K 9/00,"SYNC-RX, LTD.","KLAIMAN, Eldad; STEINBERG, Alexander; KARMON, Nili; SEMO, Sarit; COHEN, Ran","61/977,891 10.04.2014 US",EP-2015776785; JP-2017504293; EP-2016203990
EP13398881,00301288,18.02.2000,1033663,06.09.2000,EP,Apparatus and method for generating processor usable data from natural input data,Processing apparatus generates data in a processor usable form from input data in the form of units in a natural language in which the units are of a plurality of different categories. Input data is categorised into respective categories to generate processor usable data units comprising unit identification data and corresponding unit category data. This is input to a cascaded plurality of matching processing stages. A first of the matching processing stages matches the unit category data with at least one predetermined pattern of unit category data and outputs group category data for any unit category data found to match each predetermined pattern of unit category data. Each subsequent matching processing stage of this cascade uses any unmatched unit category data and group category data from at least one previous matching processing stage of the cascade in place of matched category data to match the unit and/or group category data with at least one predetermined pattern of unit and/or group category data. New group category data is output for any unit and/or group category found to match each predetermined pattern of unit and/or group category data. At least one of the matching processing stages is operable to output unit data corresponding to matched unit category data as a plurality of variables. At least one of these variables is indexed by another of the variables. <IMAGE>,G06F 17/30; G06F 17/27,CANON KK,ELWORTHY DAVID,9904663 01.03.1999 GB,
WO2019056257,PCT/CN2017/102680,21.09.2017,WO/2019/056257,28.03.2019,WO,"APPARATUS, METHOD AND COMPUTER PROGRAM PRODUCT FOR BIOMETRIC RECOGNITION","Method, apparatus, computer program product and computer readable medium are disclosed for biometric recognition. The method may comprise obtaining first biometric data, wherein the first biometric data is captured in first condition or non-first condition; determining, by a discriminative network of generative adversarial networks, whether the first biometric data is captured in the first condition or non-first condition; in response to a determination that the first biometric data is captured in the non-first condition, inputting the first biometric data to a generative network of the generative adversarial networks to generate a second biometric data; obtaining a matching result by inputting the first biometric data in response to a determination that the first biometric data is captured in the first condition or the second biometric data to a matching network; and determining a recognition result based on the matching result.",G06F 21/32; H04L 29/08; G06N 3/02,"NOKIA TECHNOLOGIES OY; NOKIA TECHNOLOGIES (BEIJING) CO., LTD.","LI, Yazhao",,
WO2016191304,PCT/US2016/033618,20.05.2016,WO/2016/191304,01.12.2016,WO,"DIRECTIONAL TWO-DIMENSIONAL ROUTER AND INTERCONNECTION NETWORK FOR FIELD PROGRAMMABLE GATE ARRAYS, AND OTHER CIRCUITS, AND APPLICATIONS OF THE ROUTER AND NETWORK","A configurable directional 2D router for Networks on Chips (NOCs) is disclosed. The router, which may be bufferless, is designed for implementation in programmable logic in FPGAs, and achieves theoretical lower bounds on FPGA resource consumption for various applications. The router employs an FPGA router switch design that consumes only one 6-LUT or 8-input ALM logic cell per router per bit of router link width. A NOC comprising a plurality of routers may be configured as a directional 2D torus, or in diverse ways, network sizes and topologies, data widths, routing functions, performance-energy tradeoffs, and other options. System on chip designs may employ a plurality of NOCs with different configuration parameters to customize the system to the application or workload characteristics. A great diversity of NOC client cores, for communication amongst various external interfaces and devices, and on-chip interfaces and resources, may be coupled to a router in order to efficiently communicate with other NOC client cores. The router and NOC enable feasible FPGA implementation of large integrated systems on chips, interconnecting hundreds of client cores over high bandwidth links, including compute and accelerator cores, industry standard IP cores, DRAM/HBM/HMC channels, PCI Express channels, and 10G/25G/40G/100G/400G networks.",H04L 12/933; H04L 12/931,GRAY RESEARCH LLC,"GRAY, Jan","62/165,774 22.05.2015 US; 14/986,532 31.12.2015 US; 62/274,745 04.01.2016 US; 62/307,330 11.03.2016 US",EP-2016726752
WO2014145018,PCT/US2014/029654,14.03.2014,WO/2014/145018,18.09.2014,WO,ACTIVE VEHICLE SUSPENSION IMPROVEMENTS,"A method of on-demand energy delivery to an active suspension system comprising an actuator body, hydraulic pump, electric motor, plurality of sensors, energy storage facility, and controller is provided. The method comprises disposing an active suspension system in a vehicle between a wheel mount and a vehicle body, detecting a wheel event requiring control of the active suspension; and sourcing energy from the energy storage facility and delivering it to the electric motor in response to the wheel event.",A61M 1/00; A61M 1/10; F16H 61/42,LEVANT POWER CORPORATION,"ANDERSON, Zackary, M.; AVADHANY, Shakeel; COLE, Matthew, D.; DRISCOLL, Robert; GIARRATANA, John; GIOVANARDI, Marco; GORELIK, Vladimir; LEEHEY, Jonathan, R.; NEAR, William, G.; NEIL, Patrick, W.; O'SHEA, Colin, Patrick; SAWYER, Tyson, David; SCHNEIDER, Johannes; TUCKER, Clive; WENDELL, Ross, J.; ZUCKERMAN, Richard, Anthony","61/913,644 09.12.2013 US; 61/789,600 15.03.2013 US; 61/815,251 23.04.2013 US; 61/865,970 14.08.2013 US",EP-2014763789
WO2019079842,PCT/AU2018/000207,26.10.2018,WO/2019/079842,02.05.2019,WO,METHOD OF UNDERSTANDING THE PROCESS OF HUMAN THINKING,"A method of understanding the process of thinking of a person in relation to said person making decisions on a particular subject, the method including the steps of using a geometric figure (10) having designated elements at vertices of the geometric figure (10) to develop a matrix (190, 200) that identifies and establishes meamngfui relationships between said designated elements by the person in making said decisions, said decisions being made in response to a sequential set of questions or required actions, and providing a temporal frame of reference that gives context to the sequence of questions or required actions.",G06Q 30/02; G09B 7/00; A61B 5/16; G06Q 10/00,GOOROO VENTURES LIMITED,"BENJAMIN, Colin Gabriel",2017904332 26.10.2017 AU,
WO1991009275,PCT/US1990/007183,10.12.1990,WO/1991/009275,27.06.1991,WO,"INTEGRATED VEHICLE POSITIONING AND NAVIGATION SYSTEM, APPARATUS AND METHOD","Systems and methods for positioning and navigating an autonomous vehicle (102, 310) allow the vehicle (102, 310) to travel between locations. A first position estimate (112) of the vehicle (102, 310) is derived from satellites (132-170, 200-206) of a global positioning system (100A) and/or a pseudolite(s) (105). The pseudolite(s) (105) may be used exclusively when the satellites (132-170, 200-206) are not in view of the vehicle (102, 310). A second position estimate (114) is derived from an inertial reference unit (904) and/or a vehicle odometer (902). The first and second position estimates are combined and filtered to derive a third position estimate (118). Navigation of the vehicle (102, 310) is obtained using the position information (414), obstacle detection and avoidance data (416), and on board vehicle data (908, 910).",B60K 31/00; B60K 31/04; G01C 21/16; G01S 1/00; G01S 5/00; G01S 5/14; G01S 17/93; G05D 1/02; G08G 1/0968; G08G 1/127,CATERPILLAR INC.,"KYRTSOS, Christos, T.; GUDAT, Adam, J.; CHRISTENSEN, Dana, A.; FRIEDRICH, Douglas, W.; STAFFORD, Darrell, E.; SENNOTT, James, W.; BRADBURY, Walter, J.; CLOW, Richard, G.; DEVIER, Lonnie, J.; KEMNER, Carl, A.; KLEIMENHAGEN, Karl, W.; KOEHRSEN, Craig, L.; LAY, Norman, K.; PETERSON, Joel, L.; RAO, Prithvi, N.; SCHMIDT, Larry, E.; SHAFFER, Gary, K.; SHI, WenFan; SHIN, Dong Hun; SINGH, Sanjiv, J.; WEINBECK, Louis, J.; WEST, Jay, H.; WHITTAKER, William, L.; WU, BaoXin",PCT/US89/05580 11.12.1989 AT,CA-2071831; EP-1991902277
WO2019185245,PCT/EP2019/054229,20.02.2019,WO/2019/185245,03.10.2019,WO,AN IMAGE PROCESSING SYSTEM AND AN IMAGE PROCESSING METHOD,"An image processing system and an image processing method for localising recognised characters in an image. An estimation means is configured to estimate a first location of a recognised character that has been obtained by performing character recognition of the image. A determination means is configured to determine second locations of a plurality of connected components in the image. A comparison means is configured to compare the first location and the second locations, to identify a connected component associated with the recognised character. An association means is configured to associate the recognised character, the identified connected component, and the second location of the identified connected component.",G06K 9/00; G06K 9/32; G06K 9/34; G06K 9/03,CANON EUROPA N.V.,"COLLET, Frédéric; HAUTOT, Jordi; DAUW, Michel",1805039.3 28.03.2018 GB,
WO2004044585,PCT/CA2003/001757,14.11.2003,WO/2004/044585,27.05.2004,WO,METHOD OF IMMOBILIZING MEMBRANE-ASSOCIATED MOLECULES,The present invention relates to methods of immobilizing membrane-associated molecules within a sol-gel matrix. The membrane-associated molecule is embedded in the bilayer of a liposome. The molecule-liposome assembly remains functionally intact when it is immobilized within a protein and membrane-compatible sol-gel derived from polyol silane precursors or sodium silicate.,G01N 33/543; G01N 33/552; G01N 33/68,"MCMASTER UNIVERSITY; BRENNAN, John, D.; BROOK, Michael, A.; BESANGER, Travis","BRENNAN, John, D.; BROOK, Michael, A.; BESANGER, Travis","60/426,018 14.11.2002 US; 2,411,827 14.11.2002 CA",EP-2003810928; JP-null
WO2003079971,PCT/US2002/040574,18.12.2002,WO/2003/079971,02.10.2003,WO,QUANTUM DYNAMIC DISCRIMINATOR FOR MOLECULAR AGENTS,"The disclosed invention (fig. 5.2) is related to the field of quantum dynamic discriminators, sample identification systems, mass spectrometers and methods for identifying a component in a composition. Also disclosed are quantum dynamic discriminators and methods for ascertaining the quantum dynamic states of a component in a composition. Optimal identification devices and methods for ascertaining quantum Hamiltonians of quantum systems are further disclosed.",G05D 11/00; G06N 3/12,TRUSTEES OF PRINCETON UNIVERSITY; WAYNE STATE UNIVERSITY,"HERSCHEL, Rabitz; SCHREIBER, Elmar; LEVIS, Robert, J.",PCT/US02/06516 04.03.2002 US,EP-2005075109; JP-2003577804; EP-2002807124
WO2010008722,PCT/US2009/047413,15.06.2009,WO/2010/008722,21.01.2010,WO,CAPTCHA SYSTEM OPTIMIZED FOR DISTINGUISHING BETWEEN HUMANS AND MACHINES,An audible based electronic challenge system is used to control access to a computing resource by using a test to identify an origin of a voice. The test is based on analyzing a spoken utterance using optimized challenge items selected for their discrimination capability to determine if it was articulated by an unauthorized human or a text to speech (TTS) system.,G06F 15/00,"GROSS, John, Nicholas","GROSS, John, Nicholas","12/484,837 15.06.2009 US; 12/484,800 15.06.2009 US; 61/074,979 23.06.2008 US; 12/484,870 15.06.2009 US",
EP14834085,07013320,16.03.2001,1852789,07.11.2007,EP,Priorities generation and management,"The present invention relates to a system and methodology to enable a plurality of information associated with electronic messages, for example, to be automatically prioritized by a priorities system for transmittal to a user or system. The priorities system can employ classifiers that can be explicitly and/or implicitly trained to prioritize one or more received messages according to a learned importance to the user. As an example, messages can be classified as high, medium, low or other degrees of importance via a training set of examples or types of messages having similar degrees of importance. A background monitor can be provided to monitor a user's activities regarding message processing to further refine or tune the classifier according to the user's personal decisions relating to message importance. Other priorities classifications can involve determinations relating to a loss associated with a time for delayed review or processing of the message.",G06F 17/30; G06F 13/00; G06Q 10/00; H04L 12/58,MICROSOFT CORP,HORVITZ ERIC J; HOVEL DAVID O; JACOBS ANDREW W; KADIE CARL M,01920508 16.03.2001 EP; 18980100 16.03.2000 US; 25501600 12.12.2000 US; 59634800 17.06.2000 US; 59636400 17.06.2000 US; 59636500 17.06.2000 US,
WO2014108866,PCT/IB2014/058194,11.01.2014,WO/2014/108866,17.07.2014,WO,PROCESS OF HANDWRITING RECOGNITION AND RELATED APPARATUS,"Process, and related apparatus, that exploits psycho-physiological aspects involved in generation and perception of handwriting for directly inferring from the trace on the paper (or any other means on which the author writes by hand) the interpretation of writing, i.e. the sequence of characters that the trace is intended to represent.",G06K 9/00; G06K 9/34; G06K 9/62; G06K 9/72,NATURAL INTELLIGENT TECHNOLOGIES S.R.L.,"MARCELLI, Angelo; SANTORO, Adolfo; DE STEFANO, Claudio; PARZIALE, Antonio; SENATORE, Rosa",RM2013A000022 11.01.2013 IT,IL-239834; EP-2014706082; US-14760236
WO2018157329,PCT/CN2017/075317,01.03.2017,WO/2018/157329,07.09.2018,WO,PROVIDING CONTENT,The present disclosure provides method and apparatus for providing content in an electrical game. Current interface information of the electrical game may be obtained. Content associated with the electrical game may be provided in a chat flow based on at least the current interface information.,G06F 3/048; G06F 17/28,"MICROSOFT TECHNOLOGY LICENSING, LLC; WU, Xianchao","WU, Xianchao",,CN-201780029269.4; EP-2017899009
EP275492905,17884719,22.12.2017,3561490,30.10.2019,EP,DATA CREATION METHOD AND DATA USE METHOD,"Provided is a data creation method which includes: an autofluorescence data generation step for generating autofluorescence data that includes intensity data and/or spectrum data of autofluorescence light, by disposing the focal point of light of a prescribed wavelength at a single set of coordinates on a prescribed focal plane, irradiating a sample positioned at the coordinates with excitation light comprising light, and thereby acquiring autofluorescence light originating from the sample; a reflected light data generation step for generating intensity data of reflected light by acquiring reflected light dispersed by the sample by irradiating the single set of coordinates on the prescribed focal plane with irradiation light; and a correspondence data generation step for creating correspondence data in which the autofluorescence data at the single set of coordinates on the prescribed focal plane and the reflected light data are associated.",G01N 21/64; C12Q 1/68; G01N 33/50,UNIV TSUKUBA,NOMURA NOBUHIKO; YAWATA YUTAKA; KIYOKAWA TATSUNORI,2016249896 22.12.2016 JP; 2017047414 22.12.2017 JP,
WO2016118672,PCT/US2016/014196,20.01.2016,WO/2016/118672,28.07.2016,WO,REAL TIME MACHINE VISION AND POINT-CLOUD ANALYSIS FOR REMOTE SENSING AND VEHICLE CONTROL,"Methods and apparatus for real time machine vision and point-cloud data analysis are provided, for remote sensing and vehicle control. Point cloud data can be analyzed via scalable, centralized, cloud computing systems for extraction of asset information and generation of semantic maps. A data storage / preprocessor (1220) subdivides a data set for streaming to a distributed processing unit (1240) and operation via data analysis mechanisms (1250). The output of the processing unit (1240) is aggregated by a map generator (1230). Machine learning components can optimize data analysis mechanisms to improve asset and feature extraction from sensor data. Optimized data analysis mechanisms can be downloaded to vehicles for use in on-board systems analyzing vehicle sensor data. Semantic map data can be used locally in vehicles, along with onboard sensors, to derive precise vehicle localization and provide input to vehicle to control systems.",G06K 9/00,"SOLFICE RESEARCH, INC.","CHRAIM, Fabien; PUTTAGUNTA, Shanmukha; GUPTA, Anuj; HARVEY, Scott; CREADORE, Jason; MILLS, Graham","62/105,696 20.01.2015 US",JP-2017556798
WO2019195344,PCT/US2019/025460,02.04.2019,WO/2019/195344,10.10.2019,WO,COMPLEX HUMAN GUT MICROBIOME CULTURED IN AN ANAEROBIC HUMAN GUT-ON-A-CHIP,"A microfluidic device is directed to sustaining a complex microbial community in direct and indirect contact with living human intestinal cells in vitro. The device includes a first microchannel having cultured cells of a human intestinal epithelium and microbiota, the first microchannel further having a first level of oxygen. The device further includes a second microchannel having cultured cells of a vascular endothelium, the second microchannel further having a second level of oxygen. The device also includes a membrane located at an interface region between the first microchannel and the second microchannel, the membrane being composed of an oxygen-permeable material or further having pores via which oxygen flows between the first microchannel and the second microchannel to form a physiologically-relevant oxygen gradient.",C12M 1/12; C12M 3/06; G01N 33/48; G01N 33/50,PRESIDENT AND FELLOWS OF HARVARD COLLEGE,"NOVAK, Richard; JALILI-FIROOZINEZHAD, Sasan; GAZZANIGA, Francesca, S.; CALAMARI, Elizabeth, L.; CAMACHO, Diogo, M.; NESTOR, Bret, A.; FADEL, Cicely; CRONCE, Michael, L.; KASPER, Dennis, L.; INGBER, Donald, E.; BEIN, Amir","62/651,438 02.04.2018 US; 62/722,658 24.08.2018 US",
EP14294382,04015374,30.06.2004,1522594,13.04.2005,EP,Methods and kits for investigating cancer,"The invention provides novel compositions, methods and uses, for the prediction, diagnosis, prognosis, prevention and treatment of malignant neoplasia and breast cancer. The invention further relates to genes that are differentially expressed in breast tissue of breast cancer patients versus those of normal ""healthy"" tissue. Differentially expressed genes for the identification of patients which are likely to respond to chemotherapy are also provided.",C12Q 1/68; G01N 33/50; G01N 33/574,BAYER HEALTHCARE AG,MUNNES MARC DR; BOJAR HANS PROF DR,03022587 06.10.2003 EP; 04015374 30.06.2004 EP,
WO2002073204,PCT/GB2002/001125,12.03.2002,WO/2002/073204,19.09.2002,WO,CELL-BASED DETECTION AND DIFFERENTIATION OF DISEASE STATES,"The present invention provides a method for detecting and differentiating disease states with high sensitivity and specificity. The method allows for a determination of whether a cell-based sample contains abnormal cells and, for certain diseases, is capable of determining the histologic type of disease present. The method detects changes in the level and pattern of expression of the molecular markers in the cell-based sample. Panel selection and validation procedures are also provided.",G01N 33/569; G01N 33/574,"MONOGEN, INC; MCCALL, John, Douglas","PRESSMAN, Norman, J.; HIRSCH, Kenneth, S.","60/274,638 12.03.2001 US",CA-2440753; EP-2002708460; JP-2002572414; NZ-528205; IL-157872; ZA-200307121; KR-1020037011975; IN-01462/DELNP/2003; ZA-2003/07121; AU-2002242823; CN-02809759.9
WO2010129074,PCT/US2010/020991,14.01.2010,WO/2010/129074,11.11.2010,WO,SYSTEM AND METHOD FOR IDENTIFYING A PERSON WITH REFERENCE TO A SCLERA IMAGE,"A method for obtaining an identification characteristic for a subject includes acquiring an image of an eye of the subject, segmenting the eye image into different regions, extracting features in a sclera region segmented from the eye image, and generating data identifying at least one feature extracted from the sclera region of the eye image.",G06K 9/00,"INDIANA UNIVERSITY RESEARCH & TECHNOLOGY CORPORATION; WUDUNN, Darrell; THOMAS, N., Luke; DU, Yingzi","WUDUNN, Darrell; THOMAS, N., Luke; DU, Yingzi","61/260,451 12.11.2009 US; 61/144,508 14.01.2009 US",US-13144517
WO2002103555,PCT/GB2002/002742,12.06.2002,WO/2002/103555,27.12.2002,WO,COMPUTER SYSTEM WITH NATURAL LANGUAGE TO MACHINE LANGUAGE TRANSLATOR,Presented is a system and method for converting or translating expressions in a natural language such as English into machine executable expression in a formal language. This translation enables a transformation from the syntactic structures of a natural language into effective algebraic forms for further exact processing. The invention utilizes algorithms employing a reduction of sequences of terms defined over an extensible lexicon into formal syntactic and semantic structures. This term reduction incorporates both syntactic type and semantic context to achieve an effective formal representation and interpretation of the meaning conveyed by any natural language expression.,G06F 17/28,"PIPEDREAM METASYSTEMS, INC.; MANSON, Keith, S.; HOWE, Steven","MANSON, Keith, S.","09/883,693 18.06.2001 US",JP-null; EP-2002732949
WO2005119260,PCT/EP2005/005787,30.05.2005,WO/2005/119260,15.12.2005,WO,METHODS FOR PREDICTING AND MONITORING RESPONSE TO CANCER THERAPY,"The invention provides novel compositions, methods and uses, for the prediction, diagnosis, prognosis, prevention and treatment of malignant neoplasia and breast cancer. The invention further relates to genes that are differentially expressed in breast tissue of breast cancer patients versus those of normal 'healthy' tissue. Differentially expressed genes for the identification of patients which are likely to respond to chemotherapy are also provided.",C12Q 1/68; G01N 33/574,"BAYER HEALTHCARE AG; MUNNES, Marc; MODLICH, Olga; PRIESACK, Hans-Bernd","MUNNES, Marc; MODLICH, Olga; PRIESACK, Hans-Bernd",04013107.0 03.06.2004 EP,JP-2007513829; DE-null; EP-2005745597; CA-2568732
WO2014000130,PCT/CN2012/000904,29.06.2012,WO/2014/000130,03.01.2014,WO,METHOD OR SYSTEM FOR AUTOMATED EXTRACTION OF HYPER-LOCAL EVENTS FROM ONE OR MORE WEB PAGES,Methods and systems are provided that may be utilized to extract hyper-local event information from one or more web pages.,G06F 17/30,"YAHOO! INC.; LONG, Chong; LI, Xin; ZHENG, Zhaohui; Selvaraj, Sathiya Keerthi; GENG, Xiubo","LONG, Chong; LI, Xin; ZHENG, Zhaohui; Selvaraj, Sathiya Keerthi; GENG, Xiubo",,US-13695774
WO2018053502,PCT/US2017/052251,19.09.2017,WO/2018/053502,22.03.2018,WO,SYSTEMS AND METHODS FOR ADAPTIVE PROPER NAME ENTITY RECOGNITION AND UNDERSTANDING,"Various embodiments contemplate systems and methods for performing automatic speech recognition (ASR) and natural language understanding (NLU) that enable high accuracy recognition and understanding of freely spoken utterances which may contain proper names and similar entities. The proper name entities may contain or be comprised wholly of words that are not present in the vocabularies of these systems as normally constituted. Recognition of the other words in the utterances in question, e.g. words that are not part of the proper name entities, may occur at regular, high recognition accuracy. Various embodiments provide as output not only accurately transcribed running text of the complete utterance, but also a symbolic representation of the meaning of the input, including appropriate symbolic representations of proper name entities, adequate to allow a computer system to respond appropriately to the spoken request without further analysis of the user's input.",G10L 15/02; G10L 15/18; G10L 15/19; G10L 15/22; G06F 17/27; G01C 21/36,PROMPTU SYSTEMS CORPORATION,"PRINTZ, Harry, William","15/269,924 19.09.2016 US",AU-2017326987; EP-2017851782; CA-3036998
WO2006047614,PCT/US2005/038623,26.10.2005,WO/2006/047614,04.05.2006,WO,COMPOSITIONS AND METHODS FOR ANALYZING BIOMOLECULES USING MASS SPECTROSCOPY,"Compositions and methods for mass spectroscopy are disclosed. The compositions and methods relate to the analysis of proteins and other biopolymers using mass spectroscopy, particularly matrix-assisted laser desorption time-of-flight mass spectrometry (MALDI-TOF MS).",G01N 33/48,"INVITROGEN CORPORATION; POPE, Robert Marshall; LEITE, Jon; HAJIVANDI, Mahbod; SHEVLIN, Charles George; UPDYKE, Timothy","POPE, Robert Marshall; LEITE, Jon; HAJIVANDI, Mahbod; SHEVLIN, Charles George; UPDYKE, Timothy","60/621,686 26.10.2004 US; 60/621,685 26.10.2004 US; 60/669,373 08.04.2005 US; 60/685,869 01.06.2005 US",
WO2019217910,PCT/US2019/031850,10.05.2019,WO/2019/217910,14.11.2019,WO,GENOME-WIDE CLASSIFIERS FOR DETECTION OF SUBACUTE TRANSPLANT REJECTION AND OTHER TRANSPLANT CONDITIONS,This disclosure provides methods of detecting sub-acute rejection and other categories of rejection in kidney transplant recipients using unique sets of gene expression markers.,C12Q 1/6837; C12Q 1/6876; G01N 33/68,THE SCRIPPS RESEARCH INSTITUTE; NORTHWESTERN UNIVERSITY,"KURIAN, Sunil, M.; ABECASSIS, Michael, M.; FRIEDEWALD, John, J.","62/669,518 10.05.2018 US",
WO2019084510,PCT/US2018/057870,26.10.2018,WO/2019/084510,02.05.2019,WO,REAL-TIME MONITORED MOBILE DEVICE SECURITY,"A system and apparatus provide mobile device and data protection by establishing a user identifier, signature, or fingerprint in response to monitoring distances or proximities between two or more of a users devices. A devices relative location or proximity to the user and to other devices is measured and tracked in real time to provide better device security, content protection and loss prevention. A processor of the device tracks one or more conditions indicative of wireless connectivity between one or more auxiliary devices and the mobile device, monitors whether the mobile computing device is operating within the one or more conditions, and controls operation of the mobile computing device to enforce security policies, based on the monitoring.",G06F 17/30; G06F 21/71; G06F 21/60; H04L 9/32; H04L 29/06; H04W 12/08,"HENDEL, Guy","HENDEL, Guy","62/577,797 27.10.2017 US",
WO2010114641,PCT/US2010/023113,03.02.2010,WO/2010/114641,07.10.2010,WO,METHOD AND SYSTEM FOR DETECTION OF TOOL PERFORMANCE DEGRADATION AND MISMATCH,"Autonomous biologically based learning tool system(s) and method(s) that the tool system(s) employs for learning and analysis of performance degradation and mismatch are provided. The autonomous biologically based learning tool system includes (a) one or more tool systems that perform a set of specific tasks or processes and generate assets and data related to the assets that characterize the various processes and associated tool performance; (b) an interaction manager that receives and formats the data, and (c) an autonomous learning system based on biological principles of learning. Objectively generated knowledge gleaned from synthetic or production data can be utilized to determine a mathematical relationship among a specific output variable and a set of associated influencing variables. The generated relationship facilitates assessment of performance degradation of a set of tools, and performance mismatch among tools therein.",G06F 15/18,"TOKYO ELECTRON LIMITED; KAUSHAL, Sanjeev; PATEL, Sukesh, J.; SUGISHIMA, Kenji","KAUSHAL, Sanjeev; PATEL, Sukesh, J.; SUGISHIMA, Kenji","12/416,018 31.03.2009 US",CN-201080024664.1; KR-1020117025734; JP-2012503438
WO2018107181,PCT/US2017/065654,11.12.2017,WO/2018/107181,14.06.2018,WO,METHODS AND SYSTEMS FOR DIAGNOSIS OF POST-TRAUMATIC STRESS DISORDER,"The present invention relates to a method of detecting PTSD in a subject comprising measurement and analysis of brain wave patterns from a subject and determination of a value for one or more neuromarkers from the brain wave pattern. The present invention additionally relates to a system that can be used to diagnose the presence or severity of PTSD in a subject, and to a computer program product for detecting PTSD in a subject by determining if the value of the one or more neuromarkers is above a designated threshold, or is increased or decreased relative to a control value. The invention can also be used to track recovery during and following PTSD therapy, and also as a means for predicting response to therapy and the potential for relapse.",A61B 5/00; A61B 5/08; A61B 5/16; A61B 5/0478; A61N 2/00,THE UNITED STATES OF AMERICA AS REPRESENTED BY THE DEPARTMENT OF VETERANS AFFAIRS,"MODARRES, Mo","62/432,526 09.12.2016 US",
WO2017070322,PCT/US2016/057875,20.10.2016,WO/2017/070322,27.04.2017,WO,CONTROLLED AND PRECISE TREATMENT OF CARDIAC TISSUES,"Systems, devices, and methods for performing precise treatment, mapping, and/or testing of tissues are disclosed. Systems, devices, and methods for administering an agent to one or more a precise regions within a tissue mass are disclosed. Systems, devices, and methods for treating targeted regions within a tissue mass are disclosed. Systems, devices, and methods for identifying, localizing, monitoring neural traffic in the vicinity of, quantifying neural traffic in the vicinity of, and mapping neural traffic near targeted regions within a tissue mass are disclosed.",A61B 5/04; A61B 5/0408; A61B 5/1473; A61B 18/14,"TOTH, Landy","SCHWARTZ, Robert, S.","62/244,322 21.10.2015 US",EP-2016858201; US-15769184
WO2000051066,PCT/US2000/000743,12.01.2000,WO/2000/051066,31.08.2000,WO,MINIMALLY INVASIVE APPARATUS AND METHOD FOR TESTING LESIONS OF THE ORAL CAVITY AND SIMILAR EPITHELIUM,A sample of an epithelial lesion which may be keratinized is disclosed in which an analytical system including an imaging system is provided to detect precancerous and cancerous cells. A transepithelial non-lacerational brush produces sufficient cells from all three layers of the epithelium so that an analytical system comprising a programmed computer can detect which cells exhibit abnormal keratinization and require further examination because of a likely suspicion of said pre-cancerous and cancerous conditions. The method and system can apply to the diagnosis of non-cancerous conditions as well.,A61B 10/00; G01N 15/00; G01N 15/10; G01N 15/14; G06T 7/00,"ORALSCAN LABORATORIES, INC.; EISEN, Drore; FRIST, Stephen; RECHT, Joel","EISEN, Drore; FRIST, Stephen; RECHT, Joel","60/121,255 23.02.1999 US; 09/298,219 23.04.1999 US; 09/298,218 23.04.1999 US",JP-2000601597; CA-2363833; EP-2000902395; IL-144933; AU-24120/00; IN-IN/PCT/2001/00959/MUM; CN-00804023.0
WO2006085984,PCT/US2005/024491,11.07.2005,WO/2006/085984,17.08.2006,WO,IMMUNE CELL BIOSENSORS AND METHODS OF USING SAME,"The present invention relates to immunological cells that are useful in detecting changes in physiological states, which provide for methods of diagnosing diseases or monitoring the course of patient therapy. Also provided are arrays of antigen presenting cell-specific markers for detecting changes in physiological states, and methods of detecting such changes.",G01N 33/68; G01N 33/53; G06F 19/00; C07K 1/04,"AMAOX, INC.; SMITH, Milton, G.; CRAWFORD, Krith, D.","SMITH, Milton, G.; CRAWFORD, Krith, D.","60/586,546 09.07.2004 US; 60/612,454 23.09.2004 US; 60/613,733 28.09.2004 US; 60/614,924 29.09.2004 US",US-11631574; JP-2007520583; EP-2005856874; AU-2005327199; CA-2614507; DE-null
WO2018038888,PCT/US2017/045123,02.08.2017,WO/2018/038888,01.03.2018,WO,HOTWORD DETECTION ON MULTIPLE DEVICES,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for hotword detection on multiple devices are disclosed. Innovative aspects of the subject matter described in this specification reduce the use of computing resources when more than one device is near a user when the user speaks a hotword. In one aspect, a method includes the actions of receiving audio data that corresponds to an utterance. The actions further include determining that the utterance likely includes a particular, predefined hotword. The actions further include transmitting (i) data indicating that the computing device likely received the particular, predefined hotword, (ii) data identifying the computing device, and (iii) data identifying a group of nearby computing devices. The actions further include receiving an instruction to commence speech recognition. The actions further include processing at least a portion of the audio data using an automated speech recognizer on the computing device.",G10L 15/22,GOOGLE LLC,"CASADO, Diego Melendo; GRUENSTEIN, Alexander H.; FOERSTER, Jakob Nicolaus","62/378,869 24.08.2016 US; 15/278,269 28.09.2016 US",CN-201780052132.0; EP-2017751221
WO2008005281,PCT/US2007/015025,28.06.2007,WO/2008/005281,10.01.2008,WO,GENES ASSOCIATED WITH CHEMOTHERAPY RESPONSE AND USES THEREOF,"The invention provides molecular markers that are associated with responsiveness of a cancer patient to a chemotherapy treatment, and methods and computer systems for determining such responsiveness based on measurements of these molecular markers. The present invention also provides methods and compositions for enhancing the efficacy of chemotherapies in patients by modulating the expression or activity of genes encoding these molecular markers and/or their encoded proteins.",C12N 15/11; C12Q 1/68; G06F 19/18; G06F 19/20,"ROSETTA INPHARMATICS LLC; MERCK & CO., INC.; DAI, Hongyue; ZHANG, Chunsheng; LOBODA, Andrey","DAI, Hongyue; ZHANG, Chunsheng; LOBODA, Andrey","60/818,262 30.06.2006 US",US-12307114
WO2006119086,PCT/US2006/016387,27.04.2006,WO/2006/119086,09.11.2006,WO,METHODS AND APPARATUS FOR ENABLING A DYNAMIC NETWORK OF INTERACTORS ACCORDING TO PERSONAL TRUST LEVELS BETWEEN INTERACTORS,"A system for causing routing of a communication event includes a sending platform for initiating and sending the communication event, a communications network for carrying the communication event, a receiving platform for receiving the communication event for final routing, and a router resident at least in the receiving platform for preparing and executing or forwarding for execution a routing instruction for handling the incoming communication event or notification thereof, the routing instruction thus executed, overriding a default routing instruction, the overriding routing instruction initiated upon discovery by the router of some level of trust metric between the sender and intended recipient of the event.",G06F 15/173,"FORTE INTERNET SOFTWARE, INC.; BECK, Christopher, Clemmett, Macleod; SIDELL, Mark, Franklin; GOLD, Thomas, Knox; POWERS, James, Karl; KNUFF, Charles, Dazler","BECK, Christopher, Clemmett, Macleod; SIDELL, Mark, Franklin; GOLD, Thomas, Knox; POWERS, James, Karl; KNUFF, Charles, Dazler","60/677,141 02.05.2005 US; 11/237,269 27.09.2005 US",EP-2006758768; RU-null; AU-2006242410; CA-2605767; DE-null
WO2009134482,PCT/US2009/032413,29.01.2009,WO/2009/134482,05.11.2009,WO,RECOGNITION VIA HIGH-DIMENSIONAL DATA CLASSIFICATION,"A method is disclosed for recognition of high-dimensional data in the presence of occlusion, including: receiving a target data that includes an occlusion and is of an unknown class, wherein the target data includes a known object; sampling a plurality of training data files comprising a plurality of distinct classes of the same object as that of the target data; and identifying the class of the target data through linear superposition of the sampled training data files using ℓ1 minimization, wherein a linear superposition with a sparsest number of coefficients is used to identify the class of the target data.",G06T 7/00,"THE BOARD OF TRUSTEES OF THE UNIVERSITY OF ILLINOIS; MA, Yi; YANG, Allen, Yang; WRIGHT, John, Norbert; WAGNER, Andrew, William","MA, Yi; YANG, Allen, Yang; WRIGHT, John, Norbert; WAGNER, Andrew, William","61/025,039 31.01.2008 US",US-12865639; CN-200980000494.0
WO2012112315,PCT/US2012/023739,03.02.2012,WO/2012/112315,23.08.2012,WO,METHODS FOR DIAGNOSIS OF KAWASAKI DISEASE,"Methods for diagnosis of Kawasaki disease (KD) are disclosed. In particular, the invention relates to the use of biomarkers for aiding diagnosis, prognosis, and treatment of KD, and more specifically to biomarkers that can be used to distinguish KD from other inflammatory diseases, including infectious illness and acute febrile illness.",G01N 33/48; G01N 33/53,"THE BOARD OF TRUSTEES OF THE LELAND STANFORD JUNIOR
UNIVERSITY; THE REGENTS OF THE UNIVERSITY OF CALIFORNIA; COHEN, Harvey, J.; BURNS, Jane, C.; WHITIN, John, C.; LING, Xuefeng, B.; SCHILLING, James","COHEN, Harvey, J.; BURNS, Jane, C.; WHITIN, John, C.; LING, Xuefeng, B.; SCHILLING, James","61/444,735 20.02.2011 US; 61/567,321 06.12.2011 US",
WO2010065940,PCT/US2009/066895,04.12.2009,WO/2010/065940,10.06.2010,WO,MATERIALS AND METHODS FOR DETERMINING DIAGNOSIS AND PROGNOSIS OF PROSTATE CANCER,Materials and methods related to diagnosing and/or determining prognosis of prostate cancer.,G01N 33/50; C12Q 1/68; G01N 33/574,"THE REGENTS OF THE UNIVERSITY OF CALIFORNIA; MCCLELLAND, Michael; WANG, YiPeng; MERCOLA, Daniel","MCCLELLAND, Michael; WANG, YiPeng; MERCOLA, Daniel","61/119,996 04.12.2008 US",EP-2009831251; US-13132878; CN-200980156188.6; CA-2745961
EP14891026,07022919,30.06.2004,1892306,27.02.2008,EP,Methods and kits for investigating cancer,"The invention provides novel compositions, methods and uses, for the prediction, diagnosis, prognosis, prevention and treatment of malignant neoplasia and breast cancer. The invention further relates to genes that are differentially expressed in breast tissue of breast cancer patients versus those of normal ""healthy"" tissue. Differentially expressed genes for the identification of patients which are likely to respond to chemotherapy are also provided.",C12Q 1/68; G01N 33/50; G01N 33/574,BAYER HEALTHCARE AG,MUNNES MARC DR; BOJAR HANS PROF DR,03022587 06.10.2003 EP; 04015374 30.06.2004 EP; 07022919 30.06.2004 EP,
WO2002065318,PCT/US2002/004683,15.02.2002,WO/2002/065318,22.08.2002,WO,A SYSTEM AND PROCESS FOR CREATING A VIRTUAL STAGE AND PRESENTING ENHANCED CONTENT VIA THE VIRTUAL STAGE,"A system and process for creating a Virtual Stage on a client device and presenting Enhanced Content on the Virtual Stage is provided. The Virtual Stage (08) is preferably implemented on a Browser (802) or similarly equipped presentation device. The Virtual Stage enables any presentation device to receive Enhanced Content from any provider regardless of the capabilities of the Browser or client device, the data format of the Enhanced Content, and/or the communications medium utilized to communicate the Enhanced Content to the Browser or client device. The Virtual Stage suitably includes an abstracted Show Object  (816) which provides a framework for presenting the Enhanced Content and an abstracted Receiver Object  (824) which provides a receiver for communicating with the Enhanced Content provider  (826) and receiving the Enhanced Content. Alternative embodiment may also include multiple abstracted Receiver Objects and/or abstracted Subscribers, which facilitates communications with subscription service provider systems, including, but not limited to, chat service systems.",G06F 17/30; G06F 9/46; H04L 29/06; H04L 29/08; H04N 21/235; H04N 21/258; H04N 21/43; H04N 21/435; H04N 21/443; H04N 21/475; H04N 21/4788; H04N 21/488; H04N 21/81; H04N 21/8543; H04N 21/858,"ACTV, INC.","ABATO, Michael, Raymond","60/269,592 15.02.2001 US; 10/076,689 14.02.2002 US",CA-2437810; JP-null; GB-GB0319138.4; EP-2002721024
WO2002054171,PCT/US2001/047922,06.12.2001,WO/2002/054171,11.07.2002,WO,"SYSTEM, METHOD, SOFTWARE ARCHITECTURE AND BUSINESS MODEL FOR AN INTELLIGENT OBJECT BASED INFORMATION TECHNOLOGY PLATFORM","The intelligent object based information technology platform provides a structure to access incompatible applications and data.Intelligent molecular objects (IMOs 200) form a data structure that takes data such as external data (493) and converts tha data to intelligent data that is capable of being functionally untergraded. The IMOs are stored in intelligent object pools (204). An intellugent object handler unifies applications (2020) and provides a framawork to functionally integrate diverse applications (495,495) and data (493) through access interface (2022).",G06F 17/30,"BIOSENTIENTS, INC.; STANLEY, Robert, A.; GOMBOCZ, Erich, A.","STANLEY, Robert, A.; GOMBOCZ, Erich, A.","60/254,063 06.12.2000 US; 60/254,062 06.12.2000 US; 60/254,064 06.12.2000 US; 60/259,050 29.12.2000 US; 60/246,238 25.01.2001 US; 60/266,957 06.02.2001 US; 60/276,711 16.03.2001 US; 60/282,656 09.04.2001 US; 60/282,658 09.04.2001 US; 60/282,654 09.04.2001 US; 60/282,657 09.04.2001 US; 60/282,655 09.04.2001 US; 60/282,979 10.04.2001 US; 60/282,989 10.04.2001 US; 60/282,991 10.04.2001 US; 60/282,990 10.04.2001 US",JP-null; EP-2001991011
WO1997036247,PCT/US1997/004844,25.03.1997,WO/1997/036247,02.10.1997,WO,AUTONOMOUS DECISION SYSTEMS,"Disclosed are autonomous decision systems which include means for determining relevance, i.e., the threats to and opportunities of the autonomous decision system as shown in the figure. Also disclosed are such autonomous decision systems of the figure constructed and arranged to interact comfortably with humans (not shown), including the use of natural languages. The desired 'whether concrete is included in abstract' computation system of the figure is enhanced by a system of categorizing natural objects using as primitives a set of self tendencies (not shown) suitable, when hierarchically assigned to objects, to do incremental simulation of 'future' situations (including such objects) from a presented situation.",G06F 15/18; G06Q 10/06,"STONEMAN, Martin, L.","STONEMAN, Martin, L.","08/621,426 25.03.1996 US",
WO2016145426,PCT/US2016/022233,12.03.2016,WO/2016/145426,15.09.2016,WO,METHODS FOR DIAGNOSIS OF SEPSIS,"Methods for diagnosis of sepsis are disclosed. In particular, the invention relates to the use of biomarkers for aiding diagnosis, prognosis, and treatment of sepsis, and to a panel of biomarkers that can be used to distinguish sepsis from noninfectious sources of inflammation, such as caused by traumatic injury, surgery, autoimmune disease, thrombosis, or systemic inflammatory response syndrome (SIRS).",C12Q 1/68; C40B 40/08; C12N 15/11; G06F 19/20,THE BOARD OF TRUSTEES OF THE LELAND STANFORD JUNIOR UNIVERSITY,"KHATRI, Purvesh; SWEENEY, Timothy, E.","62/132,293 12.03.2015 US",CA-2977422; JP-2017546801; EP-2016762690; US-15526306; IL-254229; AU-2016228508
WO2004027093,PCT/GB2003/004041,19.09.2003,WO/2004/027093,01.04.2004,WO,MOLECULAR ARRAYS AND SINGLE MOLECULE DETECTION,"Methods are provided for producing a molecular array comprising a plurality of molecules immobilised to a solid substrate at a density which allows individual immobilised molecules to be individually resolved, wherein each individual molecule in the array is spatially addressable and the identity of each molecule is known or determined prior to immobilisation. The use of spatially addressable low density molecular arrays in single molecule detection techniques is also provided.",B01J 19/00; C12M 1/34; C12Q 1/68; G01N 33/53,"THE CHANCELLOR, MASTER AND SCHOLARS OF THE UNIVERSITY OF OXFORD; MIR, Kalim","MIR, Kalim",0221792.5 19.09.2002 GB; 0222412.9 26.09.2002 GB,EP-2003748275; US-11085679; JP-null; EP-2010075556
WO2000074394,PCT/IL2000/000314,31.05.2000,WO/2000/074394,07.12.2000,WO,INTERACTIVE APPLICATION GENERATION SYSTEM AND TEXT PROCESSING SYSTEM,"A method for generating an application, the method including providing a plurality of components [5], each component defining an application building block [10], storing based on non-programming user input [45], a plurality of user-defined application-specific properties, each the property being associated with one of the plurality of components [65], receiving structured data input via a questionnaire [15] based at least in the part on the plurality of components, generating text based [30], at least in part, on the structured data, the generating text including dynamic runtime generation of a plurality of simple sentences from a plurality of sub-sentence segment based, at least in part, on user input, and providing an application based on at least some of the plurality of user-defined application-specific properties and on the components associated therewith. Related apparatus and methods are also provided.",G06F 17/28,"MAIMONIDES INNOVATIVE TECHNOLOGIES LTD.; BENTWICH, Isaac","BENTWICH, Isaac","60/136,932 01.06.1999 US; 09/410,455 01.10.1999 US",JP-2001500566; EP-2000931518
WO2002020846,PCT/US2001/028040,07.09.2001,WO/2002/020846,14.03.2002,WO,SCREENING METHODS TO IDENTIFY COMPOUNDS THAT MODULATE A RESPONSE OF A CELL TO ULTRAVIOLET RADIATION EXPOSURE,"The cellular response to ultraviolet radiation exposure has been characterized on the molecular level through the use of high density gene array technology. Nucleic acid molecules and protein molecules, the expression of which are repressed or induced in response to ultraviolet radiation exposure, are identified according to a temporal pattern of altered expression post ultraviolet radiation exposure. Methods are disclosed that utilized these ultraviolet radiation-regulated molecules as markers for ultraviolet radiation exposure. Other screening methods of the invention are designed for the idenfication of compounds that modulate the response of a cell to ultraviolet radiation exposure. The invention also provides compositions useful for drug screening or pharmaceutical purposes.",C12Q 1/68; G01N 33/50,NEW YORK UNIVERSITY,"BLUMENBERG, Miroslav","60/231,454 08.09.2000 US",AU-2001290658; JP-2002525851; CA-2419983; EP-2001970677
WO2011059997,PCT/US2010/056109,10.11.2010,WO/2011/059997,19.05.2011,WO,SYSTEM AND METHOD FOR PROVIDING A NATURAL LANGUAGE CONTENT DEDICATION SERVICE,"The system and method described herein may provide a natural language content dedication service in a voice services environment. In particular, providing the natural language content dedication service may generally include detecting multi-modal device interactions that include requests to dedicate content, identifying the content requested for dedication from natural language utterances included in the multi-modal device interactions, processing transactions for the content requested for dedication, processing natural language to customize the content for recipients of the dedications, and delivering the customized content to the recipients of the dedications.",G06F 17/27,"VOICEBOX TECHNOLOGIES, INC.; KENNEWICK, Mike; ARMSTRONG, Lynn, Elise","KENNEWICK, Mike; ARMSTRONG, Lynn, Elise","61/259,820 10.11.2009 US",
EP13023633,96931598,13.09.1996,0853679,22.07.1998,EP,EXPRESSION MONITORING BY HYBRIDIZATION TO HIGH DENSITY OLIGONUCLEOTIDE ARRAYS,"This invention provides methods of monitoring the expression levels of a multiplicity of genes. The methods involve hybridizing a nucleic acid sample to a high density array of oligonucleotide probes where the high density array contains oligonucleotide probes complementary to subsequences of target nucleic acids in the nucleic acid sample. In one embodiment, the method involves providing a pool of target nucleic acids comprising RNA transcripts of one or more target genes, or nucleic acids derived from the RNA transcripts, hybridizing said pool of nucleic acids to an array of oligonucleotide probes immobilized on surface, where the array comprising more than 100 different oligonucleotides and each different oligonucleotide is localized in a predetermined region of the surface, the density of the different oligonucleotides is greater than about 60 different oligonucleotides per 1 cm?2¿, and the oligonucleotide probes are complementary to the RNA transcripts or nucleic acids derived from the RNA transcripts; and quantifying the hybridized nucleic acids in the array.",C07H 21/04; C12Q 1/68; G01N 33/53; C12N 15/09; C12Q 1/68; G01N 15/14; G01N 37/00,AFFYMETRIX INC A DELAWARE CORP,LOCKHART DAVID J; BROWN EUGENE L; WONG GORDON; CHEE MARK; GINGERAS THOMAS R; MITTMANN MICHAEL P; LIPSHUTZ ROBERT J; FODOR STEPHEN P A; WANG CHUNWEI,52911595 15.09.1995 US; 9614839 13.09.1996 US,
EP13959512,02025530,13.11.2002,1326189,09.07.2003,EP,"Controls and displays for acquiring preferences, inspecting behaviour, and guiding the learning and decision policies of an adaptive communications prioritization and routing systems",The present invention relates to a system and methodology to enable a plurality of information associated with electronic messages to be automatically prioritized by a message urgency system for transmittal to a user or system. The message urgency system can employ classifiers that can be explicitly and/or implicitly trained to prioritize or triage one or more received messages according to a learned importance to the user. An adaptable and configurable graphical user interface is provided in order to manage the prioritized information. The interface facilitates system personalization according to user desires of how messages are received and subsequently processed by the user. Display and input adjustments are provided in a plurality of selectable pages to enable the personalization of the system. <IMAGE>,G06F 17/30; G06F 13/00; G06Q 10/00; G06Q 30/00; H04L 12/58,MICROSOFT CORP,HORVITZ ERIC J; BARIBAULT GREGORY P,2162101 12.12.2001 US,
WO2004039489,PCT/IB2003/005574,31.10.2003,WO/2004/039489,13.05.2004,WO,"COMPUTER PROGRAMS,WORKSTATIONS, SYSTEMS AND METHODS FOR MICROFLUIDIC SUBSTRATES IN CELL","The invention provides computer program products for coordinating the movement of cells and other components in a microfluidic substrate with data acquisition. The microfluidic workstation may be used to examine the physiological responses of ion channels, receptors, neurons, and other cells to fluidic streams. The system may also be useful for screening compound libraries to search for novel classes of compounds, screening members of a given class of compounds for effects on specific ion channel proteins and receptors, and to rapidly determine dose-response curves in cell­based assays.",B01L 3/00; G01N 33/487; G01N 35/00; G01N 35/10,"CELLECTRICON AB; WIGSTROM, Joakim; SINCLAIR, Jon","WIGSTROM, Joakim; SINCLAIR, Jon","60/423,197 01.11.2002 US",JP-null
EP13878224,01920430,16.03.2001,1282855,12.02.2003,EP,SYSTEM AND METHOD FOR ABSTRACTING AND VISUALIZING A ROUTE MAP,A system and method for making computer-generated maps includes a different scale factor for each road in a route (Steps 802-850). The scale factors are used to optimize the route map against a target function. The display of the route map is optimized using fitting a collection of reference points with a probability function that is used to rotate the displayed route map. Display optimization further includes splitting route maps into separate segment maps.,G06T 17/05; G01C 21/36; G06F 7/60; G06F 17/10; G06T 11/20; G06T 11/60,MICROSOFT CORP,AGRAWALA MANEESH; STOLTE CHRIS,528703  ; 727646  ; US20000528703  ; US20000727646  ; US2001008440  ; WO2001US08440  ; 0108440 16.03.2001 US; 52870300 17.03.2000 US; 72764600 30.11.2000 US,
WO2005104772,PCT/US2005/014557,27.04.2005,WO/2005/104772,10.11.2005,WO,SEMANTIC TASK COMPUTING,"Task Computing computer system by segmenting the system into a plurality of implementation tiers of a presentation layer (104), a remote procedure call programming interface (API), a middleware layer (108) to which the presentation layer interfaces via the remote procedure call API to real-time, dynamically generate a computer implemented task interface at the presentation layer to a semantically described source of function as a service on a computer system, and a service layer and a function source realization layer providing the semantically described source of function as the service on the computer system to which the middleware layer interfaces. Real-time and dynamically composing an executable task that comprises one or more services using the generated task interface at the presentation layer to one or more services on the computer based upon the semantically described application-, device- and service-rich computer.",G06F 9/45,"FUJITSU LIMITED; LABROU, Yannis; MASUOUKA, Ryusuke; HUYNH, Duy; SONG, Zhexuan","LABROU, Yannis; MASUOUKA, Ryusuke; HUYNH, Duy; SONG, Zhexuan","60/565,851 28.04.2004 US; 60/603,251 23.08.2004 US; 60/628,557 18.11.2004 US; 60/639,805 29.12.2004 US; 11/115,403 27.04.2005 US",KR-1020067017143; EP-2005739051; JP-2007510963; DE-null; CN-200580013453.7
