Time:,08.05.2020 10:09:33,...3,...4,...5,...6,...7,...8,...9,...10,...11,...12,...13
Query:,AIfunctionalapplicationsNaturalLanguageProcessingMachineTranslation,,,,,,,,,,,
Offices:,"EP,WO",,,,,,,,,,,
SortBy:,Relevance,,,,,,,,,,,
,,,,,,,,,,,,
Application Id,Application Number,Application Date,Publication Number,Publication Date,Country,Title,Abstract,I P C,Applicants,Inventors,Priorities Data,National Phase Entries
WO2018226492,PCT/US2018/035275,31.05.2018,WO/2018/226492,13.12.2018,WO,ASYNCHRONOUS AGENTS WITH LEARNING COACHES AND STRUCTURALLY MODIFYING DEEP NEURAL NETWORKS WITHOUT PERFORMANCE DEGRADATION,"Methods and computer systems improve a trained base deep neural network by structurally changing the base deep neural network to create an updated deep neural network, such that the updated deep neural network has no degradation in performance relative to the base deep neural network on the training data. The updated deep neural network is subsequently training. Also, an asynchronous agent for use in a machine learning system comprises a second machine learning system ML2 that is to be trained to perform some machine learning task. The asynchronous agent further comprises a learning coach LC and an optional data selector machine learning system DS. The purpose of the data selection machine learning system DS is to make the second stage machine learning system ML2 more efficient in its learning (by selecting a set of training data that is smaller but sufficient) and/or more effective (by selecting a set of training data that is focused on an important task). The learning coach LC is a machine learning system that assists the learning of the DS and ML2. Multiple asynchronous agents could also be in communication with each others, each trained and grown asynchronously under the guidance of their respective learning coaches to perform different tasks.",G06N 3/02; G06N 3/08; G06F 15/18; G06F 17/30,D5AI LLC,"BAKER, James K.","62/515,142 05.06.2017 US",EP-2018813951
WO2018212710,PCT/SG2018/050233,15.05.2018,WO/2018/212710,22.11.2018,WO,PREDICTIVE ANALYSIS METHODS AND SYSTEMS,"Methods and systems for predictive analysis are disclosed, A predictive analysis method comprises: receiving a set of predictor variables as an input feature vector comprising a plurality of features; projecting each feature of the input feature vector onto a dense vector representation to obtain a set of embedding vectors presenting the input feature vector in an embedding space; calculating a set of interacted vectors, each interacted vector being an element-wise product of two embedding vectors of the set of embedding vectors; performing a weight sum over the interacted vectors, the weighted sum being weighted by a plurality of attention scores each corresponding to an interaction between a pair of features of the feature vector; and projecting the weighed sum to obtain a prediction score.",G06F 15/18; G06N 7/00; G06N 3/02,NATIONAL UNIVERSITY OF SINGAPORE,"HE, Xiangnan; ZHANG, Hanwang; CHUA, Tat-Seng",10201704115T 19.05.2017 SG,
WO2018213763,PCT/US2018/033487,18.05.2018,WO/2018/213763,22.11.2018,WO,NATURAL LANGUAGE PROCESSING USING CONTEXT-SPECIFIC WORD VECTORS,"A system is provided for natural language processing. In some embodiments, the system includes an encoder for generating context-specific word vectors for at least one input sequence of words. The encoder is pre-trained using training data for performing a first natural language processing task. A neural network performs a second natural language processing task on the at least one input sequence of words using the context-specific word vectors. The first natural language process task is different from the second natural language processing task and the neural network is separately trained from the encoder. In some embodiments, the first natural processing task can be machine translation, and the second natural processing task can be one of sentiment analysis, question classification, entailment classification, and question answering.",G06N 3/04; G06F 17/28,"SALESFORCE.COM, INC.","MCCANN, Bryan; XIONG, Caiming; SOCHER, Richard","62/508,977 19.05.2017 US; 62/536,959 25.07.2017 US; 15/982,841 17.05.2018 US",CN-201880033016.9; CA-3062891; DE-112018002601
WO2017117412,PCT/US2016/069257,29.12.2016,WO/2017/117412,06.07.2017,WO,SYSTEM AND METHOD FOR NEURAL NETWORK BASED FEATURE EXTRACTION FOR ACOUSTIC MODEL DEVELOPMENT,"A system and method are presented for neural network based feature extraction for acoustic model development. A neural network may be used to extract acoustic features from raw MFCCs or the spectrum, which are then used for training acoustic models for speech recognition systems. Feature extraction may be performed by optimizing a cost function used in linear discriminant analysis. General non-linear functions generated by the neural network are used for feature extraction. The transformation may be performed using a cost function from linear discriminant analysis methods which perform linear operations on the MFCCs and generate lower dimensional features for speech recognition. The extracted acoustic features may then be used for training acoustic models for speech recognition systems.",G10L 15/06; G06F 17/27; G06F 17/28; G06N 99/00; G09B 19/04; G10L 13/08,"INTERACTIVE INTELLIGENCE GROUP, INC.","CHELUVARAJA, Srinath; IYER, Ananth Nagaraja","14/985,560 31.12.2015 US",
WO2018175972,PCT/US2018/024155,23.03.2018,WO/2018/175972,27.09.2018,WO,DEVICE PLACEMENT OPTIMIZATION WITH REINFORCEMENT LEARNING,"A method for determining a placement for machine learning model operations across multiple hardware devices is described. The method includes receiving data specifying a machine learning model to be placed for distributed processing on multiple hardware devices; generating, from the data, a sequence of operation embeddings, each operation embedding in the sequence characterizing respective operations necessary to perform the processing of the machine learning model; processing the sequence of operation embeddings using a placement recurrent neural network in accordance with first values of a plurality network parameters of the placement recurrent neural network to generate a network output that defines a placement of the operations characterized by the operation embeddings in the sequence across the plurality of devices; and scheduling the machine learning model for processing by the multiple hardware devices by placing the operations on the multiple devices according to the placement defined by the network output.",G06N 3/10; G06N 3/08; G06N 3/04,GOOGLE LLC,"BENGIO, Samuel; NOROUZI, Mohammad; STEINER, Benoit; DEAN, Jeffrey Adgate; PHAM, Hieu Hy; MIRHOSEINI, Azalia; LE, Quoc V.; KUMAR, Naveen; ZHOU, Yuefeng; LARSEN, Rasmus Munk","62/476,618 24.03.2017 US",KR-1020197026115; EP-2018716863; JP-2019552038; CN-201880011282.1
WO2019099805,PCT/US2018/061487,16.11.2018,WO/2019/099805,23.05.2019,WO,MACHINE-LEANING MODELS BASED ON NON-LOCAL NEURAL NETWORKS,"In one embodiment, a method includes training a baseline machine-learning model based on a neural network comprising a plurality of stages, wherein each stage comprises a plurality of neural blocks, accessing a plurality of training samples comprising: a plurality of content objects, respectively, determining one or more non-local operations, wherein each non-local operation is based on one or more pairwise functions and one or more unary functions, generating one or more non-local blocks based, on the plurality of training samples and the one or more non-local operations, determining a stage from the plurality of stages of the neural network, and training a non-local machine-learning model by inserting each of the one or more non-local blocks in between at least two of the plurality of neural blocks in the determined stage of the neural network.",G06N 3/08; G06N 3/04,"FACEBOOK, INC.","HE, Kaiming; GIRSHICK, Ross; WANG, Xiaolong","62/587,884 17.11.2017 US; 16/192,649 15.11.2018 US",
EP291472780,18207992,23.11.2018,3627398,25.03.2020,EP,"METHOD, SYSTEM, AND COMPUTER PROGRAM FOR ARTIFICIAL INTELLIGENCE ANSWER",Provided is an artificial intelligence (Al) answering system including a user question receiver configured to receive a user question from a user terminal; a first question extender configured to generate a question template by analyzing the user question and determine whether the user question and the generated question template match; a second question extender configured to generate a similar question template by using a natural language processing and a deep learning model when the user question and the generated question template do not match; a training data builder configured to generate training data for training the second question extender by using an neural machine translation (NMT) engine; and a question answering unit configured to transmit a user question result derived through the first question extender or the second question extender to the user terminal.,G06N 3/04; G06N 3/08; G06N 5/04,42 MARU INC,KIM DONG HWAN,20180112488 19.09.2018 KR,
WO2020006495,PCT/US2019/039955,28.06.2019,WO/2020/006495,02.01.2020,WO,DEEP LEARNING-BASED DIAGNOSIS AND REFERRAL OF DISEASES AND DISORDERS USING NATURAL LANGUAGE PROCESSING,Disclosed herein are methods and systems for Artificial Intelligence (AI)-based methods for performing medical diagnosis of diseases and conditions. An automated natural language processing (NLP) system performs deep learning techniques to extract clinically relevant information from electronic health records (EHRs). This framework provides a high diagnostic accuracy that demonstrates a successful AI-based method for systematic disease diagnosis and management.,G06F 17/28; G16H 50/70,AI TECHNOLOGIES INC.; THE REGENTS OF THE UNIVERSITY OF CALIFORNIA,"ZHANG, Kang; LI, Zhihuan; ZHENG, Lianghong","62/692,572 29.06.2018 US; 62/749,612 23.10.2018 US; 62/783,962 21.12.2018 US",
WO2018213841,PCT/US2018/033734,21.05.2018,WO/2018/213841,22.11.2018,WO,MULTI-TASK MULTI-MODAL MACHINE LEARNING MODEL,"Methods, systems, and apparatus, including computer programs encoded on computer storage media for training a machine learning model to perform multiple machine learning tasks from multiple machine learning domains. One system includes a machine learning model that includes multiple input modality neural networks corresponding to respective different modalities and being configured to map received data inputs of the corresponding modality to mapped data inputs from a unified representation space; an encoder neural network configured to process mapped data inputs from the unified representation space to generate respective encoder data outputs; a decoder neural network configured to process encoder data outputs to generate respective decoder data outputs from the unified representation space; and multiple output modality neural networks corresponding to respective different modalities and being configured to map decoder data outputs to data outputs of the corresponding modality.",G06N 3/04; G06N 3/08,GOOGLE LLC,"SHAZEER, Noam M.; GOMEZ, Aidan Nicholas; KAISER, Lukasz Mieczyslaw; USZKOREIT, Jakob D.; JONES, Llion Owen; PARMAR, Niki J.; VASWANI, Ashish Teku","62/509,016 19.05.2017 US",CN-201880028587.3; EP-2018737050
WO2019118455,PCT/US2018/064944,11.12.2018,WO/2019/118455,20.06.2019,WO,SYSTEM AND METHOD FOR THE DETECTION AND REPORTING OF OCCUPATIONAL SAFETY INCIDENTS,"A system and a method for the detection and reporting of occupational safety incidents are disclosed. The system receives a set of digital records corresponding to reported occupational safety incidents. The system converts each of the digital records from the set of digital records into a common digital format. The system deconstructs the uniform text structure of each digital recorded by a natural language processing module to lemmatize words, remove punctuation, and remove stop words. The system creates a feature vector based on the received deconstructed uniform text structure. The system inputs each feature vector to an ensemble machine learning data model, returning a determination of a possible class or characteristic of occupational safety incident. The system applies a threshold based on a probability to the determination of a possible class. The system submits a subset of the reported occupational safety incidents to a third party system.",G06F 17/20; G06F 17/21; G06F 17/27; G06F 17/28; G06N 20/20,"WALMART APOLLO, LLC","FERGUSON, David; BEYENE, Saba; TALLURI, Srinivas; DAVIS, Christopher","62/596,991 11.12.2017 US",
WO2019018332,PCT/US2018/042377,17.07.2018,WO/2019/018332,24.01.2019,WO,HIERARCHICAL DEVICE PLACEMENT WITH REINFORCEMENT LEARNING,"A method for determining a placement for machine learning model operations across multiple hardware devices includes receiving data specifying machine learning operations, and determining a placement that assigns each of the operations specified by the data to a respective device from the multiple hardware devices. Determining the placement includes: generating, from the data, a respective operation embedding for each of the operations; grouping the operations into multiple operation groups, comprising processing each of the respective operation embeddings using a grouper neural network having multiple grouper parameters, in which the grouper neural network is configured to, for each of the operations, process the operation embedding for the operation in accordance with first values of the grouper parameters to generate a grouper output that assigns the operation to an operation group from the multiple operation groups; and assigning each of the operation groups to a respective device from the multiple hardware devices.",G06N 3/04; G06N 3/08; G06F 9/50,GOOGLE LLC,"STEINER, Benoit; GOLDIE, Anna Darling; DEAN, Jeffrey Adgate; PHAM, Hieu Hy; MIRHOSEINI, Azalia; LE, Quoc V.","62/535,790 21.07.2017 US",CN-201880022767.0; EP-2018749968
WO2018093926,PCT/US2017/061839,15.11.2017,WO/2018/093926,24.05.2018,WO,SEMI-SUPERVISED TRAINING OF NEURAL NETWORKS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a neural network. One of the methods includes obtaining a batch of labeled training items and a batch of unlabeled training items; processing the labeled training items and the unlabeled training items using the neural network and in accordance with current values of the network parameters to generate respective embeddings; determining a plurality of similarity values, each similarity value measuring a similarity between the embedding for a respective labeled training item and the embedding for a respective unlabeled training item; determining a respective roundtrip path probability for each of a plurality of roundtrip paths; and performing an iteration of a neural network training procedure to determine a first value update to the current values of the network parameters that decreases roundtrip path probabilities for incorrect roundtrip paths.",G06N 3/08; G06N 3/04,GOOGLE LLC,"HAEUSSER, Philip; MORDVINTSEV, Alexander","62/422,550 15.11.2016 US",CN-201780070359.8
WO2018098442,PCT/US2017/063301,27.11.2017,WO/2018/098442,31.05.2018,WO,GENERATING STRUCTURED TEXT CONTENT USING SPEECH RECOGNITION MODELS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, to generate structured text content using speech recognition models, based on an input acoustic sequence representing one or more utterances. One method includes obtaining an input acoustic sequence, the input acoustic sequence representing one or more utterances; processing the input acoustic sequence using a speech recognition model to generate a transcription of the input acoustic sequence, wherein the speech recognition model comprises a domain-specific language model; and providing the generated transcription of the input acoustic sequence as input to a domain-specific predictive model to generate structured text content that is derived from the transcription of the input acoustic sequence.",G10L 15/26; G10L 15/18; G06F 17/24; G06F 17/28,GOOGLE LLC,"CO, Christopher S.; JAITLY, Navdeep; PENG, Lily Hao Yi; CHOU, Katherine Irene; SANKAR, Ananth","15/362,643 28.11.2016 US",CN-201780073503.3; EP-2017811802
WO2019022779,PCT/US2017/049300,30.08.2017,WO/2019/022779,31.01.2019,WO,SYSTEM AND METHOD FOR PREDICTING AND SUMMARIZING MEDICAL EVENTS FROM ELECTRONIC HEALTH RECORDS,"A system for predicting and summarizing medical events from electronic health records includes a computer memory storing aggregated electronic health records from a multitude of patients of diverse age, health conditions, and demographics including medications, laboratory values, diagnoses, vital signs, and medical notes. The aggregated electronic health records are converted into a single standardized data structure format and ordered arrangement per patient, e.g., into a chronological order. A computer (or computer system) executes one or more deep learning models trained on the aggregated health records to predict one or more future clinical events and summarize pertinent past medical events related to the predicted events on an input electronic health record of a patient having the standardized data structure format and ordered into a chronological order. An electronic device configured with a healthcare provider-facing interface displays the predicted one or more future clinical events and the pertinent past medical events of the patient.",A61B 5/00; G06F 19/00; H04L 29/08,GOOGLE LLC,"CHEN, Kai; SUNDBERG, Patrik; MOSSIN, Alexander; HAJAJ, Nissan; LITSCH, Kurt; WEXLER, James; ZHANG, Yi; ZHANG, Kun; MARCUS, Jacob; OREN, Eyal; YEE, Hector; DEAN, Jeffrey; HARDT, Michaela; IRVINE, Benjamin; WILSON, James; DAI, Andrew; LIU, Peter; SUN, Xiaomi; LE, Quoc; LIU, Xiaobing; RAJKOMAR, Alvin; CORRADO, Gregory; FLORES, Gerardo; CUI, Yingwei; DUGGAN, Gavin","62/538,112 28.07.2017 US",KR-1020197035368; EP-2017919282; CN-201780091414.1
WO2020046807,PCT/US2019/048125,26.08.2019,WO/2020/046807,05.03.2020,WO,CROSS-LINGUAL CLASSIFICATION USING MULTILINGUAL NEURAL MACHINE TRANSLATION,"Training and/or using a multilingual classification neural network model to perform a natural language processing classification task, where the model reuses an encoder portion of a multilingual neural machine translation model. In a variety of implementations, a client device can generate a natural language data stream from a spoken input from a user. The natural language data stream can be applied as input to an encoder portion of the multilingual classification model. The output generated by the encoder portion can be applied as input to a classifier portion of the multilingual classification model. The classifier portion can generate a predicted classification label of the natural language data stream. In many implementations, an output can be generated based on the predicted classification label, and a client device can present the output.",G06N 3/04; G06N 3/08; G06F 17/28,GOOGLE LLC,"JOHNSON PREMKUMAR, Melvin Jose; ERIGUCHI, Akiko; FIRAT, Orhan","62/725,245 30.08.2018 US",
WO2019098573,PCT/KR2018/013061,31.10.2018,WO/2019/098573,23.05.2019,WO,ELECTRONIC DEVICE AND METHOD FOR CHANGING CHATBOT,"An artificial intelligence (AI) system which utilizes machine learning algorithm such as deep learning and application is provided. The artificial intelligence (AI) system includes a controlling method of an electronic device for determining a chatbot using an artificial intelligence learning model includes receiving a voice uttered by a user, processing the voice and acquiring text information corresponding to the voice, and displaying the text information on a chat screen, determining a chatbot for providing a response message regarding the voice by inputting the acquired text information and chat history information regarding the chat screen to a model which is trained to determine the chatbot by inputting text information and chat history information, transmitting the acquired text information and the chat history information regarding the chat screen to a server for providing the determined chatbot, and receiving a response message from the server and displaying the response message on the chat screen.",G06Q 50/30; G06N 99/00,"SAMSUNG ELECTRONICS CO., LTD.","YUN, Ji Hwan; RYU, Won Ho; CHOI, Won Jong",10-2017-0154939 20.11.2017 KR,EP-2018879732
WO2019033381,PCT/CN2017/097979,18.08.2017,WO/2019/033381,21.02.2019,WO,EFFICIENT NEURAL NETWORKS WITH ELABORATE MATRIX STRUCTURES IN MACHINE LEARNING ENVIRONMENTS,"A mechanism is described for facilitating efficient neural networks with elaborate matrix structures in machine learning environments. A method of embodiments, as described herein, includes facilitating selection of one or more paths associated with one or more matrix structures for a neural network associated with deep learning processes performed by a processor of a computing device. The method further includes training the neural network based on the one or more paths and the corresponding one or more matrix structure to facilitate customization of the deep learning processes.",G06N 3/02; G06N 3/08,"INTEL CORPORATION; CHEN, Yurong; LI, Jianguo; NI, Renkun","CHEN, Yurong; LI, Jianguo; NI, Renkun",,
WO2018153806,PCT/EP2018/054000,19.02.2018,WO/2018/153806,30.08.2018,WO,TRAINING MACHINE LEARNING MODELS,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for training a machine learning model. In one aspect, a method includes receiving training data for training the machine learning model on a plurality of tasks, where each task includes multiple batches of training data. A task is selected in accordance with a current task selection policy. A batch of training data is selected from the selected task. The machine learning model is trained on the selected batch of training data to determine updated values of the model parameters. A learning progress measure that represents a progress of the training of the machine learning model as a result of training the machine learning model on the selected batch of training data is determined. The current task selection policy is updated using the learning progress measure.",G06N 3/08; G06N 3/04,DEEPMIND TECHNOLOGIES LIMITED,"GENDRON-BELLEMARE, Marc; MENICK, Jacob Lee; GRAVES, Alexander Benjamin; KAVUKCUOGLU, Koray; MUNOS, Remi","62/463,540 24.02.2017 US",CN-201880013612.0; EP-2018705928
WO2018191344,PCT/US2018/027040,11.04.2018,WO/2018/191344,18.10.2018,WO,NEURAL MACHINE TRANSLATION WITH LATENT TREE ATTENTION,"We introduce an attentional neural machine translation model for the task of machine translation that accomplishes the longstanding goal of natural language processing to take advantage of the hierarchical structure of language without a priori annotation. The model comprises a recurrent neural network grammar (RNNG) encoder with a novel attentional RNNG decoder and applies policy gradient reinforcement learning to induce unsupervised tree structures on both the source sequence and target sequence. When trained on character-level datasets with no explicit segmentation or parse annotation, the model learns a plausible segmentation and shallow parse, obtaining performance close to an attentional baseline.",G06N 3/04,"SALESFORCE.COM, INC.","BRADBURY, James","62/485,856 14.04.2017 US; 15/901,722 21.02.2018 US",CN-201880024708.7; EP-2018720934; JP-2019555607
WO2018085577,PCT/US2017/059776,02.11.2017,WO/2018/085577,11.05.2018,WO,IMPLICIT BRIDGING OF MACHINE LEARNING TASKS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media for performing machine learning tasks. One method includes receiving (i) a model input, and (ii) data identifying a first machine learning task to be performed on the model input to generate a first type of model output for the model input; augmenting the model input with an identifier for the first machine learning task to generate an augmented model input; and processing the augmented model input using a machine learning model. An exemplary system applying implicit bridging for machine learning tasks, as described in this specification, trains a machine learning model to perform certain types of machine learning tasks without requiring that explicit training data for the certain types of machine learning tasks to be used during training.",G06N 3/04; G06F 17/28; G06N 3/063,GOOGLE LLC,"CHEN, Zhifeng; SCHUSTER, Michael; JOHNSON PREMKUMAR, Melvin Jose; WU, Yonghui; LE, Quoc V.; KRIKUN, Maxim; BRANTS, Thorsten","62/418,098 04.11.2016 US; 15/394,708 29.12.2016 US",KR-1020197015572; EP-2017800671; JP-2019522923; CN-201780068195.5
WO2019040173,PCT/US2018/038683,21.06.2018,WO/2019/040173,28.02.2019,WO,COMPRESSION OF WORD EMBEDDINGS FOR NATURAL LANGUAGE PROCESSING SYSTEMS,"Described herein are systems and methods that provide a natural language processing system (NLPS) that employs compressed word embeddings. An auto-encoder that includes encoder circuitry and decoder circuitry can be used to produce the compressed word embeddings. The decoder circuitry is trained to decompress the word embeddings with reduced or minimal differences between the original uncompressed word embeddings and the corresponding decompressed word embeddings. One or more parameters of the trained decoder circuitry are transferred to the NLPS, where the NLPS is then trained using the compressed word embeddings to improve the correctness of the responses or actions determined by the NLPS.",G06F 17/27; G06N 5/00; G06K 9/00; G10L 15/00,"MICROSOFT TECHNOLOGY LICENSING, LLC","LIN, Xihui; MCNAMARA, Andrew James; SULEMAN, Kaheer","15/685,929 24.08.2017 US",
EP176116713,16154406,05.02.2016,3054403,10.08.2016,EP,RECURRENT NEURAL NETWORKS FOR DATA ITEM GENERATION,"Methods, and systems, including computer programs encoded on computer storage media for generating data items. A method includes reading a glimpse from a data item using a decoder hidden state vector of a decoder for a preceding time step, providing, as input to a encoder, the glimpse and decoder hidden state vector for the preceding time step for processing, receiving, as output from the encoder, a generated encoder hidden state vector for the time step, generating a decoder input from the generated encoder hidden state vector, providing the decoder input to the decoder for processing, receiving, as output from the decoder, a generated a decoder hidden state vector for the time step, generating a neural network output update from the decoder hidden state vector for the time step, and combining the neural network output update with a current neural network output to generate an updated neural network output.",G06N 3/04; G10L 13/02; G10L 25/30,GOOGLE LLC,GREGOR KAROL; DANIHELKA IVO,201562113338 06.02.2015 US,
WO2018081089,PCT/US2017/058046,24.10.2017,WO/2018/081089,03.05.2018,WO,PROCESSING TEXT SEQUENCES USING NEURAL NETWORKS,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for neural machine translation. In one aspect, a system is configured to receive an input sequence of source embeddings representing a source sequence of words in a source natural language and to generate an output sequence of target embeddings representing a target sequence of words that is a translation of the source sequence into a target natural language, the system comprising: a dilated convolutional neural network configured to process the input sequence of source embeddings to generate an encoded representation of the source sequence, and a masked dilated convolutional neural network configured to process the encoded representation of the source sequence to generate the output sequence of target embeddings.",G06N 3/04; G06F 17/20,DEEPMIND TECHNOLOGIES LIMITED,"KALCHBRENNER, Nal Emmerich; SIMONYAN, Karen; ESPEHOLT, Lasse","62/413,366 26.10.2016 US",KR-1020197013231; EP-2017794596; JP-2019522499; CN-201780073530.0
WO2018023356,PCT/CN2016/092762,01.08.2016,WO/2018/023356,08.02.2018,WO,MACHINE TRANSLATION METHOD AND APPARATUS,"A neural network based translation method, wherein the method includes: mapping a source sentence to a semantic space predefined by a knowledge base by using a first machine learning module, to extract key information of the source sentence (910); and generating a target sentence by using a second machine learning module based on the extracted key information (920).",G06F 17/28,"MICROSOFT TECHNOLOGY LICENSING, LLC; LI, Mu; ZHOU, Ming; LIU, Shujie","LI, Mu; ZHOU, Ming; LIU, Shujie",,
WO2007068123,PCT/CA2006/002056,18.12.2006,WO/2007/068123,21.06.2007,WO,METHOD AND SYSTEM FOR TRAINING AND APPLYING A DISTORTION COMPONENT TO MACHINE TRANSLATION,"Machine translation is the translation by a machine of sentences in one human language (the source language) into sentences in a second human language, (the target language). However, once words in a sentence have been translated, the target-language words that have been found must often be reordered to reflect the characteristics of the target language. Thus, a 'distortion' component is desirable to assess the extent that each reordering reflects a correct translation. Since rules for word order vary from language to language, the system provides a distortion component which assigns a distortion score to individual translation hypothesizes. The distortion component is derived through a supervised learning system from a source sentence and a distorted source sentence originating from a bilingual sentence pair. The distortion component is based on multiple features; the features can be position based features, a word based feature and or a syntax based features.",G06F 17/28; G06F 15/18,"NATIONAL RESEARCH COUNCIL OF CANADA; KUHN, Roland; FOSTER, George; SIMARD, Michel; JOANIS, Eric","KUHN, Roland; FOSTER, George; SIMARD, Michel; JOANIS, Eric","60/750,828 16.12.2005 US",DE-null
WO2019083812,PCT/US2018/056493,18.10.2018,WO/2019/083812,02.05.2019,WO,GENERATING DUAL SEQUENCE INFERENCES USING A NEURAL NETWORK MODEL,"A computer-implemented method for dual sequence inference using a neural network model includes generating a codependent representation based on a first input representation of a first sequence and a second input representation of a second sequence using an encoder of the neural network model and generating an inference based on the codependent representation using a decoder of the neural network model. The neural network model includes a plurality of model parameters learned according to a machine learning process. The encoder includes a plurality of coattention layers arranged sequentially, each coattention layer being configured to receive a pair of layer input representations and generate one or more summary representations, and an output layer configured to receive the one or more summary representations from a last layer among the plurality of coattention layers and generate the codependent representation.",G06N 3/04; G06N 5/04,"SALESFORCE.COM, INC.","ZHONG, Victor; XIONG, Caiming; SOCHER, Richard","62/578,380 27.10.2017 US; 15/881,582 26.01.2018 US",
EP232832040,18167866,17.04.2018,3399471,07.11.2018,EP,EFFICIENT LEARNING AND USING OF TOPOLOGIES OF NEURAL NETWORKS IN MACHINE LEARNING,"A mechanism is described for facilitating learning and application of neural network topologies in machine learning at autonomous machines. A method of embodiments, as described herein, includes monitoring and detecting structure learning of neural networks relating to machine learning operations at a computing device having a processor, and generating a recursive generative model based on one or more topologies of one or more of the neural networks. The method may further include converting the generative model into a discriminative model.",G06N 7/00; G06N 3/04,INTEL CORP,YEHEZKEL ROHEKAR RAANAN YONATAN; KOREN GUY; NISIMOV SHAMI; NOVIK GAL,201715659853 26.07.2017 US; 201762501794 05.05.2017 US,
WO2019226954,PCT/US2019/033849,23.05.2019,WO/2019/226954,28.11.2019,WO,TRAINING SEQUENCE GENERATION NEURAL NETWORKS USING QUALITY SCORES,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a sequence generation neural network. One of the methods includes obtaining a batch of training examples; for each of the training examples: processing the training network input in the training example using the neural network to generate an output sequence; for each particular output position in the output sequence: identifying a prefix that includes the system outputs at positions before the particular output position in the output sequence, for each possible system output in the vocabulary, determining a highest quality score that can be assigned to any candidate output sequence that includes the prefix followed by the possible system output, and determining an update to the current values of the network parameters that increases a likelihood that the neural network generates a system output at the position that has a high quality score.",G06N 3/04; G06N 3/08; G06N 5/00,GOOGLE LLC,"NOROUZI, Mohammad; CHAN, William; AGHDAM, Sara Sabour Rouh","62/675,733 23.05.2018 US",
WO2019040197,PCT/US2018/041837,12.07.2018,WO/2019/040197,28.02.2019,WO,NETWORK-BASED LEARNING MODELS FOR NATURAL LANGUAGE PROCESSING,"Systems and methods of network-based learning models for natural language processing are provided. Information may be stored information in memory regarding user interaction with network content. Further, a digital recording of a vocal utterance made by a user may be captured. The vocal utterance may be interpreted based on the stored user interaction information. An intent of the user may be identified based on the interpretation, and a prediction may be made based on the identified intent. The prediction may further correspond to a selected workflow.",G06F 17/27; G06F 17/28,SONY INTERACTIVE ENTERTAINMENT LLC,"YONG, Stephen","15/682,381 21.08.2017 US",
WO2018195875,PCT/CN2017/082253,27.04.2017,WO/2018/195875,01.11.2018,WO,GENERATING QUESTION-ANSWER PAIRS FOR AUTOMATED CHATTING,The present disclosure provides method and apparatus for generating question-answer (QA) pairs for automated chatting. A plain text may be obtained. A question may be determined based on the plain text through a deep learning model. A QA pair may be formed based on the question and the plain text.,G06F 17/30,"MICROSOFT TECHNOLOGY LICENSING, LLC; WU, Xianchao","WU, Xianchao",,CN-201780049767.5; EP-2017906889
WO2018213205,PCT/US2018/032607,14.05.2018,WO/2018/213205,22.11.2018,WO,"SYSTEMS AND METHODS FOR RAPIDLY BUILDING, MANAGING, AND SHARING MACHINE LEARNING MODELS","In some aspects, systems and methods for rapidly building, managing, and sharing machine learning models are provided. Managing the lifecycle of machine learning models can include: receiving a set of unannotated data; requesting annotations of samples of the unannotated data to produce an annotated set of data; building a machine learning model based on the annotated set of data; deploying the machine learning model to a client system, wherein production annotations are generated; collecting the generated production annotations and generating a new machine learning model incorporating the production annotations; and selecting one of the machine learning model built based on the annotated set of data or the new machine learning model.",G06F 9/44; G06F 17/00; G06F 17/24,"DIGITAL REASONING SYSTEMS, INC.","HUGHES, Cory; ESTES, Timothy; LIU, John; CARL, Brandon; KAMATH, Uday","62/505,936 14.05.2017 US",EP-2018803094; AU-2018269941; CA-3063738; SG-11201910380S
WO2020005634,PCT/US2019/037583,18.06.2019,WO/2020/005634,02.01.2020,WO,NEURAL TREES,"A predictor has a memory which stores at least one example for which an associated outcome is not known. The memory stores at least one decision tree comprising a plurality of nodes connected by edges, the nodes comprising a root node, internal nodes and leaf nodes. Individual ones of the nodes and individual ones of the edges each have an assigned module, comprising parameterized, differentiable operations, such that for each of the internal nodes the module computes a binary outcome for selecting a child node of the internal node. The predictor has a processor configured to compute the prediction by processing the example using a plurality of the differentiable operations selected according to a path through the tree from the root node to a leaf node.",G06N 3/04; G06N 3/08,"MICROSOFT TECHNOLOGY LICENSING, LLC","NORI, Aditya Vithal; CRIMINISI, Antonio; TANNO, Ryutaro","1810736.7 29.06.2018 GB; 16/043,131 23.07.2018 US",
WO2019202436,PCT/IB2019/052941,10.04.2019,WO/2019/202436,24.10.2019,WO,USING GRADIENTS TO DETECT BACKDOORS IN NEURAL NETWORKS,"Mechanisms are provided for evaluating a trained machine learning model to determine whether the machine learning model has a backdoor trigger. The mechanisms process a test dataset to generate output classifications for the test dataset, and generate, for the test dataset, gradient data indicating a degree of change of elements within the test dataset based on the output generated by processing the test dataset. The mechanisms analyze the gradient data to identify a pattern of elements within the test dataset indicative of a backdoor trigger. The mechanisms generate, in response to the analysis identifying the pattern of elements indicative of a backdoor trigger, an output indicating the existence of the backdoor trigger in the trained machine learning model.",G06N 3/08,INTERNATIONAL BUSINESS MACHINES CORPORATION; IBM UNITED KINGDOM LIMITED; IBM (CHINA) INVESTMENT COMPANY LIMITED,"LEE, Taesung; MOLLOY, Ian, Michael; CARVALHO, Wilka; EDWARDS, Benjamin, James; ZHANG, Jialong; CHEN, Bryant","15/953,956 16.04.2018 US",
WO2018189279,PCT/EP2018/059354,12.04.2018,WO/2018/189279,18.10.2018,WO,BLACK-BOX OPTIMIZATION USING NEURAL NETWORKS,"Methods and systems for determining an optimized setting for one or more process parameters of a machine learning training process. One of the methods includes processing a current network input using a recurrent neural network in accordance with first values of the network parameters to obtain a current network output, obtaining a measure of the performance of the machine learning training process with an updated setting defined by the current network output, and generating a new network input that comprises (i) the updated setting defined by the current network output and (ii) the measure of the performance of the training process with the updated setting defined by the current network output.",G06N 3/04,DEEPMIND TECHNOLOGIES LIMITED,"DE FREITAS, Joao Ferdinando Gomes; CHEN, Yutian","62/484,821 12.04.2017 US",CN-201880024531.0; EP-2018717596
WO2019081979,PCT/IB2018/001318,18.10.2018,WO/2019/081979,02.05.2019,WO,SEQUENCE-TO-SEQUENCE PREDICTION USING A NEURAL NETWORK MODEL,"A method for sequence-to-sequence prediction using a neural network model includes a method for sequence-to-sequence prediction using a neural network model, generating an encoded representation based on an input sequence using an encoder of the neural network model, predicting a fertility sequence based on the input sequence, generating an output template based on the input sequence and the fertility sequence, and predicting an output sequence based on the encoded representation and the output template using a decoder of the neural network model. The neural network model includes a plurality of model parameters learned according to a machine learning process. Each item of the fertility sequence includes a fertility count associated with a corresponding item of the input sequence.",G06N 3/04; G06N 3/08; G06F 17/28,"SALESFORCE.COM, INC.","BRADBURY, James Edward Kahn; GU, Jiatao","62/578,375 27.10.2017 US; 15/885,576 31.01.2018 US",
WO2018196760,PCT/CN2018/084306,25.04.2018,WO/2018/196760,01.11.2018,WO,ENSEMBLE TRANSFER LEARNING,"An apparatus and method are provided for ensemble transfer learning. One or more first (machine learning) projects that are similar to a second (machine learning) project are identified by comparing metadata of the one or more first projects and the second project, where the metadata comprises a plurality of characteristics and the characteristics of the first projects are compared to the characteristic of the second project to identify the one or more first projects. One or more (machine learning) models associated with the one or more first projects are selected as a plurality of models that each share a common feature set with the second project. Each model in the plurality of models is applied to input data for the second project to generate a set of results. Output data corresponding to the input data is produced for the second project based on the set of results.",G06K 9/62,"HUAWEI TECHNOLOGIES CO., LTD.","ZANG, Hui; WU, Zonghuan; YU, Jiangsheng","15/499,660 27.04.2017 US",
WO2019175571,PCT/GB2019/050693,12.03.2019,WO/2019/175571,19.09.2019,WO,COMBINED METHODS AND SYSTEMS FOR ONLINE MEDIA CONTENT,"The present invention relates to a series of methods and systems in respect of online media content. More specifically, the present invention relates to aspects of fact checking of online media content.",G06F 16/35; G06Q 50/00; G06F 17/27; G06K 9/62; G06F 21/10; G06F 16/9535,FACTMATA LIMITED,"GHULATI, Dhruv; WASEEM, Zeerak; SHUKLA, Rishabh; PISAREVSKAYA, Dina; VINCENT, Emmanuel; ROBBINS, Martin","1803954.5 12.03.2018 GB; 1804295.2 16.03.2018 GB; 1804297.8 16.03.2018 GB; 1804532.8 21.03.2018 GB; 1804528.6 21.03.2018 GB; 1804529.4 21.03.2018 GB; 1804828.0 26.03.2018 GB; 62/654,699 09.04.2018 US; 62/654,908 09.04.2018 US; 62/654,968 09.04.2018 US; 62/654,700 09.04.2018 US; 62/655,053 09.04.2018 US; 62/654,901 09.04.2018 US; 62/654,947 09.04.2018 US; 1810079.2 19.06.2018 GB",
WO2018039510,PCT/US2017/048529,25.08.2017,WO/2018/039510,01.03.2018,WO,REWARD AUGMENTED MODEL TRAINING,"A method includes obtaining data identifying a machine learning model to be trained to perform a machine learning task, the machine learning model being configured to receive an input example and to process the input example in accordance with current values of a plurality of model parameters to generate a model output for the input example; obtaining initial training data for training the machine learning model, the initial training data comprising a plurality of training examples and, for each training example, a ground truth output that should be generated by the machine learning model by processing the training example; generating modified training data from the initial training data; and training the machine learning model on the modified training data.",G06N 99/00,GOOGLE LLC,"SCHUSTER, Michael; BENGIO, Samuel; JAITLY, Navdeep; CHEN, Zhifeng; SCHUURMANS, Dale Eric; NOROUZI, Mohammad; WU, Yonghui","62/379,705 25.08.2016 US",CN-201780052196.0; EP-2017761752
WO2019108367,PCT/US2018/060188,09.11.2018,WO/2019/108367,06.06.2019,WO,MACHINE LEARNING OF RESPONSE SELECTION TO STRUCTURED DATA INPUT,"A machine learning of response selection to structured data input enables a machine to flexibly and responsively actively engage with a response recipient through a device, such as any electronic device connected to a data network. In at least one embodiment, the response selection module improves response selection to the structure data input by initially filtering a library of templates to identify candidate templates that best respond to the input. In at least one embodiment, the response selection module ranks the identified candidate templates to provide the response to the device. The response selection module learns by receiving feedback, such as a linked recipient action result signal.",G06F 17/27; G06F 17/24; G06N 20/00; G06F 17/28,"OJO LABS, INC.","LEVY, Joshua Howard","15/826,151 29.11.2017 US; 15/897,885 15.02.2018 US",
WO2017192522,PCT/US2017/030552,02.05.2017,WO/2017/192522,09.11.2017,WO,USING META-INFORMATION IN NEURAL MACHINE TRANSLATION,"Systems and methods for neural machine translation are provided. In one example, a neural machine translation system translates text and comprises processors and a memory storing instructions that, when executed by at least one processor among the processors, cause the system to perform operations comprising, at least, obtaining a text as an input to a neural network system, supplementing the input text with meta information as an extra input to the neural network system, and delivering an output of the neural network system to a user as a translation of the input text, leveraging the meta information for translation.",G06F 7/00; G06F 7/02; G06F 7/10; G06F 17/27; G06F 17/28; G06F 17/30; G06N 3/04,EBAY INC.,"MATUSOV, Evgeny; CHEN, Wenhu; KHADIVI, Shahram","62/332,608 06.05.2016 US",KR-1020187035351
WO2018058046,PCT/US2017/053267,25.09.2017,WO/2018/058046,29.03.2018,WO,NEURAL MACHINE TRANSLATION SYSTEMS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for neural machine translation. One of the systems includes an encoder neural network comprising: an input forward long short-term memory (LSTM) layer configured to process each input token in the input sequence in a forward order to generate a respective forward representation of each input token, an input backward LSTM layer configured to process each input token in a backward order to generate a respective backward representation of each input token and a plurality of hidden LSTM layers configured to process a respective combined representation of each of the input tokens in the forward order to generate a respective encoded representation of each of the input tokens; and a decoder subsystem configured to receive the respective encoded representations and to process the encoded representations to generate an output sequence.",G06N 3/04; G06F 17/28,GOOGLE LLC,"NOROUZI, Mohammad; CHEN, Zhifeng; WU, Yonghui; SCHUSTER, Michael; LE, Quoc V.","62/399,990 26.09.2016 US",JP-2019516134; KR-1020197008608; EP-2017784461
WO2018118420,PCT/US2017/064755,05.12.2017,WO/2018/118420,28.06.2018,WO,"METHOD, SYSTEM, AND APPARATUS FOR VOICE AND VIDEO DIGITAL TRAVEL COMPANION","The present invention contemplates a variety of improved techniques using a travel companion. The travel companion can include a headset, a user device, and the cloud. The headset can include a microphone, a speaker, and a camera which allows for collection of data. The travel companion can process the data and output results such as translation or other information based on data received.",G02B 27/01; G06F 17/28; G06K 9/62; G10L 13/00; G10L 15/30,"ESSENTIAL PRODUCTS, INC.","FOMIN, Yury","62/438,343 22.12.2016 US; 15/826,604 29.11.2017 US",
WO2019033380,PCT/CN2017/097977,18.08.2017,WO/2019/033380,21.02.2019,WO,SLIMMING OF NEURAL NETWORKS IN MACHINE LEARNING ENVIRONMENTS,"A mechanism is described for facilitating slimming of neural networks in machine learning environments. A method of embodiments, as described herein, includes learning a first neural network associated with machine learning processes to be performed by a processor of a computing device, where learning includes analyzing a plurality of channels associated with one or more layers of the first neural network. The method may further include computing a plurality of scaling factors to be associated with the plurality of channels such that each channel is assigned a scaling factor, wherein each scaling factor to indicate relevance of a corresponding channel within the first neural network. The method may further include pruning the first neural network into a second neural network by removing one or more channels of the plurality of channels having low relevance as indicated by one or more scaling factors of the plurality of scaling factors assigned to the one or more channels.",G06N 3/08,"INTEL CORPORATION; YAN, Shoumeng; LI, Jianguo; LIU, Zhuang","YAN, Shoumeng; LI, Jianguo; LIU, Zhuang",,
WO2018194960,PCT/US2018/027744,16.04.2018,WO/2018/194960,25.10.2018,WO,MULTI-STAGE MACHINE LEARNING AND RECOGNITION,"A multi-stage machine learning and recognition system comprises multiple individual machine learning systems arranged in multiple stages, where data is passed from a machine learning system in one stage to one or more machine learning systems in a subsequent, higher-level stage of the structure according to the logic of the machine learning system. The multi-stage machine learning system can be arranged in a final stage and one or more non- final stages, where the one or more non-final stages direct data generally towards a selected one or more machine learning systems within the final stage, but less than all of the machine learning systems in the final stage. The multi-stage machine learning system can additionally include a separate machine learning system designated as a learning coach and data management system, which is configured to control the distribution of data throughout the multi-stage structure of machine learning systems by observing the internal state of the structure. The learning coach and data management system can additionally optimize the performance of the overall system by controlling one or more of the hyperparameters of any of the machine learning systems in the overall system, reorganizing the multi-stage structure, or perform other functions.",G06K 9/62; G10L 15/00; G10L 21/00,D5AI LLC,"BAKER, James, K.","62/486,650 18.04.2017 US",EP-2018787062
WO2018117532,PCT/KR2017/014683,14.12.2017,WO/2018/117532,28.06.2018,WO,SPEECH RECOGNITION METHOD AND APPARATUS,"A speech recognition method and a speech recognition apparatus which pre-download a speech recognition model predicted to be used and use the speech recognition model in speech recognition is provided. The speech recognition method, performed by the speech recognition apparatus, includes determining a speech recognition model, based on user information downloading the speech recognition model, performing speech recognition, based on the speech recognition model, and outputting a result of performing the speech recognition.",G10L 17/02; G10L 15/22; G10L 15/183; G10L 19/04; G10L 15/26; G06F 17/28,"SAMSUNG ELECTRONICS CO., LTD.","KIM, Sang-yoon; KIM, Sung-soo; KIM, Il-hwan; LEE, Kyung-min; KIM, Nam-hoon; RYU, Jong-yub; LEE, Jae-won",10-2016-0173618 19.12.2016 KR,CN-201780078456.1; EP-2017882510
WO2017161189,PCT/US2017/022812,16.03.2017,WO/2017/161189,21.09.2017,WO,PARALLEL-HIERARCHICAL MODEL FOR MACHINE COMPREHENSION ON SMALL DATA,"Examples of the present disclosure provide systems and methods relating to a machine comprehension test with a learning-based approach, harnessing neural networks arranged in a parallel hierarchy. This parallel hierarchy enables the model to compare the passage, question, and answer from a variety of perspectives, as opposed to using a manually designed set of features. Perspectives may range from the word level to sentence fragments to sequences of sentences, and networks operate on word-embedding representations of text. A training methodology for small data is also provided.",G06F 17/28; G06N 3/02; G06N 99/00,MALUUBA INC.,"TRISCHLER, Adam; YE, Zheng; YUAN, Xingdi; BACHMAN, Philip","62/309,139 16.03.2016 US",EP-2017714120
WO2016145516,PCT/CA2016/050273,11.03.2016,WO/2016/145516,22.09.2016,WO,SYSTEM AND METHOD FOR TRAINING NEURAL NETWORKS,"Systems and methods for training a neural network or an ensemble of neural networks are described. A hyper-parameter that controls the variance of the ensemble predictors is used to address overfitting. For larger values of the hyper-parameter, the predictions from the ensemble have more variance, so there is less overfitting. This technique can be applied to ensemble learning with various cost functions, structures and parameter sharing. A cost function is provided and a set of techniques for learning are described.",G06N 3/08,DEEP GENOMICS INCORPORATED,"XIONG, Hui Yuan; DELONG, Andrew; FREY, Brendan","62/133,000 13.03.2015 US",
WO2018140969,PCT/US2018/016024,30.01.2018,WO/2018/140969,02.08.2018,WO,MULTI-TASK NEURAL NETWORKS WITH TASK-SPECIFIC PATHS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for using multi-task neural networks. One of the methods includes receiving a first network input and data identifying a first machine learning task to be performed on the first network input; selecting a path through the plurality of layers in a super neural network that is specific to the first machine learning task, the path specifying, for each of the layers, a proper subset of the modular neural networks in the layer that are designated as active when performing the first machine learning task; and causing the super neural network to process the first network input using (i) for each layer, the modular neural networks in the layer that are designated as active by the selected path and (ii) the set of one or more output layers corresponding to the identified first machine learning task.",G06N 3/08; G06N 3/04,GOOGLE LLC,"WIERSTRA, Daniel Pieter; FERNANDO, Chrisantha, Thomas; PRITZEL, Alexander; BANARSE, Dylan, Sunil; BLUNDELL, Charles; RUSU, Andrei-Alexandru; ZWOLS, Yori; HA, David","62/452,276 30.01.2017 US",CN-201880005904.X; EP-2018705269
WO2020091210,PCT/KR2019/011267,02.09.2019,WO/2020/091210,07.05.2020,WO,SYSTEM AND METHOD OF INTEGRATING DATABASES BASED ON KNOWLEDGE GRAPH,"An artificial intelligence (AI) system that utilizes a machine learning algorithm, such as deep learning, etc. and an application of the AI system is provided. A method, performed by a server, of integrating and managing a plurality of databases (DBs) includes obtaining a plurality of knowledge graphs related to DBs generated from the plurality of DBs having different structures from one another, inputting the plurality of knowledge graphs related to DBs into a learning model related to DB for determining a correlation between data in the plurality of DBs, and obtaining a virtual integrated knowledge graph output from the learning model related to DB and including information about a correlation extracted from the plurality of knowledge graphs related to DBs.",G06F 16/901; G06F 16/31; G06N 3/08; G06N 20/00,"SAMSUNG ELECTRONICS CO., LTD.","LEE, Yunsu; HWANG, Taeho; KIM, Soohyung; KIM, Heejin; LEE, Jaehun; LEE, Hyonsok; KANG, Jiyoung",10-2018-0131110 30.10.2018 KR,
WO2020048721,PCT/EP2019/071308,08.08.2019,WO/2020/048721,12.03.2020,WO,SYSTEM AND METHOD FOR NATURAL LANGUAGE PROCESSING,"A natural language processing system configured for receiving an input sequence of input tokens representing a first sequence of words in a natural language of a first text and generating an output sequence of output tokens representing a second sequence of words in a natural language of a second text. The natural language processing system has at least one sequence-to-sequence (seq2seq) model and a policy gradient generator. The seq2seq model comprises an encoder, an attention module and a decoder. The encoder and the decoder each comprise a forward recurrent neural network RNN and a backward RNN, and the attention module is configured for applying weights to the encoded representations.",G06F 17/27; G06F 16/34,SIEMENS AKTIENGESELLSCHAFT,"KUMAR KARN, Sanjeev; KROMPASS, Denis; WALTINGER, Ulli",18192464.8 04.09.2018 EP,
WO2019182818,PCT/US2019/021954,13.03.2019,WO/2019/182818,26.09.2019,WO,MACHINE TRANSLATION LOCKING USING SEQUENCE-BASED LOCK/UNLOCK CLASSIFICATION,"A software input string is received and tokenized into a sequence of tokens. The sequence of tokens is applied to a trained sequence-dependent lock/unlock classifier so that each of the tokens is classified as a token that should be locked, or remain unlocked, for subsequent translation. The software input string is converted to a converted string, in which the locked tokens are identified and the converted string is submitted for machine translation. A machine translation result is received and converted so that the locked tokens are replaced in the machine translation result, to obtain a translated software string.",G06F 17/28; G06N 7/00,"MICROSOFT TECHNOLOGY LICENSING, LLC","JOO, Dong Kwon; MITTAL, Bhavishya; TIAN, Li; SRIKANTH, Prasidh; EIDT, Jürgen; STIPE, Neal Allen; TAYLOR, Marcus Andrew; DE LA GARZA MARTÍNEZ, Fernando","15/928,680 22.03.2018 US",
WO2017116839,PCT/US2016/067723,20.12.2016,WO/2017/116839,06.07.2017,WO,SYSTEMS AND METHODS FOR SUGGESTING EMOJI,"Implementations of the present disclosure are directed to a method, a system, and an article for suggesting emoji for insertion into a communication having text or other content. A plurality of features corresponding to the communication are obtained and provided to a plurality of emoji detection modules. A set of emoji and first confidence scores are received from each emoji detection module and provided to at least one classifier. A proposed set of candidate emoji and second confidence scores are received from the at least one classifier. A candidate emoji is inserted into the communication.",G06F 17/27; G06F 3/0481,"MZ IP HOLDINGS, LLC","BOJJA, Nikhil; KARUPPUSAMY, Satheeshkumar; WANG, Pidong; KANNAN, Shivasankari; NEDUNCHEZHIAN, Arun","62/272,324 29.12.2015 US",EP-2016825640; AU-2016383052; CA-3009758; JP-2018534941
WO2020074788,PCT/FI2019/050733,13.10.2019,WO/2020/074788,16.04.2020,WO,"METHOD OF TRAINING A NATURAL LANGUAGE SEARCH SYSTEM, SEARCH SYSTEM AND CORRESPONDING USE","The invention provides a method and system for training a machine learning-based patent search or novelty evaluation system. The method comprises providing a plurality of patent documents each having a computer-identifiable claim block and specification block, the specification block including at least part of the description of the patent document. The method also comprises providing a machine learning model and training the machine learning model using a training data set comprising data from said patent documents for forming a trained machine learning model. According to the invention, the training comprises using pairs of claim blocks and specification blocks originating from the same patent document as training cases of said training data set.",G06F 40/205; G06F 40/279; G06N 20/00; G06N 3/08,IPRALLY TECHNOLOGIES OY,"ARVELA, Sakari",20185865 13.10.2018 FI,
WO2019133919,PCT/US2018/068026,28.12.2018,WO/2019/133919,04.07.2019,WO,SYSTEMS AND METHODS FOR HUMAN TO AI COOPERATION IN ASSOCIATION WITH MACHINE LEARNING CONVERSATIONS,"Systems and methods for more effective AI operations, improvements to the experience of a conversation target, and increased productivity through AI assistance are provided. In some embodiments, the systems use machine learning models to classify a number of message responses with a confidence. If these classifications are below a threshold the messages are sent to a user for analysis, after prioritization, along with guidance data. Feedback from the user modified the models. In another embodiment, a system and method for an AI assistant is also provided which receives messages and determines instructions using keywords and/or classifications. The AI assistant then executes upon these instructions. In another embodiment, a conversation editor interface is provided. The conversation editor includes one or more displays that illustrate an overview flow diagram for the conversation, specific node analysis, libraries of conversations and potentially metrics that can help inform conversation flow. Lastly, task gamification may additionally be employed in order to increase the messaging system's performance.",G06F 17/20; G06F 17/27; G06F 17/28; H04M 3/50; H04M 3/51; H04M 3/527,"CONVERSICA, INC.","TERRY, George Alexis; KOEPF, Werner; HARRIGER, James D.; WEBB-PURKIS, William Dominic; JONNALAGADDA, Siddhartha Reddy; GAINOR, Macgregor S.; FERGUSON, Colin C.; MARTINI, Gabriel Vincent; CALAPRISTI, Jacqueline Loretta","16/228,721 20.12.2018 US; 16/228,712 20.12.2018 US; 16/228,717 20.12.2018 US; 16/228,723 20.12.2018 US; 62/612,020 29.12.2017 US",
EP251457635,18857429,30.08.2018,3537349,11.09.2019,EP,MACHINE LEARNING MODEL TRAINING METHOD AND DEVICE,"A machine learning model training method, the method comprising: obtaining target task training data and N types of supporting task training data (S1010); inputting the target task training data and the N types of supporting task training data into a memory model and obtaining target task training feature data and N types of supporting task training feature data (S1020); training a target task model according to the target task training feature data and obtaining a first loss of the target task model, and respectively training respective corresponding supporting task models according to the N types of supporting task training feature data and obtaining a second loss of each of the N supporting task models (S1030); updating the memory model, the target task model and the N supporting task models according to the first loss and the second loss of each of the N supporting task models (S1040). By means of the method for training a machine learning model, the accuracy of prediction results may be improved.",G06N 99/00,HUAWEI TECH CO LTD,WU BIN; ZHOU FENGEI; LI ZHENGUO,201810027720 11.01.2018 CN; 2018103364 30.08.2018 CN,
EP231869832,18161702,14.03.2018,3389005,17.10.2018,EP,ABSTRACTION LIBRARY TO ENABLE SCALABLE DISTRIBUTED MACHINE LEARNING,"One embodiment provides for a non-transitory machine readable medium storing instructions which, when executed by one or more processors, cause the one or more processors to perform operations comprising providing an interface to define a neural network using machine-learning domain specific terminology, wherein the interface enables selection of a neural network topology and abstracts low-level communication details of distributed training of the neural network.",G06T 1/20,INTEL CORP,KALAMKAR DHIRAJ D; VAIDYANATHAN KARTHIKEYAN; SRIDHARAN SRINIVAS; DAS DIPANKAR,201715482925 10.04.2017 US,
WO2019023984,PCT/CN2017/095621,02.08.2017,WO/2019/023984,07.02.2019,WO,SYSTEM AND METHOD ENABLING ONE-HOT NEURAL NETWORKS ON A MACHINE LEARNING COMPUTE PLATFORM,"A compute apparatus to perform machine learning operations, the compute apparatus comprising instruction decode logic to decode a single instruction including multiple operands into a single decoded instruction, the multiple operands including a first operand and a second operand, the first operand including vector of one-hot coded weights and the second operand including a vector of input data； and a general-purpose graphics compute unit including a first logic unit, the general-purpose graphics compute unit to execute the single decoded instruction, wherein to execute the single decoded instruction includes to perform multiple operations on the first set of operands and the second set of operands.",G06N 3/02,INTEL CORPORATION,"CHEN, Yurong; LI, Jianguo",,
WO2020091919,PCT/US2019/053233,26.09.2019,WO/2020/091919,07.05.2020,WO,COMPUTER ARCHITECTURE FOR MULTIPLIER-LESS MACHINE LEARNING,"A computer architecture for multiplier-less machine learning is disclosed. According to some aspects, a neural network apparatus include processing circuitry and memory. The processing circuitry accesses a plurality of weights for a neural network layer and an input vector for the neural network layer, the input vector comprising a plurality of data values. The processing circuitry provides the plurality of weights and the input vector to an addition layer. The addition layer generates data value-weight pairs and, for each data value-weight pair, creates an input block comprising a sum of the data value and the weight. The processing circuitry sorts the input blocks generated by the addition layer. The processing circuitry cancels any opposite signed input blocks from the sorted input blocks to generate a set of blocks. The processing circuitry outputs a Kth largest value from the set of blocks. K is a positive integer.",G06N 3/04; G06N 3/063; G06N 3/08; G06N 5/00; G06N 7/00,RAYTHEON COMPANY,"PARKER, Michael A.","62/752,654 30.10.2018 US",
WO2018126213,PCT/US2017/069102,29.12.2017,WO/2018/126213,05.07.2018,WO,MULTI-TASK LEARNING USING KNOWLEDGE DISTILLATION,"Methods, systems, and apparatus, including computer programs encoded on computer storage media for performing multi-task learning. In one method a system obtains a respective set of training data for each of multiple machine learning tasks. For each of the machine learning tasks, the system configures a respective teacher machine learning model to perform the machine learning task by training the teacher machine learning model on the training data. The system trains a single student machine learning model to perform the multiple machine learning tasks using (i) the configured teacher machine learning models, and (ii) the obtained training data.",G06N 3/04,GOOGLE LLC,"CHUNG, Junyoung; JOHNSON PREMKUMAR, Melvin, Jose; SCHUSTER, Michael; MACHEREY, Wolfgang","62/441,119 30.12.2016 US",
WO2019022854,PCT/US2018/036810,11.06.2018,WO/2019/022854,31.01.2019,WO,DATA2DATA: DEEP LEARNING FOR TIME SERIES REPRESENTATION AND RETRIEVAL,"A computer-implemented method for employing deep learning for time series representation and retrieval is presented. The method includes retrieving multivariate time series segments from a plurality of sensors, storing the multivariate time series segments in a multivariate time series database constructed by a sliding window over a raw time series of data, applying an input attention based recurrent neural network to extract real value features and corresponding hash codes, executing similarity measurements by an objective function, given a query, obtaining a relevant time series segment from the multivariate time series segments retrieved from the plurality of sensors, and generating an output including a visual representation of the relevant time series segment on a user interface.",G06N 3/08; G06N 3/04,"NEC LABORATORIES AMERICA, INC.","SONG, Dongjin; XIA, Ning; CHEN, Haifeng","62/537,577 27.07.2017 US; 15/991,205 29.05.2018 US",
WO2005057425,PCT/EP2005/002376,07.03.2005,WO/2005/057425,23.06.2005,WO,HYBRID MACHINE TRANSLATION SYSTEM,"In order to achieve improvement of the accuracy and speed of a conversion of source language elements to target language elements a machine translation system is provided with context and linguistic processing comprising a dictionary storage 100, linguistic analysis storage 114, transfer rule storage 116 and a context storage 130, wherein selecting means 118 determines an order of selection among transfer rules to be executed to obtain target language elements from linguistic processing and target language elements from context processing. The correlation between language elements and context elements is obtained using a neural network.",G06F 17/28,"LINGUATEC SPRACHTECHNOLOGIEN GMBH; THURMAIR, Gregor; WILL, Thilo; ALEKSIC, Vera","THURMAIR, Gregor; WILL, Thilo; ALEKSIC, Vera",,US-11885688; RU-null; EP-2005715789
WO2020074787,PCT/FI2019/050732,13.10.2019,WO/2020/074787,16.04.2020,WO,METHOD OF SEARCHING PATENT DOCUMENTS,"A method of searching patent documents comprising reading a plurality of patent documents each comprising a specification and a converted into specification graphs and claim graphs. The graphs contain nodes each having a first natural language unit extracted from the specification or claim as a node value, and edges between the nodes determined based on at least one second natural language unit extracted from the specification or claim. A machine learning model is trained using an algorithm capable of travelling through the graphs according to the edges and utilizing said node values for forming a trained machine learning model. The method comprises reading a fresh graph and utilizing the trained machine learning model for determining a subset of patent documents.",G06F 40/205; G06F 40/279; G06N 20/00; G06N 3/08,IPRALLY TECHNOLOGIES OY,"ARVELA, Sakari; KALLIO, Juho; BJÖRKQVIST, Sebastian",20185864 13.10.2018 FI; 20185866 13.10.2018 FI,
WO2018106613,PCT/US2017/064558,04.12.2017,WO/2018/106613,14.06.2018,WO,PREDICTING A SEARCH ENGINE RANKING SIGNAL VALUE,"Methods, systems, and apparatus including computer programs encoded on a computer storage medium, for augmenting search engine index that indexes resources from a collection of resources. In one aspect, a method of augmenting a search engine index that indexes resources from a collection of resources includes the actions of identifying a resource, in the collection of resources, that is indexed in the search engine index for which a value of a search engine ranking signal is not available; processing data from the resource using a machine learning model, the machine learning model being configured to: process the data to predict a value of the search engine ranking signal for the resource; and updating the search engine index by associating the predicted value of the search engine ranking signal with the resource in the search engine index.",G06F 17/30,GOOGLE LLC,"ARRIZABALAGA, Javier, Spagnolo; NUHN, Malte; LE, Quoc, V.; DUCKWORTH, Daniel; HEILER, Matthias","15/369,849 05.12.2016 US",CN-201780074815.6
EP153680792,15170815,05.06.2015,2953065,09.12.2015,EP,GENERATING REPRESENTATIONS OF INPUT SEQUENCES USING NEURAL NETWORKS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating representations of input sequences. One of the methods includes obtaining an input sequence, the input sequence comprising a plurality of inputs arranged according to an input order; processing the input sequence using a first long short term memory (LSTM) neural network to convert the input sequence into an alternative representation for the input sequence; and processing the alternative representation for the input sequence using a second LSTM neural network to generate a target sequence for the input sequence, the target sequence comprising a plurality of outputs arranged according to an output order.",G06N 3/04,GOOGLE INC,VINYALS ORIOL; LE QUOC V; SUTSKEVER ILYA,201462009121 06.06.2014 US,
WO2017090954,PCT/KR2016/013471,22.11.2016,WO/2017/090954,01.06.2017,WO,ELECTRONIC DEVICE AND OPERATING METHOD THEREOF,A method of operating an electronic device according to various example embodiments of the present disclosure may include: acquiring a plurality of text messages; acquiring a keyword corresponding to the plurality of text messages by analyzing each of the plurality of text messages; transmitting a query including the keyword; and performing an operation corresponding to an analysis result of the keyword after receiving the analysis result of the keyword.,G06F 17/30; G06F 17/28; G06N 99/00,"SAMSUNG ELECTRONICS CO., LTD.","LEE, Hae-Jun; RHO, Ji-Hyun; KIM, Deok-Ho",10-2015-0165070 24.11.2015 KR; 10-2016-0107179 23.08.2016 KR,EP-2016868850
WO2018085722,PCT/US2017/060049,03.11.2017,WO/2018/085722,11.05.2018,WO,QUASI-RECURRENT NEURAL NETWORK,"The technology disclosed provides a quasi-recurrent neural network (QRNN) that alternates convolutional layers, which apply in parallel across timesteps, and minimalist recurrent pooling layers that apply in parallel across feature dimensions.",G06N 3/04; G10L 15/16; G10L 15/18; G06F 17/20; G10L 25/30,"SALESFORCE.COM, INC.","BRADBURY, James; MERITY, Stephen, Joseph; XIONG, Caiming; SOCHER, Richard","62/417,333 04.11.2016 US; 62/418,075 04.11.2016 US; 15/420,710 31.01.2017 US; 15/420,801 31.01.2017 US",CN-201780068556.6; JP-2019522910; EP-2017800682; AU-2017355535; CA-3040188
EP12683820,95304339,21.06.1995,0689147,27.12.1995,EP,Natural language processing system and method,"A natural language processing method, by which a sequence of natural language information is analyzed so as to derive a concept represented by the information. In this method, the input natural language information is sequentially processed as word by word. At that time, the kind of a subsequent word is expected from a currently processed word by using knowledge concerning the word order of words in the natural language information. Thus the processing is performed by eliminating ambiguity in the information on the basis of such an expectation. <IMAGE>",G06F 9/44; G06F 17/27; G06F 17/28; G06N 5/04,CANON KK,SUDA ARUNA ROHRA; JEYACHANDRAN SURESH,13888894 21.06.1994 JP; 14468395 12.06.1995 JP,
WO2018170175,PCT/US2018/022504,14.03.2018,WO/2018/170175,20.09.2018,WO,PROBABILITY-BASED GUIDER,"The technology disclosed proposes using a combination of computationally cheap, less-accurate bag of words (BoW) model and computationally expensive, more-accurate long short-term memory (LSTM) model to perform natural processing tasks such as sentiment analysis. The use of cheap, less-accurate BoW model is referred to herein as ""skimming"". The use of expensive, more-accurate LSTM model is referred to herein as ""reading"". The technology disclosed presents a probability-based guider (PBG). PBG combines the use of BoW model and the LSTM model. PBG uses a probability thresholding strategy to determine, based on the results of the BoW model, whether to invoke the LSTM model for reliably classifying a sentence as positive or negative. The technology disclosed also presents a deep neural network-based decision network (DDN) that is trained to learn the relationship between the BoW model and the LSTM model and to invoke only one of the two models.",G06N 3/04,"SALESFORCE.COM, INC.","JOHANSEN, Alexander Rosenberg; MCCANN, Bryan; BRADBURY, James; SOCHER, Richard","62/471,934 15.03.2017 US; 15/853,530 22.12.2017 US",JP-2019550612; CA-3052212; CN-201880018349.4
EP232831978,18170151,30.04.2018,3399418,07.11.2018,EP,FINE-GRAIN COMPUTE COMMUNICATION EXECUTION FOR DEEP LEARNING FRAMEWORKS,"One embodiment provides for a system to configure distributed training of a neural network. The system includes memory to store a library to facilitate transmission of data during distributed training of the neural network; a network interface to transmit and receive gradient data associated with the trainable parameters; a general-purpose processor to execute instructions provided by the library, the instructions to cause the general-purpose processor to configure the network interface to transmit and receive the gradient data associated with the trainable parameters during a workflow of a machine learning framework; and a graphics processor to perform compute operations associated with machine learning framework workflow to generate the gradient data associated with the trainable parameters, wherein, based on the machine learning framework workflow, the library is to interleave the compute operations on the graphics processor with transmission and receipt of gradient data via the network interface.",G06F 9/54; G06N 3/063,INTEL CORP,SRIDHARAN SRINIVAS; MUDIGERE DHEEVATSA,201762502453 05.05.2017 US; 201815869502 12.01.2018 US,
WO2017052820,PCT/US2016/046202,09.08.2016,WO/2017/052820,30.03.2017,WO,AUTOMATIC TRANSLATION OF DIGITAL GRAPHIC NOVELS,Digital graphic novel content is received and features of the graphic novel content are identified. At least one of the identified features includes text. Contextual information corresponding to the feature or features that include text is generated based on the identified features. The contextual information is used to aid translation of the text included in the feature or features that include text.,G06F 17/22; G06F 17/28; G06N 3/02; G06K 9/00,GOOGLE LLC,"HARTRELL, Greg, Don; GHOSH, Debajit; VAUGHAN-VAIL, Matthew; RIVLIN, John, Michael; CONBOY, Garth; GU, Xinxing; TOSHEV, Alexander","14/863,394 23.09.2015 US",JP-2017556883; EP-2016754068
WO2019204252,PCT/US2019/027598,16.04.2019,WO/2019/204252,24.10.2019,WO,AUTOMATED ASSISTANTS THAT ACCOMMODATE MULTIPLE AGE GROUPS AND/OR VOCABULARY LEVELS,"Techniques are described herein for enabling an automated assistant to adjust its behavior depending on a detected age range and/or ""vocabulary level"" of a user who is engaging with the automated assistant. In various implementations, data indicative of a user's utterance may be used to estimate one or more of the user's age range and/or vocabulary level. The estimated age range/vocabulary level may be used to influence various aspects of a data processing pipeline employed by an automated assistant. In various implementations, aspects of the data processing pipeline that may be influenced by the user's age range/vocabulary level may include one or more of automated assistant invocation, speech-to-text (""STT"") processing, intent matching, intent resolution (or fulfillment), natural language generation, and/or text-to-speech (""TTS"") processing. In some implementations, one or more tolerance thresholds associated with one or more of these aspects, such as grammatical tolerances, vocabularic tolerances, etc., may be adjusted.",G10L 15/22; G06F 17/27; G10L 15/18,GOOGLE LLC,"ANDERS, Pedro Gonnet; CARBUNE, Victor; KEYSERS, Daniel; DESELAERS, Thomas; FEUZ, Sandro","15/954,174 16.04.2018 US",EP-2019720325
WO2018085728,PCT/US2017/060056,03.11.2017,WO/2018/085728,11.05.2018,WO,JOINT MANY-TASK NEURAL NETWORK MODEL FOR MULTIPLE NATURAL LANGUAGE PROCESSING (NLP) TASKS,"The technology disclosed provides a so-called ""joint many-task neural network model"" to solve a variety of increasingly complex natural language processing (NLP) tasks using growing depth of layers in a single end-to-end model. The model is successively trained by considering linguistic hierarchies, directly connecting word representations to all model layers, explicitly using predictions in lower tasks, and applying a so-called ""successive regularization"" technique to prevent catastrophic forgetting. Three examples of lower level model layers are part-of-speech (POS) tagging layer, chunking layer, and dependency parsing layer. Two examples of higher level model layers are semantic relatedness layer and textual entailment layer. The model achieves the state-of-the-art results on chunking, dependency parsing, semantic relatedness and textual entailment.",G06N 3/04; G10L 15/16; G10L 15/18; G10L 25/30; G06F 17/20,"SALESFORCE.COM, INC.","HASHIMOTO, Kazuma; XIONG, Caiming; SOCHER, Richard","62/417,269 03.11.2016 US; 62/418,070 04.11.2016 US; 15/421,407 31.01.2017 US; 15/421,424 31.01.2017 US; 15/421,431 31.01.2017 US",CN-201780068289.2; JP-2019523092; CA-3039517; EP-2017800683
WO2017147785,PCT/CN2016/075186,01.03.2016,WO/2017/147785,08.09.2017,WO,AUTOMATED COMMENTARY FOR ONLINE CONTENT,"Techniques for artificially generating commentary for online content including news items. In an aspect, a personification engine incorporates a machine learning model trained using corpus elements comprising an item of online content and relevant commentary. The personification engine is configured to generate relevant commentary when provided with an item of online content such as a news item. In a further aspect, a chatbot engine incorporates a model similarly trained using corpus element comprising a comment and a relevant response. The chatbot engine is configured to generate relevant responses to user comments in the context of a forum or comments section related to the item of online content.",G06F 17/30,"MICROSOFT TECHNOLOGY LICENSING, LLC","LU, Yumao",,US-16076703
WO2018217828,PCT/US2018/033986,22.05.2018,WO/2018/217828,29.11.2018,WO,METHODS AND APPARATUS FOR DISCRIMINATIVE SEMANTIC TRANSFER AND PHYSICS-INSPIRED OPTIMIZATION OF FEATURES IN DEEP LEARNING,"Methods and apparatus for discrimitive semantic transfer and physics-inspired optimization in deep learning are disclosed. A computation training method for a convolutional neural network (CNN) includes receiving a sequence of training images in the CNN of a first stage to describe objects of a cluttered scene as a semantic segmentation mask. The semantic segmentation mask is received in a semantic segmentation network of a second stage to produce semantic features. Using weights from the first stage as feature extractors and weights from the second stage as classifiers, edges of the cluttered scene are identified using the semantic features.",G06N 3/08; G06N 3/04,INTEL CORPORATION,"YAO, Anbang; ZHAO, Hao; LU, Ming; GUO, Yiwen; CHEN, Yurong","62/509,960 23.05.2017 US; 62/509,990 23.05.2017 US",EP-2018805872
WO2018085724,PCT/US2017/060051,03.11.2017,WO/2018/085724,11.05.2018,WO,QUASI-RECURRENT NEURAL NETWORK BASED ENCODER-DECODER MODEL,"The technology disclosed provides a quasi-recurrent neural network (QRNN) that alternates convolutional layers, which apply in parallel across timesteps, and minimalist recurrent pooling layers that apply in parallel across feature dimensions.",G06N 3/04; G10L 15/16; G10L 15/18; G06F 17/20; G10L 25/30,"SALESFORCE.COM, INC.","BRADBURY, James; MERITY, Stephen, Joseph; XIONG, Caiming; SOCHER, Richard","62/417,333 04.11.2016 US; 62/418,075 04.11.2016 US; 15/420,801 31.01.2017 US; 15/420,710 31.01.2017 US",CA-3040153; JP-2019523049; CN-201780068559.X; AU-2017355537; EP-2017798367
WO2019226051,PCT/NL2019/050301,24.05.2019,WO/2019/226051,28.11.2019,WO,"MONITORING AND ANALYZING BODY LANGUAGE WITH MACHINE LEARNING, USING ARTIFICIAL INTELLIGENCE SYSTEMS FOR IMPROVING INTERACTION BETWEEN HUMANS, AND HUMANS AND ROBOTS","There is provided a body language system for determining a body language message of a living being in a context, said system comprising an artificial intelligence (AI) system, said AI system running a computer program that: - retrieves at least one image of said living being showing body language; - labels said living being in said at least one image, resulting in a labeled living being; - determines said context from said at least one image using a trained machine learning model; - determines a baseline body language of said labeled living being from said at least one image using a trained machine learning model; - adapts a trained machine learning model of said AI system using said baseline body language and said context; - applies the adapted trained machine learning model of said AI system to at least one of said at least one image for categorizing said body language resulting in a category, and applying said category for determining said body language message.",G06K 9/00,KEPLER VISION TECHNOLOGIES B.V.,"STOKMAN, Henricus Meinardus Gerardus; VAN OLDENBORGH, Marc Jean Baptist; ALNAJAR, Fares",2020989 25.05.2018 NL; 2020996 28.05.2018 NL,EP-2019743015
WO2019133506,PCT/US2018/067213,21.12.2018,WO/2019/133506,04.07.2019,WO,INTELLIGENT ROUTING SERVICES AND SYSTEMS,"A source content routing system is described for distributing source content received from clients such as documents, to translators for performing translation services on the source content. The routing system extracts source content features, which may be represented as vectors. The vectors may be assembled into an input matrix, which may be processed using an artificial neural network, classifier, perceptron, CRF model, and/or the like, to select a translator such as a machine translation system and/or human. The translator provides translation services translation from a source language to a target language, post translation editing, proof reading, quality analysis of a machine, quality analysis of human translation, and/or the like and returns the product to the content routing system or clients.",G06F 17/27; G06F 17/20; G06F 17/21; G06F 17/28,SDL INC.,"VLAD, Mihai; ECHIHABI, Abdessamad","62/610,591 27.12.2017 US; 16/226,419 19.12.2018 US",
WO2011094090,PCT/US2011/021530,18.01.2011,WO/2011/094090,04.08.2011,WO,ENHANCED SPEECH-TO-SPEECH TRANSLATION SYSTEM AND METHODS,"A speech translation system and methods for cross-lingual communication that enable users to improve and modify content and usage of the system and easily abort or reset translation. The system includes a speech recognition module configured for accepting an utterance, a machine translation module, an interface configured to communicate the utterance and proposed translation, a correction module and an abort action unit that removes any hypotheses or partial hypotheses and terminates translation. The system also includes modules for storing favorites, changing language mode, automatically identifying language, providing language drills, viewing third party information relevant to conversation, among other things.",G10L 15/18; G06F 17/28; G10L 15/06; G10L 15/22,"MOBILE TECHNOLOGIES, LLC; WAIBEL, Alexender; LANE, Ian, R.","WAIBEL, Alexender; LANE, Ian, R.","12/689,042 18.01.2010 US",EP-2014190061; EP-2011702324
WO2019101836,PCT/EP2018/082162,22.11.2018,WO/2019/101836,31.05.2019,WO,POPULATION BASED TRAINING OF NEURAL NETWORKS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for training a neural network. A method includes: training a neural network having a plurality of network parameters to perform a particular neural network task and to determine trained values of the network parameters using an iterative training process having a plurality of hyperparameters, the method comprising: maintaining a plurality of candidate neural networks and, for each of the candidate neural networks, data specifying: (i) respective values of the network parameters for the candidate neural network, (ii) respective values of the hyperparameters for the candidate neural network, and (iii) a quality measure that measures a performance of the candidate neural network on the particular neural network task; and for each of the plurality of candidate neural networks, repeatedly performing additional training operations.",G06N 3/08; G06N 3/12; G06N 5/00,DEEPMIND TECHNOLOGIES LIMITED,"JADERBERG, Maxwell Elliot; CZARNECKI, Wojciech; GREEN, Timothy Frederick Goldie; DALIBARD, Valentin Clement","62/590,177 22.11.2017 US",
WO2017210613,PCT/US2017/035767,02.06.2017,WO/2017/210613,07.12.2017,WO,NATURAL LANGUAGE GENERATION IN A SPOKEN DIALOGUE SYSTEM,"Described herein are systems and methods for providing a natural language generator in a spoken dialogue system that considers both lexicalized and delexicalized dialogue act slot-value pairs when translating one or more dialogue act slot-value pairs into a natural language output. Each slot and value associated with the slot in a dialogue act are represented as (dialogue act + slot, value), where the first term (dialogue act + slot) is delexicalized and the second term (value) is lexicalized. Each dialogue act slot-value representation is processed to produce to produce at least one delexicalized sentence as an output. A lexicalized sentence is produced by replacing each delexicalized slot with the value associated with the delexicalized slot.",G06F 17/28,MALUUBA INC.,"SHARMA, Shikhar; HE, Jing; SULEMAN, Kaheer; BACHMAN, Philip; SCHULZ, Hannes","62/345,456 03.06.2016 US",CN-201780033548.8; EP-2017730017
EP12741101,95309041,12.12.1995,0717364,19.06.1996,EP,Method for expecting correction information in a natural language processing system,"A natural language processing system and method in which, in order to achieve a high accuracy of recognition of natural language information, a series of natural language information groups is progressively and sequentially recognized, with reference to a knowledge base which contains knowledge concerning the types of natural language information to be processed and knowledge concerning restriction in regard to the sequence of units of the series of natural language groups. In the course of the sequential recognition, the kind of the object to be recognized subsequently is expected based on the kinds of objects in the series of information groups which have been recognized, and a recognition result of the type which coincides with the expected type is delivered as a candidate output. <IMAGE>",G06F 9/44; G06F 17/27; G06F 17/28; G06K 9/72; G06N 5/04,CANON KK,SUDA ARUNA R; JEYACHANDRAN SURESH,30889694 13.12.1994 JP,
WO2019219963,PCT/EP2019/062911,20.05.2019,WO/2019/219963,21.11.2019,WO,NEURAL NETWORKS WITH RELATIONAL MEMORY,"DeepMind Technologies Limited M ay 20, 2019 F&R ref.: 45288-0008WO 2 ABSTRACT A system including one or more computers and one or more storage devices storing instructions that when executed by the one or more computers cause the one or more computers to implement a memory and memory-based neural network is described. The memory is configured to store a respective memory vector at each of a plurality of memory locations in the memory. The memory-based neural network is configured to: at each of a plurality of time steps: receive an input; determine an update to the memory, wherein determining the update comprising applying an attention mechanism over the memory vectors in the memory and the received input; update the memory using the determined update to the memory; and generate an output for the current time step using the updated memory.",G06N 3/04,DEEPMIND TECHNOLOGIES LIMITED,"RAE, Jack William; FAULKNER, Ryan; WEBER, Theophane Guillaume; RAPOSO, David Nunes; SANTORO, Adam Anthony; CHRZANOWSKI, Mike","62/673,818 18.05.2018 US",
WO2019177819,PCT/US2019/020853,05.03.2019,WO/2019/177819,19.09.2019,WO,NATURAL LANGUAGE TO API CONVERSION,"Representative embodiments disclose mechanisms to map natural language input to an application programming interface (API) call. The natural language input is first mapped to an API frame, which is a representation of the API call without any API call formatting. The mapping from natural language input to API frame is performed using a trained sequence to sequence neural model. The sequence to sequence neural model is decomposed into small prediction units called modules. Each module is highly specialized at predicting a pre-defined kind of sequence output. The output of the modules can be displayed in an interactive user interface that allows the user to add, remove, and/or modify the output of the individual modules. The user input can be used as further training data. The API frame is mapped to an API call using a deterministic mapping.",G06N 3/02; G06F 17/20,"MICROSOFT TECHNOLOGY LICENSING, LLC","AWADALLAH, Ahmed Hassan; WANG, Miaosen; WHITE, Ryen; SU, Yu","15/919,209 13.03.2018 US",
WO2009087431,PCT/IB2008/000018,07.01.2008,WO/2009/087431,16.07.2009,WO,A FRAMEWORK FOR NATURAL LANGUAGE PROCESSING,"A framework provides a method by which Natural Language Processing (NLP) modules (and any other additional modules) can be combined in a modular manner period. This frame work offers a very flexible, module-independent and efficient platform to build NLP applications such as machine translation, search engines, information extraction system and cross language information retrieval systems. This approach is particularly suitable in artificial intelligence (Al), in general, where modules may or may not be able to perform their task with 100% accuracy, and yet must work together without significant drop in over all accuracy.",G06F 17/27,"INTERNATIONAL INSTITUTE OF INFORMATION TECHNOLOGY; SANGAL, Rajeev","SANGAL, Rajeev",,
WO2019202073,PCT/EP2019/060070,18.04.2019,WO/2019/202073,24.10.2019,WO,NEURAL NETWORKS FOR SCALABLE CONTINUAL LEARNING IN DOMAINS WITH SEQUENTIALLY LEARNED TASKS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for scalable continual learning using neural networks. One of the methods includes receiving new training data for a new machine learning task; training an active subnetwork on the new training data to determine trained values of the active network parameters from initial values of the active network parameters while holding current values of the knowledge parameters fixed; and training a knowledge subnetwork on the new training data to determine updated values of the knowledge parameters from the current values of the knowledge parameters by training the knowledge subnetwork to generate knowledge outputs for the new training inputs that match active outputs generated by the trained active subnetwork for the new training inputs.",G06N 3/04; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"SCHWARZ, Jonathan; PASCANU, Razvan; HADSELL, Raia Thais; CZARNECKI, Wojciech; THE, Yee Whye; LUKETINA, Jelena","62/659,610 18.04.2018 US",
WO2018182357,PCT/KR2018/003774,30.03.2018,WO/2018/182357,04.10.2018,WO,DATA LEARNING SERVER AND METHOD FOR GENERATING AND USING LEARNING MODEL THEREOF,"An apparatus and a method for a data learning server is provided. The apparatus of the disclosure includes a communicator configured to communicate with an external device, at least one processor configured to acquire a set temperature set in an air conditioner and a current temperature of the air conditioner at the time of setting the temperature via the communicator, and a generate or renew a learning model using the set temperature and the current temperature, and a storage configured to store the generated or renewed learning model to provide a recommended temperature to be set in the air conditioner as a result of generating or renewing the learning model. For example, the data learning server of the disclosure may generate a learned learning model to provide a recommended temperature using a neural network algorithm, a deep learning algorithm, a linear regression algorithm, or the like as an artificial intelligence algorithm.",F24F 11/30; G06N 3/02; F24F 11/65; F24F 11/59; F24F 11/52; F24F 11/62; F24F 120/20; F24F 110/10; F24F 110/20,"SAMSUNG ELECTRONICS CO., LTD.","OCK, Hyun-woo; KIM, Min-kyong; KIM, Tan; SONG, Hyung-seon; SHIN, Dong-jun; IM, Sung-bin; SEO, Hyeong-joon; JOO, Young-ju","62/479,207 30.03.2017 US; 10-2017-0123239 25.09.2017 KR",CA-3058373; EP-2018753038; CN-201880022241.2; AU-2018246843
WO2020073085,PCT/AU2019/051086,09.10.2019,WO/2020/073085,16.04.2020,WO,METHOD AND SYSTEM FOR PROVIDING CHATBOTS WITHIN INSTANT MESSAGING APPLICATIONS,"The invention relates, in one aspect, to a method, comprising displaying a visual avatar of a chatbot in a contact list of a user of an instant messaging application; receiving an instant message from the user to the visual avatar of the chatbot within the instant messaging application; processing the instant message from the user using a chatbot system to generate a contextual response from the visual avatar of the chatbot; and displaying the contextual response from the visual avatar of the chatbot to the user within the instant messaging application.",G06F 17/28; G06F 17/27; G06F 3/00; G06F 15/00,EICHAT PTY LTD,"HUILGOL, Ravi",2018903809 09.10.2018 AU,
WO2020036490,PCT/NL2019/050533,15.08.2019,WO/2020/036490,20.02.2020,WO,A METHOD AND SYSTEM FOR AUTOMATICALLY ANNOTATING AND IDENTIFYING A LIVING BEING OR AN OBJECT WITH AN IDENTIFIER PROVIDING A SUBJECT IDENTIFICATION,"The invention relates to a method for training a machine learning model to identify a subject having at least one machine readable identifier providing a subject ID, said method comprising: providing a computer vision system with an image capturing system comprising at least one image capturing device, and a reader system comprising at least one reader for reading said at least one machine readable identifier; defining said machine learning model in said computer vision system; capturing a first image using said image capturing system, said first image showing said subject; reading said subject ID using said reader system when capturing said first image, and linking said subject ID with said first image, said linking providing said first image with a linked subject ID, providing a first annotated image; capturing at least one further image showing said subject, linking said linked subject ID to said at least one further image providing at least one further annotated image, and subjecting said first annotated image and said at least one further annotated image to said machine learning model for training said machine learning model.",G06K 9/00,KEPLER VISION TECHNOLOGIES BV,"VAN OLDENBORGH, Marc Jean Baptist; SNOEK, Cornelis Gerardus Maria",2021481 17.08.2018 NL; 2021498 24.08.2018 NL,
WO2009002864,PCT/US2008/067721,20.06.2008,WO/2009/002864,31.12.2008,WO,MACHINE TRANSLATION FOR QUERY EXPANSION,"Methods, systems and apparatus, including computer program products, for expanding search queries. One method includes receiving a search query, selecting a synonym of a term in the search query based on a context of occurrence of the term in the received search query, the synonym having been derived from statistical machine translation of the term, and expanding the received search query with the synonym and using the expanded search query to search a collection of documents. Alternatively, another method includes receiving a request to search a corpus of documents, the request specifying a search query, using statistical machine translation to translate the specified search query into an expanded search query, the specified search query and the expanded search query being in the same natural language, and in response to the request, using the expanded search query to search a collection of documents.",G06F 17/28,"GOOGLE INC.; RIEZLER, Stefan; VASSERMAN, Alexander, L.","RIEZLER, Stefan; VASSERMAN, Alexander, L.","60/945,903 22.06.2007 US; 12/050,022 17.03.2008 US",CN-200880102717.X; EP-2008771627
WO2017049350,PCT/AU2016/050884,22.09.2016,WO/2017/049350,30.03.2017,WO,"METHODS FOR THE AUTOMATED GENERATION OF SPEECH SAMPLE ASSET PRODUCTION SCORES FOR USERS OF A DISTRIBUTED LANGUAGE LEARNING SYSTEM, AUTOMATED ACCENT RECOGNITION AND QUANTIFICATION AND IMPROVED SPEECH RECOGNITION","Methods for automated generation of speech sample asset production scores for users of a distributed language learning system, automated accent recognition and quantification and improved speech recognition. Utilising a trained supervised machine learning module which is trained utilising a training set comprising a plurality of production speech sample asset recordings, associated production scores generated by system users performing perception exercises and user background information. The trained supervised machine learning module may be configured for automated accent recognition, by feeding a candidate production speech sample asset so as to automate the generation of a speech sample asset production score and user background information. As such, the user background information may be translated into an accent type categorisation and the speech sample asset production score may be translated into an accent strength. In further embodiments, the accent type categorisation generated using the trained system may be utilised for improved speech recognition.",G09B 19/06; G09B 5/04; G06F 15/18; G06F 17/28,VENDOME CONSULTING PTY LTD,"CASSAGNE, Gregory; SCHAPOTSCHNIKOW, Philipp",2015903856 22.09.2015 AU,US-15762062; EP-2016847648; AU-2016327448
WO2020068831,PCT/US2019/052703,24.09.2019,WO/2020/068831,02.04.2020,WO,DYNAMIC GRAPH REPRESENTATION LEARNING VIA ATTENTION NETWORKS,"A method includes extracting, by an analysis computer, a plurality of first datasets from a plurality of graph snapshots using a structural self-attention module. The analysis computer can then extract at least a second dataset from the plurality of first datasets using a temporal self-attention module across the plurality of graph snapshots. The analysis computer can then perform graph context prediction with at least the second dataset.",G06F 16/901; G06N 5/02; G06N 20/00,VISA INTERNATIONAL SERVICE ASSOCIATION,"SANKAR, Aravind; WU, Yanhong; GOU, Liang; ZHANG, Wei; YANG, Hao","62/736,953 26.09.2018 US",
EP236491132,17766614,13.03.2017,3432227,23.01.2019,EP,LEARNING SERVICE PROVISION DEVICE,"Provided is a mechanism for improving the efficiency of development operations for adding a new ability to an apparatus. Also, a mechanism is provided with which even a person who does not have a knowledge and a system relating to machine learning can easily add a new ability acquired by machine learning to his/her apparatus. A request acceptance unit accepts, as learning request information, information necessary for performing machine learning with respect to an ability to be added to a target apparatus, from a requester. A learning simulator performs machine learning according to the learning request information accepted from the requester. An ability providing data generation unit generates, based on a learning result obtained by the learning simulator, ability providing data, which is data for adding a new ability acquired as the learning result to the target apparatus. A service providing unit provides the ability providing data to the requester.",G06N 99/00; G06F 8/71; G06F 9/445; G06K 9/00; G06K 9/46; G06K 9/62; G06N 3/063; G06N 3/08; G06N 3/10,OMRON TATEISI ELECTRONICS CO,ANDO TANICHI,2016049236 14.03.2016 JP; 2017009984 13.03.2017 JP,
WO2018085729,PCT/US2017/060057,03.11.2017,WO/2018/085729,11.05.2018,WO,DEEP NEURAL NETWORK MODEL FOR PROCESSING DATA THROUGH MULTIPLE LINGUISTIC TASK HIERARCHIES,"The technology disclosed provides a so-called ""joint many-task neural network model"" to solve a variety of increasingly complex natural language processing (NLP) tasks using growing depth of layers in a single end-to-end model. The model is successively trained by considering linguistic hierarchies, directly connecting word representations to all model layers, explicitly using predictions in lower tasks, and applying a so-called ""successive regularization"" technique to prevent catastrophic forgetting. Three examples of lower level model layers are part-of-speech (POS) tagging layer, chunking layer, and dependency parsing layer. Two examples of higher level model layers are semantic relatedness layer and textual entailment layer. The model achieves the state-of-the-art results on chunking, dependency parsing, semantic relatedness and textual entailment.",G06N 3/04; G10L 15/16; G10L 15/18; G10L 25/30; G06F 17/20,"SALESFORCE.COM, INC.","HASHIMOTO, Kazuma; XIONG, Caiming; SOCHER, Richard","62/417,269 03.11.2016 US; 62/418,070 04.11.2016 US; 15/421,424 31.01.2017 US; 15/421,407 31.01.2017 US; 15/421,431 31.01.2017 US",EP-2017797845; JP-2019522984; CN-201780068577.8; CA-3039386
WO2018085730,PCT/US2017/060059,03.11.2017,WO/2018/085730,11.05.2018,WO,TRAINING A JOINT MANY-TASK NEURAL NETWORK MODEL USING SUCCESSIVE REGULARIZATION,"The technology disclosed provides a so-called ""joint many-task neural network model"" to solve a variety of increasingly complex natural language processing (NLP) tasks using growing depth of layers in a single end-to-end model. The model is successively trained by considering linguistic hierarchies, directly connecting word representations to all model layers, explicitly using predictions in lower tasks, and applying a so-called ""successive regularization"" technique to prevent catastrophic forgetting. Three examples of lower level model layers are part-of-speech (POS) tagging layer, chunking layer, and dependency parsing layer. Two examples of higher level model layers are semantic relatedness layer and textual entailment layer. The model achieves the state-of-the-art results on chunking, dependency parsing, semantic relatedness and textual entailment.",G06N 3/04; G10L 15/16; G10L 15/18; G10L 25/30; G06F 17/20,"SALESFORCE.COM, INC.","HASHIMOTO, Kazuma; XIONG, Caiming; SOCHER, Richard","62/417,269 03.11.2016 US; 62/418,070 04.11.2016 US; 15/421,431 31.01.2017 US; 15/421,407 31.01.2017 US; 15/421,424 31.01.2017 US",CA-3039551; CN-201780068346.7; JP-2019522896; EP-2017801556
WO2018213840,PCT/US2018/033732,21.05.2018,WO/2018/213840,22.11.2018,WO,DEPTHWISE SEPARABLE CONVOLUTIONS FOR NEURAL MACHINE TRANSLATION,"Methods, systems, and apparatus, including computer programs encoded on computer storage media for performing machine translation tasks. One method includes receiving an input text segment in an input language; processing the input text segment using an encoder neural network to generate an encoder neural network output, the encoder neural network comprising multiple depth wise separable convolutional neural network layers; processing the encoder neural network output using an autoregressive decoder neural network to generate a decoder neural network output; and processing the decoder neural network output to generate a predicted output text segment in a target natural language.",G06N 3/04,GOOGLE LLC,"GOMEZ, Aidan Nicholas; KAISER, Lukasz Mieczyslaw; CHOLLET, Francois","62/509,038 19.05.2017 US",EP-2018734997; CN-201880028541.1
WO2019138289,PCT/IB2018/060736,31.12.2018,WO/2019/138289,18.07.2019,WO,MACHINE LEARNING TO INTEGRATE KNOWLEDGE AND NATURAL LANGUAGE PROCESSING,"A system, computer program product, and method are provided to automate a framework for knowledge graph based persistence of data, and to resolve temporal changes and uncertainties in the knowledge graph. Natural language understanding, together with one or more machine learning models (MLMs), is used to extract data from unstructured information, including entities and entity relationships. The extracted data is populated into a knowledge graph. As the KG is subject to change, the KG is used to create new and retrain existing machine learning models (MLMs). Weighting is applied to the populated data in the form of veracity value. Blockchain technology is applied to the populated data to ensure reliability of the data and to provide auditability to assess changes to the data.",G06F 17/28,INTERNATIONAL BUSINESS MACHINES CORPORATION; IBM UNITED KINGDOM LIMITED; IBM (CHINA) INVESTMENT COMPANY LIMITED,"BACARELLA, David; BARNEBEE, James; LAWRENCE, Nicholas; PATEL, Sumit","15/866,698 10.01.2018 US",
WO2020080773,PCT/KR2019/013446,14.10.2019,WO/2020/080773,23.04.2020,WO,SYSTEM AND METHOD FOR PROVIDING CONTENT BASED ON KNOWLEDGE GRAPH,"Provided are an artificial intelligence (AI) system using a machine learning algorithm and an application of the AI system. A device for providing content based on a knowledge graph includes: a processor configured to execute instructions to: obtain context information related to the device; obtain a first device knowledge graph of a user of the device by inputting the obtained context information to a first AI model for determining a relation between entities related to the user of the device; request, from a server, a server knowledge graph generated by the server; receive the server knowledge graph; obtain a second device knowledge graph of the user by inputting the obtained first device knowledge graph and the received server knowledge graph to a second AI model for extending the first device knowledge graph; and provide content based on the obtained second device knowledge graph.",G06Q 50/10; G06N 20/00; G06N 3/02,"SAMSUNG ELECTRONICS CO., LTD.","LEE, Jaehun; LEE, Yunsu; HWANG, Taeho; PARK, Jungho; JEONG, Mirae; KANG, Jiyoung",10-2018-0123272 16.10.2018 KR,
EP289344239,19182451,25.06.2019,3617883,04.03.2020,EP,INFERENCE ENGINE ACCELERATION FOR VIDEO ANALYTICS IN COMPUTING ENVIRONMENTS,"A mechanism is described for facilitating deep learning inference acceleration in computing environments. An apparatus of embodiments, as described herein, includes one or more processors to compare a current input value associated with a layer of a plurality of layers of a neural network to a cached input value associated with the layer. The one or more processors are further to import the cached input value for the layer for further processing within the neural network, if the current input value and the cached input value are equal.",G06F 9/54; G06N 3/04; G06N 3/063; G06N 3/08,INTEL CORP,CHEN FAN,201816114818 28.08.2018 US,
WO2018140885,PCT/US2018/015753,29.01.2018,WO/2018/140885,02.08.2018,WO,MEMORY SIDE ACCELERATION FOR DEEP LEARNING PARAMETER UPDATES,"Examples disclosed herein relate to using a memory side accelerator to calculate updated deep learning parameters. A globally addressable memory includes deep learning parameters. The deep learning parameters are partitioned, where each partition is associated with a memory side accelerator. A memory side accelerator is to receive calculated gradient updates associated with its partition and calculate an update to the deep learning parameters associated with the partition.",G06N 3/08; G06N 3/04; G06F 9/22,HEWLETT PACKARD ENTERPRISE DEVELOPMENT LP,"XU, Cong; CAI, Qiong","15/417,760 27.01.2017 US",
EP12939005,97106582,21.04.1997,0805402,05.11.1997,EP,Document conversion system for processing typographie effects,"When natural-language processing is applied to a document containing embedded information specifying typographical effects, the embedded information is first converted, so that each unit of embedded information applies to only one unit of the natural language, then concealed, so that the natural-language processing can be carried out on the natural-language units alone. After the natural-language processing, the embedded information can be restored, and redundant items of embedded information can be removed. <IMAGE>",G06F 17/21; G06F 17/22; G06F 17/27; G06F 17/28,OKI ELECTRIC IND CO LTD,SUGIO TOSHIYUKI,10909396 30.04.1996 JP; 10910096 30.04.1996 JP,
WO2018203147,PCT/IB2018/000935,23.04.2018,WO/2018/203147,08.11.2018,WO,MULTI-LINGUAL SEMANTIC PARSER BASED ON TRANSFERRED LEARNING,"The disclosure relates to transferred learning from a first language (e.g., a source language for which a semantic parser has been defined) to a second language (e.g., a target language for which a semantic parser has not been defined). A system may use knowledge from a trained model in one language to model another language. For example, the system may transfer knowledge of a semantic parser from a first (e.g., source) language to a second (e.g., target) language. Such transfer of knowledge may occur and be useful when the first language has sufficient training data but the second language has insufficient training data. The foregoing transfer of knowledge may extend the semantic parser for multiple languages (e.g., the first language and the second language).",G06F 17/27; G10L 15/18; G10L 21/00,"NUANCE COMMUNICATIONS, INC.","DUONG, Long; AFSHAR, Hadi; ESTIVAL, Dominique; PINK, Glen; COHEN, Philip; JOHNSON, Mark, Edward","62/488,838 23.04.2017 US",EP-2018794176
WO2013016071,PCT/US2012/047049,17.07.2012,WO/2013/016071,31.01.2013,WO,CUSTOMIZATION OF NATURAL LANGUAGE PROCESSING ENGINE,"A method, an apparatus and an article of manufacture for customizing a natural language processing engine. The method includes enabling selection of one or more parameters of a desired natural language processing task, the one or more parameters intended for use by a trained and an untrained user, mapping the one or more selected parameters to a collection of one or more intervals of an input parameter to an optimization algorithm, and applying the optimization algorithm with the collection of one or more intervals of an input parameter to a model used by a natural language processing engine to produce a customized model.",G06F 17/27,"INTERNATIONAL BUSINESS MACHINES CORPORATION; ZHAO, Bing; CASTELLI, Vittorio","ZHAO, Bing; CASTELLI, Vittorio","13/190,962 26.07.2011 US",GB-1401199.3
EP248178206,18209351,29.11.2018,3509017,10.07.2019,EP,EFFICIENT CONVOLUTION IN MACHINE LEARNING ENVIRONMENTS,"A mechanism is described for facilitating smart convolution in machine learning environments. An apparatus of embodiments, as described herein, includes one or more processors including one or more graphics processors, and detection and selection logic to detect and select input images having a plurality of geometric shapes associated with an object for which a neural network is to be trained. The apparatus further includes filter generation and storage logic (""filter logic"") to generate weights providing filters based on the plurality of geometric shapes, where the filter logic is further to sort the filters in filter groups based on common geometric shapes of the plurality of geographic shapes, and where the filter logic is further to store the filter groups in bins based on the common geometric shapes, wherein each bin corresponds to a geometric shape.",G06N 3/04; G06N 3/063; G06N 3/08,INTEL CORP,SRIVASTAVA DHAWAL,201715859487 30.12.2017 US,
WO2016070034,PCT/US2015/058300,30.10.2015,WO/2016/070034,06.05.2016,WO,TRANSFER LEARNING FOR BILINGUAL CONTENT CLASSIFICATION,"This disclosure provides systems and methods for determining a classification model for a secondary language different from a primary language. A social networking server is configured to obtain primary language content written in a first spoken language and secondary language content written in a second spoken language. The social networking server further obtains a machine translation of the primary language content. The social networking server then determines an initial language model from the machine translation. The social networking further determines a language model perturbation using the initial language model, where the language model perturbation accounts for a difference between the machine translation and the secondary language content. The social networking server also determines a classification model from the initial language model and the language model perturbation, which is then applied to a plurality of comments associated with an item of interest provided by a social networking service.",G06Q 50/00; G06F 17/27,LINKEDIN CORPORATION,"AMIN, Mohammad Shafkat; YAN, Baoshi; MARTELL, Craig; MARKMAN, Vita; BHASIN, Anmol","62/073,556 31.10.2014 US",
EP283378001,18776062,26.01.2018,3605407,05.02.2020,EP,"INFORMATION PROCESSING DEVICE, INFORMATION PROCESSING METHOD, AND COMPUTER-READABLE STORAGE MEDIUM","An information processing apparatus includes acquisition means for acquiring first training data that includes data and a label for target task learning, and second training data that includes data and a label for watermark detection, and learning means for generating a model parameter constituting a machine learning model for detecting a target task or a watermark based on the first training data and the second training data.",G06N 99/00; G06F 21/16; G06N 20/00,KDDI CORP,KOBAYASHI TATSUYA,2017072610 31.03.2017 JP; 2018002369 26.01.2018 JP,
WO2015048480,PCT/US2014/057767,26.09.2014,WO/2015/048480,02.04.2015,WO,PRESENTING STATISTICAL DATA IN A NATURAL LANGUAGE FORMAT,"A computer-implemented method for presenting statistical analysis in a natural language textual output comprising: receiving data to be analyzed by the processor; processing the data according to at least one of a plurality of pre-established statistical analysis types, thereby providing processed data; interpreting the processed data by converting the processed data to a pre-determined natural language text, thereby providing interpreted data; and generating a natural language textual output for the interpreted data according to at least one pre-established rule for converting the interpreted data to a natural language textual output.",G06F 17/28,"STATISTICS SOLUTIONS, LLC","LANI, James, A.; MORAN, Melissa","14/040,029 27.09.2013 US",
WO2018184193,PCT/CN2017/079680,07.04.2017,WO/2018/184193,11.10.2018,WO,ADVANCED ARTIFICIAL INTELLIGENCE AGENT FOR MODELING PHYSICAL INTERACTIONS,"Described herein are advanced artificial intelligence agents for modeling physical interactions. An apparatus to provide an active artificial intelligence (AI) agent includes at least one database to store physical interaction data and compute cluster coupled to the at least one database. The compute cluster automatically obtains physical interaction data from a data collection module without manual interaction, stores the physical interaction data in the at least one database, and automatically trains diverse sets of machine learning program units to simulate physical interactions with each individual program unit having a different model based on the applied physical interaction data.",G06F 17/30,"INTEL CORPORATION; YAO, Anbang; CAI, Dongqi; WANG, Libin; XU, Lin; HU, Ping; WANG, Shandong; CHENG, Wenhua; GUO, Yiwen; YANG, Liu; HOU, Yuqing; SU, Zhou","YAO, Anbang; CAI, Dongqi; WANG, Libin; XU, Lin; HU, Ping; WANG, Shandong; CHENG, Wenhua; GUO, Yiwen; YANG, Liu; HOU, Yuqing; SU, Zhou",,EP-2017904807; CN-201780088086.X
EP232159380,18162142,15.03.2018,3392825,24.10.2018,EP,EXTEND GPU/CPU COHERENCY TO MULTI-GPU CORES,"In an example, an apparatus comprises a plurality of processing unit cores, a plurality of cache memory modules associated with the plurality of processing unit cores, and a machine learning model communicatively coupled to the plurality of processing unit cores, wherein the plurality of cache memory modules share cache coherency data with the machine learning model. Other embodiments are also disclosed and claimed.",G06T 1/20,INTEL CORP,SAKTHIVEL CHANDRASEKARAN; SURTI PRASOONKUMAR; WEAST JOHN C; BAGHSORKHI SARA S; GOTTSCHLICH JUSTIN E; APPU ABHISHEK R; GALOPPO VON BORRIES NICOLAS C; RAY JOYDEEP; SRINIVASA NARAYAN; CHEN FENG; ASHBAUGH BEN J; BARIK RAJKISHORE; LIN TSUNG-HAN; SINHA KAMAL; NURVITADHI ERIKO; VEMBU BALAJI; KOKER ALTUG,201715489149 17.04.2017 US,
WO2009026337,PCT/US2008/073671,20.08.2008,WO/2009/026337,26.02.2009,WO,ENHANCED REJECTION OF OUT-OF-VOCABULARY WORDS,"Enhanced rejection of out-of-vocabulary words, in which, based on applying an input gesture to hidden Markov models collectively modeling a vocabulary of training gestures, a likelihood that the input gesture matches each training gesture, and a quantity of states of the input gesture that match corresponding states of a modeled training gesture determined to have a highest likelihood are determined. The input gesture is rejected if the determined quantity does not satisfy a threshold.",G06F 17/28,"GESTURETEK, INC.; SHAMAIE, Atid; MACDOUGALL, Francis","SHAMAIE, Atid; MACDOUGALL, Francis","60/956,784 20.08.2007 US; 60/956,776 20.08.2007 US",CN-200880112388.7; EP-2008827702
WO2018067495,PCT/US2017/054833,03.10.2017,WO/2018/067495,12.04.2018,WO,PROCESSING TEXT SEQUENCES USING NEURAL NETWORKS,"A computer-implemented method for training a neural network that is configured to generate a score distribution over a set of multiple output positions. The neural network is configured to process a network input to generate a respective score distribution for each of a plurality of output positions including a respective score for each token in a predetermined set of tokens that includes n-grams of multiple different sizes. Example methods described herein provide trained neural networks which produce results with improved accuracy compared to the state of the art, e.g. translations that are more accurate compared to the state of the art, or more accurate speech recognition compared to the state of the art.",G06N 3/08,GOOGLE LLC,"JAITLY, Navdeep; ZHANG, Yu; LE, Quoc V.; CHAN, William","62/403,615 03.10.2016 US",EP-2017784512; CN-201780067511.7
WO2009061390,PCT/US2008/012441,04.11.2008,WO/2009/061390,14.05.2009,WO,MACHINE LEARNING SYSTEMS AND METHODS FOR IMPROVED NATURAL LANGUAGE PROCESSING,"Disclosed is a method to generate at least one new set of concepts to be used to perform natural language processing (NLP) on data. The method includes receiving one or more sources of input data, and determining, based on the one or more sources of input data and on at least one initial set of concepts, at least one attribute representative of a type of information detail to be included in the at least one new set of concepts.",G06F 17/28,"ENHANCED MEDICAL DECISIONS, INC.; BEGGELMAN, Marlene, J.; SMYCHKOVICH, Yuri","BEGGELMAN, Marlene, J.; SMYCHKOVICH, Yuri","60/985,402 05.11.2007 US",
WO2016065327,PCT/US2015/057229,23.10.2015,WO/2016/065327,28.04.2016,WO,NEURAL MACHINE TRANSLATION SYSTEMS WITH RARE WORD PROCESSING,"Method, system and apparatus, including computer programs encoded on computer storage media, for neural translation systems with rare word processing. A method of training a neural network translation system to track the source in source sentences of unknown words in target sentences, in a source language and a target language, respectively.",G06F 17/27; G06F 17/28,GOOGLE INC.,"LE, Quoc V.; LUONG, Minh-Thang; SUTSKEVER, Ilya; VINYALS, Oriol; ZAREMBA, Wojciech","62/068,601 24.10.2014 US",EP-2015787870
EP240631690,18194451,14.09.2018,3468140,10.04.2019,EP,NATURAL LANGUAGE PROCESSING ARTIFICIAL INTELLIGENCE NETWORK AND DATA SECURITY SYSTEM,"According to an embodiment, a natural language processing artificial intelligence network and data security system determines an emotions model for one or more users from electronic natural language interactions of the users. The system includes a natural language processing decoder to determine textual features from the electronic natural language interactions that may be indicative of emotional states of the users. They system includes an emotions model encoder that generates an emotions model based on the emotional states of the users in the electronic natural language interactions retrieved from the data storage. The system also includes an artificial intelligence network and data security subsystem. The artificial intelligence network and data security subsystem may use the emotions model as a primitive for artificial intelligence based tasks including computer system security, network security, data security, proactive monitoring and preventive actions, that are moderated using the context provided by the emotional state of a user.",H04L 29/06; G06F 17/27; G06F 21/50; G06N 99/00; H04L 12/58,ACCENTURE GLOBAL SOLUTIONS LTD; MISRAM LLC,BOYADJIEV CONSTANTINE T; CHANDRAMOULI RAJARATHNAM; SHAO ZONGRU; SUBBALAKSHMI KODUVAYUR,201715726137 05.10.2017 US,
WO2008103961,PCT/US2008/054803,22.02.2008,WO/2008/103961,28.08.2008,WO,DIVERSE TOPIC PHRASE EXTRACTION,"Systems and methods for implementing diverse topic phrase extraction are disclosed. According to one implementation, multiple word candidate phrases are extracted from a corpus and weighed. One or more documents are re-weighed to identify less obvious candidate topics using latent semantic analysis (LSA). Phrase diversification is then used to remove redundancy and select informative and distinct topic phrases.",G06F 17/28,MICROSOFT CORPORATION,"ZHANG, Benyu; CHEN, Jilin; CHEN, Zheng; ZENG, HuaJun; WANG, Jian","60/891,189 22.02.2007 US; 11/859,461 21.09.2007 US",
EP13543921,99949601,08.09.1999,1110205,27.06.2001,EP,INTERACTIVE USER INTERFACE USING SPEECH RECOGNITION AND NATURAL LANGUAGE PROCESSING,"A system and method for interacting with a computer using utterances, speech processing and natural language processing. The system comprises a speech processor for searching a first grammar file for a matching phrase for the utterance, and for searching a second grammar file for the matching phrase if the matching phrase is not found in the first grammar file. The system also includes a natural language processor for searching a database for a matching entry for the matching phrase; and an application interface for performing an action associated with the matching entry if the matching entry is found in the database. The system utilizes context-specific grammars, thereby enhancing speech recognition and natural language processing efficiency. Additionally, the system adaptively and interactively 'learns' words and phrases, and their associated meanings.",G06F 17/30; G06F 3/16; G06F 13/00; G06F 17/27; G06F 17/28; G10L 15/00; G10L 15/06; G10L 15/18; G10L 15/19; G10L 15/22; G10L 15/26; G10L 15/28; H04L 29/06,ONE VOICE TECHNOLOGIES INC,WEBER DEAN C,15045998 09.09.1998 US; 9920445 08.09.1999 US,
WO2020081239,PCT/US2019/054445,03.10.2019,WO/2020/081239,23.04.2020,WO,SPEAKING CLASSIFICATION USING AUDIO-VISUAL DATA,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for generating predictions for whether a target person is speaking during a portion of a video. In one aspect, a method includes obtaining one or more images which each depict a mouth of a given person at a respective time point. The images are processed using an image embedding neural network to generate a latent representation of the images. Audio data corresponding to the images is processed using an audio embedding neural network to generate a latent representation of the audio data. The latent representation of the images and the latent representation of the audio data is processed using a recurrent neural network to generate a prediction for whether the given person is speaking.",G10L 17/10; G10L 25/78,GOOGLE LLC,"CHAUDHURI, Sourish; KLEJCH, Ondrej; ROTH, Joseph Edward","16/161,927 16.10.2018 US",
WO2016109102,PCT/US2015/063514,02.12.2015,WO/2016/109102,07.07.2016,WO,USE OF STATISTICAL FLOW DATA FOR MACHINE TRANSLATIONS BETWEEN DIFFERENT LANGUAGES,"In a flow of computer actions, a computer system (110) receives a request involving a machine translation. In performing the translation (160, 238), or in using the translation in subsequent computer operations (242, 1110), the computer system takes into account known statistical relationships (310), obtained from previously accumulated click-through data (180), between a machine translation performed in a flow, the flow's portions preceding the translation, and success indicators pertaining to the flow's portion following the translation. The statistical relationships are derived by data mining of the click-through data. Further, normal actions can be suspended to use a random option to accumulate the click-through data and/or perform statistical AB testing. Other features are also provided.",G06F 17/28,"PAYPAL, INC.","SAWAF, Hassan","14/584,925 29.12.2014 US",DE-112015005839
WO2018057809,PCT/US2017/052819,21.09.2017,WO/2018/057809,29.03.2018,WO,POINTER SENTINEL MIXTURE ARCHITECTURE,"The technology disclosed provides a so-called ""pointer sentinel mixture architecture"" for neural network sequence models that has the ability to either reproduce a token from a recent context or produce a token from a predefined vocabulary. In one implementation, a pointer sentinel-LSTM architecture achieves state of the art language modeling performance of 70.9 perplexity on the Penn Treebank dataset, while using far fewer parameters than a standard softmax LSTM.",G06N 3/04,"SALESFORCE.COM, INC.","MERITY, Stephen Joseph; XIONG, Caiming; BRADBURY, James; SOCHER, Richard","62/397,926 22.09.2016 US; 62/398,461 22.09.2016 US; 62/417,334 04.11.2016 US; 15/421,016 31.01.2017 US",CN-201780060729.X; CA-3034918; JP-2019537050; EP-2017780275
WO2019018548,PCT/US2018/042725,18.07.2018,WO/2019/018548,24.01.2019,WO,"NEURAL NETWORK PROCESSING METHOD, APPARATUS, DEVICE AND COMPUTER READABLE STORAGE MEDIA","A method, an apparatus, a device and a computer readable storage media for neural network processing are disclosed. The method includes constructing a training function having a constraint for a neural network; and solving a constrained optimization based on the training function to obtain connection weights of the neural network. The neural network processing method, apparatus, device and computer readable storage media of the embodiments of the present disclosure model a problem of solving connection weights of a neural network from the perspective of an optimization problem, and can effectively find a solution for the problem of solving the connection weights of the neural network, thus being able to improve the speed of training of the neural network.",G06F 17/27; G06F 17/28; G06N 3/02; G06N 3/08,ALIBABA GROUP HOLDING LIMITED,"LENG, Cong; LI, Hao; DOU, Zesheng; ZHU, Shenghuo; JIN, Rong",201710592048.X 19.07.2017 CN,
WO2018120013,PCT/CN2016/113477,30.12.2016,WO/2018/120013,05.07.2018,WO,ARTIFICIAL NEURAL NETWORK,"According to an example aspect of the present invention, there is provided a method, comprising: resizing a convolutional layer input of an artificial neural network with at least two different scales to obtain multiple groups of intermediate features maps, convolving the intermediate feature maps with a filter, resizing the convolution results to the size of the layer input, and concatenating the resized convolution results to form an output of the convolutional layer.",G06T 7/00; G06N 3/02,"NOKIA TECHNOLOGIES OY; NOKIA TECHNOLOGIES (BEIJING) CO., LTD.","JIANG, Xiaoheng",,
WO2017074785,PCT/US2016/057871,20.10.2016,WO/2017/074785,04.05.2017,WO,METHOD AND SYSTEM FOR STATISTICS-BASED MACHINE TRANSLATION,"Embodiments of the present application provide a method and system for statistics-based machine translation. During operation, the system may obtain at least one text to be translated and localized information. The system may decode the text to be translated. The system may generate a plurality of candidate translations for the text to be translated. For each candidate translation of the plurality of candidate translations, the system may obtain linguistic translation features according to the text to be translated and the candidate translation. The system may extract localized translation features according to the localized information. The system may then apply a translation quality prediction model to calculate translation quality scores for the plurality of candidate translations according to the linguistic translation features and the localized translation features. The system may select a predetermined number of candidate translations with highest translation quality scores as translations of the text to be translated.",G06F 17/20; G06F 17/21; G06F 17/27; G06F 17/28,ALIBABA GROUP HOLDING LIMITED,"HUANG, Rui; LUO, Weihua; LIN, Feng; XU, Xing","201510726342.6 30.10.2015 CN; 15/296,907 18.10.2016 US",EP-2016860535
WO2019089339,PCT/US2018/057485,25.10.2018,WO/2019/089339,09.05.2019,WO,METHOD AND SYSTEM FOR NEURAL NETWORK SYNTHESIS,"According to various embodiments, a method for generating one or more optimal neural network architectures is disclosed. The method includes providing an initial seed neural network architecture and utilizing sequential phases to synthesize the neural network until a desired neural network architecture is reached. The phases include a gradient-based growth phase and a magnitude-based pruning phase.",G06N 3/02; G06F 15/18,THE TRUSTEES OF PRINCETON UNIVERSITY,"DAI, Xiaoliang; YIN, Hongxu; JHA, Niraj, K.","62/580,525 02.11.2017 US",
WO2017180475,PCT/US2017/026636,07.04.2017,WO/2017/180475,19.10.2017,WO,QUERY OPTIMIZER FOR COMBINED STRUCTURED AND UNSTRUCTURED DATA RECORDS,"A method of optimizing a query over a database, the method includes obtaining a set of data records from the database, the data records containing structured data and unstructured data documents, extracting the structured and unstructured data from the set of data records, transforming the structured and unstructured data into a vector that is an element of a weighted vector space, receiving a target data record containing structured and unstructured data, generating a target vector for the target data record, executing a similarity algorithm using the target vector and the weighted vector space generated by the collection of database records to provide a reduced number of data records that are most similar to the target data record, and executing a query against the reduced number of data records that are most similar to the target data record.",G06F 17/30; G06F 17/21; G06F 17/27; G06F 17/28,3M INNOVATIVE PROPERTIES COMPANY,"STANKIEWICZ, Brian J.; ASENDORF, Nicholas A.; SCHUMACHER, Jennifer F.; PETERSON, Kelly S.","62/323,220 15.04.2016 US",CA-3020921; AU-2017250467; EP-2017782889
WO2014071330,PCT/US2013/068360,04.11.2013,WO/2014/071330,08.05.2014,WO,NATURAL LANGUAGE PROCESSING SYSTEM AND METHOD,"A natural language processing system is disclosed herein. Embodiments of the NLP system perform hand-written rule-based operations that do not rely on a trained corpus. Rules can be added or modified at any time to improve accuracy of the system, and to allow the same system to operate on unstructured plain text from many disparate contexts (e.g. articles as well as twitter contexts as well as medical articles) without harming accuracy for any one context.",G06F 17/28,FIDO LABS INC.,"WROCZYNSKI, Michal; KRUPA, Tomasz; LELIWA, Gniewosz; WIACEK, Piotr; STANCYK, Michal","61/721,792 02.11.2012 US",EP-2013851449
EP174003802,14832137,31.07.2014,3028190,08.06.2016,EP,IDENTIFICATION OF SURGERY CANDIDATES USING NATURAL LANGUAGE PROCESSING,"The present invention relates to computer-based clinical decision support tools including, computer-implemented methods, computer systems, and computer program products for clinical decision support. These tools assist the clinician in identifying epilepsy patients who are candidates for surgery and utilize a combination of natural language processing, corpus linguistics, and machine learning techniques.",G06F 17/30; G06F 17/28; G06F 19/00; G06Q 10/10; G16H 10/60,CHILDREN'S HOSPITAL MEDICAL CENTER,PESTIAN JOHN P; GLAUSER TRACY A; HOLLAND KATHERINE D; STANDRIDGE SHANNON MICHELLE; GREINER HANSEL M; COHEN KEVIN BRETONNEL,201361861173 01.08.2013 US; 2014049301 31.07.2014 US,
WO2019032994,PCT/US2018/046265,10.08.2018,WO/2019/032994,14.02.2019,WO,"ORAL, FACIAL AND GESTURE COMMUNICATION DEVICES AND COMPUTING ARCHITECTURE FOR INTERACTING WITH DIGITAL MEDIA CONTENT","The display of digital media content includes graphical user interfaces and predefined data fields that limit interaction between a person and a computing system. An oral communication device and a data enablement platform are provided for ingesting oral conversational data from people, and using machine learning to provide intelligence. At the front end, an oral conversational bot, or chatbot, interacts with a user. The chatbot is specific to a customized digital magazine, which both evolve over time to a user for a given topic. On the backend, the data enablement platform has a computing architecture that ingests data from various external data sources as well as data from internal applications and databases. These data and algorithms are applied to surface new data, identify trends, provide recommendations, infer new understanding, predict actions and events, and automatically act on this computed information. The chatbot then reads out the content to the user.",G10L 15/22; G10L 13/08; G06F 17/28; G10L 13/00,"FACET LABS, LLC","OGAWA, Stuart; SPARKS, Lindsay; NISHIMURA, Koichi; SO, Wilfred P.","62/543,784 10.08.2017 US",
WO2019167296,PCT/JP2018/023961,25.06.2018,WO/2019/167296,06.09.2019,WO,"DEVICE, METHOD, AND PROGRAM FOR NATURAL LANGUAGE PROCESSING","The present invention discloses a natural language processing technology by a neural network with high interpretability. An embodiment of the present disclosure relates to a device having: a learned neural network to which a first natural language sentence is input, and which is caused to learn to output a second natural language sentence according to a predetermined purpose corresponding to the first natural language sentence and correspondence information indicating on the basis of which part information of the first natural language sentence respective parts of the second natural language sentence are generated; and an analysis unit for outputting, by inputting an input text into the learned neural network, a prediction result of an output text according to the predetermined purpose and correspondence information indicating on the basis of which part information of the input text respective parts of the prediction result of the output text is generated.",G06F 17/28; G06F 17/27,NIPPON TELEGRAPH AND TELEPHONE CORPORATION; 日本電信電話株式会社; TOHOKU UNIVERSITY; 国立大学法人東北大学,"SUZUKI, Jun; 鈴木　潤; TAKASE, Sho; 高瀬　翔; INUI, Kentaro; 乾　健太郎; OKAZAKI, Naoaki; 岡▲崎▼　直観; KIYONO, Shun; 清野　舜",2018-034781 28.02.2018 JP,
WO2018097907,PCT/US2017/057251,18.10.2017,WO/2018/097907,31.05.2018,WO,ANSWER TO QUESTION NEURAL NETWORKS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for identifying answers to questions using neural networks. One of the methods includes receiving an input text passage and an input question string; processing the input text passage using an encoder neural network to generate a respective encoded representation for each passage token in the input text passage; at each time step: processing a decoder input using a decoder neural network to update the internal state of the decoder neural network; and processing the respective encoded representations and a preceding output of the decoder neural network using a matching vector neural network to generate a matching vector for the time step; and generating an answer score that indicates how well the input text passage answers a question posed by the input question string.",G06N 3/08,GOOGLE LLC,"LAO, Ni; KAISER, Lukasz, Mieczyslaw; GUPTA, Nitin; MOHIUDDIN, Afroz; POPAT, Preyas","62/410,773 20.10.2016 US",
WO2019231289,PCT/KR2019/006604,31.05.2019,WO/2019/231289,05.12.2019,WO,METHOD AND APPARATUS FOR MACHINE LEARNING BASED WIDE BEAM OPTIMIZATION IN CELLULAR NETWORK,"The present disclosure relates to a pre-5th-Generation (5G) or 5G communication system to be provided for supporting higher data rates Beyond 4th-Generation (4G) communication system such as Long Term Evolution (LTE). The present disclosure relates an artificial intelligence (AI) system and its application that sumltate functions such as recognition and judgment of a human brain using a machine learning algorithm such as deep learning. An apparatus and method for controlling and optimizing the broadcast beam for base stations (BS) using user equipment (UE) measurements with machine learning is provided. The apparatus and method is configured to select a first beam for each BS, send selected beams for each BS, receive measurement information of a first beam from UEs via BSs, preprocess the measurement results, use a neural network or a table for each BS to give a score for each broadcast beam in the beam pool, select a second beam with the highest score for each BS either from a neural network or a table, train the neural network for broadcast beam optimization offline based on a UE distribution pattern and ray-tracing data, identify typical UE distribution patterns based on AI classification algorithms and UE history measurement and location infomraiton, and create scenario-specific ray-tracing data based on typical UE distribution patterns.",H04W 16/28; H04W 24/10; H04W 24/02; H04W 72/04; G06N 3/02; G06N 20/00; H04B 7/06,"SAMSUNG ELECTRONICS CO., LTD.","CHEN, Hao; ZHANG, Jianzhong; SHAFIN, Rubayet; NAM, Younghan","62/679,409 01.06.2018 US; 62/719,964 20.08.2018 US; 62/741,982 05.10.2018 US; 62/743,919 10.10.2018 US; 16/361,061 21.03.2019 US",
WO2018184102,PCT/CA2018/050408,03.04.2018,WO/2018/184102,11.10.2018,WO,SYSTEMS AND METHODS FOR MALICIOUS CODE DETECTION,"There is provided a neural network system for detection of malicious code, the neural network system comprising: an input receiver configured for receiving input text from one or more code input sources; a convolutional neural network unit including one or more convolutional layers, the convolutional unit configured for receiving the input text and processing the input text through the one or more convolutional layers; a recurrent neural network unit including one or more long short term memory layers, the recurrent neural network unit configured to process the output from the convolutional neural network unit to perform pattern recognition; and a classification unit including one or more classification layers, the classification unit configured to receive output data from the recurrent neural network unit to perform a determination of whether the input text or portions of the input text are malicious code or benign code.",G06F 21/56; G06N 3/02; G06N 3/04; G06N 3/08,ROYAL BANK OF CANADA,"SMYTH, Cathal; FONG, Cory; LUI, Yik Chau; CAO, Yanshuai","62/480,856 03.04.2017 US",CA-3058010
WO2020060659,PCT/US2019/041531,12.07.2019,WO/2020/060659,26.03.2020,WO,SYSTEM AND METHOD FOR SYNTHESIS OF COMPACT AND ACCURATE NEURAL NETWORKS (SCANN),"According to various embodiments, a method for generating a compact and accurate neural network for a dataset is disclosed. The method includes providing an initial neural network architecture; performing a dataset modification on the dataset, the dataset modification including reducing dimensionality of the dataset; performing a first compression step on the initial neural network architecture that results in a compressed neural network architecture, the first compression step including reducing a number of neurons in one or more layers of the initial neural network architecture based on a feature compression ratio determined by the reduced dimensionality of the dataset; and performing a second compression step on the compressed neural network architecture, the second compression step including one or more of iteratively growing connections, growing neurons, and pruning connections until a desired neural network architecture has been generated.",G06N 3/02; G06N 3/08; G06F 15/18,THE TRUSTEES OF PRINCETON UNIVERSITY,"HASSANTABAR, Shayan; WANG, Zeyu; JHA, Niraj, K.","62/732,620 18.09.2018 US; 62/835,694 18.04.2019 US",
WO2018085643,PCT/US2017/059909,03.11.2017,WO/2018/085643,11.05.2018,WO,MIXTURE OF EXPERTS NEURAL NETWORKS,"A system includes a neural network that includes a Mixture of Experts (MoE) subnetwork between a first neural network layer and a second neural network layer. The MoE subnetwork includes multiple expert neural networks. Each expert neural network is configured to process a first layer output generated by the first neural network layer to generate a respective expert output. The MoE subnetwork further includes a gating subsystem that selects, based on the first layer output, one or more of the expert neural networks and determine a respective weight for each selected expert neural network, provides the first layer output as input to each of the selected expert neural networks, combines the expert outputs generated by the selected expert neural networks in accordance with the weights for the selected expert neural networks to generate an MoE output, and provides the MoE output as input to the second neural network layer.",G06N 3/04,GOOGLE LLC,"SHAZEER, Noam, M.; MIRHOSEINI, Azalia; MAZIARZ, Krzysztof Stanislaw","62/418,135 04.11.2016 US; 62/432,497 09.12.2016 US",CN-201780068472.2; EP-2017804369; JP-2019522815
WO2019049060,PCT/IB2018/056802,06.09.2018,WO/2019/049060,14.03.2019,WO,FROTH SEGMENTATION IN FLOTATION CELLS,"System (100) and method for generating a bubble segmentation image from a digital froth image of a froth phase of a flotation cell (107). The method comprises receiving the froth image, applying one or more deep learning networks to the froth image, the deep learning networks having been trained with one or more datasets of training images of labelled, predetermined bubble segmentation images to learn to identify features useful for identifying bubble boundaries automatically. The method further comprises generating the bubble segmentation image utilizing the deep learning networks so that the bubble segmentation image includes identified boundary data representing boundaries between bubbles present in the froth image, and outputting the bubble segmentation image.",B03D 1/02; G06K 9/34,STONE THREE DIGITAL (PTY) LTD,"IRWIN, Shaun George; BOTHA, Kristo; VAN DER BIJL, Leendert",2017/06114 08.09.2017 ZA,
EP209681386,16205181,19.12.2016,3239854,01.11.2017,EP,TEXTUAL EMOTION DETECTION,"A method may include receiving a textual input. Topics associated with the textual input and top words associated with each of the topics may be generated by way of Latent Dirichlet Allocation (LDA) topic modeling. Relevance weights may be generated for each emotion associated with the topics generated by the LDA topic modeling. Emotion weights associated with the textual input may be output. The emotion weights may be based, at least in part, on the relevance weights.",G06F 17/27,FUJITSU LTD,SRINIVASAN RAMYA MALUR; CHANDER AJAY,201615143479 29.04.2016 US,
EP134004711,13196364,10.12.2013,2884434,17.06.2015,EP,Method and device for automatic feedback generation,"The present invention relates to a computer implemented method for creating a statistical classification model for automatic feedback generation starting from a set of features describing possible errors and a set of raw data units, each raw data unit comprising at least an answer, correction and feedback. The method comprises: 
a) transforming raw data units to instances composed of one or more differences obtained by comparing the answer to the correction, so assigning a value to features of said set of features, 
b) deriving a set of classes from said feedback of the raw data units, 
c) reducing the number of classes in the set based on similarities between classes, 
d) labelling each instance with one of the classes of the reduced set, and 
e) building the statistical classification model for automatic feedback generation by means of a machine learning classifier using the labelled instances as training data.",G06N 99/00; G10L 15/08,TELEVIC EDUCATION NV,STUBBE BRECHT; LAGATIE RUBEN,13196364 10.12.2013 EP,
WO2019164251,PCT/KR2019/002051,20.02.2019,WO/2019/164251,29.08.2019,WO,METHOD OF PERFORMING LEARNING OF DEEP NEURAL NETWORK AND APPARATUS THEREOF,An encoding apparatus connected to a learning circuit processing learning of a deep neural network and configured to perform encoding for reconfiguring connection or disconnection of a plurality of edges in a layer of the deep neural network using an edge sequence generated based on a random number sequence and dropout information indicating a ratio between connected edges and disconnected edges of a plurality of edges included in a layer of the deep neural network.,G06N 3/08; G06N 5/04; G06N 3/063,"SAMSUNG ELECTRONICS CO., LTD.","KANG, Sungho; KWON, Hyungdal; LEE, Cheon; LIM, Yunjae",10-2018-0020005 20.02.2018 KR,
WO2017130089,PCT/IB2017/050325,23.01.2017,WO/2017/130089,03.08.2017,WO,SYSTEMS AND METHODS FOR NEURAL CLINICAL PARAPHRASE GENERATION,"The present disclosure pertains to a paraphrase generation system. The system comprises one or more hardware processors and/or other components. The system is configured to obtain a training corpus. The training corpus comprises language and known paraphrases of the language. The system is configured to generate, based on the training corpus, a word-level attention-based model and a character- level attention- based model. The system is configured to provide one or more candidate paraphrases of a natural language input based on both the word-level and character-level attention-based models. The word-level attention-based model is a word-level bidirectional long short term memory (LSTM) network and the character-level attention-based model is a character-level bidirectional LSTM network. The word-level and character level LSTM networks are generated based on words and characters in the training corpus. In some embodiments, the LSTM networks are stacked residual LSTM networks comprising residual connections between stacked layers of a given LSTM network.",G06F 17/27; G06F 17/28,KONINKLIJKE PHILIPS N.V.,"AL HASAN, Sheikh Sadid; LIU, Bo; FARRI, Oladimeji Feyisetan; LIU, Junyi; PRAKASH, Aaditya","62/286,989 26.01.2016 US",JP-2018537859; EP-2017701752; US-16072128
WO2020068877,PCT/US2019/052797,24.09.2019,WO/2020/068877,02.04.2020,WO,REINFORCEMENT LEARNING APPROACH TO APPROXIMATE A MENTAL MAP OF FORMAL LOGIC,"Methods, systems, and apparatus, including computer programs language encoded on a computer storage medium for a logic correction system whereby input text is modified to a logical state using a reinforcement learning system with a real-time logic engine. The logic engine is able to extract the symmetry of word relationships and negate relationships into formal logical equations such that an automated theorem prover can evaluate the logical state of the input text and return a positive or negative reward. The reinforcement learning agent optimizes a policy creating a conceptual understanding of the logical system, a 'mental map' of word relationships.",G06N 3/08,"MICHELLE, Archuleta","MICHELLE, Archuleta","62/735,600 24.09.2018 US",
EP12067329,90302676,13.03.1990,0388156,19.09.1990,EP,Natural language processing system,"A natural language sentence generating apparatus comprises a grammatical rule storing section (11) for storing grammatical rules each of which includes a phrase structure part, a semantic part which represents the manner of propagation of attribute information from a particular superordinate category to a subordinate category linked thereto, a condition part which represents an applying condition for the grammatical rule, and a message part which represents a message for imposing limitations on a phrase structure rule utilizing the subordinate category as a new superordinate category. The natural language sentence generating apparatus also comprises a search section (12) for searching the grammatical rule storing section, an interpreting section (13) for interpreting the grammatical rules stored in the grammatical rule storing section, and generating section (14) for generating a phrase structure from a set of information on a grammatical function imparted to a particular grammatical rule by interpreting and applying the particular grammatical rule which is extracted from the grammatical rule storing section by the search section.",G06F 17/27; G06F 17/28,CANON KK,TOKUUME YOSHIHIRO; SHIBATA SHOGO; MASEGI KOICHI,6325389 14.03.1989 JP,
WO2019002996,PCT/IB2018/054034,06.06.2018,WO/2019/002996,03.01.2019,WO,ENHANCED VISUAL DIALOG SYSTEM FOR INTELLIGENT TUTORS,"Systems, methods, and computer program products to perform an operation comprising receiving text input via a chat interface of a tutor application, identifying, by at least one classifier applied to the text input, a concept in the text input, mapping the concept in the text input to at least one of a visual action and a first visual object, generating, based on a first machine learning (ML) model, a first program code statement corresponding to the at least one of the visual action and the first visual object, and executing the first program code statement to modify a visualization interface of the tutor application based on the text input received via the chat interface.",G06F 17/28,INTERNATIONAL BUSINESS MACHINES CORPORATION; IBM UNITED KINGDOM LIMITED; IBM (CHINA) INVESTMENT COMPANY LIMITED,"WATSON, Patrick; AHN, Jae-Wook; CHANG, Maria; SUNDARARAJAN, Sharad, Chandra","15/634,451 27.06.2017 US",DE-112018001952; CN-201880036840.X
WO2019032996,PCT/US2018/046269,10.08.2018,WO/2019/032996,14.02.2019,WO,"ORAL COMMUNICATION DEVICE AND COMPUTING ARCHITECTURE FOR PROCESSING DATA AND OUTPUTTING USER FEEDBACK, AND RELATED METHODS","Typical graphical user interfaces and predefined data fields limit the interaction between a person and a computing system. An oral communication device and a data enablement platform are provided for ingesting oral conversational data from people, and using machine learning to provide intelligence. At the front end, an oral conversational bot, or chatbot, interacts with a user. On the backend, the data enablement platform has a computing architecture that ingests data from various external data sources as well as data from internal applications and databases. These data and algorithms are applied to surface new data, identify trends, provide recommendations, infer new understanding, predict actions and events, and automatically act on this computed information. The chatbot then provides audio data that reflects the information computed by the data enablement platform. The system and the devices, for example, are adaptable to various industries.",G10L 15/22; G10L 13/08; G06F 17/28; G10L 13/00,"FACET LABS, LLC","OGAWA, Stuart; SPARKS, Lindsay; NISHIMURA, Koichi; SO, Wilfred P.","62/543,777 10.08.2017 US",
WO2018216493,PCT/JP2018/018142,10.05.2018,WO/2018/216493,29.11.2018,WO,"LEARNING APPARATUS, LEARNING CONTROL METHOD, AND PROGRAM THEREFOR","In order to provide a technique for shortening the time required for a learning apparatus to achieve a learning purpose, without performing manual manipulation, a learning apparatus configured to learn control of an operation involved in a predetermined task includes: a learning data accepting unit configured to accept learning data containing a learning purpose; a neural network configured to perform learning based on the learning data; and an output unit configured to output a learning result obtained by the neural network, wherein the neural network performs a first learning process for achieving an initial stage of the learning purpose, performs a second learning process for learning control with which an operation involved in the learning is made non-continuable, based on a result of the first learning process, and performs a third learning process for achieving the learning purpose, with the control with which an operation involved in the learning is made non-continuable being excluded, based on a result of the second learning process.",B25J 9/16; G05B 13/02; G05D 1/00; G05D 1/02; G06N 3/08,OMRON CORPORATION,"ANDO, Tanichi",2017-104523 26.05.2017 JP,
WO2019217100,PCT/US2019/029518,27.04.2019,WO/2019/217100,14.11.2019,WO,JOINT NEURAL NETWORK FOR SPEAKER RECOGNITION,A speaker recognition system includes a previously-trained joint neural network. An enrollment machine of the speaker recognition system is configured to operate the previously-trained joint neural network to enroll a new speaker based on audiovisual data featuring the newly enrolled speaker. A recognition machine of the speaker recognition system is configured to operate the previously-trained joint neural network to recognize a previously-enrolled speaker based on audiovisual data featuring the previously-enrolled speaker.,G10L 17/18; G10L 17/04; G10L 17/10,"MICROSOFT TECHNOLOGY LICENSING, LLC","ZHANG, Shixiong; KRUPKA, Eyal","62/667,565 06.05.2018 US; 16/022,026 28.06.2018 US",
EP232545777,18163752,23.03.2018,3396604,31.10.2018,EP,ACCELERATED DECISION TREES ON DATA CENTER CLUSTERS,"In an example, an apparatus comprises a plurality of execution units and logic, at least partially including hardware logic, to implement training of a deep tree application at a data center. Other embodiments are also disclosed and claimed.",G06N 5/00; G06N 99/00,INTEL CORP,BLEIWEISS AMIT; FAIVISHEVSKY LEV; SCHWARTZ TOMER; FAIS YANIV; SUBAG JACOB,201715499899 28.04.2017 US,
WO2018216490,PCT/JP2018/018133,10.05.2018,WO/2018/216490,29.11.2018,WO,"LEARNING APPARATUS, LEARNING CONTROL METHOD, PROGRAM THEREFOR","In order to provide a technique for shortening the time required for a learning apparatus to achieve a learning purpose, without performing manual manipulation, a learning apparatus configured to learn control of an operation involved in a predetermined task includes: a learning data accepting unit configured to accept learning data containing a learning purpose and an allowable requirement for a learning operation performed when learning the control; a neural network configured to perform learning based on the learning data; and an output unit configured to output a learning result obtained by the neural network, wherein the neural network performs a first learning process for achieving an initial stage of the learning purpose, performs a second learning process for learning a control range in which a learning operation matches an allowable requirement, based on a result of the first learning process, and performs a third learning process for achieving the learning purpose within the control range based on a result of the second learning process.",B25J 9/16; G05B 13/02; G05D 1/00; G05D 1/02; G06N 3/08,OMRON CORPORATION,"ANDO, Tanichi",2017-104528 26.05.2017 JP,
WO2017020027,PCT/US2016/044923,29.07.2016,WO/2017/020027,02.02.2017,WO,SET-BASED PARSING FOR COMPUTER-IMPLEMENTED LINGUISTIC ANALYSIS,"The invention concerns linguistic analysis. In particular the invention involves a method of operating a computer to perform linguistic analysis. In another aspect the invention is a computer system which implements the method, and in a further aspect the invention is software for programming a computer to perform the method. The method comprising the steps of: receiving a list of elements, storing them in a list of sets, and then repeatedly matching patterns stored in the sets elements and storing their result in the list until no new matches are found. For each match comprising the steps: Creating a new consolidated set (overphrase) to store the full representation of the phrase as a new element, migrating the head element specified in the phrase, all phrase attributes, storing the matched elements in sequence, and copying tagged copies of the matched elements. After the consolidated set is created and filled, linkset intersections to effect WSD is performed. The resulting elements may be selected to identify the best fit, enabling effective WBI and PBI. The bidirectional nature of elements enables phrase generation to any target language.",G06F 17/27; G06F 17/28,PAT INC.,"BALL, John","62/198,684 30.07.2015 US; 15/222,399 28.07.2016 US",EP-2016831459
EP289840062,19176058,23.05.2019,3620939,11.03.2020,EP,METHOD AND DEVICE FOR SIMULTANEOUS INTERPRETATION BASED ON MACHINE LEARNING,"The present application discloses a method and device for simultaneous interpretation based on machine learning, wherein the method for simultaneous interpretation based on machine learning comprises: collecting a speech content and a speech feature of a target person's speech; using a machine to learn and imitate the speech feature of the target person; translating the speech content of the target person into a speech content of a specified language; and outputting, in the specified language, a speech content having the target person's speech feature imitated by the machine, wherein the language of the target person and the specified language are different languages. The technical solution of the present application could automatically identify and translate, output the translation result in the target person's speech feature, so that the translation result is more realistic, which is advantageous to improve the user experience.",G06N 20/00; G10L 13/00; G10L 15/18,MANJINBA SHENZHEN TECH CO LTD,LIANG ZHIJUN,201811030459 05.09.2018 CN,
WO1991010196,PCT/GB1990/002006,21.12.1990,WO/1991/010196,11.07.1991,WO,NEURAL NETWORKS,"A neural net in which new nodes and connections are created in both input and intermediate layers during training, which is by punishment, reward and teaching. This can use a small increase in memory requirement to preclude the necessity for long training times applicable problems in speech and natural language processing, video recognition and simple logic functions.",G06N 3/08,"BRITISH TELECOMMUNICATIONS PUBLIC LIMITED COMPANY; NIGHTINGALE, Charles; WYARD, Peter, Joseph","NIGHTINGALE, Charles; WYARD, Peter, Joseph",8929146.2 22.12.1989 GB,EP-1991900886; CA-2070677
EP282270463,18777880,29.03.2018,3598770,22.01.2020,EP,ELECTRONIC DEVICE FOR DETERMINING EMOTION OF USER AND METHOD FOR CONTROLLING SAME,"The present disclosure relates to an artificial intelligence (AI) system utilizing a machine learning algorithm such as deep learning, and application of the same. In particular, a method for controlling an electronic device of the present disclosure comprises the steps of: obtaining image data and supplementary data including data on a user from an external terminal connected to the electronic device; generating feature data for determining the user's actual emotion by using the image data and the supplementary data; and determining the user's actual emotion by inputting the feature data into an emotion recognition model.",H04N 21/466; G06K 9/00; G06K 9/62; G06N 5/04,SAMSUNG ELECTRONICS CO LTD,YUN SO-JUNG; KIM YE-HOON; JANG JUN-IK,20170041774 31.03.2017 KR; 20170162116 29.11.2017 KR; 2018003735 29.03.2018 KR,
WO2019027259,PCT/KR2018/008759,01.08.2018,WO/2019/027259,07.02.2019,WO,APPARATUS AND METHOD FOR PROVIDING SUMMARIZED INFORMATION USING AN ARTIFICIAL INTELLIGENCE MODEL,An artificial intelligence system using a machine learning algorithm for providing summary information of a document input to an artificial intelligence learning model trained to obtain summary information.,G06F 17/27; G06N 99/00,"SAMSUNG ELECTRONICS CO., LTD.","HWANG, Jin-young","62/539,686 01.08.2017 US; 10-2018-0007169 19.01.2018 KR",EP-2018840709; CN-201880035705.3
WO2019024083,PCT/CN2017/096004,04.08.2017,WO/2019/024083,07.02.2019,WO,ARTIFICIAL NEURAL NETWORK,"There is provided an apparatus comprising at least one processing core, at least one memory including computer program code, at least one memory and the computer program code being configured to, with at least one processing core, cause the apparatus at least to obtain, from a first sequential input(102), a first output from a first recurrent neural network, the first sequential input being of a first modality, obtain, from a second sequential input(103), a second output from a second recurrent neural network, the second sequential input being of a second modality, and process the first output and the second output to obtain a correlation of the first and second sequential inputs.",G06N 3/08,"NOKIA TECHNOLOGIES OY; NOKIA TECHNOLOGIES (BEIJING) CO., LTD.","WANG, Meng",,
WO2018218651,PCT/CN2017/086972,02.06.2017,WO/2018/218651,06.12.2018,WO,ARTIFICIAL NEURAL NETWORK,"According to an example aspect of the present invention, there is provided an apparatus comprising memory configured to store convolutional artificial neural network information comprising at least one filter definition, and at least one processing core configured to generate, from a preceding layer, a convolutional result of a succeeding layer of the artificial neural network in accordance with the at least one filter definition, and generate, from the convolutional result, an activation result of the succeeding layer by using an activation function, the activation function taking three arguments, the three arguments being derived from the convolutional result.",G06N 3/08,"NOKIA TECHNOLOGIES OY; NOKIA TECHNOLOGIES (BEIJING) CO., LTD.","LI, Hongyang",,EP-2017912152
EP232545772,18159840,02.03.2018,3396599,31.10.2018,EP,HARDWARE OPTIMIZED CONVOLUTIONAL NEURAL NETWORK,"In an example, an apparatus comprises at least one execution platform; and logic, at least partially including hardware logic, to receive a trained neural network model in a model optimizer and convert the trained neural network model to an optimized model comprising parameters that are fit to the at least one execution platform. Other embodiments are also disclosed and claimed.",G06N 3/04; G06F 8/52; G06F 9/445,INTEL CORP,BLEIWEISS AMIT; BEN-ARI LTAMAR; BEHAR MICHAEL; JACOB GUY; LEIBOVICH GAL; SUBAG JACOB; FAIVISHEVSKY LEV; FAIS YANIV; SCHWARTZ TOMER,201715494861 24.04.2017 US,
WO2019129775,PCT/EP2018/086863,24.12.2018,WO/2019/129775,04.07.2019,WO,A HIERARCHICAL ENTITY RECOGNITION AND SEMANTIC MODELING FRAMEWORK FOR INFORMATION EXTRACTION,"Extracting entities from a document with a hierarchical entity graph of entities. Entity definitions and entity recognition definitions are customized by a user and provided. The configuration information is utilized to generate (905) an entity graph, which is then utilized to parse one or more documents. In some implementations, the resulting parse tree may be utilized, in conjunction with user feedback, to generate one or more training instances for a machine learning model assigned to one or more of the custom nodes as an entity recognition definition. Parsing of the resulting tree may be performed with a lazy parsing methodology, with only the portions of interest to the user being identified in the document.",G16H 15/00; G06K 9/72; G06F 17/28,KONINKLIJKE PHILIPS N.V.,"HU, Yiyi; OUYANG, En; LI, Zuofeng",PCT/CN2017/118217 25.12.2017 CN,
WO2020025932,PCT/GB2019/052080,25.07.2019,WO/2020/025932,06.02.2020,WO,"SYSTEM, METHOD AND APPARATUS FOR NEURAL NETWORKS","An system, apparatus and method for utilizing software and hardware portions of a neural network to fix, or hardwire,certain portions while modifying other portions. A first set of weights for layers of the first neural network are established, and selected weights are modified to generate a second set of weights, based on a second dataset. The second set of weights is then used to train a second neural network.",G06F 1/3234; G06N 3/08; G06N 3/04; G06N 3/063,ARM LIMITED,"WHATMOUGH, Paul Nicholas; MATTINA, Matthew; BEU, Jesse Garrett","16/054,358 03.08.2018 US",
WO2000013102,PCT/JP1999/004726,31.08.1999,WO/2000/013102,09.03.2000,WO,NATURAL LANGUAGE PROCESSING DEVICE AND METHOD,"A natural language processing device for processing a natural language with few confirmation operations by the user, comprising an input section for inputting a natural language, a represetation converting section for converting the represetation of the natural language, a display section for displaying a sentence the representation of which is converted by the representation converting section so as to make confirmation, a machine-translation section for machine-translating the confirmed sentence, and a control section for controlling the other sections.",G06F 17/28,"SONY CORPORATION; ; ASANO, Yasuharu; ; HIROE, Atsuo; ; SHIMAKAWA, Masato; ; KAGAMI, Tetsuya; ; KOBAYASHI, Erika;","ASANO, Yasuharu; ; HIROE, Atsuo; ; SHIMAKAWA, Masato; ; KAGAMI, Tetsuya; ; KOBAYASHI, Erika;",10/246400 31.08.1998 JP,KR-1020007004712; US-09530200; CN-99801490.7
WO2015188137,PCT/US2015/034544,05.06.2015,WO/2015/188137,10.12.2015,WO,LANGUAGE PLATFORM,"A system receives original content from a user for translating to translated content. If a machine is to be used for translating, the system determines whether the machine-translated content is to be used as the translated content, or whether the machine-translated content should be transmitted to human translators for scoring or review. If the machine-translated content is not to be used as the translated content, it is sent to human translators for scoring or review. If the machine- translated content is to be used as the translated content, the machine -translated content may still be transmitted to human translators for scoring or review, the results used for machine learning. If a machine is not to be used for translating, the original content is sent to human translators for translating. The foregoing determinations are made based on user information or on statistical analysis.",G06F 17/28,EBAY INC.,"YORAM, Vardi; KUMAR, Nagarur, Kiran","14/298,770 06.06.2014 US",
WO2019205564,PCT/CN2018/114017,05.11.2018,WO/2019/205564,31.10.2019,WO,MACHINE TRANSLATION SYSTEM BASED ON CAPSULE NEURAL NETWORK AND INFORMATION DATA PROCESSING TERMINAL,"A machine translation system based on a capsule neural network and an information data processing terminal, for use in the technical field of computer software. A machine translation method based on a capsule neural network, comprising: mapping words to a high-dimensional vector space to obtain word vectors, obtaining word vectors combining additional information in a corpus, and also combining position information of the words (S101); receiving context vectors, obtaining word vectors to the target language, and obtaining a target language vocabulary by means of a dictionary (S102); In the present solution, by means of changing the internal structure of the neural network, additional information in the corpus can be learned by means of a word embedding layer after improvement of the capsule layer, such that the corresponding words in the source text and the translation are closer, and the distance of words having similar additional information in the source text and the translation in the word vector space is closer.",G06F 17/28,"GLABAL TONE COMMUNICATION TECHNOLOGY CO., LTD.; 中译语通科技股份有限公司","BEI, Chao; 贝超; CHENG, Guo Gen; 程国艮",201810371528.8 24.04.2018 CN,
WO2018027453,PCT/CN2016/093904,08.08.2016,WO/2018/027453,15.02.2018,WO,ARTIFICIAL NEURAL NETWORK,"According to an example aspect of the present invention, there is provided an apparatus comprising memory configured to store data defining, at least partly, an artificial neural network, and at least one processing core configured to train the artificial neural network by applying a test dataset to the artificial neural network with at least one stochastic rectified linear unit, the at least one stochastic rectified linear unit being configured to produce a positive output from a positive input by multiplying the input with a stochastically selected value.",G06K 9/62,"NOKIA TECHNOLOGIES OY; NOKIA TECHNOLOGIES (BEIJING) CO., LTD.","JIANG, Xiaoheng",,EP-2016911909; CN-201680088205.7
WO2020055910,PCT/US2019/050469,10.09.2019,WO/2020/055910,19.03.2020,WO,SYSTEMS AND METHODS FOR GRAPH-BASED AI TRAINING,"Graphs are powerful structures made of nodes and edges. Information can be encoded in the nodes and edges themselves, as well as the connections between them. Graphs can be used to create manifolds which in turn can be used to efficiently train more robust Al systems. Systems and methods for graph-based Al training in accordance with embodiments of the invention are illustrated. In one embodiment, a graph interface system including a processor, and a memory configured to store a graph interface application, where the graph interface application directs the processor to obtain a set of training data, where the set of training data describes a plurality of scenarios, encode the set of training data into a first knowledge graph, generate a manifold based on the first knowledge graph, and train an Al model by traversing the manifold.",G06K 9/62; G06N 3/04; G06K 9/46,"DRISK, INC.","STETSON, Robert, Chess; CHAISANGUANTHUM, Kris; FERGUSON, Robert; REVECHKIS, Boris","62/789,955 08.01.2019 US; 62/729,368 10.09.2018 US",
WO2018075190,PCT/US2017/052649,21.09.2017,WO/2018/075190,26.04.2018,WO,SYSTEMS AND METHODS FOR HANDLING FORMALITY IN TRANSLATIONS OF TEXT,"A computer-implemented method can include obtaining, by a server computing device, a machine translation model relating sets of source words in a source language to sets of target words in a different target language, each of the sets of source words and target words being labeled with a level of formality with respect to its corresponding language. The method can include receiving, by the server computing device, a request to obtain a translated text representing a translation of a text from the source language to the target language, the request further specifying a desired level of formality for the translated text. The method can include in response to receiving the request, obtaining, by the server computing device, the translated text by translating the text using the machine translation model and the desired level of formality. The method can further include outputting, by the server computing device, the translated text.",G06F 17/28,GOOGLE LLC,"PREMKUMAR, Melvin Jose Johnson; NGUYEN, Sarah; MACHEREY, Klaus","15/295,582 17.10.2016 US",
WO2019033836,PCT/CN2018/090300,07.06.2018,WO/2019/033836,21.02.2019,WO,ADAPTIVE BIT-WIDTH REDUCTION FOR NEURAL NETWORKS,"A method of providing an adaptive bit-width neural network model on a computing device, comprising: obtaining a first neural network model, wherein each layer of first neural network model has a respective set of parameters expressed with an original bit-width of the first neural network model; reducing a footprint of the first neural network model by using respective reduced bit-widths for storing the respective sets of parameters of different layers of the first neural network model, wherein: preferred values of the respective reduced bit-widths are determined through multiple iterations of forward propagation through the first neural network model using a validation data set while each of two or more layers of the first neural network model is expressed with different degrees of quantization until a predefined information loss threshold is met; and generating a reduced neural network model with quantized parameters expressed with the respective reduced bit-widths.",G06N 3/04,"MIDEA GROUP CO., LTD.","WANG, Aosen; ZHOU, Hua; CHEN, Xin","15/676,701 14.08.2017 US",CN-201880042804.4; EP-2018845593
WO2004102418,PCT/EP2004/004727,04.05.2004,WO/2004/102418,25.11.2004,WO,MULTI-LANGUAGE SUPPORT FOR DATA MINING MODELS,An analytical application provider may provide certain middleware functionality that includes updating model output to include textual descriptions of the data mining model and the data fields in a language selected by a front-end application. Certain implementations of the invention relate to a computer-implemented method for providing multi-language support for data mining models. Some implementations relate to computer-implemented method for outputting textual descriptions of data fields in a data mining model in a selected language.,G06F 17/28,"SAP AKTIENGESELLSCHAFT; KRAISS, Achim; MAHABAL, Harish, Hoskere; ROY, Dipankar","KRAISS, Achim; MAHABAL, Harish, Hoskere; ROY, Dipankar","60/471,048 16.05.2003 US; 10/664,771 17.09.2003 US",EP-2004730990
EP251457656,18747326,29.01.2018,3537368,11.09.2019,EP,DEVICE AND METHOD FOR RECOMMENDING PRODUCT,"The present disclosure relates to an artificial intelligence (AI) system for simulating human brain functions such as perception and judgement by using a machine learning algorithm such as deep learning, and an application thereof. Provided is a device and method for recommending products to a user on the basis of facial expression information of the user through an artificial intelligence system. The method for recommending products by a device comprises the steps of: displaying a product selected by a user; acquiring information on the user's facial expression for the displayed product; determining the user's satisfaction with the displayed product, on the basis of the acquired information on the user's facial expression; selecting a product set to be recommended to the user among a plurality of product sets, on the basis of the determined user's satisfaction; and displaying at least one product included in the selected product set.",G06Q 30/00; G06K 9/00; G06Q 30/02; G06Q 30/06,SAMSUNG ELECTRONICS CO LTD,YUN SO-JUNG; JANG JUN-IK,20170014376 01.02.2017 KR; 20180007889 22.01.2018 KR; 2018001240 29.01.2018 KR,
WO2017151757,PCT/US2017/020183,01.03.2017,WO/2017/151757,08.09.2017,WO,RECURRENT NEURAL FEEDBACK MODEL FOR AUTOMATED IMAGE ANNOTATION,"A deep learning model is provided to efficiently detect disease from an image (e.g., an x-ray image) and annotate its contexts. In one example of the disclosed technology, a method of generating an annotation sequence describing an input image includes training a convolutional neural network (CNN) with a series of reference images and associated annotation sequences, training a recurrent neural network (RNN) by initializing the RNN with the trained CNN embedding of the reference image and a first word of an annotation sequence, sampling the CNN and RNN with a reference image, and producing a sequence of annotation describing the image, disease(s) in the image, one or more attributes or contexts. In one examples of the disclosed technology, mean pooling is applied to the state vectors of RNN to obtain a joint image/text context vector summarizing the contexts of image and text annotation.",G06N 3/04,"THE UNITED STATES OF AMERICA, AS REPRESENTED BY THE SECRETARY, DEPARTMENT OF HEALTH AND HUMAN SERVICES","SHIN, Hoo-Chang; LU, Le; SUMMERS, Ronald, M.","62/302,084 01.03.2016 US",
WO2018120000,PCT/CN2016/113429,30.12.2016,WO/2018/120000,05.07.2018,WO,ARTIFICIAL NEURAL NETWORK,"An apparatus comprises memory configured to store, at least partly, labelling information of a convolutional artificial neural network, and at least one processing core configured to generate, from an input data item, partial feature maps of the convolutional artificial neural network in accordance with the labelling information, generate, from the partial feature maps, inputs to a plurality of weak classifiers to generate a classification decision, wherein the labelling information identifies at least one of the following: elements of the feature maps that generate the inputs, and elements of the feature maps that are used to generate the elements that generate the inputs.",G06N 3/08,"NOKIA TECHNOLOGIES OY; NOKIA TECHNOLOGIES (BEIJING) CO., LTD.","CAO, Jiale",,EP-2016925674; CN-201680091920.6
EP232545709,18163728,23.03.2018,3396548,31.10.2018,EP,BARRIERS AND SYNCHRONIZATION FOR MACHINE LEARNING AT AUTONOMOUS MACHINES,"A mechanism is described for facilitating barriers and synchronization for machine learning at autonomous machines. A method of embodiments, as described herein, includes detecting thread groups relating to machine learning associated with one or more processing devices. The method may further include facilitating barrier synchronization of the thread groups across multiple dies such that each thread in a thread group is scheduled across a set of compute elements associated with the multiple dies, where each die represents a processing device of the one or more processing devices, the processing device including a graphics processor.",G06F 9/52; G06N 3/063,INTEL CORP,APPU ABHISHEK R; KOKER ALTUG; RAY JOYDEEP; VEMBU BALAJI; WEAST JOHN C; MACPHERSON MIKE B; KIM DUKHWAN; HURD LINDA L; JAHAGIRDAR SANJEEV; RANGANATHAN VASANTH,201715495112 24.04.2017 US,
WO2018218034,PCT/US2018/034411,24.05.2018,WO/2018/218034,29.11.2018,WO,SHEET MUSIC SEARCH AND DISCOVERY SYSTEM,"A sheet music search and discovery system is disclosed that uses specific mathematical rules to analyze and characterize sheet music and provides functionality for users to identify sheet music based on those characterizations. The system stores sheet music data and metadata characterizing each composition, provides a graphical user interface that provides functionality for users to search the sheet music data for compositions, and generates search results based at least in part on the metadata characterizing each composition. In one embodiment, metadata describing structured sheet music data is generated using a global vector space that includes semantic representations of elements extracted from a large corpus. In another embodiment, metadata describing unstructured sheet music data is generated using machine learning-based pattern recognition. In another embodiment, the interface provides functionality for users to identify instruments and a range for each of the instruments and identify compositions with similar instruments and ranges.",G06F 17/00,"J. W. PEPPER & SON, INC.","SAWRUK, Jeremy; DONNELLY, Bruce; HAMILTON, Michael","62/511,025 25.05.2017 US",CA-3062700
WO2017112813,PCT/US2016/068123,21.12.2016,WO/2017/112813,29.06.2017,WO,MULTI-LINGUAL VIRTUAL PERSONAL ASSISTANT,"Provided are systems, computer-implemented methods, and computer-program products for a multi-lingual device, capable of receiving verbal input in multiple languages, and further capable of providing conversational responses in multiple languages. In various implementations, the multi-lingual device includes an automatic speech recognition engine capable of receiving verbal input in a first natural language and providing a textual representation of the input and a confidence value for the recognition. The multi-lingual device can also include a machine translation engine, capable of translating textual input from the first natural language into a second natural language. The machine translation engine can output a confidence value for the translation. The multi-lingual device can further include natural language processing, capable of translating from the second natural language to a computer-based language. Input in the computer-based language can be processed, and the multi-lingual device can take an action based on the result of the processing.",G06F 17/28,SRI INTERNATIONAL,"WANG, Wen; VERGYRI, Dimitra; ACHARYA, Girish","62/270,792 22.12.2015 US",
WO2019222206,PCT/US2019/032207,14.05.2019,WO/2019/222206,21.11.2019,WO,MULTITASK LEARNING AS QUESTION ANSWERING,"Approaches for natural language processing include a multi-layer encoder for encoding words from a context and words from a question in parallel, a multi-layer decoder for decoding the encoded context and the encoded question, a pointer generator for generating distributions over the words from the context, the words from the question, and words in a vocabulary based on an output from the decoder, and a switch. The switch generates a weighting of the distributions over the words from the context, the words from the question, and the words in the vocabulary, generates a composite distribution based on the weighting of the distribution over the first words from the context, the distribution over the second words from the question, and the distribution over the words in the vocabulary, and selects words for inclusion in an answer using the composite distribution.",G06F 17/27; G06N 3/04,"SALESFORCE.COM, INC.","MCCANN, Bryan; KESKAR, Nitish Shirish; XIONG, Caiming; SOCHER, Richard","62/673,606 18.05.2018 US; 16/006,691 12.06.2018 US",
WO2018128362,PCT/KR2018/000069,03.01.2018,WO/2018/128362,12.07.2018,WO,ELECTRONIC APPARATUS AND METHOD OF OPERATING THE SAME,"An electronic apparatus includes a processor configured to obtain a plurality of images, extract deep features with respect to the plurality of images using a feature extraction model, classify the plurality of images into certain groups using the extracted deep features and a classification model, display a result of the classification on the display, determine whether the feature extraction model and/or the classification model need to be updated using the result of the classification, and train and update at least one of the feature extraction model and the classification model based on a result of the determination. The electronic apparatus may estimate a deep feature of an image using a rule-based or artificial intelligence (AI) algorithm. When the deep feature of the image is estimated using the AI algorithm, the electronic apparatus may use a machine learning, neural network, or deep learning algorithm, or the like.",G06F 17/30; G06N 3/04; G06N 3/08,"SAMSUNG ELECTRONICS CO., LTD.","KANG, Seong-min; HAN, Heung-woo",10-2017-0000789 03.01.2017 KR; 10-2017-0136612 20.10.2017 KR,EP-2018735947; CN-201880005869.1
WO2015003143,PCT/US2014/045432,03.07.2014,WO/2015/003143,08.01.2015,WO,METHOD AND SYSTEM FOR SIMPLIFYING IMPLICIT RHETORICAL RELATION PREDICTION IN LARGE SCALE ANNOTATED CORPUS,"The present invention provides a method and system directed to predicting implicit rhetorical relations between two spans of text, e.g., in a large annotated corpus, such as the Penn Discourse Treebank (""PDTB""), Rhetorical Structure Theory corpus, and the Discourse Graph Bank, and particularly directed to determining a rhetorical relation in the absence of an explicit discourse marker. Surface level features may be used to capture pragmatic information encoded in the absent marker. In one manner a simplified feature set based only on raw text and semantic dependencies is used to improve performance for all relations. By using surface level features to predict implicit rhetorical relations for the large annotated corpus the invention approaches a theoretical maximum performance, suggesting that more data will not necessarily improve performance based on these and similarly situated features.",G06F 17/30; G06F 15/18,"THOMSON REUTERS GLOBAL RESOURCES; HOWALD, Blake; NYSTROM, Andrew","HOWALD, Blake; NYSTROM, Andrew","61/842,635 03.07.2013 US",CA-2917153; AU-2014285073
WO2017059500,PCT/AU2016/050950,10.10.2016,WO/2017/059500,13.04.2017,WO,"FRAMEWORKS AND METHODOLOGIES CONFIGURED TO ENABLE STREAMLINED INTEGRATION OF NATURAL LANGUAGE PROCESSING FUNCTIONALITY WITH ONE OR MORE USER INTERFACE ENVIRONMENTS, INCLUDING ASSISTED LEARNING PROCESS","The present disclosure relates to frameworks and methodologies configured to enable streamlined integration of natural language processing functionality with user interface environments. For example, embodiments provide technology that enable integration of a natural language query processing functionality into existing use interface environments, such as websites (although websites are used as an illustrative example below, the technology is applicable to a wide range of other user interface environments). At a broad level, the technology allows a query to be submitted in natural language form (for example via text input and/or voice input), and for that query to be processed thereby to trigger an action that is specific to the user interface environment.",G06F 17/28,SAYITY PTY LTD,"PARTRIDGE, Matthew",2015904121 09.10.2015 AU; 2015905046 04.12.2015 AU; 2015905061 07.12.2015 AU,
WO2019012527,PCT/IL2018/050746,09.07.2018,WO/2019/012527,17.01.2019,WO,DEEP LEARNING NETWORKS ORCHESTRATION,"A method for responding to a query is implemented on at least one computing device and includes: receiving at least one query from a user device; determining a context for the at least one query, selecting at least one deep learning network (DLN) of a plurality of DLNs to process the at least one query, where the selecting is based at least on matching the context to the at least one DLN, sending at least a representation of the at least one query and the context to the at least one DLN, receiving at least one response to the at least one query from the at least one DLN, and sending the at least one response to the user device.",G06F 15/18,CORTICA LTD.,"RAICHELGAUZ, Igal; ODINAEV, Karina; ZEEVI, Yehoshua, Y.","62/530,215 09.07.2017 US",
WO2019216578,PCT/KR2019/004887,23.04.2019,WO/2019/216578,14.11.2019,WO,METHOD AND APPARATUS FOR EXECUTING CLEANING OPERATION,"A robotic cleaning apparatus for performing a cleaning operation and a method of cleaning a cleaning space therefor are provided. The method includes acquiring contamination data indicating a contamination level of the cleaning space, acquiring contamination map data based on the contamination data, determining at least one cleaning target area in the cleaning space, based on a current time and the contamination map data, and cleaning the determined at least one cleaning target area. The method and apparatus may relate to artificial intelligence (AI) systems for mimicking functions of human brains, e.g., cognition and decision, by using a machine learning algorithm such as deep learning, and applications thereof.",A47L 9/28; G05D 1/02; G06N 3/08; B25J 11/00; B25J 9/16,"SAMSUNG ELECTRONICS CO., LTD.","HAN, Seungbeom; KUK, Junggap; KIM, Hyunsuk; JANG, Kyunghun","62/670,149 11.05.2018 US; 10-2018-0143896 20.11.2018 KR",
WO2016166417,PCT/FI2016/050244,13.04.2016,WO/2016/166417,20.10.2016,WO,METHOD FOR GENERATING NATURAL LANGUAGE COMMUNICATION,"The present invention relates to a method implementable on a computing device configured for generating natural language communication, and a computer program product implementing the method. The method comprises displaying in a user interface a first number of recipient-specific pseudo-predefined elements. A semantic allocation of the elements is received from a user, in which allocation at least part of said first number of recipient-specific pseudo-predefined elements are allocated into at least two different classes. The semantically allocated elements are further allocated into at least one logical class, wherein said logical class defines, for each semantically allocated element, a specific portion and/or context of said communication to be automatically generated. At least one natural language sentence is generated in each logical class containing at least one of said semantically allocated elements. The generated sentence may include said elements allocated to the respective logical class in said at least one generated sentence or the sentence may include words describing a semantic meaning of said elements allocated to the respective logical class. The invention further discloses a computer program product comprising computer executable instructions configured for providing a user interface for a natural language processing system.",G06F 17/28; G06Q 10/10; G06Q 30/02; G06Q 50/20,EQUIVALENTOR OY,"LATVALA, Joni; VALKAMA, Saku",20155267 13.04.2015 FI,US-15565460
WO2018034930,PCT/US2017/046253,10.08.2017,WO/2018/034930,22.02.2018,WO,ONLINE PERSONAL ASSISTANT WITH NATURAL LANGUAGE UNDERSTANDING,"Transforming formal and informal natural language user inputs into a more formal, machine-readable, structured representation of a search query. In one scenario, a processed sequence of user inputs and machine-generated prompts for further data from a user in a multi-turn interactive dialog improves the efficiency and accuracy of automated searches for the most relevant items available for purchase in an electronic marketplace. Analysis of user inputs may discern user intent, user input type, a dominant object of user interest, item categories, item attributes, attribute values, and item recipients. Other inputs considered may include dialog context, item inventory-related information, and external knowledge to improve inference of user intent from user input. Different types of analyses of the inputs each yield results that are interpreted in aggregate and coordinated via a knowledge graph based on past users interactions with the electronic marketplace and/or inventory-related data.",G06F 17/27; G06F 17/28; G06N 3/04; G06N 5/02; G06Q 30/02,EBAY INC.,"HEWAVITHARANA, Sanjika; KALE, Ajinkya, Gorakhnath; MANSOUR, Saab","15/238,675 16.08.2016 US",CN-201780050295.5; EP-2017841888
WO2016043609,PCT/RO2014/000024,18.09.2014,WO/2016/043609,24.03.2016,WO,THREE-DIMENSIONAL LATENT SEMANTIC ANALYSIS,"In some examples, a computing system may access multiple information files, generate term-passage matrix data based on the multiple information files, and decompose the term-passage matrix data to generate a reduced-dimensional semantic space, which may be used for information retrieval.",G06F 17/28,"EMPIRE TECHNOLOGY DEVELOPMENT LLC; DASCĀLU, Mihai; ASH, David, Walter","DASCĀLU, Mihai; ASH, David, Walter",,US-14891810; EP-2014902019
WO2018204763,PCT/US2018/031055,04.05.2018,WO/2018/204763,08.11.2018,WO,GENETIC PROFILE TEST AND RELATED PURCHASE RECOMMENDATIONS VIA AN ARTIFICIAL INTELLIGENCE-ENHANCED CHATBOT,"Presented herein are systems and methods that allow a user to interact with an artificial intelligence chatbot in order to automatically identify genetic profile tests of interest to them, as well as recommendations about health and fitness products and/or plans personalized for the user based at least in part on the user's genetic profile test results (e.g., as stored in his/her/their genetic profile). Such recommendations may include, for example, additional diagnostic tests (e.g., additional genetic profile tests, e.g., tests for particular characteristics, traits, diseases, and/or conditions), recommendations of nutritional supplements to purchase, recommendations about specific programs (e.g., meal programs, fitness programs, etc.) that are well-suited for the user, and the like.",G06F 17/28; G06F 19/22; G06F 19/24; G06F 19/26; G06Q 30/06,"ORIG3N, INC.","SMITH, Robin, Y.; GLICKSMAN, Marcie, A.; GUPTA, Sunil, Anant","62/502,556 05.05.2017 US",
WO2019167794,PCT/JP2019/006555,21.02.2019,WO/2019/167794,06.09.2019,WO,"LEARNING QUALITY ESTIMATION DEVICE, METHOD, AND PROGRAM","Provided are a learning quality estimation device, a method, and a program capable of removing erroneous data from learning data used for machine learning such as natural language processing. A learning quality estimation device 90 is provided with: a storage unit 16 that stores a forward direction learned model of a discrete series converter learned in advance on the basis of a plurality of first learning pairs in which a first discrete series and a second discrete series respectively indicating the input and output of discrete series are in a correct correspondence relationship, the discrete series converter being configured to convert the first discrete series of discrete series to the second discrete series; and a quality score calculation unit 14 that calculates a quality score by using the forward direction learned model, regarding a second learning pair comprising the input and output of the discrete series in which an error may be included in the correspondence relationship.",G06F 17/28; G06N 99/00,NIPPON TELEGRAPH AND TELEPHONE CORPORATION; 日本電信電話株式会社,"MORISHITA, Makoto; 森下　睦; SUZUKI, Jun; 鈴木　潤; NAGATA, Masaaki; 永田　昌明",2018-033719 27.02.2018 JP,
WO2013135474,PCT/EP2013/053546,22.02.2013,WO/2013/135474,19.09.2013,WO,"METHODS, APPARATUS AND PRODUCTS FOR SEMANTIC PROCESSING OF TEXT","The invention relates to a computer-implemented method of generating a computer-readable dictionary for translating text into a neural network-readable form, comprising: training a first neural network (4) of a self organizing map type with a first set (2) of first text documents (3) each containing one or more keywords (7) in a semantic context to map each text document (3) to a point (Xi/Yj) in the self organizing map (5) by semantic clustering; determining, for each keyword (7) occurring in the first set (2), all points (Xi/Yj) in the self organizing map (5) to which text documents (3) containing said keyword (7) are mapped, as a pattern (6) of points (Xi/Yj) associated with said keyword (7); and storing all keywords (7) and associated patterns (6) as a computer-readable pattern dictionary (9). The invention further relates to computer-implemented methods of training neural networks, and classification, prediction and translation machines based on neural networks.",G06N 3/08; G06N 3/04; G06F 17/28,CEPT SYSTEMS GMBH,"DE SOUSA WEBBER, Francisco Eduardo",12159672.0 15.03.2012 EP,AU-2013231564; CA-2864946; JP-2014561350
WO2020081256,PCT/US2019/054672,04.10.2019,WO/2020/081256,23.04.2020,WO,NEURAL NETWORK ARCHITECTURES EMPLOYING INTERRELATEDNESS,"Enhanced neural network architectures that enable the determination and employment of association-based or attention-based ""interrelatedness"" of various portions of the input data are provided. A method of employing an architecture includes receiving a first input data element, a second input element, and a third input element. A first interrelated metric that indicates a degree of interrelatedness between the first input data element and the second input data element is determined. A second interrelated metric is determined. The second interrelated metric indicates a degree of interrelatedness between the first input data element and the third input data element. An interrelated vector is generated based on the first interrelated metric and the second interrelated metric. The neural network is employed to generate an output vector that corresponds to the first input vector and is based on a combination of the first input vector and the interrelated vector.",G06N 3/04; G06N 3/08,"MICROSOFT TECHNOLOGY LICENSING, LLC","STOKES III, Jack Wilson; AGRAWAL, Rakshit; SELVARAJ, Karthik; MARINESCU, Adrian M.","16/160,540 15.10.2018 US",
WO2020068311,PCT/US2019/047480,21.08.2019,WO/2020/068311,02.04.2020,WO,POWER SAVINGS FOR NEURAL NETWORK ARCHITECTURE WITH ZERO ACTIVATIONS DURING INFERENCE,"Embodiments are generally directed to providing power savings for a neural network architecture with zero activations during inference. An embodiment of an apparatus includes one or more processors including one or more processor cores; and a memory to store data for processing including neural network processing, wherein the apparatus to perform a fast clear operation to initialize activation buffers for a neural network by updating metadata to indicate zero values, the neural network including a plurality of layers, wherein the apparatus is to compare outputs for the neural network to the metadata values and to write an output to memory only if the output is non-zero.",G06N 3/063; G06N 3/08; G06F 1/3206; G06F 1/3234; G06N 3/04,INTEL CORPORATION,"DESAI, Kinchit; JAHAGIRDAR, Sanjeev; SURTI, Prasoonkumar; RAY, Joydeep","16/144,538 27.09.2018 US",
WO2017091763,PCT/US2016/063661,23.11.2016,WO/2017/091763,01.06.2017,WO,END-TO-END SPEECH RECOGNITION,"Embodiments of end-to-end deep learning systems and methods are disclosed to recognize speech of vastly different languages, such as English or Mandarin Chinese. In embodiments, the entire pipelines of hand-engineered components are replaced with neural networks, and the end-to-end learning allows handling a diverse variety of speech including noisy environments, accents, and different languages. Using a trained embodiment and an embodiment of a batch dispatch technique with GPUs in a data center, an end-to-end deep learning system can be inexpensively deployed in an online setting, delivering low latency when serving users at scale.",G06F 17/28; G10L 15/04; G10L 15/06; G10L 15/08; G10L 15/183; G10L 15/28,BAIDU USA LLC,"CATANZARO, Bryan; CHEN, Jingdong; CHRZANOWSKI, Mike; ELSEN, Erich; ENGEL, Jesse; FOUGNER, Christopher; HAN, Xu; HANNUN, Awni; PRENGER, Ryan; SATHEESH, Sanjeev; SENGUPTA, Shubhabrata; YOGATAMA, Dani; WANG, Chong; ZHAN, Jun; ZHU, Zhenyao; AMODEI, Dario","62/260,206 25.11.2015 US; 15/358,102 21.11.2016 US; 15/358,083 21.11.2016 US",JP-2017544352; KR-1020177023177
EP232545799,18162611,19.03.2018,3396623,31.10.2018,EP,REAL TIME CONTEXT DEPENDENT DEEP LEARNING,"In an example, an apparatus comprises a plurality of execution units comprising and logic, at least partially including hardware logic, to receive a plurality of data inputs for training a neural network, wherein the data inputs comprise training data and weights inputs; represent the data inputs in a first form; and represent the weight inputs in a second form. Other embodiments are also disclosed and claimed.",G06T 1/20,INTEL CORP,FAIVISHEVSKY LEV; BAR-ON TOMER; FAIS YANIV; SUBAG JACOB; DREYFUSS JEREMIE; BLEIWEISS AMIT; SCHWARTZ TOMER,201715494887 24.04.2017 US,
WO2018048945,PCT/US2017/050335,06.09.2017,WO/2018/048945,15.03.2018,WO,PROCESSING SEQUENCES USING CONVOLUTIONAL NEURAL NETWORKS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for generating of generating a neural network output from an input sequence. One of the methods includes, for each of the inputs, providing a current input sequence that comprises the input and the inputs preceding the input in the input sequence to a convolutional subnetwork comprising a plurality of dilated convolutional neural network layers, wherein the convolutional subnetwork is configured to, for each of the plurality of inputs: receive the current input sequence for the input, and process the current input sequence to generate an alternative representation for the input; and providing the alternative representations to an output subnetwork, wherein the output subnetwork is configured to receive the alternative representations and to process the alternative representations to generate the neural network output.",G06N 3/04,DEEPMIND TECHNOLOGIES LIMITED,"VAN DEN OORD, Aaron Gerard Antonius; DIELEMAN, Sander Etienne Lea; KALCHBRENNER, Nal Emmerich; SIMONYAN, Karen; VINYALS, Oriol; ESPEHOLT, Lasse","62/384,123 06.09.2016 US",CN-201780065178.6; EP-2017780544; JP-2019533306; KR-1020197008257
WO2017015231,PCT/US2016/042838,18.07.2016,WO/2017/015231,26.01.2017,WO,NATURAL LANGUAGE PROCESSING SYSTEM AND METHOD,"Embodiments of a system and method for natural language processing (NLP) utilize one or more extraction models, and an output of syntactic parser applied to a text to extract information from the text. In an embodiment, an extraction model defines one or more units or combinations of units within a grammar hierarchy (a word, a phase, a clause, or any combination of words, phrases and clauses) as an output of extraction process. An extraction model further comprises a set of rules where each rule sets one or more constraints on: a grammar structure output by extraction process; on the context of the output of extraction process; and on the relations between the output and the context.",G06F 17/20; G06F 17/21; G06F 17/28,"FIDO LABS, INC.","LELIWA, Gniewosz; WROCZYNSKI, Michal","62/193,943 17.07.2015 US",
WO1997040453,PCT/US1996/010283,14.06.1996,WO/1997/040453,30.10.1997,WO,AUTOMATED NATURAL LANGUAGE PROCESSING,An automated natural language translation system takes source natural language text (preferably in Japanese) and translates them into a target natural language (preferably English). The system also allows an operator to re-translate automatically selected portions of the source text. The system includes an improvement directed to transforming kanas in the source text into alphabetic letters of the target language which allows the presence of a word or phrase boundary to be recognized in the middle of a kana. The system also includes an improvement involving performing concurrently on the source text both a morphological analysis and a syntactic analysis.,G06F 17/28,"LANGUAGE ENGINEERING CORPORATION; AKERS, Glenn, A.; KUNO, Susumu","AKERS, Glenn, A.; KUNO, Susumu",PCT/US96/05567 23.04.1996 US,US-09171185
WO2014060001,PCT/EP2012/003756,13.09.2012,WO/2014/060001,24.04.2014,WO,MULTITRANSMITTER MODEL OF THE NEURAL NETWORK WITH AN INTERNAL FEEDBACK,"The invention relates to the field of information processing, including of parallel and neural network calculations, and may be used in the development and creation of programmable and physically realizable fast neural networks. The efficiency of the calculations is ensured by the high training rate of the given neural network, as well as the parallelism of the calculation streams not only in the recognition of images, but in the neural network training. Furthermore, the described neural network model can easily be realized in the form of an analogue arrangement, which significantly improves the efficiency of its apparative realization. The said neural network training is based on a novel structure and a novel principle of functioning of the neural synapse forming the neural network structure and performing the function of transmission and transformation of a signal. The training takes place under counter-propagation of direct and backward signals, where the direct signal performs the recognition of the image, and the counter (reverse) signal ensures the neural network training. The difference in the direct and reverse signals at the output of the neuron is the basis for error compensation and, consequently, leads to the training of the neuron and the whole neural network. The information carrier (memory) in the given neural network is dendrites (neuron inputs), and also neuron synapses with dendrites of other neurons. The structure of the connections between the neurons is in principle unimportant. The contribution of dendrites is defined not only by weight coefficient, and by weight ranges. Training is carried out by modification of parameters of synapses and weight ranges of dendrites of a neuron. Thus, plasticity of a neural network is ensured not only by identical weights of dendrites, but through ranges of the weights of dendrites and adaptation of the functions of signal transformation (transfer functions) on synapses. Synapses ensure not simple signal transmission between neurons, but also transform these signals. Notably, transformation of signals on synapses has the complex non-linear functional nature depending on value of a signal coming at the synapse.",G06N 3/04; G06N 3/08,"PESCIANSCHI, Dmitri; FRENKEL, Christina; FRENKEL, Daniel; HAEMMERLING, Valentin","PESCIANSCHI, Dmitri",,
EP12570931,94300701,31.01.1994,0625758,23.11.1994,EP,Natural language processing system.,"A B-tree 21 is used to store natural language data, for example as part of a speech recognition or speech synthesis system. The B-tree is arranged in a hierarchy, with each node pointing to two nodes in the level below. Each node contains a test value (a word), and data relating to that test value (or a reference to a storage location where the data is maintained). The data is accessed by starting at the top of the tree and comparing the desired word with the test value for that node. Depending on the relative alphabetical ordering of the desired word and the test value, the appropriate branch from that node is followed. This process is continued down the tree until a test value corresponding to the desired word is located. The B-tree is arranged so that frequency of occurrence of the test values in natural language decreases substantially monotonically as the tree is descended. <IMAGE>",G06F 15/38; G06F 15/419; G06F 17/27; G06F 17/28; G06F 17/30,IBM,SHARMAN RICHARD,9308240 21.04.1993 GB,
WO2017177183,PCT/US2017/026682,07.04.2017,WO/2017/177183,12.10.2017,WO,METHOD AND SYSTEM FOR ARTIFICIAL INTELLIGENCE BASED CONTENT RECOMMENDATION AND PROVISIONING,Systems and methods of artificial intelligence based recommendation are disclosed herein. The system can include: a user device including: a network interface; and an I/O subsystem. The system can include an artificial intelligence engine that can provide a remediation dialogue. The system can include a content management server that can: receive a user identification identifying a user from the user device; retrieve user information from a memory; identify and deliver a question to the user device based on the retrieved user information; receive a response to the delivered question from the user device; determine that the received response is incorrect; trigger the launch of the artificial intelligence engine; receive an indication of completion of the dialogue; and provide a second question after receipt of the indication of completion of the dialogue.,G06N 3/08; G09B 7/00; G06F 17/28; G06F 17/30,"MCALLISTER, Angie; MORIARTY, Brian; MCFALL, Greg","MCALLISTER, Angie; MORIARTY, Brian; MCFALL, Greg","62/320,213 08.04.2016 US",EP-2017779939; CN-201780035911.X
WO2020069048,PCT/US2019/053039,25.09.2019,WO/2020/069048,02.04.2020,WO,REINFORCEMENT LEARNING APPROACH TO MODIFY SENTENCE READING GRADE LEVEL,"Methods, systems, and apparatus, including computer programs language encoded on a computer storage medium for a language simplification system whereby input jargon language is modified to plain language using a reinforcement learning system with a real-time reward grade level grammar engine. The actions of an agent are to reduce the reading grade level: 1) substituting plain language words for technical terms, 2) splitting long sentences into shorter sentences and rebuilding the sentences to maintain the original meaning. The reinforcement learning agent learns a policy of edits and modifications to a sentence such that the output sentence is grammatical and retains the intended meaning.",G06F 17/27; G06N 3/08; G16H 10/60,"ARCHULETA, Michelle","ARCHULETA, Michelle","62/736,148 25.09.2018 US",
WO2018010455,PCT/CN2017/077950,23.03.2017,WO/2018/010455,18.01.2018,WO,NEURAL NETWORK-BASED TRANSLATION METHOD AND APPARATUS,"Disclosed in embodiments of the present invention are a neural network-based translation method and apparatus, said method comprising: acquiring an initial translation of a sentence to be translated, the initial translation containing unlisted words; splitting the unlisted words in the initial translation into characters, and inputting a character sequence formed by the characters which are acquired by splitting the words into a first multi-layer neural network; acquiring a character vector of each character in the character sequence by means of the first multi-layer neural network, and inputting all character vectors of the character sequence into a second multi-layer neural network; using the second multi-layer neural network and a pre-set common words database to encode all of the character vectors in order so as to acquire semantic vectors; inputting the semantic vectors into a third multi-layer neural network, decoding the semantic vectors by means of the third multi-layer neural network, and combining such with the initial translation of the sentence to be translated to determine a final translation of the sentence to be translated. The present invention offers the advantages of increasing the operability of translating unlisted words, lowering the translation costs of machine translation, and improving the translation quality of machine translation.",G06F 17/28,"HUAWEI TECHNOLOGIES CO., LTD.; 华为技术有限公司","TU, Zhaopeng; 涂兆鹏; LI, Hang; 李航; JIANG, Wenbin; 姜文斌",201610545902.2 12.07.2016 CN,
WO2018145098,PCT/US2018/017083,06.02.2018,WO/2018/145098,09.08.2018,WO,SYSTEMS AND METHODS FOR AUTOMATIC SEMANTIC TOKEN TAGGING,"A computing system can receive a request to apply semantic token tagging on a specified domain, and can retrieve a set of data associated with the specified domain from a data storage facility. Canonical sequences can be formed from strings included in the data set. Each canonical sequence can be permutated to form sequence variations and each sequence variation can be verified against a generalized domain. Semantic token tagging can be applied to the specified domain using a subset of the sequence variations that are successfully verified as training data.",G06F 17/27; G06F 17/28; G06F 19/00; G06N 7/00,"THOMSON REUTERS GLOBAL RESOURCES UNLIMITED COMPANY; SCHILDER, Frank","SCHILDER, Frank; SONG, Dezhao","62/455,082 06.02.2017 US",CA-3052638; EP-2018747399; AU-2018214675
EP14224984,04010931,07.05.2004,1482415,01.12.2004,EP,System and method for user modelling to enhance named entity recognition,The present invention employs user modeling to model a user's behavior patterns. The user's behavior patterns are then used to influence named entity (NE) recognition.,G06F 17/27; G06N 3/00; G06F 17/28; G06F 40/00; G10L 15/00; G10L 15/06,MICROSOFT TECHNOLOGY LICENSING LLC,DONG YU; MAU PETER K L; WANG KUANSAN; MAHAJAN MILIND; ACERO ALEJANDRO,44553203 27.05.2003 US,
WO2020091503,PCT/KR2019/014704,01.11.2019,WO/2020/091503,07.05.2020,WO,ELECTRONIC APPARATUS AND CONTROL METHOD THEREOF,"An electronic apparatus and a control method thereof are provided. A method of controlling an electronic apparatus according to an embodiment of the disclosure includes: receiving input of a first utterance, identifying a first task for the first utterance based on the first utterance, providing a response to the first task based on a predetermined response pattern, receiving input of a second utterance, identifying a second task for the second utterance based on the second utterance, determining the degree of association between the first task and the second task, and setting a response pattern for the first task based on the second task based on the determined degree of association satisfying a predetermined condition. The control method of an electronic apparatus may use an artificial intelligence model trained according to at least one of machine learning, a neural network, or a deep learning algorithm.",G06F 3/16; G10L 15/04; G06N 3/08; G10L 15/22,"SAMSUNG ELECTRONICS CO., LTD.","LEE, Yeonho; LEE, Kyenghun; JANG, Saebom; JEON, Silas",10-2018-0132717 01.11.2018 KR; 10-2019-0129837 18.10.2019 KR,
WO2016090197,PCT/US2015/063862,04.12.2015,WO/2016/090197,09.06.2016,WO,AUTOMATED CONTENT CLASSIFICATION/FILTERING,"Apparatuses, components, methods, and techniques for classifying content are provided. An example method classifies textual content as objectionable. Another example identifies relevant attributes for the content. The example method includes analyzing a body of the content to determine a level of similarity between text in the content and a corpus of predetermined content. The example method further includes upon determining that the level of similarity is greater than a predefined threshold using natural language processing to extract a plurality of features from the content, the features being associated with concepts related to the body of the content. The example method further includes analyzing the extracted features to determine a second level of similarity between the content and the corpus of predetermined content. The example method further includes upon determining that the second level of similarity is greater than a second predefined threshold, classifying the content as objectionable.",G06F 17/27; G06F 17/28; G06F 17/30,LIGHTNING SOURCE INC.,"ARIÑO DE LA RUBIA, Eduardo","14/562,127 05.12.2014 US",GB-1710805.1
WO2019073000,PCT/EP2018/077795,11.10.2018,WO/2019/073000,18.04.2019,WO,ARTIFICIAL NEURAL NETWORK,"According to an example aspect of the present invention, there is provided an apparatus comprising a memory configured to store training data, at least one processor configured to provide a trusted execution environment, wherein the apparatus is configured to run, in the trusted execution environment, a training process configured to obtain parameters of a neural network, using the training data.",G06F 21/53; G06F 21/57; G06N 3/00; H04L 29/06; G06F 21/62; H04W 12/02,NOKIA TECHNOLOGIES OY,"BITAULD, David; BAYKANER, Khan Richard",17196277.2 13.10.2017 EP,
WO2007070558,PCT/US2006/047508,12.12.2006,WO/2007/070558,21.06.2007,WO,LANGUAGE TRANSLATION USING A HYBRID NETWORK OF HUMAN AND MACHINE TRANSLATORS,"A Hybrid Distributed Network Language Translation (HDNLT) system having a distributed network of human and machine translators that communicate electronically and provide for the translation of material in source language. Individual translators receive a reputation that reflects their translation competency, reliability and accuracy. An individual translator's reputation is adjusted dynamically with feedback from other translators and/or comparison of their translation results to translations from those with known high reputation and to the final translation results. Additionally, translations are produced statistically, first by breaking input source text into fragments, sending each fragment redundantly to a number of translators with varying levels of reputation. The results of these translations are assembled taking into account (giving weight to) the translator reputation of each translator, the statistical properties of the translation results, the statistical correlation of preferred results to target language fragments, the properties of the particular language and other relevant factors.",G06F 17/28,"MEADAN, INC.; SHORE, JOHN; BICE, ED","SHORE, JOHN; BICE, ED","60/749,530 12.12.2005 US",DE-null
WO2013186216,PCT/EP2013/062040,11.06.2013,WO/2013/186216,19.12.2013,WO,"A METHOD, COMPUTER PROGRAM AND SYSTEM FOR INFERRING AND STRUCTURING RELATIONS BETWEEN CULTURAL SPECIFIC CONCEPTS IN TWO CULTURES","The present invention relates to a method, computer program and system for inferring relations between cultural specific concepts (CSC) in two cultures at least comprising the steps of - extracting and listing said cultural specific concepts (CSCs) and features of said CSCs from at least a first corpora belonging to a first culture and a second corpora belonging to a second culture, - applying a algorithm to infer relations between said CSCs in the first and the second corpora.",G06F 17/28; G06F 17/30; G06F 9/44,IBC - DEPARTMENT OF INTERNATIONAL BUSINESS COMMUNICATION; TECHNICAL UNIVERSITY OF DENMARK,"GLÜCKSTAD, Fumiko Kano; MØRUP, Morten; HERLAU, Tue; SCHMIDT, Mikkei, N.","12171535.3 11.06.2012 EP; 61/658,003 11.06.2012 US",
WO2019083553,PCT/US2017/066771,15.12.2017,WO/2019/083553,02.05.2019,WO,CAPSULE NEURAL NETWORKS,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for a neural network that is configured to receive a network input and to generate a network output for the network input. The neural network comprises a plurality of layers arranged in a sequence, including a plurality of capsule layers. Each particular capsule in a particular capsule layer is configured to receive respective inputs including: (i) outputs generated by capsules of a previous capsule layer that is before the particular capsule layer in the sequence, and (ii) final routing factors between capsules of the previous capsule layer and the particular capsule, wherein the final routing factors are generated by a routing subsystem. Each particular capsule in the particular capsule layer is configured to determine a particular capsule output based on the received inputs, wherein the particular capsule output is of dimension greater than one.",G06N 3/04; G06N 3/08,GOOGLE LLC,"HINTON, Geoffrey E.; FROSST, Nicholas Myles Wisener; AGHDAM, Sara Sabour Rouh","62/578,391 27.10.2017 US",
WO2017091751,PCT/US2016/063641,23.11.2016,WO/2017/091751,01.06.2017,WO,DEPLOYED END-TO-END SPEECH RECOGNITION,"Embodiments of end-to-end deep learning systems and methods are disclosed to recognize speech of vastly different languages, such as English or Mandarin Chinese. In embodiments, the entire pipelines of hand-engineered components are replaced with neural networks, and the end-to-end learning allows handling a diverse variety of speech including noisy environments, accents, and different languages. Using a trained embodiment and an embodiment of a batch dispatch technique with GPUs in a data center, an end-to-end deep learning system can be inexpensively deployed in an online setting, delivering low latency when serving users at scale.",G10L 15/16; G10L 15/06; G10L 15/08; G10L 15/183,BAIDU USA LLC,"CATANZARO, Bryan; CHEN, Jingdong; CHRZANOWSKI, Mike; ELSEN, Erich; ENGEL, Jesse; FOUGNER, Christopher; HAN, Xu; HANNUN, Awni; PRENGER, Ryan; SATHEESH, Sanjeev; SENGUPTA, Shubhabrata; YOGATAMA, Dani; WANG, Chong; ZHAN, Jun; ZHU, Zhenyao; AMODEI, Dario","62/260,206 25.11.2015 US; 15/358,102 21.11.2016 US; 15/358,083 21.11.2016 US",JP-2017544340; KR-1020177023173
WO2018217948,PCT/US2018/034224,23.05.2018,WO/2018/217948,29.11.2018,WO,ATTENTION-BASED SEQUENCE TRANSDUCTION NEURAL NETWORKS,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for generating an output sequence from an input sequence. In one aspect, one of the systems includes an encoder neural network configured to receive the input sequence and generate encoded representations of the network inputs, the encoder neural network comprising a sequence of one or more encoder subnetworks, each encoder subnetwork configured to receive a respective encoder subnetwork input for each of the input positions and to generate a respective subnetwork output for each of the input positions, and each encoder subnetwork comprising: an encoder self-attention sub-layer that is configured to receive the subnetwork input for each of the input positions and, for each particular input position in the input order: apply an attention mechanism over the encoder subnetwork inputs using one or more queries derived from the encoder subnetwork input at the particular input position.",G06N 3/04,GOOGLE LLC,"SHAZEER, Noam M.; GOMEZ, Aidan Nicholas; KAISER, Lukasz Mieczyslaw; USZKOREIT, Jakob D.; JONES, Llion Owen; PARMAR, Niki J.; POLOSUKHIN, Illia; VASWANI, Ashish Teku","62/510,256 23.05.2017 US; 62/541,594 04.08.2017 US",CN-201880007309.X; CA-3050334; AU-2018271931; EP-2018739661; KR-1020197019186; JP-2019538514
WO2019172848,PCT/SG2019/050125,06.03.2019,WO/2019/172848,12.09.2019,WO,METHOD AND APPARATUS FOR PREDICTING OCCURRENCE OF AN EVENT TO FACILITATE ASSET MAINTENANCE,"An apparatus and method for predicting occurrence of an event to facilitate asset maintenance, the apparatus comprising: a processor for executing instructions in a memory to: receive a maintenance log comprising: asset identifiers; event markers; and timestamps;determine an asset ontology vector for a target asset comprising: a target asset functionality vector and an ontology location vector of the target asset comprising values of distances between an asset identifier of the target asset and asset identifiers of other assets; extract features from the maintenance log to form a vector defining values of an operation time window and a feature vector for the target asset; input the asset identifier of the target asset, the asset ontology vector and the feature vector to a neural network; and output from the neural network a predicted event that will occur and time of occurrence of the predicted event.",G06N 3/08; G06Q 10/04; G06N 20/00; G06N 99/00; G06Q 50/30,"AGENCY FOR SCIENCE, TECHNOLOGY AND RESEARCH; ILLINOIS AT SINGAPORE PTE LTD","LI, Yan; ZHENG, Wenchen; CHEN, Binbin; CAI, Hongyun",10201801831Q 06.03.2018 SG,
WO2017132018,PCT/US2017/013884,18.01.2017,WO/2017/132018,03.08.2017,WO,DETERMINING USER SENTIMENT IN CHAT DATA,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for receiving a message authored by a user, determining, using a first classifier, that the message contains at least a first word describing positive or negative sentiment and, based thereon, extracting, using a first feature extractor, one or more features of the message, wherein each feature comprises a respective word or phrase in the message and a respective weight signifying a degree of positive or negative sentiment, and determining, using a second classifier that uses the extracted features as input, a score describing a degree of positive or negative sentiment of the message, wherein the first feature extractor was trained with a set of training messages that each was labeled as having positive or negative sentiment.",G06F 17/27,"MZ IP HOLDINGS, LLC","BOJJA, Nikhil; KANNAN, Shivasankari; KARUPPUSAMY, Satheeshkumar","15/007,639 27.01.2016 US",RU-2018125272; AU-2017211681; EP-2017704584; JP-2018539050; CA-3011016
WO2015034622,PCT/US2014/050222,07.08.2014,WO/2015/034622,12.03.2015,WO,METHODS AND SYSTEMS OF FOUR VALUED ANALOGICAL TRANSFORMATION OPERATORS USED IN NATURAL LANGUAGE PROCESSING AND OTHER APPLICATIONS,"A system for the dynamic encoding in a semantic network of both syntactic and semantic information into a common four valued logical notation. The encoding of new information being benign to prior syntactic constructions, tests for N conditionals in time 0(C) and allows for the proper quantification of variables at each recursive step. The query/inference engine constructed from such an implementation is able to optimize short term memory for maximizing long term storage in the automaton. In a parallel context this can be viewed as optimizing communication and memory allocation between processes. The self-referencing system is capable of analogically extending knowledge from one knowledge source to another linearly. Disclosed embodiments include machine translation, text summarization, natural language speech recognition natural language.",G06F 17/50,"MIDMORE, Roger","MIDMORE, Roger","14/016,538 03.09.2013 US; 14/016,518 03.09.2013 US",CN-201480060269.7; CA-2966686; AU-2014315620; EP-2014842561
WO2019081623,PCT/EP2018/079241,25.10.2018,WO/2019/081623,02.05.2019,WO,AUTO-REGRESSIVE NEURAL NETWORK SYSTEMS WITH A SOFT ATTENTION MECHANISM USING SUPPORT DATA PATCHES,"A system comprising a causal convolutional neural network to autoregressively generate a succession of values of a data item conditioned upon previously generated values of the data item. The system includes support memory for a set of support data patches each of which comprises an encoding of an example data item. A soft attention mechanism attends to one or more patches when generating the current item value. The soft attention mechanism determines a set of scores for the support data patches, for example in the form of a soft attention query vector dependent upon the previously generated values of the data item. The soft attention query vector is used to query the memory. When generating the value of the data item at a current iteration layers of the causal convolutional neural network are conditioned upon the support data patches weighted by the scores.",G06N 3/04; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"VAN DEN OORD, Aaron Gerard Antonius; CHEN, Yutian; REZENDE, Danilo Jimenez; VINYALS, Oriol; GOMES DE FREITAS, Joao Ferdinando; REED, Scott Ellison","62/577,114 25.10.2017 US",
EP13807804,00977144,10.11.2000,1245023,02.10.2002,EP,DISTRIBUTED REAL TIME SPEECH RECOGNITION SYSTEM,"A real-time system (100) incorporating speech recognition and linguistic processing for recognizing a spoken query by a user and distributed between client (150) and server (180), is disclosed. The system (100) accepts user's queries in the form of speech at the client (150) where minimal processing extracts a sufficient number of acoustic speech vectors representing the utterance. These vectors are sent via a communications channel (160A) to the server (180) where additional acoustic vectors are derived. Using Hidden Markov Models (HMMs), and appropriate grammars and dictionaries conditioned by the selections made by the user, the speech representing the user's query is fully decoded into text (or some other suitable form) at the server (180). The text corresponding to the user's query is then simultaneously sent to a natural language engine (190) and a database processor (186) where optimized SQL statements are constructed for a full-text search from a database (188) for a record set of several stored questions that best matches the user's query. Further processing in the natural language engine (190) narrows the search to a single stored question. The answer corresponding to this single stored question is next retrieved from the file path and sent to the client (150) in compressed form. At the client (150), the answer to the user's query is articulated to the user using a text-to-speech engine (159) in his or her native natural language. The system (100) requires no training and can operate in several natural languages.",G06F 3/16; G10L 15/22; G06F 17/28; G06F 17/30; G09B 7/02; G10L 13/00; G10L 15/00; G10L 15/02; G10L 15/14; G10L 15/18; G10L 15/20; G10L 15/28; G10L 21/02,PHOENIX SOLUTIONS INC,BENNETT IAN M; BABU BANDI RAMESH; MORKHANDIKAR KISHOR; GURURAJ PALLAKI,0030918 10.11.2000 US; 43914599 12.11.1999 US,
EP232159381,18163810,23.03.2018,3392826,24.10.2018,EP,CONVOLUTIONAL NEURAL NETWORK OPTIMIZATION MECHANISM,An apparatus to facilitate optimization of a convolutional neural network (CNN) is disclosed. The apparatus includes optimization logic to receive a CNN model having a list of instructions and including pruning logic to optimize the list of instructions by eliminating branches in the list of instructions that comprise a weight value of 0.,G06T 1/20,INTEL CORP,MA LIWEI; OULD-AHMED-VALL ELMOUSTAPHA; LAKSHMANAN BARATH; ASHBAUGH BEN J; JIN JINGYI; BOTTLESON JEREMY; MACPHERSON MIKE B; NEALIS KEVIN; SRIVASTAVA DHAWAL; RAY JOYDEEP; TANG PING T; STRICKLAND MICHAEL S; CHEN XIAOMING; YAO ANBANG; SHPEISMAN TATIANA; KOKER ALTUG; APPU ABHISHEK R,201715488551 17.04.2017 US,
EP12768622,95309436,27.12.1995,0720106,03.07.1996,EP,System for generating natural language information from information expressed by concept and method therefor,"When information expressed by concept is input to a natural language processing system, the form of expressing the input concept is selected by referring to a knowledge base having the knowledge of languages, general knowledge, and the knowledge of specific areas. In addition, the information expressed by the concept is split into individual concepts, one natural language expression is selected from among one or more natural language expressions with respect to the split individual concepts, and the selected natural language expression is output. In this way, information for natural language appropriate for the situation is generated from the same concept. <IMAGE>",G06F 17/27; G06F 17/28,CANON KK,SUDA ARUNA ROHRA; JEYACHANDRAN SURESH,32744894 28.12.1994 JP; 32744994 28.12.1994 JP,
WO2018184208,PCT/CN2017/079726,07.04.2017,WO/2018/184208,11.10.2018,WO,METHODS AND APPARATUS FOR DEEP LEARNING NETWORK EXECUTION PIPELINE ON MULTI-PROCESSOR PLATFORM,"Methods and systems are disclosed using an execution pipeline on a multi-processor platform for deep learning network execution. In one example, a network workload analyzer receives a workload, analyzes a computation distribution of the workload, and groups the network nodes into groups. A network executor assigns each group to a processing core of the multi-core platform so that the respective processing core handle computation tasks of the received workload for the respective group.",G06F 15/76,"INTEL CORPORATION; YANG, Liu; YAO, Anbang","YANG, Liu; YAO, Anbang",,CN-201780088118.6; EP-2017904717
WO2002031814,PCT/US2001/031162,03.10.2001,WO/2002/031814,18.04.2002,WO,LANGUAGE INDEPENDENT VOICE-BASED SEARCH SYSTEM,"A language independent, voice based user interface method includes receiving voice input data spoken by a user, identifying a language spoken by the user from the voice input data, converting the voice input data into a first text in the identified language by recognizing the user's speech in the voice input data based at least in part on the language identifier, parsing the first text to extract a keyword, and using the keyword as a command to an application. Further actions include receiving results to the command, converting the results into a second text in a natural language format according to the identified language, and rendering the second text for perception by the user.",G06F 17/28; G06F 17/30; G10L 15/00; G10L 15/26,"INTEL CORPORATION; ZHOU, Guojun","ZHOU, Guojun","09/685,419 10.10.2000 US",EP-2001979481; KR-1020037005005; JP-2002535114; CN-01817139.7; IN-396/MUMNP/2003
EP14534376,05270078,08.11.2005,1657650,17.05.2006,EP,System and method for compiling rules created by machine learning program,"A system, a method, and a machine-readable medium are provided. A group of linear rules and associated weights are provided as a result of machine learning. Each one of the group of linear rules is partitioned into a respective one of a group of types of rules. A respective transducer for each of the linear rules is compiled. A combined finite state transducer is created from a union of the respective transducers compiled from the linear rules.",G06N 5/02; G06F 17/27,AT & T CORP,BANGALORE SRINIVAS,62599304 08.11.2004 US,
EP12291903,91480001,08.01.1991,0494573,15.07.1992,EP,Method for automatically disambiguating the synonymic links in a dictionary for a natural language processing system.,"A method for automatically disambiguating the synonymic links in a dictionary for a natural language processing system. Said dictionary is stored in the memory of a data processing system and includes a list of headwords with their respective synonym lists. The same headword can have different meanings, each of which has its own synonym list, each of which also can have different meanings. Disambiguation of the synonymic links is performed by reading from said dictionary a ""meaning-entry"", the words from which it is a synonym and its own list of synonyms, to build a synonymic environment table. A similarity index is computed for each pair of words of said environment and the words having the greatest similarity with the aggregate are incrementally clustered. The final cluster is then validated and the ""meaning-entry"" and its disambiguated synonyms are written back into the dictionary. <IMAGE>",G06F 15/38; G06F 17/28; G06F 15/40; G06F 17/27,IBM; IBM FRANCE,BEDECARRAX CHANTAL; PARISOT PIERRE; WARNESSON ISABELLE,91480001 08.01.1991 EP,
WO2016187472,PCT/US2016/033363,19.05.2016,WO/2016/187472,24.11.2016,WO,MULTILINGUAL IMAGE QUESTION ANSWERING,"Embodiments of a multimodal question answering (mQA) system are presented to answer a question about the content of an image. In embodiments, the model comprises four components: a Long Short-Term Memory (LSTM) component to extract the question representation; a Convolutional Neural Network (CNN) component to extract the visual representation; an LSTM component for storing the linguistic context in an answer, and a fusing component to combine the information from the first three components and generate the answer. A Freestyle Multilingual Image Question Answering (FM-IQA) dataset was constructed to train and evaluate embodiments of the mQA model. The quality of the generated answers of the mQA model on this dataset is evaluated by human judges through a Turing Test.",G01C 21/36; G06E 1/00; G06E 3/00; G06F 3/01; G06F 17/00; G06F 17/27; G06F 17/30,BAIDU USA LLC,"GAO, Haoyuan; MAO, Junhua; ZHOU, Jie; HUANG, Zhiheng; WANG, Lei; XU, Wei","62/164,984 21.05.2015 US; 15/137,179 25.04.2016 US",JP-2017514532; EP-2016797334
WO2019113783,PCT/CN2017/115691,12.12.2017,WO/2019/113783,20.06.2019,WO,"NUMBER GENERALIZATION METHOD AND SYSTEM FOR MACHINE TRANSLATION, COMPUTER, AND COMPUTER PROGRAM","A number generalization method and system for machine translation, a computer, and a computer program, pertaining to the technical field of computer software. The method comprises the following steps: in a training stage, performing special processing on a training corpus and performing normal training without changing a structure of a neural network model; and in a translation stage replacing generalized tags in a translation with normal translated text. The method can apply generalization techniques by changing only pre-processing and post-processing stages, expands application of the generalization technique in neural network machine translation, is adapted to a novel machine translation model structure, translates number-containing words or phrases accurately, and replaces numbers in a term list with generalized tags, thereby reducing the size of the term list and improving training efficiency of a neural network model.",G06F 17/28,"GLABAL TONE COMMUNICATION TECHNOLOGY CO., LTD.; 中译语通科技股份有限公司","BEI, Chao; 贝超; CHENG, Guogen; 程国艮",201711309873.0 11.12.2017 CN,
WO2019035765,PCT/SG2018/050411,14.08.2018,WO/2019/035765,21.02.2019,WO,"METHODS, MACHINE LEARNING ENGINES AND FILE MANAGEMENT PLATFORM SYSTEMS FOR CONTENT AND CONTEXT AWARE DATA CLASSIFICATION AND SECURITY ANOMALY DETECTION","Systems, methods and computer readable medium are provided for perform a method for content and context aware data classification or a method for content and context aware data security anomaly detection. The method for content and context aware data confidentiality classification includes scanning one or more documents in one or more network data repositories of a computer network and extracting content features and context features of the one or more documents into one or more term frequency- inverse document frequency (TF-IDF) vectors and one or more latent semantic indexing (LSI) vectors. The method further includes classifying the one or more documents into a number of category classifications by machine learning the extracted content features and context features of the one or more documents at a file management platform of the computer network, each of the category classifications being associated with one or more confidentiality classifications.",G06N 20/00; G06F 16/00; G06F 17/27; G06F 17/28; G06F 21/62,DATHENA SCIENCE PTE. LTD.,"MUFFAT, Christopher",,
WO2020051256,PCT/US2019/049609,04.09.2019,WO/2020/051256,12.03.2020,WO,REINFORCEMENT LEARNING APPROACH TO MODIFY SENTENCES USING STATE GROUPS,"Methods, systems, and apparatus, including computer programs language encoded on a computer storage medium for a language modification system whereby input jargon language is modified to plain language using a reinforcement learning system with a real-time reward grammar engine. The actions of an agent are limited by three different methods: an operational window that defines the grammatical boundary or states that an agent can perform actions within an environment, state groups that specify that actions must be performed to all states belonging to a state group, and the length of the environment or input sentence. The reinforcement learning agent learns a policy of edits and modifications to a sentence such that the output sentence is grammatical and retains the intended meaning.",G06F 17/27,"MICHELLE, Archuleta","MICHELLE, Archuleta","62/726,532 04.09.2018 US",
EP12410841,91914992,08.08.1991,0545988,16.06.1993,EP,COMMUNICATION SYSTEM WITH TEXT MESSAGE RETRIEVAL BASED ON CONCEPTS INPUTTED VIA KEYBOARD ICONS,"A Natural Language Processing System utilizes a symbol parsing layer (5) and an intelligent word parsing layer (5) to produce a syntactically or pragmatically correct output. A plurality of polysemic symbol sequences are input through a keyboard with semantic, syntactic, or pragmatic segments including agent, action and patient segments, for example. One polysemic sequence is input from each of the three segments of the keyboard (1). A symbol parsing device, then parses each symbols in each polysemic symbol sequence to access a previously stored word, morpheme, or phrase. The accessed word, morpheme, or phrase (50) corresponds to the input polysemic symbol sequence and further corresponds to one of the designated agent, action or patient segments. Each accessed word, morpheme, or phrase further accesses corresponding and previously stored grammatical and semantic information. An intelligent word parsing layer (5) subsequently applies each of the plurality of words, morphemes, or phrases to a predetermined hierarchy of rules based upon the accessed grammatical and semantic information. The intelligent word parsing device subsequently parses the received plurality of accessed words, morphemes, or phrases into a syntactically or pragmatically correct output.",G06F 17/27; G06F 17/28; G06F 19/00; G09B 21/00; G10L 13/08; G10L 15/00,SEMANTIC COMPACTION SYS,BAKER BRUCE R; NYBERG ERIC H,56483590 09.08.1990 US; 9105507 08.08.1991 US,
EP234205406,18162246,16.03.2018,3407264,28.11.2018,EP,"LISTEN, INTERACT, AND TALK: LEARNING TO SPEAK VIA INTERACTION","Described herein are systems and methods for grounded natural language learning in an interactive setting. In embodiments, during a learning process, an agent learns natural language by interacting with a teacher and learning from feedback, thus learning and improving language skills while taking part in the conversation. In embodiments, a model is used to incorporate both imitation and reinforcement by leveraging jointly sentence and reward feedback from the teacher. Various experiments are conducted to validate the effectiveness of a model embodiment.",G06N 3/00; G06F 17/20; G06N 3/04; G06N 3/08,BAIDU USA LLC,ZHANG HAICHAO; YU HAONAN; XU WEI,201715821452 22.11.2017 US; 201762511295 25.05.2017 US,
WO2018110985,PCT/KR2017/014672,14.12.2017,WO/2018/110985,21.06.2018,WO,METHOD AND APPARATUS FOR AUTOMATED DECISION MAKING,"A method for a first electronic device comprises generating a decision-making data structure using a machine learning data structure; transmitting, to a second electronic device, the decision-making data structure; receiving, from the electronic device, result data regarding a result of performing a selected action selected from the decision-making data structure; and updating the machine learning data structure using the result data.",G06N 99/00; G06N 3/08,"SAMSUNG ELECTRONICS CO., LTD.","LOBETE, Daniel Ansorregui; SARAVANAN, Karthikeyan Palavedu",1621347.2 15.12.2016 GB,EP-2017881319; KR-1020197020085
WO2019112646,PCT/US2018/037858,15.06.2018,WO/2019/112646,13.06.2019,WO,GRAPHICAL USER INTERFACE RENDERING MANAGEMENT BY VOICE-DRIVEN COMPUTING INFRASTRUCTURE,"Managing rendering of a graphical user interface is provided. A system receives data packets comprising an input audio signal. The system determines an application identifier and query. The system provides the query to the application to cause the application to generate a second query for transmission to a third-party server, and identify responses to the query. The system intercepts the responses, and generates a keyword based on the responses. The system selects a digital component using the keyword, executes a deduplication process, and determines to add the digital component to the responses. The system constructs a display output using a graphical user interface template that integrates the plurality of responses generated by the application with the digital component, and provides the display output to the computing device for rendering.",G06F 9/451; G10L 15/22; G10L 17/22; G06F 17/30; G06F 3/16,GOOGLE LLC,"KOTHARI, Anshul; BHAYA, Gaurav; JAIN, Tarun","15/836,746 08.12.2017 US",EP-2018740948
WO2020064212,PCT/EP2019/071874,14.08.2019,WO/2020/064212,02.04.2020,WO,PROVIDING A TRAINED NEURAL NETWORK AND DETERMINING A CHARACTERISTIC OF A PHYSICAL SYSTEM,"A method of determining a characteristic, such as optical response, of a physical system having a material structure, such as a thin-film multilayer stack or other optical system, has the steps: providing (1430) a neural network (1440) with its network architecture configured based on a model (1420) of scattering of radiation by the material structure along the radiation's path; training (1450) and using (1460) the neural network to determine the characteristic of the physical system. The network architecture may be configured based on the model by configuring parameters including number of units per hidden layer, number of hidden layers, layer interconnection and dropout.",G03F 7/20; G06N 3/04; G06N 3/08,ASML NETHERLANDS B.V.,"REHMAN, Samee, Ur",18197556.6 28.09.2018 EP,
EP292571797,18809417,04.06.2018,3632322,08.04.2020,EP,"SLEEP DETERMINING DEVICE, SLEEP DETERMINING METHOD, AND SLEEP DETERMINING PROGRAM","An object of the present invention is to provide a sleep determination apparatus, a sleep determination method, and a sleep determination program that provide an accurate and detailed determination of a sleep stage.A sleep determination apparatus of the present invention comprising: a heart rate data obtaining means for obtaining, based on data regarding a heart rate of a body of a user, a very low frequency component (VLF), a ratio of a low frequency component (LF) to a high frequency component (HF), a mean heartbeat interval (RRI), and a standard deviation of each heartbeat interval (RRI) of the heart rate as heart rate variability parameters indicating a heart rate state; and a sleep state determining means for determining which of the first non-REM sleep stage or the second non-REM sleep stage the heart rate variability parameters of the user indicate, in accordance with a first determination condition that is set based on a correlation between the heart rate variability parameters and the first non-REM sleep stage and a second determination condition that is set based on a correlation between the heart rate variability parameters and the second non-REM sleep stage.",A61B 5/16; A61B 5/0245,UNIV KEIO,MITSUKURA YASUE; YASUI MASATO; FUKUNAGA KOICHI; FURUKAWA TOSHIHARU,2017110495 02.06.2017 JP; 2018021420 04.06.2018 JP,
EP45426837,11182366,22.09.2011,2434454,28.03.2012,EP,Computerized characterization of cardiac motion in medical diagnostic ultrasound,"Computerized characterization of cardiac wall motion is provided. Quantities for cardiac wall motion are determined (34) from a four-dimensional (i.e., 3D + time) sequence of ultrasound data. A processor (12) automatically processes the volume data to locate (28) the cardiac wall through the sequence and calculate (34) the quantity from the cardiac wall position or motion. Various machine learning is used for locating (28) and tracking (30) the cardiac wall, such as using a motion prior learned from training data for initially locating the cardiac wall and the motion prior, speckle tracking, boundary detection, and mass conservation cues for tracking with another machine learned classifier. Where the sequence extends over multiple cycles, the cycles are automatically divided (26) for independent tracking of the cardiac wall. The cardiac wall from one cycle may be used to propagate (32) to another cycle for initializing the tracking. Independent tracking (32) in each cycle may reduce or avoid inaccuracies due to drift.",G06T 7/20; A61B 8/08; G06T 7/246,SIEMENS CORP; SIEMENS MEDICAL SOLUTIONS USA INC,WANG YANG; GEORGESCU BOGDAN; HOULE HELENE; COMANICIU DORIN,201113234697 16.09.2011 US; 201161482714 05.05.2011 US; 38664210 27.09.2010 US,
WO2019084551,PCT/US2018/058025,29.10.2018,WO/2019/084551,02.05.2019,WO,ATTENTION-BASED DECODER-ONLY SEQUENCE TRANSDUCTION NEURAL NETWORKS,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for generating an output sequence from an input sequence. One of the methods includes, at each of a plurality of generation time steps: generating a combined sequence for the generation time step that includes the input sequence followed by the output tokens that have already been generated as of the generation time step; processing the combined sequence using a self-attention decoder neural network to generate a time step output that defines a score distribution over a set of possible output tokens; and selecting, using the time step output, an output token from the set of possible output tokens as the next output token in the output sequence.",G06N 3/04,GOOGLE LLC,"SHAZEER, Noam M.; KAISER, Lukasz Mieczyslaw; POT, Etienne; SALEH, Mohammad; GOODRICH, Ben David; LIU, Peter J.; SEPASSI, Ryan","62/578,358 27.10.2017 US",
EP209999614,17155528,10.02.2017,3267328,10.01.2018,EP,AUTOMATED INTERPRETATION METHOD AND APPARATUS,"Provided is an automated interpretation method, apparatus, and system. The automated interpretation method includes encoding a voice signal in a first language to generate a first feature vector, decoding the first feature vector to generate a first language sentence in the first language, encoding the first language sentence to generate a second feature vector with respect to a second language, decoding the second feature vector to generate a second language sentence in the second language, controlling a generating of a candidate sentence list based on any one or any combination of the first feature vector, the first language sentence, the second feature vector, and the second language sentence, and selecting, from the candidate sentence list, a final second language sentence as a translation of the voice signal.",G06F 17/27; G06F 17/28; G10L 15/02,SAMSUNG ELECTRONICS CO LTD,LEE HODONG; PARK YOUNGKI; YOO SANG HYUN,20160086036 07.07.2016 KR,
WO2018184194,PCT/CN2017/079682,07.04.2017,WO/2018/184194,11.10.2018,WO,METHODS AND SYSTEMS USING IMPROVED CONVOLUTIONAL NEURAL NETWORKS FOR IMAGE PROCESSING,"Methods and systems are disclosed using improved Convolutional Neural Networks (CNN) for image processing. In one example, an input image is down-sampled into smaller images with a smaller resolution than the input image. The down-sampled smaller images are processed by a CNN having a last layer with a reduced number of nodes than a last layer of a full CNN used to process the input image at a full resolution. A result is outputted based on the processed down-sampled smaller images by the CNN having a last layer with a reduced number of nodes. In another example, shallow CNN networks are built randomly. The randomly built shallow CNN networks are combined to imitate a trained deep neural network (DNN).",G06K 9/00,"INTEL CORPORATION; WANG, Shandong; GUO, Yiwen; YAO, Anbang; CAI, Dongqi; WANG, Libin; XU, Lin; HU, Ping; CHENG, Wenhua; CHEN, Yurong","WANG, Shandong; GUO, Yiwen; YAO, Anbang; CAI, Dongqi; WANG, Libin; XU, Lin; HU, Ping; CHENG, Wenhua; CHEN, Yurong",,EP-2017904390
EP232545773,18163730,23.03.2018,3396600,31.10.2018,EP,NEURAL NETWORK OPTIMIZATION MECHANISM,"An apparatus to facilitate optimization of a neural network (NN) is disclosed. The apparatus includes optimization logic to define a NN topology having one or more macro layers, adjust the one or more macro layers to adapt to input and output components of the NN and train the NN based on the one or more macro layers.",G06N 3/04; G06N 3/063; G06N 3/08,INTEL CORP,SRINIVASA NARAYAN; RAY JOYDEEP; GALOPPO VON BORRIES NICOLAS C; ASHBAUGH BEN; SURTI PRASOONKUMAR; CHEN FENG; LAKSHMANAN BARATH; OULD-AHMED-VALL ELMOUSTAPHA; MA LIWEI; HURD LINDA L; APPU ABHISHEK R; WEAST JOHN C; BAGHSORKHI SARA S; GOTTSCHLICH JUSTIN E; SAKTHIVEL CHANDRASEKARAN; AKHBARI FARSHAD; KIM DUKHWAN; KOKER ALTUG; SATISH NADATHUR RAJAGOPALAN,201715494948 24.04.2017 US,
WO2020080834,PCT/KR2019/013618,17.10.2019,WO/2020/080834,23.04.2020,WO,ELECTRONIC DEVICE AND METHOD FOR CONTROLLING THE ELECTRONIC DEVICE,"An electronic device includes a memory including at least one instruction, and a processor configured to execute the at least one instruction to, based on receiving a user inquiry, identify whether a response to the received user inquiry is present in a personal knowledge base that is included in the memory, based on the response to the received user inquiry being identified to be present in the personal knowledge base, acquire the response to the received user inquiry, from the personal knowledge base, and based on the response to the received user inquiry being identified to not be present in the personal knowledge base, change a first text included in the received user inquiry to a second text, and acquire, from an external server, the response to the received user inquiry, using the second text to which the first text is changed.",G06F 16/332; G06F 16/33; G06F 15/02; G06N 20/00; G06N 3/08,"SAMSUNG ELECTRONICS CO., LTD.","SEO, Sungmok; CHANG, Byungjoon; KIM, Sehoon; SEOL, Jeongsu; LEE, Jaehun",10-2018-0124626 18.10.2018 KR,
WO2018184222,PCT/CN2017/079771,07.04.2017,WO/2018/184222,11.10.2018,WO,METHODS AND SYSTEMS USING IMPROVED TRAINING AND LEARNING FOR DEEP NEURAL NETWORKS,"Methods and systems are disclosed using improved training and learning for deep neural networks. In one example, a deep neural network includes a plurality of layers, and each layer has a plurality of nodes. For each L layer in the plurality of layers, the nodes of each L layer are randomly connected to nodes in a L+1 layer. For each L+1 layer in the plurality of layers, the nodes of each L+1 layer are connected to nodes in a subsequent L layer in a one-to-one manner. Parameters related to the nodes of each L layer are fixed. Parameters related to the nodes of each L+1 layers are updated, and L is an integer starting with 1. In another example, a deep neural network includes an input layer, output layer, and a plurality of hidden layers. Inputs for the input layer and labels for the output layer are determined related to a first sample. Similarity between different pairs of inputs and labels between a second sample with the first sample is estimated using Gaussian regression process.",G06N 3/02; G06N 3/04; G06N 3/08,"INTEL CORPORATION; GUO, Yiwen; YAO, Anbang; CAI, Dongqi; WANG, Libin; XU, Lin; HU, Ping; WANG, Shandong; CHENG, Wenhua; CHEN, Yurong","GUO, Yiwen; YAO, Anbang; CAI, Dongqi; WANG, Libin; XU, Lin; HU, Ping; WANG, Shandong; CHENG, Wenhua; CHEN, Yurong",,EP-2017904931; CN-201780088106.3
EP276032577,16925613,30.12.2016,3564863,06.11.2019,EP,"APPARATUS FOR EXECUTING LSTM NEURAL NETWORK OPERATION, AND OPERATIONAL METHOD","An apparatus for executing an LSTM neural network operation, and an operational method. The apparatus comprises a direct memory access unit (1), an instruction cache unit (2), a controller unit (3), a plurality of data cache units (4) arranged in parallel and a plurality of data processing modules (5) arranged in parallel, the plurality of data processing modules (5) corresponding to the data cache units (4) in a one-to-one manner, for acquiring, from the corresponding data cache units (4), input data and weights and offsets required during operation, so as to perform an LSTM neural network operation; the plurality of data processing modules (5) execute parallel operations. The apparatus runs using special instructions, the number of instructions required for operation is reduced, and decoding overheads are decreased; weights and offsets are cached so that data transmission overheads are decreased; the plurality of data processing modules (5) run in parallel, improving the operation speed of the LSTM network.",G06N 3/06,SHANGHAI CAMBRICON INFORMATION TECH CO LTD,CHEN YUNJI; CHEN XIAOBING; LIU SHAOLI; CHEN TIANSHI,2016113493 30.12.2016 CN,
WO2020014590,PCT/US2019/041566,12.07.2019,WO/2020/014590,16.01.2020,WO,GENERATING A COMPRESSED REPRESENTATION OF A NEURAL NETWORK WITH PROFICIENT INFERENCE SPEED AND POWER CONSUMPTION,"The disclosure relates to technology for generating a compressed neural network weight tensor. A weight tensor is received from a neural network to be compressed, and it is reordered to be compressed to have an inner two-dimensional (2D) shape and a 2D sparse bitmap. A layered structure is generated that represents the reordered weight tensor, and the reordered weight tensor is divided into a group of coefficients (GOCs). An encoding mode is selected to generate a quantized reordered weight tensor using one of a codebook or direct quantization, and a column swapped quantized reordered weigh tensor is generated. A compressed neural network is formed by encoding and the compressed representation of the neural network is transmitted to a target system for decompression.",G06N 3/063,"FUTUREWEI TECHNOLOGIES, INC.","WANG, Wei; JIANG, Wei","62/697,251 12.07.2018 US",
WO2019107674,PCT/KR2018/003912,03.04.2018,WO/2019/107674,06.06.2019,WO,COMPUTING APPARATUS AND INFORMATION INPUT METHOD OF THE COMPUTING APPARATUS,"Provided are a method and apparatus for classifying and storing input information based on machine learning and artificial intelligence and automatically inputting the stored information. According to an exemplary embodiment, input information is classified and stored using machine learning, an input item to which the stored input information is to be input is identified using machine learning, and the stored input information is input to the input item.",G06K 9/62; G06N 99/00; G06K 9/32,"SAMSUNG ELECTRONICS CO., LTD.","HAN, Jun Kyu",10-2017-0163447 30.11.2017 KR,
WO2012079257,PCT/CN2010/079963,17.12.2010,WO/2012/079257,21.06.2012,WO,METHOD AND DEVICE FOR MACHINE TRANSLATION,"The invention discloses a machine translation method and a machine translation device, related to the field of natural language processing. The device includes: a source language input unit, which inputs source language sentences; a source language analysis unit, which analyses the morphology and syntax to acquire the syntactic structure, and sets property features for the nodes of the syntactic structure; a storage unit of any-genitive determination model, which saves the any-genitive determination model; a determination unit of any-genitive, which determines whether the sentence contains any-genitive; an extraction unit of any-genitive phrases, which obtains any-genitive phrases; a translation unit of any-genitive phrases, which translates any-genitive phrases; a first extraction unit, which obtains the remaining part of the source language sentence; a machine translation unit, which translates the remaining part of the source language sentence; an integration unit of translation results, which integrates the translation results to obtain a target language; a target language output unit, which outputs the target language. The invention can decrease the complexity of the source language syntactic structure, and improve the generation efficiency of the target language, thus improving translation accuracy, and appropriately decreasing decoding computation of machine translation.",G06F 17/28,"BEIJING JIAOTONG UNIVERSITY; 北京交通大学; XU, Jin'an; 徐金安; MENG, Fandong; 孟凡东; CHEN, Qia; 陈恰; PAN, Xu; 潘栩; DA, Zhen; 达珍; MENG, QingChen; 孟庆辰","XU, Jin'an; 徐金安; MENG, Fandong; 孟凡东; CHEN, Qia; 陈恰; PAN, Xu; 潘栩; DA, Zhen; 达珍; MENG, QingChen; 孟庆辰",,
WO2019126740,PCT/US2018/067276,21.12.2018,WO/2019/126740,27.06.2019,WO,AN ON-CHIP COMMUNICATION SYSTEM FOR NEURAL NETWORK PROCESSORS,"The present disclosure provides an on-chip communication system for neural network processors, a processing device, and a method for operating on an on-chip communication system. The system can include a cluster manager configured to generate a global signal, and a plurality of tile units in a tile array coupled with the cluster manager, each including two connectors and a node connected between the two connectors.",G06N 3/02; G06N 3/04; G06N 3/08; G06N 7/04,ALIBABA GROUP HOLDING LIMITED,"CHEN, Jian","15/980,685 15.05.2018 US; 62/610,127 22.12.2017 US",
WO2019083227,PCT/KR2018/012376,19.10.2018,WO/2019/083227,02.05.2019,WO,"METHOD OF PROCESSING MEDICAL IMAGE, AND MEDICAL IMAGE PROCESSING APPARATUS PERFORMING THE METHOD","A device and a method for medical image processing are provided. The medical image processing method may include: obtaining a plurality of actual medical images corresponding to a plurality of patients and including lesions; training a deep neural network (DNN), based on the plurality of actual medical images, to obtain a first neural network for predicting a variation in a lesion over time, the lesion being included in a first medical image of the plurality of actual medical images, wherein the first medical image is obtained at a first time point; and obtaining, via the first neural network, a second medical image representing a state of the lesion at a second time point different from the first time point.",G16H 50/20; G06N 3/02; G16H 50/30; G06T 7/00; G06T 1/00,"SAMSUNG ELECTRONICS CO., LTD.","LEE, Dong-jae; OH, Hyun-hwa; KIM, Se-min; SONG, Jeong-yong; LEE, Hyun-jung",10-2017-0140317 26.10.2017 KR,
WO2018084577,PCT/KR2017/012275,01.11.2017,WO/2018/084577,11.05.2018,WO,"DATA RECOGNITION MODEL CONSTRUCTION APPARATUS AND METHOD FOR CONSTRUCTING DATA RECOGNITION MODEL THEREOF, AND DATA RECOGNITION APPARATUS AND METHOD FOR RECOGNIZING DATA THEREOF","Disclosed is a data recognition model construction apparatus. The data recognition model construction apparatus includes a video inputter configured to receive a video, an image composition unit configured to, based on a common area included in each of a plurality of images that form at least a portion of the video, generate a composition image by overlaying at least a portion of the plurality of images, a learning data inputter configured to receive the generated composition image, a model learning unit configured to make a data recognition model learn using the generated composition image, and a model storage configured to store the learnt data recognition model.",G06K 9/00; G06T 17/00; G06Q 50/22,"SAMSUNG ELECTRONICS CO., LTD.","KIM, Ji-man; PARK, Chan-jong; YANG, Do-jun; LEE, Hyun-woo",10-2016-0145748 03.11.2016 KR; 10-2017-0104312 17.08.2017 KR,CN-201780067877.4; EP-2017867457
EP232545798,18159838,02.03.2018,3396622,31.10.2018,EP,COORDINATION AND INCREASED UTILIZATION OF GRAPHICS PROCESSORS DURING INFERENCE,"A mechanism is described for facilitating inference coordination and processing utilization for machine learning at autonomous machines. A method of embodiments, as described herein, includes detecting, at training time, information relating to one or more tasks to be performed according to a training dataset relating to a processor including a graphics processor. The method may further include analyzing the information to determine one or more portions of hardware relating to the processor capable of supporting the one or more tasks, and configuring the hardware to pre-select the one or more portions to perform the one or more tasks, while other portions of the hardware remain available for other tasks.",G06T 1/20,INTEL CORP,APPU ABHISHEK R; KOKER ALTUG; WEAST JOHN C; MACPHERSON MIKE B; HURD LINDA L; BAGHSORKHI SARA S; GOTTSCHLICH JUSTIN E; SURTI PRASOONKUMAR; SAKTHIVEL CHANDRASEKARAN; MA LIWEI; OULD-AHMED-VALL ELMOUSTAPHA; SINHA KAMAL; RAY JOYDEEP; VEMBU BALAJI; JAHAGIRDAR SANJEEV; RANGANATHAN VASANTH; KIM DUKHWAN,201715495054 24.04.2017 US,
EP128397488,14170998,03.06.2014,2811414,10.12.2014,EP,Confidence-driven rewriting of source texts for improved translation,"A method for rewriting source text includes receiving source text including a source text string in a first natural language. The source text string is translated (S208) with a machine translation system to generate a first target text string in a second natural language. A translation confidence for the source text string is computed (S210), based on the first target text string. At least one alternative text string is generated (S216), where possible, in the first natural language by automatically rewriting the source string. Each alternative string is translated (S218) to generate a second target text string in the second natural language. A translation confidence is computed (S220) for the alternative text string based on the second target string. Based on the computed translation confidences, one of the alternative text strings may be selected as a candidate replacement for the source text string and may be proposed to a user on a graphical user interface.",G06F 17/28,XEROX CORP,MIRKIN SHACHAR; VENKATAPATHY SRIRAM; DYMETMAN MARC,201313908157 03.06.2013 US,
WO2017094913,PCT/JP2016/086042,05.12.2016,WO/2017/094913,08.06.2017,WO,NATURAL LANGUAGE PROCESSING DEVICE AND NATURAL LANGUAGE PROCESSING METHOD,"The present invention is equipped with: a dialogue processing unit that, for each input of an analyzable unit of a natural language sentence, executes analysis processes sequentially and in parallel with each of multiple analysis processing units; and an output unit that, on the basis of the analysis result from each analysis processing unit in the dialogue processing unit, obtains an output such as a dialogue response sentence. Each processing unit provided in the dialogue processing unit acquires its own immediately prior analysis result or an earlier past analysis result and an immediately prior analysis result or earlier past result from the other processing units, and makes an inference while referencing the acquired analysis results, thereby obtaining a single analysis result or a limited number of analysis results.",G06F 17/27; G06F 17/28; G10L 13/00,NATIONAL UNIVERSITY CORPORATION SHIZUOKA UNIVERSITY; 国立大学法人静岡大学,NATIONAL UNIVERSITY CORPORATION SHIZUOKA UNIVERSITY; 国立大学法人静岡大学; KANO Yoshinobu; 狩野　芳伸,2015-236446 03.12.2015 JP,US-15780272
EP289344282,18853051,05.09.2018,3617921,04.03.2020,EP,VIDEO DISPLAY DEVICE AND OPERATING METHOD THEREFOR,"Provided is an artificial intelligence (Al) system simulating functions of a human brain, such as recognition and decision, by using a machine learning algorithm, such as deep-learning.Image display apparatuses are more convenient for a user, by performing user authentication by using an authentication image set generated based on an object recognized from content viewed by the user.",G06F 21/36; G06F 16/00; G06N 3/08; G06T 7/11,SAMSUNG ELECTRONICS CO LTD,CHO EUN-AE; KIM JIN-HYUN; PARK GI-HOON; KWON JAE-OOK,20170113352 05.09.2017 KR; 20180083651 18.07.2018 KR; 2018010350 05.09.2018 KR,
EP13810181,02396035,19.03.2002,1246075,02.10.2002,EP,Determining language for character sequence,"A method for determining the language for a character sequence fed into a data processing device, wherein decision trees are trained for different characters on the basis of lexicons of predetermined languages. The decision trees describe language probabilities on the basis of characters in the environments of the characters. The decision trees for at least some of the characters of the character sequence fed into the data processing device are traversed, thus obtaining a probability of at least one language for each character. The language for the character sequence is determined on the basis of the probabilities obtained.",G06F 17/27; G06F 40/00,NOKIA CORP,HAEKKINEN MR JUHA; METTAELAE MR MARKKU,20010644 28.03.2001 FI,
EP232545687,18162625,19.03.2018,3396528,31.10.2018,EP,DYNAMIC DISTRIBUTED TRAINING OF MACHINE LEARNING MODELS,"In an example, an apparatus comprises a plurality of execution units comprising at least a first type of execution unit and a second type of execution unit and logic, at least partially including hardware logic, to analyze a workload and assign the workload to one of the first type of execution unit or the second type of execution unit. Other embodiments are also disclosed and claimed.",G06F 9/28; G06F 9/50; G06N 3/04; G06N 3/063,INTEL CORP,KOKER ALTUG; APPU ABHISHEK R; SINHA KAMAL; RAY JOYDEEP; VEMBU BALAJI; OULD-AHMED-VALL ELMOUSTAPHA; BAGHSORKHI SARA S; YAO ANBANG; NEALIS KEVIN; CHEN XIAOMING; WEAST JOHN C; GOTTSCHLICH JUSTIN E; SURTI PRASOONKUMAR; SAKTHIVEL CHANDRASEKARAN; AKHBARI FARSHAD; SATISH NADATHUR RAJAGOPALAN; MA LIWEI; BOTTLESON JEREMY; NURVITADHI ERIKO; SCHLUESSLER TRAVIS T; SHAH ANKUR N; KENNEDY JONATHAN; RANGANATHAN VASANTH; JAHAGIRDAR SANJEEV,201715494971 24.04.2017 US,
WO2018083670,PCT/IB2017/056905,04.11.2017,WO/2018/083670,11.05.2018,WO,SEQUENCE TRANSDUCTION NEURAL NETWORKS,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for generating a target sequence from an input sequence. In one aspect, a method comprises maintaining a set of current hypotheses, wherein each current hypothesis comprises an input prefix and an output prefix. For each possible combination of input and output prefix length, the method extends any current hypothesis that could reach the possible combination to generate respective extended hypotheses for each such current hypothesis; determines a respective direct score for each extended hypothesis using a direct model; determines a first number of highest- scoring hypotheses according to the direct scores; rescores the first number of highest-scoring hypotheses using a noisy channel model to generate a reduced number of hypotheses; and adds the reduced number of hypotheses to the set of current hypotheses.",G06F 17/22; G06F 17/28; G06N 3/02,DEEPMIND TECHNOLOGIES LIMITED,"YU, Lei; DYER, Christopher James; KOCISKY, Tomas; BLUNSOM, Philip","62/418,170 04.11.2016 US",CN-201780082293.4
WO2008045815,PCT/US2007/080663,07.10.2007,WO/2008/045815,17.04.2008,WO,METHOD AND SYSTEM FOR NATURAL-LANGUAGE SENTENCE GENERATION FROM LANGUAGE-INDEPENDENT SEMANTIC STRUCTURES,"A method and computer system for translating sentences between languages from an intermediate language-independent semantic representation is provided. On the basis of comprehensive understanding about languages and semantics, exhaustive linguistic descriptions are used to analyze sentences, to build syntactic structures and language independent semantic structures and representations, and to synthesize one or more sentences in a natural or artificial language. A computer system is also provided to analyze and synthesize various linguistic structures and to perform translation of a wide spectrum of various sentence types. As result, a generalized data structure, such as a semantic structure, is generated from a sentence of an input language and can be transformed into a natural sentence expressing its meaning correctly in an output language. The method and computer system can be applied to in automated abstracting, machine translation, natural language processing, control systems, Internet information retrieval, etc.",G06F 17/27; G06F 17/28,"ABBYY SOFTWARE LTD; ANISIMOVICH, Konstantin; SELEGEY, Vladimir; ZUEV, Konstantin","ANISIMOVICH, Konstantin; SELEGEY, Vladimir; ZUEV, Konstantin","11/548,214 10.10.2006 US; 11/690,099 22.03.2007 US",
WO2017132846,PCT/CN2016/073227,02.02.2016,WO/2017/132846,10.08.2017,WO,ADAPTIVE BOOSTING MACHINE LEARNING,"An apparatus comprising memory configured to store data to be machine-recognized(710), and at least one processing core configured to run an adaptive boosting machine learning algorithm with the data, wherein a plurality of learning algorithms are applied, wherein a feature space is partitioned into bins, wherein a distortion function is applied to features of the feature space(720), and wherein a first derivative of the distortion function is not constant(730).",G06K 9/62,"NOKIA TECHNOLOGIES OY; NAVTEQ (SHANGHAI) TRADING CO., LTD.","SHANG, Chubo",,US-16074820; EP-2016888671
WO2018217829,PCT/US2018/033987,22.05.2018,WO/2018/217829,29.11.2018,WO,METHODS AND APPARATUS FOR ENHANCING A NEURAL NETWORK USING BINARY TENSOR AND SCALE FACTOR PAIRS,"Methods and apparatus are disclosed for enhancing a neural network using binary tensor and scale factor pairs. For one example, a method of optimizing a trained convolutional neural network (CNN) includes initializing an approximation residue as a trained weight tensor for the trained CNN. A plurality of binary tensors and scale factor pairs are determined. The approximation residue is updated using the binary tensors and scale factor pairs.",G06N 3/04; G06N 3/08,INTEL CORPORATION,"GUO, Yiwen; YAO, Anbang; ZHAO, Hao; LU, Ming; CHEN, Yurong","62/510,025 23.05.2017 US",CN-201880026768.2; EP-2018805760
WO2019024050,PCT/CN2017/095841,03.08.2017,WO/2019/024050,07.02.2019,WO,DEEP CONTEXT-BASED GRAMMATICAL ERROR CORRECTION USING ARTIFICIAL NEURAL NETWORKS,"Disclosed herein are methods and systems for grammatical error detection. In one example, a sentence is received. One or more target words in the sentence are identified based, at least in part, on one or more grammatical error types. Each of the one or more target words corresponds to at least one of the one or more grammatical error types. For at least one of the one or more target words, a classification of the target word with respect to the corresponding grammatical error type is estimated using an artificial neural network model trained for the grammatical error type. A grammatical error in the sentence is detected based, at least in part, on the target word and the estimated classification of the target word.",G06F 17/27,"LINGOCHAMP INFORMATION TECHNOLOGY (SHANGHAI) CO., LTD.","LIN, Hui; WANG, Chuan; LI, Ruobing",,KR-1020207005087
WO2019133267,PCT/US2018/065316,13.12.2018,WO/2019/133267,04.07.2019,WO,CHARACTERIZED CHATBOT WITH PERSONALITY,"The present disclosure provides a technical solution related to establishing a characterized chatbot with personality. On one hand, a corpus database matched with a specific character may be established, and a generated regular/conventional response messages may be converted into a characterized response messages with character's features during conversation, so that the conversation style of a chatbot may be characterized with a certain character's features. On the other hand, a chatbot may select a response message with a specific emotion by using an emotion conversation table corresponding to a personality when generating the response message against a content of a conversation input by a user, so that a chatbot may be characterized and have certain personality.",G06F 17/28; G06F 17/27,"MICROSOFT TECHNOLOGY LICENSING, LLC","LIN, Pingping; SONG, Ruihua; ZENG, Min; CHEN, Yan; LIU, Yue",201711487229.2 29.12.2017 CN,
EP74866064,09852479,23.12.2009,2518639,31.10.2012,EP,METHOD AND DEVICE FOR PROCESSING CONTINUOUS QUERIES,"A method for processing continuous queries in natural language received from a client machine (11-i) connected to a second applications server (14) for continuous queries by means of a first application server and a telecommunications network (12); comprising the steps of receiving first text data in natural language in a processing unit (21), arranged in accordance with the linguistic rules of the natural language of a query posed, to supply second text data in an intermediate language based on the first text data in natural language, the generation of third text data in natural language in a dialogue unit (23), arranged in accordance with the linguistic rules of the natural language of a reply message, based on the second text data in the intermediate language received from the processing unit (21) and the issuing of the reply message to the client machine (11-i) by means of a first application server and a telecommunications network (12).",G06F 17/27; G06F 17/28; G06F 17/30,URIBE-ETXEBARRIA JIMENEZ XABIER,URIBE-ETXEBARRIA JIMENEZ XABIER,2009070625 23.12.2009 ES,
WO2020088330,PCT/CN2019/112878,23.10.2019,WO/2020/088330,07.05.2020,WO,LATENT SPACE AND TEXT-BASED GENERATIVE ADVERSARIAL NETWORKS (LATEXT-GANS) FOR TEXT GENERATION,"According to embodiments, an encoder neural network receives a one-hot representation of a real text. The encoder neural network outputs a latent representation of the real text. A decoder neural network receives random noise data or artificial code generated by a generator neural network from random noise data. The decoder neural network outputs softmax representation of artificial text. The decoder neural network receives the latent representation of the real text. The decoder neural network outputs a reconstructed softmax representation of the real text. A hybrid discriminator neural network receives a first combination of the soft-text and the latent representation of the real text and a second combination of the softmax representation of artificial text and the artificial code. The hybrid discriminator neural network outputs a probability indicating whether the second combination is similar to the first combination. Additional embodiments for utilizing latent representation are also disclosed.",G06F 40/56; G06N 3/02,"HUAWEI TECHNOLOGIES CO., LTD.","HAIDAR, Md Akmal; REZAGHOLIZADEH, Mehdi","16/175,373 30.10.2018 US",
EP208102801,16746308,29.01.2016,3255606,13.12.2017,EP,DETERMINATION METHOD AND PROGRAM,"A determination method for determining the structure of a convolutional neural network includes the acquisition step of acquiring N filters having the weights trained using a training image group as the initial values, where N is a natural number greater than or equal to 1, (S10) and the splitting step of increasing the number of the filters from N to M, where M is a natural number greater than or equal to 2 and is greater than N, by adding a filter obtained by performing a transformation used in image processing fields on at least one of the N filters (S20).",G06T 7/00; G06K 9/46; G06K 9/62; G06N 3/04; G06N 3/08,PANASONIC IP MAN CO LTD,KIM MIN YOUNG; RIGAZIO LUCA; TSUKIZAWA SOTARO; KOZUKA KAZUKI,2016000462 29.01.2016 JP; 2016006580 15.01.2016 JP; 201562113174 06.02.2015 US,
WO2018184204,PCT/CN2017/079719,07.04.2017,WO/2018/184204,11.10.2018,WO,METHODS AND SYSTEMS FOR BUDGETED AND SIMPLIFIED TRAINING OF DEEP NEURAL NETWORKS,"Methods and systems for budgeted and simplified training of deep neural networks (DNNs) are disclosed. In one example， a trainer is to train a DNN using a plurality of training sub-images derived from a down-sampled training image. A tester is to test the trained DNN using a plurality of testing sub-images derived from a down-sampled testing image. In another example， in a recurrent deep Q-network (RDQN) having a local attention mechanism located between a convolutional neural network (CNN) and a long-short time memory (LSTM), a plurality of feature maps are generated by the CNN from an input image. Hard-attention is applied by the local attention mechanism to the generated plurality of feature maps by selecting a subset of the generated feature maps. Soft attention is applied by the local attention mechanism to the selected subset of generated feature maps by providing weights to the selected subset of generated feature maps in obtaining weighted feature maps. The weighted feature maps are stored in the LSTM. A Q value is calculated for different actions based on the weighted feature maps stored in the LSTM.",G06K 9/66; G06N 3/08,"INTEL CORPORATION; GUO, Yiwen; HOU, Yuqing; YAO, Anbang; CAI, Dongqi; WANG, Libin; XU, Lin; HU, Ping; WANG, Shandong; CHENG, Wenhua; CHEN, Yurong","GUO, Yiwen; HOU, Yuqing; YAO, Anbang; CAI, Dongqi; WANG, Libin; XU, Lin; HU, Ping; WANG, Shandong; CHENG, Wenhua; CHEN, Yurong",,CN-201780088119.0; EP-2017904518
EP12112333,90306992,26.06.1990,0409425,23.01.1991,EP,METHOD AND APPARATUS FOR TRANSLATING LANGUAGE,"A method for processing natural language comprises the steps of alternating words constructing a sentence of a natural language into computing units made up of the Speech Element by each of Parts of Speech which are absolutely necessary and selected for analyzing and processing a natural language, and then computing analysis values among Speech Elements having information of character classification, means of Parts of Speech, grammatical relation, and functions in sense or by use which words have. A machine translation system implementing the method comprises input means, dictionary means, reading-dictionary memory means, original sentence memory means, computing unit memory means, analysis value memory means, translated sentence memory part, output means, and a CPU for controlling each of the said means.",G06F 17/27; G06F 17/28,"KIM, KEECHUNG; KIM, SUNCHANG","KIM, KEECHUNG; KIM, SUNCHANG",890010080 15.07.1989 KR; 890014447 07.10.1989 KR,
WO2019203488,PCT/KR2019/004173,09.04.2019,WO/2019/203488,24.10.2019,WO,ELECTRONIC DEVICE AND METHOD FOR CONTROLLING THE ELECTRONIC DEVICE THEREOF,"An artificial intelligence (AI) system utilizing a machine learning algorithm such as deep learning for controlling an electronic device when a video is reproduced and a user's voice instruction is received, to acquire a frame corresponding to the time point when the input of the user's voice instruction is received, and obtain a search result for information on objects in the frame using an AI model trained according to at least one of machine learning, a neural network or a deep learning algorithm.",H04N 21/472; H04N 21/4722; H04N 21/422; G06N 3/08; G06F 16/903; G06F 3/16,"SAMSUNG ELECTRONICS CO., LTD.","LEE, Jungmin",10-2018-0046072 20.04.2018 KR,
WO2005115559,PCT/US2005/017033,13.05.2005,WO/2005/115559,08.12.2005,WO,INTERACTIVE LANGUAGE LEARNING SYSTEM AND METHOD,"A method of interactive language instruction includes obtaining a sequence of basic units to present to a student. The method also includes obtaining a plurality of alternate representations for each of a plurality of the basic units. The method further includes presenting at least a portion of the sequence of basic units to the student. The method also includes obtaining input from the student during the presenting of the basic units. For at least one of the sequence of basic units to be presented to the student and the input from the student, segmentation is performed to break up a continuous stream of units into a sequence of discrete units. For at least one particular basic unit with the plurality of alternate representations, at least one of the alternate representations is automatically selected to present to the student based at least in part on the input obtained from the student during the presentation of basic units that are earlier in the sequence of basic units than the particular basic unit.",G09B 19/00; G06F 17/20; G10L 15/00,"AURILAB, LLC.; BAKER, James, K.","BAKER, James, K.","60/571,512 17.05.2004 US",DE-null
EP225510961,18155516,07.02.2018,3370165,05.09.2018,EP,"SENTENCE GENERATION APPARATUS, SENTENCE GENERATION METHOD, AND SENTENCE GENERATION PROGRAM","A sentence generation apparatus (100) for automatically generating one sentence from a plurality of input keywords includes a candidate sentence generator (120) incorporating a learned neural network (121) configured to take in the plurality of keywords and generate a plurality of candidate sentences each including at least some of the plurality of keywords, and an evaluation outputter (130) configured to calculate a repeat ratio for each of the plurality of candidate sentences generated by the candidate sentence generator and increase an evaluation of the candidate sentence with a small repeat ratio to thereby determine an output sentence from the plurality of candidate sentences. The repeat ratio is the number of occurrences of a repeated word with respect to the number of occurrences of all words included in the corresponding candidate sentence.",G06F 17/28; G06N 3/04,UNIV TOKYO METROPOLITAN; TOYOTA MOTOR CO LTD,KOMACHI MAMORU; KANOUCHI SHIN; OGATA TOMOYA; TAKATANI TOMOYA,2017039141 02.03.2017 JP,
EP232545775,18159837,02.03.2018,3396602,31.10.2018,EP,NEURAL NETWORK TRAINING MECHANISM,An apparatus to facilitate neural network (NN) training is disclosed. The apparatus includes training logic to receive one or more network constraints and train the NN by automatically determining a best network layout and parameters based on the network constraints.,G06N 3/063; G06F 9/30; G06F 9/38,INTEL CORP,CILINGIR GOKCEN; OULD-AHMED-VALL ELMOUSTAPHA; BARIK RAJKISHORE; NEALIS KEVIN; CHEN XIAOMING; GOTTSCHLICH JUSTIN E; SURTI PRASOONKUMAR; SAKTHIVEL CHANDRASEKARAN; APPU ABHISHEK R; WEAST JOHN C; BAGHSORKHI SARA S; DAS BARNAN; BISWAL NARAYAN; BARAN STANLEY J; SHAH NILESH; SHARMA ARCHIE; VARERKAR MAYURESH M,201715494826 24.04.2017 US,
WO2020063715,PCT/CN2019/108037,26.09.2019,WO/2020/063715,02.04.2020,WO,METHOD AND SYSTEM FOR TRAINING BINARY QUANTIZED WEIGHT AND ACTIVATION FUNCTION FOR DEEP NEURAL NETWORKS,"A method of training a neural network (NN) block for a neural network, including: performing a first quantization operation on a real-valued feature map tensor to generate a corresponding binary feature map tensor; performing a second quantization operation on a real-valued weight tensor to generate a corresponding binary weight tensor; convoluting the binary feature map tensor with the binary weight tensor to generate a convoluted output; scaling the convoluted output with a scaling factor to generate a scaled output, wherein the scaled output is equal to an estimated weight tensor convoluted with the binary feature map tensor, the estimated weight tensor corresponding to a product of the binary weight tensor and the scaling factor; calculating a loss function, the loss function including a regularization function configured to train the scaling factor so that the estimated weight tensor is guided towards the real-valued weight tensor; and updating the real-valued weight tensor and scaling factor based on the calculated loss function.",G06N 3/08,"HUAWEI TECHNOLOGIES CO., LTD.","LI, Xinlin; DARABI, Sajad; BELBAHRI, Mouloud; PARTOVI NIA, Vahid","62/736,630 26.09.2018 US; 16/582,131 25.09.2019 US",
WO2019081937,PCT/GB2018/053090,25.10.2018,WO/2019/081937,02.05.2019,WO,DETERMINING OPERATING STATE FROM COMPLEX SENSOR DATA,"A method of detecting an operating state of a process, system or machine based on sensor signals from a plurality of sensors is disclosed. The method comprises receiving sensor data, the sensor data based on sensor signals from the plurality of sensors and providing the sensor data as input to a neural network. The neural network comprises an encoder sub-network arranged to receive the sensor data as input and to generate a context vector based on the sensor data; and a decoder subnetwork arranged to receive the context vector as input and to regenerate sensor data corresponding to at least a subset of the sensors based on the context vector. The method comprises comparing the context vector to at least one context vector classification; detecting an operating state in dependence on the comparison; and outputting a notification indicating the detected operating state.",G06N 3/04; G05B 13/02; G06N 3/08,GB GAS HOLDINGS LIMITED,"WONG, Timothy",1717651.2 26.10.2017 GB,
WO2019132518,PCT/KR2018/016678,26.12.2018,WO/2019/132518,04.07.2019,WO,IMAGE ACQUISITION DEVICE AND METHOD OF CONTROLLING THE SAME,"Provided are an artificial intelligence (AI) system that mimics functions, such as recognition and determination by human brains, by utilizing a machine learning algorithm and applications of the AI system. An image acquisition device is disclosed including a camera configured to acquire a first image, at least one processor configured to: input the first image to a first AI neural network; detect, by the first AI neural network from data corresponding to a plurality of object included the first image, first data corresponding to the main object and second data corresponding to the sub-object, and generate, using a second AI neural network, a second image by restoring third data corresponding to at least a portion of the main object hidden by the sub-object, wherein the third data replaces the second data; and a display configured to display at least one of the first image and the second image.",G06T 1/00; G06T 7/11; G06T 5/00; G06T 7/20,"SAMSUNG ELECTRONICS CO., LTD.","JUNG, Jaeho; SUNG, Yeultak",10-2017-0180036 26.12.2017 KR,EP-2018894837
WO2019219799,PCT/EP2019/062587,16.05.2019,WO/2019/219799,21.11.2019,WO,DYNAMIC DISCOVERY OF DEPENDENCIES AMONG TIME SERIES DATA USING NEURAL NETWORKS,"Techniques for determining temporal dependencies and inter-time series dependencies in multi-variate time series data are provided. For example, embodiments described herein can comprise a system, which can comprise a memory that can store computer executable components. The system can also comprise a processor that can execute the computer executable components stored in the memory. The computer executable components can include: a computing component that encodes recurrent neural networks (RNNs) with time series data and determines decoded RNNs based on temporal context vectors, to determine temporal dependencies in time series data; a combining component that combines the decoded RNNs and determines an inter-time series dependence context vector and an RNN dependence decoder; and an analysis component that determines inter-time series dependencies in the time series data and forecast values for the time series data based on the inter-time series dependence context vector and the RNN dependence decoder.",G06N 3/04,INTERNATIONAL BUSINESS MACHINES CORPORATION; IBM UNITED KINGDOM LIMITED,"SHAH, Syed, Yousaf; DANG, Xuan-Hong; ZERFOS, Petros","15/982,615 17.05.2018 US",
EP13507190,00308460,27.09.2000,1089256,04.04.2001,EP,Speech recognition models adaptation from previous results feedback,"A speech recognition unit performs speech recognition on input speech based on models, such as HMMs, and supplies a speech recognition result to a dialog management unit. The dialog management unit forms a reply to the speech recognition result. In this case, the dialog management unit detects zones in which the speech recognition result is correct based on the speech recognition result and the associated reply, and feeds them back to the speech recognition unit. Then, the speech recognition unit performs on-line adaptation of the models based on the speech of the correct zones fed back from the dialog management unit and the associated speech recognition result. <IMAGE>",G10L 15/06; G06F 17/28; G10L 15/00; G10L 15/06; G10L 15/18,SONY CORP,HONDA HITOSHI; OMOTE MASANORI; OGAWA HIROAKI; PAO HONGCHANG,27774599 30.09.1999 JP,
WO2016036623,PCT/US2015/047629,31.08.2015,WO/2016/036623,10.03.2016,WO,FACET RECOMMENDATIONS FROM SENTIMENT-BEARING CONTENT,"A ""Facet Recommender"" creates conversational recommendations for facets of particular conversational topics, and optionally for things associated with those facets, from consumer reviews or other social media content. The Facet Recommender applies a machine-learned facet model and optional sentiment-model, to identify facets associated with spans or segments of the content and to determine neutral, positive, or negative consumer sentiment associated with those facets and, optionally, things associated with those facets. These facets are selected by the facet model from a list or set of manually defined or machine-learned facets for particular conversational topic types. The Facet Recommender then generates new conversational utterances (i.e., short neutral, positive or negative suggestions) about particular facets based on the sentiments associated with those facets. In various implementations, utterances are fit to one or more predefined conversational frameworks. Further, responses or suggestions provided as utterances may be personalized to individual users.",G06F 17/27; G06F 17/28; G06Q 30/00; G06F 3/048; H04M 1/72; G06F 17/30,"MICROSOFT TECHNOLOGY LICENSING, LLC","DOLAN, Bill; MITCHELL, Margaret; BANERJEE, Jay; CHOUDHURY, Pallavi; HENDRICH, Susan; MASON, Rebecca; OWENS, Ron; REDDY, Mouni; SONG, Yaxiao; TOUTANOVA, Kristina; XU, Liang; YIN, Xuetao","14/475,450 02.09.2014 US",EP-2015760050; CN-201580047303.1
WO2019207421,PCT/IB2019/053173,17.04.2019,WO/2019/207421,31.10.2019,WO,NAVIGATION AND COGNITIVE DIALOG ASSISTANCE,"A system, computer program product, and method are provided to apply artificial intelligence and natural language processing to a route navigation module. An artificial intelligence platform transforms the functionality of the navigation module in real-time. As natural language input is received, a parser is leveraged to parse the input into grammatical sub-components. An analyzer is involved to analyze and identify an associated category for the parsed sub-component(s). A sensor is provided operatively couple to the navigation module. The parsed and analyzed data are applied to an operating state of the sensor. The artificial intelligence platform dynamically translates the identified category of the received input to a natural language instruction congruent with the parsed grammatical sub-components.",G06F 17/28,INTERNATIONAL BUSINESS MACHINES CORPORATION; IBM UNITED KINGDOM LIMITED; IBM (CHINA) INVESTMENT COMPANY LIMITED,"KOCHURA, Nadiya; LU, Fang","15/959,625 23.04.2018 US",
WO2019097749,PCT/JP2018/020251,21.05.2018,WO/2019/097749,23.05.2019,WO,COMPUTER-BASED SYSTEM AND COMPUTER-BASED METHOD,"A computer-based system trains a neural network by solving a double layer optimization problem. The system includes an input interface to receive an input to the neural network and labels of the input to the neural network; a processor to solve a double layer optimization to produce parameters of the neural network, and an output interface to output the parameters of the neural network. The double layer optimization includes an optimization of a first layer subject to an optimization of a second layer. The optimization of the first layer minimizes a difference between an output of the neural network processing the input and the labels of the input to the neural network, the optimization of the second layer minimizes a distance between a non-negative output vector of each layer and a corresponding input vector to each layer. The input vector of a current layer is a linear transformation of the non-negative output vector of the previous layer.",G06N 3/04; G06N 3/08,MITSUBISHI ELECTRIC CORPORATION,"ZHANG, Ziming; BRAND, Matthew","15/814,568 16.11.2017 US",
WO2020040517,PCT/KR2019/010547,20.08.2019,WO/2020/040517,27.02.2020,WO,ELECTRONIC APPARATUS AND CONTROL METHOD THEREOF,"A method of controlling an electronic apparatus is provided. The method includes obtaining a name referring to a user of another electronic apparatus in a chat with the user of the other electronic apparatus using an artificial intelligence (AI) model trained by an AI algorithm while conducting the chat with the user of the other electronic apparatus using the electronic apparatus; and storing the obtained name in association with contact information of the user of the other electronic apparatus. At least some of the control method of the disclosure may use an AI model trained according to at least one of machine learning, neural network, or deep learning algorithm.",G06F 17/27; G06F 3/048; G06F 3/16; G06N 3/08; H04M 1/725; G10L 15/22,"SAMSUNG ELECTRONICS CO., LTD.","KIM, Soofeel; CHOI, Wonjong; HAM, Jina",10-2018-0096867 20.08.2018 KR; 10-2019-0096871 08.08.2019 KR,
WO2016195912,PCT/US2016/031082,06.05.2016,WO/2016/195912,08.12.2016,WO,CONTEXT-SENSITIVE GENERATION OF CONVERSATIONAL RESPONSES,"Examples are generally directed towards context-sensitive generation of conversational responses. Context-message-response n-tuples are extracted from at least one source of conversational data to generate a set of training context-message-response n-tuples. A response generation engine is trained on the set of training context-message-response n-tuples. The trained response generation engine automatically generates a context-sensitive response based on a user generated input message and conversational context data. A digital assistant utilizes the trained response generation engine to generate context-sensitive, natural language responses that are pertinent to user queries.",G06F 17/28,"MICROSOFT TECHNOLOGY LICENSING, LLC","GALLEY, Michel; SORDONI, Alessandro; BROCKETT, Christopher John; GAO, Jianfeng; DOLAN, William Brennan; JI, Yangfeng; AULI, Michael; MITCHELL, Margaret Ann; NIE, Jian-Yun","14/726,562 31.05.2015 US",EP-2016723226
WO2018226247,PCT/US2017/037025,12.06.2017,WO/2018/226247,13.12.2018,WO,MODIFICATION OF AUDIO-BASED COMPUTER PROGRAM OUTPUT,Modifying computer program output in a voice or non-text input activated environment is provided. A system can receive audio signals detected by a microphone of a device. The system can parse the audio signal to identify a computer program to invoke. The computer program can identify a dialog data structure. The system can modify the identified dialog data structure to include a content item. The system can provide the modified dialog data structure to a computing device for presentation.,G10L 15/22,GOOGLE LLC,"EIDEM, Laura; JACOBSON, Alex","15/618,842 09.06.2017 US; 15/618,854 09.06.2017 US; 15/618,871 09.06.2017 US; 15/618,873 09.06.2017 US",CN-201780001058.X; CN-CN201780001058x; EP-2017732673; KR-1020197025033
WO2019172946,PCT/US2018/027774,16.04.2018,WO/2019/172946,12.09.2019,WO,FACILITATING END-TO-END COMMUNICATIONS WITH AUTOMATED ASSISTANTS IN MULTIPLE LANGUAGES,"Techniques described herein relate to facilitating end-to-end multilingual communications with automated assistants. In various implementations, speech recognition output may be generated based on voice input in a first language. A first language intent may be identified based on the speech recognition output and fulfilled in order to generate a first natural language output candidate in the first language. At least part of the speech recognition output may be translated to a second language to generate an at least partial translation, which may then be used to identify a second language intent that is fulfilled to generate a second natural language output candidate in the second language. Scores may be determined for the first and second natural language output candidates, and based on the scores, a natural language output may be selected for presentation.",G10L 15/32; G10L 15/28; G10L 15/18,GOOGLE LLC,"KUCZMARSKI, James; JAIN, Vibhor; SUBRAMANYA, Amarnag; RANJAN, Nimesh; JOHNSON PREMKUMAR, Melvin Jose; VUSKOVIC, Vladimir; DAI, Luna; IKEDA, Daisuke; BALANI, Nihal Sandeep; LEI, Jinna; NIU, Mengmeng","62/639,740 07.03.2018 US",EP-2018722831; KR-KR1020187028532; JP-2018548678; CN-201880001823.2
WO2008109665,PCT/US2008/055900,05.03.2008,WO/2008/109665,12.09.2008,WO,FAST SEMANTIC EXTRACTION USING A NEURAL NETWORK ARCHITECTURE,"A system and method for semantic extraction using a neural network architecture includes indexing (102) each word in an input sentence into a dictionary and using these indices to map each word to a d-dimensional vector (the features of which are learned). Together with this, position information for a word of interest {the word to labeled) and a verb of interest (the verb that the semantic role is being predicted for) with respect to a given word are also used. These positions are integrated (106) by employing a linear layer that is adapted to the input sentence. Several linear transformations (108) and squashing functions (110) are then applied to output class probabilities for semantic role labels. All the weights for the whole architecture are trained by backpropagation.",G06F 17/21,"NEC LABORATORIES AMERICA. INC.; COLLOBERT, Ronan","COLLOBERT, Ronan; WESTON, Jason","60/893,712 08.03.2007 US",
WO2007076529,PCT/US2006/062689,28.12.2006,WO/2007/076529,05.07.2007,WO,A SYSTEM AND METHOD FOR ACCESSING IMAGES WITH A NOVEL USER INTERFACE AND NATURAL LANGUAGE PROCESSING,"Systems and methods for accessing images with natural language processing are provided. The methods for accessing images include linking an image with image-summarizing text by applying a hierarchical clustering algorithm to cluster one or more abstract sentences and one or more images, and linking an image with image-summarizing text if the abstract sentence belongs to a cluster that includes the image. The systems for accessing images include a natural language processor that applies a hierarchical clustering algorithm to link one or more abstract sentences in an article with one or more images in the article, and a user interface in which selecting image- summarizing text displays one or more linked images.",G06F 17/30,"THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK; YU, Hong","YU, Hong","60/754,380 28.12.2005 US; 60/779,837 07.03.2006 US",US-12139267; DE-null
WO2019118363,PCT/US2018/064777,10.12.2018,WO/2019/118363,20.06.2019,WO,ON-CHIP COMPUTATIONAL NETWORK,"Provided are systems, methods, and integrated circuits for neural network processing. In various implementations, an integrated circuit for neural network processing can include a plurality of memory banks storing weight values for a neural network. The memory banks can be on the same chip as an array of processing engines. Upon receiving input data, the circuit can be configured to use the set of weight values to perform a task defined for the neural network. Performing the task can include reading weight values from the memory banks, inputting the weight values into the array of processing engines, and computing a result using the array of processing engines, where the result corresponds to an outcome of performing the task.",G06N 3/02; G06N 3/063,"AMAZON TECHNOLOGIES, INC.","HUANG, Randy; DIAMANT, Ron; ZEJDA, Jindrich; BORKOVIC, Drazen","15/839,017 12.12.2017 US; 15/839,301 12.12.2017 US; 15/839,157 12.12.2017 US",
WO2019022472,PCT/KR2018/008355,24.07.2018,WO/2019/022472,31.01.2019,WO,ELECTRONIC DEVICE AND METHOD FOR CONTROLLING THE ELECTRONIC DEVICE,"A method for controlling an electronic device including at least one processor configured to encrypt an image and upload the encrypted image to an external server by using an artificial intelligence neural network model is provided. The method includes receiving a command to upload an image to the external server; acquiring, based on the command, a characteristic value corresponding to the image by inputting the image and a key of the electronic device into a neural network model trained to identify characteristic values based on an input image and an input key; and transmitting identification information of the image and the characteristic value to the external server.",G06F 21/60; G06F 21/62; G06F 21/46; G06T 7/00; G06T 9/00; H04N 21/2347; H04N 21/4405; G06N 3/08,"SAMSUNG ELECTRONICS CO., LTD.","KANG, Seong-min; HAN, Heung-woo","62/536,042 24.07.2017 US; 10-2017-0142106 30.10.2017 KR",EP-2018838530
WO2020064990,PCT/EP2019/076148,27.09.2019,WO/2020/064990,02.04.2020,WO,COMMITTED INFORMATION RATE VARIATIONAL AUTOENCODERS,"A variational autoencoder (VAE) neural network system, comprising an encoder neural network to encode an input data item to define a posterior distribution for a set of latent variables, and a decoder neural network to generate an output data item representing values of a set of latent variables sampled from the posterior distribution. The system is configured for training with an objective function including a term dependent on a difference between the posterior distribution and a prior distribution. The prior and posterior distributions are arranged so that they cannot be matched to one another. The VAE system may be used for compressing and decompressing data.",G06N 3/04; G06N 3/00; G06N 3/08,DEEPMIND TECHNOLOGIES LIMITED,"POOLE, Benjamin; VAN DEN OORD, Aäron Gerard Antonius; RAZAVI-NEMATOLLAHI, Ali; VINYALS, Oriol","62/737,845 27.09.2018 US",
WO2014197463,PCT/US2014/040676,03.06.2014,WO/2014/197463,11.12.2014,WO,SYSTEMS AND METHODS FOR MULTI-USER MULTI-LINGUAL COMMUNICATIONS,"Various embodiments described herein facilitate multi-lingual communications. The systems and methods of some embodiments enable multi-lingual communications through different modes of communication including, for example, Internet-based chat, e-mail, text- based mobile phone communications, postings to online forums, postings to online social media services, and the like. Certain embodiments implement communication systems and methods that translate text between two or more languages. Users of the systems and methods may be incentivized to submit corrections for inaccurate or erroneous translations, and may receive a reward for these submissions. Systems and methods for assessing the accuracy of translations are described.",G06F 17/28,"MACHINE ZONE, INC.","LEYDON, Gabriel; ORSINI, Francois; BOJJA, Nikhil; NEDUNCHEZHIAN, Arun; PUZON, Bartlomiej","13/908,979 03.06.2013 US",RU-2015156890; KR-1020167000062; CA-2913984; KR-1020177014779; AU-2014275087; EP-2014735028; CN-201480041034.3
WO2019226324,PCT/US2019/030988,07.05.2019,WO/2019/226324,28.11.2019,WO,HIGHLY PERFORMANT PIPELINE PARALLEL DEEP NEURAL NETWORK TRAINING,"Layers of a deep neural network (DNN) are partitioned into stages using a profile of the DNN. Each of the stages includes one or more of the layers of the DNN. The partitioning of the layers of the DNN into stages is optimized in various ways including optimizing the partitioning to minimize training time, to minimize data communication between worker computing devices used to train the DNN, or to ensure that the worker computing devices perform an approximately equal amount of the processing for training the DNN. The stages are assigned to the worker computing devices. The worker computing devices process batches of training data using a scheduling policy that causes the workers to alternate between forward processing of the batches of the DNN training data and backward processing of the batches of the DNN training data. The stages can be configured for model parallel processing or data parallel processing.",G06N 3/063; G06N 3/08,"MICROSOFT TECHNOLOGY LICENSING, LLC","SESHADRI, Vivek; PHANISHAYEE, Amar; NARAYANAN, Deepak; HARLAP, Aaron; RANGARAJAN, Nikhil Devanur","62/675,497 23.05.2018 US; 16/024,369 29.06.2018 US",
WO2014140977,PCT/IB2014/059310,27.02.2014,WO/2014/140977,18.09.2014,WO,IMPROVING ENTITY RECOGNITION IN NATURAL LANGUAGE PROCESSING SYSTEMS,"Mechanisms are provided for generating a dictionary data structure for analytical operations. A source terminology resource is ingested to generate a hierarchical representation of the source terminology resource comprising nodes for terms related to concepts in the source terminology resource. For a node of the nodes in the hierarchical representation of the source terminology resource, a permutation of a corresponding term associated with the node is generated. An expanded hierarchical representation of the source terminology resource is generated based on the generated permutation. An enhanced dictionary data structure is generated based on the expanded hierarchical representation and output to an analytics engine to perform analysis of a corpus of information using the enhanced dictionary data structure.",G06F 17/28,INTERNATIONAL BUSINESS MACHINES CORPORATION; IBM UNITED KINGDOM LIMITED; IBM (CHINA) INVESTMENT COMPANY LIMITED,"GERKEN III, John, Kenyon; ZBOICHYK, Fiodar; PRAGER, John, Martin","13/843,377 15.03.2013 US",
WO2018194940,PCT/US2018/027680,13.04.2018,WO/2018/194940,25.10.2018,WO,POWER-EFFICIENT DEEP NEURAL NETWORK MODULE CONFIGURED FOR PARALLEL KERNEL AND PARALLEL INPUT PROCESSING,"A deep neural network (DNN) module utilizes parallel kernel and input processing to decrease bandwidth utilization, reduce power consumption, improve neuron multiplier stability, and provide other technical benefits. Parallel kernel processing enables the DNN module to load input data once for processing by multiple kernels. Parallel input processing enables the DNN module to load kernel data once for processing with multiple input data. The DNN module can implement other power-saving techniques like clock-gating and power-gating banks of accumulators based upon usage of the accumulators. For example, individual banks of accumulators can be power-gated when all accumulators in a bank are not in use, and do not store data for a future calculation. Banks of accumulators can also be clock-gated when all accumulators in a bank are not in use, but store data for a future calculation.",G06N 3/063,"MICROSOFT TECHNOLOGY LICENSING, LLC","AMBARDEKAR, Amol Ashok; MCBRIDE, Chad Balling; PETRE, George; WALL, Larry Marvin; CEDOLA, Kent D.; BOBROV, Boris","62/486,432 17.04.2017 US; 15/951,690 12.04.2018 US",
EP14036983,02708744,01.04.2002,1376536,02.01.2004,EP,SOUND PROCESSING APPARATUS,"The present invention relates to a voice recognition apparatus capable of easily registering a word which has not been registered. The registering of an unregistered word into a dictionary can be easily performed without causing a significant increase in the size of the dictionary. The clustering unit 29 detects a cluster (detected cluster) to which a new unregistered word is to be added as a new member, from existing clusters obtained by clustering unregistered words. The unregistered word is added as a new member to the detected cluster, and the cluster is divided depending on the members of the cluster such that unregistered words which are acoustically similar to each other belong to the same cluster. The maintenance unit 31 updates the word dictionary on the basis of the result of the clustering. The present invention may be applied to a robot including a voice recognition apparatus. <IMAGE>",G06F 3/16; G10L 15/00; G06F 3/16; G06F 17/28; G10L 15/00; G10L 15/06; G10L 15/06; G10L 15/14; G10L 15/14; G10L 15/20; G10L 15/20; G10L 15/22; G10L 15/24,SONY CORP,OMOTE MASANORI; LUCKE HELMUT,0203248 01.04.2002 JP; 2001097843 30.03.2001 JP; 2002069603 14.03.2002 JP,
WO2018217863,PCT/US2018/034088,23.05.2018,WO/2018/217863,29.11.2018,WO,METHODS AND APPARATUS FOR ENHANCING A BINARY WEIGHT NEURAL NETWORK USING A DEPENDENCY TREE,"Methods and apparatus are disclosed for enhancing a binary weight neural network using a dependency tree. A method of enhancing a convolutional neural network (CNN) having binary weights includes constructing a tree for obtained binary tensors, the tree having a plurality of nodes beginning with a root node in each layer of the CNN. A convolution is calculated of an input feature map with an input binary tensor at the root node of the tree. A next node is searched from the root node of the tree and a convolution is calculated at the next node using a previous convolution result calculated at the root node of the tree. The searching of a next node from root node is repeated for all nodes from the root node of the tree, and a convolution is calculated at each next node using a previous convolution result.",G06N 3/04; G06N 3/08,INTEL CORPORATION,"GUO, Yiwen; YAO, Anbang; ZHAO, Hao; LU, Ming; CHEN, Yurong","62/510,075 23.05.2017 US",EP-2018806815; CN-201880026996.X
EP13543943,99945549,08.09.1999,1110206,27.06.2001,EP,NETWORK INTERACTIVE USER INTERFACE USING SPEECH RECOGNITION AND NATURAL LANGUAGE PROCESSING,"A system and method for interacting with networked objects, via a computer using utterances, speech processing and natural language processing. A Data Definition File relates networked objects and a speech processor. The Data Definition File encompasses a memory structure relating the networked objects, including grammar files and a natural language processor. The speech processor searches a first grammar file for a matching phrase for the utterance, and for searching a second grammar file for the matching phrase if the matching phrase is not found in the first grammar file. The system also includes a natural language processor for searching a data base for a matching entry for the matching phrase; and an application interface for performing an action associated with the matching entry if the matching entry is found in the database. The system utilizes context-specific grammars, thereby enhancing speech recognition and natural language processing efficiency. Additionally, the system adaptively and interactively 'learns' words and phrases, and their associated meanings.",G06F 17/30; G06F 3/16; G06F 13/00; G06F 17/27; G06F 17/28; G10L 15/00; G10L 15/06; G10L 15/18; G10L 15/19; G10L 15/22; G10L 15/26; G10L 15/28; H04L 29/06,ONE VOICE TECHNOLOGIES INC,WEBER DEAN C,15045998 09.09.1998 US; 16619898 05.10.1998 US; 9920447 08.09.1999 US,
WO2018081020,PCT/US2017/057936,23.10.2017,WO/2018/081020,03.05.2018,WO,COMPUTERIZED DOMAIN EXPERT,"A computer system that permits flexible, natural conversational type interactions is disclosed. A natural language processing module receives natural conversational type interactions from a user and generates structured data from unstructured inputs regarding user queries within a domain. A data stack comprises a database with configurable comparison and evaluation logic for importing, transforming, normalizing, and exporting data pertaining to the domain. A dialogue authoring module includes control logic for permitting creation of complex dialogues. The dialogues are generated from recipes that characterize aspects of a product within the domain. Each recipe takes the form of a model with one or more nodes with each node assigning a numeric utility value to an atomic constituent part of an element of the domain. Each recipe also accumulates the numeric utility values to a top-level score. A core module receives the structured data created by the natural language processing module and causes output to the user in the form of natural language type responses by way of one or more templates.",G06F 17/00; G06F 17/28; G06F 17/30,CARLABS INC.,"HAVENS, Samuel, Akiba; SCHMITT, Martin; KARAVANI, Barack, Brian","62/412,169 24.10.2016 US",
EP232545763,18163805,23.03.2018,3396591,31.10.2018,EP,"RECOGNITION, REIDENTIFICATION AND SECURITY ENHANCEMENTS USING AUTONOMOUS MACHINES","A mechanism is described for facilitating recognition, reidentification, and security in machine learning at autonomous machines. A method of embodiments, as described herein, includes facilitating a camera to detect one or more objects within a physical vicinity, the one or more objects including a person, and the physical vicinity including a house, where detecting includes capturing one or more images of one or more portions of a body of the person. The method may further include extracting body features based on the one or more portions of the body, comparing the extracted body features with feature vectors stored at a database, and building a classification model based on the extracted body features over a period of time to facilitate recognition or reidentification of the person independent of facial recognition of the person.",G06K 9/00,INTEL CORP,DAS BARNAN; VARERKAR MAYURESH M; BISWAL NARAYAN; BARAN STANLEY J; CILINGIR GOKCEN; SHAH NILESH V; SHARMA ARCHIE; ABDELHAK SHERINE; KOTHA PRANEETHA; PANDIT NEELAY; WEAST JOHN C; MACPHERSON MIKE B; KIM DUKHWAN; HURD LINDA L; APPU ABHISHEK R; KOKER ALTUG; RAY JOYDEEP,201715495327 24.04.2017 US,
WO2015054240,PCT/US2014/059480,07.10.2014,WO/2015/054240,16.04.2015,WO,"COMPUTER IMPLEMENTED METHOD, COMPUTER SYSTEM AND SOFTWARE FOR REDUCING ERRORS ASSOCIATED WITH A SITUATED INTERACTION","A computer implemented method and computer system for reducing errors associated with a situated interaction performed by at least two agents of a sociotechnical team and for augmenting situation awareness of the at least two agents. Also, a non-transitory computer- readable storage medium used to store instructions relating to the computer method and the computer system. The situated interaction can be surgery and the at least two agents can be members of a surgical team.",G06F 17/28,"PRESIDENT AND FELLOWS OF HARVARD COLLEGE; VETERANS AFFAIRS, THE UNITED STATES GOVERNMENT AS REPRESENTED BY THE DEPARTMENT OF","ZENATI, Marco; MARON, Jason","61/887,559 07.10.2013 US",EP-2014852109
WO2019087033,PCT/IB2018/058438,29.10.2018,WO/2019/087033,09.05.2019,WO,PROTECTING COGNITIVE SYSTEMS FROM GRADIENT BASED ATTACKS THROUGH THE USE OF DECEIVING GRADIENTS,"Mechanisms are provided for providing a hardened neural network. The mechanisms configure the hardened neural network executing in the data processing system to introduce noise in internal feature representations of the hardened neural network. The noise introduced in the internal feature representations diverts gradient computations associated with a loss surface of the hardened neural network. The mechanisms configure the hardened neural network executing in the data processing system to implement a merge layer of nodes that combine outputs of adversarially trained output nodes of the hardened neural network with output nodes of the hardened neural network trained based on the introduced noise. The mechanisms process, by the hardened neural network, input data to generate classification labels for the input data and thereby generate augmented input data which is output to a computing system for processing to perform a computing operation.",G06N 3/04,INTERNATIONAL BUSINESS MACHINES CORPORATION; IBM UNITED KINGDOM LIMITED; IBM (CHINA) INVESTMENT COMPANY LIMITED,"LEE, Taesung; MOLLOY, Ian, Michael; TEJANI, Farhan","15/800,697 01.11.2017 US",
WO2016196005,PCT/US2016/032942,18.05.2016,WO/2016/196005,08.12.2016,WO,"FAST LOW-MEMORY METHODS FOR BAYESIAN INFERENCE, GIBBS SAMPLING AND DEEP LEARNING","Methods of training Boltzmann machines include rejection sampling to approximate a Gibbs distribution associated with layers of the Boltzmann machine. Accepted sample values obtained using a set of training vectors and a set of model values associate with a model distribution are processed to obtain gradients of an objective function so that the Boltzmann machine specification can be updated. In other examples, a Gibbs distribution is estimated or a quantum circuit is specified so at to produce eigenphases of a unitary.",G06N 3/04; G06N 7/00; G06F 17/10; G06N 99/00,"MICROSOFT TECHNOLOGY LICENSING, LLC","WIEBE, Nathan; KAPOOR, Ashish; SVORE, Krysta; GRANADE, Christopher","62/171,195 04.06.2015 US",EP-2016728149; US-15579190
EP11612430,85113695,28.10.1985,0180888,14.05.1986,EP,Method and apparatus for natural language processing.,,G06F 17/27; G06F 17/28; G06Q 10/04,HITACHI LTD,KATAYAMA YASUNORI; NAKANISHI KUNIO; YOSHIURA HIROSHI; HIRASAWA KOTARO,22725184 29.10.1984 JP,
WO2019167600,PCT/JP2019/004805,12.02.2019,WO/2019/167600,06.09.2019,WO,"PSEUDO-BILINGUAL DATA GENERATION DEVICE, MACHINE TRANSLATION PROCESSING DEVICE, AND PSEUDO-BILINGUAL DATA GENERATION METHOD","The present invention achieves: a model training method for neural machine translation, wherein the overall accuracy of a translation device is improved by strengthening an encoder using a monolingual corpus of a target language; and a machine translation system for executing said model training method. With this machine translation system (1000), it is possible to acquire large quantities of diverse pseudo-bilingual corpus data by acquiring a multiple sets of pseudo-original language data from a single set of target language data, by using a monolingual corpus of the target language. Further, the machine translation system (1000) executes learning processing (training processing) of a machine translation model by varying a learning rate using both the acquired large quantities of diverse pseudo-bilingual corpus data and base bilingual corpus data that, yet in small quantities, is of highly accurate nature. By this configuration, the machine translation system (1000) is able to acquire a highly-accurate learned model (machine translation model).",G06F 17/28,NATIONAL INSTITUTE OF INFORMATION AND COMMUNICATIONS TECHNOLOGY; 国立研究開発法人情報通信研究機構,IMAMURA Kenji; 今村　賢治; FUJITA Atsushi; 藤田　篤; SUMITA Eiichiro; 隅田　英一郎,2018-037055 02.03.2018 JP,
WO2017136674,PCT/US2017/016431,03.02.2017,WO/2017/136674,10.08.2017,WO,GENERATING FEATURE EMBEDDINGS FROM A CO-OCCURRENCE MATRIX,"Methods, and systems, including computer programs encoded on computer storage media for generating compressed representations from a co-occurrence matrix. A method includes obtaining a set of sub matrices of a co-occurrence matrix, where each row of the co-occurrence matrix corresponds to a feature from a first feature vocabulary and each column of the co-occurrence matrix corresponds to a feature from a second feature vocabulary; selecting a sub matrix, wherein the sub matrix is associated with a particular row block and column block of the co-occurrence matrix; assigning respective d-dimensional initial row and column embedding vectors to each row and column from the particular row and column blocks, respectively; and determining a final row embedding vector and a final column embedding vector by iteratively adjusting the initial row embedding vectors and the initial column embedding vectors using the co-occurrence matrix.",G06F 17/16; G06F 17/28,GOOGLE LLC,"SHAZEER, Noam M.; EVANS, Colin Hearne; WATERSON, Christopher Robert; DOHERTY, Ryan P.","62/291,956 05.02.2016 US",EP-2017710076
WO2019004481,PCT/JP2018/024981,25.06.2018,WO/2019/004481,03.01.2019,WO,"INFORMATION PROCESSING DEVICE, MANIPULATOR CONTROL SYSTEM, AND NATURAL LANGUAGE PROCESSING SYSTEM","[Problem] To execute a highly versatile, neural network-based information process. [Solution] NN module groups 22, 23, 24, each being an assemblage of pluralities of NN modules 21 of the same function level and comprising neural networks, are constructed hierarchically. An NN module 21 in a high-order layer controls the process working of at least one of any NN module 21 in a layer of a low order. A process module 21 of the lowest-order layer 24 also outputs information to an output device group 3 based on input information from an input device group 2, and learns correlations between the input information and output information according to process content of the NN module 21.",G06N 3/04; B25J 13/08; G06F 17/28,"ISHII, Masayoshi; 石井　正好","ISHII, Masayoshi; 石井　正好",2017-125681 27.06.2017 JP; 2018-044420 12.03.2018 JP,JP-2019527098
EP12143504,90311167,11.10.1990,0424032,24.04.1991,EP,Naturel language processing apparatus,"A natural language processing apparatus (Fig. 3; 100) for performing processing to analyze the meaning of an input sentence entered in the form of a natural language includes a plurality of meaning analyzing devices (41) networked in order to perform processing to analyze the meaning of the input sentence (10), the meaning analyzing devices performing meaning analyzing operations that differ from one another and outputting the results of analysis on a network, a communicating device (50) for applying the input sentence, which is a subject of analysis, to each of the plurality of meaning analyzing devices, a decision device (Fig. 1; 50, Fig. 8) for determining whether independent meaning analysis performed by the plurality of meaning analyzing devices is required with regard to the input sentence, and a consolidating device (Fig. 1; 50, Fig. 8) for consolidating the analytical results from each of the plurality of meaning analyzing devices and applying the consolidated results to the communicating device as the subject of analysis which the communicating device applies to each of the meaning analyzing devices.",G06F 17/27; G06F 17/28,CANON KK,IKEDA YUJI; FUJITA MINORU,26751589 14.10.1989 JP,
EP206658662,16171927,30.05.2016,3252618,06.12.2017,EP,DATABASE INTEGRATION SYSTEM,"The invention provides for a method of using a database assembly (100). The database assembly comprises at least three computing systems (102, 104, 106). Each of the at least three computing systems comprises at least one application (116) and a local database system (118).The database assembly further comprise a database integration system (108) and a network connection (110) between each of the at least three computing systems and the database integration system. The method comprises: receiving (200) a first root transaction (130) by the local database of a first computing system (102); executing (202) the first root transaction on the local database of the first computing system; generating (204) a first link transaction (132) by the local database of the first computing system; sending (206) the first link transaction from the first computing system to the database integration system via the network connection of the first computing system; generating (208) a first routed transaction (134, 136) for at least one of the first remaining computing systems (104, 106) by the data base integration system; sending (210) the first routed transaction to the at least one of the remaining computing systems via the network connection; and executing (212) the first routed transaction on the local database of the at least one of the remaining computer system.",G06F 17/30,SAP SE,SUNDARAM P MEENAKSHI,16171927 30.05.2016 EP,
WO2016195931,PCT/US2016/031696,11.05.2016,WO/2016/195931,08.12.2016,WO,AUTOMATED EFFICIENT TRANSLATION CONTEXT DELIVERY,"Embodiments relate to automatically providing textual context for source strings in a source language that are to be translated by a human translator to target strings in a target language. The source strings are compared against a dictionary of reference strings in the source language. For each source string, one or more of the reference strings that are most relevant, similar, etc., are selected. When a human translator is to translate the source strings, the selected reference strings are presented; each source string has one or more similar/related strings displayable in association therewith. For a given source string, the human translator can use the associated reference strings as a form of context to help estimate the intended meaning of the given source string when translating the given source string to a target string in the target language.",G06F 17/28; G06F 9/44,"MICROSOFT TECHNOLOGY LICENSING, LLC","JOO, Dong Kwon","14/725,867 29.05.2015 US",
WO2018194993,PCT/US2018/027834,16.04.2018,WO/2018/194993,25.10.2018,WO,POWER-EFFICIENT DEEP NEURAL NETWORK MODULE CONFIGURED FOR EXECUTING A LAYER DESCRIPTOR LIST,"A deep neural network (DNN) processor is configured to execute descriptors in layer descriptor lists. The descriptors define instructions for performing a pass of a DNN by the DNN processor. Several types of descriptors can be utilized: memory-to-memory move (M2M) descriptors; operation descriptors; host communication descriptors; configuration descriptors; branch descriptors; and synchronization descriptors. A DMA engine uses M2M descriptors to perform multi-dimensional strided DMA operations. Operation descriptors define the type of operation to be performed by neurons in the DNN processor and the activation function to be used by the neurons. M2M descriptors are buffered separately from operation descriptors and can be executed at soon as possible, subject to explicitly set dependencies. As a result, latency can be reduced and, consequently, neurons can complete their processing faster. The DNN module can then be powered down earlier than it otherwise would have, thereby saving power.",G06N 3/063,"MICROSOFT TECHNOLOGY LICENSING, LLC","AMBARDEKAR, Amol Ashok; CEDOLA, Kent D.; WALL, Larry Marvin; BOBROV, Boris; PETRE, George; MCBRIDE, Chad Balling","62/486,432 17.04.2017 US; 15/951,106 11.04.2018 US",CN-201880025508.3; EP-2018721665
WO2015106353,PCT/CA2015/050024,15.01.2015,WO/2015/106353,23.07.2015,WO,ITEM CLASSIFICATION METHOD AND SELECTION SYSTEM FOR ELECTRONIC SOLICITATION,"The present application discloses a system to efficiently index advertisement content using artificial intelligence to infer and generate meaningful thematic category groupings for said content. Said groupings are further matched to collected customer profile data and combined to deploy custom media solicitations via 5 predictive analytics, thereby addressing the problem posed by ineffective mass solicitations which often inadequately target – and therefore miss – their intended audience.",G06Q 30/02; G06F 17/27; G06F 17/30,INTEMA SOLUTIONS INC.,"PLOURDE, Sébastien","61/927,723 15.01.2014 US",CA-2973706; US-15110307
WO2019241145,PCT/US2019/036368,10.06.2019,WO/2019/241145,19.12.2019,WO,ARTIFICIAL INTELLIGENCE APPLICATIONS FOR COMPUTER-AIDED DISPATCH SYSTEMS,"Exemplary embodiments of the present invention provide a virtual dispatch assist system in which various types of Intelligent Agents are deployed (e.g., as part of a new CAD system architecture or as add-ons to existing CAD systems) to analyze vast amounts of historic operational data and provide various types of dispatch assist notifications and recommendations that can be used by a dispatcher or by the CAD system itself (e.g., autonomously) to make dispatch decisions.",G06N 5/04; G06N 3/00; G06N 3/08; G06N 7/00,INTERGRAPH CORPORATION,"WILLIAMS, Jackie, Paul; COLE, Michael, Thomas; DEBONI, Jose Eduardo, Zindel","62/683,754 12.06.2018 US",
WO2020036297,PCT/KR2019/006880,07.06.2019,WO/2020/036297,20.02.2020,WO,ELECTRONIC APPARATUS AND CONTROLLING METHOD THEREOF,"An electronic apparatus includes a storage configured to store a liquid-state machine (LSM) model and a recurrent neural networks (RNN) model, and a processor configured to input and process a feature data acquired from an input data using the LSM model, to input and process an output value output by the LSM model using the RNN model, and to identify whether a preset object is included in the input data based on an output value output by the RNN model. The RNN model is trained by a sample data related to the preset object. The LSM model includes a plurality of interlinked neurons. A weight applied to a link between the plurality of interlinked neurons is identified based on a spike at which a neuron value is greater than or equal to a preset threshold in a preset unit time.",G06N 3/08; G06N 3/04,"SAMSUNG ELECTRONICS CO., LTD.","USHAKOV, Yury",10-2018-0096368 17.08.2018 KR,
WO2018146514,PCT/IB2017/050658,07.02.2017,WO/2018/146514,16.08.2018,WO,GENERALIZED OPERATIONAL PERCEPTRONS: NEWGENERATION ARTIFICIAL NEURAL NETWORKS,"Certain embodiments may generally relate to various techniques for machine learning. Feed-forward, fully-connected Artificial Neural Networks (ANNs), or the so-called Multi- Layer Perceptrons (MLPs) are well-known universal approximators. However, their learning performance may vary significantly depending on the function or the solution space that they attempt to approximate for learning. This is because they are based on a loose and crude model of the biological neurons promising only a linear transformation followed by a nonlinear activation function. Therefore, while they learn very well those problems with a monotonous, relatively simple and linearly separable solution space, they may entirely fail to do so when the solution space is highly nonlinear and complex. In order to address this drawback and also to accomplish a more generalized model of biological neurons and learning systems, Generalized Operational Perceptrons (GOPs) may be formed and they may encapsulate many linear and nonlinear operators.",G06F 17/28; G06N 3/08; H04B 1/40; H04B 15/00,QATAR UNIVERSITY,"KIRANYAZ, Serkan; INCE, Turker; GABBOUJ, Moncef; IOSIFIDIS, Alexandros",,CN-201780085807.1
WO2018089762,PCT/US2017/061053,10.11.2017,WO/2018/089762,17.05.2018,WO,ONLINE PERSONAL ASSISTANT WITH IMAGE TEXT LOCALIZATION,"Systems, methods, and computer program products for identifying a candidate product in an electronic marketplace based on a visual comparison between candidate product image visual text content and input query image visual text content. Unlike conventional optical character recognition (OCR) based systems, embodiments automatically localize and isolate portions of a candidate product image and an input query image that each contain visual text content, and calculate a visual similarity measure between the respective portions. A trained neural network may be re-trained to more effectively find visual text content by using the localized and isolated visual text content portions as additional ground truths. The visual similarity measure serves as a visual search result score for the candidate product. Any number of images of any number of candidate products may be compared to an input query image to enable text-in-image based product searching without resorting to conventional OCR techniques.",G06K 9/46; G06T 7/00; G06K 9/62; G06F 17/30; G06Q 30/00; G06K 9/68,EBAY INC.,"ZHENG, Shuai; PIRAMUTHU, Robinson","15/349,462 11.11.2016 US",
WO2018031656,PCT/US2017/046096,09.08.2017,WO/2018/031656,15.02.2018,WO,SYSTEMS AND METHODS FOR CONTEXTUAL RETRIEVAL OF ELECTRONIC RECORDS,"Provided are systems and methods for contextual retrieval of electronic records. The systems and methods provided herein can enhance a search query and/or search results based on (i) natural language processing (NLP) models, (ii) user behavior, and/or (iii) relationships between various entities involved in a search, such as between users, records, and/or fields of expertise. An enhanced search query can be executed using a mechanism more specific to or more compatible with the type of search query. Search results may be contextually relevant. Search results may be specific to a user.",G06F 17/28; G06F 17/30; G06F 17/27; G10L 15/18,"RIPCORD, INC.","MOSKWINSKI, Michael; FIELDING, Alex; HALL, Kevin, Christopher; LEMBO, Kimberly","62/372,565 09.08.2016 US; 62/372,577 09.08.2016 US; 62/372,571 09.08.2016 US",MX-MX/a/2019/001576; EP-2017840208; CN-201780062309.5; JP-2019506714; CA-3033108; KR-1020197006759
WO2019118864,PCT/US2018/065727,14.12.2018,WO/2019/118864,20.06.2019,WO,TRAINING AND/OR USING AN ENCODER MODEL TO DETERMINE RESPONSIVE ACTION(S) FOR NATURAL LANGUAGE INPUT,"Systems, methods, and computer readable media related to: training an encoder model that can be utilized to determine semantic similarity of a natural language textual string to each of one or more additional natural language textual strings (directly and/or indirectly); and/or using a trained encoder model to determine one or more responsive actions to perform in response to a natural language query. The encoder model is a machine learning model, such as a neural network model. In some implementations of training the encoder model, the encoder model is trained as part of a larger network architecture trained based on one or more tasks that are distinct from a ""semantic textual similarity"" task for which the encoder model can be used.",G10L 15/18; G06F 17/27; G10L 15/22; G06F 16/332,GOOGLE LLC,"STROPE, Brian; SUNG, Yun-Hsuan; YUAN, Wangqing","62/599,550 15.12.2017 US",EP-2018830624
WO2018237110,PCT/US2018/038687,21.06.2018,WO/2018/237110,27.12.2018,WO,USING CONVERSATIONAL SIMILARITY FOR DIMENSION REDUCTION IN DEEP ANALYTICS,"A system for using conversational similarity for dimension reduction in deep analytics, comprising a self-learning interaction optimizer that receives string-based data from a contact center and analyzes it to produce a plurality of information similarity vectors, provides the vectors to a neural network and receives output vectors from the neural network, and produces context data from the output vectors and associates the context data with the original string-based data.",G06F 17/27; G06F 17/28,NEWVOICEMEDIA US INC.,"McCORD, Alan; UNITT, Ashley","62/523,733 22.06.2017 US; 15/675,420 11.08.2017 US",
WO2019108276,PCT/US2018/045377,06.08.2018,WO/2019/108276,06.06.2019,WO,METHOD AND APPARATUS FOR PROVIDING PERSONALIZED SELF-HELP EXPERIENCE,"Method and apparatus for providing personalized self-help experience in online application. A predictive model is trained to learn a relationship between one or more user features and one or more tags using historical user feature data. High-dimensional vectors representing each of a plurality of questions are generated and stored in the lookup table. The trained predictive model outputs tags probabilities from the incoming user data, using the learned relationship. A user high-dimensional vector is formed based on the tags probabilities. Similarity metrics are calculated between the highdimensional vector for the respective question and the user high dimensional vector. One or more of the most relevant question titles are returned to a client device for presentation to a user.",G06F 17/30; G06F 17/28; G06N 3/08,INTUIT INC.,"DAIANU, Madelaine; MORIN, Yao; WEI, Ling Feng; PETERS, Chris; JECZMIEN, Itai","15/824,883 28.11.2017 US",
WO1999000789,PCT/IB1998/000495,07.04.1998,WO/1999/000789,07.01.1999,WO,A MACHINE-ORGANIZED METHOD AND A DEVICE FOR TRANSLATING A WORD-ORGANIZED SOURCE TEXT INTO A WORD-ORGANIZED TARGET TEXT,"For translating a word-organized source text into a word-organized target text through mapping of source words on target words, both a translation model and a language model are used. In particular, alignment probabilities are ascertained between various source word and target word pairs, whilst preemptively assuming that alignment between such word pairs is monotonous through at least substantial substrings of a particular sentence. This is done by evaluating incrementally statistical translation performance of various target word strings, deciding on an optimum target word string, and outputting the latter.",G06F 17/28,KONINKLIJKE PHILIPS ELECTRONICS N.V.; PHILIPS PATENTVERWALTUNG GMBH; PHILIPS NORDEN AB,"TILLMANN, Christoph; VOGEL, Stephan; NEY, Hermann",97201959.0 26.06.1997 EP,JP-1998529390; EP-1998909698
WO2014113127,PCT/US2013/068699,06.11.2013,WO/2014/113127,24.07.2014,WO,BOOTSTRAPPING NAMED ENTITY CANONICALIZERS FROM ENGLISH USING ALIGNMENT MODELS,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for training recognition canonical representations corresponding to named-entity phrases in a second natural language based on translating a set of allowable expressions with canonical representations from a first natural language, which may be generated by expanding a context-free grammar for the allowable expressions for the first natural language.",G06F 17/27; G06F 17/28,GOOGLE INC.,"EPSTEIN, Mark Edward; MORENO MENGIBAR, Pedro J.","61/753,089 16.01.2013 US; 13/830,969 14.03.2013 US",EP-2013795639
WO2015130986,PCT/US2015/017848,26.02.2015,WO/2015/130986,03.09.2015,WO,"MULTILINGUAL DICTIONARY ITEMS FROM NON-PARALLEL, SEMI-STRUCTURED DATA","Multilingual dictionaries can be learned from the use of structured data that a commercial service (e.g., an ecommerce site like that operated by eBay Inc.) has in its databases. Consumer behavior can be modelled in different countries, and a mathematical model can be found to correlate user interest. Specific aspects, categories and images of products or services can be used to constrain probabilities to identify semantically similar units across languages. The information can be independently coded in taxonomies for different languages. Taxonomies can be seen as trees of information and certain nodes of these trees can be aligned using prior knowledge, even if that prior knowledge is limited. With machine learning the nodes that are left out can be assumed to be aligned as well, and the probability of this alignment can be estimated.",G06F 17/28; G06F 17/30,EBAY INC.,"SAWAF, Hassan","14/194,606 28.02.2014 US",
WO2019204037,PCT/US2019/025692,04.04.2019,WO/2019/204037,24.10.2019,WO,QUALITY-AWARE DATA INTERFACES,"A set of unstructured data is analyzed to infer structural elements from the unstructured data, and quantized data quality levels, indicative of data quality in the structural elements, are assigned to the structural elements. A set of structured data is generated to include the structural elements inferred from the unstructured data and associations between respective ones of the structural elements in the set of structured data and the corresponding quantized quality levels assigned to the structural elements. The set of structured data, including the associations between respective ones of the structural elements and the corresponding quantized quality levels assigned to the structural elements, is provided to a user interface application to enable the user interface application to visually display varying data qualities in the set of structured data.",G06F 17/21; G06F 17/27; G06F 17/28; G06F 16/28,"MICROSOFT TECHNOLOGY LICENSING, LLC","EDGE, Darren Keith; LARSON, Jonathan Karl; WHITE, Christopher Miles","15/958,428 20.04.2018 US",
WO2019175574,PCT/GB2019/050696,13.03.2019,WO/2019/175574,19.09.2019,WO,A SPEECH PROCESSING SYSTEM AND A METHOD OF PROCESSING A SPEECH SIGNAL,"A speech processing system for generating translated speech, the system comprising: an input for receiving a first speech signal comprising a second language; an output for outputting a second speech signal comprising a first language; and a processor configured to: generate a first text signal from a segment of the first speech signal, the first text signal comprising the second language; generate a second text signal from the first text signal, the second text signal comprising the first language; extract a plurality of first feature vectors from the segment of the first speech signal, wherein the first feature vectors comprise information relating to audio data corresponding to the segment of the first speech signal; generate a speaker vector using a first trained algorithm taking one or more of the first feature vectors as input, wherein the speaker vector represents a set of features corresponding to a speaker; generate a second speech signal segment using a second trained algorithm taking information relating to the second text signal as input and using the speaker vector, the second speech signal segment comprising the first language.",G10L 13/04; G10L 13/08; G10L 15/14; G06F 17/28,PAPERCUP TECHNOLOGIES LIMITED,"GAO, Jiameng",1804073.3 14.03.2018 GB; 1807225.6 02.05.2018 GB,
WO2000063687,PCT/US2000/010302,14.04.2000,WO/2000/063687,26.10.2000,WO,GENE DISCOVERY THROUGH COMPARISONS OF NETWORKS OF STRUCTURAL AND FUNCTIONAL RELATIONSHIPS AMONG KNOWN GENES AND PROTEINS,"The present invention relates to methods for identifying novel genes comprising: (i) generating one or more specialized databases containing information on gene/protein structure, function and/or regulatory interactions; and (ii) searching the specialized databases for homology or for a particular motif and thereby identifying a putative novel gene of interest. The invention may further comprise performing simulation and hypothesis testing to identify or confirm that the putative gene is a novel gene of interest. The present invention also relates to natural language processing and extraction of relational information associated with genes and proteins that are found in genomics journal articles. To enable access to information in textual form, the natural language processing system of the present invention provides a method for extracting and structuring information found in the literature in a form appropriate for subsequent applications.",G06F 19/12; G06F 19/14; G06F 19/28; G06F 19/18; G06F 19/22; G06F 19/24,THE TRUSTEES OF COLUMBIA UNIVERSITY IN THE CITY OF NEW YORK,"RZHETSKY, Andrey; KALACHIKOV, Sergey; KRAUTHAMMER, Michael, O.; FRIEDMAN, Carol; KRA, Pauline","60/129,469 15.04.1999 US; 09/327,983 08.06.1999 US",
EP241675016,18202742,26.10.2018,3477589,01.05.2019,EP,"METHOD OF PROCESSING MEDICAL IMAGE, AND MEDICAL IMAGE PROCESSING APPARATUS PERFORMING THE METHOD","A device and a method for medical image processing are provided. The medical image processing method may include: obtaining a plurality of actual medical images corresponding to a plurality of patients and including lesions; training a deep neural network (DNN), based on the plurality of actual medical images, to obtain a first neural network for predicting a variation in a lesion over time, the lesion being included in a first medical image of the plurality of actual medical images, wherein the first medical image is obtained at a first time point; and obtaining, via the first neural network, a second medical image representing a state of the lesion at a second time point different from the first time point.",G06T 7/00; G06T 11/00,SAMSUNG ELECTRONICS CO LTD,LEE DONG-JAE; OH HYUN-HWA; KIM SE-MIN; SONG JEONG-YONG; LEE HYUN-JUNG,20170140317 26.10.2017 KR,
WO2018070066,PCT/JP2017/010017,13.03.2017,WO/2018/070066,19.04.2018,WO,"IDENTIFYING INFORMATION ASSIGNMENT SYSTEM, IDENTIFYING INFORMATION ASSIGNMENT METHOD, AND PROGRAM THEREFOR","In order to provide a technique for identifying what kind of learning was performed, for each capability acquired as a result of performing a learning process by machine learning, and managing the relationship as appropriate, an identifying information assignment system includes: a generating portion configured to generate, for a learning result obtained by attaining a predetermined capability through a predetermined learning process by machine learning, identifying information for identifying the predetermined learning process; and an assignment portion configured to assign the generated identifying information to the learning result.",G06N 99/00,OMRON CORPORATION,"ANDO, Tanichi",2016-201201 12.10.2016 JP,CN-201780056234.X; EP-2017713476
WO2018156373,PCT/US2018/017893,13.02.2018,WO/2018/156373,30.08.2018,WO,SEQUENCE PROCESSING USING ONLINE ATTENTION,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for generating a target sequence including a respective output at each of multiple output time steps from respective encoded representations of inputs in an input sequence. The method includes, for each output time step, starting from the position, in the input order, of the encoded representation that was selected as a preceding context vector at a preceding output time step, traversing the encoded representations until an encoded representation is selected as a current context vector at the output time step. A decoder neural network processes the current context vector and a preceding output at the preceding output time step to generate a respective output score for each possible output and to update the hidden state of the decoder recurrent neural network. An output is selected for the output time step using the output scores.",G06N 3/04; G06N 3/08,GOOGLE LLC,"WEISS, Ron J.; LUONG, Thang Minh; LIU, Peter J.; RAFFEL, Colin Abraham; ECK, Douglas","62/463,570 24.02.2017 US",EP-2018707518; CN-201880013742.4
WO2009023545,PCT/US2008/072568,08.08.2008,WO/2009/023545,19.02.2009,WO,PROGRESSIVE DISPLAY RENDERING OF PROCESSED TEXT,"A method and a system are provided for processing displayed text and progressively displaying results of processing the displayed text. In some embodiments, displayed text may be submitted as processing requests to process portions of the displayed text. The processing may include translation of the portions of the displayed text from a source natural language to a target natural language, grammar checking of the portions of the displayed text, or other types of processing. Each of the processing requests may include one or more complete sentences, or other units of text. Further, each of the processing requests may be submitted independently of receiving a processing response corresponding to an immediately preceding submitted processing request. Changed or annotated text included in processing responses may replace corresponding displayed text.",G06F 17/21; G06F 17/28,MICROSOFT CORPORATION,"BODE, Andreas; MAURICE, Sandor Loren","60/955,041 10.08.2007 US; 11/865,284 01.10.2007 US",
EP13665838,01117480,19.07.2001,1178408,06.02.2002,EP,Segmenter for a natural language processing system,"The present invention is a segmenter used in a natural language processing system. The segmenter segments a textual input string into tokens for further natural language processing. In accordance with one feature of the invention, the segmenter includes a tokenizer engine that proposes segmentations and submits them to a linguistic knowledge component for validation. In accordance with another feature of the invention, the segmentation system includes language-specific data that contains a precedence hierarchy for punctuation. If proposed tokens in the input string contain punctuation, they can illustratively be broken into subtokens based on the precedence hierarchy. <IMAGE>",G06F 17/27,MICROSOFT CORP,PENTHEROUDAKIS JOSEPH E; BRADLEE DAVID G; KNOLL SONJA S,21957900 20.07.2000 US; 82297601 30.03.2001 US,
WO2018194939,PCT/US2018/027674,13.04.2018,WO/2018/194939,25.10.2018,WO,POWER-EFFICIENT DEEP NEURAL NETWORK MODULE CONFIGURED FOR LAYER AND OPERATION FENCING AND DEPENDENCY MANAGEMENT,"A deep neural network (DNN) processor is configured to execute layer descriptors in layer descriptor lists. The descriptors define instructions for performing a forward pass of a DNN by the DNN processor. The layer descriptors can also be utilized to manage the flow of descriptors through the DNN module. For example, layer descriptors can define dependencies upon other descriptors. Descriptors defining a dependency will not execute until the descriptors upon which they are dependent have completed. Layer descriptors can also define a ""fence,"" or barrier, function that can be used to prevent the processing of upstream layer descriptors until the processing of all downstream layer descriptors is complete. The fence bit guarantees that there are no other layer descriptors in the DNN processing pipeline before the layer descriptor that has the fence to be asserted is processed.",G06N 3/063; G06F 9/48,"MICROSOFT TECHNOLOGY LICENSING, LLC","MCBRIDE, Chad Balling; AMBARDEKAR, Amol Ashok; CEDOLA, Kent D.; PETRE, George; WALL, Larry Marvin; BOBROV, Boris","62/486,432 17.04.2017 US; 15/950,550 11.04.2018 US",EP-2018721658; CN-201880025488.X
EP242633146,18208155,23.11.2018,3489860,29.05.2019,EP,IMAGE DISPLAY APPARATUS AND METHOD OF OPERATING THE SAME,,G06K 9/62; G06K 9/00,SAMSUNG ELECTRONICS CO LTD,GARG JATIN; KOO JAYOON; AGARWAL VIVEK; SANCHES ERNESTO,20170161002 28.11.2017 KR,
WO2018094295,PCT/US2017/062434,18.11.2017,WO/2018/094295,24.05.2018,WO,ADAPTIVE ATTENTION MODEL FOR IMAGE CAPTIONING,"The technology disclosed presents a novel spatial attention model that uses current hidden state information of a decoder long short-term memory (LSTM) to guide attention and to extract spatial image features for use in image captioning. The technology disclosed also presents a novel adaptive attention model for image captioning that mixes visual information from a convolutional neural network (CNN) and linguistic information from an LSTM. At each timestep, the adaptive attention model automatically decides how heavily to rely on the image, as opposed to the linguistic model, to emit the next caption word. The technology disclosed further adds a new auxiliary sentinel gate to an LSTM architecture and produces a sentinel LSTM (Sn-LSTM). The sentinel gate produces a visual sentinel at each timestep, which is an additional representation, derived from the LSTM's memory, of long and short term visual and linguistic information.",G06N 3/04,"SALESFORCE.COM, INC.","LU, Jiasen; XIONG, Caiming; SOCHER, Richard","62/424,353 18.11.2016 US; 15/817,153 17.11.2017 US; 15/817,161 17.11.2017 US; 15/817,165 18.11.2017 US",
WO2019094891,PCT/US2018/060640,13.11.2018,WO/2019/094891,16.05.2019,WO,KNOWLEDGE PROCESS MODELING AND AUTOMATION,"A method for automating knowledge-based processes and operations includes a computer receiving an information dataset comprising knowledge and organizing the information dataset into a plurality of information elements. The computer maps the plurality of information elements into knowledge processes expressed in a knowledge process modeling language. Then, the computer converts the knowledge processes into a knowledge process executable language. Alternatively (or additionally), the computer translates the knowledge processes in a business process model language and converts the translated knowledge processes into a business process executable language.",G06F 17/28,"AHUJA-COGNY, Shruti; COGNY, Adrien","AHUJA-COGNY, Shruti; COGNY, Adrien","15/810,451 13.11.2017 US",
WO2007125151,PCT/FI2006/000135,27.04.2006,WO/2007/125151,08.11.2007,WO,"A METHOD, A SYSTEM AND A DEVICE FOR CONVERTING SPEECH",An arrangement for converting speech into text comprises a mobile device (202) and a server entity (208) configured to perform the conversion and additional optional processes in co-operation. The user of the mobile device (202) may locally edit the speech signal prior to or between the execution of the actual speech recognition tasks. Task sharing details can be negotiated dynamically based on a number of parameters.,G10L 15/26,"KURKI-SUONIO, Risto","KURKI-SUONIO, Risto",,EP-2006743504; US-12298697
WO2018194456,PCT/NL2018/050250,20.04.2018,WO/2018/194456,25.10.2018,WO,OPTICAL MUSIC RECOGNITION OMR : CONVERTING SHEET MUSIC TO A DIGITAL FORMAT,"The invention provides an optical music recognition (OMR) assembly for converting sheet music, representing a music part as a first temporal representation, into a machine-processable representation of said piece of music that represents at least a pitch and duration of notes that are graphically represented in said sheet music and form said music part as a second temporal representation, said assembly comprising a data processor system and software which, when running on said data processor system: - retrieves a machine-processable representation of said sheet music; - generate a series of time slices of said sheet music, by applying a sliding window on said over said machine-processable representation of at least part of said sheet music; - defines a sequence-to-sequence system, said sequence-to-sequence system comprising: provide a convolutional neural network (CNN) for converting said time slices into a sequence of third representations of said sheet music, said CNN comprising an input layer and an output layer; provide a first, encoder recurrent neural network (RNN) as an encoder on said sequence of third representations, for providing a hidden representation of said sheet music, said first RNN having an input layer that is functionally coupled to said output layer of said CNN, and an output layer; * provide a second, decoder recurrent neural network (RNN) as a decoder to said hidden representation, for converting said hidden representation into said machine- processable representation, said second RNN having an input layer that is functionally coupled to said output layer of said first RNN, and an output for providing said machine-processable representation.",G10H 1/00; G06N 3/04; G06N 3/02; G10G 1/04,UNIVERSITEIT VAN AMSTERDAM,"WEL, VAN DER, Eelco Jan; ULLRICH, Karin",2018758 20.04.2017 NL,
WO2018097439,PCT/KR2017/006627,23.06.2017,WO/2018/097439,31.05.2018,WO,ELECTRONIC DEVICE FOR PERFORMING TRANSLATION BY SHARING CONTEXT OF UTTERANCE AND OPERATION METHOD THEREFOR,"The present disclosure relates to an artificial intelligence (AI) system which simulates the functions of a human brain, such as recognition, judgment, etc., by using a machine learning algorithm, such as deep learning; and applications thereof.",G06F 17/28,"SAMSUNG ELECTRONICS CO., LTD.; 삼성전자 주식회사","KIM, Sang-ha; 김상하; KIM, Eun-kyoung; 김은경; YU, Ji-sang; 유지상; RYU, Jong-youb; 류종엽; LEE, Jae-won; 이재원",10-2016-0159416 28.11.2016 KR; 10-2017-0048534 14.04.2017 KR,EP-2017873361; CN-201780081483.4
WO2019101338,PCT/EP2017/080430,24.11.2017,WO/2019/101338,31.05.2019,WO,METHOD OF HANDWRITTEN CHARACTER RECOGNITION CONFIRMATION,"The present invention concerns a method for an artificial neural network to confirm the recognition of handwritten characters produced by a user. The method comprising: training (21) the artificial neural network with a training data set comprising a first set of characters; collecting (23) handwritten characters of a second set of characters produced by the user; and analysing (25, 27) the collected characters of the second set of characters by using the artificial neural network to obtain a first set of probability values comprising character specific probability values for the collected characters, each character specific probability value indicating the probability that the collected character has been correctly interpreted. The analysis considers at least the manner how the collected characters are handwritten and the appearance of the collected characters to obtain the character specific probability values. The invention also relates to a corresponding data processing apparatus.",G06K 9/62; G06K 9/00; G06K 9/66,ECOLE POLYTECHNIQUE FEDERALE DE LAUSANNE (EPFL),"ZOLNA, Konrad; ASSELBORN, Thibault; JOHAL, Wafa",,
WO2018045060,PCT/US2017/049426,30.08.2017,WO/2018/045060,08.03.2018,WO,ELECTRONIC BOOK READER WITH SUPPLEMENTAL MARGINAL DISPLAY,"Digital content is received and supplemental content metadata is produced. The supplemental content metadata indicates a location of a feature in the digital content that is predicted to be of interest to a user. A digital content package is created that includes the digital content and the supplemental content metadata. The digital content package is provided to an electronic device, which presents the digital content in conjunction with a notification that a current position in the digital content is approaching the location of the feature.",G06F 17/28; G06F 3/147; G09B 5/00,GOOGLE LLC,"CHAK, Daniel; VADLAPATLA, Vikas","15/252,836 31.08.2016 US",EP-2017847488
EP236489322,16711210,16.03.2016,3430613,23.01.2019,EP,CONTROLLING PLAYBACK OF SPEECH-CONTAINING AUDIO DATA,"A control method improves a user's ability to navigate in speech-containing audio data during playback of the audio data on a computing device. The control method is executed by a processor in the computing device and comprises operating (51) a media player on the computing device to play the audio data, detecting (52) a user-initiated time-shift command to step forward or backward in the audio data, and, after detecting the time-shift command at a current time in the audio data, identifying (55) a starting point of a sentence in the audio data and operating (56) the media player to play the audio data from the starting point.",G06F 3/16; G06F 15/08; G06F 17/00; G06F 17/27; G06F 17/28; G10L 15/05; G10L 15/08; G10L 15/22; G10L 15/26; G10L 17/00; G11B 27/10; G11B 27/28,SONY MOBILE COMMUNICATIONS INC,THÖRN OLA,2016055626 16.03.2016 EP,
EP283496595,18306104,10.08.2018,3608844,12.02.2020,EP,METHODS FOR TRAINING A CRNN AND FOR SEMANTIC SEGMENTATION OF AN INPUTTED VIDEO USING SAID CRNN,"The present invention relates to a method for training a convolutional recurrent neural network, CRNN, for semantic segmentation in videos; the method being characterized in that it comprises the implementation, by a data processor (11a) of a first server (1a), of steps of:(a) Training from a base of training images already semantically segmented, a first convolutional neural network, CNN;(b) Training from a base of training videos already semantically segmented, a recurrent convolutional neural network, CRNN, corresponding to the first CNN wherein a convolutional layer has been replaced by a recurrent module having a hidden state; said training comprising, for each pair of successive frames (t- 1,t∈1;T<sup>2</sup>) of a video of said base of training videos already semantically segmented:(b1) Warping the internal state of the recurrent layer according to an estimated optical flow between the frames of the pair, so as to adapt the internal state to the motion of pixels between the frames of the pair;(b2) learning parameters of at least the recurrent moduleA method for semantic segmentation of an inputted video is further proposed.",G06N 3/04; G06N 3/08,NAVER CORP,WEINZAEPFEL PHILIPPE,18306104 10.08.2018 EP,
WO2009149174,PCT/US2009/046117,03.06.2009,WO/2009/149174,10.12.2009,WO,METHOD AND SYSTEM FOR OPTIMIZING THE VIBRATIONAL CHARACTERISTICS OF A STRUCTURE,"A structural optimization engine generates a response profile based on a vibrational analysis of a three-dimensional (3D) structure. The structural optimization engine determines whether the 3D structure complies with one or more design goals set for the 3D structure based on the response profile. When the 3D structure does not comply with the design goals, the structural optimization engine retrieves dependency data from a structure database. The dependency data indicates various dependencies between response characteristics included in the response profile and specific regions of the 3D model. Based on the dependency data, the structural optimization engine determines structural modifications that can be made to the 3D structure to bring the 3D structure into compliance with the design goals. A multi-axis computer-aided manufacturing unit then makes the structural modifications to the 3D structure.",G06F 19/00,"CONE, Michael","CONE, Michael","61/058,730 04.06.2008 US; 12/477,071 02.06.2009 US",
WO2020047288,PCT/US2019/048862,29.08.2019,WO/2020/047288,05.03.2020,WO,IMAGE DRIVEN QUALITY CONTROL FOR ARRAY BASED PCR,"A system and methods are provided for image driven quality control for array based PCR. The system comprises a PCR unit, a reaction array plate, a convolutional neural network (CNN) configured to receive a sequence of images of the reaction array plate in the PCR system, and an output of the CNN coupled to a control for the reaction array plate. The method comprises applying a sequence of images from a plurality of subarrays of the reaction array plate to a plurality of CNNs during operation of the PCR system on the reaction plate array, operating the CNNs to generate failure mode predictions for the reaction plate based on the sequence of images, and coupling an output of the CNNs to one or more of a setting for manufacture of the reaction array plate or to control the PCR system.",G06N 3/04; G06N 3/08; G01N 35/00; G01N 35/02; G06T 7/00,LIFE TECHNOLOGIES CORPORATION,"CHU, Yong; MAJUMBAR, Nivedita; ALIMINATI, Manjula; CHEN, Yongzhi; PAPENFUSS, Kevin","62/725,894 31.08.2018 US",
WO2016094096,PCT/US2015/062872,30.11.2015,WO/2016/094096,16.06.2016,WO,LOCALIZATION COMPLEXITY OF ARBITRARY LANGUAGE ASSETS AND RESOURCES,"A ""Linguistic Complexity Tool"" uses Machine Learning (ML) based techniques to predict ""source complexity scores"" for localization of source language assets or resources (i.e., ""source content""), or subsections of that content, to provide users with predicted levels of difficulty in localizing source content into target languages, dialects, or linguistic styles. These predicted source complexity scores provide a number of advantages, including but not limited to, improved user efficiency and user interaction performance by identifying source content, or subsections of that content, that are likely to be difficult or time consuming for users to localize. Further, these source complexity scores enable users to modify source content prior to localization to provide lower source complexity scores, thereby reducing error rates with respect to localized text or language presented in software applications or other media including, but not limited to, spoken or written localizations of the source content.",G06F 17/27; G06F 17/28,"MICROSOFT TECHNOLOGY LICENSING, LLC","COGLEY, James; GROVES, Declan; JONES, Michael Aziel; HEDLEY, Michael Reid","14/563,029 08.12.2014 US",EP-2015816945; JP-2017548358; RU-2017119853; KR-1020177015617; MX-MX/a/2017/007364; CA-2967977
WO2019009995,PCT/US2018/038100,18.06.2018,WO/2019/009995,10.01.2019,WO,SYSTEM AND METHOD FOR NATURAL LANGUAGE MUSIC SEARCH,"Various methods and systems are provided for implementing a search engine that generates search results for a natural language description of music. A music description and categorization schema is defined to provide a common terminology and taxonomy. Music catalogs are ingested to generate a searchable catalog index. A natural language description of music is analyzed using various natural language processing techniques to generate corresponding musical features of the schema to be searched. A query string is generated from the musical features using a query term profile including one or more query term generators. A ranking score and other search result statistics are generated. Various visualizations can be provided, including a visualization of the translated search and a visualization of search results. In some embodiments, word clouds are provided to allow a user to filter search results by a selected matched feature. As such, users can efficiently review search results.",G06F 17/28; G06F 17/30; G10L 15/18,"SYNC FLOOR, INC","DEBIQUE, Kirt","62/529,293 06.07.2017 US; 15/881,416 26.01.2018 US",EP-2018827656
WO2016040772,PCT/US2015/049632,11.09.2015,WO/2016/040772,17.03.2016,WO,METHOD AND APPARATUS OF MATCHING AN OBJECT TO BE DISPLAYED,"A method and an apparatus of matching an object to be displayed are disclosed. The method includes obtaining a plurality of search keywords and released product information and grouping each of the plurality of search keywords with the released product information to form a plurality of search keyword and released product information pairs, with each search keyword and released product information pair comprising a respective search keyword and the released product information; determining and matching a plurality of features for the plurality of search keyword and released product information pairs according to a constructed first decision tree; and determining respective correlation classes of the plurality of search keyword and released product information pairs based at least in part on a result of determining and matching of the plurality of features. The disclosed method and apparatus are able to accurately and conveniently determine a matching degree between a search keyword and released product information.",G06F 17/27; G06F 17/28; G06F 17/30,ALIBABA GROUP HOLDING LIMITED,"WANG, Tao; HUANG, Peng; LIN, Feng",201410461059.0 11.09.2014 CN,
WO2018184187,PCT/CN2017/079663,07.04.2017,WO/2018/184187,11.10.2018,WO,METHODS AND SYSTEMS FOR ADVANCED AND AUGMENTED TRAINING OF DEEP NEURAL NETWORKS USING SYNTHETIC DATA AND INNOVATIVE GENERATIVE NETWORKS,"Methods and systems for advanced and augmented training of deep neural networks (DNNs) using synthetic data and innovative generative networks. A method includes training a DNN using synthetic data, training a plurality of DNNs using context data, associating features of the DNNs trained using context data with features of the DNN trained with synthetic data, and generating an augmented DNN using the associated features.",G06K 9/66,"INTEL CORPORATION; YAO, Anbang; WANG, Shandong; CHENG, Wenhua; CAI, Dongqi; WANG, Libin; XU, Lin; HU, Ping; GUO, Yiwen; YANG, Liu; HOU, Yuqing; SU, Zhou; CHEN, Yurong","YAO, Anbang; WANG, Shandong; CHENG, Wenhua; CAI, Dongqi; WANG, Libin; XU, Lin; HU, Ping; GUO, Yiwen; YANG, Liu; HOU, Yuqing; SU, Zhou; CHEN, Yurong",,EP-2017904421; CN-201780088109.7
EP14284139,02756018,28.05.2002,1508861,23.02.2005,EP,METHOD FOR SYNTHESISING A SELF-LEARNING SYSTEM FOR KNOWLEDGE ACQUISITION FOR TEXT-RETRIEVAL SYSTEMS,"The invention relates to computer science, information-search and intelligent systems, and can be used in developing information-search and other information and intelligent systems that operate on the basis of Internet. The invention provides the possibility of automatic creation of knowledge by extraction of knowledge from textual documents in electronic form in different languages; intelligent processing of textual information and users' requests to extract knowledge in any foreign language. The claimed method provides a mechanism of self-learning in the form of a stochastically indexed system of artifical intelligence, providing automatic instruction of the system in rules of grammatical and semantic analysis. The method includes creating databases of stochastically indexed dictionaries, tables of indices of linguistic texts and knowledge bases of morphological analysis; performing morphological and syntactical analysis, and also stochastic indexing of textual documents in respect to a given theme from the search system in a given language, and creating knowledge base of syntactical analysis. Stochastically indexed textual documents pertaining to the given theme are subjected to semantic analysis, and knowledge bases of semantic analysis. A user's request is compiled and transformed, in the stochastically indexed form, into a plurality of new requests that are equivalent to the original request; and stochastically indexed fragments of textual documents that comprise all word combinations of the transformed request are selected. A stochastically indexed structure is generated from the selected documents and basing on said structure by means of logical conclusion a brief reply of the system is generated. Relevancy of the obtained brief reply is checked by generating an interrogative sentence based on said reply, and by comparing said sentence with the request. When the user's request is identical to the obtained interrogative sentence, the decision is made that the brief reply of the system is identical to the request, and the reply is submitted to the user. <IMAGE>",G09B 19/00; G06F 17/30; G06F 15/18; G06F 17/00; G06F 17/27; G06F 17/28; G06F 17/30; G06N 5/02; G09B 19/00,NASYPNY VLADIMIR VLADIMIROVICH; NASYPNAYA GALINA ANATOLIEVNA,NASYPNY VLADIMIR VLADIMIROVICH; NASYPNAYA GALINA ANATOLIEVNA,0200258 28.05.2002 RU,
EP14204348,04006714,19.03.2004,1462948,29.09.2004,EP,"Ordering component for sentence realization for a natural language generation system, based on linguistically informed statistical models of constituent structure",The present invention is a tree ordering component within a sentence realization system which receives an unordered syntax tree and generates a ranked list of alternative ordered syntax trees from the unordered syntax tree. The present invention also includes statistical models of constituent structure employed by the tree ordering component in scoring the alternative ordered trees. <IMAGE>,G06F 3/00; G06F 17/28; G06F 12/00; G06F 17/27; G06F 40/00; G10L 15/26,MICROSOFT CORP,RINGGER ERIC; GAMON MICHAEL; SMETS MARTINE; CORSTON-OLIVER SIMON; MOORE ROBERT C,39654903 25.03.2003 US,
WO2016134183,PCT/US2016/018536,18.02.2016,WO/2016/134183,25.08.2016,WO,SYSTEMS AND METHODS FOR NEURAL LANGUAGE MODELING,"In some aspects, the present disclosure relates to neural language modeling. In one embodiment, a computer-implemented neural network includes a plurality of neural nodes, where each of the neural nodes has a plurality of input weights corresponding to a vector of real numbers. The neural network also includes an input neural node corresponding to a linguistic unit selected from an ordered list of a plurality of linguistic units, and an embedding layer with a plurality of embedding node partitions. Each embedding node partition includes one or more neural nodes. Each of the embedding node partitions corresponds to a position in the ordered list relative to a focus term, is configured to receive an input from an input node, and is configured to generate an output. The neural network also includes a classifier layer with a plurality of neural nodes, each configured to receive the embedding outputs from the embedding layer, and configured to generate an output corresponding to a probability that a particular linguistic unit is the focus term.",G06F 17/30,"DIGITAL REASONING SYSTEMS, INC.","TRASK, Andrew; GILMORE, David; RUSSELL, Matthew","62/118,200 19.02.2015 US; 62/128,915 05.03.2015 US",
EP249469768,18209316,29.11.2018,3518176,31.07.2019,EP,"MACHINE LEARNING SPARSE COMPUTATION MECHANISM FOR ARBITRARY NEURAL NETWORKS, ARITHMETIC COMPUTE MICROARCHITECTURE, AND SPARSITY FOR TRAINING MECHANISM",,G06T 1/20,INTEL CORP,NURVITADHI ERIKO; BLEIWEISS AMIT; MARR DEBORAH; WANG EUGENE; DWARAKAPURAM SARITHA; GANAPATHY SABAREESH,201715859203 29.12.2017 US,
EP252257023,17884410,15.12.2017,3543896,25.09.2019,EP,"METHOD FOR ESTIMATING LANE INFORMATION, AND ELECTRONIC DEVICE","Disclosed are: an artificial intelligence (AI) system for mimicking functions such as cognition and determination of the human brain by utilizing a machine learning algorithm such as deep learning; and an application thereof. Disclosed is an electronic device comprising: a camera for capturing an external image of a vehicle; and a processor for executing one or more instructions stored in a memory, wherein the processor determines at least one object for estimating lane information from a captured image by executing one or more instructions, estimates lane information of a road, on which the vehicle is traveling, in an image on the basis of the distance between the determined at least one object and the vehicle and the vanishing point of the image, and outputs guide information for guiding the traveling of the vehicle on the basis of the estimated lane information.",G06K 9/00; G06K 9/62; H04N 5/225,SAMSUNG ELECTRONICS CO LTD,KIM JI-MAN; PARK CHAN-JONG; YANG DO-JUN; LEE HYUN-WOO,20160178012 23.12.2016 KR; 20170142567 30.10.2017 KR; 2017014810 15.12.2017 KR,
WO2020085769,PCT/KR2019/013903,22.10.2019,WO/2020/085769,30.04.2020,WO,SPEECH RECOGNITION METHOD AND APPARATUS IN ENVIRONMENT INCLUDING PLURALITY OF APPARATUSES,"Provided are an artificial intelligence (AI) system that utilizes a machine learning algorithm such as deep learning, etc. and an application of the AI system. A speech recognition method, performed by a speech recognition apparatus, of performing speech recognition in a space in which a plurality of speech recognition apparatuses are present includes extracting a speech signal of a speaker from an input audio signal; obtaining a first speaker recognition score indicating a similarity between the speech signal and a speech signal of a registration speaker; and outputting a speech recognition result with respect to the speech signal based on a second speaker recognition score obtained from another speech recognition apparatus among the plurality of speech recognition apparatuses and the first speaker recognition score.",G10L 17/02; G10L 17/12; G10L 17/08; G10L 15/22,"SAMSUNG ELECTRONICS CO., LTD.","CHO, Keunseok; ROH, Jaeyoung; HYUNG, Jiwon; JANG, Donghan; LEE, Jaewon",10-2018-0127696 24.10.2018 KR; 10-2019-0110772 06.09.2019 KR,
WO1999005621,PCT/US1998/014883,17.07.1998,WO/1999/005621,04.02.1999,WO,SYSTEM FOR PROCESSING TEXTUAL INPUTS USING NATURAL LANGUAGE PROCESSING TECHNIQUES,"A system (1480) filters documents in a document set retrieved from a document store in response to a query. The system (1480) obtains (1830) a first set of logical forms based on a selected one of the query and the documents in the document set. The system (1480) obtains a second set of logical forms based on another of the query and the documents in the document set. The system (1480) then uses natural language processing techniques to modify (1832, 1834) the first logical forms to obtain a modified set of logical forms. The system (1480) filters (1836) documents in the document set based on a predetermined relationship betwwen the modified set of logical forms and the second set of logical forms.",G06F 17/30,MICROSOFT CORPORATION,"CORSTON, Simon, H.; DOLAN, William, B.; VANDERWENDE, Lucy, H.; BRADEN-HARDER, Lisa","08/898,652 22.07.1997 US; 09/097,979 16.06.1998 US",EP-1998936899; CN-98807504.0
EP212454810,17182712,24.07.2017,3282367,14.02.2018,EP,METHOD FOR CONTROLLING IDENTIFICATION AND IDENTIFICATION CONTROL APPARATUS,"A method for controlling identification includes obtaining first text, which is text in a first language, obtaining second text, which is text in a second language obtained by translating the first text into the second language, obtaining correct labels, which indicate content of the first text, inputting the first text and the second text to an identification model common to the first and second languages, and updating the common identification model such that labels identified by the common identification model from the first text and the second text match the correct labels.",G06F 17/27; G06F 17/28; G06N 3/04,PANASONIC IP MAN CO LTD,SHI HONGJIE; USHIO TAKASHI; ENDO MITSURU; YAMAGAMI KATSUYOSHI,2017067775 30.03.2017 JP; 201662372456 09.08.2016 US,
WO2017068439,PCT/IB2016/055028,23.08.2016,WO/2017/068439,27.04.2017,WO,NATURAL LANGUAGE PROCESSOR FOR PROVIDING NATURAL LANGUAGE SIGNALS IN A NATURAL LANGUAGE OUTPUT,Embodiments are directed to a natural language processing (NLP) system configured to receive a natural language (NL) input and perform an analysis operation to generate a NL output. The NLP system is configured to generate at least one confidence level based at least in part on at least one portion of the analysis operation. The NLP system is further configured to integrate at least one disfluency into the NL output based at least in part on the at least one confidence level.,G06F 17/28,INTERNATIONAL BUSINESS MACHINES CORPORATION; IBM UNITED KINGDOM LIMITED; IBM (CHINA) INVESTMENT COMPANY LIMITED,"ERICKSON, Thomas; FARRELL, Robert, George","14/920,131 22.10.2015 US; 14/965,368 10.12.2015 US",GB-1807907.9; JP-2018515210; DE-112016003335
WO2018081163,PCT/US2017/058138,24.10.2017,WO/2018/081163,03.05.2018,WO,SEQUENCE TO SEQUENCE TRANSFORMATIONS FOR SPEECH SYNTHESIS VIA RECURRENT NEURAL NETWORKS,"A system eliminates alignment processing and performs TTS functionality using a new neural architecture. The neural architecture includes an encoder and a decoder. The encoder receives an input and encodes it into vectors. The encoder applies a sequence of transformations to the input and generates a vector representing the entire sentence. The decoder takes the encoding and outputs an audio file, which can include compressed audio frames.",G10L 25/00,"SEMANTIC MACHINES, INC.","HALL, David Leo Wright; KLEIN, Daniel; ROTH, Daniel Lawrence; GILLICK, Laurence Steven; MAAS, Andrew Lee; WEGMANN, Steven Andrew","62/412,165 24.10.2016 US; 15/792,236 24.10.2017 US",PH-12019550054; SG-11201903130W; CA-3037090; AU-2017347995; EP-2017863701
WO2020047264,PCT/US2019/048826,29.08.2019,WO/2020/047264,05.03.2020,WO,"A DEVICE EMBEDDED IN, OR ATTACHED TO, A PILLOW CONFIGURED FOR IN-BED MONITORING OF RESPIRATION","A monitoring device has microphones, an ADC; a digital radio; and a processor with firmware. The firmware includes code for digitizing audio from the microphones into time-domain audio, performing FFT to provide frequency-domain audio, running a first neural network on time domain and frequency-domain audio to extract features, executing a classifier on the features to identify candidate events, and using the digital radio to upload candidate events and features. A pressure sensor awakens the processor from a low-power state. In particular embodiments, the first neural network is an embedded Gated Recurrent Unit having weights trained to extract features of use in the classifier; and candidate events include normal inhalation and exhalation breathing sounds, crackles, wheezes, coughs, snoring, gasping, choking, and speech sounds and in some embodiments heart sounds. A method of monitoring breathing during sleep includes attaching the device to, or embedding the device within, a pillow.",A61B 5/00; A61B 5/0205; A61B 5/08,THE TRUSTEES OF DARTMOUTH COLLEGE,"AMOH, Justice; BEMOWSKI, Jeffrey A.","62/726,146 31.08.2018 US",
WO2001075662,PCT/US2001/010628,02.04.2001,WO/2001/075662,11.10.2001,WO,METHOD AND APPARATUS FOR PROVIDING MULTILINGUAL TRANSLATION OVER A NETWORK,"L'invention concerne un procédé pour traduire électroniquement des textes, qui repose sur un traducteur électronique. Un texte en langue de départ est reçu comme une entrée dans le traducteur électronique. Ce texte en langue de départ est traduit par le traducteur électronique, au moment de sa soumission, dans une ou plusieurs langues d'arrivée. Un utilisateur peut ensuite visualiser un ou plusieurs textes en langue d'arrivée avec ou sans les textes en langue de départ.",G06F 17/28,"AMIKAI, INC.; RITTER, Thomas; CHIN, Jeffrey; FLOURNOY, Raymond; HIDISYAN, Pria; HORIUCHI, Rina; KASSUM, Yannick; LEE, Kevin; LEE, Nicholas; LOWSKY, David; WEINSTEIN, David; CALLISON-BURCH, Christopher","RITTER, Thomas; CHIN, Jeffrey; FLOURNOY, Raymond; HIDISYAN, Pria; HORIUCHI, Rina; KASSUM, Yannick; LEE, Kevin; LEE, Nicholas; LOWSKY, David; WEINSTEIN, David; CALLISON-BURCH, Christopher","60/193,937 31.03.2000 US; 60/212,553 20.06.2000 US",JP-2001573273
WO2019028261,PCT/US2018/045026,02.08.2018,WO/2019/028261,07.02.2019,WO,METHOD AND APPARATUS FOR TRAINING OF CONVERSATIONAL AGENTS,"A computer-implemented method and an apparatus for facilitating training of conversational agents are disclosed. The method includes automatically extracting a workflow associated with each conversation from among a plurality of conversations between agents and customers of an enterprise. The workflow is extracted, at least in part, by encoding one or more utterances associated with the respective conversation and mapping the encoded one or more utterances to predefined workflow stages. A clustering of the plurality of conversations is performed based on a similarity among respective extracted workflows. The clustering of the plurality of conversations configures a plurality of workflow groups. At least one conversational agent is trained in customer engagement using a set of conversations associated with at least one workflow group from among the plurality of workflow groups.",G06F 17/20; G06F 17/27; G06F 17/28; G06F 17/30; G06Q 10/06; G10L 15/08; G10L 15/18; G10L 15/22,"[24]7.AI, INC.","CHAKRABORTY, Abir; RALLAPALLI, Sruti; DUTHALURU, Vidhya","16/053,190 02.08.2018 US; 62/540,364 02.08.2017 US",
EP12523833,92480198,17.12.1992,0602296,22.06.1994,EP,Adaptive method for generating field dependant models for intelligent systems.,"A system architecture made to enable providing human intelligible information by processing a flow of input data; e.g. converting speech (source information) into printable data (target information) based on target dependent probalistic models; and more particularly enable efficiently switching from one target field of information into another. To that end, the system is provided with a Language Modeling device including a Data Base (40) loadable with application dependent corpuses of words or symbols through a workstation (16); and a Language Modeling processor programmed to refresh, in practice, a tree organized model, efficiently, with no blocking situations, and at a reasonable cost. <IMAGE>",G06F 15/38; G10L 5/06; G10L 15/10; G06F 17/27; G06F 17/28; G10L 15/18; G10L 15/28,IBM,MERIALDO BERNARD,92480198 17.12.1992 EP,
EP12263771,90850295,04.09.1990,0473864,11.03.1992,EP,Method and apparatus for paraphrasing information contained in logical forms.,"A method of paraphrasing logical forms of natural language expressions in an information processing system, such as a data base query system is disclosed. It comprises mapping logical forms to a set of Initial Trees. The structure and overall content of these trees is such as to be usable as the input to a parser for natural language analysis. Each tree has a set of syntactic features, that is, pairs of attributes and their values. A grammar is applied to the Initial Trees, in order to build a syntactic tree, whereby said Initial Trees are parsed as an unordered set of complex symbols. Each grammar rule is partly a phrase structure recognition rule and partly a specification of the translation of a node built up by the rule. The syntactic tree thus produced are evaluated, and translation strings are created by mapping all Initial Trees to (possibly null) natural language strings, as a function of their categories and the features which the grammar and the Initial Tree generator has placed on them. Also an apparatus for carrying out the method of paraphrasing logical forms of natural language expressions is disclosed. <IMAGE>",G06F 15/38; G06F 17/27; G06F 17/28,IBM,WHITE BRIAN FREDERICK; BRETAN IVAN PAUL; SANAMRAD MOHAMMAD ALI,90850295 04.09.1990 EP,
WO2019022722,PCT/US2017/043765,25.07.2017,WO/2019/022722,31.01.2019,WO,LANGUAGE IDENTIFICATION WITH SPEECH AND VISUAL ANTHROPOMETRIC FEATURES,"In some examples, language identification with speech and visual anthropometric features may include analyzing an input signal to identify a speech of a user, and extracting a feature of the speech. Language identification with speech and visual anthropometric features may further include identifying, based on a classification of the feature, a language of the speech, and controlling processing associated with the speech based on the identified language.",G10L 15/16,"HEWLETT-PACKARD DEVELOPMENT COMPANY, L.P.","BHARITKAR, Sunil; MURPHY, David",,
WO2019118007,PCT/US2018/044779,01.08.2018,WO/2019/118007,20.06.2019,WO,DOMAIN-SPECIFIC NATURAL LANGUAGE UNDERSTANDING OF CUSTOMER INTENT IN SELF-HELP,"Method and apparatus for providing a personalized self-support service to a user of an online application coupled with an online community forum. Embodiments include obtaining a plurality of questions from the online community forum and obtaining historical user data. Embodiments further include identifying one or more part-of-speech words in the plurality of questions and generating a high-dimensional vector for each question of the plurality of questions based on a frequency of the one or more part-of-speech words. Embodiments further include identifying one or more user features of the plurality of users based on the historical user data and establishing, based on the historical user data, one or more statistical correlations between user features and part-of-speech words. Embodiments further include training a predictive model based on the one or more statistical correlations. Embodiments further include using the predictive model to predict to provide one or more relevant questions to the user.",G06F 17/30; G06F 17/27; G06F 17/28,INTUIT INC.,"DAIANU, Madelaine; MORIN, Yao; LUNT, Jonathan; CESSNA, Joseph B.","15/844,475 15.12.2017 US",
WO2019167603,PCT/JP2019/004818,12.02.2019,WO/2019/167603,06.09.2019,WO,"NEURAL MACHINE TRANSLATION MODEL TRAINING METHOD AND DEVICE, AND COMPUTER PROGRAM THEREFOR","[Problem] To provide an NMT training method and device that allow achievement of high-precision translation even when there is a plurality of target fields and the field to which the present to-be-translated target belongs is unknown. [Solution] An NMT 40 training method is for, when the field for actual translation to be performed is unknown, improving translation precision of the NMT 40 in the unknown field by performing training for a neural machine translation model with use of training data comprising field-by-field training data prepared for a plurality of already known fields. This method includes: a storing step for storing training data in a machine-readable storage device 46; and a step for causing a computer to access the storage device 46 and causing a training device 42 to perform training for parameter collection in a neural network such that the distribution of field-by-field training data in the training data used for training the NMT 40 is made uniform over the plurality of fields.",G06F 17/28,NATIONAL INSTITUTE OF INFORMATION AND COMMUNICATIONS TECHNOLOGY; 国立研究開発法人情報通信研究機構,"WANG, Rui; ワン　ルイ; UCHIYAMA, Masao; 内山　将夫",2018-033544 27.02.2018 JP,
EP222886344,17206555,11.12.2017,3343460,04.07.2018,EP,HARDWARE ACCELERATOR TEMPLATE AND DESIGN FRAMEWORK FOR IMPLEMENTING RECURRENT NEURAL NETWORKS,"Hardware accelerator templates and design frameworks for implementing recurrent neural networks (RNNs) and variants thereof are described. A design framework module obtains a flow graph for an RNN algorithm. The flow graph identifies operations to be performed to implement the RNN algorithm and further identifies data dependencies between ones of the operations. The operations include matrix operations and vector operations. The design framework module maps the operations of the flow graph to an accelerator hardware template, yielding an accelerator instance comprising register transfer language code that describes how one or more matrix processing units and one or more vector processing units are to be arranged to perform the RNN algorithm. At least one of the one or more MPUs, as part of implementing the RNN algorithm, is to directly provide or directly receive a value from one of the one or more VPUs.",G06N 3/04; G06N 3/063,INTEL CORP,NURVITADHI ERIKO; MARR DEBORAH,201615396520 31.12.2016 US,
WO2016081707,PCT/US2015/061539,19.11.2015,WO/2016/081707,26.05.2016,WO,SYSTEMS AND METHODS FOR AUTOMATIC IDENTIFICATION OF POTENTIAL MATERIAL FACTS IN DOCUMENTS,"Systems and methods to identify potential material fact sentences in electronic legal documents obtained from electronic repositories are disclosed. A system includes a processing device and a storage medium in communication with the processing device. The storage medium includes programming instructions that cause the processing device to obtain a document and parse text within the document to determine whether each paragraph in the document is a fact paragraph, a discussion paragraph, or an outcome paragraph based on at least one of a heading associated with the paragraph and features of the paragraph. The storage medium further includes programming instructions that cause the processing device to extract each sentence in the fact paragraph, direct a trained sentence classifier to determine whether each sentence is a potential material fact sentence or a non-material fact sentence based on features of the sentence, and identify potential material fact sentences.",G06F 15/18; G06F 17/28; G06F 17/30,"LEXISNEXIS, A DIVISION OF REED ELSEVIER INC.","PENDYALA, Mahesh; OSGOOD, Gene; MYERS, Jacob, Aaron","62/081,786 19.11.2014 US",JP-2017527215; CA-2964391; AU-2015349927
WO2017213780,PCT/US2017/031616,08.05.2017,WO/2017/213780,14.12.2017,WO,MOBILE AND WEARABLE VIDEO CAPTURE AND FEEDBACK PLAT-FORMS FOR THERAPY OF MENTAL DISORDERS,"Behavioral and mental health therapy systems in accordance with several embodiments of the invention include a wearable camera and/or a variety of sensors (accelerometer, microphone, among various other) connected to a computing system including a display, audio output, holographic output, and/or vibrotactile output to automatically recognize social cues from images captured by at least one camera and provide this information to the wearer via one or more outputs such as (but not limited to) displaying an image, displaying a holographic overlay, generating an audible signal, and/or generating a vibration.",G06F 19/00; G06T 7/20; G06Q 50/22,"THE BOARD OF TRUSTEES OF THE LELAND STANFORD JUNIOR UNIVERSITY; VOSS, Catalin","VOSS, Catalin; HABER, Nicholas, Joseph; WALL, Dennis, Paul; KLINE, Aaron, Scott; WINOGRAD, Terry, Allen","62/333,108 06.05.2016 US",CA-3023241; EP-2017810680; CN-201780036661.1; JP-2019510585; KR-1020187035497
WO2000038083,PCT/US1999/028948,06.12.1999,WO/2000/038083,29.06.2000,WO,METHOD AND APPARATUS FOR PERFORMING FULL BI-DIRECTIONAL TRANSLATION BETWEEN A SOURCE LANGUAGE AND A LINKED ALTERNATIVE LANGUAGE,"System with apparatus to improve international and other communication, and to provide easier access to data, especially digitized data, by means of linked alternative language generated from a source language. As taught by the present invention, a linked alternative language is an especially designated language form quite different in outward format from its source language in that it has been optimized in a plurality of ways to allow targeted population to comprehend and use it more efficiently than the source language, but which has also been carefully designed to retain full bi-directional machine translation equivalence to the source language. All use of artificial intelligence and computational linguistics for machine translation as taught in the present invention is constrained by these considerations.",G06F 17/28,"MOSER, Leo, J.; MOSER, Robert, D.","MOSER, Leo, J.; MOSER, Robert, D.","09/215,425 18.12.1998 US",
WO2019027258,PCT/KR2018/008756,01.08.2018,WO/2019/027258,07.02.2019,WO,ELECTRONIC DEVICE AND METHOD FOR CONTROLLING THE ELECTRONIC DEVICE,"An artificial intelligence (AI) system utilizing a machine learning algorithm to receive an area in an image provide a first search result by using first text information describing an object in the area by using a trained model, and provide a second search result by using second text information describing an object in the second area using the trained model.",G06F 17/30; G06N 3/08,"SAMSUNG ELECTRONICS CO., LTD.","KIM, Wonsik; CHOI, Yoon-hee","62/539,760 01.08.2017 US; 62/540,221 02.08.2017 US; 10-2018-0007301 19.01.2018 KR",EP-2018840410
WO2019043540,PCT/IB2018/056441,24.08.2018,WO/2019/043540,07.03.2019,WO,TEXT DATA REPRESENTATION LEARNING USING RANDOM DOCUMENT EMBEDDING,"Embodiments of the present invention provide a computer-implemented: method for performing unsupervised feature representation learning for text data. The method generates reference text data having a set of random text sequences:, in which each text sequence of set of random text sequences is of a random Iength and comprises a number of random words, and in which each random Iength is sampled from a minimum; length to a maximum length. The random words of each text sequence i in the set are drawn from a distribution. The method generates a feature matrix for raw text data based at least in part on a set of computed distances between the set of random text sequences and the raw text data. The method provides the feature matrix as an input to one or more machine earning models,",G06F 17/27,INTERNATIONAL BUSINESS MACHINES CORPORATION; IBM UNITED KINGDOM LIMITED; IBM (CHINA) INVESTMENT COMPANY LIMITED,"WU, Lingfei; WITBROCK, Michael, John","15/689,799 29.08.2017 US",
WO2020077946,PCT/CN2019/078929,20.03.2019,WO/2020/077946,23.04.2020,WO,SYSTEM AND METHOD FOR PROVIDING PORTABLE NATURAL LANGUAGE PROCESSING INTERFACE ACROSS MULTIPLE APPLIANCES,"A method and system of providing a portable voice-based control user interface for multiple types of appliances are disclosed. The method includes activating a built-in voice communication interface of a voice control apparatus; selecting a first target appliance to receive voice-based commands; receiving a first voice input; in accordance with a determination that the first target appliance is a first appliance of a first appliance type, processing the first voice input using a first NLP model corresponding to the first appliance type to obtain a first machine command, and sending the first machine command to the first appliance; and in accordance with a determination that the first target appliance is a second appliance of a second appliance type, processing the first voice input using a second NLP model corresponding to the second appliance type to obtain a second machine command, and sending the second machine command to the second appliance.",G06F 17/28,"MIDEA GROUP CO., LTD.","HUANG, Haibin; ZHANG, Chen; LIU, Xin","16/160,929 15.10.2018 US",
WO2008118814,PCT/US2008/057915,21.03.2008,WO/2008/118814,02.10.2008,WO,"REAL-TIME TRANSLATION OF TEXT, VOICE AND IDEOGRAMS","A system and method translate a statement in real time. Artificial intelligence translates text, speech or ideograms from a first language to a second language. The translated statement may be edited by a person at the source of the message and/or a person receiving the statement. Edits are used to train the artificial intelligence in the proper translation of the language. The system learns the language, or a vernacular thereof, and translates future messages in accordance with the edits received.",G06F 17/28; G06F 17/20,"MEGLOBE, INC.; DEGROOT, Ben","DEGROOT, Ben","11/691,472 26.03.2007 US; 11/874,371 18.10.2007 US",
WO2006128238,PCT/AU2006/000739,02.06.2006,WO/2006/128238,07.12.2006,WO,A METHOD FOR SUMMARISING KNOWLEDGE FROM A TEXT,"The present invention relates to a method for summarising knowledge from text and in particular to a method and system for summarising knowledge from text such as scientific or research papers. The continuing growth of the published literature has created a fundamental barrier to the transfer of what is published being used in common practice. There is just too much literature for human beings to deal with. The present invention provides a computing system and method for automatically summarising knowledge from text, by determining some concepts from the text, generating a set of candidate relationships between the concepts, generating a set of relationships based on the set of candidate relationships according to predetermined criteria and generating a decision model based on the set of relationships.",G06F 17/27; G06F 17/28,"NEWSOUTH INNOVATIONS PTY LIMITED; COIERA, Enrico","COIERA, Enrico",2005902860 02.06.2005 AU,DE-null; US-11916442; EP-6741156
WO2016172038,PCT/US2016/028091,18.04.2016,WO/2016/172038,27.10.2016,WO,WELLSITE REPORT SYSTEM,A method can include receiving state information for a wellsite system; receiving contextual information for a role associated with a workflow; generating a natural language report based at least in part on the state information and based at least in part on the contextual information; and transmitting the natural language report via a network interface based at least in part on an identifier associated with the role.,E21B 44/00; E21B 41/00; G05B 19/02; G06F 19/00,SCHLUMBERGER TECHNOLOGY CORPORATION; SCHLUMBERGER CANADA LIMITED; SERVICES PETROLIERS SCHLUMBERGER; GEOQUEST SYSTEMS B.V.,"FOUBERT, Benoit; MEEHAN, Richard John; POYET, Jean-Pierre; REYES, Sandra; LIN, Raymond; CHAMBON, Sylvain","62/149,620 19.04.2015 US",US-15566110
WO2018187712,PCT/US2018/026497,06.04.2018,WO/2018/187712,11.10.2018,WO,"ADAPTIVE, INTERACTIVE, AND COGNITIVE REASONER OF AN AUTONOMOUS ROBOTIC SYSTEM","An artificial intelligence problem is solved using an artificial intelligence memory graph data structure and a lexical database to identify supporting knowledge. A natural language input is received and classified into components. A starting node of an artificial intelligence memory graph data structure, which comprises one or more data nodes, is selected to begin a search for one or more supporting knowledge data nodes associated with the classified components. Starting at the starting node, the artificial intelligence memory graph data structure is searched using a lexical database to identify the one or more supporting knowledge data nodes. An artificial intelligence problem is identified and solved using the one or more identified supporting knowledge data nodes of the artificial intelligence memory graph data structure.",G06F 17/20; G06F 17/28; G06N 5/02; G06N 5/04; G10L 15/22; G06K 9/62; G06Q 30/02,"AIBRAIN, INC.","SHINN, Hong, Shik; HONG, Eunmi; LIM, Byoung-kwon; LEE, Cheogan","15/946,646 05.04.2018 US; 62/482,631 06.04.2017 US",
WO2003065180,PCT/US2003/003251,03.02.2003,WO/2003/065180,07.08.2003,WO,SYSTEM AND METHOD FOR CREATING A DISTRIBUTED NETWORK ARCHITECTURE,"A large scale distributed multimedia system comprising the following: I) one or more server(s), wherein each server includes a main server thread (210), one or more threads capable of monitoring incoming data feeds (221) and instantiating the resultant data into the system (monitoring threads), one or more threads capable of handling incoming data requests (211) (request threads), and cache memory (250); ii) a mass storage system (MSS) (250), wherein the MSS stores information concerning the arrangement of one or more server(s) and is capable of controlling one or more robotic autoloader systems (robots); iii) a types system for defining data types at a binary level and for associating those data types with one or more server(s) such that the mapping maps data types with the servers that must be addressed to obtain the corresponding data; and iv) a query system for executing data queries on servers mapped to the data type being queried. Additional features are also supported including registration on one or more servers of customized commands and functions, and input and output folders for transmitting data to or from data storage.",G06F 9/45; G06F 12/06; G06F 13/00; G06F 15/16; G06F 15/173; G06F 17/00; G06F 17/21; G06F 17/27; G06F 17/28; G06F 17/30; G06K 9/72; G06N 5/00,"FAIRWEATHER, John","FAIRWEATHER, John","60/353,487 01.02.2002 US",JP-null
WO2019050137,PCT/KR2018/006984,20.06.2018,WO/2019/050137,14.03.2019,WO,SYSTEM AND METHOD OF DETERMINING INPUT CHARACTERS BASED ON SWIPE INPUT,"Provided are an artificial intelligence (AI) system and an application thereof, which simulate functions of a human brain, such as recognition and determination, by using a machine learning algorithm, such as deep-learning. A method of processing, by a device, a keyboard input, based on training, may include: displaying a keyboard on a screen of the device; receiving a swipe input of a user, the swipe input connecting a plurality of keys on a displayed keyboard; extracting a trajectory connecting the plurality of keys; applying, to a trained model for a keyboard input, based on the trajectory, trajectory information indicating a shape of the trajectory and a relative position of the trajectory with respect to the keyboard.",G06F 3/0488; G06N 99/00; G06K 9/32,"SAMSUNG ELECTRONICS CO., LTD.","KIM, Jung-wook; YUN, Hui-won; LEE, Hae-jun; JUNG, Ho-jin",10-2017-0113345 05.09.2017 KR,EP-2018853823
EP293254139,19214143,26.03.2018,3637246,15.04.2020,EP,INSTRUCTIONS AND LOGIC TO PERFORM FLOATING-POINT AND INTEGER OPERATIONS FOR MACHINE LEARNING,"One embodiment provides for a machine-learning hardware accelerator comprising a compute unit having an adder and a multiplier that are shared between integer data path and a floating-point datapath, the upper bits of input operands to the multiplier to be gated during floating-point operation.",G06F 7/483; G06F 7/544; G06F 9/30; G06N 3/04; G06N 3/063; G06N 3/08,INTEL CORP,KAUL HIMANSHU; ANDERS MARK A; MATHEW SANU K; YAO ANBANG; RAY JOYDEEP; TANG PING T; STRICKLAND MICHAEL S; CHEN XIAOMING; SHPEISMAN TATIANA; APPU ABHISHEK R; KOKER ALTUG; SINHA KAMAL; VEMBU BALAJI; NURVITADHI ERIKO; BARIK RAJKISHORE; LIN TSUNG-HAN; RANGANATHAN VASANTH; JAHAGIRDAR SANJEEV; GALOPPO VON BORRIES NICOLAS C,18164093 26.03.2018 EP; 201715787129 18.10.2017 US; 201762491699 28.04.2017 US,
WO2007100519,PCT/US2007/004132,13.02.2007,WO/2007/100519,07.09.2007,WO,ADAPTIVE SEMANTIC PLATFORM ARCHITECTURE,"An adaptive shared infrastructure that can be easily utilized to enable natural interaction between user(s) and machine system(s) is provided. Additionally, the novel innovation can provide interactive techniques that produce accurate intent-to-action mapping based upon a user input. Further, the innovation can provide novel mechanism by which assets (e.g., documents, actions) can be authored. The authoring mechanisms can enable the generation of learning models such that the system can infer a user intent based at least in part upon an analysis of a user input. In response thereto, the system can discover an asset, or group of assets based upon the inference. Moreover, the innovation can provide a natural language interface that learns and/or adapts based upon one or more user input(s), action(s), and/or state(s).",G06F 17/28; G06F 17/30; G06F 15/16,MICROSOFT CORPORATION,"RAMSEY, William D.; KATARIYA, Sanjeev; LIU, Jun; GAO, Jianfeng; YAO, Qi; CHEN, Zhanliang","11/363,747 28.02.2006 US",EP-2007750932; CN-200780007007.4; JP-2008557284; KR-1020087020416
WO2018124620,PCT/KR2017/015178,21.12.2017,WO/2018/124620,05.07.2018,WO,METHOD AND DEVICE FOR TRANSMITTING AND RECEIVING AUDIO DATA,"An artificial intelligence (AI) system configured to simulate functions of a human brain, such as recognition, determination, etc., by using a machine learning algorithm, such as deep learning, etc., and an application thereof. The AI system includes a method performed by a device to transmit and receive audio data to and from another device includes obtaining a voice input that is input by a first user of the device, obtaining recognition information indicating a meaning of the obtained voice input, transmitting the obtained voice input to the other device, determining whether an abnormal situation occurs, in which a second user of the other device does not understand the transmitted voice input, and transmitting the obtained recognition information to the other device, based on a result of the determination.",G10L 15/18; G10L 15/26; G10L 15/06; G10L 17/22,"SAMSUNG ELECTRONICS CO., LTD.","KIM, Jae-deok; PARK, Mee-jeong",10-2016-0179317 26.12.2016 KR; 10-2017-0148328 08.11.2017 KR,EP-2017887809; CN-201780084788.0
WO2019139431,PCT/KR2019/000513,11.01.2019,WO/2019/139431,18.07.2019,WO,SPEECH TRANSLATION METHOD AND SYSTEM USING MULTILINGUAL TEXT-TO-SPEECH SYNTHESIS MODEL,"The present disclosure relates to a speech translation method or system using a multilingual text-to-speech synthesis model. A speech translation method using a multilingual text-to-speech synthesis model comprises the steps of: acquiring a single artificial neural network text-to-speech synthesis model having acquired learning on the basis of learning text of a first language and learning speech data of the first language corresponding to the learning text of the first language and, learning text of a second language and learning speech data of the second language corresponding to the learning text of the second language; receiving input speech data of the first language and an utterer's articulatory characteristics in the first language; converting the input speech data of the first language into text of the first language; converting the text of the first language into text of the second language; and generating output speech data which corresponds to the text of the second language and replicates the utterer's speech, by inputting the text of the second language and the utterer's articulatory characteristics to a single artificial neural network text-to-speech synthesis model.",G06F 17/28; G10L 13/08; G10L 13/033; G10L 15/26; G10L 15/02,"NEOSAPIENCE, INC.; 네오사피엔스 주식회사","KIM, Tae Su; 김태수; LEE, Young Gun; 이영근",10-2018-0004047 11.01.2018 KR; 10-2018-0036377 29.03.2018 KR; 10-2019-0004188 11.01.2019 KR,
WO2020067633,PCT/KR2019/008652,12.07.2019,WO/2020/067633,02.04.2020,WO,ELECTRONIC DEVICE AND METHOD OF OBTAINING EMOTION INFORMATION,"Emotion information is obtained by an electronic device in order to improve communication between a person and the electronic device. Multimedia data is obtained regarding a person, predicted values for the person are obtained by applying the multimedia data to neural network models, and emotion information of the person is obtained by applying the predicted values to a weight model. Then, feedback information is obtained from the person with respect to the first emotion information of the person. Finally, the weight model is updated by using the feedback information. Subsequently, when multimedia data are again obtained regarding the person, new predicted values for the person are obtained by applying later multimedia data the plurality of neural network models, and emotion information of the person is again obtained, but this time using the weight model updated using the feedback information.",A61B 5/16; A61B 5/00,"SAMSUNG ELECTRONICS CO., LTD.","SEO, Chanwon; ZHANG, Lei; KIM, Yehoon; YUN, Sojung; LEE, Dongwan; KIM, Yongsung; LEE, Juyoung","62/738,656 28.09.2018 US; 10-2018-0140093 14.11.2018 KR",
WO2019064158,PCT/IB2018/057353,24.09.2018,WO/2019/064158,04.04.2019,WO,CONVERSION BETWEEN GRAPHEMES AND PHONEMES ACROSS DIFFERENT LANGUAGES,"A technique for estimating phonemes for a word written in a different language is disclosed. A sequence of graphemes of a given word in a source language is received. The sequence of the graphemes in the source language is converted into a sequence of phonemes in the source language. One or more sequences of phonemes in a target language are generated from the sequence of the phonemes in the source language by using a neural network model. One sequence of phonemes in the target language is determined for the given word. Also, technique for estimating graphemes of a word from phonemes in a different language is disclosed.",G10L 13/08,INTERNATIONAL BUSINESS MACHINES CORPORATION; IBM UNITED KINGDOM LIMITED; IBM (CHINA) INVESTMENT COMPANY LIMITED,"NAGANO, Toru; KURATA, Gakuto; TSUBOI, Yuta","15/717,194 27.09.2017 US; 15/801,820 02.11.2017 US",
EP13748218,01111720,15.05.2001,1213660,12.06.2002,EP,Meaning understanding by means of local pervasive intelligence,"Scheme for enriching an input network (18) with knowledge from a fractal semantic knowledge network (11). The input network (18) comprises objects and pointers between these objects, and the knowledge network (11) comprises semantic units, and a plurality of Jani, whereby any of these Jani is associated with one or more of the semantic units such that the respective Janus is able to operate on one or more of the semantic units. The following steps are carried out: 
  finding a counterpart element for an object or a pointer by looking for a semantic unit that is related to the object or the pointer; 
  establishing a classification connection between the object or the pointer and its counterpart element; 
  assigning the module that is associated with the counterpart element, if any, to the object or the pointer; 
  examining the objects' or the pointers' neighborhoods in the input network (18) by comparing them with the counterpart elements' neighborhoods in knowledge network (11) to verify the classification connection.",G06F 17/27; G06F 17/28; G06N 3/08; G06N 5/02,IBM,BERGAN ELIAS; BINNIG GERD K; KLENK JUERGEN A,00113438 24.06.2000 EP; 01111720 15.05.2001 EP,
WO2019231516,PCT/US2019/022246,14.03.2019,WO/2019/231516,05.12.2019,WO,"SYSTEM AND METHOD FOR COMPACT, FAST, AND ACCURATE LSTMS","According to various embodiments, a method for generating an optimal hidden-layer long short-term memory (H-LSTM) architecture is disclosed. The H-LSTM architecture includes a memory cell and a plurality of deep neural network (DNN) control gates enhanced with hidden layers. The method includes providing an initial seed H-LSTM architecture, training the initial seed H-LSTM architecture by growing one or more connections based on gradient information and iteratively pruning one or more connections based on magnitude information, and terminating the iterative pruning when training cannot achieve a predefined accuracy threshold.",G10L 15/16; G06F 7/483; G06N 3/04; G06N 3/063; G10L 21/0224,THE TRUSTEES OF PRINCETON UNIVERSITY,"DAI, Xiaoliang; YIN, Hongxu; JHA, Niraj K.","62/677,232 29.05.2018 US",
WO2013050749,PCT/GB2012/052432,02.10.2012,WO/2013/050749,11.04.2013,WO,ASSISTIVE DEVICE FOR CONVERTING AN AUDIO SIGNAL INTO A VISUAL REPRESENTATION,"A device for converting an audio signal into a visual representation, the device comprising at least one receiver for receiving the audio signal; a signal processing unit for processing the received audio signal; a converter for converting the processed audio signal into a visual representation; and projecting means for projecting the visual representation onto a display, wherein the display comprises an embedded grating structure.",G02B 27/01; G10L 21/06; G10L 15/26,"KANEGAONKAR, Rahul Govind","CLARKE, Roger; RIX, Anthony William",1116994.3 03.10.2011 GB,US-14348221; EP-2012790622
WO2018174815,PCT/SG2017/050153,24.03.2017,WO/2018/174815,27.09.2018,WO,METHOD AND APPARATUS FOR SEMANTIC COHERENCE ANALYSIS OF TEXTS,"A method, a computer-readable medium, and an apparatus for constructing machine learning based models for pronoun resolution are provided. The apparatus may identify a set of subjects in a first sentence and a pronoun in a second sentence. The apparatus may generate a set of tuples. Each tuple may include a subject of the set of subjects, the pronoun, a first subgraph of a first dependency graph corresponding to the first sentence, and a second subgraph of a second dependency graph corresponding to the second sentence. For each tuple, the apparatus may identify a trained machine learning based model corresponding to the tuple. For each tuple, the apparatus may determine a validation score of the tuple using the trained machine learning based model corresponding to the tuple. The apparatus may determine a referent of the pronoun based on the validation scores.",G06F 17/27,"AGENCY FOR SCIENCE, TECHNOLOGY AND RESEARCH","HU, Shangfeng; KIM, Jung Jae; KANAGASABAI, Rajaraman",,
WO2020050508,PCT/KR2019/010039,09.08.2019,WO/2020/050508,12.03.2020,WO,IMAGE DISPLAY APPARATUS AND OPERATION METHOD OF THE SAME,"An image display apparatus includes a display configured to display a plurality of images, a memory storing one or more instructions, and a processor configured to execute the one or more instructions stored in the memory to obtain semantic information corresponding to each of the plurality of images by using a first neural network, obtain emotion information corresponding to each of the plurality of images by using a second neural network, determine at least one piece of audio corresponding to the plurality of images, based on the semantic information and the emotion information, and output the at least one piece of audio.",G06F 3/16; G06F 3/01; G06F 3/0481; G06N 3/04; G06N 3/08,"SAMSUNG ELECTRONICS CO., LTD.","BAIJAL, Anant; HYUN, Daeeun; KWON, Mijeong",10-2018-0106046 05.09.2018 KR,
EP293254140,19214829,26.03.2018,3637247,15.04.2020,EP,INSTRUCTIONS AND LOGIC TO PERFORM FLOATING-POINT AND INTEGER OPERATIONS FOR MACHINE LEARNING,"One embodiment provides for a machine-learning hardware accelerator comprising a compute unit having an adder and a multiplier that are shared between integer data path and a floating-point datapath, the upper bits of input operands to the multiplier to be gated during floating-point operation.",G06F 7/483; G06F 7/544; G06F 9/30; G06N 3/04; G06N 3/063; G06N 3/08,INTEL CORP,KAUL HIMANSHU; ANDERS MARK A; MATHEW SANU K; YAO ANBANG; RAY JOYDEEP; TANG PING T; STRICKLAND MICHAEL S; CHEN XIAOMING; SHPEISMAN TATIANA; APPU ABHISHEK R; KOKER ALTUG; SINHA KAMAL; VEMBU BALAJI; NURVITADHI ERIKO; BARIK RAJKISHORE; LIN TSUNG-HAN; RANGANATHAN VASANTH; JAHAGIRDAR SANJEEV; GALOPPO VON BORRIES NICOLAS,18164093 26.03.2018 EP; 201715787129 18.10.2017 US; 201762491699 28.04.2017 US,
WO2019051057,PCT/US2018/049709,06.09.2018,WO/2019/051057,14.03.2019,WO,MACHINE LEARNING LEXICAL DISCOVERY,"Various data or document processing systems may benefit from an improved machine learning process for information extraction. For example, certain data or document processing systems may benefit from enhanced Semantic Vector Rules and a lexical knowledge base used to extract information from the text. A method may include analyzing a set of documents including a plurality of text. The method may also include extracting information from the plurality of text based on a lexicon. In addition, the method may include updating the lexicon with at least one new term based on one or more semantic vector rules.",G06F 17/27; G06F 17/21; G06F 17/28; G06F 15/18,"ROSOKA SOFTWARE, INC.","SORAH, Michael, Allen; ROBERTS, Gregory, F.","62/554,855 06.09.2017 US",
EP275493182,19162692,13.03.2019,3561738,30.10.2019,EP,MACHINE LEARNING ACCELERATOR ARCHITECTURE,,G06N 3/063; G06N 3/04; G06N 3/08,INTEL CORP,DAGA BHARAT; JANEDULA PRADEEP; SRINIVASAN ARAVIND BABU; VENGALLUR AMBILI,201815960851 24.04.2018 US,
WO2018194998,PCT/US2018/027840,16.04.2018,WO/2018/194998,25.10.2018,WO,NEURAL NETWORK PROCESSOR USING COMPRESSION AND DECOMPRESSION OF ACTIVATION DATA TO REDUCE MEMORY BANDWIDTH UTILIZATION,"A deep neural network (""DNN"") module can compress and decompress neuron-generated activation data to reduce the utilization of memory bus bandwidth. The compression unit can receive an uncompressed chunk of data generated by a neuron in the DNN module. The compression unit generates a mask portion and a data portion of a compressed output chunk. The mask portion encodes the presence and location of the zero and non-zero bytes in the uncompressed chunk of data. The data portion stores truncated non-zero bytes from the uncompressed chunk of data. A decompression unit can receive a compressed chunk of data from memory in the DNN processor or memory of an application host. The decompression unit decompresses the compressed chunk of data using the mask portion and the data portion. This can reduce memory bus utilization, allow a DNN module to complete processing operations more quickly, and reduce power consumption.",G08B 13/196; G06N 3/063; H03M 7/30; H03M 7/46,"MICROSOFT TECHNOLOGY LICENSING, LLC","CORKERY, Joseph Leon; LUNDELL, Benjamin Eliot; WALL, Larry Marvin; MCBRIDE, Chad Balling; AMBARDEKAR, Amol Ashok; PETRE, George; CEDOLA, Kent D.; BOBROV, Boris","62/486,432 17.04.2017 US; 15/953,356 13.04.2018 US",MX-MX/a/2019/012388; EP-2018721932; RU-2019136750; JP-2019555659; CN-201880025420.1; CA-3056660; AU-2018256212; SG-11201909175X; IL-269888; KR-1020197033456
EP13322524,98922234,13.05.1998,0996899,03.05.2000,EP,APPARATUS AND METHODS FOR AN INFORMATION RETRIEVAL SYSTEM THAT EMPLOYS NATURAL LANGUAGE PROCESSING OF SEARCH RESULTS TO IMPROVE OVERALL PRECISION,"Apparatus and accompanying methods for an information retrieval system that utilizes natural language processing to process results retrieved by, for example, an information retrieval engine such as a conventional statistical-based search engine, in order to improve overall precision. Specifically, such a search ultimately yields a set of retrieved documents. Each such document is then subjected to natural language processing to produce a set of logical forms. Each such logical form encodes, in a word-relation-word manner, semantic relationships, particularly argument and adjunct structure, between words in a phrase. A user-supplied query is analyzed in the same manner to yield a set of corresponding logical forms therefor. Documents are ranked as a predefined function of the logical forms from the documents and the query. Specifically, the set of logical forms for the query is then compared against a set of logical forms for each of the retrieved documents in order to ascertain a match between any such logical forms in both sets. Each document that has at least one matching logical forms is heuristically scored, with each different relation for a matching logical forms being assigned a different corresponding predefined weight. The score of each such document is, e.g., a predefined function of the weights of its uniquely matching logical forms. Finally, the retained documents are ranked in order of descending score and then presented to a user in that order.",G06F 17/28; G06F 17/30,MICROSOFT TECHNOLOGY LICENSING LLC,BRADEN-HARDER LISA; CORSTON SIMON H; DOLAN WILLIAM B; VANDERWENDE LUCY H,89865297 22.07.1997 US; 9809711 13.05.1998 US,
EP160970432,15187618,30.09.2015,3002686,06.04.2016,EP,LANGUAGE IDENTIFICATION,A plurality of documents in each of a plurality of languages can be received. A Latent Semantic Indexing (LSI) index can be created from the plurality of documents. A language classification model can be trained from the LSI index. A document to be identified by language can be received. A vector in the LSI index can be generated for the document to be identified by language. The vector can be evaluated against the language classification model.,G06F 17/27,ACCENTURE GLOBAL SERVICES LTD,BITTMAN MARK,201414502465 30.09.2014 US,
WO2020060223,PCT/KR2019/012138,19.09.2019,WO/2020/060223,26.03.2020,WO,DEVICE AND METHOD FOR PROVIDING APPLICATION TRANSLATION INFORMATION,"The present disclosure relates to: an artificial intelligence (AI) system for simulating the human brain’s functions such as cognition and decision-making by using a machine learning algorithm such as deep learning; and an application thereof. A method for providing application translation information by a device comprises the operations of: acquiring a resource file of an application through the operating system (OS) of a device; translating text in the acquired resource file to be displayed in an execution screen of the application, by using an artificial intelligence model; generating an execution screen of the application by using the resource file and the text in translation; and displaying the generated execution screen, wherein the translating operation translates the text from a first language into a second language by applying at least part of data in the resource file to the artificial intelligence model which has performed learning in order to translate text to be displayed in the execution screen of the application.",G06F 17/28; G06F 17/21; G06N 3/02; G06N 20/00,"SAMSUNG ELECTRONICS CO., LTD.; 삼성전자주식회사","KIM, Jiwan; 김지완",10-2018-0112377 19.09.2018 KR,
WO2016125031,PCT/IB2016/000622,01.02.2016,WO/2016/125031,11.08.2016,WO,MODIFYING A TOKENIZER BASED ON PSEUDO DATA FOR NATURAL LANGUAGE PROCESSING,"Techniques for training a tokenizer (or word segmenter) are provided. In one technique, (100), a tokenizer (210) tokenizes a token string to identify individual tokens or words. A language model (230) is generated based on the identified tokens or words. A vocabulary (240) about an entity, such as a person or company, is identified. The vocabulary may be online data that refers to the entity, such as a news article or a profile page of a member of a social network. Some of the tokens in the vocabulary may be weighted higher than others (2560). The language model accepts the weighted vocabulary (260) as input and generates pseudo sentences (270). Alternatively, regular expressions are used to generate the pseudo sentences (270). The pseudo sentences (270) are used to train the tokenizer.",G06F 17/27; G06F 17/28; G10L 15/183,LINKEDIN CORPORATION,"ZHAO, Bing; ZHANG, Ethan","14/611,816 02.02.2015 US",
EP248884905,19151731,14.01.2019,3511887,17.07.2019,EP,AUTOMATED CHAT ASSISTANT FOR PROVIDING INTERACTIVE DATA USING NPL - NATURAL LANGUAGE PROCESSING - SYSTEM AND METHOD,,G06Q 10/10; G06F 17/27; G06Q 10/06; G06Q 30/00; G06Q 30/02; H04L 12/58,CAPITAL ONE SERVICES LLC,RELANGI ADITYA; CHITNIS ABHIJIT,201815872454 16.01.2018 US,
WO2009014465,PCT/RS2008/000025,16.07.2008,WO/2009/014465,29.01.2009,WO,SYSTEM AND METHOD FOR MULTILINGUAL TRANSLATION OF COMMUNICATIVE SPEECH,"The invention relates to the system and method for translation of communicative speech using multilingual resources as universal base for multilingual translation. Specific aspect of the invention is the generalized interaction of languages through Interlingua Domain which contains formal descriptions of both speech and language of the source speaker in the form of concepts which are accessible for the synthesis in other languages. The system consists of Interlingua Domain (ID) which contains Interlingua Reservoir of Concepts (IRC) and Interlingua Bank of Bilingual Dictionaries (IBBD). Each language in the translation system has the module with two-way processing of speech and language: analytic towards Interlingua Domain where the sentence in the source language is processed and synthetic from Interlingua Domain where the sentence is generated in the target language. Analytic and synthetic procedures are based on grammatical rules with specific solutions in extraction and synthesis of features, meanings and concepts of two languages in interaction.",G06F 17/28; G10L 15/26,"JOVICIC, Slobodan; SARIC, Zoran","JOVICIC, Slobodan; SARIC, Zoran",P-2007/0316 25.07.2007 RS,
EP243305306,18207882,22.11.2018,3493119,05.06.2019,EP,LANGUAGE PROCESSING METHOD AND APPARATUS,,G06N 3/04; G06F 17/27; G06F 17/28; G06N 3/08,SAMSUNG ELECTRONICS CO LTD,LEE MIN-JOONG; LEE HODONG,20170165397 04.12.2017 KR,
WO2017198909,PCT/FI2017/050379,19.05.2017,WO/2017/198909,23.11.2017,WO,SEGMENTATION OF DATA,"The present invention relates to a computer-implemented method for segmenting input data. In the method a plurality of tags is generated (110); the input data is masked with the plurality of tags (120); a plurality of output reconstructions (130) is generated by inputting the plurality of masked input data to one of the following: a denoising neural network, a variational autoencoder; a plurality of values representing distances of each plurality of output reconstructions to the input data are determined (140); a plurality of updated versions of input data is generated (150) by applying at least one of the determined values representing distances of each plurality of output reconstructions to the input data; and updated output reconstructions (160) are generated by inputting the plurality of updated versions of input data to one of the networks. The invention also relates to a method for training the network and a processing unit.",G06N 3/02,CURIOUS AI OY,"VALPOLA, Harri; GREFF, Klaus",20160136 20.05.2016 FI,
WO2019098538,PCT/KR2018/012123,15.10.2018,WO/2019/098538,23.05.2019,WO,DEVICE AND METHOD FOR PROCESSING CONVOLUTION OPERATION USING KERNEL,"Provided are a method and apparatus for processing a convolution operation in a neural network. The apparatus may include a memory, and a processor configured to read, from the memory, one of divided blocks of input data stored in a memory; generate an output block by performing the convolution operation on the one of the divided blocks with a kernel; generate a feature map by using the output block, and write the feature map to the memory.",G06N 3/063; G06N 3/04,"SAMSUNG ELECTRONICS CO., LTD.","KIM, Kyoung-hoon; PARK, Young-hwan; SUH, Dong-kwan; PRASAD, Keshava; KIM, Dae-hyun; KIM, Suk-jin; CHO, Han-su; KIM, Hyun-jung",10-2017-0151722 14.11.2017 KR,EP-2018878124
WO2014194161,PCT/US2014/040141,30.05.2014,WO/2014/194161,04.12.2014,WO,SYSTEMS AND METHODS FOR PERFORMING BAYESIAN OPTIMIZATION,"Techniques for use in connection with performing optimization using a plurality of objective functions associated with a respective plurality of tasks. The techniques include using at least one computer hardware processor to perform: identifying, based at least in part on a joint probabilistic model of the plurality of objective functions, a first point at which to evaluate an objective function in the plurality of objective functions; selecting, based at least in part on the joint probabilistic model, a first objective function in the plurality of objective functions to evaluate at the identified first point; evaluating the first objective function at the identified first point; and updating the joint probabilistic model based on results of the evaluation to obtain an updated joint probabilistic model.",G06F 15/18,PRESIDENT AND FELLOWS OF HARVARD COLLEGE; THE GOVERNING COUNCIL OF THE UNIVERSITY OF TORONTO; UNIVERSITE DE SHERBROOKE,"ADAMS, Ryan, P.; SNOEK, Roland, Jasper; LAROCHELLE, Hugo; SWERSKY, Kevin; ZEMEL, Richard","61/829,090 30.05.2013 US; 61/829,604 31.05.2013 US; 61/910,837 02.12.2013 US",EP-2014804134; CA-2913743
EP13468521,99920828,30.04.1999,1076861,21.02.2001,EP,MACHINE-ASSISTED TRANSLATION TOOLS,"The present invention provides an improved method and apparatus for translating a source language to a target language. The invention uses placeables (e.g., proper nouns, titles and names, dates, times, units and measurements, numbers, formatting information, such as tags or escape sequences, styles, graphics, hyperlinks) to assist a translator by not having to retype information that does not need to be translated and to provide conversions to the target locale if necessary like for speeds.",G06F 17/27; G06F 17/28,TRADOS GMBH,HUMMEL JOCHEN; KNYPHAUSEN IKO,9902959 30.04.1999 EP; 7190098 04.05.1998 US,
WO2020091350,PCT/KR2019/014292,28.10.2019,WO/2020/091350,07.05.2020,WO,ELECTRONIC DEVICE AND CONTROL METHOD THEREOF,"An electronic apparatus and a control method are provided, including an input interface, a communication interface, a memory including at least one command, and at least one processor configured to control the electronic device and execute the at least one command to receive a user speech through the input interface, determine whether or not the user speech is a speech related to a task requiring user confirmation by analyzing the user speech, generate a question for the user confirmation when it is determined that the user speech is the speech related to the task requiring the user confirmation, and perform a task corresponding to the user speech when a user response corresponding to the question is input through the input interface. Embodiments may use an artificial intelligence model learned according to at least one of machine learning, a neural network, and a deep learning algorithm.",G06F 3/16; G06F 3/01; G06F 21/32; G10L 17/24,"SAMSUNG ELECTRONICS CO., LTD.","KIM, Chanwoo; LEE, Kyungmin; ROH, Jaeyoung; JANG, Donghan; CHO, Keunseok; HYUNG, Jiwon",10-2018-0130007 29.10.2018 KR,
WO2018110818,PCT/KR2017/011440,17.10.2017,WO/2018/110818,21.06.2018,WO,SPEECH RECOGNITION METHOD AND APPARATUS,"A speech recognition method and apparatus for performing speech recognition in response to an activation word determined based on a situation are provided. The speech recognition method and apparatus include an artificial intelligence (AI) system and its application, which simulates functions such as recognition and judgment of a human brain using a machine learning algorithm such as deep learning.",G10L 15/04; G10L 15/02; G10L 15/22; G10L 15/26,"SAMSUNG ELECTRONICS CO., LTD.","CHOI, Sung-ja; KIM, Eun-kyoung; YU, Ji-sang; HONG, Ji-yeon; RYU, Jong-youb; LEE, Jae-won",10-2016-0171670 15.12.2016 KR; 10-2017-0054513 27.04.2017 KR,EP-2017879966; CN-201780078008.1
WO2019139428,PCT/KR2019/000509,11.01.2019,WO/2019/139428,18.07.2019,WO,MULTILINGUAL TEXT-TO-SPEECH SYNTHESIS METHOD,The present disclosure provides a multilingual text-to-speech synthesis method and system. A multilingual text-to-speech synthesis method comprises the steps of: receiving first learning data including learning text of a first language and learning speech data of the first language corresponding to the learning text of the first language; receiving second learning data including learning text of a second language and learning speech data of the second language corresponding to the learning text of the second language; and generating a single artificial neural network text-to-speech synthesis model by learning similarity information between a phoneme of the first language and a phoneme of the second language on the basis of the first learning data and the second learning data.,G06F 17/28; G10L 13/08; G10L 13/033; G10L 15/26; G10L 15/02,"NEOSAPIENCE, INC.; 네오사피엔스 주식회사","KIM, Tae Su; 김태수; LEE, Young Gun; 이영근",10-2018-0004047 11.01.2018 KR; 10-2018-0036377 29.03.2018 KR; 10-2019-0003979 11.01.2019 KR,
WO2002029622,PCT/US2001/030920,02.10.2001,WO/2002/029622,11.04.2002,WO,MACHINE EDITING SYSTEM INCORPORATING DYNAMIC RULES DATABASE,"Documents translated from one language to another, especially machine-translated documents, typically require editing to better reflect the nuances of language content and meaning; and especially the use of nomenclature that is culture and or industry specific. A dynamic database of editing rules (2) helps to automate this editing of already-translated documents. An initial set of editing rules is deployed in the database and used to edit machine-translated documents. Manual changes, made by a human editor (4), are subsequently made to the machine-edited documents (3) are recorded and that data is used to form updates or additions to the initial editing rules. Over time, the rules database improves so that machine editing is more effective and, conversely, the manual editing burden and corresponding cost is reduced.",G06F 17/24; G06F 17/28,"VIALANGUAGE, INC.; BALLANCE, Chanin, M.; HALPIN, Francis, A.; DIRKSEN, James; WAIBLINGER, Dieter","BALLANCE, Chanin, M.; HALPIN, Francis, A.; DIRKSEN, James; WAIBLINGER, Dieter","60/237,226 02.10.2000 US",
WO2018131048,PCT/IN2017/050085,08.03.2017,WO/2018/131048,19.07.2018,WO,SYSTEM AND METHOD FOR NATURAL LANGUAGE GENERATION,"The system includes receiving one or more semantic items and a language object corresponding to the language in which the text is to be generated. The system further includes identifying one or more sentence types and one or more sentence part types for each identified sentence type. The system includes obtaining a vocabulary class for the each identified sentence part type by querying the word to sentence part type association rule, obtains one or more vocabulary class features for each of the sentence part type by querying the word to sentence part type association rule. The system further includes creating and building a natural language phrase object for each sentence part type. The system further includes deriving an expression for each built natural language phrase object. The System further includes arranging sequentially all the derived expressions using a word separation character between every pair of successive expressions.",G06F 17/28; G06F 17/20,"KRISHNAMURTHY, Satyanarayana","KRISHNAMURTHY, Satyanarayana",201741001148 11.01.2017 IN,US-15520608
WO2014085015,PCT/US2013/067429,30.10.2013,WO/2014/085015,05.06.2014,WO,"BUILDING, REUSING AND MANAGING AUTHORED CONTENT FOR INCIDENT MANAGEMENT","Building, reusing and calibrating network of authored content, in one aspect, may comprise clustering a plurality of problem tickets into one or more clusters. The clusters may be associated to one or more FAQ nodes in a FAQ network. The associated one or more FAQ nodes may be checked to determine whether the nodes are part of a broken branch. If the one or more FAQ nodes leads to a broken branch, a user may be notified to update the branch, e.g., with an answer or resolution to the one or more FAQ nodes.",G06F 17/28,INTERNATIONAL BUSINESS MACHINES CORPORATION,"RANGACHARI, Anand; LEE, Juhnyoung; LIU, Rong; MIYAMOTO, Kohtaroh","13/687,725 28.11.2012 US",
EP177407429,15845502,01.04.2015,3065068,07.09.2016,EP,METHOD AND APPARATUS FOR DETERMINING SEMANTIC MATCHING DEGREE,"The present invention provides a method and an apparatus for determining a semantic matching degree. The method includes: acquiring a first sentence and a second sentence; dividing the first sentence and the second sentence into x and y sentence fragments, respectively; performing a convolution operation on word vectors in each sentence fragment of the first sentence and word vectors in each sentence fragment of the second sentence, to obtain a three-dimensional tensor; performing integration and/or screening on adjacent vectors in the one-dimensional vectors of x rows and y columns, until the three-dimensional tensor is combined into a one-dimensional target vector; and determining a semantic matching degree between the first sentence and the second sentence according to the target vector. In the embodiments of the present invention, sentences to be matched are divided according to a word order into sentence fragments that are based on word vectors, a convolution operation is performed on every two sentence fragments in two sentences, to obtain a three-dimensional tensor, where the three-dimensional tensor includes partial matching information of the sentence fragments among the sentences, and a semantic matching result that is obtained based on the three-dimensional tensor is more accurate.",G06F 17/27; G06F 17/30,HUAWEI TECH CO LTD,LU ZHENGDONG; LI HANG,201410709568 28.11.2014 CN; 2015075670 01.04.2015 CN,
WO2018094294,PCT/US2017/062433,18.11.2017,WO/2018/094294,24.05.2018,WO,SPATIAL ATTENTION MODEL FOR IMAGE CAPTIONING,"The technology disclosed presents a novel spatial attention model that uses current hidden state information of a decoder long short-term memory (LSTM) to guide attention and to extract spatial image features for use in image captioning. The technology disclosed also presents a novel adaptive attention model for image captioning that mixes visual information from a convolutional neural network (CNN) and linguistic information from an LSTM. At each timestep, the adaptive attention model automatically decides how heavily to rely on the image, as opposed to the linguistic model, to emit the next caption word. The technology disclosed further adds a new auxiliary sentinel gate to an LSTM architecture and produces a sentinel LSTM (Sn-LSTM). The sentinel gate produces a visual sentinel at each timestep, which is an additional representation, derived from the LSTM's memory, of long and short term visual and linguistic information.",G06N 3/04,"SALESFORCE.COM, INC.","LU, Jiasen; XIONG, Caiming; SOCHER, Richard","62/424,353 18.11.2016 US; 15/817,153 17.11.2017 US; 15/817,161 17.11.2017 US; 15/817,165 18.11.2017 US",CA-3040165; CN-201780071579.2; EP-2017821750
WO2018174816,PCT/SG2017/050154,24.03.2017,WO/2018/174816,27.09.2018,WO,METHOD AND APPARATUS FOR SEMANTIC COHERENCE ANALYSIS OF TEXTS,"A method, a computer-readable medium, and an apparatus for constructing machine learning based models for semantic text coherence analysis are provided. The apparatus may automatically generate a plurality of tuples based on a text corpus. Each tuple of the plurality of tuples may include a first subject, a second subject, a first subgraph, a second subgraph, and a relationship. For each tuple of the plurality of tuples, the apparatus may normalize the tuple. For each normalized tuple, the apparatus may merge the normalized first subgraph and the normalized second subgraph to obtain a joined pattern. The apparatus may classify the plurality of tuples into a plurality of groups based on the joined pattern of each normalized tuple. For each group of the plurality of groups, the apparatus may train a machine learning based model based on tuples classified into the group.",G06F 17/27,"AGENCY FOR SCIENCE, TECHNOLOGY AND RESEARCH","HU, Shangfeng; KIM, Jung Jae; KANAGASABAI, Rajaraman",,
WO2015148281,PCT/US2015/021624,20.03.2015,WO/2015/148281,01.10.2015,WO,TEMPORAL TRANSLATION GRAMMAR FOR LANGUAGE TRANSLATION,"In language translation and intent understanding scenarios, the automated translation of expressions including temporal elements (e.g., calendar dates, date ranges, times, and durations) may be achieved by an implementation of translation techniques, such as compiled rule sets and/or machine learning recognizers that have been trained with a training set. However, sharing development resources among various implementations may be difficult; e.g., updates that extend a rule set for application of the translation techniques to a new context may be difficult to utilize while updating a machine learning recognizer. Presented herein are techniques for facilitating the development of temporal translation resources by providing a temporal translation grammar, comprising recognition rules that specify the recognition of temporal elements; normalization rules that specify the normalization of recognized temporal elements into normalized temporal elements and temporal intent; and translation rules that translate the normalized temporal elements of an expression into dates in a translated expression.",G06F 17/28; G06F 17/22; G06Q 10/10; G06F 17/27,"MICROSOFT TECHNOLOGY LICENSING, LLC","PROKOFYEV, Andrey; CHENNAI, Selvi","14/225,894 26.03.2014 US",CN-201580016200.9; EP-2015715033
WO2019074185,PCT/KR2018/006509,08.06.2018,WO/2019/074185,18.04.2019,WO,ELECTRONIC APPARATUS AND CONTROL METHOD THEREOF,"An electronic apparatus and method thereof are provided for performing deep learning. The electronic apparatus includes a storage configured to store target data and kernel data; and a processor including a plurality of processing elements that are arranged in a matrix shape. The processor is configured to input, to each of the plurality of processing elements, a first non-zero element from among a plurality of first elements included in the target data, and sequentially input, to each of a plurality of first processing elements included in a first row from among the plurality of processing elements, a second non-zero element from among the plurality of elements included in the kernel data. Each of the plurality of first processing elements is configured to perform an operation between the input first non-zero element and the input second non-zero element, based on depth information of the first non-zero element and depth information of the second non-zero element.",G06N 3/08; G06N 3/04; G06N 3/063,"SAMSUNG ELECTRONICS CO., LTD.","KIM, Kyung-hoon; PARK, Young-hwan; SUH, Dong-kwan; PRASADNAGARAJA, Keshava; KIM, Dae-hyun; KIM, Suk-jin; CHO, Han-su; KIM, Hyun-jung","62/571,599 12.10.2017 US; 10-2018-0022960 26.02.2018 KR",EP-2018866233
WO2018069260,PCT/EP2017/075716,09.10.2017,WO/2018/069260,19.04.2018,WO,DATA SCIENCE VERSIONING AND INTELLIGENCE SYSTEMS AND METHODS,"This disclosure relates to systems and methods for interacting with, controlling, and/or otherwise managing statistical, machine learning, data mining, and/or other predictive methods to produce algorithms for intelligent systems. Various embodiments allow for management of diverse, distributed predictive algorithms via user interfaces and APIs that enable access to configuration, optimization, and/or other activities related to managing computational models in training, production, and/or archival processes. Further embodiments disclosed herein allow for the tracking and/or improvement of models over time.",G06N 99/00,PROEKSPERT AS,"KARPIŠTŠENKO, Andre; PEET, Tanel; LUMISTE, Martin; PUNGAS, Taivo; KUUS, Andrus; SAENKO, Aleksei; MEOS, Peeter","62/406,106 10.10.2016 US",
EP14719822,06021908,19.10.2006,1783629,09.05.2007,EP,Representing a computer system state to a user,"Operations to represent a computer system state to a user include maintaining a model (14) in a computer system (10). The model (14) is updated at times and represents a current state of the computer system (10). The model (14) uses formal-language statements to associate each of several predefined goals (16) with at least one of several predefined actions (18) that can be performed in the computer system (10) to accomplish the associated predefined goal. The operations comprise providing an output to a user regarding the current state of the computer system (10), the output comprising a natural-language statement generated using at least one of the formal-language statements. A statement generating module (20) may include a text planner (202), a grammar (206), a lexicon (208), a translator (204) or a text post-processor (210).",G06F 17/28,SAP AG,KAISER MATTHIAS,26978405 07.11.2005 US,
EP12798897,96302629,15.04.1996,0737928,16.10.1996,EP,Language processing method and apparatus,"A data processing apparatus for generating from a plurality of data units corresponding to a string of elements of a first language, a string of elements of a second language representative of the meaning of the string of elements of the first language. Each data unit is indicative of the meaning of a corresponding element of the first language and includes one or more identifiers related to one or more identifiers of one or more other data units. The generator includes a set of instructions dependent on grammatical rules of the second language, and processing means for providing the elements of the second language in dependence upon the meaning indicated by the data units. The processing means also orders the elements in the string of elements in the second language in dependence upon the meaning indicated by the data units, upon the related identifiers and upon the set of instructions stored. <IMAGE>",G06F 17/27; G06F 17/28; G06F 17/30,CANON KK,VAN DE VEEN EVELYN,9507774 13.04.1995 GB,
EP12439731,93301810,10.03.1993,0560587,15.09.1993,EP,Sign language translation system and method,"A sign language translation system and method not only recognizes words of a sign language but also supplements omitted words between the words of the sign language, to thereby generate a spoken language. The sign language translation system has an input unit (105) for inputting at least the motion of hands, a language generating unit (102) responsive to the inputted motion of hands for recognizing the words corresponding to the motion of hands and generating a spoken language using the relationship between the recognized words, and an output unit (103) for outputting the generated spoken language. The sign language translation system and method can translate a sign language into an easy-to-understand spoken language. <IMAGE>",G06F 15/18; G06F 17/28; G06K 9/00; G06K 9/62; G06K 9/68; G06N 3/00; G06N 99/00; G06T 1/00; G09B 19/06; G09B 21/00; G09B 21/04,HITACHI LTD,ABE MASAHIRO; SAKOU HIROSHI; SAGAWA HIROHIKO; NITIN INDURKHYA,5130092 10.03.1992 JP,
WO2020085796,PCT/KR2019/013988,23.10.2019,WO/2020/085796,30.04.2020,WO,ELECTRONIC DEVICE AND METHOD FOR CONTROLLING ELECTRONIC DEVICE THEREOF,"An electronic device for performing a control operation and a method therefor are provided. The electronic device includes a communication interface, a memory to store at least one command, and at least one processor connected to the communication interface and the memory. The at least one processor is configured to, by executing the at least one command, based on usage information of a first user using the electronic device, establish a first device knowledge base by obtaining a first control condition and a first control operation preferred by a first user, based on a context corresponding to the first control condition being detected, identify whether to perform the first control operation stored in the first device knowledge base based on a basic knowledge base that stores information on the context and information on the electronic device, and based on a result of the identification, control the electronic device.",H04N 21/466; H04N 21/431; G06N 5/02; G06N 5/04,"SAMSUNG ELECTRONICS CO., LTD.","LEE, Jaehun; LEE, Yunsu; HWANG, Taeho; PARK, Jungho; JEONG, Mirae; KANG, Jiyoung",10-2018-0129351 26.10.2018 KR,
WO2019235103,PCT/JP2019/017805,25.04.2019,WO/2019/235103,12.12.2019,WO,"QUESTION GENERATION DEVICE, QUESTION GENERATION METHOD, AND PROGRAM",This invention is characterized by comprising a generation means for receiving input of question text and a related document including an answer to the question text and using a pre-learned machine learning model to generate revised question text wherein a potentially missing portion of the question text is supplemented with words which are included in a prescribed vocabulary set.,G06F 16/90; G06F 16/30; G06F 17/28,NIPPON TELEGRAPH AND TELEPHONE CORPORATION; 日本電信電話株式会社,"OTSUKA, Atsushi; 大塚　淳史; NISHIDA, Kyosuke; 西田　京介; SAITO, Itsumi; 斉藤　いつみ; NISHIDA, Kosuke; 西田　光甫; ASANO, Hisako; 浅野　久子; TOMITA, Junji; 富田　準二",2018-109765 07.06.2018 JP; 2018-214187 14.11.2018 JP,
WO2020002309,PCT/EP2019/066794,25.06.2019,WO/2020/002309,02.01.2020,WO,SYSTEMS AND METHODS FOR TRANSLATING NATURAL LANGUAGE SENTENCES INTO DATABASE QUERIES,"Described systems and methods allow an automatic translation from a natural language (e.g., English) into an artificial language such as a structured query language (SQL). In some embodiments, a translator module includes an encoder component and a decoder component, both components comprising recurrent neural networks. Training the translator module comprises two stages. A first stage trains the translator module to produce artificial language (AL) output when presented with an AL input. For instance, the translator is first trained to reproduce an AL input. A second stage of training comprises training the translator to produce AL output when presented with a natural language (NL) input.",G06F 16/2452; G06F 17/28,BITDEFENDER IPR MANAGEMENT LTD,"TRAIAN, Rebedea; ELENA, Burceanu; FLORIN, Brad","16/020,910 27.06.2018 US",
EP13765448,00971002,19.10.2000,1222655,17.07.2002,EP,NATURAL LANGUAGE INTERFACE CONTROL SYSTEM,"A natural language interface control system (206) for operating a plurality of devices (114) consists of a first microphone array (108), a feature extraction module (202) coupled to the first microphone array, and a speech recognition module (204) coupled to the feature extraction module, wherein the speech recognition module utilizes hidden Markov models. The system also comprises a natural language interface module (222) coupled to the speech recognition module (204) and a device interface (210) coupled to the natural language interface module (222), wherein the natural language interface module is for operating a plurality of devices coupled to the device interface based upon non-prompted, open-ended natural language requests from a user.",G10L 15/22; G06F 17/28; G10L 11/02; G10L 15/00; G10L 15/08; G10L 15/14; G10L 15/18; G10L 15/20; G10L 15/22; G10L 15/28,SONY ELECTRONICS INC,KONOPKA COURTNEY CHARLES; ALMSTRAND LARS CRISTIAN,0029036 19.10.2000 US; 16028199 19.10.1999 US,
WO2018164435,PCT/KR2018/002593,05.03.2018,WO/2018/164435,13.09.2018,WO,"ELECTRONIC APPARATUS, METHOD FOR CONTROLLING THE SAME, AND NON-TRANSITORY COMPUTER READABLE RECORDING MEDIUM","An electronic apparatus is provided. The electronic apparatus includes an input interface configured to receive a user command, a memory, a display configured to display a content, and a processor configured, in response to a predetermined command with respect to the content being received through the input interface, to acquire context information of the content by analyzing the content, to store the context information together with the information relating to the content in the memory, and in response to a context corresponding to the context information being detected, to control the display to provide a content corresponding to the detected context. At least some of a method for controlling the electronic apparatus may use a rules-based model or an artificial intelligence model which is trained according to at least one of a machine learning, a neural network, and a deep learning algorithm. For example, the artificial intelligence model may provide context information, which is a result of determination using a content as an input value, to the electronic apparatus.",G06F 17/30,"SAMSUNG ELECTRONICS CO., LTD.","AHN, Hyoung-joo",10-2017-0029490 08.03.2017 KR; 10-2017-0145925 03.11.2017 KR,EP-2018764090
WO2010042452,PCT/US2009/059576,05.10.2009,WO/2010/042452,15.04.2010,WO,MACHINE LEARNING FOR TRANSLITERATION,"Methods, systems, and apparatus, including computer program products, for automatically identifying transliteration pairs are disclosed. In one implementation, a method is provided. The method includes receiving a plurality of resources, the plurality of resources including a plurality of anchor text; determining one or more potential transliterations from the plurality of anchor text; and identifying one or more potential transliteration pairs from the one or more potential transliterations, where each potential transliteration pair includes a first anchor text in a first writing system and a second anchor text in a second writing system, the second anchor text and the first anchor text identifying a same resource or location.",G06F 17/28; G06F 17/00,"GOOGLE INC.; BILAC, Slaven; ICHIKAWA, Hiroshi","BILAC, Slaven; ICHIKAWA, Hiroshi","61/104,692 10.10.2008 US; 12/357,269 21.01.2009 US",JP-2011531101; KR-1020117008322; CN-200980148103.X
WO2019082166,PCT/IB2018/058411,26.10.2018,WO/2019/082166,02.05.2019,WO,UNIT-LEVEL UNCERTAINTY AND PROPAGATION,"Neural Networks such as Deep Neural Networks (DNNs) output calibrated probabilities that substantially represent frequencies of occurrences of events. A DNN propagates uncertainty information of a unit of the DNN from an input to an output of the DNN. The uncertain information measures a degree of consistency of the test data with training data used to train a DNN. The uncertainty information of all units of the DNN can be propagated. Based on the uncertainty information, the DNN outputs probability scores that reflect received input data that is substantially different from the training data.",G06N 3/08; G06N 3/04,"UBER TECHNOLOGIES, INC.","GHAHRAMANI, Zoubin","62/577,631 26.10.2017 US",
EP281666901,19182892,26.03.2018,3594813,15.01.2020,EP,COMPUTE OPTIMIZATIONS FOR LOW PRECISION MACHINE LEARNING OPERATIONS,,G06F 9/50; G06F 9/30; G06F 9/38; G06N 3/04; G06N 3/063; G06N 3/08; G06T 1/20; G06T 15/00,INTEL CORP,OULD-AHMED-VALL ELMOUSTAPHA; BAGHSORKHI SARA S; YAO ANBANG; NEALIS KEVIN; CHEN XIAOMING; KOKER ALTUG; APPU ABHISHEK R; WEAST JOHN C; MACPHERSON MIKE B; KIM DUKHWAN; HURD LINDA L; ASHBAUGH BEN J; LAKSHMANAN BARATH; MA LIWEI; RAY JOYDEEP; TANG PING T; STRICKLAND MICHAEL S,18164092 26.03.2018 EP; 201715581167 28.04.2017 US,
WO1998000794,PCT/US1997/011029,25.06.1997,WO/1998/000794,08.01.1998,WO,IDENTIFICATION OF WORDS IN JAPANESE TEXT BY A COMPUTER SYSTEM,"A word breaking facility operates to identify words within a Japanese text string. The word breaking facility performs morphological processing to identify postfix bound morphemes and prefix bound morphemes. The word breaking facility also performs opheme matching to identify likely stem characters. A scoring heuristic is applied to determine an optimal analysis that includes a postfix analysis, a stem analysis, and a prefix analysis. The morphological analyses are stored in an efficient compressed format to minimize the amount of memory they occupy and maximize the analysis speed. The morphological analyses of postfixes, stems, and prefixes are performed in a right-to-left fashion. The word breaking facility may be used in applications that demand identity of selection granularity, autosummarization applications, content indexing applications, and natural language processing applications.",G06F 17/27; G06F 17/28,MICROSOFT CORPORATION,"HALSTEAD, Patrick, H., Jr.; SUZUKI, Hisami","08/672,638 28.06.1996 US",CN-97195935.8; EP-1997931394
WO2015161129,PCT/US2015/026252,16.04.2015,WO/2015/161129,22.10.2015,WO,AUTOMATIC TOPIC DISCOVERY IN STREAMS OF UNSTRUCTURED DATA,"A method is provided for automatically discovering topics in electronic posts, such as social media posts. The method includes receiving a corpus that includes a plurality of electronic posts. The method further includes identifying a plurality of candidate terms within the corpus and selecting, as a trimmed lexicon, a subset of the plurality of candidate terms using predefined criteria. The method further includes clustering at least a subset of the plurality of electronic posts according to a plurality of clusters using the lexicon to produce a plurality of statistical topic models. The method further includes storing information corresponding to the statistical topic models.",G06F 17/28; G06F 17/27,"UDA, LLC","WEISSINGER, Steve; STEVENS, Luis; SCHIAVONE, Vincent","14/688,865 16.04.2015 US; 61/980,525 16.04.2014 US",EP-2015780371
EP231575400,18159604,01.03.2018,3385844,10.10.2018,EP,NEURAL NETWORK SCHEDULING MECHANISM,"An apparatus to facilitate workload scheduling is disclosed. The apparatus includes one or more clients, one or more processing units to processes workloads received from the one or more clients, including hardware resources and scheduling logic to schedule direct access of the hardware resources to the one or more clients to process the workloads.",G06F 9/50; G06N 3/02,INTEL CORP,MA LIWEI; SATISH NADATHUR RAJAGOPALAN; BOTTLESON JEREMY; AKHBARI FARSHAD; NURVITADHI ERIKO; SAKTHIVEL CHANDRASEKARAN; LAKSHMANAN BARATH; JIN JINGYI; GOTTSCHLICH JUSTIN E; STRICKLAND MICHAEL,201715482793 09.04.2017 US,
WO2018071403,PCT/US2017/055909,10.10.2017,WO/2018/071403,19.04.2018,WO,SYSTEMS AND METHODS FOR OPTICAL CHARATER RECOGNITION FOR LOW-RESOLUTION DUCUMENTS,"Systems and methods for optical character resolution (OCR) at low resolutions are provided. The system receives a dataset and extracts document images from the dataset. The system then segments and extracts a plurality of text lines from the document images. The system then processes the plurality of text lines using a Recurrent Neural Network (RNN) with Long Short Term Memory (LSTM) module to perform line OCR. Finally, the system generates a plurality of text strings corresponding to the plurality of text lines.",G06F 9/45,"INSURANCE SERVICES OFFICE, INC.","WANG, Shuai; SIGH, Maneesh Kumar","62/406,665 11.10.2016 US; 62/406,272 10.10.2016 US",
WO2018090013,PCT/US2017/061562,14.11.2017,WO/2018/090013,17.05.2018,WO,SYSTEM AND METHOD OF CHARACTER RECOGNITION USING FULLY CONVOLUTIONAL NEURAL NETWORKS WITH ATTENTION,Embodiments of the present disclosure include a method that obtains a digital image. The method includes extracting a word block from the digital image. The method includes processing the word block by evaluating a value of the word block against a dictionary. The method includes outputting a prediction equal to a common word in the dictionary when a confidence factor is greater than a predetermined threshold. The method includes processing the word block and assigning a descriptor to the word block corresponding to a property of the word block. The method includes processing the word block using the descriptor to prioritize evaluation of the word block. The method includes concatenating a first output and a second output. The method includes predicting a value of the word block.,G06K 9/00; G06K 9/34; G06K 9/46,KODAK ALARIS INC.,"SUCH, Felipe Petroski; PTUCHA, Raymond; BROCKLER, Frank; HUTKOWSKI, Paul","62/422,000 14.11.2016 US; 62/524,983 26.06.2017 US; 15/709,014 19.09.2017 US; 15/708,918 19.09.2017 US",EP-2017809110; CN-201780080467.3
WO2001037126,PCT/US2000/041831,03.11.2000,WO/2001/037126,25.05.2001,WO,A SYSTEM AND METHOD FOR JOINT OPTIMIZATION OF LANGUAGE MODEL PERFORMANCE AND SIZE,"A method for the joint optimization of language model performance and size is presented comprising developing a language model from a tuning set of information, segmenting at least a subset of a received textual corpus and calculating a perplexity value for each segment and refining the language model with one or more segments of the received corpus bases, at least in part, on the calculated perplexity value for the one or more segments.",G06F 17/27; G06F 17/28,MICROSOFT CORPORATION,"GAO, Jianfeng; LEE, Kai-Fu; LI, Mingjing; WANG, Hai-Feng; CAI, Dong-Feng; CHIEN, Lee-Feng","60/163,851 05.11.1999 US; 09/607,786 30.06.2000 US",
WO2019059579,PCT/KR2018/010748,13.09.2018,WO/2019/059579,28.03.2019,WO,DEVICE AND METHOD FOR PROVIDING RESPONSE TO DEVICE USAGE INQUIRY,"Provided are a device for providing a response operation corresponding to a device usage inquiry and a method of controlling the device. The method of controlling a device for providing a response operation corresponding to a device usage inquiry may include: receiving a user input corresponding to the device usage inquiry; classifying the device usage inquiry by analyzing the received user input corresponding to the device usage inquiry; extracting operation scenario information corresponding to a result of the classifying the device usage inquiry; and executing preset response operations of the device based on the operation scenario information, wherein the classifying includes classifying the device usage inquiry by inputting the user input of the device usage inquiry to a learning model that is a pre-generated.",G06F 9/451; G06N 3/08,"SAMSUNG ELECTRONICS CO., LTD.","JEONG, Man-un; JO, Seo-young; CHOI, Chang-hwan",10-2017-0120511 19.09.2017 KR,EP-2018859583
WO2018119145,PCT/US2017/067727,20.12.2017,WO/2018/119145,28.06.2018,WO,ACCENT TRANSLATION,"Techniques for accent translation are described herein. A plurality of audio samples may be received, and each of the plurality of audio samples may be associated with at least one of a plurality of accents. Audio samples associated with at least a first accent of the plurality of accents may be compared to audio samples associated with at least one other accent of the plurality of accents. A translation model between the first accent and a second accent may be generated. An input audio portion in a first spoken language may be received. It may be determined whether the input audio portion is substantially associated with the first accent, and if so, an output audio portion substantially associated with the second accent in the first spoken language may be outputted based, at least in part, on the translation model.",G10L 15/00; G06F 17/28; G10L 13/10,"AMAZON TECHNOLOGIES, INC.","DIRAC, Leo, Parker; MOERCHEN, Fabian; LIBERTY, Edo","15/387,038 21.12.2016 US",KR-1020197021381; EP-2017829859; CN-201780079074.0
EP248884919,17866051,26.10.2017,3511899,17.07.2019,EP,"IMAGE PROCESSING APPARATUS, IMAGE PROCESSING METHOD, AND COMPUTER-READABLE RECORDING MEDIUM",An image processing apparatus is disclosed. The present image processing apparatus comprises: an input unit to which an image is input; and a processor which extracts visual characteristics by reducing an input image and generates a high-definition image by reflecting extracted visual characteristics on the input image. The present disclosure relates to an artificial intelligence (AI) system and application thereof that simulate functions such as cognition and decision-making of a human brain using a machine learning algorithm such as deep learning.,G06T 3/40; G06T 5/50,SAMSUNG ELECTRONICS CO LTD,AHN IL-JUN; NAM WOO-HYUN; CHO KI-HEUM; PARK YONG-SUP; LEE TAMMY; CHEON MIN-SU,20160140237 26.10.2016 KR; 2017011932 26.10.2017 KR,
EP291937941,18843146,11.07.2018,3629238,01.04.2020,EP,METHOD AND APPARATUS FOR RECOGNIZING OBJECT,"The present disclosure relates to an artificial intelligence (AI) system for simulating functions of a human brain such as cognition and decision-making by using machine learning algorithms such as deep learning, and applications thereof. In particular, the present disclosure provides a method of recognizing an object by using an AI system and its application, including: extracting pieces of first feature information respectively regarding a plurality of images, each image including an object; generating at least one piece of second feature information representing a correlation between the plurality of images by combining together the extracted pieces of first feature information respectively regarding the plurality of images; and recognizing, based on the at least one piece of second feature information, the object included in each of the plurality of images by using a pre-generated learning network model.",G06K 9/20; G06K 9/46; G06K 9/62; G06N 3/08,SAMSUNG ELECTRONICS CO LTD,JUNG HYUN-JOO; LEE GUN-HEE; CHOI IN-KWON; KIM SUNG-JIN; CHOI HYUN-SOO,20170100514 08.08.2017 KR; 2018007828 11.07.2018 KR,
WO2002039318,PCT/US2000/042120,09.11.2000,WO/2002/039318,16.05.2002,WO,USER ALTERABLE WEIGHTING OF TRANSLATIONS,"In one aspect, the invention relates to a method of allowing a user to view and modify a weighting associated with a  translation of a source language string. The method includes displaying to the user the weighting associated with the translation of the source language string, the weighting for use by a translation engine in selecting the translation and allowing the usr to modify the weighting associated with the translation. In one embodiment, the method further includes allowing the user to reset the weighting back to a default value subsequent to user modification of the weighting.",G06F 17/28,"LOGOVISTA CORPORATION; PRINGLE, Lewis, G.; SWERDLOW, Robert, W.; WYSOKER, Alec; WRIGHT, Sterling","PRINGLE, Lewis, G.; SWERDLOW, Robert, W.; WYSOKER, Alec; WRIGHT, Sterling",,JP-2002541571
EP11029200,09151293,04.02.2000,2085963,05.08.2009,EP,System and method for bilateral communication between a user and a system,"A method for a human machine communication system that includes the steps of receiving a first statement in a natural language from a user, generating first information based on the statement and storing context information of at least one of the first statement and the first information. The method also includes the steps of optionally generating a question to be presented to the user in the natural language based on the context information, receiving a second statement in the natural language from the user and generating second information based on the second statement and the context information.",G06F 17/28; G10L 15/18; G10L 13/00; G10L 13/08; G10L 15/00; G10L 15/22,SOLQUE SOFTWARE LTD LIABILITY,LUCENTE MARK; POLISH NATHANIEL,00914516 04.02.2000 EP; 11880099 04.02.1999 US; 49572200 01.02.2000 US,
WO2018090011,PCT/US2017/061556,14.11.2017,WO/2018/090011,17.05.2018,WO,SYSTEM AND METHOD OF CHARACTER RECOGNITION USING FULLY CONVOLUTIONAL NEURAL NETWORKS,"Embodiments of the present disclosure include a method for extracting symbols from a digitized object. The method includes processing the word block against a dictionary. The method includes comparing the word block against a word in the dictionary, the comparison providing a confidence factor. The method includes outputting a prediction equal to the word when the confidence factor is greater than a predetermined threshold. The method includes evaluating properties of the word block when the confidence factor is less than the predetermined threshold. The method includes predicting a value of the word block based on the properties of the word block. The method further includes determining an error rate for the predicted value of the word block. The method includes outputting a value for the word block, the output equal to a calculated value corresponding to a value of the word block having the lowest error rate.",G06K 9/00; G06K 9/34; G06K 9/46,KODAK ALARIS INC.,"SUCH, Felipe Petroski; PTUCHA, Raymond; BROCKLER, Frank; HUTKOWSKI, Paul; SINGH, Vatsala","62/422,000 14.11.2016 US; 62/524,983 26.06.2017 US; 15/709,014 19.09.2017 US; 15/708,918 19.09.2017 US",CN-201780080468.8; EP-2017809109
WO2010051966,PCT/EP2009/007868,03.11.2009,WO/2010/051966,14.05.2010,WO,METHOD FOR SEMANTIC PROCESSING OF NATURAL LANGUAGE USING GRAPHICAL INTERLINGUA,"A method for processing natural language using a language processing system is described herein. Written or spoken text is input to the language processing system. The method includes the step of analysing the text syntactically. Next a step of extracting components of the text and their relation to each other within the text follows. A graph or graphical representation of the text is generated or used as a language independent representation of the meaning of the text. This graph or graphical representation is used to perform modelling, knowledge representation and processing at the language processing system. Further a system for processing natural language and a method of developing a language processing system are described.",G06F 17/27; G06F 17/28,"LINGUPEDIA INVESTMENTS SARL; MENDE, Michael","MENDE, Michael","08019498.8 07.11.2008 EP; 12/267,461 07.11.2008 US",CN-200980153796.1; RU-2011122784; IN-2370/KOLNP/2011
WO2010002286,PCT/RO2009/000006,17.06.2009,WO/2010/002286,07.01.2010,WO,METHOD AND SYSTEM FOR INTERLINGUA-BASED MACHINE TRANSLATION,"The target of proposed invention is intended to create for computers the ability to understand like human and to use that ability for plurality of applications. The invention presents the components and the functioning of a system which model the human understanding for messages, one of components being the knowledge base. Using the model for understanding the invention present a method of communication between persons, persons and apparatus, apparatus through which the method uses the understanding for transform the messages in special messages called content expressions, those being the way of communication. The communication follow a scheme Expression_ message 1 - (understanding) -> content _expression -(generating) -> expression_ message 2 The understanding is modeled like an ensemble of pattern recognition processes, a set of tools, which are used appropriate with the message which is supposed to be understood. The way in which are used that tools collection is subject of training using as model human education system which is intended, among other, to develop the ability to recognize and to understand notions and concepts classified on school courses and grades. The invention presents the way in which the knowledge base is developed step by step, derived from messages, how parts from the knowledge base can be cut for serving a user or to be used for a studding a subject. Also it is presented a personal apparatus for the communication assisting, apparatus which can assure the communication with persons and apparatus in the conditions which between the user and apparatus is developed and improved a personalized stable interface that can facilitate communication with a large variety of persons and apparatus. Through the development of the computer understands ability is it expected that those to be capable to training from book manuals, documents destined to the human. The indexing and Internet search is expected to be changed from the indexing words and phrase to indexing content and to search for content an ideas.",G06F 17/28,"TOMA, Mihu Mircea","TOMA, Mihu Mircea",a 2008 00513 02.07.2008 RO,
EP291937793,18197073,27.09.2018,3629105,01.04.2020,EP,HIGH-LEVEL DECISION MAKING FOR SAFE AND REASONABLE AUTONOMOUS LANE CHANGING USING REINFORCEMENT LEARNING,"An aspect of the invention describes a system for training an artificial intelligence unit for an automated vehicle, with said artificial intelligence unit comprising a knowledge configuration, with said artificial intelligence unit determining or reading out an evaluation value for at least two motion actions for the automated vehicle considering an input state and considering the knowledge configuration, said input state characterizing the automated vehicle and/or its environment, said system configured to determine for each of the at least two motions actions whether the respective motion action is to be filtered out considering the input state; select one motion action from the set of motion actions, which are not to be filtered out of the at least two motion actions, considering the evaluation value of the respective motion actions; and train the artificial intelligence unit by adapting the knowledge configuration of the artificial intelligence unit considering the selected motion action.",G05B 13/02,BAYERISCHE MOTOREN WERKE AG,MIRCHEVSKA BRANKA; PEK CHRISTIAN; DR WERLING MORITZ,18197073 27.09.2018 EP,
WO2017223010,PCT/US2017/038210,20.06.2017,WO/2017/223010,28.12.2017,WO,END-TO-END MEMORY NETWORKS FOR CONTEXTUAL LANGUAGE UNDERSTANDING,"A processing unit can extract salient semantics to model knowledge carryover, from one turn to the next, in multi-turn conversations. Architecture described herein can use the end-to-end memory networks to encode inputs, e.g., utterances, with intents and slots, which can be stored as embeddings in memory, and in decoding the architecture can exploit latent contextual information from memory, e.g., demographic context, visual context, semantic context, etc. e.g., via an attention model, to leverage previously stored semantics for semantic parsing, e.g., for joint intent prediction and slot tagging. In examples, architecture is configured to build an end-to-end memory network model for contextual, e.g., multi-turn, language understanding, to apply the end-to-end memory network model to multiple turns of conversational input; and to fill slots for output of contextual, e.g., multi-turn, language understanding of the conversational input. The neural network can be learned using backpropagation from output to input using gradient descent optimization.",G10L 15/18; G10L 15/16; G10L 15/22,"MICROSOFT TECHNOLOGY LICENSING, LLC","CHEN, Yun-Nung; HAKKANI-TUR, Dilek, Z.; TUR, Gokhan; DENG, Li; GAO, Jianfeng","62/354,076 23.06.2016 US; 15/229,039 04.08.2016 US",
WO2017066851,PCT/AU2016/095007,21.10.2016,WO/2017/066851,27.04.2017,WO,INFERENCING LEARNING AND UTILISATION SYSTEM AND METHOD,"An automatic system and method for the performance of scientific inferencing including the determination of a null hypothesis significance testing on an interactive computer system, the method including the steps of: (a) providing for the input of an input description of a proposed hypothesis test, the input description including a number of relevant input parameters; (b) utilising the computational system for processing the input description into a null hypothesis significance test; (c) executing the null hypothesis significance test on the computational system; and (d) visually displaying the results of the execution.",G06N 5/04; G06F 17/28,"MONSON, Ronald Christopher","MONSON, Ronald Christopher",2015904318 21.10.2015 AU,EP-2016856506; US-15769530; AU-2016343300
WO2019015889,PCT/EP2018/065786,14.06.2018,WO/2019/015889,24.01.2019,WO,AUTOMATIC CLASSIFICATION AND TRANSLATION OF WRITTEN SEGMENTS,"A translation server computer and related methods are described. The translation server computer is programmed or configured to create computer-implemented techniques for classifying segments in a source language as non-translatable into a target language, nearly-translatable into the target language, or otherwise, and for generating translations in the target language for the segments classified as nearly-translatable. The translation server computer is further programmed or configured to apply the computer-implemented techniques on an input document to generate a classification and a translation when appropriate for each segment in the document, and cause a user computer to display the translations and classifications.",G06F 17/28; G06F 17/27; G06N 3/04; G06N 3/08,MEMSOURCE A.S.,"ČANĚK, David; FRÍVALDSKÝ, Dalibor; TAMCHYNA, Aleš","15/657,065 21.07.2017 US",
EP232545705,18163725,23.03.2018,3396544,31.10.2018,EP,EFFICIENT SHARING AND COMPRESSION OF DATA ACROSS PROCESSING SYSTEMS,"A mechanism is described for facilitating sharing of data and compression expansion of models at autonomous machines. A method of embodiments, as described herein, includes detecting a first processor processing information relating to a neural network at a first computing device, where the first processor comprises a first graphics processor and the first computing device comprises a first autonomous machine. The method further includes facilitating the first processor to store one or more portions of the information in a library at a database, where the one or more portions are accessible to a second processor of a computing device.",G06F 9/50; G06N 3/02,INTEL CORP,APPU ABHISHEK R; KOKER ALTUG; WEAST JOHN C; MACPHERSON MIKE B; KIM DUKHWAN; HURD LINDA L; BAGHSORKHI SARA S; GOTTSCHLICH JUSTIN E; SURTI PRASOONKUMAR; SAKTHIVEL CHANDRASEKARAN; RAY JOYDEEP,201715495081 24.04.2017 US,
WO2019051658,PCT/CN2017/101502,13.09.2017,WO/2019/051658,21.03.2019,WO,INCREMENTAL NETWORK QUANTIZATION,"Methods and apparatus relating to techniques for incremental network quantization. In an example, an apparatus comprises logic, at least partially comprising hardware logic to partition a plurality of model weights in a deep neural network (DNN) model into a first group of weights and a second group of weights, convert each weight in the first group of weights to a power of two, and repeatedly retrain the DNN model while converting a subset of weights in the second group to a power of two or zero. Other embodiments are also disclosed and claimed.",G06N 3/04,"INTEL CORPORATION; CHEN, Yurong; YAO, Anbang; XU, Lin; GUO, Yiwen; ZHOU, Aojun","CHEN, Yurong; YAO, Anbang; XU, Lin; GUO, Yiwen; ZHOU, Aojun",,
EP11130064,08019498,07.11.2008,2184685,12.05.2010,EP,Method for semantic processing of natural language using graphical interlingua,"A method for processing natural language using a language processing system is described herein. Written or spoken text is input to the language processing system. The method includes the step of analysing the text syntactically. Next a step of extracting components of the text and their relation to each other within the text follows. A graph or graphical representation of the text is generated or used as a language independent representation of the meaning of the text. This graph or graphical representation is used to perform modelling, knowledge representation and processing at the language processing system.",G06F 17/27; G06F 17/28,LINGUPEDIA INVEST SARL,MENDE MICHAEL,08019498 07.11.2008 EP,
EP12672956,95302110,29.03.1995,0676704,11.10.1995,EP,Training apparatus and methods.,"Apparatus and methods for training classifiers. The apparatus includes a degree of certainty classifier which classifies examples in categories and indicates a degree of certainty regarding the classification and an annotating classifier which receives classified examples with a low degree of certainty from the degree of certainty classifier and annotates them to indicate whether their classifications are correct. The annotated examples are then used to train another classifier. In one version of the invention, the other classifier is a new version of the degree of certainty classifier, and training continues until the degree of certainty classifier has satisfactory performance. The degree of certainty classifier of the embodiment is a probabilistic binary classifier which is trained using relevance feedback. The annotating classifier may include an interactive interface which permits a human user of the system to examine an example and indicate whether it was properly classified.",G06F 17/28; G06F 17/27; G06F 15/18; G06F 17/30,AT & T CORP,CATLETT JASON A; GALE WILLIAM ARTHUR; LEWIS DAVID DOLAN,22459994 07.04.1994 US,
WO2015018430,PCT/EP2013/066391,05.08.2013,WO/2015/018430,12.02.2015,WO,METHOD FOR ASSESSING FREE TEXT INPUT,"The invention pertains to a Method for assessing free text input, comprising the steps of: receiving a free text input, analysing the free text input using a first analysing method leading to a first rating, analysing the free text input using a second analysing method leading to a second rating, whereby said analysing methods may be statistical methods and/or regular expression based. A common rating is determined based on a weighted first rating and weighted second rating, whereby the weighting of the first rating and the second rating is predetermined. The method may be applied within a teaching environment as part of an automatic assessment system.",G06F 17/27; G06F 17/28,UNIVERSITÄT DUISBURG-ESSEN,"GOEDICKE, Michael; FILIPCZYK, Martin; STRIEWE, Michael",,
WO2008146583,PCT/JP2008/058539,08.05.2008,WO/2008/146583,04.12.2008,WO,"DICTIONARY REGISTERING SYSTEM, DICTIONARY REGISTERING METHOD, AND DICTIONARY REGISTERING PROGRAM","A dictionary registering system for enabling the user to register a word in a user dictionary while alleviating the adverse effect even if the word may have an adverse effect on natural language processing. The dictionary registering system comprises a data processing device for implementing natural language processing by managing/using a user dictionary and a storage device holding system dictionary information and user dictionary information used for the natural language processing. The dictionary registering system is used for natural language processing using the user dictionary. The storage device includes the system dictionary information used for natural language processing and the user dictionary. The data processing device has word information registering means for registering information on the inputted word in the user dictionary, difference creating means for creating the difference between a first processing result of the natural language processing using the system dictionary information and a second processing result of the natural language processing using the system dictionary information and the user dictionary information, a correctness/error receiving means for receiving judgment on correctness/error whether the change from the first processing result to the second processing result which corresponds to the difference is correct or wrong, and dictionary registering means for registering in the user dictionary the received word registering information and a part or all of a combination of the received correctness/error and the input sentence from which the difference giving the correctness/error is created.",G06F 17/28,"NEC CORPORATION; 日本電気株式会社; SADAMASA, Kunihiko; 定政 邦彦; ANDO, Shinichi; 安藤 真一","SADAMASA, Kunihiko; 定政 邦彦; ANDO, Shinichi; 安藤 真一",2007-136660 23.05.2007 JP,US-12601486; JP-2009516236
WO2002103555,PCT/GB2002/002742,12.06.2002,WO/2002/103555,27.12.2002,WO,COMPUTER SYSTEM WITH NATURAL LANGUAGE TO MACHINE LANGUAGE TRANSLATOR,Presented is a system and method for converting or translating expressions in a natural language such as English into machine executable expression in a formal language. This translation enables a transformation from the syntactic structures of a natural language into effective algebraic forms for further exact processing. The invention utilizes algorithms employing a reduction of sequences of terms defined over an extensible lexicon into formal syntactic and semantic structures. This term reduction incorporates both syntactic type and semantic context to achieve an effective formal representation and interpretation of the meaning conveyed by any natural language expression.,G06F 17/28,"PIPEDREAM METASYSTEMS, INC.; MANSON, Keith, S.; HOWE, Steven","MANSON, Keith, S.","09/883,693 18.06.2001 US",JP-null; EP-2002732949
WO2019159130,PCT/IB2019/051250,15.02.2019,WO/2019/159130,22.08.2019,WO,SYSTEM FOR CLASSIFYING THE USAGE OF A HANDHELD CONSUMER DEVICE,"The present disclosure is concerned with a system for classifying the usage of a handheld consumer device, the system having a movable handheld consumer device, the consumer device having a sensor unit for determining usage data at successive time instants, the sensor unit being arranged for providing a temporally successive sequence of at least one usage data during a usage session, and an analyzing device being arranged for classifying the usage of the consumer device with respect to at least one set of at least two usage classes relating to different usage properties, the analysis device being arranged for assembling a temporally successive sequence of input tuples of usage data relating to a predetermined time period of the usage session, each of the input tuples having at least one element representing the usage data at the respective time instant, and for inputting the sequence of input tuples into at least one artificial neural network that is arranged to output at least one output tuple that comprises a number of elements in accordance with the number of usage classes, each element of the output tuple representing a prediction value that the usage of the consumer device at the given time instant relates to a respective usage class.",G06K 9/00; G06K 9/62,BRAUN GMBH,"SHERMAN, Faiz, Feisal; MAO, Xiaole",18157358.5 19.02.2018 EP; 18157362.7 19.02.2018 EP,
EP250876576,19157587,15.02.2019,3528172,21.08.2019,EP,SYSTEM FOR CLASSIFYING THE USAGE OF A HANDHELD CONSUMER DEVICE,"The present disclosure is concerned with a system for classifying the usage of a handheld consumer device, the system having a movable handheld consumer device, the consumer device having a sensor unit for determining usage data at successive time instants, the sensor unit being arranged for providing a temporally successive sequence of at least one usage data during a usage session, and an analyzing device being arranged for classifying the usage of the consumer device with respect to at least one set of at least two usage classes relating to different usage properties, the analysis device being arranged for assembling a temporally successive sequence of input tuples of usage data relating to a predetermined time period of the usage session, each of the input tuples having at least one element representing the usage data at the respective time instant, and for inputting the sequence of input tuples into at least one artificial neural network that is arranged to output at least one output tuple that comprises a number of elements in accordance with the number of usage classes, each element of the output tuple representing a prediction value that the usage of the consumer device at the given time instant relates to a respective usage class.",G06K 9/00; G06K 9/62,BRAUN GMBH,SHERMAN FAIZ FEISAL; MAO XIAOLE,18157358 19.02.2018 EP; 18157362 19.02.2018 EP,
WO2015028844,PCT/IB2013/058131,29.08.2013,WO/2015/028844,05.03.2015,WO,TEXT GENERATION FROM CORRELATED ALERTS,"Methods, apparatuses, and computer program products are described herein that are configured to generate an operator text in response to an alarm that is either received from an alarm or alert system or that is self-generated based on an analysis of one or more data feeds. The method of an example embodiment may include determining whether an operator text is to be generated in response to a received alert condition by performing data analysis operations comprising: analyzing, using a processor, a primary data feed and at least one confirmatory data feed to identify one or more features; and determining based on the detection of a feature in the primary data feed or the at least one confirmatory data feed satisfies at least one predetermined constraint. The method may further include generating an output text that is displayable in a user interface that describes at least a diagnosis for the feature that satisfied that at least one predetermined constraint.",G06F 17/28; A61B 5/024,ARRIA DATA2TEXT LIMITED,"REITER, Ehud B.; LOGAN, Alasdair; ALVAREZ, Lucia Ortega; APEH, Edward; LIBMAN, Bracha; BRADSHAW, William",,US-14914461
WO2019015633,PCT/CN2018/096238,19.07.2018,WO/2019/015633,24.01.2019,WO,SYSTEMS AND METHODS FOR PROCESSING A CONVERSATION MESSAGE,The present disclosure is related to systems and methods for processing a conversation message. The method includes receiving the conversation message from the client terminal via the data exchange port. The method also includes determining whether the conversation message is associated with at least one pre-set topic category. The method also includes determining a topic category associated with the conversation message based on a prior conversation message in response to a determination that the conversation message is not associated with at least one pre-set topic category. The method further includes determining a semantics associated with the conversation message based on the topic category and the conversation message. The method still further includes generating a response to the conversation message based on the determined semantics to be transmitted to the service system implemented on the client terminal via the data exchange port.,G06F 17/28,"BEIJING DIDI INFINITY TECHNOLOGY AND DEVELOPMENT CO., LTD.","WANG, Yu; YE, Zhou; ZHANG, Duokun; LI, Min; LEI, Hui; GUO, Rui",201710590119.2 19.07.2017 CN,EP-2018835324
EP14215602,02786125,17.12.2002,1469398,20.10.2004,EP,TEXT GENERATING METHOD AND TEXT GENERATOR,"The present invention provides method and apparatus for generating a natural text from at least one keyword. The keyword is input by a keyword input unit, and a text and phrase searching and extracting unit extracts any text or phrase containing keywords, if any. A text generation unit morphologically analyzes and parses the extracted text, and outputs a natural text by combining the text with the keyword. <IMAGE>",G06F 17/27; G06F 17/28,NAT INST INF & COMM TECH,UCHIMOTO KIYOTAKA; ISAHARA HITOSHI,0213185 17.12.2002 JP; 2001395618 27.12.2001 JP,
EP30783185,11004802,23.09.2005,2388710,23.11.2011,EP,Scoring word order in a target dependency structure,"In one embodiment of the present invention, a decoder receives a dependency tree as a source language input and accesses a set of statistical models that produce outputs combined in a log linear framework. The decoder also accesses a table of treelet translation pairs and returns a target dependency tree based on the source dependency tree, based on access to the table of treelet translation pairs, and based on the application of the statistical models.",G06F 17/28,MICROSOFT CORP,QUIRK CHRISTOPHER B; MENEZES ARUL A; CHERRY COLIN A,05108799  ; 14108  ; 14152  ; 14492  ; 14503  ; 625489 P  ; EP20050108799  ; US20040014108  ; US20040014152  ; US20040014492  ; US20040014503  ; US20040625489P  ; 05108799 23.09.2005 EP; 1410804 16.12.2004 US; 1415204 16.12.2004 US; 1449204 16.12.2004 US; 1450304 16.12.2004 US; 62548904 04.11.2004 US,
WO2000045290,PCT/US1999/029093,07.12.1999,WO/2000/045290,03.08.2000,WO,A METHOD AND APPARATUS FOR ADAPTIVE SPEECH RECOGNITION HYPOTHESIS CONSTRUCTION AND SELECTION IN A SPOKEN LANGUAGE TRANSLATION SYSTEM,"A method and apparatus for adaptive speech recognition hypothesis are provided, wherein a number of ordered recognition hypotheses are generated and presented in response to a received speech input comprising natural spoken language. Generation of the recognition hypotheses comprises assigning (408) basic probabilities to at least one basic component of the speech input using language models and calculating (410) an overall probability of each of the recognition hypotheses using the assigned basic probabilities. The best hypothesis is selected (1802) by a user from the recognition hypotheses. Hypothesis generation is adapted (1810) in response to the selected best hypotheses, wherein the selected hypothesis is analyzed, a list comprising the basic components of the selected best hypothesis and the assigned basic probabilities is generated, credit is assigned to the basic components of the selected hypothesis by raising the assigned basic probabilities, and the basic probabilities of the language model are renormalized. An output is provided (306) comprising the best hypothesis; moreover, the input is translated in response to the selected best hypothesis, and a synthesized translated speech output is provided.",G06F 17/28; G10L 15/06,"SONY ELECTRONICS, INC.","FRANZ, Alexander, M.; HORIGUCHI, Keiko","09/239,643 29.01.1999 US",
WO2012145782,PCT/AU2011/000483,27.04.2011,WO/2012/145782,01.11.2012,WO,GENERIC SYSTEM FOR LINGUISTIC ANALYSIS AND TRANSFORMATION,"A system providing a set of natural language processing functionalities, such as named entity extraction, domain extraction, sense disambiguation, automatic translation between different natural languages, morphological analysis, tokenization, via a unified process of analysis and transformation, using underlying linguistic database. The invention can accept text input and can be used to translate text, find out the correct sense of a word, obtain the main subject of a text, obtain the grammatical attributes of a word, paraphrase a text, and search for specific entities within the input text.",G06F 17/28; G06F 17/21; G06F 17/27,"BERMAN, Vadim; DIGITAL SONATA PTY LTD","BERMAN, Vadim",,EP-2011864378
WO2019060912,PCT/US2018/052728,25.09.2018,WO/2019/060912,28.03.2019,WO,SYSTEMS AND METHODS FOR AUTONOMOUS DATA ANALYSIS,"The present disclosure relates to systems for providing information in an automated or semi-automated manner, through use of one or more autonomous virtual analysts. In one embodiment, the autonomous virtual analysts may perform many of the same functions as a human analyst, and provide business intelligence relating to revenue, income, profit, loss, expenses, historical data, projections, trends, comparative analysis, etc. In embodiments, the autonomous virtual analyst may be employed through use of natural language dialog with a user, and further configured to capture and appropriately respond to the context of the dialog by supplying a user with information pertinent to the request. According to varying embodiments, a variety of decision trees comprising a plurality of nodes is disclosed. In varying embodiments, the system may comprise one or more distinct modules, including a driver graph module. Methods of automatically and near-instantaneously providing information in response to a user inquiry are also disclosed.",G06F 3/048; G06F 17/21; G06F 17/27; G06F 17/28; G06F 17/30; G06N 5/02; H04N 5/445,APPLI INC.,"ELISSEEFF, Pierre; EUBANKS, Curtis Ray; SEIGEL, Robert Brian","62/562,910 25.09.2017 US; 62/625,645 02.02.2018 US",
EP13990928,03006251,20.03.2003,1351157,08.10.2003,EP,Sentence realization model for a natural language generation system,The present invention is a sentence realization system that processes an abstract linguistic representation (ALR) of a sentence into a structure that can be fully realizable. The system includes a tree conversion component that receives the ALR and generates a basic syntax tree from the ALR. A global movement component then receives the basic syntax tree and hierarchically orders child nodes in that syntax tree relative to ancestor nodes. An intra-constituent ordering component then establishes a linear order among the nodes such that the syntax tree is fully ordered. A surface cleanup component receives the fully ordered tree and performs a number of realization operations to generate surface realizations for constituents that are still represented in an abstract way in the fully ordered syntax tree.,G06F 17/27; G06F 17/28,MICROSOFT CORP,SIMON CORSTON-OLIVER; GAMON MICHAEL; RINGGER ERIC; MOORE ROBERT C; ZHANG ZHU,10316302 20.03.2002 US,
WO2018094296,PCT/US2017/062435,18.11.2017,WO/2018/094296,24.05.2018,WO,SENTINEL LONG SHORT-TERM MEMORY,"The technology disclosed presents a novel spatial attention model that uses current hidden state information of a decoder long short-term memory (LSTM) to guide attention and to extract spatial image features for use in image captioning. The technology disclosed also presents a novel adaptive attention model for image captioning that mixes visual information from a convolutional neural network (CNN) and linguistic information from an LSTM. At each timestep, the adaptive attention model automatically decides how heavily to rely on the image, as opposed to the linguistic model, to emit the next caption word. The technology disclosed further adds a new auxiliary sentinel gate to an LSTM architecture and produces a sentinel LSTM (Sn-LSTM). The sentinel gate produces a visual sentinel at each timestep, which is an additional representation, derived from the LSTM's memory, of long and short term visual and linguistic information.",G06N 3/04,"SALESFORCE.COM, INC.","LU, Jiasen; XIONG, Caiming; SOCHER, Richard","62/424,353 18.11.2016 US; 15/817,153 17.11.2017 US; 15/817,161 17.11.2017 US; 15/817,165 18.11.2017 US",
WO2016089711,PCT/US2015/062848,28.11.2015,WO/2016/089711,09.06.2016,WO,QUANTUM DEEP LEARNING,"Boltzmann machines are trained using an objective function that is evaluated by sampling quantum states that approximate a Gibbs state. Classical processing is used to produce the objective function, and the approximate Gibbs state is based on weights and biases that are refined using the sample results. In some examples, amplitude estimation is used. A combined classical/quantum computer produces suitable weights and biases for classification of shapes and other applications.",G06N 99/00,"MICROSOFT TECHNOLOGY LICENSING, LLC","WIEBE, Nathan; SVORE, Krysta; KAPOOR, Ashish","62/088,409 05.12.2014 US",US-15532996
EP250370757,17870527,08.11.2017,3525164,14.08.2019,EP,IMAGE PROCESSING APPARATUS AND IMAGE PROCESSING METHOD,"Disclosed is an image processing apparatus. The present image processing apparatus comprises: an input unit for inputting an image; and a processor for shrinking the inputted image to a predetermined ratio, extracting a visual feature from the shrunken image, performing an image quality enhancement process reflecting the extracted visual feature in the inputted image, repeatedly performing, for a predetermined number of times, the shrinking, the extracting, and the image quality enhancement process on the image that has undergone the image quality enhancement process. The present disclosure relates to an artificial intelligence (AI) system and an application thereof that simulate the functions of a human brain, such as recognition, judgment, etc., by using a machine learning algorithm such as deep learning, etc.",G06T 3/40; G06T 7/33,SAMSUNG ELECTRONICS CO LTD,NAM WOO-HYUN; AHN IL-JUN; LEE TAMMY; CHO KI-HEUM; PARK YONG-SUP; CHEON MIN-SU,20160148510 09.11.2016 KR; 2017012627 08.11.2017 KR,
EP254136767,17875986,11.01.2017,3550477,09.10.2019,EP,END-TO-END MODELLING METHOD AND SYSTEM,"An end-to-end modelling method and system. The method comprises: determining a topological structure of a target-based end-to-end model, wherein the topological structure comprises an input layer, an encoding layer, an enhancement encoding layer, a filtering layer, a decoding layer and an output layer, with the enhancement encoding layer being used for adding target unit information to a feature sequence output by the encoding layer, and the filtering layer being used for performing information filtering on the feature sequence to which the target unit information is added by the enhancement encoding layer; collecting a large amount of training data; determining a labelled object of the training data, and labelling a target unit in the labelled object; extracting a feature sequence of the training data; and using the feature sequence of the training data and labelling information about the target unit thereof to train a parameter of the target-based end-to-end model, so as to obtain a target-based end-to-end model parameter. By means of the present invention, the accuracy of modelling can be improved.",G06N 99/00,IFLYTEK CO LTD,PAN JIA; ZHANG SHILIANG; XIONG SHIFU; WEI SI; HU GUOPING,201611070244 29.11.2016 CN; 2017070812 11.01.2017 CN,
WO2017132660,PCT/US2017/015607,30.01.2017,WO/2017/132660,03.08.2017,WO,SYSTEMS AND METHODS FOR DYNAMIC PREDICTION OF WORKFLOWS,Aspects of the present disclosure provide a mechanism to directly interact and access with micro-services and/or services using natural-language and machine intelligence and algorithmic learning so that users may access desired micro-services and/or services with minimal interaction.,G10L 15/26; G06F 17/20; G06F 17/28,"LIQUID ANALYTICS, INC.; CANARAN, Vishvas Trimbak; ELLIS, David Andrew; NGUYEN, Phuonglien Thi; KALLIES, Andrea","CANARAN, Vishvas Trimbak; ELLIS, David Andrew; NGUYEN, Phuonglien Thi; KALLIES, Andrea","62/288,923 29.01.2016 US",CA-3017121
WO2017124116,PCT/US2017/013829,17.01.2017,WO/2017/124116,20.07.2017,WO,"SEARCHING, SUPPLEMENTING AND NAVIGATING MEDIA","One or more computing devices, systems, and/or methods for searching, supplementing and/or navigating media are provided. For example, a query for media may be used to identify results and provide the results based upon temporal properties of the results. In another example, media may be segmented into portions based upon time-associated text information of the media, and each portion of the media may be supplemented with content selected based upon a context of the portion. In another example, an area of a video may be selected based upon image analysis of the video, and the video may be supplemented with content at the area. In another example, a video may be supplemented with content, and properties of the content may be adjusted based upon image analysis of the video. In another example, media may be navigated through at different rates of advancement.",G06F 17/30,"BAO, Sheng; LIU, Yang","BAO, Sheng; LIU, Yang","62/279,616 15.01.2016 US; 62/446,650 16.01.2017 US",
WO2019118256,PCT/US2018/064149,06.12.2018,WO/2019/118256,20.06.2019,WO,GENERATION OF TEXT FROM STRUCTURED DATA,"Implementations of the subject matter described herein provide a solution for generating a text from the structured data. In this solution, the structured data is converted into its representation, where the structured data comprises a plurality of cells, and the representation of the structured data comprises plurality of representations of the plurality of cells. A natural language sentence associated with the structured data may be determined based on the representation of the structured data, thereby implementing the function of converting the structured data into a text.",G06F 17/28; G06F 17/24,"MICROSOFT TECHNOLOGY LICENSING, LLC","DUAN, Nan; LV, Yuanhua; ZHOU, Ming; TANG, Duyu",201711348978.7 15.12.2017 CN,
WO2014052739,PCT/US2013/062148,27.09.2013,WO/2014/052739,03.04.2014,WO,SYSTEM FOR INTERACTIVELY VISUALIZING AND EVALUATING USER BEHAVIOR AND OUTPUT,"The present invention discloses CrowdScape, a system that supports the human evaluation of complex crowd work through interactive visualization and mixed initiative machine learning. The system combines information about worker behavior with worker outputs and aggregate worker behavioral traces to allow the isolation of target worker clusters. This approach allows users to develop and test their mental models of tasks and worker behaviors, and then ground those models in worker outputs and majority or gold standard verifications.",G06F 15/18,CARNEGIE MELLON UNIVERSITY,"KITTUR, Aniket, Dilip; RZESZOTARSKI, Jeffrey, Mark",61744490 27.09.2012 US,
WO2014147468,PCT/IB2014/000390,19.03.2014,WO/2014/147468,25.09.2014,WO,TOOL COMPILER,"Automatic generation of documentation and software for an equipment or tool, together with an automatic synchronization between the corresponding documentation and software can be preformed with a tool model representation. The tool model can include a textual, graphical, symbolic, and program representation of the tool. Default components, derived components, and standard components can be added to the tool model.",G06F 17/22; G06F 9/44,"DYNAMIC MICRO SYSTEMS; TANGUY, François; DECKER, Andreas","TANGUY, François; DECKER, Andreas","61/803,427 19.03.2013 US",JP-2016504766
WO2006138386,PCT/US2006/023182,14.06.2006,WO/2006/138386,28.12.2006,WO,COLLOCATION TRANSLATION FROM MONOLINGUAL AND AVAILABLE BILINGUAL CORPORA,"A system and method of extracting collocation translations is presented. The methods include constructing a collocation translation model using monolingual source and target language corpora as well as bilingual corpus, if available. The collocation translation model employs an expectation maximization algorithm with respect to contextual words surrounding collocations. The collocation translation model can be used later to extract a collocation translation dictionary. Optional filters based on context redundancy and/or bi-directional translation constrain can be used to ensure that only highly reliable collocation translations are included in the dictionary. The constructed collocation translation model and the extracted collocation translation dictionary can be used later for further natural language processing, such as sentence translation.",G06F 17/28,MICROSOFT CORPORATION,"LU, Yajuan; GAO, Jianfeng; ZHOU, Ming; CHEN, John T.; LI, Mu","11/152,540 14.06.2005 US",JP-2008517071; MX-MX/a/2007/015438; CN-200680020698.7; DE-null; EP-2006784886; KR-1020077028750
EP12667783,95106331,27.04.1995,0681284,08.11.1995,EP,Speech interpreter with a unified grammar compiler,"The present invention provides a unified grammar for a speech interpreter capable of real-time speech understanding for user applications running on a general purpose microprocessor-based computer. The speech interpreter includes a unified grammar (UG) compiler (350), a speech recognizer (320) and a natural language (NL) processor (330). The UG compiler (350) receives a common UG lexicon and unified grammar description, and generates harmonized speech recognition (SR) and NL grammars for the speech recognizer (320) and natural language processor (330), respectively. The lexicon includes a plurality of UG word entries having predefined characteristics, i.e., features, while the UG description includes a plurality of complex UG rules which define grammatically allowable word sequences. The UG compiler (350) converts the complex UG rules (complex UG rules include augmentations for constraining the UG rules) into permissible SR word sequences and SR simple rules (simple rules do not include any augmentation) for the SR grammar. The SR grammar is a compact representation of th SR word entries corresponding to th UG word entries, permissible SR word sequences and simple SR rules corresponding to the augmentations of the complex UG rules. The NL grammar provides the NL processor (330) with NL patterns enabling the NL processor to extract the meaning of the validated word sequences passed from the speech recognizer. <IMAGE>",G10L 15/18; G10L 15/10; G06F 17/28; G10L 15/18; G10L 15/28,SUN MICROSYSTEMS INC,MARTIN PAUL A,23504694 29.04.1994 US,
WO2018164378,PCT/KR2018/001611,06.02.2018,WO/2018/164378,13.09.2018,WO,"ELECTRONIC APPARATUS FOR COMPRESSING LANGUAGE MODEL, ELECTRONIC APPARATUS FOR PROVIDING RECOMMENDATION WORD AND OPERATION METHODS THEREOF","An electronic apparatus for compressing a language model is provided, the electronic apparatus including a storage configured to store a language model which includes an embedding matrix and a softmax matrix generated by a recurrent neural network (RNN) training based on basic data including a plurality of sentences, and a processor configured to convert the embedding matrix into a product of a first projection matrix and a shared matrix, the product of the first projection matrix and the shared matrix having a same size as a size of the embedding matrix, and to convert a transposed matrix of the softmax matrix into a product of a second projection matrix and the shared matrix, the product of the second projection matrix and the shared matrix having a same size as a size of the transposed matrix of the softmax matrix, and to update elements of the first projection matrix, the second projection matrix and the shared matrix by performing the RNN training with respect to the first projection matrix, the second projection matrix and the shared matrix based on the basic data.",G06F 17/16; G06F 17/30; G06N 3/08,"SAMSUNG ELECTRONICS CO., LTD.","YU, Seung-hak; KULKARNI, Nilesh; SONG, Hee-jun; LEE, Hae-jun","62/469,089 09.03.2017 US; 10-2017-0147922 08.11.2017 KR",EP-2018763492; CN-201880005774.X
EP249227595,19152645,18.01.2019,3514694,24.07.2019,EP,QUERY TRANSLATION,"Translating a natural language search query into a query language includes receiving a natural language query for a database, processing the natural language query to generate a modified text input, generating an entity tree based on the modified text input, including assigning one or more semantic markers to one or more words or one or more groups of words within the modified text input, wherein each semantic tag denotes a semantic class for each respective word or group or words, and converting the entity tree into the query language associated with the first database.",G06F 16/2452; G06F 17/28,SERVICENOW INC,RUMIANTSAU MIKHAIL; ZAYTSAV ALYAKSANDR; ZENOVICH ALEXEY; VERTSEL ALAIKSEI,201862619654 19.01.2018 US; 201916249725 16.01.2019 US,
EP276032575,18170554,03.05.2018,3564862,06.11.2019,EP,DETERMINING INFLUENCE OF ATTRIBUTES IN RECURRENT NEURAL NETWORKS TRAINED ON THERAPY PREDICTION,,G06N 3/04,SIEMENS AG,YANG YINCHONG; TRESP VOLKER,18170554 03.05.2018 EP,
EP12384174,92308276,11.09.1992,0532338,17.03.1993,EP,Natural language processing method on computer,"The method comprising, preparing a word dictionary DIC-WD which stores language structure information IMF-LS corresponding to letter series KNJ composed of words WD, particles JO and symbols KI ; a configuration dictionary DIC-KT which stores the instant language structure information IMF-LS based upon mutual connecting relations of letter series KNJ composed of such as words WD, particles JO and symbols KI ; a meaning frame dictionary DIC-IMI which stores meaning (IMI) frames IMI-FRM defining abstract meaning structures corresponding to letter series KNJ composed of words WD ; and a meaning analysis grammar IMI-GRM which commands such as mutual case coupling relations and mutual logical coupling relations of words WD, particles JO, symbols KI and the meaning frames IMI-FRM corresponding to combinations of the language structure information IMF-LS and further commands filling-ups of the words WD, the particles JO and the symbols KI into the meaning frames IMI-FRM. When a natural sentence is inputted the natural sentence is subjected to a construction analysis by making use of the word dictionary DIC-WD and the configuration dictionary DIC-KT and the letter series KNJ of the inputted natural sentence is converted into a series of a language structure information IMF-LS, namely into a language structure information series IMF-LSL ; and then the inputted natural sentence is subjected to the meaning analysis of the content in such a manner that through an application of the meaning analysis grammar IMI-GRM to the language structure information series IMF-LSL a single or a plurality of meaning frames IMF-FRM are read out from the meaning frame dictionary DIC-IMI in accordance with the command of the meaning analysis grammar IMI-GRM ; further when a plurality of meaning frames IMI-FRM are read out a meaning frame which defines an abstract meaning expressed by the inputted natural sentence is synthesized such as by case coupling and logic coupling the meaning frames IMI-FRM ; words WD, particles JO and symbols KI are filled up into the meaning frames IMI-FRM read out or the meaning frame IMI-FRM synthesized to thereby determine the meaning of the inputted natural language on a computer ; and then data sentence DT-S is produced which enables to correctly express the meaning of the inputted natural sentence on the computer ; thereby the language structure information series IMF-LSL is converted into the data sentence DT-S with a multi layered case-logic language structure based on data structure PSMW. <IMAGE>",G06F 17/27; G06F 17/28,ANDO SHIMON,ANDO SHIMON,31029291 11.09.1991 JP,
WO2017120551,PCT/US2017/012642,06.01.2017,WO/2017/120551,13.07.2017,WO,CONVEX RELAXION REGRESSION SYSTEMS AND RELATED METHODS,"A computer implemented method for optimizing a function is disclosed. The method may comprise identifying an empirical convex envelope, on the basis of a hyperparameter, that estimates the convex envelope of the function; optimizing the empirical convex envelope; and providing the result of optimizing the empirical convex envelope as an estimate of the optimization of the first function.",G06K 9/18,"REHABILITATION INSTITUTE OF CHICAGO; AZAR, Mohammad G.; DYER, Eva; KORDING, Konrad","AZAR, Mohammad G.; DYER, Eva; KORDING, Konrad","62/276,679 08.01.2016 US",
WO2019135164,PCT/IB2019/000058,04.01.2019,WO/2019/135164,11.07.2019,WO,METHOD FOR TOPOLOGICAL OPTIMIZATION GRAPH-BASED MODELS,"A method may include receiving a graph-based model in a first format, including a static topology of the graph-based model. The method may also include encoding the graph-based model from the first format into a neural network topology optimizer (NNTO) readable format such that the topology of the encoded graph-based model is configured to be altered; creating a first group of entities based on at least a same portion of the encoded graph-based model; and performing a learning operation by tuning parameters of the first group of entities to produce an optimization score for each entity. Additionally, the method may include performing a validation operation; determining that an improvement in validation performance for at least one entity is within a threshold amount of improvement; selecting a solution entity; and adding the selected solution entity into the graph-based model in place of the same portion.",G06N 3/08,DATAVALORIS S.A.S.,"SHER, Yevgeniy; ZALESKI, Anton; GLAFKIDES, Jean-patrice","62/613,514 04.01.2018 US; 16/239,431 03.01.2019 US",
WO2017210634,PCT/US2017/035812,02.06.2017,WO/2017/210634,07.12.2017,WO,ITERATIVE ALTERNATING NEURAL ATTENTION FOR MACHINE READING,"Described herein are systems and methods for providing a natural language comprehension system (NLCS) that iteratively performs an alternating search to gather information that may be used to predict the answer to the question. The NLCS first attends to a query glimpse of the question, and then finds one or more corresponding matches by attending to a text glimpse of the text.",G06F 17/28; G06N 3/04,MALUUBA INC.,"SORDONI, Alessandro; BACHMAN, Philip; TRISCHLER, Adam","62/345,421 03.06.2016 US",
WO2018211408,PCT/IB2018/053364,15.05.2018,WO/2018/211408,22.11.2018,WO,NEURAL PARAPHRASE GENERATOR,"A neural paraphrase generator receives a sequence of tuples comprising a source sequence of words, each tuple comprising word data element and structured tag element representing a linguistic attribute about the word data element. An RNN encoder receives a sequence of vectors representing a source sequence of words, and RNN decoder predicts a probability of a target sequence of words representing a target output sentence based on a recurrent state in the decoder. An input composition component includes a word embedding matrix and a tag embedding matrix transforms the input sequence of tuples into a sequence of vectors. An output decomposition component outputs a target sequence of tuples representing predicted words and structured tag elements, the probability of each single tuple from the output is predicted based on a recurrent state of the decoder.",G06F 17/27; G06F 17/28,THOMSON REUTERS GLOBAL RESOURCES UNLIMITED COMPANY,"LEIDNER, Jochen; PLACHOURAS, Vassilis; PETRONI, Fabio","62/506,223 15.05.2017 US",CA-3063006; AU-2018270241; EP-2018737016
WO2019225961,PCT/KR2019/006111,22.05.2019,WO/2019/225961,28.11.2019,WO,ELECTRONIC DEVICE FOR OUTPUTTING RESPONSE TO SPEECH INPUT BY USING APPLICATION AND OPERATION METHOD THEREOF,"An artificial intelligence (AI) system is provided. The AI system simulates functions of human brain such as recognition and judgment by utilizing a machine learning algorithm such as deep learning, etc. and an application of the AI system. A method, performed by an electronic device, of outputting a response to a speech input by using an application, includes receiving the speech input, obtaining text corresponding to the speech input by performing speech recognition on the speech input, obtaining metadata for the speech input based on the obtained text, selecting at least one application from among a plurality of applications for outputting the response to the speech input based on the metadata, and outputting the response to the speech input by using the selected at least one application.",G10L 15/22; G10L 15/26,"SAMSUNG ELECTRONICS CO., LTD.","BHARGAVA, Cheenepalli Srirama Krishna; GUPTA, Ankush",201841019106 22.05.2018 IN; 201841019106 30.11.2018 IN; 10-2019-0054521 09.05.2019 KR,
WO2017200588,PCT/US2016/068737,27.12.2016,WO/2017/200588,23.11.2017,WO,GENERATING NATURAL LANGUAGE OUTPUT BASED ON NATURAL LANGUAGE USER INTERFACE INPUT,"Some implementations are directed to generating a personal database entry for a user based on free-form natural language input formulated by the user via user interface input device(s) of a computing device of the user. The generated personal database entry may include term(s) of the natural language input and descriptive metadata determined based on term(s) of the natural language input and/or based on contextual features associated with receiving the natural language input. Some implementations are directed to generating, based on one or more personal database entries of a user, output that is responsive to further free-form natural language input of the user. For example, one or more entries responsive to further natural language input can be identified based on matching content of those entries to search parameter(s) determined based on the further input. Some implementations are directed to improved automated personal assistants.",G06F 17/30; G06F 17/28,GOOGLE LLC,"GARRETT, Maryam; QUAH, Wan Fen Nicole; HORLING, Bryan; HE, Ruijie","15/157,297 17.05.2016 US",EP-2016826623; JP-2018560513; CN-201680085778.4; KR-1020187036265
WO2018003457,PCT/JP2017/021407,09.06.2017,WO/2018/003457,04.01.2018,WO,"INFORMATION PROCESSING DEVICE, INFORMATION PROCESSING METHOD OF TIME SERIES DATA, AND PROGRAM","An information processing device (2) functions as a neural network (10) on the basis of time-series data (D1). The information processing device is provided with a storage unit (21) and an arithmetic processing unit (20). The storage unit stores an input variable (x[t]) for each order in the time-series data and a parameter group (W1-W3) for functioning as a neural network. The arithmetic processing unit performs a conversion based on the parameter group, calculates an intermediate variable (h[t]) on the basis of an input variable of each order, and calculates an output variable (y[t]) on the basis of the calculated intermediate variable. When calculating an n+1’th intermediate variable, the arithmetic processing unit weights and adds together the calculation result (51) of an n’th intermediate variable and the conversion result (50) of the n’th intermediate variable and an n+1’th input variable that are converted on the basis of the parameter group and calculates the n+1’th intermediate variable.",G06N 3/04; G06F 17/28,"PANASONIC INTELLECTUAL PROPERTY MANAGEMENT CO., LTD.; パナソニックＩＰマネジメント株式会社","ISHIDA, Ryo; 石田　諒",2016-130498 30.06.2016 JP,EP-2017819822; JP-2018525012; KR-1020187022112
WO2015013554,PCT/US2014/048089,24.07.2014,WO/2015/013554,29.01.2015,WO,SYSTEM AND METHOD FOR DISCOVERING AND EXPLORING CONCEPTS,"A method for identifying concepts in a plurality of interactions includes: filtering, on a processor, the interactions based on intervals; creating, on the processor, a plurality of sentences from the filtered interactions; computing, on the processor, a saliency of each the sentences; pruning away, on the processor, sentences with low saliency for generating a set of informative sentences; clustering, on the processor, the sentences of the set of informative sentences for generating a plurality of sentence clusters, each of the clusters corresponding to a concept of the concepts; computing, on the processor, a saliency of each of the clusters; and naming, on the processor, each of the clusters.",G06Q 30/02; G06Q 30/06; G06F 17/30; G06F 17/28,"GREENEDEN U.S. HOLDINGS II, LLC","LEV-TOV, Amir; FAIZAKOF, Avraham; OLLINGER, David; KONIG, Yochai","13/952,470 26.07.2013 US; 13/952,459 26.07.2013 US",EP-2014828714; KR-1020167005393; CN-201480053132.9
WO2015159133,PCT/IB2014/060846,18.04.2014,WO/2015/159133,22.10.2015,WO,METHOD AND APPARATUS FOR DOCUMENT PLANNING,"Methods, apparatuses, and computer program products are described herein that are configured to be embodied as and/or performed by a document planner. In some examples, a method is provided for generating a document plan. The method may include receiving a document plan template and a message store. The document plan template may include program code defining the structure and content of a document plan. The method may also include processing, by a processor, the document plan template to determine one or more messages from the message store for inclusion in the document plan. The method may also include generating the document plan. A structure and a content of the document plan may be determined at least based on the determined one or more messages and the document plan template. Apparatuses and computer readable media are also provided.",G06F 17/28; G06F 17/22; G06F 17/24,ARRIA DATA2TEXT LIMITED,"MAHAMOOD, Saad",,US-15022420
EP250876666,16918904,20.12.2016,3528250,21.08.2019,EP,VOICE QUALITY EVALUATION METHOD AND APPARATUS,"Proposed are a voice quality evaluation method and apparatus. The voice quality evaluation method comprises: receiving voice data to be evaluated; extracting an evaluation characteristic of the voice data to be evaluated; and according to the evaluation characteristic of the voice data to be evaluated and a constructed voice quality evaluation model, performing quality evaluation on the voice data to be evaluated, wherein the voice quality evaluation model is used for indicating a relationship between the evaluation characteristic of single-ended voice data and quality information about the single-ended voice data. The method can expand the application scope of voice quality evaluation.",G10L 25/60; G10L 15/06,IFLYTEK CO LTD,YIN BING; WEI SI; HU GUOPING; CHENG SU,201610892176 12.10.2016 CN; 2016111050 20.12.2016 CN,
WO2018034957,PCT/US2017/046429,11.08.2017,WO/2018/034957,22.02.2018,WO,CONVERSATIONAL CHATBOT FOR TRANSLATED SPEECH CONVERSATIONS,"A server includes a processor and memory, a network interface, and a first application executed by the processor and memory. The first application is configured to receive an input in a first language based on a call received via the network interface by a Voice over Internet Protocol (VoIP) application executed by the server. The call includes speech in a second language. The VoIP application includes speech recognition and translation functionality to process the call. The first application is configured to generate a response in the first language to the input. The first application is configured to transmit the response to the VoIP application to send a speech representation of the response in the second language via the call. The speech representation indicates quality of the speech recognition and translation functionality of the VoIP application.",G10L 15/22; H04L 12/58; G10L 15/01; G06F 17/28,"MICROSOFT TECHNOLOGY LICENSING, LLC","CHOWDHARY, Vishal; LEWIS, Will; SURTI, Tanvi","15/238,329 16.08.2016 US",
EP233540691,18169500,26.04.2018,3404578,21.11.2018,EP,SENSOR TRANSFORMATION ATTENTION NETWORK (STAN) MODEL,"A sensor transformation attention network (STAN) model including sensors configured to collect input signals, attention modules configured to calculate attention scores of feature vectors corresponding to the input signals, a merge module configured to calculate attention values of the attention scores, and generate a merged transformation vector based on the attention values and the feature vectors, and a task-specific module configured to classify the merged transformation vector is provided.",G06K 9/00; G06K 9/46; G06K 9/62; G10L 15/16; G10L 15/20,SAMSUNG ELECTRONICS CO LTD; UNIV ZUERICH,BRAUN STEFAN; NEIL DANIEL; CEOLINI ENEA; ANUMULA JITHENDAR; LIU SHIH-CHII,20170117021 13.09.2017 KR; 201762507385 17.05.2017 US; 201762508631 19.05.2017 US,
WO2019133715,PCT/US2018/067680,27.12.2018,WO/2019/133715,04.07.2019,WO,SYSTEM AND METHOD FOR ARTIFICIAL INTELLIGENCE DRIVEN AUTOMATED COMPANION,"The present teaching relates to method, system, medium, and implementations for an automated dialogue companion. Multimodal input data associated with a user engaged in a dialogue of a certain topic in a dialogue scene are first received and used to extract features representing a state of the user and relevant information associated with the dialogue scene. A current state of the dialogue characterizing the context of the dialogue is generated based on the state of the user and the relevant information associated with the dialogue scene. A response communication for the user is determined based on a dialogue tree corresponding to the dialogue of the certain topic, the current state of the dialogue, and utilities learned based on historic dialogue data and the current state of the dialogue.",G10L 15/22; G06T 13/40; G06F 17/28,"DMAI, INC.","SHUKLA, Nishant; FANG, Rui; LIU, Changsong","62/612,145 29.12.2017 US",
WO2019157462,PCT/US2019/017534,11.02.2019,WO/2019/157462,15.08.2019,WO,FAST DECODING IN SEQUENCE MODELS USING DISCRETE LATENT VARIABLES,"Methods, systems, and apparatus, including computer programs encoded on a computer storage medium, for generating an output sequence from an input sequence. One of the methods includes receiving the input sequence; processing the input sequence using a latent prediction model configured to autoregressively predict a sequence of discrete latent variables that is shorter than the output sequence and that encodes the output sequence, wherein each discrete latent variable in the sequence is selected from a discrete set of latent variables; and processing the input sequence and the predicted sequence of discrete latent variables using a parallel decoder model configured to generate the outputs in the output sequence in parallel from the input sequence and the predicted sequence of discrete latent variables.",G06N 3/04; G06N 3/08,GOOGLE LLC,"KAISER, Lukasz Mieczyslaw; ROY, Aurko; VASWANI, Ashish Teku; PARMAR, Niki; BENGIO, Samuel; USZKOREIT, Jakob D.; SHAZEER, Noam M.","62/628,912 09.02.2018 US",
WO2015039222,PCT/CA2014/050533,09.06.2014,WO/2015/039222,26.03.2015,WO,SYSTEMS AND METHODS FOR ACTIVELY COMPOSING CONTENT FOR USE IN CONTINUOUS SOCIAL COMMUNICATION,"A system and method are provided for analysing and communicating social data. A method performed by a computing device or server system includes obtaining social data and deriving at least two concepts from the social data. A relationship between the at least two concepts is determined. The method also includes composing a new social data object using the relationship and transmitting the new social data object. User feedback associated with new social data object is obtained, and the computing device or server system computes an adjustment command using the user feedback. Executing the adjustment command adjusts a parameter used in the method. After the adjustment command is executed, the method is repeated.",G06F 17/00; G06F 17/28; H04L 12/16,SYSOMOS L.P.,"OGAWA, Stuart","61/880,027 19.09.2013 US",CA-2924375; KR-1020167010232; EP-2014845851
WO2017083695,PCT/US2016/061597,11.11.2016,WO/2017/083695,18.05.2017,WO,GENERATING TARGET SEQUENCES FROM INPUT SEQUENCES USING PARTIAL CONDITIONING,"A system can be configured to perform tasks such as converting recorded speech to a sequence of phonemes that represent the speech, converting an input sequence of graphemes into a target sequence of phonemes, translating an input sequence of words in one language into a corresponding sequence of words in another language, or predicting a target sequence of words that follow an input sequence of words in a language (e.g., a language model). In a speech recognizer, the RNN system may be used to convert speech to a target sequence of phonemes in real-time so that a transcription of the speech can be generated and presented to a user, even before the user has completed uttering the entire speech input.",G10L 15/16; G05B 13/02,GOOGLE LLC,"JAITLY, Navdeep; LE, QUOC V.; VINYALS, Oriol; BENGIO, Samuel; SUTSKEVER, Ilya","62/254,687 12.11.2015 US",EP-2016802210
WO2019222751,PCT/US2019/033156,20.05.2019,WO/2019/222751,21.11.2019,WO,UNIVERSAL TRANSFORMERS,"Methods, systems, and apparatus, including computer programs encoded on computer storage media, for implementing a sequence to sequence model that is recurrent in depth while employing self-attention to combine information from different parts of sequences.",G06N 5/04; G06N 3/04; G06N 3/08,GOOGLE LLC,"DEGHANI, Mostafa; GOUWS, Stephan; VINYALS, Oriol; USZKOREIT, Jakob D.; KAISER, Lukasz Mieczyslaw","62/673,831 18.05.2018 US",
WO2017019056,PCT/US2015/042617,29.07.2015,WO/2017/019056,02.02.2017,WO,CONTEXT ORIENTED TRANSLATION,"An example non-transitory computer-readable medium to store machine-readable instructions that when accessed and executed by a processing resource cause a computing device to perform operations is described herein. The operations include connecting a first properties file with a corresponding application. The first properties file includes a plurality of text entries and associated location indicators. Text in the application is identified that is to be translated. The text to be translated corresponds to at least some of the text entries in the first properties file. The identified text is presented in the application, which provides context for the translation. The translation is received and a second properties file that includes the translation of the identified text and an associated location indicator is generated.",G06F 17/28; G06F 17/27,ENTIT SOFTWARE LLC,"AZULAI, Asaf; ABRAMOVSKY, Ori; DAVID, Ben",,US-15746160
WO2018171533,PCT/CN2018/079362,16.03.2018,WO/2018/171533,27.09.2018,WO,REVIEW MACHINE LEARNING SYSTEM,"An apparatus and method are provided for review-based machine learning. Included are a non-transitory memory storing instructions and one or more processors in communication with the non-transitory memory. The one or more processors execute the instructions to receive first data, generate a plurality of first features based on the first data, and identify a first set of labels for the first data. A first model is trained using the first features and the first set of labels. The first model is reviewed to generate a second model, by receiving a second set of labels for the first data, and reusing the first features with the second set of labels in connection with training the second model.",G06F 17/30,"HUAWEI TECHNOLOGIES CO., LTD.","HU, Luhui; ZANG, Hui; HU, Ziang","15/467,847 23.03.2017 US",
WO2020082187,PCT/CA2019/051515,25.10.2019,WO/2020/082187,30.04.2020,WO,SENSITIVE DATA DETECTION AND REPLACEMENT,"Systems and methods for privacy and sensitive data protection. An image of a document is received at a pre-processing stage and image pre-processing is applied to the image to ensure that the resulting image is sufficient for further processing. Pre-processing may involve processing relating to image quality and image orientation. The image is then passed to an initial processing stage. At the initial processing stage, the relevant data in the document are located and bounding boxes are placed around the data. The resulting image is then passed to a processing stage. At this stage, the type of data within the bounding boxes is determined and suitable replacement data is generated. The replacement data is then inserted into the image to thereby remove and replace the sensitive data in the image.",G06F 21/60; G06F 17/24; G06F 17/28; G06K 9/80,ELEMENT AI INC.,"BUSILA, Elena; PASQUERO, Jerome; LAZARUS, Patrick","62/751,159 26.10.2018 US",
WO2019164078,PCT/KR2018/010398,06.09.2018,WO/2019/164078,29.08.2019,WO,REAL-TIME MULTI-LANGUAGE INTERPRETATION WIRELESS TRANSMITTING AND RECEIVING SYSTEM CAPABLE OF EXTRACTING TOPIC SENTENCE AND TRANSMITTING AND RECEIVING METHOD USING SAME,"The present invention relates to a real-time multi-language interpretation wireless transmitting and receiving system and a transmitting and receiving method and to a device for enabling conversation with a plurality of users using different languages by using a transceiver. The transceiver is connected to a translation server that receives ID data and voice data transmitted from the transmission units of a plurality of one-to-many or many-to-many transceivers and transmits the ID data and voice data to the reception units of the plurality of transceivers by a plurality of predefined languages. In addition, during interpreting and translating, a key sentence extraction method based on a deep learning algorithm is used.",G06F 17/28; G10L 15/00; H04R 1/10; G06F 17/21; G06N 3/08; H04L 29/06; H04L 12/18,AIR SOUND INC.; (주)에어사운드,"PAEK, Min-Ho; 백민호",10-2018-0021969 23.02.2018 KR; 10-2018-0031774 20.03.2018 KR; 10-2018-0086950 26.07.2018 KR,
WO2018035248,PCT/US2017/047190,16.08.2017,WO/2018/035248,22.02.2018,WO,ENHANCING USER QUERIES USING IMPLICIT INDICATORS,"In various example embodiments, a system and method for balancing implicit and explicit indicators is presented. In one example, a method includes a user's utterance that includes a user query, extracting user intent parameters from the user query, constructing a structured query in a machine readable format using user intent parameters, determining whether the user query includes an implicit indicator, determining a confidence rating for the implicit indicator, updating the structured query to include the implicit indicator in response to the confidence rating for the implicit indicator being above a threshold value, and submitting the structured query to a database of items.",G06F 3/16; G06F 17/30; G10L 15/22,"EBAY INC.; HEWAVITHARANA, Sanjika; KALE, Ajinkya Gorakhnath","HEWAVITHARANA, Sanjika; KALE, Ajinkya Gorakhnath","62/375,847 16.08.2016 US",
WO2018200979,PCT/US2018/029834,27.04.2018,WO/2018/200979,01.11.2018,WO,GENERATING QUERY VARIANTS USING A TRAINED GENERATIVE MODEL,"Systems, methods, and computer readable media related to generating query variants for a submitted query. In many implementations, the query variants are generated utilizing a generative model. A generative model is productive, in that it can be utilized to actively generate a variant of a query based on application of tokens of the query to the generative model, and optionally based on application of additional input features to the generative model.",G06F 17/30,GOOGLE LLC,"ALAKUIJALA, Jyrki; BUCK, Christian; BULIAN, Jannis; CIARAMITA, Massimiliano; GAJEWSKI, Wojciech; GESMUNDO, Andrea; HOULSBY, Neil; WANG, Wei","62/492,154 29.04.2017 US",CN-201880028212.7; JP-2019558737; EP-2018724709; KR-1020197035500
EP292573640,19161511,08.03.2019,3633959,08.04.2020,EP,AUTOMATION OF DATA ANALYTICS IN AN INTERNET OF THINGS (IOT) PLATFORM,"Advanced analytics refers to theories, technologies, tools, and processes that enable an in-depth understanding and discovery of actionable insights in big data, wherein conventional systems and methods may be prone to errors leading to inaccuracies. Embodiments of the present disclosure provide systems and methods for performing data analytics in an IoT platform wherein input data pertaining to problem type, solution associated thereof, sensory information corresponding to sensors deployed in the platform, knowledge of domain expert(s) specific to input data are depicted in graphical knowledge representations, wherein relationships between (i) sensors and associated attributes and (ii) the domain knowledge across the plurality of graphical knowledge representations are determined wherein Machine Learning (ML) models are then applied to the determined relationship for optimizing ML models wherein problem statement, root cause, from one knowledge to another are translated using translation technique(s) to determine root cause analysis and interpretable root cause information.",H04L 29/08; G06N 5/02,TATA CONSULTANCY SERVICES LTD,CHATTOPADHYAY TANUSHYAM; PANDA SATANIK; MISRA PRATEEP; PAL ARPAN; BHATTACHYARYA INDRAJIT; AGARWAL PUNEET; BANDYOPADHYAY SOMA; UKIL ARIJIT; BANERJEE SNEHASIS; DAS ABHISEK,201821037802 05.10.2018 IN,
WO2018101671,PCT/KR2017/013328,22.11.2017,WO/2018/101671,07.06.2018,WO,APPARATUS AND METHOD FOR PROVIDING SENTENCE BASED ON USER INPUT,"Disclosed are an apparatus and/or method for providing a sentence based on a user input. When a sentence corresponding to a shorthand word input from a user is generated and provided to the user, a sentence most suitable for a current context is provided to the user by further considering context information. At least a portion of the method for providing a sentence based on a user input may be performed using a rule-based model and/or an artificial intelligence model learned according to at least one of neural network or deep learning algorithms. The rule-based model and/or artificial intelligence model may provide a sentence most suitable for a current context to the user by using the input shorthand word and the context information as input values.",G06F 3/023; G06F 3/0484; G06N 3/08; G06F 17/27,"SAMSUNG ELECTRONICS CO., LTD.","LEE, Ji-yeon; RHO, Ji-hyun; RYU, Won-ho",10-2016-0160783 29.11.2016 KR; 10-2017-0144234 31.10.2017 KR,EP-2017875469; CN-201780073446.9
EP97587472,12814991,19.07.2012,2734938,28.05.2014,EP,METHOD AND SYSTEM OF CLASSIFICATION IN A NATURAL LANGUAGE USER INTERFACE,"A method and system are provided for processing natural language user queries for commanding a user interface to perform functions. Individual user queries are classified in accordance with the types of functions and a plurality of user queries may be related to define a particular command. To assist with classification, a query type for each user query is determined where the query type is one of a functional query requesting a particular new command to perform a particular type of function, an entity query relating to an entity associated with the particular new command having the particular type of function and a clarification query responding to a clarification question posed to clarify a prior user query having the particular type of function. Functional queries may be processed using a plurality of natural language processing techniques and scores from each technique combined to determine which type of function is commanded.",G06F 17/30; G06F 3/16; G06F 17/27; G06F 17/28; G06Q 30/06; G10L 15/18; G10L 15/22; G10L 15/26,SULEMAN KAHEER; PANTONY JOSHUA R; HSU WILSON; WU ZHIYUAN; TREGENZA PHIL; PASUPALAK SAM,SULEMAN KAHEER; PANTONY JOSHUA R; HSU WILSON; WU ZHIYUAN; TREGENZA PHIL; PASUPALAK SAM,2012000685 19.07.2012 CA; 2747153 19.07.2011 CA; 201261596407 08.02.2012 US,
EP236491134,17766637,13.03.2017,3432229,23.01.2019,EP,ABILITY IMPARTING DATA GENERATION DEVICE,"Provided is a mechanism for increasing the efficiency of development work for adding a new ability to an apparatus. In addition, a mechanism that makes it possible to easily add a new ability to another apparatus is provided. A target apparatus has an architecture that is modeled as an ability acquisition model including an ability unit that executes an ability, a data input unit that is an interface for input of the ability unit, and a data output unit that is an interface for output of the ability unit. an ability-providing-data generation apparatus generates ability providing data including ability setting data for setting a function in the ability unit in the ability acquisition model of the target apparatus, input setting data for setting a function in the data input unit in the ability acquisition model of the target apparatus, and output 
setting data for setting a function in the data output unit in the ability acquisition model of the target apparatus.",G06N 99/00; G06F 8/71; G06F 9/445; G06N 3/063; G06N 3/08; G06N 3/10,OMRON TATEISI ELECTRONICS CO,ANDO TANICHI,2016049329 14.03.2016 JP; 2017010041 13.03.2017 JP,
WO2019113308,PCT/US2018/064240,06.12.2018,WO/2019/113308,13.06.2019,WO,ACTIVE ADAPTATION OF NETWORKED COMPUTE DEVICES USING VETTED REUSABLE SOFTWARE COMPONENTS,"A method includes receiving a text description of a system capability request, and converting the text description into a normalized description of the system capability request. A repository is then queried, based on the normalized description and using a search algorithm, to identify multiple candidate application software units (ASUs). The candidate ASUs are displayed to a user for selection. The user-selected ASU is then deployed, either locally or to at least one remote compute device, in response to receiving the user selection. Deployment can include the user-selected candidate ASU being integrated into a local or remote software package, thus defining a modified software package that is configured to provide the system capability.",G06F 9/06; G06F 9/44; G06F 9/45; G06F 15/16; G06F 17/30; G06F 17/50,"FRANCHITTI, Jean-Claude","FRANCHITTI, Jean-Claude","62/594,922 05.12.2017 US",
WO2007041117,PCT/US2006/037562,26.09.2006,WO/2007/041117,12.04.2007,WO,WEIGHTED LINEAR MODEL,"A weighted linear word alignment model linearly combines weighted features to score a word alignment for a bilingual, aligned pair of text fragments. The features are each weighted by a feature weight. One of the features is a word association metric, which may be generated from surface statistics.",G06F 17/28,MICROSOFT CORPORATION,"MOORE, Robert C.; YIH, Wen-tau; ANDREW, Galen; TOUTANOVA, Kristina","11/242,290 03.10.2005 US; 11/485,015 12.07.2006 US",EP-06815511; EP-6815511
WO2019113546,PCT/US2018/064614,07.12.2018,WO/2019/113546,13.06.2019,WO,ASSISTANCE ENGINE FOR MULTIPARTY MEDIATION,"The subject disclosure relates to methods for facilitating a settlement between two or more parties engaged in mediation through an online platform. In some aspects, the disclosed technology provides settlement suggestions and predictions based on historic settlement data. Settlement suggestions and predictions can be informed using a machine learning (ML) model that is configured to make predictions about the likelihood of acceptance of various settlement amounts by all mediating parties. In some aspects, ML model may also provide messages to one or more parties engaged in mediation to encourage settlement. Systems and computer-readable media are also provided.",G06F 3/0482; G06F 3/0484; G06F 17/27; G06F 17/28; G06Q 10/10; G06Q 50/18,"FAIRCLAIMS, INC.","MORETTI, Matt; BOESE, John","62/596,483 08.12.2017 US",
WO2020072759,PCT/US2019/054470,03.10.2019,WO/2020/072759,09.04.2020,WO,A VOICE ASSISTANT SYSTEM FOR A VEHICLE COCKPIT SYSTEM,"A method of operating a voice assistant system (30) of a vehicle (20) includes inputting (104) a voice input (200) into a computing device (28), and converting (106) the voice input into a natural language input text data file (224) with a speech-to-text converter (50). The natural language input text data file is analyzed (108) to determine a requested action (108). An action identifier (44) determines if the requested action is a cloud-based action (112) or an on-board based action (122). When the requested action is determined to be the cloud-based action, the computing device communicates (114) the text data file to a cloud-based service provider (226). When the requested action is determined to be the on-board based action, then the computing device executes (126) the requested action with a skill (46) operable on the computing device to perform the requested action.",G06F 17/27; G06F 17/28; G06N 5/04; G06Q 10/10; G10L 15/18; G10L 15/22; G10L 15/08; G10L 15/28; G10L 15/32,"VISTEON GLOBAL TECHNOLOGIES, INC.","SUKUMAR, Ranjeeth Kumar","62/740,681 03.10.2018 US; 62/776,951 07.12.2018 US",
EP238117461,17187015,21.08.2017,3447655,27.02.2019,EP,A REVISION SYSTEM AND METHOD FOR REVISING TRANSLATED TEXTS WITH REDUCTION OF FALSE POSITIVES,There is described a revision system and method that searches translated texts (12) for the presence of the translation errors (20) stored in the at least one revision memory (32). This generates a corresponding search result list (200) comprising any of the occurrences (210) of the translation errors (20) of which the association with any of the translated texts (12) is not yet stored in the at least one translation memory (32) of the revision module (30). The revision system (1) further comprises a false positive module (80) configured to filter said search result list (200) thereby generating a filtered result list (220) by removing any false positive occurrences (230) of translation errors (20) in function of one or more false positive detection rules (240).,G06F 17/27; G06F 17/28,TELEVIC EDUCATION NV,VANLERBERGHE FILIP ROBERT MARIA; WYLIN BERT GUILLAUME JOZEF GERARD; LAGATIE RUBEN,17187015 21.08.2017 EP,
WO2005017767,PCT/AU2004/001088,16.08.2004,WO/2005/017767,24.02.2005,WO,NATURAL LANGUAGE RECOGNITION USING DISTRIBUTED PROCESSING,"A method and system for computer-based recognition of natural language data. The method is implemented on a distributed computer network and includes obtaining natural language data, such as digital ink handwriting, using an input device (415), receiving the natural language data on a server (430) via a network, processing the natural language data using a recognizer (440) residing on the server (430) to produce intermediate format data (445), transmitting the intermediate format data (445) to an application (450), and decoding the intermediate format data 445 into computer-readable format data using the application (450) and context information associated with the application (450).",G06F 17/24; G06F 17/27; G10L 15/28,"SILVERBROOK RESEARCH PTY LTD; NAPPER, Jonathon, Leigh; LAPSTUN, Paul; SILVERBROOK, Kia","NAPPER, Jonathon, Leigh; LAPSTUN, Paul; SILVERBROOK, Kia",2003904350 15.08.2003 AU; 2003904351 15.08.2003 AU,EP-2004761125; US-10510392; AU-2004265700; CA-2529037
EP12594184,94305716,02.08.1994,0637805,08.02.1995,EP,Context-sensitive method of finding information about a word in an electronic dictionary,"A technique of using an electronic dictionary in conjunction with electronically-encoded running text that gives the user the most relevant information rather than belaboring the user with all possible information about a selected word. The technique maps the selected word from its inflected form to its citation form, analyzes the selected word in the context of neighboring and surrounding words to resolve ambiguities, and displays the information that is determined to be the most likely to be relevant. The dictionary preferably has information about multi-word combinations that include the selected word, and the context determination typically entails checking whether the selected word is part of a predefined multi-word combination. <IMAGE>",G06F 17/21; G06F 17/27; G06F 17/30,XEROX CORP,ZAENEN ANNIE E; KARTTUNEN LAURI J,10096093 03.08.1993 US,
EP77334186,12191872,08.11.2012,2592570,15.05.2013,EP,Pronounceable domain names,"Embodiments of the present teachings relate to systems and methods for generating pronounceable domain names. The method includes proving a list of character strings; filtering the list of character strings through a first filter based on a phonetic model to produce a first filtered list of character strings; filtering the list of character strings through a second filter based on a character order mode to produce a second filtered list of character strings; and generating, by a processor, a list of pronounceable domain names based on the first filtered list of character strings and the second filtered list of character strings.",G06F 17/27; G06F 17/28; H04L 29/12,VERISIGN INC,MUGALI ADITYA; SIMPSON ANDREW; WALKER SCOTT,201161557248 08.11.2011 US,
WO2019060889,PCT/US2018/052641,25.09.2018,WO/2019/060889,28.03.2019,WO,ARTIFICIAL INTELLIGENCE (AI) CHARACTER SYSTEM CAPABLE OF NATURAL VERBAL AND VISUAL INTERACTIONS WITH A HUMAN,"Systems and methods herein are directed to an artificial intelligence (AI) character capable of natural verbal and visual interactions with a human. In one embodiment, an AI character system receives, in real-time, one or both of an audio user input and a visual user input of a user interacting with the AI character system. The AI character systems determines one or more avatar characteristics based on the one or both of the audio user input and the visual user input of the user. The AI character system manages interaction of an avatar with the user based on the one or more avatar characteristics.",G06N 5/00,"VENTANA 3D, LLC","LEMBERSKY, Roman; BORKE, Michael, James; BEZIRGANYAN, Hayk; CROWDER, Ashley; CONWAY, Benjamin; VU, Hoang, Son; BEHMKE, James, M.","62/562,592 25.09.2017 US; 62/620,682 23.01.2018 US",
WO2014189400,PCT/RS2013/000010,22.05.2013,WO/2014/189400,27.11.2014,WO,A METHOD FOR DIACRITISATION OF TEXTS WRITTEN IN LATIN- OR CYRILLIC-DERIVED ALPHABETS,"The presented invention is related to the method for the recovery of diacritical marks in texts written in any of the languages using Latin- or Cyrillic-derived alphabets with diacritical marks. The embodiment of the invention presented in this document uses multiple information sources (topical information and information on semantic proximity) in the task of diacritisation, which is recognised and treated as a classification task. The invention relies on classification based on topical information provided by text categorisation, the information on semantic proximity of particular words in the text, as well as morphological information. At word level the classification task is limited to the calculation of the semantic score of each particular word interpretation. The actual recovery of the diacritical marks is carried out only at the sentence level (or possibly some higher level such as paragraph or the entire text), with the assumption that users, when adapting a text to a non-diacritised setting, consistently use one of the existing conventions, rather than switching between different conventions.",G06F 17/22; G06F 17/27,AXON DOO,"SEČUJSKI, Milan; OSTROGONAC, Stevan; PEKAR, Darko; KNEŽEVIĆ, Dragan; POPOVIĆ, Branislav; BOJANIĆ, Milana",,
WO2018098318,PCT/US2017/063066,22.11.2017,WO/2018/098318,31.05.2018,WO,SERVICE FOR DEVELOPING DIALOG-DRIVEN APPLICATIONS,"A natural language understanding model is trained using respective natural language example inputs corresponding to a plurality of applications. A determination is made as to whether a value of a first parameter of a first application is to be obtained using a natural language interaction. Using the natural language understanding model, at least a portion of the first application is generated.",G06F 17/27; G06F 17/28; G10L 15/22; G10L 15/26; G06F 8/30,"AMAZON TECHNOLOGIES, INC.","ANBAZHAGAN, Vikram Sathyanarayana; POKKUNURI, Rama Krishna Sandeep; SIVASUBRAMANIAN, Swaminathan; STEFANI, Stefano; ZHUKOV, Vladimir","15/360,814 23.11.2016 US",CN-201780072369.5; EP-2017817458
WO2012000043,PCT/AU2011/000814,30.06.2011,WO/2012/000043,05.01.2012,WO,SYSTEM AND METHOD OF PROVIDING A COMPUTER-GENERATED RESPONSE,"The present invention generally concerns a method and a system for providing a computer-generated response in response to natural language inputs. The response includes, but is not limited to, visual, audio, and textual forms. The response is capable of being displayed or shown in a visual 2- or 3- dimensional virtual world. In one aspect, the present invention provides a method of providing a computer- generated response, comprising the steps of (i) receiving a computer-recognisable input originating from a user of a computer-simulated environment for facilitating interaction between the user and a simulated character controlled by a controller, (ii) extracting input information from the computer-recognisable input as extracted input information at least partly by linguistic analysis or semantic analysis and (iii) causing an action to be generated in response to the computer-recognisable input based at least partly on the extracted input information.",G06F 17/28; G10L 15/00,"MORF DYNAMICS PTY LTD; ZHANG, Yitao; ALI, Lukie","ZHANG, Yitao; ALI, Lukie",2010902865 29.06.2010 AU,
EP13771863,00976319,17.11.2000,1233347,21.08.2002,EP,LANGUAGE TRANSLATION SYSTEM,"A system is disclosed which allows communication between various kinds of languages. The conversion processing portion (300) rewrites components of the representation in the natural language constructing given natural language representation to universal language elements corresponding thereto in the universal language dictionary (210). The conversion processing portion (300) joins multiple rewritten universal language elements by applying the rewriting rules (220) in accordance with an order in universal language element and creates representation in universal language, which is represented in the binary relation. A reverse-conversion processing portion (350) resolves representation in universal language represented in the binary relation to universal language elements constructing joins therein with reference to the rewriting rules (220) in accordance with rules for representation in the binary relation, which are included in the rules. The reverse-conversion processing portion (350) rewrites the resolved universal language elements to components constructing the natural language representation with reference to the universal language dictionary (120) in order to create representation in natural language. <IMAGE>",G06F 17/28,UNITED NATIONS; UCHIDA HIROSHI; ZHU MEIYING,UCHIDA HIROSHI; ZHU MEIYING,0008116 17.11.2000 JP; 32752699 17.11.1999 JP,
WO2019011356,PCT/DE2017/100587,14.07.2017,WO/2019/011356,17.01.2019,WO,METHOD FOR CONDUCTING DIALOG BETWEEN HUMAN AND COMPUTER,"The invention relates to a method for conducting dialog between human and computer by means of a self-learning system, comprising: receiving user inputs in natural spoken text, associating synonyms and key words and making word associations, analyzing the user inputs with respect to sentence structure and sentence construction and recognizing same, associating key phrases, determining and classifying the user intention, checking if a confirmation is required, carrying out logical processing in a reasoning-and-answer preparation with formulation of a decision on the further dialog development, formulation or the dialog course with possible generation of an answer, wherein in order to recognize the user intention the statistical relevance of the association with a target intention is determined while at the same time all meta-information is retained, the classification occurs by means of a classification algorithm for intention clarification, logic and speech understanding are linked by means of meta-information in the decision tree, feedback to the self-learning system is generated by using earlier user questioning, a query to the user as to whether the recognized intention was correctly understood is generated if the statistical relevance is below a limit value, in this case an answer of the user is received and is then analyzed with respect to sentence structure and sentence construction and the user inputs are again divided into substantive content and into meta-information about the user and the user intention is again determined and classified, the recognition result is output to the self-learning system, the self-learning system develops automatic system recommendations and/or decisions for improving the intention recognition across a plurality of user interactions and keeps same at hand for later use, initiates the generation of the spoken-text answer to the user if the statistical relevance exceeds a limit value, and otherwise triggers a further inquiry.",G06F 17/27; G06F 17/28; G10L 15/22,COGNIGY GMBH,"HELTEWIG, Philipp; POGGEMANN, Sascha",,EP-2017780297
WO2020033922,PCT/US2019/046057,09.08.2019,WO/2020/033922,13.02.2020,WO,SHORT ANSWER GRADE PREDICTION,"Implementations include computer-implemented methods, computer-readable medium, and/or systems for short answer grade prediction.",G05B 23/02; G06F 11/26; G06F 17/27; G06F 17/28; G06K 9/72; G06F 16/245; G09B 7/02,"ACTIVELY LEARN, INC.","GOYAL, Jay; FELDMAN, Sergey; BARSHAI, Ilya","62/717,723 10.08.2018 US",
WO2005020091,PCT/CA2004/001531,20.08.2004,WO/2005/020091,03.03.2005,WO,SYSTEM AND METHOD FOR PROCESSING TEXT UTILIZING A SUITE OF DISAMBIGUATION TECHNIQUES,"The invention relates to a system and method for processing natural language text utilizing disambiguation components to identify a disambiguated sense for the text. For the method, it comprises applying a selection of the components to the text to identify a local disambiguated sense for the text. Each component provides a local disambiguated sense of the text with a confidence score and a probability score. The disambiguated sense is determined utilizing a selection of local disambiguated senses. The invention also relates to a system and method for generating sense-tagged text. For the method, it comprises steps of: disambiguating a quantity of documents utilizing a disambiguation component; generating a confidence score and a probability score for a sense identified for a word provided by the component;  if the confidence score for the sense for the word is below a set threshold, the sense is ignored; and if the confidence score for the sense for the word is above the set threshold, the sense is added to the sense-tagged text.",G06F 17/27,IDILIA INC.,"COLLEDGE, Matthew; BELZILE, Pierre; BARNES, Jeremy","60/496,681 21.08.2003 US",EP-2004761695; CN-200480031233.2; CA-2536262; IN-319/MUMNP/2006
EP154346761,14716736,14.03.2014,2973002,20.01.2016,EP,USER TRAINING BY INTELLIGENT DIGITAL ASSISTANT,"The method includes receiving, from a user, a first speech input spoken in a first language; inferring a user intent based on at least the first speech input in the first language; based on the inferred user intent, generating one or more alternative expressions of the first speech input in the first language; and providing feedback to the user introducing the alternative expressions as a more preferred input to express the inferred user intent than the first speech input provided by the user.",G06F 17/28; G09B 19/06; G10L 15/22,APPLE INC,PITSCHEL DONALD W; GRUBER THOMAS R,201361800846 15.03.2013 US; 2014028785 14.03.2014 US,
WO2014196375,PCT/JP2014/063667,23.05.2014,WO/2014/196375,11.12.2014,WO,"TRANSLATION DEVICE, LEARNING DEVICE, TRANSLATION METHOD, AND RECORDING MEDIUM","[Problem] When using a neural network which joins features in a nonlinear fashion, it is necessary to recalculate a translation candidate score while searching, which has a large load. [Solution] Provided is a translation device, comprising: a parameter storage unit which is capable of storing a first weight vector which is applied to a non-local feature function, and a second weight vector which is applied to a local feature function; a feature function information storage unit which is capable of storing non-local first feature function information, and local second feature function information; a partial pair information storage unit which is capable of storing two or more instances of partial pair information which is a phrase pair, a rule pair, etc.; a score acquisition unit which introduces a non-linear model on a phrase pair, rule pair, etc., unit basis, and limits the non-linear model to a feature which is closed to either the phrase pair or the rule pair, acquiring two or more target language text scores; a target language text acquisition unit which acquires the target language text with the highest score; and an output unit which outputs the target language text. With the translation device, it is possible to rapidly and highly precisely translate in machine translation.",G06F 17/28,NATIONAL INSTITUTE OF INFORMATION AND COMMUNICATIONS TECHNOLOGY; 国立研究開発法人情報通信研究機構,"WATANABE, Taro; 渡辺　太郎; LIU, Lemao; リュウ　レモ; SUMITA, Eiichiro; 隅田　英一郎",2013-117146 03.06.2013 JP,EP-2014807128; US-14893197; KR-1020157030875; CN-201480023760.2
EP249227604,18215235,21.12.2018,3514701,24.07.2019,EP,"METHOD AND DEVICE FOR DISPLAYING MULTI-LANGUAGE TYPESETTING, BROWSER, TERMINAL AND COMPUTER READABLE STORAGE MEDIUM","The present disclosure provides a method and a device for displaying multi-language typesetting, a browser, a terminal and a computer readable storage medium. The method includes: obtaining (S110) a text to be typeset; identifying (S120) embedded language content in a principal language text of the text to be typeset, in which the embedded language content comprises at least one non-principal language content embedded in the principal language text; determining (S130) replacement content of the embedded language content, in which the replacement content comprises a principal language text corresponding to the embedded language content or an abbreviation of a non-principal language text in the embedded language content; and replacing (S140) the embedded language content with the replacement content.",G06F 17/21; G06F 17/22; G06F 17/27,BEIJING BAIDU NETCOM SCI & TEC,XIAO QIUGEN,201810061020 22.01.2018 CN,
EP14194416,04008096,02.04.2004,1465155,06.10.2004,EP,Automatic resolution of segmentation ambiguities in grammar authoring,"A rules-based grammar is generated. Segmentation ambiguities are identified in training data. Rewrite rules for the ambiguous segmentations are enumerated and probabilities are generated for each. Ambiguities are resolved based on the probabilities. In one embodiment, this is done by applying the expectation maximization (EM) algorithm. <IMAGE>",G06F 17/28; G10L 15/18; G06F 17/21; G06F 17/27,MICROSOFT CORP,WANG YEYI; ACERO ALEJANDRO,40652403 03.04.2003 US,
WO2018065045,PCT/EP2016/073768,05.10.2016,WO/2018/065045,12.04.2018,WO,METHOD AND SYSTEM FOR ESTIMATING ENERGY GENERATION BASED ON SOLAR IRRADIANCE FORECASTING,"A method (300) is proposed for estimating energy generated by a solar system (130) in a predetermined geographic area. The method (300) comprises, at each predetermined time instant: - retrieving (305) measured values of at least one weather parameter and of solar irradiance in respect of said predetermined geographic area, said measured values being related to a first time slot before said predetermined time instant; - performing (315) an auto-regression analysis of the measured values; - estimating (315), based on said auto-regression analysis, a relationship between the at least one weather parameter and the solar irradiance; - retrieving (325) forecasted values of said at least one weather parameter in respect of said predetermined geographic area, said forecasted values being forecasted for a second time slot after said predetermined time instant; - performing (330) a regression analysis of said relationship between the at least one weather parameter and the solar irradiance and of said forecasted values; - forecasting (330) a solar irradiance in said second time slot based on said regression analysis, and - estimating energy generated by the solar system (130) in said second time slot according to the forecasted solar irradiance and at least one solar system parameter.",G05B 17/02; G06N 3/04,TELECOM ITALIA S.P.A.,"BOREAN, Claudio; GRASSO, Ennio",,EP-2016788445
EP282270370,18801300,08.05.2018,3598342,22.01.2020,EP,METHOD AND DEVICE FOR IDENTIFYING OBJECT,"The present disclosure relates to an artificial intelligence (AI) system which copies functions of the human brain such as cognition and judgment by utilizing a machine learning algorithm such as deep learning, and to an application of the system. The present disclosure provides a method for a device to identify an object by: acquiring an image including an object; extracting attribute information of the object from the image by using a plurality of layers included in a network for determining a category of the object; acquiring feature information representing the object by combining attribute information of the object extracted from at least some of the plurality of layers by using at least one feature extraction layer; and identifying the object on the basis of the result of a comparison between the acquired feature information and feature information of each of a plurality of pre-stored object images, wherein at least one parameter of the feature extraction layer is set up based on a learning result based on a database including a plurality of images.",G06K 9/20; G06K 9/62,SAMSUNG ELECTRONICS CO LTD,KIM DEOK-HO; LEE WON-WOO; LEE JAE-WOONG; PARK BONG-HOON; LEE GUN-ILL; JEONG JI-WON; NG TERESA KA KI,20170060961 17.05.2017 KR; 2018005257 08.05.2018 KR,
EP74721509,12175196,13.04.2007,2509312,10.10.2012,EP,On-demand language translation for television programs,"A method comprising: receiving a request from a subscriber to translate a video signal from a source language to a target language, wherein the video signal comprises text information in the source language; charging the subscriber a fee for on-demand translation during a paid-for period, after which the on-demand translation expires; generating translated information in the target language based on the text information in the source language during the paid-for period; and outputting the video signal embedded with the translated information.",H04N 7/173; G06F 17/28; H04N 7/088; H04N 21/235; H04N 21/2543; H04N 21/4402; H04N 21/81,AT & T CORP,BANGALORE SRINIVAS; GIBBON DAVID CRAWFORD; GILBERT MAZIN; HAFFNER PATRICK GUY; LIU ZHU; SHAHRARAY BEHZAD,07775510 13.04.2007 EP; 27985206 14.04.2006 US,
WO2019112625,PCT/US2017/065462,08.12.2017,WO/2019/112625,13.06.2019,WO,SIGNAL PROCESSING COORDINATION AMONG DIGITAL VOICE ASSISTANT COMPUTING DEVICES,"Coordinating signal processing among computing devices in a voice-driven computing environment is provided. A first and second digital assistant can detect an input audio signal, perform a signal quality check, and provide indications that the first and second digital assistants are operational to process the input audio signal. A system can select the first digital assistant for further processing. The system can receive, from the first digital assistant, data packets including a command. The system can generate, for a network connected device selected from a plurality of network connected devices, an action data structure based on the data packets, and transmit the action data structure to the selected network connected device.",G06F 9/50; G06F 3/16; G06F 1/32; G10L 15/32,GOOGLE LLC,"KOTHARI, Anshul; BHAYA, Gaurav; JAIN, Tarun",,
WO2017112423,PCT/US2016/065574,08.12.2016,WO/2017/112423,29.06.2017,WO,METHOD AND SYSTEM FOR AUTOMATIC FORMALITY CLASSIFICATION,"The present teaching relates to automatic formality classification and transformation of online text items. In one example, a request is received for determining a formality level of a text item in an online communication. One or more linguistic features are extracted from the text item. Contextual information with respect to the online communication is extracted. A formality level of the text item is determined based on the one or more linguistic features and the contextual information. The formality level represents a degree of formality of the text item. The formality level is provided as a response to the request.",G06F 17/27; G06F 17/28; G06F 17/30; G06Q 30/02,YAHOO! INC.,"TETREAULT, Joel; PAVLICK, Ellie","14/757,446 23.12.2015 US",
WO2003079223,PCT/FI2003/000195,14.03.2003,WO/2003/079223,25.09.2003,WO,METHOD AND ARRANGEMENT FOR TRANSLATING DATA,"The invention relates to a method and arrangement for classifying the data of an input data flow (200) containing elements (211, 212, 213, 221, 222, 223) by using a knowledge base containing segments. The invention is particularly suited for translating languages. In the method, the processable part of the input data flow (200) is read (501), divided into elements (211, 212, 213, 221, 222, 223), and the processable part of the input data flow (200) is divided into segments (502), so that each segment (210, 220) contains one or several elements (211, 212, 213, 221, 222, 223). The elements of the processable part of the input data flow are analyzed, and on the basis of the analysis results there is produced a segment specific classification. The segment classification is compared with the classifications of the knowledge base segments (31, 32), and equivalent segments are associated with each other. Thereafter there is reported the classification result, which consists of a number of knowledge base segments associated with the input data flow to be processed.",G06F 17/28,"MASTER'S INNOVATIONS LTD OY; BECKS, Ari","BECKS, Ari",20020532 20.03.2002 FI,JP-null; EP-2003714987; RU-2004127924; US-10507144
EP232545692,18162628,19.03.2018,3396532,31.10.2018,EP,DYNAMIC PRECISION FOR NEURAL NETWORK COMPUTE OPERATIONS,"In an example, an apparatus comprises a compute engine comprising a high precision component and a low precision component; and logic, at least partially including hardware logic, to receive instructions in the compute engine; select at least one of the high precision component or the low precision component to execute the instructions; and apply a gate to at least one of the high precision component or the low precision component to execute the instructions. Other embodiments are also disclosed and claimed.",G06F 9/30; G06F 1/32; G06F 15/78; G06T 15/00,INTEL CORP,SINHA KAMAL; VEMBU BALAJI; NURVITADHI ERIKO; GALOPPO VON BORRIES NICOLAS C; BARIK RAJKISHORE; LIN TSUNG-HAN; RAY JOYDEEP; TANG PING T; STRICKLAND MICHAEL S; CHEN XIAOMING; YAO ANBANG; SHPEISMAN TATIANA; APPU ABHISHEK R; KOKER ALTUG; AKHBARI FARSHAD; SRINIVASA NARAYAN; CHEN FENG; KIM DUKHWAN; SATISH NADATHUR RAJAGOPALAN; WEAST JOHN C; MACPHERSON MIKE B; HURD LINDA L; RANGANATHAN VASANTH; JAHAGIRDAR SANJEEV S,201715495020 24.04.2017 US,
EP12135686,90113224,11.07.1990,0413132,20.02.1991,EP,A COMPUTER METHOD FOR IDENTIFYING PREDICATE-ARGUMENT STRUCTURES IN NATURAL LANGUAGE TEXT,"A computer method is disclosed for determining predicate-argument structures in input prose sentences of English. The input sentence, in the form of a string of words separated by blanks, is first analyzed (parsed) by a rule component that has access only to morphological and syntactic information about the words. The output of this rule component, in the form of a data structure consisting of attribute-value pairs, is then processed by the argument-structure component, which consists of a set of partially ordered procedures that incorporate further linguistic knowledge. The output of these procedures is the same attribute-value structure, now enhanced by the presence of semantic (i.e., meaningful, non-syntactic) attributes. These semantic attributes, taken together, form the argument structure of the input sentence. The resulting invention constitutes a fully modular, comprehensive and efficient method for passing from syntax to the first stage of semantic processing of natural (human) language. The invention applies to all prose sentences of the language for which it is designed, and not just to a subset of those sentences. It does not use domain-specific semantic information to improve the accuracy or efficiency of the syntactic component. It therefore constitutes an unrestricted broad-coverage method for natural language processing (NLP), as opposed to the restricted methods used in most NLP applications today. Although the specific rules and procedures will be different for different natural languages, the general concept embodied in this invention is applicable to all natural languages.",G06F 17/27; G06F 17/28,INTERNATIONAL BUSINESS MACHINES CORPORATION,"JENSEN, KAREN",39511889 16.08.1989 US,
EP14054372,03254238,03.07.2003,1378838,07.01.2004,EP,Evaluating distinctiveness of document,"Two document sets are compared in natural language processing and the distinctiveness of each constituent element (such as a sentence, term or phrase) of one document set is evaluated by dividing both the target and comparison documents into document segments, constructing the sentence vector of each document segment whose components are the occurring frequencies of terms occurring in the document segment, and projecting all the sentence vectors of both the documents on a projection axis to find a projection axis which maximizes a ratio equal to: (squared sum of projected values originating from the target document)/(squared sum of projected values originating from the comparison document). Projected values are obtained by projecting the sentence vectors on the projection axis, and the degrees of distinctiveness of the individual sentences of the target document are calculated on the basis of the projected values.",G06F 17/21; G06F 17/27; G06F 17/28; G06F 17/30; G06K 9/62,HEWLETT PACKARD DEVELOPMENT CO,KAWATANI TAKAHIKO,2002195375 04.07.2002 JP,
WO2017218273,PCT/US2017/036466,08.06.2017,WO/2017/218273,21.12.2017,WO,COMPUTER PROXY MESSAGING BOT,"A computer system can conduct corresponding natural language dialogs with multiple computer-readable profiles using a computer proxy messaging bot. For example, a first set of natural language instructions can be received via a computer messaging proxy bot from a first computer-readable profile. The first set of natural language instructions can be analyzed via the proxy bot. Also, first and second natural language dialog scripts can be generated via the proxy bot using results of the analyzing of the first set of natural language instructions, with the second natural language dialog script including natural language data derived from the first set of natural language instructions. The first natural language dialog script can be sent to the first profile via the proxy bot and the second natural language dialog script can be sent to a second computer-readable profile via the proxy bot, both in response to the first set of instructions.",G06F 17/27; G06F 17/28,"MICROSOFT TECHNOLOGY LICENSING, LLC","SCHLESINGER, Benny; FITOUSSI, Hen; COHEN, Avichai; BORSUTSKY, Yuval Pinchas; COHEN, Eldar; RAMSEY, William; KOREN, Delia","15/182,059 14.06.2016 US",CN-201780037452.9; EP-2017739747
EP291472779,18868807,13.07.2018,3627397,25.03.2020,EP,PROCESSING METHOD AND APPARATUS,"Provided are a processing method and apparatus. The method involves: respectively quantizing a weight and an input neuron to determine a weight dictionary, a weight code book, a neuron dictionary and a neuron code book; and determining a calculation code book according to the weight code book and the neuron code book. In addition, in the present application, a calculation code book is determined according to quantized data, and the two types of quantized data are combined, thereby facilitating data processing.",G06N 3/02,SHANGHAI CAMBRICON INFORMATION TECH CO LTD,LIU SHAOLI; ZHOU XUDA; DU ZIDONG; LIU DAOFU; ZHANG LEI; CHEN TIANSHI; HU SHUAI; WEI JIE; MENG XIAOFU,201710989575 20.10.2017 CN; 201711004974 24.10.2017 CN; 201711029543 29.10.2017 CN; 201711061069 24.10.2017 CN; 201711118938 29.10.2017 CN; 201711289667 07.12.2017 CN; 2018095548 13.07.2018 CN,
EP11269342,78101879,30.12.1978,0012777,09.07.1980,EP,Method using a programmed digital computer system for translation between natural languages.,"A Computerized translation method with universal application to all natural languages is provided. With this method, parameters are changed only when source or target languages are changed. The computerized method can be regarded as a self-contained system, having been developed to accept input texts in the source language, and look up individual (or sequences of) textwords in various dictionaries. On the basis of the dictionary information, sequences of operations are carried out which gradually generate the multiplicity of computer codes needed to express all the syntactic and semantic functions of the words in the sentence. On the basis of all the codes and target meanings in the dictionary, plus synthesis codes of such meanings, translation is carried out automatically. Procedures which generate and easily update main dictionaries, idiom dictionaries, high frequency dictionaries and compound dictionaries are integral parts of the system.",G05B 1/00; G06F 15/38; G06F 17/27; G06F 17/28,SYSTRAN INST,TOMA PETER DR,873458 12.01.1979 BE; 78101879 30.12.1978 EP; 7900395 09.01.1979 FR; 17667271 31.08.1971 US,
WO2017176749,PCT/US2017/025937,04.04.2017,WO/2017/176749,12.10.2017,WO,SELF-SERVICE CLASSIFICATION SYSTEM,"Systems, technologies and techniques for generating a customized classification model are disclosed. The system and technologies, such as THOMSON REUTERS SELF-SERVICE CLASSIFICATION™, employ part machine learning and part an user interactive approach to generate a customized classification model. The system combines a novel approach for text classification using a smaller initial set of data to initiate training, with a unique workflow and user interaction for customization.",G06F 3/0482; G06F 17/28; G06K 9/62; G10L 15/18,"THOMSON REUTERS GLOBAL RESOURCES UNLIMITED COMPANY; HERTZ, Shai","HERTZ, Shai; ZAROSIM, Hila; HAZAI, Oren; ROM, Ofri; AZIKRI, Ehud; WEINTRAUB, Lior; LINDMAN, Yael; WEINREB, Enav; KHALAMAN, Savva; BEN-SHLOMO, Yossi; LEVINSON, Dmitry; SHARABI, Evyatar; GOLDSHLAGER, Alexandra, Rabinovich","62/376,039 17.08.2016 US; 62/318,412 05.04.2016 US",SG-11201805746Y; CA-3008462; AU-2017246552
WO2019045746,PCT/US2017/049771,31.08.2017,WO/2019/045746,07.03.2019,WO,DATA-DRIVEN AUTOMATED SELECTION OF PROFILES OF TRANSLATION PROFESSIONALS FOR TRANSLATION TASKS,"The subject matter of this specification can be implemented in, among other things, a method that includes storing previous translations of electronic documents for profiles of translation professionals. The method includes receiving a request to translate an electronic document. The method includes selecting ones of the profiles as being experienced in at least one subject area of the electronic document based on a proximity of terms or subject areas in the electronic documents translated by the ones of the profiles to terms or the subject area of the electronic document. The method includes evaluating qualities of the previous translations for each of the selected ones of the profiles. The method includes planning a workflow for translation of the electronic document based on the selected ones of the profiles. The method includes causing the electronic document to be translated according to the planned workflow.",G06Q 10/06; G06Q 10/10; G06F 17/28,SMARTCAT LLC,"TUZHILINA, Elena; UKRAINETS, Artem; GUSAKOV, Vladimir; SMOLNIKOV, Ivan",,US-15782004
EP232832028,17305486,02.05.2017,3399460,07.11.2018,EP,CAPTIONING A REGION OF AN IMAGE,"The invention notably relates to a computer implemented method for learning a function configured for captioning a region of an image, the method comprising providing a dataset of triplets each including a respective image, a respective region of the respective image, and a respective caption of the respective region; and learning, with the dataset of triplets, a function that is configured to generate an output caption based on an input image and on an input region of the input image.  Such a method constitutes an improved solution for captioning a region of an image.",G06K 9/62; G06K 9/00,DASSAULT SYSTEMES,LUBBERS NIELS; BOULKENAFED MALIKA,17305486 02.05.2017 EP,
WO2018124309,PCT/JP2017/047417,25.12.2017,WO/2018/124309,05.07.2018,WO,METHOD AND SYSTEM FOR MULTI-MODAL FUSION MODEL,"A system for generating a word sequence includes one or more processors in connection with a memory and one or more storage devices storing instructions causing operations that include receiving first and second input vectors, extracting first and second feature vectors, estimating a first set of weights and a second set of weights, calculating a first content vector from the first set of weights and the first feature vectors, and calculating a second content vector, tranforming the first content vector into a first modal content vector having a predetermined dimension and tranforming the second content vector into a second modal content vector having the predetermined dimension, estimating a set of modal attention weights, generating a weighted content vector having the predetermined dimension from the set of modal attention weights and the first and second modal content vectors, and generating a predicted word using the sequence generator.",H04N 21/2343; H04N 21/439; H04N 21/8549; G06N 3/04; G10L 25/30; G10L 25/57; G06F 17/30,MITSUBISHI ELECTRIC CORPORATION,"HORI, Chiori; HORI, Takaaki; HERSHEY, John; MARKS, Tim","62/440,433 30.12.2016 US; 15/472,797 29.03.2017 US",DE-112017006685; CN-201780079516.1; JP-2019513858
EP11187857,09179150,14.12.2009,2226733,08.09.2010,EP,Computer assisted natural language translation,"Disclosed are a computer implemented method and apparatus for use in translation of source material in a source natural language into a target natural language, said method comprising performing, in a software process, the steps of: receiving a first data input in said target natural language, said first data input comprising a first part of a sub-segment of a translation of said source material from said source natural language into said target natural language; identifying at least one selectable target text sub-segment in said target natural language associated with said received first data input, said at least one selectable target text sub-segment having been extracted from a corpus of previously translated text segment pairs, each text segment pair comprising a source text segment in said source natural language and a corresponding translated text segment in said target natural language; and outputting said at least one selectable target text sub-segment.",G06F 17/28; G06F 17/27,SDL PLC,CHRIST OLIVER,0903418 02.03.2009 GB,
WO2011067463,PCT/FI2010/050975,29.11.2010,WO/2011/067463,09.06.2011,WO,WEIGHT-ORDERED ENUMERATION OF REFERENTS AND CUTTING OFF LENGTHY ENUMERATIONS,"In many reference resolution problems there are many candidate referents, and the overhead of enumerating them can be considerable. The overhead is reduced by stopping enumeration be- fore all candidate referents have been enumerated, utilizing the properties of ordered and semi-ordered enumerators. Converting semi-ordered enumerators into ordered enumerators and combining several ordered enumerators into a single using dynamic weightings for handling determiner interpretations are dis- closed.",G06F 17/27; G06F 17/28,"TATU YLÖNEN OY; YLÖNEN, Tatu","YLÖNEN, Tatu","12/629,606 02.12.2009 US",EP-2010834276
WO2007120889,PCT/US2007/009280,13.04.2007,WO/2007/120889,25.10.2007,WO,NATURAL LANGUAGE WATERMARKING,"A method, system and machine-readable medium are provided for watermarking natural language digital text. A deep structure may be generated and a group of features may be extracted from natural language digital text input. The deep structure may be modified based, at least pardy, on a watermark. Natural language digital text output may be generated based on die modified deep structure.",G06F 17/27,"AT & T CORP.; ATALLAH, Mike; BANGALORE, Srinivas; HAKKANI-TUR, Dilek, Z.; RICCARDI, Giuseppe; TOPKARA, Mercan; TOPKARA, Umut","ATALLAH, Mike; BANGALORE, Srinivas; HAKKANI-TUR, Dilek, Z.; RICCARDI, Giuseppe; TOPKARA, Mercan; TOPKARA, Umut","11/279,835 14.04.2006 US",EP-2007775502; CA-2649011
EP13961888,03250358,21.01.2003,1335301,13.08.2003,EP,Context-aware linear time tokenizer,"A context automaton such as a left context automaton predefined and a right context automaton generate a context record that is combined with pattern knowledge stored in a token automaton to segment an input data stream into tokens. The resulting context-aware tokenizer can be used in many natural language processing application including text-to-speech synthesizers and text processors. The tokenizer is robust in that upon failure to match any explicitly stored token pattern a default token is recognized. Token matching follows a left-to-right longest-match strategy. The overall process operates in linear time, allowing for fast context-dependent tokenization in practice. <IMAGE>",G06F 17/27; G06F 17/28,MATSUSHITA ELECTRIC IND CO LTD,WALTHER MARKUS,7193402 07.02.2002 US,
WO2018198695,PCT/JP2018/014387,04.04.2018,WO/2018/198695,01.11.2018,WO,PROCESSING APPARATUS AND GENERATION APPARATUS,"An integrated circuit can be easily incorporated in a target apparatus without changing the input/output condition of the integrated circuit. Provided is a processing apparatus that is to be connected to a target apparatus, the processing apparatus including: a first circuit that has a predetermined capability achieved by performing learning, and has a first connection terminal for inputting an input signal for exhibiting the predetermined capability and outputting an output signal that is output by exhibiting the predetermined capability, a second connection terminal for receiving input of an input signal from the target apparatus, and outputting an output signal to the target apparatus, and a second circuit that is connected to the first connection terminal and the second connection terminal, and in which data indicating the connection relationship between the first connection terminal and the second connection terminal is written. The data indicating the connection relationship is generated by learning the connection relationship.",G06N 3/063; G06N 3/08,OMRON CORPORATION,"ANDO, Tanichi",2017-089917 28.04.2017 JP,
WO2003065179,PCT/US2003/003205,03.02.2003,WO/2003/065179,07.08.2003,WO,A SYSTEM AND METHOD FOR MINING DATA,"A system and method for extracting data, hereinafter referred to as MitoMineTM, that produces a strongly-typed ontology defined collection referencing (and cross referencing) all extracted records. The input to the mining process can be any data source, such as a text file delimited into a set of possibly dissimilar records. Mitomine contains parser routines and post processing functions, known as 'munchers'. The parser routines can be accessed either via a batch mining process or as part of a running server process connected to a live source. Munchers can be registered on a per data-source basis in order to process the records produced, possibly writing them to an external database and/or a set of servers. The present invention also embeds an interpreted ontology based language within a compiler/interpreter (for the source format) such that the statements of the embedded language are executed as a result of the source compiler `recognizing' a given construct within the source and extracting the corresponding source content. In this way, the execution of the statements in the embedded program will occur in a sequence that is dictated wholly by the source content. This system and method therefore make it possible to bulk extract free-form data from such sources as CD-ROMs, the web etc. and have the resultant structured data loaded into an ontology based system.",G06F 9/45; G06F 12/06; G06F 13/00; G06F 15/16; G06F 15/173; G06F 17/00; G06F 17/21; G06F 17/27; G06F 17/28; G06F 17/30; G06K 9/72; G06N 5/00,"FAIRWEATHER, John","FAIRWEATHER, John","60/353,487 01.02.2002 US",JP-null
WO2018165579,PCT/US2018/021798,09.03.2018,WO/2018/165579,13.09.2018,WO,AUTOMATED TOOL FOR QUESTION GENERATION,"Computerized methods are disclosed for automated question generation from source documents through natural language processing, for applications including training and testing. Interleaved selection and transformation phases employ combined systematic-syntactic analysis to progressively refine natural input text into a high density of text fragments having high content value. Non-local semantic content and attributes such as emphasis attributes can be attached to the text fragments. The text fragments are reverse parsed by matching against a precomputed library of combined semantic-syntactic patterns. Once the patterns of each fragment are determined, transformation of fragments into question-answer pairs is performed using question selectors and answer selectors tailored to each pattern. Methods for constructing distractors, both internal and external, are also disclosed. The ecosystem of machine learning components, ontology resources, and process improvement are also described.",G06F 17/30,EDUWORKS CORPORATION,"KELSEY, Elaine; GOETSCHALCKX, Robby Jozef Maria; RAY, Ronald Edward; VEDEN, Aaron J.; ROBSON, Elliot Nicholas; ROBSON, Robert O.","62/469,807 10.03.2017 US",EP-2018764977; CA-3055379
WO2011074792,PCT/KR2010/008211,19.11.2010,WO/2011/074792,23.06.2011,WO,MOBILE TERMINAL AND CONTROL METHOD THEREOF,Disclosed is a mobile terminal and control method thereof capable of automatically extracting a user desired key word from already retained information and transmitting the already retained information and/or additional information related to the extracted information based on the extracted information to a certain terminal. The method for controlling a mobile terminal includes: extracting particular information included in a certain message; and transmitting the message and/or additional information corresponding to the particular information based on the extracted particular information.,H04B 1/40; G06F 17/28; H04W 4/02; G06F 17/27,"LG ELECTRONICS INC.; BANG, Kyuseop","BANG, Kyuseop",10-2009-0125721 16.12.2009 KR,EP-2010837789
WO2008109769,PCT/US2008/056087,06.03.2008,WO/2008/109769,12.09.2008,WO,MACHINE LEARNING FOR TRANSLITERATION,"Methods, systems, and apparatus, including computer program products, for performing transliteration between text in different scripts. In one aspect, a method includes generating a transliteration model based on statistical information derived from parallel text having first text in an input script and corresponding second text in an output script; and using the transliteration model to transliterate input characters in the input script to output characters in the output script. In another aspect, a method includes performing word level transliterations. In another aspect, a method includes using an entry-aligned dictionary of source and target script pairs, in which, whenever a particular source word is mapped to multiple target words, the dictionary includes an entry for each target word including the same source word repeated in each entry. In another aspect, a method includes using phonetic scores of words in different scripts to identify corresponding parallel text.",G06F 17/28,"GOOGLE INC.; KATRAGADDA, Lalitesh; DESHPANDE, Pawan; DUTTA, Anupama; ARORA, Nitin","KATRAGADDA, Lalitesh; DESHPANDE, Pawan; DUTTA, Anupama; ARORA, Nitin","60/893,372 06.03.2007 US",EP-2008731575; IN-1845/MUMNP/2009
WO2016134685,PCT/DE2016/000023,19.01.2016,WO/2016/134685,01.09.2016,WO,DEVELOPMENT OF AN EXTREMELY EXTENDED DICTIONARY LEADING TO A NUMERIC LANGUAGE BY SYSTEMATICALLY NUMBERING THE WORDS AND MEANINGS THEREOF,"In order for a natural language to be processed by machines, the vocabulary has to be preprocessed to such an extent that each word has only one meaning, and this requires the creation of new words. Since all words that represent only one meaning are assigned their own whole number, all it takes is to standardize which meaning is to be represented by which number and then have the machine operate only with these numbers instead of new words. Using grammar analysis capability and specific word fields, said method makes possible various new machine-based applications: 1) identify the context of existing original texts and 2) one-to-one machine translation, 3) the new type of word field that particularly ascertains the meaning of a word, 4) automatically summarize large quantities to text. 5) the systematic implementation of the development thus results in a numeric language which is open to all numeric algorithms and which functions linguistically because the rules on how the numbers interact in the relational database have been established using natural grammatical rules rather than formal ones.",G06F 17/27; G06F 17/28,"GRAF ZU CASTELL, Nikolaus","GRAF ZU CASTELL, Nikolaus",10 2015 001 596.6 07.02.2015 DE,
WO2018194994,PCT/US2018/027835,16.04.2018,WO/2018/194994,25.10.2018,WO,ENHANCING PROCESSING PERFORMANCE OF A DNN MODULE BY BANDWIDTH CONTROL OF FABRIC INTERFACE,"An exemplary computing environment having a DNN module can maintain one or more bandwidth throttling mechanisms. Illustratively, a first throttling mechanism can specify the number of cycles to wait between transactions on a cooperating fabric component (e.g., data bus). Illustratively, a second throttling mechanism can be a transaction count limiter that operatively sets a threshold of a number of transactions to be processed during a given transaction sequence and limits the number of transactions such as multiple transactions in flight to not exceed the set threshold. In an illustrative operation, in executing these two exemplary calculated throttling parameters, the average bandwidth usage and the peak bandwidth usage can be limited. Operatively, with this fabric bandwidth control, the processing units of the DNN are optimized to process data across each transaction cycle resulting in enhanced processing and lower power consumption.",G06N 3/04; G06N 3/063,"MICROSOFT TECHNOLOGY LICENSING, LLC","MCBRIDE, Chad Balling; HEIL, Timothy Hume; AMBARDEKAR, Amol Ashok; PETRE, George; CEDOLA, Kent D.; WALL, Larry Marvin; BOBROV, Boris","62/486,432 17.04.2017 US; 15/950,644 11.04.2018 US",EP-2018724644; CN-201880025130.7
WO2014105912,PCT/US2013/077712,24.12.2013,WO/2014/105912,03.07.2014,WO,FAST OUT-OF-VOCABULARY SEARCH IN AUTOMATIC SPEECH RECOGNITION SYSTEMS,"A method including: receiving, on a computer system, a text search query, the query including one or more query words; generating, on the computer system, for each query word in the query, one or more anchor segments within a plurality of speech recognition processed audio files, the one or more anchor segments identifying possible locations containing the query word; post-processing, on the computer system, the one or more anchor segments, the post-processing including: expanding the one or more anchor segments; sorting the one or more anchor segments; and merging overlapping ones of the one or more anchor segments; and searching, on the computer system, the post-processed one or more anchor segments for instances of at least one of the one or more query words using a constrained grammar.",G10L 15/18; G10L 15/26; G10L 15/28; G06F 17/28,"GREENEDEN U.S. HOLDINGS II, LLC","LEV-TOV, Amir; FAIZAKOF, Avraham; KONIG, Yochai","61/791,581 15.03.2013 US; 61/747,242 29.12.2012 US; 13/886,205 02.05.2013 US",EP-2013866559; CN-201380074067.3
WO2012079245,PCT/CN2010/079937,17.12.2010,WO/2012/079245,21.06.2012,WO,DEVICE FOR ACQUIRING KNOWLEDGE AND METHOD THEREOF,"A device and a method for acquiring knowledge are provided, wherein the device includes: a case frame feature extraction unit, used to extract case frame elements and attribute information thereof from the the predicate elements in an inputted sentence; a model database, used to store arbitrary case models; arbitrary case judgement unit, used to perform a model matching on the extraction results from the case frame feature extraction unit and the arbitrary case models to determine the arbitrary case information in the case frame of the predicate elements. The process of automatic obtainment and effective distinction of the essential case and arbitrary case of the case frame of the predicate elements are realized，and the ability of structure disambiguation and semantic disambiguation of the natural language process are improved.",G06F 17/28,"BEIJING JIAOTONG UNIVERSITY; 北京交通大学; XU, Jinan; 徐金安; MENG, Fandong; 孟凡东; CHEN, Qia; 陈恰; PAN, Xu; 潘栩; DA, Zhen; 达珍; MENG, Qingchen; 孟庆辰","XU, Jinan; 徐金安; MENG, Fandong; 孟凡东; CHEN, Qia; 陈恰; PAN, Xu; 潘栩; DA, Zhen; 达珍; MENG, Qingchen; 孟庆辰",,CN-201080069243.0
WO2016094649,PCT/US2015/064978,10.12.2015,WO/2016/094649,16.06.2016,WO,WEIGHTED SUBSYMBOLIC DATA ENCODING,"Described herein is a method and system of geometrically encoding data including partitioning data into a plurality of semantic classes based on a dissimilarity metric, generating a subspace formed by first and second data elements, the first and second data elements being included in first and second numbers of partitioned semantic classes, encoding the first data element with respect to the second data element such that the generated subspace formed by the first data element and the second data element is orthogonal, computing a weight distribution of the first data element with respect to the second data element, the weight distribution being performed for each of the first number of semantic classes and the second number of semantic classes, and determining a dominant semantic class corresponding to an ordered sequence of the first data element and the second data element, the dominant semantic class having a maximum weight distribution.",G06F 17/28,"KYNDI, INC.","MAJUMDAR, Arun","62/090,198 10.12.2014 US",CA-2970168; AU-2015360472; JP-2017550085; KR-1020177018967
EP206520225,16869294,23.11.2016,3245652,22.11.2017,EP,DEPLOYED END-TO-END SPEECH RECOGNITION,,G10L 15/16; G10L 15/06; G10L 15/08; G10L 15/183,BAIDU USA LLC,CATANZARO BRYAN; CHEN JINGDONG; CHRZANOWSKI MIKE; ELSEN ERICH; ENGEL JESSE; FOUGNER CHRISTOPHER; HAN XU; HANNUN AWNI; PRENGER RYAN; SATHEESH SANJEEV; SENGUPTA SHUBHABRATA; YOGATAMA DANI; WANG CHONG; ZHAN JUN; ZHU ZHENYAO; AMODEI DARIO,201562260206 25.11.2015 US; 2016063641 23.11.2016 US; 201615358083 21.11.2016 US; 201615358102 21.11.2016 US,
WO2010080180,PCT/US2009/055623,01.09.2009,WO/2010/080180,15.07.2010,WO,NATURAL LANGUAGE ASSERTION PROCESSOR,"A method of processing natural language assertions (NLAs) can include identifying an NLA and then translating that NLA into a verification language assertion (VLA) using a natural language parser (NLP) and synthesis techniques. This VLA can be translated into an interpreted NLA (NLA*) using a VLA parser and pattern matching techniques. At this point, the process can allow user review of the NLA* and the NLA. When the user determines that the NLA* and the NLA are the same or have insignificant difference, then verification can be performed using the VLA. The results of the verification can then be back annotated on the NLA. In one fully-automatic embodiment, in addition to comparing the NLA and the NLA*, the VLA and a VLA* (generated from the NLA*) can be compared, thereby providing yet another test of accuracy for the user during verification.",G06F 17/28; G06F 17/27; G06F 17/20; G06F 17/25,"SYNOPSYS, INC.; DARGELAS, Alain, M.","DARGELAS, Alain, M.","12/352,423 12.01.2009 US",JP-2010546153; KR-1020097022583; EP-2009736555; CN-200980000269.7
EP14062260,02733992,17.04.2002,1390867,25.02.2004,EP,SYSTEM AND METHOD FOR STORING DATA USING A MACHINE READABLE VOCABULARY,"A system and method for storing and processing words (figure 1) of a vocabulary that represents all concepts (figure 2). The words are divided into a number of field (figure 3), each field having meaning with respect to the meaning of the word. The fields (fig. 3) are stored and processed in a manner that allows the meaning of each field to be recognized by machine. The meanings of each field are processed to interpret the meaning of each word. This vocabulary of words as stored and processed by machine is particularly useful in fields such as artificial intelligence, natural language processing and database processing.",G06F 17/20; G06F 17/27; G06F 17/28; G06F 17/21; G06F 17/30; G06F 17/30,HARVEY GEORGE HAMILTON; HARVEY SUZANNE ELIZABETH,HARVEY GEORGE HAMILTON; HARVEY SUZANNE ELIZABETH,0211943 17.04.2002 US; 83540001 17.04.2001 US,
WO2013172500,PCT/KR2012/003998,21.05.2012,WO/2013/172500,21.11.2013,WO,APPARATUS AND METHOD FOR DETERMINING SIMILARITY BETWEEN PARAPHRASE IDENTIFICATION-BASED SENTENCES,"The present invention discloses an apparatus for determining the similarity between paraphrase identification-based sentences, and a method for operating same. The present invention comprises: a phrase analysis step for extracting predicate argument tuples corresponding to a first sentence and a second sentence, respectively, by designating a correlation between two or more words included in each phrase in a sentence, on the basis of a grammatical relationship between the words comprising the sentence; a similarity measuring step of measuring the similarity between one or more predicate argument tuples extracted from the first sentence and one or more predicate argument tuples extracted from the second sentence; and an approximate alignment step of carrying out an approximate alignment for measuring the similarity between the first sentence and the second sentence, on the basis of the similarity of the predicate argument tuples that is measured, thereby enabling an approach to a paraphrase identification problem with a supervised learning-based automatic categorization model.",G06F 17/27; G06F 17/28,"KOREA INSTITUTE OF SCIENCE & TECHNOLOGY INFORMATION; 한국과학기술정보연구원; CHOI, Sung Pil; 최성필; CHUN, Hong Woo; 전홍우; JEONG, Chang Hoo; 정창후; CHOI, Yun Soo; 최윤수; SONG, Sa Kwang; 송사광; JUNG, Han Min; 정한민","CHOI, Sung Pil; 최성필; CHUN, Hong Woo; 전홍우; JEONG, Chang Hoo; 정창후; CHOI, Yun Soo; 최윤수; SONG, Sa Kwang; 송사광; JUNG, Han Min; 정한민",10-2012-0052736 17.05.2012 KR,
WO2016099867,PCT/US2015/063277,01.12.2015,WO/2016/099867,23.06.2016,WO,APP STORE UPDATE NOTIFICATION AND WARNING SYSTEM,"A system for maintaining and upgrading hardware device functioning provides processes to select and install updates for software (e.g., applications or apps) on the hardware device. A notification system provides information for discretion and control over the selection of software updates to be applied to consumer mobile devices according to the particular characteristics of the device, e.g., the model of device, the specific operating system of the device, and software applications installed on the device. The notification system may be integral with app stores on mobile devices and tablets, and may also be applicable to the Internet of Things. A notification may take the form, for example, of a warning or recommendation associated with an update for an app on the user device and may enable the user to make an informed decision beforehand about whether or not to install a particular update on the user device.",G06Q 30/02; G06F 17/28; G06F 17/30,"PAYPAL, INC.","DAS, Ananya; ZIAJA, Jason; LUK, Bryant Genepang; BRENNER, Jennifer T.; TANG, Yu; HE, Robert; O'TOOLE, Christopher Diebold","14/577,025 19.12.2014 US",
WO2014030834,PCT/KR2013/005403,19.06.2013,WO/2014/030834,27.02.2014,WO,"METHOD FOR DETECTING GRAMMATICAL ERRORS, ERROR DETECTION DEVICE FOR SAME, AND COMPUTER-READABLE RECORDING MEDIUM HAVING METHOD RECORDED THEREON","The present invention relates to a method for detecting grammatical errors, an error detection device for the same and a computer-readable recording medium having the method recorded thereon, wherein the frequency of morpheme sequences which are the same as a forward morpheme sequence and a reverse morpheme sequence with respect to a written sentence are confirmed and errors on the basis of a high frequency are detected. An example-based technique in the natural language processing field is an existing technique used in machine translation, and a method for extracting translation knowledge with many pairs of original sentences and translated sentences as examples and performing automatic translation on the basis of the extracted translation knowledge is applied. Therefore, since the example-based method applied in machine translation uses a large amount of examples, there is an advantage of using the example-based method as a high-quality translation function. Particularly, since language naturally changes according to the time and location rather than rules, patterns frequently used by people can be easily applied even without continuously generating complicated rules.",G06F 17/27,"SK TELECOM CO., LTD.; 에스케이텔레콤 주식회사","KIM, Seunghwan; 김승환",10-2012-0092088 23.08.2012 KR,
WO2013089668,PCT/US2011/064453,12.12.2011,WO/2013/089668,20.06.2013,WO,CONTENT-BASED AUTOMATIC INPUT PROTOCOL SELECTION,"Technologies for selecting an input protocol based on an input content are generally disclosed. In one example, a method for selecting an input protocol based on an input content can include: acquiring the input content; analyzing the input content; extracting one or more indivisible individual units from the input content; calculating a similarity between a first frequency of occurrence of the one or more indivisible individual units and a second frequency of occurrence of the one or more indivisible individual units, wherein the second frequency of occurrence of the one or more indivisible individual units is predetermined with a second value of frequency of occurrence; ranking the similarity; identifying the input protocol based on the similarity; and selecting a first ranked input protocol having a highest similarity.",G06F 17/28,"EMPIRE TECHNOLOGY DEVELOPMENT LLC; KURABAYASHI, Shuichi; YOSHIDA, Naofumi; TAKANO, Kosuke","KURABAYASHI, Shuichi; YOSHIDA, Naofumi; TAKANO, Kosuke",,KR-1020147018984; JP-2014547149; US-13519308
WO2008107305,PCT/EP2008/052051,20.02.2008,WO/2008/107305,12.09.2008,WO,SEARCH-BASED WORD SEGMENTATION METHOD AND DEVICE FOR LANGUAGE WITHOUT WORD BOUNDARY TAG,"Disclosed are a search-based word segmentation method and device for a language without a word boundarytag. The method includes the steps of: a. providing at least one search engine witha segment of a text including at least one segment; b. searching for the segment through the at least one search engine, and returning search results; and c. selecting a word segmentation approach for the segment in accordance with at least part of the returned search results. The method and device address the problems of word segmentation for a language without a word boundary tag, and thus combat the limitations of the prior art in terms of flexibility, dependence upon coverage of dictionaries, available training data corpuses, processing of a new word, etc.",G06F 17/28,"INTERNATIONAL BUSINESS MACHINES CORPORATION; IBM UNITED KINGDOM LIMITED; LIU, Wen; QIN, Yong; WANG, Xin Jing","LIU, Wen; QIN, Yong; WANG, Xin Jing",200710086030.9 07.03.2007 CN,
EP76200414,12181098,20.08.2012,2563003,27.02.2013,EP,Cloud-based translation service for multi-function peripheral,"Techniques are provided for translating a document that was scanned by a multi-function peripheral (MFP). A server within a computing cloud receives an MFP identifier and processed scan data that results from optical character recognition and/or natural language translation having been performed on scan data produced by the MFP. In response to the receipt of the processed scan data at the server, the server selects a set of rules that is mapped to a context to which the MFP identifier is mapped. Corrected processed scan data is generated by applying the set of rules to the processed scan data that was received by the server. Manual corrections made to the corrected processed scan data may be used to update the set of rules so that those corrections are also made to other processed scan data produced by MFPs having identifiers mapped to the same context.",H04N 1/00; G06F 17/28; G06K 9/00; G06K 9/03; G06K 9/32; G06K 9/68,RICOH CO LTD,SHARMA DEEKSHA,201113217198 24.08.2011 US,
WO2019140075,PCT/US2019/013027,10.01.2019,WO/2019/140075,18.07.2019,WO,CODE-SWITCHING OF BLENDED MULTILINGUAL CONTENT,An electronic platform to generate and display blended multilingual content. The methods and systems can be employed in an educational environment to assist a user fluent in a native language in learning a target language. One or more blended combinations of content in the native language and the target language are generated and displayed to the user. A machine learning component can be used to evaluate performance data to execute adjusts to the level and type of blending applied to the blended combinations to increase and improve learning efficiency.,G06F 17/21; G06F 17/27; G06F 17/28; G09B 19/06,"TRANSCENDENT INTERNATIONAL, LLC.","TAN, William Z.","62/615,739 10.01.2018 US",
WO2018034902,PCT/US2017/046023,09.08.2017,WO/2018/034902,22.02.2018,WO,KNOWLEDGE GRAPH CONSTRUCTION FOR ONLINE PERSONAL ASSISTANT,"Processing natural language user inputs into a more formal, machine-readable, structured query representation used for making an item recommendation. Analyses of user inputs are coordinated via a knowledge graph constructed from categories, attributes, and attribute values describing relatively frequently occurring prior interactions of various users with an electronic marketplace. The knowledge graph has directed edges each with a score value based on: the conditional probabilities of category/attribute/attribute value interactions calculated from user behavioral patterns, associations between user queries and structured data based on historical buyer behavioral patterns in the marketplace, metadata from items made available for purchase by sellers used to better define buyers requirements, and/or world knowledge of weather, locations/places, occasions, and item recipients that map to inventory-related data, for generating relevant prompts for further user input. The knowledge graph may be dynamically updated during a multi-turn interactive dialog.",G06N 3/04; G06N 5/02; G06F 17/30; G06Q 30/02,EBAY INC.,"KALE, Ajinkya Gorakhnath; HEWAVITHARANA, Sanjika","15/238,679 16.08.2016 US",
WO2019051064,PCT/US2018/049716,06.09.2018,WO/2019/051064,14.03.2019,WO,SEMANTIC VECTOR RULE DISCOVERY,"Various data or document processing systems may benefit from an improved machine learning process for information extraction. For example, certain data or document processing systems may benefit from enhanced Semantic Vector Rules and a lexical knowledge base used to extract information from the text. A method may include analyzing a set of documents including a plurality of text. The method may also include extracting information from the plurality of text based on one or more semantic vector rules. In addition, the method may include updating the one or more semantic vector rules to include at least one new semantic vector rule based on a semantic rule state evaluation.",G06F 17/27; G06F 17/21; G06F 17/28; G06F 15/18,"ROSOKA SOFTWARE, INC.","SORAH, Michael Allen; ROBERTS, Gregory F.","62/554,847 06.09.2017 US",
EP153679719,14461535,29.05.2014,2950306,02.12.2015,EP,A method and system for building a language model,"A method for building a language model, the method comprising the steps of: providing (101) a corpus; dividing (103) the corpus into words; dividing (104) the words into word chunks; calculating (105) n-gram tables; training (106) the model to create a language model; wherein calculating (105) the n-gram tables comprises generating n-grams of complete words, n-grams of word chunks and n-grams of words and chunks.",G10L 15/197; G06F 17/27; G06K 9/72,SAMSUNG ELECTRONICS POLSKA SPOLKA Z ORGANICZONA ODPOWIEDZIALNOSCIA,BRODA BARTOSZ; MAZUR PAWEL; GWARDYS GRZEGORZ; DURZEWSKI MACIEJ,14461535 29.05.2014 EP,
EP241675012,17815062,17.05.2017,3477586,01.05.2019,EP,"IMAGE PROCESSING DEVICE, IMAGE PROCESSING METHOD, AND IMAGE PROCESSING PROGRAM","The purpose of the present invention is to provide an image processing device, image processing method, and image processing program which are capable of distinguishing between a background which is surrounded by a plurality of cell nuclei and an outline-only cell nucleus, in an image process which extracts, from an image in which a tissue specimen has been photographed, a cell upon which a staining process has been carried out. This image processing device comprises: an input means which receives an input of an image which has been obtained by photographing a stained specimen; a cell region extraction means which extracts from the image, as cell regions, regions in which the staining has been carried out; a candidate region extraction means which extracts, as candidate regions, regions which are surrounded by the cell regions and in which the staining has not been carried out; a characteristic value extraction means which extracts characteristic values of the candidate regions; an assessment means which, on the basis of the characteristic values which have been extracted from the candidate regions, assesses whether the candidate regions are cell regions; and a correction means which corrects, to be cell regions, the candidate regions which have been assessed by the assessment means as being cell regions.",G06T 7/00; G01B 11/24; G01N 33/48; G01N 33/483; G06T 7/60,KONICA MINOLTA INC,MIMURA YUSUKE,2016124037 23.06.2016 JP; 2017018453 17.05.2017 JP,
EP12034054,89310723,18.10.1989,0365309,25.04.1990,EP,A data unification system and method,"Unification of a disjunctive system is performed based on context identifiers within data structures that correspond to disjunctions. Each context identifier is a logical combination of choices, with each choice identifying one of the disjuncts of a disjunction in the system. Each choice can include a disjunction identifier and a choice identifier identifying one of the disjuncts of the identified disjunction. The logical combination of choices in a context identifier thus corresponds to a combination of disjuncts, all of which could be from different disjunctions. If two data units have context identifiers identifying contexts that are genuine alternatives, those data units are not unified. Data units that have context identifiers that are not genuine alternatives are unified. A set of context-value pairs, referred to as a disjunctive value, can be unified with another disjunctive value by considering all combinations of pairs of context identifiers that include one context identifier from each disjunctive value. The number of combinations of context identifiers in each disjunctive value is reduced by combining context-value pairs: Pairs with equal value tokens are combined by merging their context identifiers and unifying the value tokens. Pairs with f-structures as values are combined by merging context identifiers and unifying the f-structures. An equality within a disjunct is handled by unifying the equated entities, but only in the context appropriate to that disjunct. If it is necessary to insert a pointer, the pointer is inserted so that it initially leads to a disjunctive value, with the source of the pointer indicating which of the context-value pairs in the disjunctive value is to be accessed. This technique can avoid exponential growth for some classes of the NP-complete problem that occur in such domains as natural language processing.",G06F 9/44; G06F 9/44; G06F 17/27; G06F 17/28,XEROX CORP,MAXWELL III JOHN T; KAPLAN RONALD M,26020588 19.10.1988 US,
WO2018212538,PCT/KR2018/005524,15.05.2018,WO/2018/212538,22.11.2018,WO,ELECTRONIC DEVICE AND METHOD OF DETECTING DRIVING EVENT OF VEHICLE,"Provided are a method and an electronic device for determining whether a driving event of a vehicle occurs, based on a location of an object in a plurality of frames, using a plurality of trained models.",G06T 7/70; G06T 5/30; G06N 3/08; G06N 99/00; B60W 30/08; B60W 50/14,"SAMSUNG ELECTRONICS CO., LTD.","JANG, Seo-woo; BAN, Dae-hyun; PARK, Un-kyu","62/506,712 16.05.2017 US; 10-2018-0049405 27.04.2018 KR",EP-2018801907
WO2020023298,PCT/US2019/042542,19.07.2019,WO/2020/023298,30.01.2020,WO,"DEVICE, SYSTEM AND METHOD FOR CAUSING AN OUTPUT DEVICE TO PROVIDE INFORMATION FOR VOICE COMMAND FUNCTIONALITY","A device, system and method for causing an output device to provide information for voice command functionality is provided. A controller determines when a received textual term, received at the controller via one or more of an input device and a communications unit, is phonetically similar to one or more existing textual terms used for activating functionality at a communication device using a voice recognition algorithm. When the received textual term, are phonetically similar to one or more existing textual terms, the controller: generates one or more suggested textual terms, related to the received textual term, that minimizes phonetic similarities with the one or more existing textual terms; and causes an output device to provide an indication of the one or more suggested textual terms to use in place of the received textual term.",G06F 17/28,"MOTOROLA SOLUTIONS, INC.","KING, Melanie A.; SIDDOWAY, Craig F","16/042,056 23.07.2018 US",
EP13578377,99951722,01.10.1999,1125279,22.08.2001,EP,SYSTEM AND METHOD FOR PROVIDING NETWORK COORDINATED CONVERSATIONAL SERVICES,"A system and method for providing automatic and coordinated sharing of conversational resources, e.g. functions and arguments, between network-connected servers and devices, and their corresponding applications. In one aspect, a system for providing automatic and coordinated sharing of conversational resources comprises: a network comprising a first (100), and second (106) network device; the first (100) and second (106) network device each comprising a set of conversational resources (102, 107), a dialog manager (103, 108), for managing a conversation and executing calls requesting a conversational service, and a communication stack (111, 115), for communicating messages over a network using conversational protocols, wherein the conversational protocols establish coordinated network communication between the dialog managers of the first and second device to automatically share the set of conversational resources of the first and second network device, when necessary, to perform their respective requested conversational service.",G06F 3/16; G10L 15/22; G06F 9/44; G06F 9/46; G06F 9/54; G06F 12/00; G06F 15/00; G06F 17/28; G06F 17/30; G06F 40/00; G10L 13/00; G10L 13/08; G10L 15/26; H04M 1/253; H04M 1/27; H04M 1/725; H04M 3/42; H04M 3/44; H04M 3/493; H04M 3/50; H04M 7/00; H04M 11/00,IBM,MAES STEPHANE H; GOPALAKRISHNAN PONANI,10295798 02.10.1998 US; 11759599 27.01.1999 US; 9922925 01.10.1999 US,
EP244377306,17306801,18.12.2017,3499384,19.06.2019,EP,WORD AND SENTENCE EMBEDDINGS FOR SENTENCE CLASSIFICATION,,G06F 17/27; G06F 17/28,FORTIA FINANCIAL SOLUTIONS,MANSAR YOUNESS; FERRADANS SIRA; STAIANO JACOPO,17306801 18.12.2017 EP,
WO2016186966,PCT/US2016/032146,12.05.2016,WO/2016/186966,24.11.2016,WO,COORDINATED USER WORD SELECTION FOR TRANSLATION AND OBTAINING OF CONTEXTUAL INFORMATION FOR THE SELECTED WORD,"A computer-implemented technique can include receiving a selection by a user of a single word in a document in a source language, the document being displayed in a viewing application executing at the computing device, obtaining contextual information from the document that is indicative of a context of the selected word, providing the selected word and its contextual information from the viewing application to a different translation application, obtaining potential translated words using the translation application, the selected word, and its contextual information, each potential translated word being a potential translation of the selected word to a different target language that is preferred by the user, and displaying the potential translated words.",G06F 17/28,GOOGLE INC.,"CUTHBERT, Alexander Jay; CATTIAU, Julie","14/714,419 18.05.2015 US",DE-112016002275; GB-1715508.6; EP-2016725317
WO2018131259,PCT/JP2017/038781,26.10.2017,WO/2018/131259,19.07.2018,WO,TEXT EVALUATION DEVICE AND TEXT EVALUATION METHOD,"Provided is a text evaluation device (2) which carries out an evaluation of inputted text. The text evaluation device comprises acquisition units (22-25) and a computation processing unit (20). The acquisition units acquire information which indicates a first input text and information which indicates a second input text. The computation processing unit carries out an information process, which is performed by an algorithm (3) based on machine learning, upon the information which has been acquired by the acquisition units. The computation processing unit comprises a first encoder (31) that recognizes the first input text and a second encoder (32) that recognizes the second input text in the algorithm based on the machine learning. On the basis of a result of the recognition of the first input text in the first encoder and a result of the recognition of the second input text in the second encoder, the computation processing unit generates evaluation information which indicates an evaluation of the first input text in relation to the second input text.",G06F 17/28,"PANASONIC INTELLECTUAL PROPERTY MANAGEMENT CO., LTD.; パナソニックＩＰマネジメント株式会社","ISHIDA, Ryo; 石田　諒; NAKAO, Taketoshi; 中尾　武寿; MORIOKA, Mikio; 森岡　幹夫",2017-002777 11.01.2017 JP,JP-2018561820
EP128597558,13174929,03.07.2013,2821934,07.01.2015,EP,System and method for optical character recognition and document searching based on optical character recognition,"The present invention provides a method for document searching. The method for document searching comprises: capturing a first image of a first portion of a document at a device; determining a first text associated with the first image, wherein the first text is determined by performing optical character recognition (OCR) on the first image; receiving a first result from a first search of a set of documents that was performed based on one or more search terms determined based on the first text associated with the first image; and presenting the first result on the device. Additionally, the present invention provides a method for performing optical character recognition (OCR) on a device.",G06K 9/00; G06F 17/30; G06K 9/22; G06K 9/72,OPEN TEXT S A,COPSEY SIMON,13174929 03.07.2013 EP,
WO2006002219,PCT/US2005/022027,21.06.2005,WO/2006/002219,05.01.2006,WO,SYSTEMS AND METHODS FOR SPELL CORRECTION OF NON-ROMAN CHARACTERS AND WORDS,"Systems and methods to process and correct spelling errors for non-Roman based words such as in Chinese, Japanese, and Korean languages using a rule-based classifier and a hidden Markov model are disclosed. The method generally includes converting an input entry in a first language such as Chinese to at least one intermediate entry in an intermediate representation, such as pinyin, different from the first language, converting the intermediate entry to at least one possible alternative spelling or form of the input in the first language, and determining that the input entry is either a correct or questionable input entry when a match between the input entry and all possible alternative spellings to the input entry is or is not located, respectively. The questionable input entry may be classified using, for example, a transformation rule based classifier based on transformation rules generated by a transformation rules generator.",G06F 17/27,"GOOGLE INC.; WU, Jun; ZHU, Hongjun; ZHU, Huican; HUANG, Wei-Hwa; CHAN, Chiu-Ki","WU, Jun; ZHU, Hongjun; ZHU, Huican; HUANG, Wei-Hwa; CHAN, Chiu-Ki","10/875,449 23.06.2004 US",KR-1020077001543; EP-5762558; CN-200580026350.4; DE-null; JP-2007518226
WO2015077398,PCT/US2014/066513,20.11.2014,WO/2015/077398,28.05.2015,WO,ADAPTIVE VIRTUAL INTELLIGENT AGENT,"Embodiments of an adaptive virtual intelligent agent (""AVIA"") service are disclosed. It may include the functions of a human administrative assistant for an enterprise including customer support, customer relationship management, and fielding incoming caller inquiries. It also has multi-modal applications for the home through interaction with AVIA implemented in the home. It may engage in free-form natural language dialogs. During a dialog, embodiments maintain the context and meaning of the ongoing dialog and provides information and services as needed by the domain of the application. Over time, the service automatically extends its knowledge of the domain (as represented in the Knowledge Tree Graphs) through interaction with external resources. Embodiments can intelligently understand and converse with users using free-form speech without pre-programmed deterministic sequences of questions and answers, can dynamically determine what it needs to know to converse meaningfully with users, and knows how to obtain information it needs.",G10L 15/00,"LONDON, Justin","LONDON, Justin","61/906,839 20.11.2013 US; 62/026,023 17.07.2014 US; 14/546,097 18.11.2014 US",
EP250371224,18211564,11.12.2018,3525108,14.08.2019,EP,INCREMENTAL GENERATION OF WORD EMBEDDING MODEL,,G06F 17/27,NTT DOCOMO INC,SUBASIC PERO; LIN XIAO,201816200548 26.11.2018 US; 201862628177 08.02.2018 US,
WO2002035376,PCT/US2001/032636,26.10.2001,WO/2002/035376,02.05.2002,WO,ONTOLOGY-BASED PARSER FOR NATURAL LANGUAGE PROCESSING,"An ontology-based parser incorporates both a system and method for converting natural-language text into predicate-argument format that can be easily used by a variety of applications, including search engines, summarization applications, categorization applications, and word processors. The ontology-based parser contains functional components for receiving documents in a plurality of formats, tokenizing them into instances of concepts from an ontology, and assembling the resulting concepts into predicates. The ontological parser has two major functional elements, a sentence lexer and a parser. The sentence lexer takes a sentence and converts it into a sequence of ontological entities that are tagged with part-of-speech information. The parser converts the sequence of ontological entities into predicate structures using a two-stage process that analyzes the grammatical structure of the sentence, and then applies rules to it that bind arguments into predicates.",G06F 17/27,SCIENCE APPLICATIONS INTERNATIONAL CORPORATION,"BUSCH, Justin, Eliot; LIN, Albert, Deirchow; GRAYDON, Patrick, John; CAUDILL, Maureen","09/697,676 27.10.2000 US",
WO2003079276,PCT/US2002/020423,28.06.2002,WO/2003/079276,25.09.2003,WO,PORTABLE OBJECT IDENTIFICATION AND TRANSLATION SYSTEM AND METHOD,"A portable information system is comprised of an input device for capturing an image having a user-selected object or text, and a background. A hand-held computer is responsive to the input device and is programmed to: distinguish the user-selected object/text from the background; compare the user-selected object to a database of objects/characters; and output a translation of, information about, or interpretation of, the user-selected object or text in response to the step of comparing. The invention is particularly useful as a portable aid for translating or remembering text messages foreign to the user that are found in visual scenes. A second important use is to provide mobile information and guidance to the mobile user in connection with surrounding objects (such as, identifying landmarks, people, and/or acting as a navigational aid). Methods of operating the present invention are also disclosed.",G06F 1/16; G06K 9/22,"MOBILE TECHNOLOGIES, INC.","WAIBEL, Alex","10/090,559 04.03.2002 US",JP-null
WO2016130788,PCT/US2016/017524,11.02.2016,WO/2016/130788,18.08.2016,WO,DETERMINING REPLY CONTENT FOR A REPLY TO AN ELECTRONIC COMMUNICATION,"Methods and apparatus related to determining reply content for a reply to an electronic communication. Some implementations are directed generally toward analyzing a corpus of electronic communications to determine relationships between one or more original message features of ""original"" messages of electronic communications and reply content that is included in ""reply"" messages of those electronic communications. Some implementations are directed generally toward providing reply text to include in a reply to a communication based on determined relationships between one or more message features of the communication and the reply text.",G06F 17/24; G06F 17/28; G06Q 10/10,GOOGLE INC.,"SHARP, Phillip Neal; RAGHAVAN, Prabhakar; GAWLEY, Thompson Alexander Ivor; MIKLOS, Balint; KURACH, Karol; KAUFMANN, Tobias; CORRADO, Gregory Sean; LUKÁCS, László","14/620,630 12.02.2015 US",GB-1714398.3; DE-112016000741
EP233149134,17305546,12.05.2017,3401796,14.11.2018,EP,FAULT-TOLERANT INFORMATION EXTRACTION,"The invention provides a computer-implemented method for automatically analyzing a natural language input for information extraction, the method comprising (i) a step of receiving the natural language input; (ii) a step of providing a grammar model, the grammar model comprising: a local grammar model with a finite set of state transitions between states, at least one external function for information extraction, linked to the local grammar model, and a finite set of read/write memory locations, accessible by the at least one external function, in which are stored the natural language input, the states, one or more outputs of the grammar model, and/or other data; (iii) a step of applying the grammar model to at least a part of the natural language input; at least one of the state transitions of the finite set of state transitions being defined by a current state, a following state, an input label and an output label, and wherein the external function is attached to the state transition, the external function being an operation over: at least the part of the natural language input, one or more states, at least one output of the grammar model, and/or other data; the external function having a read/write access to: the natural language input, the current state, an output of the grammar model, and/or other data, applying the grammar model comprising evaluating the external function attached to the at least one state transition; and the external function returning, after being called, a return value, applying the grammar model further comprising changing from the current state to the following state of the at least one state transition, whenever the condition is fulfilled that the external function returns a non-empty string, a number or a boolean value equal to true.",G06F 17/27,UNIV PARIS EST MARNE LA VALLEE; ESIEE PARIS CHAMBRE DE ET DINDUSTRIE DE REGION PARIS ILE DE FRANCE; CENTRE NAT RECH SCIENT; ECOLE DES PONTS PARIS TECH,MARTINEZ CRISTIAN; MARTINEAU CLAUDE; SCHOEN ANTOINE; KYRIACOPOULOU TITA,17305546 12.05.2017 EP,
WO2005050475,PCT/SG2004/000373,19.11.2004,WO/2005/050475,02.06.2005,WO,METHOD AND SYSTEM FOR VALIDATING THE CONTENT OF TECHNICAL DOCUMENTS,"An automatic document validation system that can be trained to extract domain-specific entities and their linguistically-associated physical, abstract or relational properties, as described within an electronic document. Training of the system can be achieved through the provision of a set of example documents representative of the domain and that have been manually tagged by a domain expert in such a way as to identify the various types of entities and their associated set of recordable properties. Together with a domain-specific vocabulary (e.g.. a dictionary), the trained system is then able to automatically process new documents belonging to the same domain and to test the extracted information on any number of content-conditional rules that have been specified by the domain expert as necessary to confirm the completeness and validity of the new documents.",G06F 17/27; G06F 17/28,"AGENCY FOR SCIENCE, TECHNOLOGY AND RESEARCH; LAI, Fon Lin; TAN, Ah Hwee","LAI, Fon Lin; TAN, Ah Hwee",200307192-5 21.11.2003 SG,GB-0611461; CN-200480040794.9; DE-null
WO2005098620,PCT/US2005/009999,25.03.2005,WO/2005/098620,20.10.2005,WO,METHOD OF AND APPARATUS FOR REALIZING SYNTHETIC KNOWLEDGE PROCESSES IN DEVICES FOR USEFUL APPLICATIONS,"Arbitrary knowledge and language is retained, manipulated, and transformed according to a universal grammar that defines the mind's innate action on language, or the ""deep"" structure and meaning of language, in analogue and digital devices and software according to operations and knowledge network structures, including programmable digital bytes configured into epistemic moments and parse trees made therefrom.",G06F 15/18; G06F 17/20; G06F 15/00; G06F 17/00; G06F 17/21; G06F 17/24,"DATIG, William, E.","DATIG, William, E.","10/811,507 26.03.2004 US",DE-null
WO2020083831,PCT/EP2019/078563,21.10.2019,WO/2020/083831,30.04.2020,WO,COMPUTER BASED OBJECT DETECTION WITHIN A VIDEO OR IMAGE,"Described herein are software and systems for analyzing videos and/or images. Software and systems described herein are configured in different embodiments to carry out different types of analyses. For example, in some embodiments, software and systems described herein are configured to locate an object of interest within a video and/or image.",G06K 9/00; G06K 9/46; G06K 9/62,FUTURE HEALTH WORKS LTD.,"PHAN, Quoc Huy; HARTE, Thomas","16/167,300 22.10.2018 US; 1817286.6 24.10.2018 GB",
WO2019226474,PCT/US2019/032796,17.05.2019,WO/2019/226474,28.11.2019,WO,IMPROVING ABSTRACTION OF TEXT SUMMARIZATON,"A system is disclosed for providing an abstractive summary of a source textual document. The system includes an encoder, a decoder, and a fusion layer. The encoder is capable of generating an encoding for the source textual document. The decoder is separated into a contextual model and a language model. The contextual model is capable of extracting words from the source textual document using the encoding. The language model is capable of generating vectors paraphrasing the source textual document based on pre-training with a training dataset. The fusion layer is capable of generating the abstractive summary of the source textual document from the extracted words and the generated vectors for paraphrasing. In some embodiments, the system utilizes a novelty metric to encourage the generation of novel phrases for inclusion in the abstractive summary.",G06F 17/27; G06N 3/04,"SALESFORCE.COM, INC.","PAULUS, Romain; KRYSCINSKI, Wojciech; XIONG, Caiming","62/675,147 22.05.2018 US; 16/051,188 31.07.2018 US",
WO2020017006,PCT/JP2018/027173,19.07.2018,WO/2020/017006,23.01.2020,WO,"LEARNING METHOD, TRANSLATION METHOD, LEARNING PROGRAM, TRANSLATION PROGRAM, AND INFORMATION PROCESSING DEVICE","An information processing device (100) analyzes first text information and second identification information, and for a word that is included in the first and second text information, acquires first word information and second word information for identifying a combination of a word and the meaning of the word. The information processing device (100) converts the first word information to a first meaning vector, and converts the second word information to a second meaning vector. The information processing device (100) uses the first meaning vector and the second meaning vector to learn a parameter of a learning model.",G06F 17/28,FUJITSU LIMITED; 富士通株式会社,"KATAOKA, Masahiro; 片岡　正弘; MATOBA, Yuki; 的場　友希; INOUE, Sakae; 井上　栄",,
WO2004053725,PCT/US2003/012514,23.04.2003,WO/2004/053725,24.06.2004,WO,MULTIMODAL SPEECH-TO-SPEECH LANGUAGE TRANSLATION AND DISPLAY,"A multimodal speech-to-speech language translation system and method for translating a natural language sentence of a source language into a symbolic representation and/or target language is provided. The system (100) includes an input device (102) for inputting a natural language sentence (402) of a source language into the system(100); a translator (104) for receiving the natural language sentence (402) in machine-readable form and translating the natural language sentence (402) into a symbolic representation (404) and/or a target language (406); and an image display (106) for displaying the symbolic representation (404) of the natural language sentence. Additionally, the image display (106) indicates a correlation (408) between text of the target language (406), the symbolic representation (404) and the text of the source language (402).",G06F 17/28,INTERNATIONAL BUSINESS MACHINES CORPORATION,"GAO, Yuqing; GU, Liang; LIU, Fu-Hua; SORENSEN, Jeffrey","10/315,732 10.12.2002 US",JP-2004559022; KR-1020057008295; EP-2003719900; CN-03825926.5
WO2001046838,PCT/US2000/034853,20.12.2000,WO/2001/046838,28.06.2001,WO,ANSWER RETRIEVAL TECHNIQUE,"An answer retrieval technique uses natural language processing and optimizable resources. The technique includes query entry (fig. 3, block 1), query filtering (fig.3, block 2), query enrichment (fig. 3, block 3), text entry and decomposition (fig. 3, block 4), text filtering (fig. 3, block 5), FUSS (fig. 3, block 6), linguistic wrappers (fig. 3, block 7).",G06F 17/30,"ANSWERCHASE, INC.; BERKAN, Riza, C.; VALENTI, Mark, E.","BERKAN, Riza, C.; VALENTI, Mark, E.","60/172,662 20.12.1999 US",
WO2019225154,PCT/JP2019/013792,28.03.2019,WO/2019/225154,28.11.2019,WO,CREATED TEXT EVALUATION DEVICE,"The present invention addresses the problem of evaluating a created text created in a predetermined language. A created text evaluation device 1 which uses a neural network unit 10 of an encoder/decoder model, in which an encoder unit 100 inputs a text in a first language, and a decoder unit 101 sequentially outputs word candidates of a text in a second language corresponding to the text in the first language and likelihoods of the word candidates is provided with: an encoder input unit 13 for sequentially inputting a created text created in the second language to the encoder unit 100 on a word basis; an evaluation unit 17 for evaluating the words of the created text on the basis of the word candidates in the second language output by the decoder unit 101 on the basis of the input by the encoder input unit 13 and the likelihoods of the word candidates; and an output unit 14 for performing an output based on a result of the evaluation by the evaluation unit 17.",G06F 17/28,"NTT DOCOMO, INC.; 株式会社ＮＴＴドコモ",MATSUOKA Hosei; 松岡　保静,2018-098812 23.05.2018 JP,
WO2019046463,PCT/US2018/048603,29.08.2018,WO/2019/046463,07.03.2019,WO,SYSTEM AND METHOD FOR DEFINING DIALOG INTENTS AND BUILDING ZERO-SHOT INTENT RECOGNITION MODELS,"A system and method of creating the natural language understanding component of a speech/text dialog system. The method involves a first step of defining user intent in the form of an intent flow graph. Next, (context, intent) pairs are created from each of the plurality of intent flow graphs and stored in a training database. A paraphrase task is then generated from each (context, intent) pair and also stored in the training database. A zero- shot intent recognition model is trained using the plurality of (context, intent) pairs in the training database to recognize user intents from the plurality of paraphrase tasks in the training database. Once trained, the zero-shot intent recognition model is applied to user queries to generate semantic outputs.",G06F 17/27; G06F 17/28,"ZHOA, Tiancheng","ZHOA, Tiancheng","62/551,324 29.08.2017 US",
EP14018772,03008805,23.04.2003,1361522,12.11.2003,EP,A system for automatically annotating training data for a natural language understanding system,"The present invention uses a natural language understanding system that is currently being trained to assist in annotating training data for training that natural language understanding system. Unannotated training data is provided to the system and the system proposes annotations to the training data. The user is offered an opportunity to confirm or correct the proposed annotations, and the system is trained with the corrected or verified annotations. <IMAGE>",G06F 3/16; G06F 17/24; G06F 17/27; G06F 17/28,MICROSOFT CORP,ACERO ALEJANDRO; WANG YE-YI; WONG LEON,14262302 10.05.2002 US,
WO2018152261,PCT/US2018/018257,14.02.2018,WO/2018/152261,23.08.2018,WO,SYSTEMS AND METHODS FOR USING MACHINE LEARNING AND RULES-BASED ALGORITHMS TO CREATE A PATENT SPECIFICATION BASED ON HUMAN-PROVIDED PATENT CLAIMS SUCH THAT THE PATENT SPECIFICATION IS CREATED WITHOUT HUMAN INTERVENTION,"Systems and methods for using machine learning and rules-based algorithms to create a patent specification based on human-provided patent claims such that the patent specification is created without human intervention are disclosed. Exemplary implementations may: obtain a claim set; obtain a first data structure representing the claim set; obtain a second data structure; obtain a third data structure; and determine one or more sections of the patent specification based on the first data structure, the second data structure, and the third data structure.",G06F 17/28; G06Q 10/10; G06Q 50/18,"SPECIFIO, INC.","SCHICK, Ian C.; KNIGHT, Kevin","62/459,199 15.02.2017 US; 62/459,208 15.02.2017 US; 62/459,235 15.02.2017 US; 62/459,246 15.02.2017 US; 62/459,357 15.02.2017 US; 15/892,679 09.02.2018 US",CA-3053483; EP-2018707830; AU-2018221586; JP-2019564389; KR-1020197026814
WO2018125299,PCT/US2017/049713,31.08.2017,WO/2018/125299,05.07.2018,WO,NATURAL LANGUAGE PROCESSING FOR SESSION ESTABLISHMENT WITH SERVICE PROVIDERS,"Routing packetized actions in a voice activated data packet based computer network environment is provided. A system can receive audio signals detected by a microphone of a device. The system can parse the audio signal to identify trigger keyword and request, and generate an action data structure. The system can transmit the action data structure to a third party provider device. The system can receive an indication from the third party provider device that a communication session was established with the device.",H04M 3/42; G10L 15/08; H04M 3/493; G06F 17/30; G06Q 30/02,GOOGLE LLC,"BHAYA, Gaurav; STETS, Robert","15/395,689 30.12.2016 US",KR-1020197024075; DE-212017000029; KR-1020177031189; DE-112017000122; EP-2017768558; GB-1802705.2; JP-2017556891
WO2020060311,PCT/KR2019/012272,20.09.2019,WO/2020/060311,26.03.2020,WO,ELECTRONIC DEVICE AND METHOD FOR PROVIDING OR OBTAINING DATA FOR TRAINING THEREOF,"Methods for providing and obtaining data for training and electronic devices thereof are provided. The method for providing data for training includes obtaining first voice data for a voice uttered by a user at a specific time through a microphone of the electronic device and transmitting the voice recognition result to a second electronic device which obtained second voice data for the voice uttered by the user at the specific time, for use as data for training a voice recognition model. In this case, the voice recognition model may be trained using the data for training and an artificial intelligence algorithm such as deep learning.",G10L 15/06; G10L 15/04; G06F 3/16; G10L 15/22,"SAMSUNG ELECTRONICS CO., LTD.","KIM, Sangha; KIM, Sungchan; LEE, Yongchan",10-2018-0113234 20.09.2018 KR; 10-2019-0013855 01.02.2019 KR,
EP231575465,18160825,08.03.2018,3385901,10.10.2018,EP,MACHINE LEARNING SPARSE COMPUTATION MECHANISM,"An apparatus to facilitate processing of a sparse matrix is disclosed. The apparatus includes a plurality of processing units each comprising one or more processing elements, including logic to read operands, a multiplication unit to multiply two or more operands and a scheduler to identify operands having a zero value and prevent scheduling of the operands having the zero value at the multiplication unit.",G06T 1/20,INTEL CORP,NURVITADHI ERIKO; VEMBU BALAJI; LIN TSUNG-HAN; SINHA KAMAL; BARIK RAJKISHORE; GALOPPO VON BORRIES NICOLAS C,201715482791 09.04.2017 US,
EP13477675,99914283,29.03.1999,1073970,07.02.2001,EP,METHOD AND APPARATUS FOR USING IDEAS AND CONCEPTS WITHIN COMPUTER PROGRAMS,"A method and apparatus that allows computer programs to define ideas and concepts symbolically is provided. The method and apparatus include a grammar that may be used to represent any concept. Sentences are parsed, using this grammar, into their component parts. As part of the parsing process, each word is compared to the contents of a dictionary database. The dictionary database and a set of tense-mood tables are used to identify individual words as concepts, entities, actions or qualifiers. The parsing process creates a data structure (200) for each sentence. The data structure organizes the sentence into its component parts, such as an ID field (202) and POC fields (204). The data structures for different sentences can be compared to determine matching or similarity. The data structures can also be processed to accomplish more advanced ends, such as reasoning systems or expert systems.",G06F 17/28; G06F 17/27; G06F 17/30; G06F 17/27; G06F 17/28,WORLDFREE NET INC,KIRCHMAN KEVIN A P,28199699 29.03.1999 US; 8003098 30.03.1998 US; 9906935 29.03.1999 US,
EP13741514,01129639,12.12.2001,1217535,26.06.2002,EP,Method and apparatus for generating normalized representations of strings,"A method generates normalized representations of strings, in particular sentences. The method, which can be used for translation, receives an input string. The input string is subjected to a first operation out of a plurality of operating functions for linguistically processing the input string to generate a first normalized representation of the input string that includes linguistic information. The first normalized representation is then subjected to a second operation for replacing linguistic information in the first normalized representation by abstract variables and to generate a second normalized representation. <IMAGE>",G06F 17/30; G06F 17/27; G06F 17/28,XEROX CORP,AIT-MOKHTAR SALAH; CHANOD JEAN-PIERRE; GAUSSIER ERIC,73831900 18.12.2000 US,
WO2018187167,PCT/US2018/025285,29.03.2018,WO/2018/187167,11.10.2018,WO,TRIGGERING ACTIONS BASED ON SHARED VIDEO FOOTAGE FROM AUDIO/VIDEO RECORDING AND COMMUNICATION DEVICES,"Systems and methods for communicating in a network using share signals in accordance with various embodiments of the present disclosure are provided. In one embodiment, a method for communicating in a network may include receiving, from a first client device, a share signal including first image data captured by a camera of a first audio/video (A/V) recording and communication device and a command to share the first image data with a network of users; processing the share signal by comparing the first image data to second image data captured by a camera of a second A/V recording and communication device; and generating and transmitting an alert to a second client device associated with the second A/V recording and communication device when comparison of the first image data with the second image data indicates a person of interest is depicted in both the first image data and the second image data.",H04N 7/18; H04N 5/91; G06K 9/00; G08B 13/196; G10L 25/57; G06F 17/28; H04N 5/77,RING INC.,"SIMINOFF, James; TROUGHTON, Mark; ZAVALA, Jeff","15/480,214 05.04.2017 US",
WO2006020992,PCT/US2005/029139,15.08.2005,WO/2006/020992,23.02.2006,WO,THE ONE-ROW KEYBOARD AND APPROXIMATE TYPING,"An apparatus is provided for character entry on an electronic device comprising a keyboard with one row of keys, and an electronic display device in communication with the keyboard, wherein one or more keys on the keyboard has a correspondence with a plurality of characters, and wherein the correspondence enables QWERTY-based typing In another aspect, an apparatus is provided for character entry on an electronic device comprising a keyboard with a plurality of keys, and an electronic display device in communication with the keyboard, wherein one or more keys on the keyboard has a correspondence with a plurality of characters, and wherein, for each of the one or more keys, the plurality of characters comprising a home row character associated with a particular finger when touch typing and a non-home row character associated with the particular finger when touch typing Also methods for disambiguating human input for text entry are provided.",G06F 15/02; B41J 5/10,"5 EXAMPLES, INC.; JAWERTH, Bjorn; MEHTA, Viraj","JAWERTH, Bjorn; MEHTA, Viraj","60/601,224 13.08.2004 US",EP-2005791130; CA-2577075
WO2007038292,PCT/US2006/037017,22.09.2006,WO/2007/038292,05.04.2007,WO,METHOD AND APPARATUS FOR AUTOMATIC ENTITY DISAMBIGUATION,"Entity disambiguation resolves which names, words, or phrases in text correspond to distinct persons, organizations, locations, or other entities in the context of an entire corpus. The invention is based largely on language- independent algorithms. Thus, it is applicable not only to unstructured text from arbitrary human languages, but also to semi-structured data, such as citation databases and the disambiguation of named entities mentioned in wire transfer transaction records for the purpose of detecting money-laundering activity. The system uses multiple types of context as evidence for determining whether two mentions correspond to the same entity and it automatically learns the weight of evidence of each context item via corpus statistics. The invention uses multiple search keys to efficiently find pairs of mentions that correspond to the same entity by performing within-document entity disambiguation (100) and cross-document entity disambiguation (110), while skipping billions of unnecessary comparisons, yielding a system with very high throughput that can be applied to truly massive data.",G06F 17/28; G06F 17/20; G06F 17/27,FAIR ISAAC CORPORATION,"BLUME, Matthias; CALMBACH, Richard; FREITAG, Dayne; ROHWER, Richard; ZOLDI, Scott","11/234,692 22.09.2005 US",EP-2006804047
WO1998057271,PCT/US1998/000729,14.01.1998,WO/1998/057271,17.12.1998,WO,AUTOMATIC TRANSLATION AND RETRANSLATION SYSTEM,"An automatic natural translation system for translating input text in a source natural language such as English, to output text in a target natural language, such as Japanese, as the input text is being generated, includes a translation activator that determines when a pause occurs in the creation of source language input text in a document or file, and effects, in response to the pause, a translation of the input text in a target language, up to that point that the pause was sensed. The translation system can further effect a translation as text is being generated, in response to sensing a certain text structure or in response to an input function. Each time an automatic translation is performed, the translation can begin at a starting point, such as the beginning of a word processing document into which the text was entered, the beginning of immediately received input text, or the beginning of a page or paragraph, thus allowing any changes in sentence structure or recent edits to the input text to be reflected in the output text translation.",G06F 17/28,"LOGOVISTA CORPORATION; PRINGLE, Lewis, G.","PRINGLE, Lewis, G.",PCT/US97/10005 09.06.1997 JP,US-09445715
WO2018125302,PCT/US2017/049758,31.08.2017,WO/2018/125302,05.07.2018,WO,MODULATION OF PACKETIZED AUDIO SIGNALS,"Modulating packetized audio signals in a voice activated data packet based computer network environment is provided. A system can receive audio signals detected by a microphone of a device. The system can parse the audio signal to identify trigger keyword and request, and generate a first action data structure. The system can identify a content item object based on the trigger keyword, and generate an output signal comprising a first portion corresponding to the first action data structure and a second portion corresponding to the content item object. The system can apply a modulation to the first or second portion of the output signal, and transmit the modulated output signal to the device.",G10L 13/027; G10L 15/22,GOOGLE LLC,"BHAYA, Gaurav; STETS, Robert","15/395,660 30.12.2016 US",EP-2017768898; JP-2017556901; KR-1020197037009; DE-212017000032; AU-2017386097; KR-1020177031462; DE-112017000139; GB-1803881.0
WO2017001940,PCT/IB2016/050524,02.02.2016,WO/2017/001940,05.01.2017,WO,METHOD AND SYSTEM FOR TRANSCRIPTION OF A LEXICAL UNIT FROM A FIRST ALPHABET INTO A SECOND ALPHABET,"A server and a method for transcription of a lexical unit from a first alphabet into a second alphabet, the method comprising: acquiring a pair of (i) the lexical unit written in the first alphabet, and (ii) the corresponding transcription of the lexical unit written in the second alphabet, both having been divided into respective segments, such that within the pair, every segment of the lexical unit has a corresponding segment in the transcription of the lexical unit, and such that each lexical unit comprises either a sequence of sequentially alternating consonant segments, or a single vowel segment, or a single consonant segment; defining, for each given segment of the lexical unit, its context; training the server to calculate a theoretical frequency of at least one second alphabet character representing transcription of a particular given segment based on the context of particular given segment of the lexical unit.",G06F 17/28,YANDEX EUROPE AG; YANDEX LLC; YANDEX INC.,"ZELENKOV, Yury Grigorievich",2015125963 30.06.2015 RU,US-15542255
WO2018206784,PCT/EP2018/062244,11.05.2018,WO/2018/206784,15.11.2018,WO,FAULT-TOLERANT INFORMATION EXTRACTION,"The invention provides a computer-implemented method for automatically analyzing a natural language input for information extraction, the method comprising (i) a step of receiving the natural language input, (ii) a step of providing a grammar model, the grammar model being represented as an augmented transition network with outputs and comprising: a local grammar model used for modelling the syntactic and semantic structure of at least the part of the natural language input; a set of external functions for information extraction, linked to the local grammar model, each external function being external in the sense that the function is loosely coupled and not part of the local grammar model; the external function being an operation over: at least the part of the natural language input, one or more states, at least one output of the grammar model, and/or other data; a finite set of read/write shared memory registers used by a parsing engine and the external functions, in which are stored the natural language input, the states, one or more stored outputs of the grammar model, and/or other data; (iii) a step of applying the grammar model to at least a part of the natural language input using the parsing engine, comprising a call of the one or more external functions by the parsing engine and evaluating the external functions on an virtual machine independent from the parsing engine;; (iv) a step of extracting information from the at least a part of the natural language input using at least one new output of the grammar model, the new output of the grammar model being built based: on at least one return value of the one or more external functions from evaluating the one or more external functions in step (iii), and one or more input labels and/or output labels.",G06F 17/27,UNIVERSITE PARIS EST MARNE LA VALLEE; ESIEE PARIS - CHAMBRE DE COMMERCE ET D'INDUSTRIE DE REGION PARIS ILE DE FRANCE; CENTRE NATIONAL DE LA RECHERCHE SCIENTIFIQUE; ECOLE DES PONTS PARIS TECH,"MARTINEZ, Cristian; MARTINEAU, Claude; SCHOEN, Antoine; KYRIACOPOULOU, Tita",17305546.8 12.05.2017 EP,
WO2010027561,PCT/US2009/050276,10.07.2009,WO/2010/027561,11.03.2010,WO,SYSTEM AND METHOD FOR GENERATING NATURAL LANGUAGE PHRASES FROM USER UTTERANCES IN DIALOG SYSTEMS,"Embodiments of a dialog system that employs a corpus-based appioach to generate responses based on a given number of semantic constraint-value pairs are described. The system makes full use of the data from the user input to produce dialog system responses in combination with a template generator The system primarily utilizes constraint values in order to realize efficiencies based on the more frequent tasks performed in real dialog systems although rhetorical or discourse aspects of the dialog could also be included in a similar way, that is, labeling the data with such information and performing a training process. The benefits of this system include higher quality user-aligned responses, broader coverage, faster response time, and shorter development cycles",G10L 15/22; G06F 17/27; G06F 17/28,"ROBERT BOSCH GMBH; WENG, Fuliang; STOIA, Laura; HU, Junling; FENG, Zhe; CAO, Junkuo","WENG, Fuliang; STOIA, Laura; HU, Junling; FENG, Zhe; CAO, Junkuo","12/199,520 27.08.2008 US",EP-2009790288; CN-200980137642.3
EP97588623,13192858,14.11.2013,2735974,28.05.2014,EP,System and method for suggesting domain names,"Systems and methods are provided for providing domain name suggestions based on user preferences and terms extracted from one or more information sources. Terms may be continuously extracted from information sources and used to generate domain name suggestions. Generated domain name suggestions may then be delivered to customers. The systems and methods may utilize customer preferences in providing the domain name suggestions, such as preferences as to information sources or topics of interest. The systems and methods may be self-learning, taking historical domain name registration information into account to improve the domain name suggestions.",G06F 17/27; G06F 17/28; H04L 29/12,VERISIGN INC,SMITH DAVID; SARAMBALE MILIND; BEN YACOUB SOUHEIL,201213683160 21.11.2012 US,
WO2019177816,PCT/US2019/020849,05.03.2019,WO/2019/177816,19.09.2019,WO,SEQUENCE TO SEQUENCE CONVERSATIONAL QUERY UNDERSTANDING,Systems and techniques for sequence to sequence conversational query understanding are described herein. A query may be received that includes multiple words. It may be identified that the query is to be reformulated based on an attention value for an attention word in the query. Relationships may be determined among words of the query and words in a previously submitted query and words in results from the previously submitted query. The query may be reformulated based on the relationships. The reformulated query may be employed to retrieve query results.,G06F 17/27; G06F 16/242; G06F 16/33,"MICROSOFT TECHNOLOGY LICENSING, LLC","NI, Xiaochuan; REN, Jiarui; MALIK, Manish; KE, Qifa","15/918,838 12.03.2018 US",
WO2014025911,PCT/US2013/053990,07.08.2013,WO/2014/025911,13.02.2014,WO,SENSOR INPUT RECORDING AND TRANSLATION INTO HUMAN LINGUISTIC FORM,"Systems, methods, and devices use a mobile devices sensor inputs to automatically draft natural language messages, such as text messages or email messages. In the various embodiments, sensor inputs may be obtained and analyzed to identify subject matter which a processor of the mobile device may reflect in words included in a communication generated for the user. In an embodiment, subject matter associated with a sensor data stream may be associated with a word, and the word may be used to assemble a natural language narrative communication for the user, such as a written message.",G06F 17/28; G06Q 10/10; H04M 1/725,QUALCOMM INCORPORATED,"KENAGY, Jason B.; HANNAN, John J.; KASKOUN, Kenneth","13/572,324 10.08.2012 US",
WO2019112326,PCT/KR2018/015355,06.12.2018,WO/2019/112326,13.06.2019,WO,SECURITY ENHANCEMENT METHOD AND ELECTRONIC DEVICE THEREFOR,"An electronic device and method that are robust against attacks on encryption-related vulnerabilities as detection of an encryption algorithm based on if artificial intelligence technology is enabled are provided. A security enhancement method includes a hooking loading of an executable code into a memory, inputting the executable code into an encryption code identification model that is based on an artificial neural network, determining, by the encryption code identification model, whether the loading of the executable code into the memory is allowed, and when the loading of the executable code is not allowed, blocking the loading of the executable code into the memory.",G06F 21/55; G06F 21/57; G06F 21/60; G06N 99/00,"SAMSUNG ELECTRONICS CO., LTD.","SEO, Jaewoo",10-2017-0167588 07.12.2017 KR,EP-2018886351
WO2001088747,PCT/US2001/015675,16.05.2001,WO/2001/088747,22.11.2001,WO,SYSTEM AND METHOD FOR MATCHING A TEXTUAL INPUT TO A LEXICAL KNOWLEDGE BASE AND FOR UTILIZING RESULTS OF THAT MATCH,"The present invention can be used in a natural language processing system (100) to determine a relationship (such as similarity in meaning) between two textual segments. The relationship can be identified or determined based on logical graphs (e.g. FIGS. 3B, 3C) generated from the textual segments. A relationship between first and second logical graphs (FIGS. 3B, 3C) is determined. This is accomplished regardless of whether there is an exact match between the first and second logical graphs (FIGS. 3B, 3C). In one embodiment, the first graph (FIG. 3B) represents an input textual discourse unit. The second graph (FIG. 3C), in one embodiment, represents information in a lexical knowledge base (LKB) (106). The input graph can be matched against the second graph, if they have similar meaning, even if the two differ lexically or structurally.",G06F 17/30,MICROSOFT CORPORATION,"DOLAN, William, B.; BARNETT, Michael; RICHARDSON, Stephen, D.; MENEZES, Arul, A.; VANDERWENDE, Lucretia, H.","09/572,765 17.05.2000 US",EP-2001939049; CN-01809516.X
WO2019113302,PCT/US2018/064230,06.12.2018,WO/2019/113302,13.06.2019,WO,FACIAL ANIMATION FOR SOCIAL VIRTUAL REALITY (VR),An avatar's lips (306) are animated using visemes (308) derived from a response (406) to a digital assistant (40) query in synchronization with playing the response.,G10L 21/06; G10L 21/10; G06F 17/28,"SONY INTERACTIVE ENTERTAINMENT INC.; KITAJIMA, Marie; OMOTE, Masanori","KITAJIMA, Marie; OMOTE, Masanori","15/833,680 06.12.2017 US",
WO2019000170,PCT/CN2017/090010,26.06.2017,WO/2019/000170,03.01.2019,WO,GENERATING RESPONSES IN AUTOMATED CHATTING,"The present disclosure provides method and apparatus for generating responses in automated chatting. A message may be received in a session. An intention vector may be determined based at least on the message and the session through dynamic memory network (DMN), the intention vector indicating an attention point and an intention. A response may be generated based at least on the intention vector.",G06F 17/28,"MICROSOFT TECHNOLOGY LICENSING, LLC; WU, Xianchao; CHEN, Zhan","WU, Xianchao; CHEN, Zhan",,CN-201780064420.8; EP-2017915810
WO2018184062,PCT/AU2018/050304,03.04.2018,WO/2018/184062,11.10.2018,WO,A LANGUAGE TRANSLATION AID,"The present invention relates to an electronic language translation aid. The aid includes a receiver for receiving a language sentence in a first language. A translator translates the language sentence into both a literal translation and a correct translation in a second language. A display displays the literal translation and the correct translation. Preferably, the display is configured to display both translations concurrently so that an early language learner can obtain an immediate comprehension of individual word meaning through literal translation, and overall contextual meaning through the correct translation.",G06F 17/28,TSTREET PTY LTD,"ALMOND, Benjamin Price",2017901233 05.04.2017 AU,JP-2019555119; AU-2018247564; KR-1020197032617; CN-201880023102.1; EP-2018781857
WO2015133238,PCT/JP2015/053825,12.02.2015,WO/2015/133238,11.09.2015,WO,"WORD ALIGNMENT SCORE COMPUTATION DEVICE, WORD ALIGNMENT DEVICE, AND COMPUTER PROGRAM","[Problem] To provide a device for performing word alignment with high precision. [Solution] This device comprises: a selection means for receiving a bilingual sentence pair and word alignments for the bilingual sentence pair, and selecting, in a prescribed order, the words (fj) of a first language in sequence; and a recurrent neural network (RNN) (100) for computing for each word in the sentence in the first language a score (102) that indicates the likelihood of the correctness of a word pair consisting of the respective word (fj) and a word (ea_{j}) that is in the second language of the bilingual sentence pair and is aligned with the word (fj) by a word alignment (aj), and computing the score of the word alignment (aj) on the basis of that score. When computing the score of a word pair (fj, ea_{j}), the RNN (100) computes the score (102) of the word pair (fj, ea_{j}) by means of a cyclic connection (118), on the basis of all (a1j-1) of the word alignments (aj) for words that had been selected by the selection means prior to word (fj) of the word pair (fj, ea_{j}).",G06F 17/28,NATIONAL INSTITUTE OF INFORMATION AND COMMUNICATIONS TECHNOLOGY; 国立研究開発法人情報通信研究機構,"TAMURA, Akihiro; 田村　晃裕; WATANABE, Taro; 渡辺　太郎; SUMITA, Eiichiro; 隅田　英一郎",2014-045012 07.03.2014 JP,US-15118703; CN-201580012326.9
WO2018097022,PCT/JP2017/041249,16.11.2017,WO/2018/097022,31.05.2018,WO,"AUTOMATIC TRANSLATION PATTERN LEARNING DEVICE, AUTOMATIC TRANSLATION PREPROCESSING DEVICE, AND COMPUTER PROGRAM","[Problem] Provided is an automatic translation pattern learning device for learning patterns for, prior to automatic translation, transposing constituent component strings of an original text into an order suitable for automatic translation. [Solution] A learning processing unit 164 includes: a dividing point detection unit 190 for detecting in a parallel translation, as the division position of two sentences, the position at which the corresponding relationship between the order of occurrence of constituent components of a sentence in the original language and the order of occurrence of constituent components of the corresponding translated sentence changes; a learning data generation unit 192 for generating, as learning data for mechanical learning, data comprising a constituent component string of a continuous prescribed number of items within the sentence in the original language, and correct answer information indicating whether the division position is within the constituent component string; and a model learning unit 196 for, when an input constituent component string of a prescribed number of units in a sentence in the original language is provided by machine learning, learning a division model 166 for determining whether the division position is at the prescribed position in the constituent component string, using the generated learning data.",G06F 17/28,NATIONAL INSTITUTE OF INFORMATION AND COMMUNICATIONS TECHNOLOGY; 国立研究開発法人情報通信研究機構,"FUJI, Masaru; 富士　秀; UCHIYAMA, Masao; 内山　将夫",2016-227583 24.11.2016 JP,
WO2003037231,PCT/US2002/031269,01.10.2002,WO/2003/037231,08.05.2003,WO,CLOSED LOOP BRAIN MACHINE INTERFACE,"A closed loop brain-machine interface (100) is disclosed. The closed loop brain-machine interface translates one or more neural signals into a movement, or a series of movements, performed by a machine (40, 45). The closed loop brain-machine also provides sensory feedback to the subject. Methods of employing the closed loop brain-machine interface are also disclosed. .",A61F 2/70; G06F 3/00; G06F 17/00,"DUKE UNIVERSITY; NICOLELIS, Miguel, A.L.; CHAPIN, John, K.; WESSBERG, Johan","NICOLELIS, Miguel, A.L.; CHAPIN, John, K.; WESSBERG, Johan","10/012,012 29.10.2001 US",EP-2002782089; CA-2463873; AU-2002348482; EP-2012156889; JP-null
EP11414757,83301921,06.04.1983,0091317,12.10.1983,EP,SYNTAX ANALYZING METHOD AND APPARATUS,,G06F 17/27,TOKYO SHIBAURA DENKI KABUSHIKI KAISHA,"AMANO, SHIN-YA; HIRAKAWA, HIDEKI",5792082 07.04.1982 JP,
EP241458588,18197984,01.10.2018,3474157,24.04.2019,EP,METHOD OF UPDATING SENTENCE GENERATION MODEL AND SENTENCE GENERATING APPARATUS,The application comprises a processor implemented method of updating sentence generation model and sentence generating apparatus and includes: generating a target sentence corresponding to a source sentence using a first decoding model; calculating reward information associated with the target sentence using a second decoding model configured to generate a sentence in a word order different from a word order of the sentence generated by the first decoding model; and generating an updated sentence generation model by resetting a weight of respective nodes in the first decoding model based on the calculated reward information.,G06F 17/28,SAMSUNG ELECTRONICS CO LTD,LEE HOSHIK; NA HWIDONG,20170133971 16.10.2017 KR,
EP12080920,90103323,21.02.1990,0394633,31.10.1990,EP,METHOD FOR LANGUAGE-INDEPENDENT TEXT TOKENIZATION USING A CHARACTER CATEGORIZATION,"A computer method is disclosed to isolate linguistically salient strings (""words"") from a natural language text stream. The process is applicable to a variety of computer hardware, to any character encoding scheme, and to the idiosyncrasies of most natural languages.",G06F 17/27; G06F 17/28,INTERNATIONAL BUSINESS MACHINES CORPORATION,"FAGAN, JOEL LA VERNE; GUNTHER, MICHAEL DANIEL; OVER, PAUL DOUGLAS; PASSON, GREG; TSAO, CHIEN CHUN; ZAMORA, ANTONIO",34434189 26.04.1989 US,
WO2009070619,PCT/US2008/084755,25.11.2008,WO/2009/070619,04.06.2009,WO,"MODULAR SYSTEM AND METHOD FOR MANAGING CHINESE, JAPANESE, AND KOREAN LINGUISTIC DATA IN ELECTRONIC FORM","Embodiments can include means for categorizing lexical data, means for accurately describing the structure hierarchical data, means for accommodating lexicons having disparate data structures, means for pooling data from separate lexicons into aggregate lists, means for gathering data from participating users, and specified interfaces for handwriting recognition, optical character recognition, and text-to-speech and speech-to-text conversion. Embodiments can provide significant enhancements in data description, data connectivity and access, data presentation, data enhancement, and input functionality. The input means may be coupled with an electronic implementation of the character lookup invention by the same inventor to facilitate the lookup of individual characters. An exemplary embodiment can comprise a linguistic services center that interfaces with various natural language processing modules such that users of one module can take advantage of the wealth of linguistic information provided in the system. The resulting system may greatly minimize the frustration and inconvenience users typically experience when using Japanese, Chinese, or Korean in electronic contexts. A revenue sharing and data security system is disclosed for encouraging competitors to make their data available to the system in a way that lexical data providers, the OS provider, the LSC provider, and the user may all mutually benefit.",G06F 17/28; G06F 17/22; G06F 17/30,"CHILD, Warren Daniel","CHILD, Warren Daniel","60/990,123 26.11.2007 US; 60/990,166 26.11.2007 US; 60/991,010 29.11.2007 US",CN-200880125477.5; US-12744801; JP-2010535118
WO2019216969,PCT/US2019/017806,13.02.2019,WO/2019/216969,14.11.2019,WO,SYNCHRONIZING ACCESS CONTROLS BETWEEN COMPUTING DEVICES,Synchronization of access controls between computing devices is provided. The system receives a request from a first device. The system performs a session handover to a second device responsive to determining an incompatibility. The system modifies a parameter in an access control database. The system receives a request from a third device. The system provides the digital component to the third device.,G06F 21/62; G10L 15/00; G06F 17/27; H04L 29/06; G06F 16/242; H04L 29/08,GOOGLE LLC,"PARIKH, Stavan; LU, Wei; JAIN, Tarun; GUPTA, Anshul; SRIVASTAVA, Srishti","62/668,218 07.05.2018 US",CN-201980002194.X; EP-2019710514
WO2019108622,PCT/US2018/062804,28.11.2018,WO/2019/108622,06.06.2019,WO,SYSTEMS AND METHODS FOR ARTIFICIAL MODEL BUILDING TECHNIQUES,"Embodiments disclosed describe a security awareness system may adaptively learn the best design of a simulated phishing campaign to get a user to perform the requested actions, such as clicking a hyperlink or opening a file. In some implementations, the system may adapt an ongoing campaign based on user's responses to messages in the campaign, along with the system's learned awareness. The learning process implemented by the security awareness system can be trained by observing the behavior of other users in the same company, other users in the same industry, other users that share similar attributes, all other users of the system, or users that have user attributes that match criteria set by the system, or that match attributes of a subset of other users in the system.",H04L 29/06; G06F 21/55; G06F 21/57; G06N 3/08,"KNOWBE4, INC.","SITES, Eric","15/829,719 01.12.2017 US",
WO2016200471,PCT/US2016/025408,31.03.2016,WO/2016/200471,15.12.2016,WO,NATURAL LANGUAGE EVENT DETECTION,"Systems and processes for detecting an event within natural language are provided. In one example of a process, unstructured natural language information may be received from at least one user. The presence of event information in the unstructured natural language information may be determined. In accordance with a determination that event information is present within the unstructured natural language information, a pseudo-event entry associated with that event information may be generated.",G06F 17/21; G06F 17/28; G06Q 10/10; H04L 12/58,APPLE INC.,"CARLHIAN, Alexandre; GROSS, Daniel, C.; DENIAU, Thomas; BORIOS, Guillaume; MARTEL, Mathieu, Jean; REKIN, Sabrine; AGARWAL, Sachin; BELLEGARDA, Jerome, R.; SIAHAAN, Linden, B.; MOORE, Jennifer; MOHA, Alexandre; ARRAS, Hafid, J.","62/172,176 07.06.2015 US; 14/846,629 04.09.2015 US",
EP232545707,18163807,23.03.2018,3396546,31.10.2018,EP,COMPUTE OPTIMIZATION MECHANISM FOR DEEP NEURAL NETWORKS,"An apparatus to facilitate compute optimization is disclosed. The apparatus includes a plurality of processing units each comprising a plurality of execution units (EUs), wherein the plurality of EUs comprise a first EU type and a second EU type",G06F 9/50; G06F 8/41; G06T 1/20,INTEL CORP,SURTI PRASOONKUMAR; SRINIVASA NARAYAN; CHEN FENG; RAY JOYDEEP; ASHBAUGH BEN J; GALOPPO VON BORRIES NICOLAS C; NURVITADHI ERIKO; VEMBU BALAJI; LIN TSUNG-HAN; SINHA KAMAL; BARIK RAJKISHORE; BAGHSORKHI SARA S; GOTTSCHLICH JUSTIN E; KOKER ALTUG; SATISH NADATHUR RAJAGOPALAN; AKHBARI FARSHAD; KIM DUKHWAN; FU WENYIN; SCHLUESSLER TRAVIS T; MASTRONARDE JOSH B; HURD LINDA L; FEIT JOHN H; BOLES JEFFREY S; LAKE ADAM T; VAIDYANATHAN KARTHIK; BURKE DEVAN; MAIYURAN SUBRAMANIAM; APPU ABHISHEK R; MASTRONARDE JOSH B,201715494886 24.04.2017 US,
WO2014145884,PCT/US2014/030728,17.03.2014,WO/2014/145884,18.09.2014,WO,SYNTACTIC TAGGING IN A DOMAIN-SPECIFIC CONTEXT,"This application relates generally to defining a domain-specific syntax characterizing a functional information system and performing operations on data entities represented by the domain-specific syntax, including defining a domain-specific syntax, receiving and storing a domain-specific data entity, assigning a syntactic tag to the domain-specific data entity, and electronically storing the tag assigned to the data entity in the electronic data store so that the tag is logically linked to the stored data entity.",G06F 17/00; G06F 17/28; G06F 17/30,"LOCUS ANALYTICS, LLC","RIGGS, Rory","61/801,959 15.03.2013 US; 61/802,245 15.03.2013 US; 14/216,390 17.03.2014 US",EP-2014765266; CA-2924083
WO2006036128,PCT/SG2005/000321,28.09.2005,WO/2006/036128,06.04.2006,WO,SYSTEM FOR SEMANTICALLY DISAMBIGUATING TEXT INFORMATION,"Disclosed is a semantic user interface system that allows text information to be tagged with machine-readable IDs that are associated with concepts for conveying information without any ambiguity or without being hampered by the limitations of human languages. Typically, a plurality of vocabularies are stored across a network, and each vocabulary includes a plurality of machine-readable IDs each corresponding to a concept and at least one keyword corresponding to each machine-readable ID. An input interface accepts text information, selects those machine-readable IDs whose keywords match up with the text information, and returns a list of candidates each corresponding to one of the selected machine-readable IDs and including a corresponding description. The machine-readable IDs can carry information in the form of concepts without any ambiguity as opposed to text information. This system can be applied to web and database searches, publishing messages to selected subscribers, interfacing of applications software, machine translations and so forth.",G06F 17/27,"SARKAR PTE LTD; SARKAR, Devajyoti","SARKAR, Devajyoti","10/954,964 29.09.2004 US",
WO2012151479,PCT/US2012/036500,04.05.2012,WO/2012/151479,08.11.2012,WO,CROSS-LANGUAGE COMMUNICATION BETWEEN PROXIMATE MOBILE DEVICES,"A system facilitates cross-language communication among users of respective wireless communication devices. Two or more mutually-agreeing users establish and participate in a cross- language communication session, without revealing private information, such as their telephone numbers. Once the session has been established, each user enters text into her wireless communication device, and a translated version of the entered text is displayed on a screen of the other user's wireless communication device. The text may be entered, such as by typing on a keyboard on the wireless communication device or by speaking inputs into a microphone and automatically recognizing the speech. Optionally, the translated text may be spoken by a speech synthesizer. No permanent information about the participants need be stored in the respective wireless communication devices, so once the communication session ends, no further communication between or among the participants is possible, without establishing another session, thereby preserving each user's privacy.",G06F 17/28,"ORTSBO, INC.; ZIVKOVIC, Aleksandar","ZIVKOVIC, Aleksandar","61/482,958 05.05.2011 US",CA-2835110; AU-2012250625; EP-2012780055; JP-2014509472
EP14391508,05101567,01.03.2005,1571565,07.09.2005,EP,Method and system for ranking words and concepts in a text using graph-based ranking,"The present invention is a method and system for identifying words, text fragments, or concepts of interest in a corpus of text. A graph is built which covers the corpus of text. The graph includes nodes and links, where nodes represent a word or a concept and links between the nodes represent directed relation names. A score is then computed for each node in the graph. Scores can also be computed for larger sub-graph portions of the graph (such as tuples). The scores are used to identify desired sub-graph portions of the graph, those sub-graph portions being referred to as graph fragments.",G06F 17/21; G06F 17/30; G06F 7/00; G06F 40/00; G06K 9/34,MICROSOFT CORP,MENEZES ARUL A; VANDERWENDE LUCRETIA H; BANKO MICHELE L,54977504 02.03.2004 US; 82564204 15.04.2004 US,
EP231575450,18159487,01.03.2018,3385887,10.10.2018,EP,SUB-GRAPH IN FREQUENCY DOMAIN AND DYNAMIC SELECTION OF CONVOLUTION IMPLEMENTATION ON A GPU,"In an example, an apparatus comprises a plurality of execution units; and logic, at least partially including hardware logic, to determine a sub-graph of a network that can be executed in a frequency domain and apply computations in the sub-graph in the frequency domain. Other embodiments are also disclosed and claimed.",G06N 3/04; G06N 3/063,INTEL CORP,SAREL UZI; COHEN EHUD; SCHWARTZ TOMER; ARMON AMITAI; SHADMIY YAHAV; BEN-ARI LTAMAR; BLEIWEISS AMIT; FAIVISHEVSKY LEV; BAR-ON TOMER; FAIS YANIV; SUBAG JACOB; BEHAR MICHAEL; JACOB GUY; LEIBOVICH GAL; DREYFUSS JEREMIE,201715482724 08.04.2017 US,
WO2014210334,PCT/US2014/044376,26.06.2014,WO/2014/210334,31.12.2014,WO,MACHINE LEARNING ENCHANCED BY HUMAN MEASUREMENTS,"In various embodiments, training objects are classified by human annotators, psychometric data characterizing the annotation of the training objects is acquired, a human-weighted loss function based at least in part on the classification data and the psychometric data is computationally derived, and one or more features of a query object are computationally classified based at least in part on the human- weighted loss function.",G06F 19/24,PRESIDENT AND FELLOWS OF HARVARD COLLEGE,"COX, David; SCHEIRER, Walter; ANTHONY, Samuel; NAKAYAMA, Ken","61/840,871 28.06.2013 US",US-14900397
EP279633405,18206520,15.11.2018,3582114,18.12.2019,EP,"METHOD OF TRAINING A DESCRIPTIVE TEXT GENERATING MODEL, AND METHOD AND APPARATUS FOR GENERATING DESCRIPTIVE TEXT",,G06F 16/34; G06F 17/28,BEIJING BAIDU NETCOM SCI & TEC,HUANG JIZHOU; SUN YAMING; ZHANG WEI; WANG HAIFENG,201810622437 15.06.2018 CN,
WO2009006911,PCT/EG2007/000022,12.07.2007,WO/2009/006911,15.01.2009,WO,SYSTEM AND METHOD FOR LARGE-SCALE ARABIC LEXICAL SEMANTIC ANALYSIS,"System and method for extracting word senses sequences (01 ) corresponding to sequences of input Arabic words (11 ). These senses belong to a global compact basis set of predefined semantic fields. The system can also produce the semantic relations (02) between the words of two input Arabic sequences of words (11, 12). It relies on a lexical semantic relational database that relates the lexical Arabic compounds to semantic fields both in the forward and backward directions. To achieve high coverage of the highly derivative and inflective Arabic language, this database is not a vocabulary but a morpheme based one. Semantic fields are associated with lexical compounds with the aid of a large-scale morphological analyzer. Semantic relations between words are determined by first reducing the words to lexical compounds, mapping lexical compounds to semantic fields, and relating the latter to each other. This approach reduces complexity considerably.",G06F 17/30; G06F 17/27,"THE ENGINEERING COMPANY FOR THE DEVELOPMENT OF COMPUTER SYSTEMS. (RDI); RASHWAN, Mohsen Abdel-Razik Ali; AHMED, Mohamed Attia Mohamed El-Araby","RASHWAN, Mohsen Abdel-Razik Ali; AHMED, Mohamed Attia Mohamed El-Araby",,
WO2019217101,PCT/US2019/029519,27.04.2019,WO/2019/217101,14.11.2019,WO,MULTI-MODAL SPEECH ATTRIBUTION AMONG N SPEAKERS,"A computerized conference assistant includes a camera and a microphone. A face location machine of the computerized conference assistant finds a physical location of a human, based on a position of a candidate face in digital video captured by the camera. A beamforming machine of the computerized conference assistant outputs a beamformed signal isolating sounds originating from the physical location of the human. A diarization machine of the computerized conference assistant attributes information encoded in the beamformed signal to the human.",G10L 21/0272; G10L 21/0216; G10L 21/02; G10L 17/00,"MICROSOFT TECHNOLOGY LICENSING, LLC","ZHANG, Shixiong; WU, Lingfeng; KRUPKA, Eyal; XIAO, Xiong; GONG, Yifan","62/667,564 06.05.2018 US; 62/667,562 06.05.2018 US; 16/019,318 26.06.2018 US",
WO2020060814,PCT/US2019/050549,11.09.2019,WO/2020/060814,26.03.2020,WO,ANOMALOUS DEVICE DETECTION FROM COMMUNICATION DATA,"Systems and methods for implementing heterogeneous feature integration for device behavior analysis (HFIDBA) are provided. The method includes representing (620) each of multiple devices as a sequence of vectors for communications and as a separate vector for a device profile. The method also includes extracting (630) static features, temporal features, and deep embedded features from the sequence of vectors to represent behavior of each device. The method further includes determining (650), by a processor device, a status of a device based on vector representations of each of the multiple devices.",H04L 29/06; G06F 21/55; G06N 3/08,"NEC LABORATORIES AMERICA, INC.","CHEN, Haifeng; ZONG, Bo; CHENG, Wei; TANG, LuAn; NI, Jingchao","62/732,633 18.09.2018 US; 16/562,755 06.09.2019 US",
WO2018179355,PCT/JP2017/013635,31.03.2017,WO/2018/179355,04.10.2018,WO,"INFORMATION PROCESSING SYSTEM, INFORMATION PROCESSING DEVICE, INFORMATION PROCESSING METHOD, AND INFORMATION PROCESSING PROGRAM","The present invention is an information processing device for learning parameters for a converter that converts queries in a natural language to query expressions in a formal language, the information processing device comprising: an input receiving unit that receives an input of a pair consisting of a query in a natural language and a correct reply which is an appropriate output for the query; a positive example condition generating unit that generates, on the basis of formal language-related data stored in a search database, at least one or more conditions to be satisfied by a formal language which is inputted when the search database is searched for the correct reply; a query expression generating unit that generates a query expression in the formal language corresponding to the query by using the parameters for the converter such that any of the conditions is satisfied; a reply acquiring unit that acquires a reply to the query on the basis of searching of the search database performed with use of the generated query expression; and a parameter updating unit that updates the parameters for the converter such that, when the reply matches the correct reply, the query is preferentially converted to the query expression generated from the query. The information processing device efficiently performs machine learning of the converter even when the number of expressions in a formal language is large.",G06F 17/30; G06F 17/28,NEC CORPORATION; 日本電気株式会社,OKAJIMA Yuzuru; 岡嶋　穣; SADAMASA Kunihiko; 定政　邦彦,,JP-2019508124
WO1998009228,PCT/US1997/015388,28.08.1997,WO/1998/009228,05.03.1998,WO,NATURAL-LANGUAGE SPEECH CONTROL,A natural-language speech control method (20) produces a command (34) for controlling the operation of a digital computer (36) from words spoken in a natural-language. An audio signal that represents the spoken words is processed to generate textual digital-computer-data (24). The textual digital-computer-data (24) is then processed by a natural-language-syntactic-parser (26) to produce a parsed sentence in a logical form of the command (28). The parsed sentence is then processed by a semantic compiler (32) to generate the command (34) that controls the operation of the digital computer (36). The command (34) is expressed in a natural-language sentence that has an implied second person singular pronoun subject and the verb is active voice present tense. The preferred method uses a principles-and-parameters (P-and-P) Government-and-Binding-based (GB-based) natural-language-syntactic-parser (26) for resolving ambiguous syntactic structures.,G06F 17/27; G10L 15/18,"BCL COMPUTERS, INC.","ALAM, Hassan","60/025,145 29.08.1996 US; 08/919,138 27.08.1997 US",EP-1997940741; NZ-333716; CA-2263743; JP-1998512005
WO2018104834,PCT/IB2017/057578,01.12.2017,WO/2018/104834,14.06.2018,WO,"REAL-TIME, EPHEMERAL, SINGLE MODE, GROUP & AUTO TAKING VISUAL MEDIA, STORIES, AUTO STATUS, FOLLOWING FEED TYPES, MASS ACTIONS, SUGGESTED ACTIVITIES, AR MEDIA & PLATFORM","Various embodiments of a system, methods, platform, database, search engine & device enabling user to auto open or unlocks user device, auto open camera display screen, auto capture photo or auto start recording of video, auto open media viewer when user wants to view, apply ephemeral or non-ephemeral and real-time content access rules and settings for one or more destinations and/or sources, enables user to search, match, save, bookmark, subscribe and view one or more object criteria specific contents, user related visual media captured by other users related privacy settings, supplied object models specific advertisements in visual media feeds, enables sender of media to access media shared by sender at recipient device, enables various embodiments relates to the display of ephemeral messages and real-time ephemeral messages, enables multi-tasking intelligent visual media capture controller so user can easily take front or back photo or video or live stream and view received media items and/or access one or more pre-set interfaces or applications, enables auto generating of user's current status, user's current activities and auto generate emoticons, emoji, cartoon based on front and/or back camera photo(s) and/or video(s) and user data, auto open or unlock camera device and auto start recording of parent video and during recording of said parent video enabling to store trimmed video(s) and/or back camera & front camera video(s) and/or capture photo(s) and/or share with contact(s) and/or group(s) and/or destination(s), enable to create events so invited or targeted criteria specific participants including based on profile data, supplied object, voice, location or place, status or presented members at particular place or location can capture, share & view one or more types of media, enable augmented reality platform, enabling new type of media including augmented reality photo or video which user can share with others, enabling automated recording and providing of viewing user's reactions, enabling requirement specification specific responses and real-time communications for better matchmaking, quality, services & saving money, enabling user to user providing and consuming visual media taking service(s), enabling periocular session start and end date & time specific presentation of one or more types of contents for enabling one or more types of mass user actions (view, buy, participate, react etc.), enabling user's availability specific presentation of suggested activities, enabling user's multi types feeds following, enabling to identify user related keywords, and enables natural talking like communication application.",G06K 9/00; G06F 3/01; G06T 7/00; G06T 7/73,"RATHOD, Yogesh Chunilal","RATHOD, Yogesh Chunilal",PCT/IB2016/057398 07.12.2016 IB; PCT/IB2017/050468 29.01.2017 IB,
WO2020005616,PCT/US2019/037562,18.06.2019,WO/2020/005616,02.01.2020,WO,GENERATION OF SLIDE FOR PRESENTATION,"In embodiments of the present disclosure, there is provided a method of generating a slide for presentation. Upon a target passage for presentation is obtained, a plurality of sentences are generated based on the target passage, and a label associated with each sentence and an icon corresponding to each label are determined. Then, the sentences, labels and icons are displayed in association in a user interface of an application for presentation. According to embodiments of the present disclosure, the illustrated slides can be automatically generated for a passage to be presented, which can improve efficiency of slide making and improve user experience for slide presentation.",G06F 17/24; G06F 17/27; G06F 17/21; G06F 16/34,"MICROSOFT TECHNOLOGY LICENSING, LLC","CUI, Lei; HUANG, Shaohan; ZHANG, Xingxing; WEI, Furu; ZHOU, Ming",201810664753.0 25.06.2018 CN,
WO2018136870,PCT/US2018/014680,22.01.2018,WO/2018/136870,26.07.2018,WO,WORD VECTOR PROCESSING METHOD AND APPARATUS,"Embodiments of the present application disclose a word vector processing method and apparatus. The method includes: performing word segmentation on a corpus to obtain words; determining n-gram strokes corresponding to the words, the n-gram stroke representing n successive strokes of a corresponding word; establishing and initializing word vectors of the words and stroke vectors of the n-gram strokes corresponding to the words; and training the word vectors and the stroke vectors according to the corpus obtained after the word segmentation, the word vectors, and the stroke vectors. With the embodiments of the present application, features of a word can be shown more precisely by using n-gram strokes corresponding to the word, thus enhancing accuracy of word vectors of Chinese words and achieving a desirable practical effect.",G06F 17/28; G06F 17/27,ALIBABA GROUP HOLDING LIMITED,"CAO, Shaosheng; LI, Xiaolong","15/874,725 18.01.2018 US; 201710045459.7 22.01.2017 CN",SG-11201906524T; KR-1020197021351; EP-2018702885; JP-2019539241; PH-12019501675
EP13552391,99945272,31.08.1999,1112541,04.07.2001,EP,DOCUMENT SEMANTIC ANALYSIS/SELECTION WITH KNOWLEDGE CREATIVITY CAPABILITY,"A computer based software system and method for semantically processing a user entered natural language request to identify (16) and store (18) linguistic subject-action-object (SAO) structures, using such structures as key words/phrases (24) to search (30) local and Web-based databases for downloading (12) candidate natural language documents, semantically processing candidate document texts into candidate document SAO structures, and selecting and storing only relevant documents whose SAO structures include a match with a stored request SAO structure. Further features include analyzing relationships among relevant document SAO structures and creating new SAO structures (20) based on such relationships that may yield new knowledge concepts and ideas for display to the user and generating and displaying natural language summaries (22, 26) based on the relevant document SAO structures.",G06F 17/21; G06F 17/28; G06F 17/27; G06F 17/30; G06F 17/28; G06F 17/30,INV MACHINE CORP,TSOURIKOV VALERY M; BATCHILO LEONID S; SOVPEL IGOR V,32180499 27.05.1999 US; 9919699 31.08.1999 US; 9964198 09.09.1998 US,
EP191879093,16180842,22.07.2016,3125235,01.02.2017,EP,LEARNING TEMPLATES GENERATED FROM DIALOG TRANSCRIPTS,"Agent utterances are generated for implementing dialog acts recommended by a dialog manager of a call center. To this end, a set of word lattices, each represented as a weighted finite state automaton (WFSA), is constructed from training dialogs between call center agents and second parties (e.g. customers). The word lattices are assigned conditional probabilities over dialog act type. For each dialog act received from the dialog manager, the word lattices are ranked by the conditional probabilities for the dialog act type. At least one word lattice is chosen from the ranking, and is instantiated to generate a recommended agent utterance for implementing the recommended dialog act. The word lattices may be constructed by clustering agent utterances of training dialogs using context features from preceding second party utterances and grammatical dependency link features between words within agent utterances. Path variations of the word lattices may define slots or paraphrases.",G10L 15/18; G06F 17/27; G06F 17/28; G06F 17/30; G10L 15/22; H04M 3/42; H04M 3/51,XEROX CORP,VENKATAPATHY SRIRAM; MIRKIN SHACHAR; DYMETMAN MARC,201514810817 28.07.2015 US,
WO2018018626,PCT/CN2016/092403,29.07.2016,WO/2018/018626,01.02.2018,WO,CONVERSATION ORIENTED MACHINE-USER INTERACTION,"In implementations of the subject matter described herein, a new approach for presenting a response to a message in a conversation is proposed. Generally speaking, in response to receiving a message in a conversation, the received message will be matched with one or more documents on the sentence basis. That is, the received message is compared with the sentences from a document(s), rather than predefined query-response pairs. In this way, a whole sentence may be selected from the document as a candidate response. Then the suitability of this sentence with respect to the ongoing conversation will be determined, and the response will be generated and rendered in an adaptive way based on the suitability. As a result, the user experiences may be significantly enhanced in the chatbot scenario.",G06F 17/30,"MICROSOFT TECHNOLOGY LICENSING, LLC.","DUAN, Nan; ZHOU, Ming",,EP-2016910206; CN-201680087962.2
WO2018157329,PCT/CN2017/075317,01.03.2017,WO/2018/157329,07.09.2018,WO,PROVIDING CONTENT,The present disclosure provides method and apparatus for providing content in an electrical game. Current interface information of the electrical game may be obtained. Content associated with the electrical game may be provided in a chat flow based on at least the current interface information.,G06F 3/048; G06F 17/28,"MICROSOFT TECHNOLOGY LICENSING, LLC; WU, Xianchao","WU, Xianchao",,CN-201780029269.4; EP-2017899009
WO2007061451,PCT/US2006/025101,28.06.2006,WO/2007/061451,31.05.2007,WO,A KNOWLEDGE CORRELATION SEARCH ENGINE,"Clauses are important for a variety of NLP tasks such as predicting phrasing in text-to- speech synthesis and inferring text alignment for machine translation (Ejerhed 1988, Leffa 1998, Papageorgiou 1997). The Computational Natural Language Learning 2001 shared task (Sang & Déjean 2001) set the goal of identifying clause boundaries in text using machine learning methods. Systems created for the task predicted a label for each word specifying the number of clauses starting and ending at that position in the sentence without differentiating between clause types. This work extends that of the shared task in several ways: (1) performance bounds are explored, (2) an attempt is made to distinguish 'main' and 'subordinate' clauses, and (3) Winnow and maximum entropy, model classes proven effective in similar domains yet not previously employed for the task, are applied to the problem.",G06F 17/30,"BOBICK, Mark; WIMMER, Carl; Make Sence, Inc.","BOBICK, Mark; WIMMER, Carl","11/273,568 14.11.2005 US; 11/314,835 21.12.2005 US",CN-200680042357.X; IN-764/MUMNP/2008; EP-2006774152; JP-2008541146
WO2019221850,PCT/US2019/026932,11.04.2019,WO/2019/221850,21.11.2019,WO,BUILDING MANAGEMENT AUTONOMOUS HVAC CONTROL USING REINFORCEMENT LEARNING WITH OCCUPANT FEEDBACK,"A building management system includes one or more processors, and one or more computer-readable storage media communicably coupled to the one or more processors and having instructions stored thereon that cause the one or more processors to: define a state of a zone or space within a building; control an HVAC system to adjust a temperature of the zone or space corresponding to a first action; receive utterance data from a voice assist device located in the zone or space; analyze the utterance data to identify a sentiment relating to the temperature of the zone or space; calculate a reward based on the state, the first action, and the sentiment; determine a second action to adjust the temperature of the zone or space based on the reward; and control the HVAC system to adjust the temperature of the zone or space corresponding to the second action.",G05B 15/02; G05B 13/02; F24F 11/30; F24F 11/62; F24F 120/20,JOHNSON CONTROLS TECHNOLOGY COMPANY,"RAMAMURTI, Viswanath; LEE, Young M.; PARK, Youngchoon; MURUGESAN, Sugumar","15/980,547 15.05.2018 US",
WO2019095033,PCT/CA2018/000207,05.11.2018,WO/2019/095033,23.05.2019,WO,METHOD AND SYSTEM FOR PRESENTING A USER SELECTABLE INTERFACE IN RESPONSE TO A NATURAL LANGUAGE REQUEST,"The present invention discloses numerous implementations of system and method which receives a user request and, using methods of natural language processing including part of speech tagging, analyses the user request to generate a query to a database of information. Based on the machine understanding, the system presents an interactive representation of the uttered request back to the user. This provides context to the user, which explains the machine understanding of the request and acts as an interface to iteratively refine or adjust the machine understanding by altering specific elements of the uttered language. The methods of altering specific elements of the uttered language may vary depending on the element and a variety of user selectable interfaces may be used to display one or more queried elements along with alternative elements pertaining to the queried element. The user could select an alternative element and change the database query.",G06F 17/30; G06F 16/9032; G06F 16/9038; G06F 17/27,MINDBRIDGE ANALYTICS INC.,"MILLIGAN, Nicolas Yvon Elijah; GROSSET, Robin Neil","15/812,710 14.11.2017 US",
WO2019241619,PCT/US2019/037166,14.06.2019,WO/2019/241619,19.12.2019,WO,DEEP ACTIONABLE BEHAVIORAL PROFILING AND SHAPING,"Behavioral profiling and shaping is used in a ""closed-loop"" in that an interaction with at least one human is monitored and based on inferred characteristics of the interaction with that human (e.g., their behavioral profile) the interaction is guided. In one exemplary embodiment, the interaction is between two humans, for example, a ""customer"" and an ""agent"" and the interaction is monitored and the agent is guided according to the inferred behavioral profile of the customer (or optionally of the agent themselves).",G06Q 30/00; G06Q 30/02; G06F 17/27,"BEHAVIORAL SIGNAL TECHNOLOGIES, INC.","KATSAMANIS, Athanasios; NARAYANAN, Shrikanth; POTAMIANOS, Alexandros","62/684,934 14.06.2018 US",
WO2018140099,PCT/US2017/057044,17.10.2017,WO/2018/140099,02.08.2018,WO,AUTOMATIC SUGGESTED RESPONSES TO IMAGES RECEIVED IN MESSAGES USING LANGUAGE MODEL,"Implementations relate to automatic response suggestions to images included in received messages. In some implementations, a computer-implemented method includes detecting an image posted within a first message by a first user, and programmatically analyzing the image to determine a feature vector representative of the image. The method programmatically generates one or more suggested responses to the first message based on the feature vector, each suggested response being a conversational reply to the first message. Generating the suggested responses includes determining probabilities associated with word sequences for the feature vector using a model trained with previous responses to previous images, and selecting one or more of the word sequences based on the associated probabilities. The suggested responses are determined based on the selected word sequences. The method causes the suggested responses to be rendered in the messaging application as one or more suggestions to a second user.",G06F 17/27; G06F 17/28,GOOGLE LLC,"FUXMAN, Ariel; RAMAVAJJALA, Vivek; YE, Ning","15/415,506 25.01.2017 US",KR-1020197011687; JP-2019520680; CN-201780066316.2; EP-2017794825
WO2010105214,PCT/US2010/027218,12.03.2010,WO/2010/105214,16.09.2010,WO,QUESTION-ANSWERING SYSTEM AND METHOD BASED ON SEMANTIC LABELING OF TEXT DOCUMENTS AND USER QUESTIONS,"A question-answering system for searching exact answers in text documents provided in the electronic or digital form to questions formulated by user in the natural language is based on automatic semantic labeling of text documents and user questions. The system performs semantic labeling with the help of markers in terms of basic knowledge types, their components and attributes, in terms of question types from the predefined classifier for target words, and in terms of components of possible answers. A matching procedure makes use of mentioned types of semantic labels to determine exact answers to questions and present them to the user in the form of fragments of sentences or a newly synthesized phrase in the natural language. Users can independently add new types of questions to the system classifier and develop required linguistic patterns for the system linguistic knowledge base.",G06F 17/30; G06F 17/20; G06F 17/28; G06F 17/21,"INVENTION MACHINE CORPORATION; TODHUNTER, James; SOVPEL, Igor; PASTANOHAU, Dzianis","TODHUNTER, James; SOVPEL, Igor; PASTANOHAU, Dzianis","61/159,959 13.03.2009 US; 61/159,972 13.03.2009 US",EP-2010751508; JP-2011554249; CN-201080020564.1; KR-1020117023697
WO2019005348,PCT/US2018/034263,24.05.2018,WO/2019/005348,03.01.2019,WO,VIRTUAL ASSISTANT PROVIDING ENHANCED COMMUNICATION SESSION SERVICES,"Methods for providing enhanced services to users participating in communication sessions (CS), via a virtual assistant, are disclosed. One method receives content that is exchanged by users participating in the CS. The content includes natural language expressions that encode a conversation carried out by users. The method determines content features based on natural language models. The content features indicate intended semantics of the natural language expressions. The method determines a relevance of the content and identifies portions of the content that are likely relevant to the user. Determining the relevance is based on the content features, a context of the CS, a user-interest model, and a content-relevance model of the natural language models. Identifying the likely relevant content is based on the determined relevance of the content and a relevance threshold. A summary of the CS is automatically generated from summarized versions of the likely relevant portions of the content.",G06F 17/30; G06F 17/27; G06F 17/28; H04L 12/58; H04L 29/08; G06Q 10/10,"MICROSOFT TECHNOLOGY LICENSING, LLC","SOMECH, Haim; WEINBERG, Shira; MILLER, Adi","15/636,346 28.06.2017 US",EP-2018734662
WO2003034274,PCT/AU2002/001422,18.10.2002,WO/2003/034274,24.04.2003,WO,SYSTEM AND METHOD OF IMPROVED RECORDING OF MEDICAL TRANSACTIONS,"This invention relates to the field of patient health care. In particular, it relates to medical informatics, and to systems and methods for recording medical transactions. A system for recording medical transactions is disclosed, the system comprising distinct and multi-linguistic representation layers, allowing the de novo composition and construction of medical transaction codes; including a user interface including means for inputting medical transactions in a semiotic form one, the semiotic form one input being a free form-type, abbreviation-oriented natural language textual input, a transaction parser-coder configured to parse said semiotic form one input and to convert it into coded medical transactions in a semiotic form two output, the transaction codes composed and constructed de novo, the semiotic form two output embodying high level machine-parseable computer language statements comprehensible to a high certainty level by human users, means for evoking a display of system reflection in the form of coded medical transactions in said semiotic form two and system-rated confidence levels representing the match between a code and correspondence with perceived user intent, means for receiving user selection input for verifying a selected coded medical transaction, and a transaction mapper configured to convert a semiotic form two input into a semiotic form three transaction by mapping the selected coded transaction into data row in a relational database to render the transaction data amenable to structured query language processing. There is further disclosed a computer-based method for the management of medical transactions, including storing each medical transaction as a transaction code in a data row in a database table, each transaction code including a genre key relating to the nature of the transaction, and including providing storage ledgers for each genre, such that each transaction can be retrieved and displayed as an entry in a storage ledger in accordance with its genre key. This allows medical transations to be treated akin to accounting transactions, signifying credits and debits in defined transaction ledgers.",G06F 17/20; G06F 17/30; G06F 19/00; G06Q 10/00,"OON, Yeong, Kuang","OON, Yeong, Kuang",PR 8354 18.10.2001 AU; PR 9225 30.11.2001 AU; PS 1767 17.04.2002 AU; PS 2844 07.06.2002 AU; 2002951382 05.09.2002 AU,EP-2002801247; CA-2461214; AU-2002332971; US-10491933; JP-null
WO2008139724,PCT/JP2008/001145,04.05.2008,WO/2008/139724,20.11.2008,WO,LANGUAGE PROCESSING SYSTEM,"Simplification of an input sentence into a sentence having a simplicity at a level similar to that of a symbolic logic formula, inference using such a sentence (natural language sentence), and generation of an output sentence on the basis of such a sentence are realized by an adequately simple and integral method. Firstly, inference which has been conventionally made by a symbolic logic scheme is realized by using a natural language sentence having a simplicity at a level similar to that of a symbolic logic formula, thereby unification and simplification of conversion from an input sentence into an output sentence are achieved.  Secondary, paraphrase of an input sentence to a sentence at the symbolic logic formula level to an output sentence can be realized by reversely using the paraphrase of the input sentence to a sentence at the symbolic logic formula level.  Lastly, since a conditional formula at the symbolic logic formula level can be obtained by similar paraphrase of the original sentence, a general learning scheme can be devised.",G06F 17/28; G06F 17/21,"TERAO, Ryoma; 寺尾亮馬","TERAO, Ryoma; 寺尾亮馬",2007-146115 07.05.2007 JP,
WO2002027536,PCT/US2001/029943,25.09.2001,WO/2002/027536,04.04.2002,WO,EXTENDED FUNCTIONALITY FOR AN INVERSE INFERENCE ENGINE BASED WEB SEARCH,"An extension of an inverse inference search engine (Fig. 1) provides cross language document retrieval, in which the information matrix (52) used as input to the inverse inference engine is organized into rows of blocks (58) corresponding to languages within a predetermined set of natural languages. The information matrix (52) is organized into two column-wise partitions (60). The first partition consists of blocks of entries representing fully translated documents, while the second partition is a matrix of blocks of entries representing documents for which translations are not available in all of the predetermined languages.",G06F 17/20; G06F 17/30,INSIGHTFUL CORPORATION,"MARCHISIO, Giovanni, B.","60/235,255 25.09.2000 US",EP-2001977165; CA-2423476
WO2017049365,PCT/AU2016/050901,23.09.2016,WO/2017/049365,30.03.2017,WO,INTELLECTUAL PROPERTY PORTFOLIO MANAGEMENT SYSTEM,"A computer system based intellectual property (IP) portfolio management system, is provided. The system includes a data store configured to store data including user account data for a plurality of user accounts, a client interface providing user access to the system via a communication network by user computer systems or devices, a system controller in data communication with the client interface and data store via the communication network. The system controller includes a user interface and display module configured to facilitate data display to a user and receiving user input via the client interface, a user account module configured create user accounts and maintain user account information inclusive of access control of data stored in the data store for storing, updating and retrieving data stored in the data store, the data for each user including user account data, a portfolio activity controller configured to create and automatically administer a plurality of types of IP matters, each IP matter being associated with a user account, provide automated guidance of one or more activities in relation to each type of IP matter to a user and facilitate action for one or more activities in relation to an IP matter, and one or more integration modules, each configured to facilitate machine to machine communication between the system and an external IP system, whereby transactions between the external IP system and the system are executed under control of the portfolio activity controller.",G06F 17/30; G06Q 10/00; G06Q 90/00,GRIFFITH HACK PTY LTD,"BEBBER, Jurgen",2015903902 24.09.2015 AU,KR-1020187011666; US-15763086; EP-2016847663; JP-2018535205; PH-12018500656; AU-2016325873; SG-11201802423U
WO2019172546,PCT/KR2019/001801,14.02.2019,WO/2019/172546,12.09.2019,WO,ELECTRONIC APPARATUS AND CONTROL METHOD THEREOF,"An electronic apparatus is provided. The electronic apparatus includes a storage configured to store a compression rate network model configured to determine a compression rate applied to an image block from among a plurality of compression rates, and a plurality of compression noise removing network models configured to remove compression noise for each of the plurality of compression rates. The compression rate network model can be obtained by learning image characteristics of a plurality of restored image blocks corresponding to each of the plurality of compression rates through a first artificial intelligence algorithm.",H04N 19/85; H04N 19/164; H04N 19/176; H04N 19/119; G06N 20/00; G06N 3/08,"SAMSUNG ELECTRONICS CO., LTD.; SEOUL NATIONAL UNIVERSITY R&DB FOUNDATION","LEE, Hyunseung; KIM, Donghyun; MOON, Youngsu; AHN, Taegyoung; KIM, Yoonsik; PARK, Jaewoo; SOH, Jae Woong; CHO, Nam Ik; AHN, Byeongyong",10-2018-0026209 06.03.2018 KR,
EP254729651,19159376,26.02.2019,3553696,16.10.2019,EP,GENERATING A STRUCTURED DOCUMENT BASED ON A MACHINE READABLE DOCUMENT AND ARTIFICIAL INTELLIGENCE-GENERATED ANNOTATIONS,,G06K 9/00,ACCENTURE GLOBAL SOLUTIONS LTD,DI PAOLO GINO ANDRE; SACALEANU BOGDAN EUGEN; BHOWAN URVESH; DRYSDALE ROBERT,201815950515 11.04.2018 US,
WO2014162211,PCT/IB2014/001371,12.03.2014,WO/2014/162211,09.10.2014,WO,DISPLAYING FOREIGN CHARACTER SETS AND THEIR TRANSLATIONS IN REAL TIME ON RESOURCE-CONSTRAINED MOBILE DEVICES,"The present invention is related to systems and methods for translating language text on a mobile camera device offline without access to the Internet. More specifically, the present invention relates to systems and methods for displaying text of a first language and a translation of the first language text into a second language text which is displayed in real time in augmented reality on the mobile device. The processing can use a single line or a multiline algorithm designed with a plurality of processing innovations to insure accurate real-time translations without motion jitter. The invention may be used to help travelers in a foreign country with difficulties in reading and understanding text written in the local language of that country. The present invention may be utilized with wearable computers or glasses, producing seamless augmented reality foreign language translations. Some embodiments are particularly useful in translations from Asian languages to English.",G06F 17/28,"TRANSLATE ABROAD, INC.","ROGOWSKI, Ryan, Leon; WU, Huan-Yu; CLARK, Kevin, Anthony","61/791,584 15.03.2013 US",JP-2015562415; CA-2906399
WO2017201195,PCT/US2017/033159,17.05.2017,WO/2017/201195,23.11.2017,WO,MACHINE COMPREHENSION OF UNSTRUCTURED TEXT,"Described herein are systems and methods for providing a natural language comprehension system that employs a two-stage process for machine comprehension of text. The first stage indicates words in one or more text passages that potentially answer a question. The first stage outputs a set of candidate answers for the question, along with a first probability of correctness for each candidate answer. The second stage forms one or more hypotheses by inserting each candidate answer into the question and determines whether a sematic relationship exists between each hypothesis and each sentence in the text. The second processing circuitry generates a second probability of correctness for each candidate answer and combines the first probability with the second probability to produce a score that is used to rank the candidate answers. The candidate answer with the highest score is selected as a predicted answer.",G06F 17/27,MALUUBA INC.,"TRISCHLER, Adam; BACHMAN, Philip; YUAN, Xingdi; YE, Zheng; SORDONI, Alessandro","62/337,720 17.05.2016 US",EP-2017727049; CN-201780031054.6
WO1992007330,PCT/US1991/007703,16.10.1991,WO/1992/007330,30.04.1992,WO,TELECOMMUNICATIONS DEVICE AND RELATED METHOD,"A telecommunications system includes a method for at least partially automatically converting monetary amounts in a document from one currency to a second currency. In addition, the telecommunications system includes a method for at least partially automatically translating a document being input in one natural language at a transmitting machine such as a facsimile or telecopier to a second natural language to be displayed, printed or otherwise communicated at a receiving end of a telecommunications link. A document containing the monetary amounts or translated portions is transmitted from a transmitting machine (40) and displayed, printed or otherwise communicated at a receiving end (36) of a telecommunication link. The monetary conversion and/or language translation may occur at any point in the telecommunications system, particularly at a transmitting facsimile device, a receiving facsimile device or a central facility operatively connected to a telecommunication network (26). The monetary conversion is preferably accomplished fully automatically, with decoders being used for determining identities of input and output currencies.",G06F 17/28; G06Q 40/00; H04N 1/00,"RICHARD, Daniel, D.","RICHARD, Daniel, D.","598,362 16.10.1990 US; 625,460 11.12.1990 US",EP-1992902579; CA-2094281
WO2009039769,PCT/CN2008/072399,18.09.2008,WO/2009/039769,02.04.2009,WO,"VIRTUAL PET SYSTEM AND VIRTUAL PET CHATTING METHOD, APPARATUS","A virtual pet system, comprises: a virtual pet client end (201), for receiving a natural language statement and sending the statement to a question-answer server (203); A question-answer server (203), for receiving the natural language statement, making the natural language understanding treatment on the natural language statement, and generating the natural language answer based on the natural language understanding result and the rational knowledge, sending the natural language answer to the virtual pet client end (201). A virtual pet chatting method, comprises: receiving the natural language statement; making the natural language understanding treatment on the natural language statement, and generating the natural language answer based on the natural language understanding result and the rational knowledge. A question-answer server (203), comprises: a statement understanding engine unit, for making the natural language understanding treatment on the received natural language statement, and sending the natural language understanding result to a rational engine unit; a rational engine unit, for generating the natural language answer based on the natural language understanding result and the rational knowledge and sending the natural language answer; a knowledge base, for savingthe rational knowledge.",H04L 12/06; G06F 17/20; G06F 17/27; G06F 17/28,"TENCENT TECHNOLOGY (SHENZHEN) COMPANY LIMITED; 腾讯科技（深圳）有限公司; YANG, Haisong; 杨海松; LIU, Zhiyuan; 刘致远; LIU, Yunfeng; 刘云峰; YU, Rongling; 禹荣凌","YANG, Haisong; 杨海松; LIU, Zhiyuan; 刘致远; LIU, Yunfeng; 刘云峰; YU, Rongling; 禹荣凌",200710154144.2 19.09.2007 CN,US-12677074; CA-2700020; GB-1005621.6; DE-1120080025487; IN-1581/CHENP/2010
WO2014160379,PCT/US2014/026439,13.03.2014,WO/2014/160379,02.10.2014,WO,DIMENSIONAL ARTICULATION AND COGNIUM ORGANIZATION FOR INFORMATION RETRIEVAL SYSTEMS,"Systems and methods are provided that relate to dimensional articulation and cognium organization in information retrieval systems. These include, without limitation, the refinement, elucidation and presentation of dimensionally articulated controls; methods for utilizing cognium based dimensional data in the context of an information retrieval system; methods that enable hinting and inference processes for sememetic casting of terms within an IR system; methods that enable machine and human collaboration on the creation, editing, maintenance, and evaluation of dimensional tag curation for indexed artifacts; methods that enable an information retrieval system to dimensionally articulate the results of semantic analysis of an input query; methods that enable creating, editing and using training artifact sets for dimensional curation in an IR system; methods that enable creating and editing custom curation definitions; and methods for creating, maintaining and using role based indices in a dimensionally articulated IR system.",G06F 7/00; G06F 17/30,"ADVANCED SEARCH LABORATORIES, INC.","COLEMAN, Jason; HEBEL, Larry","61/781,725 14.03.2013 US; 61/781,551 14.03.2013 US; 61/781,683 14.03.2013 US; 61/781,518 14.03.2013 US; 61/781,770 14.03.2013 US; 61/781,711 14.03.2013 US; 61/781,590 14.03.2013 US; 61/781,386 14.03.2013 US; 61/781,572 14.03.2013 US; 61/781,610 14.03.2013 US",
WO2015132582,PCT/GB2015/050616,03.03.2015,WO/2015/132582,11.09.2015,WO,"MAPPING, TRANSLATION AND CATEGORISATION METHOD AND SYSTEM","A system for converting a first term (1040) in a first language to a second term (1050) in a second language that is distinct to the first language, the terms comprising identifying codes with equivalent meanings that represent goods and/or services, the system comprising a mapping system (1000) arranged to: allocate the first term (1040) to at least one of a first set of categories associated with the first term (1040); identify at least one of a second set of categories that corresponds with the at least one of the first set of categories; derive the second term (1050), the second term (1050) being associated with the identified at least one of the second set of categories. Further inventions are also discussed.",G06Q 30/02; G06F 17/22; G06F 17/27; G06F 17/28; G06F 17/30,"CLIFFORD THAMES GROUP LIMITED; CHRISTIE, Scott James; BYFORD, Paul Christopher","CHRISTIE, Scott James; BYFORD, Paul Christopher",1403724.6 03.03.2014 GB,EP-2015719267
EP246634840,17211256,30.12.2017,3506127,03.07.2019,EP,SYSTEM AND METHOD FOR GENERATING BLOCKS OF NATURAL LANGUAGE,,G06F 17/28,IPRALLY OY,ARVELA SAKARI; KALLIO JUHO,17211256 30.12.2017 EP,
EP14747437,05028402,23.12.2005,1801709,27.06.2007,EP,Speech generating system,,G06F 17/27; G01C 21/20; G01C 21/34; G06F 17/28; G08G 1/0962; G08G 1/0968; G10L 13/02; G10L 13/04,HARMAN BECKER AUTOMOTIVE SYS,WELLMANN HARALD,05028402 23.12.2005 EP,
WO2007016703,PCT/US2006/030570,01.08.2006,WO/2007/016703,08.02.2007,WO,METHODS TO ANALYZE BIOLOGICAL NETWORKS,"The present invention relates to a family of graph-theory based methods for the analysis of intracellular signaling networks created from biomedical literature using data-mining processes or acquired through high-content experiments. The methods of the present invention can be used to identify functional dynamic modules within biological networks that can be analyzed quantitatively for input/output relationships. In particular, the present invention relates to a computer-aided method for the in-silico analysis of signaling and other cellular interaction pathways to rank drug targets, identify biomarkers, predict side effects, and classify/diagnose patients.",G06G 7/48; G06F 3/048,"MOUNT SINAI SCHOOL OF MEDICINE OF NEW YORK UNIVERSITY; IYENGAR, Ravi; MA'AYAN, Avi","IYENGAR, Ravi; MA'AYAN, Avi","60/704,571 01.08.2005 US",DE-null; US-11997632
WO2019108629,PCT/US2018/062813,28.11.2018,WO/2019/108629,06.06.2019,WO,SYSTEMS AND METHODS FOR AIDA BASED GROUPING,"The present disclosure describes systems and methods for dynamically creating groups of users based on attributes for simulated phishing campaign. A campaign controller determines one or more attributes of a plurality of users during execution of a simulated phishing campaign and creates one or more groups of users during based on the identified attributes. The campaign controller selects a template to be used to execute a portion of the simulated phishing campaign for a first group of users and then communicates one or more simulated phishing communications to the first group of users according to the template. The template may identify a list of a plurality of types of simulated phishing communications (email, text or SMS message, phone call or Internet based communication) and at least a portion of the content for the simulated phishing communication.",H04L 29/06; G06F 17/24,"KNOWBE4, INC.","IRIMIE, Alin; SJOUWERMAN, Stu; KRAS, Greg; SITES, Eric","15/829,728 01.12.2017 US",
WO2005111860,PCT/AU2005/000695,13.05.2005,WO/2005/111860,24.11.2005,WO,A SYSTEM AND METHOD FOR RETRIEVING INFORMATION AND A SYSTEM AND METHOD FOR STORING INFORMATION,"A system for retrieving information, the system comprising: an input means arranged to obtain a statement; and a processing means arranged to: select a first record based on an element of the statement; select a second record that references the first record; examine the second record to identify a third record; and retrieve the information by using the third record.",G06F 17/27; G06F 17/28; G06F 17/20,"ROGERS, Robert, John","ROGERS, Robert, John",2004902570 13.05.2004 AU,IN-3534/KOLNP/2006; AU-2005243114; US-11568607; GB-0623430; US-2007233660; JP-2007511779; GB-0623430.6; DE-null; CN-200580014135.2
WO2001029699,PCT/US2000/028777,17.03.2000,WO/2001/029699,26.04.2001,WO,"METHOD AND SYSTEM TO ANALYZE, TRANSFER AND GENERATE LANGUAGE EXPRESSIONS USING COMPILED INSTRUCTIONS TO MANIPULATE LINGUISTIC STRUCTURES","A natural language translation system contains language-neutral modules for syntactic analysis (216), transfer (222), and morphological and syntactical generation (228) of feature structures for an input expression in a source (202) and a target language (230). The language-neutral modules are driven by language-specific grammars (212, 218, 224) to translate between the specified languages so that no knowledge about the languages need be incorporated into the modules themselves. The modules interface with the grammar rules in the form of compiled grammar programming language statements that perform the required manipulation of the feature sturctures. Because the modules are language-neutral, the system is readily adaptable to new languages simply by providing a grammar for the new language. Multiple copies of each module, each interfacing with a different natural language grammar, enables simultaneous translation of multiple languages in the same system.",G06F 17/28,"SONY ELECTRONICS, INC.","DUAN, Lei; FRANZ, Alexander; HORIGUCHI, Keiko","09/420,511 18.10.1999 US",
WO2020060830,PCT/US2019/050747,12.09.2019,WO/2020/060830,26.03.2020,WO,TEMPORAL BEHAVIOR ANALYSIS OF NETWORK TRAFFIC,"Systems and methods for implementing sequence data based temporal behavior analysis (SDTBA) to extract features for characterizing temporal behavior of network traffic are provided. The method includes extracting (510) communication and profile data associated with one or more devices to determine sequences of data associated with the devices. The method includes generating (520) temporal features to model anomalous network traffic. The method also includes inputting (550), into an anomaly detection process for anomalous network traffic, the temporal features and the sequences of data associated with the devices and formulating (560) a list of prediction results of anomalous network traffic associated with the devices.",H04L 29/06; G06F 21/55; G06N 3/08,"NEC LABORATORIES AMERICA, INC.","CHENG, Wei; TANG, Luan; SONG, Dongjin; CHEN, Haifeng; ZONG, Bo; NI, Jingchao","62/733,276 19.09.2018 US; 16/562,805 06.09.2019 US",
EP13849218,02013163,14.06.2002,1267274,18.12.2002,EP,A method and system for theme-based word sense ambiguity reduction,"Word sense ambiguity, for ""thematic"" words in a sentence, is achieved based on thematic prediction. The senses of ""thematic"" words are disambiguated in a sentence by determining and weighting possible themes for that sentence. Possible themes are determined for that sentence based on thematic information associated with the different senses of each word in the sentence. A highly deterministic thematic-based word sense disambiguation method is used to preprocess the sentence prior to further syntactic and semantic analysis, thereby enhancing accuracy and decreasing the demand for computational resources (memory and CPU) by reducing input ambiguities. <IMAGE>",G06F 17/27,SAKHR SOFTWARE COMPANY,CHALABI ACHRAF,88253901 15.06.2001 US,
WO2010045375,PCT/US2009/060700,14.10.2009,WO/2010/045375,22.04.2010,WO,IMPROVING DIALOG COHERENCE USING SEMANTIC FEATURES,"The present invention provides a method for identifying a turn, such as a sentence or phrase, for addition to a platform dialog comprising a plurality of turns. Lexical features of each of a set of candidate turns relative to one or more turns in the platform dialog are determined. Semantic features associated with each candidate turn and associated with the platform dialog are determined to identify one or more topics associated with each candidate turn and with the platform dialog. Lexical features of each candidate turn are compared to lexical features of the platform dialog and semantic features associated with each candidate turn are compared to semantic features of the platform dialog to rank the candidate turns based on similarity of lexical features and semantic features of each candidate turn to lexical features and semantic features of the platform dialog.",G06F 17/00,"HONDA MOTOR CO., LTD.; GUPTA, Rakesh; RATINOV, Lev-Arie","GUPTA, Rakesh; RATINOV, Lev-Arie","61/196,056 14.10.2008 US",
WO2000074394,PCT/IL2000/000314,31.05.2000,WO/2000/074394,07.12.2000,WO,INTERACTIVE APPLICATION GENERATION SYSTEM AND TEXT PROCESSING SYSTEM,"A method for generating an application, the method including providing a plurality of components [5], each component defining an application building block [10], storing based on non-programming user input [45], a plurality of user-defined application-specific properties, each the property being associated with one of the plurality of components [65], receiving structured data input via a questionnaire [15] based at least in the part on the plurality of components, generating text based [30], at least in part, on the structured data, the generating text including dynamic runtime generation of a plurality of simple sentences from a plurality of sub-sentence segment based, at least in part, on user input, and providing an application based on at least some of the plurality of user-defined application-specific properties and on the components associated therewith. Related apparatus and methods are also provided.",G06F 17/28,"MAIMONIDES INNOVATIVE TECHNOLOGIES LTD.; BENTWICH, Isaac","BENTWICH, Isaac","60/136,932 01.06.1999 US; 09/410,455 01.10.1999 US",JP-2001500566; EP-2000931518
WO2017222738,PCT/US2017/034323,24.05.2017,WO/2017/222738,28.12.2017,WO,ARCHITECTURE AND PROCESSES FOR COMPUTER LEARNING AND UNDERSTANDING,"An architecture and processes enable computer learning and developing an understanding of arbitrary natural language text through collaboration with humans in the context of joint problem solving. The architecture ingests the text and then syntactically and semantically processes the text to infer an initial understanding of the text. The initial understanding is captured in a story model of semantic and frame structures. The story model is then tested through computer generated questions that are posed to humans through interactive dialog sessions. The knowledge gleaned from the humans is used to update the story model as well as the computing system's current world model of understanding. The process is repeated for multiple stories over time, enabling the computing system to grow in knowledge and thereby understand stories of increasingly higher reading comprehension levels.",G06F 17/27; G06F 17/28,ELEMENTAL COGNITION LLC,"BARBORAK, Mike; BUCHANAN, David; BURNHAM, Greg; CHU-CARROLL, Jennifer; FERRUCCI, David; KALYANPUR, Aditya; LALLY, Adam; PACIFICO, Stefano; WANG, Chang","15/192,796 24.06.2016 US",JP-2019519963; KR-1020187037504; CN-201780039293.6; EP-2017815898
WO2002073451,PCT/IL2002/000202,13.03.2002,WO/2002/073451,19.09.2002,WO,DYNAMIC NATURAL LANGUAGE UNDERSTANDING,"Described are methods and systems for dynamic natural language understanding. A hierarchical structure of semantic categories is exploited to assist in the natural language understanding. Optionally, the natural language to be understood includes a request.",G06F 17/27; G06F 17/28,"INTELLIGATE LTD.; LAVI, Ofer; AUERBACH, Gadiel; PERSKY, Eldad","LAVI, Ofer; AUERBACH, Gadiel; PERSKY, Eldad","60/275,598 13.03.2001 US",JP-null; EP-2002703828
EP12029814,89312093,21.11.1989,0370778,30.05.1990,EP,Method for manipulating digital text data,"A technique for processing natural language text uses a data structure that includes structure data in the text data. The structure data indicates an autonomous punctuational structure of the text, a punctuational structure that is independent of the lexical content of the text and therefore can be manipulated without considering the meaning of the words in the text. The data structure can be a tree in which each node has a textual type such as a paragraph, sentence, clause, phrase, or word. The data structure could alternatively be parallel data sequences, one with codes indicating the text's characters and the other with codes indicating textual types. The data structure is produced and maintained using a grammar of textual types, indicating for each textual type the textual types of units into which it can properly be divided. During editing, a text sequence is generated by applying rendering rules to the data structure, and the text is presented to the user based on the text sequence. Prior to generating the text sequence, information relating to punctuational features is propagated through the data structure. User signals requesting editing operation are applied to modify the data structure using operations rules, and the user's pointing or selecting signals are mapped onto the data structure. The modified data structure is checked with the grammar of textual types to ensure that it has an autonomous punctuational structure. A modified text sequence is then generated, and a modified text is displayed based on it.",G06F 17/21; G06F 17/27,XEROX CORP,NUNBERG GEOFFREY D; STANSBURY TAYLOE H; ABBOTT CURTIS; SMITH BRIAN C,27415888 21.11.1988 US,
WO2000055761,PCT/US2000/007083,17.03.2000,WO/2000/055761,21.09.2000,WO,METHODS FOR CREATING AND EDITING TOPICS FOR VIRTUAL ROBOTS CONVERSING IN NATURAL LANGUAGE,"Automated methods are provided for the editing and authoring of topic scripts for the dynamic operation of virtual robots. A virtual robot, or BOT, processes natural language input from a user to effect certain actions according to use input. Typically, BOTs are constructed using topic scripts. Topic scripts may comprise example statements that typify the topic in question and patterns that are matched against user input to determine if the topic is activated by the user input. The steps of one embodiment of the present invention comprise: for an example statement associated with a topic script; testing said example statement against patterns in the topic script to determine if said example statement activates said topic; then for a word in an example statement not activating said topic: identifying zero or more pattern lists matching said word; then choosing one action from among a group of actions comprising: keeping said word; and replacing said word with a pattern list; then adding zero or more revised patterns to said topic script.",G06F 17/24; G06F 17/27; G06F 17/28,"NATIVEMINDS, INC.; BENSON, Scott; DILLINGER, Ray, S.; TACKETT, Walter, A.","BENSON, Scott; DILLINGER, Ray, S.; TACKETT, Walter, A.","09/271,665 18.03.1999 US",US-09581306; EP-2000918060
WO2012174738,PCT/CN2011/076275,24.06.2011,WO/2012/174738,27.12.2012,WO,EVALUATING QUERY TRANSLATIONS FOR CROSS-LANGUAGE QUERY SUGGESTION,"Computer-implemented methods, systems, computer program products for generating cross-language query suggestions are described. For each query suggestion written in a first natural language, candidate segmentations are generated from the query suggestion, and candidate translations are generated from each candidate segmentation. The candidate translations are evaluated based on a measure of segmentation quality associated with the respective candidate segmentation from which each candidate translation is derived, and a frequency of occurrence of the candidate translation in a target language query log. The measure of segmentation quality associated with each candidate segmentation is further based on a frequency of occurrence of the candidate segmentation in a source language query log. A candidate translation is provided as a cross-language query suggestion for the primary language query suggestion based on the result of the evaluation.",G06F 17/30,"GOOGLE INC.; CHEN, Qiliang; TAN, Weihua","CHEN, Qiliang; TAN, Weihua",,
WO2019152426,PCT/US2019/015696,29.01.2019,WO/2019/152426,08.08.2019,WO,USING COMMUNICATIVE DISCOURSE TREES TO DETECT A REQUEST FOR AN EXPLANATION,"Systems, devices, and methods of the present invention relate to detecting a request for explanation in text. In an example, a method creates a discourse tree from a subset of text. The discourse tree includes nodes, each nonterminal node representing a rhetorical relationship between two of the fragments and each terminal node of the nodes of the discourse tree is associated with one of the fragments. The method forms a communicative discourse tree from the discourse tree by matching each fragment that has a verb to a verb signature. The method further identifies that the subset of text comprises a request for an explanation by applying a classification model trained to detect a request for an explanation to the communicative discourse tree.",G06F 17/27,ORACLE INTERNATIONAL CORPORATION,"GALITSKY, Boris","62/624,001 30.01.2018 US; 62/646,711 22.03.2018 US",
WO2016020368,PCT/EP2015/067918,04.08.2015,WO/2016/020368,11.02.2016,WO,METHODS AND SYSTEMS FOR MAPPING DATA ITEMS TO SPARSE DISTRIBUTED REPRESENTATIONS,"A method of mapping data items to sparse distributed representations (SDRs) includes clustering in a two-dimensional metric space, by a reference map generator, a set of data documents selected according to at least one criterion, generating a semantic map. The semantic map associates a coordinate pair with each of the set of data documents. A parser generates an enumeration of data items occurring in the set of data documents. A representation generator determines, for each data item in the enumeration, occurrence information. The representation generator generates a distributed representation using the occurrence information. A sparsifying module receives an identification of a maximum level of sparsity. The sparsifying module reduces a total number of set bits within the distributed representation based on the maximum level of sparsity to generate an SDR having a normative fillgrade.",G06F 17/30,CORTICAL.IO GMBH,"DE SOUSA WEBBER, Francisco","62/034,269 07.08.2014 US; 62/134,202 17.03.2015 US",AU-2015299050; CA-2950676; EP-2015748026; JP-2017506821
WO2019032396,PCT/US2018/045150,03.08.2018,WO/2019/032396,14.02.2019,WO,RECONFIGURABLE FABRIC OPERATION LINKAGE,"Techniques are disclosed for reconfigurable fabric operation linkage. A first function to be performed on a reconfigurable fabric is determined, where the first function is performed on a first cluster within the reconfigurable fabric. A distance is calculated from the first cluster to a second cluster that receives output from the first function on the first cluster. A time duration is calculated for the output from the first function to travel to the second cluster. A first set of instructions for the first function is allocated to the first cluster based on the distance and the time duration. The allocating the first set of instructions is accomplished using a satisfiability solver technique including constructing a set of mapping constraints and building a satisfiability model. The satisfiability solver technique includes a Boolean satisfiability problem solving technique. The satisfiability model is solved and a solution is stored.",G06F 9/50; G06F 9/48; G06F 15/173,"WAVE COMPUTING, INC.","ESBENSEN, Henrik; SUARIS, Peter Ramyalal; CHAUDHURI, Samit","62/541,697 05.08.2017 US",
WO2009062271,PCT/BG2008/000022,12.11.2008,WO/2009/062271,22.05.2009,WO,FORMALIZATION OF A NATURAL LANGUAGE,"It is disclosed a method for formalization of a natural language allowing creation of an unambiguous model of a natural language text. It is determined the basic notions for entities that are named by a natural language and for each basic notion it is attached an unique number or name and a description, in addition it is attached a list of words which can name the basic notion for each used natural language. The unambiguous model uses only basic notions. In this way it is possible a machine to interpret the unambiguous model and to input knowledge and data in a base or to make a text generation in another natural language using the unambiguous model. Also it can be generated a text in artificial language such as a program language.",G06F 17/27,"POPOV, Ivaylo; POPOV Krasimir Nikolaev","POPOV, Ivaylo; POPOV Krasimir Nikolaev",109996 14.11.2007 BG,JP-2010533390; CN-200880115885.2; IN-4217/DELNP/2010; EP-2008850309; KR-1020107013115; CA-2705345; EA-201070614; US-12740106; UA-a201007428
WO2011156475,PCT/US2011/039606,08.06.2011,WO/2011/156475,15.12.2011,WO,AUGMENTED REALITY FOR WAGERING GAME ACTIVITY,A method includes capturing media content of a wagering game machine at a wagering game establishment with a camera of a mobile device. A location of the mobile device is determined when the media content is captured. A direction that a lens of the camera is facing when the media content is captured is determined. The wagering game machine is identified based on the location and the direction. Overlay imagery derived from wagering game activity of the wagering game machine is downloaded into the mobile device from a server. The overlay imagery is composited onto the media content to create a composited media content. The composited media content is displayed on a display of the mobile device.,G06F 17/00,"WMS GAMING, INC.; DETLEFSEN, David, E.; GAGNER, Mark, B.; GAMACHE, Brian; GURA, Damon, E.","DETLEFSEN, David, E.; GAGNER, Mark, B.; GAMACHE, Brian; GURA, Damon, E.","61/352,614 08.06.2010 US",US-13321592
WO2019070244,PCT/US2017/054940,03.10.2017,WO/2019/070244,11.04.2019,WO,DATA STRUCTURE QUERIES TO MANAGE LOADING TIME IN MULTIMEDIA CONTENT,"Systems and methods data structures queries to manage loading time of multimedia content are provided. A system receives an input audio signal from a computing device and identifies a request. The system identifies a quantized day value and a quantized time value. The system retrieves, via a lookup in a multi-dimensional matrix data structure with the quantized day value and quantized time value, signals for the quantized day value and the quantized time value. The system generates a query with the signals, and applies the query to a multimedia content data structure to identify a plurality of multimedia content items that match the plurality of signals. The system provides an indication of the plurality of multimedia content items that match the signals for the quantized day value and the quantized time value retrieved from the multi-dimensional matrix data structure.",G06F 17/30,GOOGLE LLC,"LEONG, Jian Wei",,CN-201780092060.2; EP-2017787726
WO2019237000,PCT/US2019/036057,07.06.2019,WO/2019/237000,12.12.2019,WO,SYSTEMS AND METHODS FOR EVALUATING A LOSS FUNCTION OR A GRADIENT OF A LOSS FUNCTION VIA DUAL DECOMPOSITION,"Systems and methods for evaluating a loss function or a gradient of the loss function. In one example embodiment, a computer-implemented method includes partitioning a weight matrix into a plurality of blocks. The method includes identifying a first set of labels for each of the plurality of blocks with a score greater than a first threshold value. The method includes constructing a sparse approximation of a scoring vector for each of the plurality of blocks based on the first set of labels. The method includes determining a correction value for each sparse approximation of the scoring vector. The method includes determining an approximation of a loss or a gradient of a loss associated with the scoring function based on each sparse approximation of the scoring vector and the correction value associated with the sparse approximation of the scoring vector.",G06F 17/11; G06N 20/00,GOOGLE LLC,"KALE, Satyen Chandrakant; HOLTMANN-RICE, Daniel; KUMAR, Sanjiv; YAN, Enxu; YU, Xinnan","62/682,100 07.06.2018 US",
WO2019171128,PCT/IB2018/051422,06.03.2018,WO/2019/171128,12.09.2019,WO,"IN-MEDIA AND WITH CONTROLS ADVERTISEMENT, EPHEMERAL, ACTIONABLE AND MULTI PAGE PHOTO FILTERS ON PHOTO, AUTOMATED INTEGRATION OF EXTERNAL CONTENTS, AUTOMATED FEED SCROLLING, TEMPLATE BASED ADVERTISEMENT POST AND ACTIONS AND REACTION CONTROLS ON RECOGNIZED OBJECTS IN PHOTO OR VIDEO","Described are various embodiments of system and method for a contextual and non-obstructed advertisement or contents in photo, image, video, media, post, and message. In one embodiment, a system and method are provided to present contextual advertisement on/with/overlays on user actions and reactions controls based on triggering of one or more types of events on interacted controls, interfaces, objects, contents, browser and device. In one embodiment, a system and method are provided to present recognized objects in photo or video associated actions and reactions controls including like button to enable viewing user to take one or more actions or reactions on recognized objects in photo or video including like particular object associated item, accessories, cloth, body part, place, scene, infrastructure, food item, product by clicking or tapping on object associated like button or icon. In one embodiment, a system and method are provided wherein user can intelligently manage auto viewing of feed items or posts or one or more types of contents. In one embodiment automated integration of external contents with user generated contents based on viewing user's one or more types of data. In one embodiment automated integration of external ephemeral contents with user generated contents based on viewing user's one or more types of data. In one embodiment automated integration of photo filters with user generated contents including actionable photo filters, advertisement photo filters and content item photo filters. In one embodiment enabling to select first set of photo filters and enable to select second set of photo filters for same photo and displaying first set of photo filters and in the event of swipe on photo or expiration of associated vie duration timer, displaying second set of photo filters on photo. In one embodiment enabling ephemeral photo filters. In one embodiment enabling template based advertisement post or content post.",G06F 15/16; G06F 17/30; G06Q 30/02; H04L 29/06,"RATHOD, Yogesh Chunilal","RATHOD, Yogesh Chunilal",,
WO2013079907,PCT/GB2012/000883,30.11.2012,WO/2013/079907,06.06.2013,WO,"SYSTEM, PROCESS AND METHOD FOR THE DETECTION OF COMMON CONTENT IN MULTIPLE DOCUMENTS IN AN ELECTRONIC SYSTEM","A computer-based detection tool for detecting whether content within a given document is common to content within a plurality of other, existing documents, the detection tool comprising: a character string recognizer for recognizing character strings in the content of the given document; a character string distinguisher for distinguishing main character strings and auxiliary character strings in the recognized character strings by reference to a closed list of main character strings; an encoder for encoding the content of the given document by assigning one or more digits to each main character string and one or more digits to auxiliary character strings; and a matcher for matching a plurality of n-digit streams from within the encoded content with any corresponding n-digit streams within previously- encoded content of the one or more other documents. The character strings may be encoded as a bitstream.",G06F 17/22; G06Q 10/10; G06F 21/16,"THE UNIVERSITY OF SURREY; COOKE, Neil Edward John; GILLAM, Lee","COOKE, Neil Edward John; GILLAM, Lee","13/307,428 30.11.2011 US",US-14361812; EP-2012813410
WO2006067520,PCT/GB2005/050219,30.11.2005,WO/2006/067520,29.06.2006,WO,DIGITAL SIGNAL PROCESSING METHODS AND APPARATUS,"This invention relates to a method of digitally processing data in a data array defining a target matrix (X) using non-negative matrix factorisation to determine a pair of matrices (F, G), a first matrix of said pair determining a set of features for representing said data, a second matrix of said pair determining weights of said features, such that a product of said first and second matrices approximates said target matrix, the method comprising: inputting said target matrix data (X); selecting a row of said one of said first and second matrices and a column of the other of said first and second matrices; determining a target contribution (R) of said selected row and column to said target matrix; determining, subject to a non- negativity constraint, updated values for said selected row and column from said target contribution; and repeating said selecting and determining for the other rows and columns of said first and second matrices until all said rows and columns have been updated. The invention is applicable to multi-line addressing (MLA) techniques for displays such as passive-matrix OLED displays.",G06F 17/16; G09G 3/32,"CAMBRIDGE DISPLAY TECHNOLOGY LIMITED; SMITH, Euan, Christopher; ROUTLEY, Paul, Richard; FODEN, Clare","SMITH, Euan, Christopher; ROUTLEY, Paul, Richard; FODEN, Clare",0428191.1 23.12.2004 GB,CN-200580048603.8; IN-4716/DELNP/2007; US-10578659; JP-2007547671; EP-2005813467
WO2015192117,PCT/US2015/035718,13.06.2015,WO/2015/192117,17.12.2015,WO,METHODS AND SYSTEMS FOR CREATING VIRTUAL AND AUGMENTED REALITY,"Configurations are disclosed for presenting virtual reality and augmented reality experiences to users. The system may comprise an image capturing device to capture one or more images, the one or more images corresponding to a field of the view of a user of a head-mounted augmented reality device, and a processor communicatively coupled to the image capturing device to extract a set of map points from the set of images, to identify a set of sparse points and a set of dense points from the extracted set of map points, and to perform a normalization on the set of map points.",G06K 9/00,"MAGIC LEAP, INC.","BRADSKI, Gary R.; MILLER, Samuel A.; ABOVITZ, Rony","62/012,273 14.06.2014 US",JP-2017518040; KR-1020177001117; EP-2015807476; AU-2015274283; CA-2953335; IL-249371
